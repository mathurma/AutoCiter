<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-01660</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003079</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject><subject>Sensory systems</subject></subj-group></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject><subject>Sensory systems</subject></subj-group></subj-group><subj-group><subject>Neuroimaging</subject><subj-group><subject>fMRI</subject></subj-group></subj-group><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A Two-Stage Cascade Model of BOLD Responses in Human Visual Cortex</article-title>
<alt-title alt-title-type="running-head">Two-Stage Cascade Model of Human Visual Cortex</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Kay</surname><given-names>Kendrick N.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Winawer</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Rokem</surname><given-names>Ariel</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Mezer</surname><given-names>Aviv</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Wandell</surname><given-names>Brian A.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
</contrib-group>
<aff id="aff1"><addr-line>Department of Psychology, Stanford University, Stanford, California, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Diedrichsen</surname><given-names>Jörn</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University College London, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">kendrick@post.harvard.edu</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: KK. Performed the experiments: KK. Analyzed the data: KK. Wrote the paper: KK BW. Performed retinotopic mapping: JW Provided conceptual guidance: JW AR AM.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>5</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>30</day><month>5</month><year>2013</year></pub-date>
<volume>9</volume>
<issue>5</issue>
<elocation-id>e1003079</elocation-id>
<history>
<date date-type="received"><day>21</day><month>10</month><year>2012</year></date>
<date date-type="accepted"><day>18</day><month>4</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Kay et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Visual neuroscientists have discovered fundamental properties of neural representation through careful analysis of responses to controlled stimuli. Typically, different properties are studied and modeled separately. To integrate our knowledge, it is necessary to build general models that begin with an input image and predict responses to a wide range of stimuli. In this study, we develop a model that accepts an arbitrary band-pass grayscale image as input and predicts blood oxygenation level dependent (BOLD) responses in early visual cortex as output. The model has a cascade architecture, consisting of two stages of linear and nonlinear operations. The first stage involves well-established computations—local oriented filters and divisive normalization—whereas the second stage involves novel computations—compressive spatial summation (a form of normalization) and a variance-like nonlinearity that generates selectivity for second-order contrast. The parameters of the model, which are estimated from BOLD data, vary systematically across visual field maps: compared to primary visual cortex, extrastriate maps generally have larger receptive field size, stronger levels of normalization, and increased selectivity for second-order contrast. Our results provide insight into how stimuli are encoded and transformed in successive stages of visual processing.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>Much has been learned about how stimuli are represented in the visual system from measuring responses to carefully designed stimuli. Typically, different studies focus on different types of stimuli. Making sense of the large array of findings requires integrated models that explain responses to a wide range of stimuli. In this study, we measure functional magnetic resonance imaging (fMRI) responses in early visual cortex to a wide range of band-pass filtered images, and construct a computational model that takes the stimuli as input and predicts the fMRI responses as output. The model has a cascade architecture, consisting of two stages of linear and nonlinear operations. A novel component of the model is a nonlinear operation that generates selectivity for second-order contrast, that is, variations in contrast-energy across the visual field. We find that this nonlinearity is stronger in extrastriate areas V2 and V3 than in primary visual cortex V1. Our results provide insight into how stimuli are encoded and transformed in the visual system.</p>
</abstract>
<funding-group><funding-statement>This work was supported by NEI grant RO1-EY03164 (BW) and NEI grant K99 – EY022116 (JW). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="16"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Studies of visual cortex typically measure responses to a narrow set of stimuli designed to investigate a particular phenomenon. For example, a study might use sinusoidal gratings varying in contrast to study contrast response functions <xref ref-type="bibr" rid="pcbi.1003079-Albrecht1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Carandini1">[2]</xref>, another study might use silhouettes to study shape tuning <xref ref-type="bibr" rid="pcbi.1003079-Davidenko1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Pasupathy1">[4]</xref>, and yet another study might use arrays of line segments to study texture representation <xref ref-type="bibr" rid="pcbi.1003079-Kastner1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Thielscher1">[6]</xref>. This approach provides valuable insights, but different effects are studied in isolation and different models (e.g., linear filtering, static nonlinearities, divisive normalization, MAX) are proposed for different effects. To advance our understanding, we seek to develop an integrated model that explains responses to a wide range of stimuli (<xref ref-type="fig" rid="pcbi-1003079-g001">Figure 1</xref>).</p>
<fig id="pcbi-1003079-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g001</object-id><label>Figure 1</label><caption>
<title>Building general, predictive models of the visual system.</title>
<p>We seek to develop computational models that characterize how stimuli are encoded in responses measured in the visual system. These models consist of specific computations and may have parameters that are adjusted to fit the data. Importantly, the models should operate on a wide range of stimuli and predict responses beyond those to which the models are fit.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g001" position="float" xlink:type="simple"/></fig>
<p>In this study, we measure functional magnetic resonance imaging (fMRI) responses in early visual cortex to a wide range of band-pass grayscale images, and we develop a model that starts with images and predicts these responses. The model has a cascade architecture and comprises four main components. The first component is a set of V1-like Gabor filters that are applied to the image. These filters are adapted from our previous work on modeling fMRI responses <xref ref-type="bibr" rid="pcbi.1003079-Kay1">[7]</xref>. The second component is a divisive normalization operation that is applied to filter outputs. Divisive normalization is a well-established computation that accounts for several nonlinear response properties of V1 neurons <xref ref-type="bibr" rid="pcbi.1003079-Busse1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1003079-Heeger1">[10]</xref>. The third component is a compressive static nonlinearity that is applied after summation of contrast-energy across the visual field. We recently found that this nonlinearity is important for accurately predicting responses to stimuli varying in position and size <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[11]</xref>. The fourth component is a variance-like nonlinearity that is used in the summation of contrast-energy. This nonlinearity generates selectivity for second-order contrast and shares some similarities with filter-rectify-filter models that have been proposed for texture perception <xref ref-type="bibr" rid="pcbi.1003079-Graham1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Landy1">[13]</xref>.</p>
<p>We provide software code that implements the complete model along with example datasets at <ext-link ext-link-type="uri" xlink:href="http://kendrickkay.net/socmodel/" xlink:type="simple">http://kendrickkay.net/socmodel/</ext-link>. This is useful for the goal of reproducible research <xref ref-type="bibr" rid="pcbi.1003079-Gavish1">[14]</xref> and provides the opportunity for others to improve upon our work. We welcome efforts to consider potential alternative models—including models developed in psychophysics, computer vision, and the theoretical literature, as well as models that posit specific circuit-level mechanisms—and to determine whether these models better account for the experimental measurements we have made. We hope the open exchange of data and code will spur further modeling efforts.</p>
<p>This paper is structured as follows: We start by motivating each component of our model through targeted examples of stimuli and responses. We then use cross-validation to show that the full model does not overfit the data but in fact improves prediction accuracy. Finally, we examine the parameters of the model and inspect the effect of the parameters on the behavior of the model. This examination reveals that compared to primary visual cortex, extrastriate maps generally have larger receptive field size, stronger levels of normalization, and increased selectivity for second-order contrast.</p>
</sec><sec id="s2">
<title>Results</title>
<p>We measured blood oxygenation level dependent (BOLD) responses in visual field maps V1, V2, V3, and hV4 while subjects viewed a large number of stimuli. In the main experiment, a total of 156 distinct stimuli were presented in random order 3–6 times each. The BOLD response amplitude of each voxel to each stimulus was estimated from the time-series data using a GLM (see <xref ref-type="sec" rid="s4">Methods</xref>).</p>
<sec id="s2a">
<title>Model motivation</title>
<p>The model we developed for predicting the BOLD response consists of a sequence of operations (<xref ref-type="fig" rid="pcbi-1003079-g002">Figure 2A</xref>). The BOLD response is predicted by applying V1-like Gabor filters to the luminance image (<italic>V1 energy</italic>), normalizing the filter outputs by local population activity (<italic>Divisive normalization</italic>), summing contrast-energy across a specific region of the visual field (<italic>Spatial summation</italic>) using a variance-like nonlinearity (<italic>Second-order contrast</italic>), and applying a compressive static nonlinearity (<italic>Compressive nonlinearity</italic>). The key novel component of the model is the computation of second-order contrast (<xref ref-type="fig" rid="pcbi-1003079-g002">Figure 2B</xref>), hence the name of the model. The model has eight free parameters (<xref ref-type="fig" rid="pcbi-1003079-g002">Figure 2A</xref>, bracketed variables) and is fit to the response amplitudes of each voxel.</p>
<fig id="pcbi-1003079-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g002</object-id><label>Figure 2</label><caption>
<title>Second-order contrast (SOC) model.</title>
<p>(A) Schematic of model. First, the stimulus is filtered with a set of Gabor filters at different positions, orientations, and phases; the outputs of quadrature-phase pairs are squared, summed, and square-rooted (<italic>V1 energy</italic>). Second, filter outputs are divided by local population activity (<italic>Divisive normalization</italic>). Third, filter outputs are summed across orientation, producing a map of local contrast-energy. Contrast-energy is then weighted and summed across space using a 2D Gaussian (<italic>Spatial summation</italic>). The summation is not linear; rather, the summation is performed using a variance-like nonlinearity in which average contrast-energy is subtracted before squaring and summing across space (<italic>Second-order contrast</italic>). Finally, the output of the summation is subjected to a compressive power-law function (<italic>Compressive nonlinearity</italic>), yielding the predicted response. (B) Computation of second-order contrast. Second-order contrast is computed as the variance of the contrast-energy distribution within the 2D Gaussian. In this example, there is high variation in contrast-energy and thus a high amount of second-order contrast. (C) Simplified versions of the model. To motivate the SOC model, we consider several simplified versions of the model. Each version incorporates a model component not present in the previous version.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g002" position="float" xlink:type="simple"/></fig>
<p>To motivate and explain the second-order contrast (SOC) model, we start with simpler versions of the model and incrementally build up to the full model (<xref ref-type="fig" rid="pcbi-1003079-g002">Figure 2C</xref>). At each step of the process, we assess how well a simple model explains responses to a range of stimuli and improve performance by adding a new component to the model. A caveat to this approach is that increasingly complex models may provide better fits, but these improvements may simply reflect overfitting to the noise in the data. In a later section, we use cross-validation to obtain unbiased estimates of model accuracy and verify that the more complex models are indeed more accurate than the simpler models.</p>
<p>The simplest model is the complex-cell energy (CC) model, which involves computing V1 energy and summing across the visual field. Previous studies indicate that the CC model is a reasonable starting point: the CC model accounts for substantial variance in BOLD responses in early visual areas to grayscale natural images <xref ref-type="bibr" rid="pcbi.1003079-Kay1">[7]</xref> and a closely related model accurately characterizes BOLD responses to a checkerboard pattern positioned at different visual field locations <xref ref-type="bibr" rid="pcbi.1003079-Dumoulin1">[15]</xref>. For the purposes of this project, the summation weights in the CC model were constrained to be Gaussian across space and equal for different orientations; this is a reasonable approximation for voxel responses <xref ref-type="bibr" rid="pcbi.1003079-Kay1">[7]</xref>. We assessed how well the CC model accounts for responses to a set of stimuli that included oriented gratings and mixtures of oriented gratings presented at different contrast levels (henceforth referred to as <italic>grating stimuli</italic>). <xref ref-type="sec" rid="s2">Results</xref> for an example voxel in V1 are shown (<xref ref-type="fig" rid="pcbi-1003079-g003">Figure 3</xref>).</p>
<fig id="pcbi-1003079-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g003</object-id><label>Figure 3</label><caption>
<title>Divisive normalization accounts for contrast saturation.</title>
<p>We measured responses to several types of grating stimuli varying in contrast. Responses of an example voxel are shown (subject 2, area V1, voxel 31150). The complex-cell energy (CC) model consists of V1 energy and spatial summation, and predicts that responses rise linearly with contrast. However, the actual responses exhibit saturation at low contrasts. To account for contrast saturation, we incorporated divisive normalization <xref ref-type="bibr" rid="pcbi.1003079-Heeger1">[10]</xref> into the model. The divisive normalization (DN) model fits the data accurately.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g003" position="float" xlink:type="simple"/></fig>
<p>Responses increase with contrast and with number of orientations, consistent with recent fMRI measurements <xref ref-type="bibr" rid="pcbi.1003079-Brouwer1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-McDonald1">[17]</xref>. This pattern of results is qualitatively reproduced by the CC model (<xref ref-type="fig" rid="pcbi-1003079-g003">Figure 3</xref>, red curve). However, the CC model fails quantitatively: it does not account for the fact that responses tend to saturate at low contrasts. To improve performance, we augmented the CC model with divisive normalization, a computational mechanism that explains a variety of nonlinear behaviors of V1 neurons including contrast saturation <xref ref-type="bibr" rid="pcbi.1003079-Busse1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1003079-Heeger1">[10]</xref>. The divisive normalization (DN) model fits the data accurately (<xref ref-type="fig" rid="pcbi-1003079-g003">Figure 3</xref>, orange curve).</p>
<p>To test the DN model on a wider range of stimuli, we measured responses to noise patterns covering different portions of the visual field (henceforth referred to as <italic>spatial stimuli</italic>). <xref ref-type="sec" rid="s2">Results</xref> for an example voxel in V2 are shown (<xref ref-type="fig" rid="pcbi-1003079-g004">Figure 4</xref>). The DN model does a reasonable job capturing the pattern of responses to the stimuli (<xref ref-type="fig" rid="pcbi-1003079-g004">Figure 4</xref>, orange curve). However, the model underestimates responses to stimuli covering a small portion of the receptive field and overestimates responses to stimuli covering a large portion of the receptive field. This can be seen most clearly by inspecting responses to the stimuli labeled ‘Bottom to top’.</p>
<fig id="pcbi-1003079-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g004</object-id><label>Figure 4</label><caption>
<title>Compressive nonlinearity accounts for spatial tolerance.</title>
<p>We measured responses to noise patterns covering different portions of the visual field. Responses of an example voxel are shown (subject 2, area V2, voxel 38512). The DN model underestimates responses to stimuli covering a small portion of the receptive field and overestimates responses to stimuli covering a large portion of the receptive field. To improve performance, we incorporated a compressive static nonlinearity into the model. The compressive nonlinearity is applied after spatial summation and provides increased tolerance for changes in the position and size of a stimulus <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[11]</xref>. The compressive spatial summation (CSS) model fits the data accurately.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g004" position="float" xlink:type="simple"/></fig>
<p>We observed this pattern of underestimation and overestimation of spatial responses in a previous study <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[11]</xref> and resolved the issue by applying a compressive static nonlinearity after spatial summation. Intuitively, the compressive nonlinearity boosts responses to stimuli that only partially overlap the receptive field, and can be interpreted as providing tolerance for changes in stimulus position and size <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[11]</xref>. We attempted to improve the performance of the DN model by incorporating, in an analogous fashion, a compressive nonlinearity after spatial summation. We find that the compressive spatial summation (CSS) model better fits the data (<xref ref-type="fig" rid="pcbi-1003079-g004">Figure 4</xref>, blue curve).</p>
<p>The CSS model accurately fits responses to the spatial stimuli; and since the CSS model is a more general case of the DN model, the CSS model accurately fits responses to the grating stimuli. However, the CSS model fails to fit responses to the two sets of stimuli simultaneously. For example, if the CSS model is fit to the spatial stimuli, the predicted responses to the grating stimuli substantially overestimate the actual responses (<xref ref-type="fig" rid="pcbi-1003079-g005">Figure 5A</xref>, blue curve). This failure suggests that the CSS model is incomplete and must be modified to account for the full range of responses.</p>
<fig id="pcbi-1003079-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g005</object-id><label>Figure 5</label><caption>
<title>Second-order contrast accounts for weak responses to grating stimuli.</title>
<p>(A) Second-order contrast improves model fits. We fit the CSS model to the spatial stimuli (shown in <xref ref-type="fig" rid="pcbi-1003079-g004">Figure 4</xref>) and evaluated how well the model predicts responses to the grating stimuli (shown in <xref ref-type="fig" rid="pcbi-1003079-g003">Figure 3</xref>). <xref ref-type="sec" rid="s2">Results</xref> for an example voxel are shown (subject 2, area V2, voxel 42608). The CSS model substantially overestimates the grating responses. To improve performance, we incorporated computation of second-order contrast into the model. The second-order contrast (SOC) model fits the data accurately. (B) Additional demonstration of second-order effect. We measured responses to noise patterns varying in the amount of separation between the contours composing the patterns. At low separation levels, the stimuli contain little variation in contrast-energy across space and evoke weak responses, as expected (same voxel in panel A).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g005" position="float" xlink:type="simple"/></fig>
<p>Under the CSS model, the predicted response co-varies with the total amount of contrast-energy within a certain region of the visual field (subject to a compressive nonlinearity). This explains why the model predicts large responses to the grating stimuli, as these stimuli contain contrast-energy throughout the spatial extent of the stimulus. Suppose, however, that BOLD responses are not driven by contrast-energy <italic>per se</italic>, but by variations in contrast-energy. This might explain why the grating stimuli elicit relatively weak BOLD responses.</p>
<p>To improve the performance of the CSS model, we incorporated a variance-like nonlinearity into the spatial summation stage of the model. This nonlinearity suppresses responses to stimuli with spatially homogeneous distributions of contrast-energy and enhances responses to stimuli with spatially heterogeneous contrast-energy distributions. We find that the new model, which is the full second-order contrast (SOC) model, simultaneously fits both the spatial stimuli and the grating stimuli (<xref ref-type="fig" rid="pcbi-1003079-g005">Figure 5A</xref>, green curve).</p>
<p>The noise patterns used for the spatial stimuli consist of contours that are spatially separated from one another; this spatial separation gives rise to variation in contrast-energy and generates large responses from the SOC model. We hypothesized that reducing the spatial separation of the contours would reduce variation in contrast-energy and lead to reduced BOLD responses. To test this hypothesis we measured responses to noise patterns with different levels of contour separation (<xref ref-type="fig" rid="pcbi-1003079-g005">Figure 5B</xref>). As expected, we find that the response is lowest at the smallest separation and increases at larger separations. This pattern of results is accurately predicted by the SOC model (<xref ref-type="fig" rid="pcbi-1003079-g005">Figure 5B</xref>, green curve) but not the CSS model (<xref ref-type="fig" rid="pcbi-1003079-g005">Figure 5B</xref>, blue curve).</p>
</sec><sec id="s2b">
<title>Model evaluation</title>
<p>To systematically evaluate the merit of the SOC model, we fit that model and each of the simpler models (CC, DN, CSS) independently to the data using five-fold cross-validation. Cross-validation produces a <italic>prediction</italic> of each data point based on a model that is not fit to that data point. Models are evaluated by how well model predictions match the data.</p>
<p>Because the SOC model subsumes the simpler models, it is guaranteed to produce the best fits for a given set of data. However, there is no guarantee that the SOC model will cross-validate well, i.e. generalize to unseen data. The SOC model will cross-validate well only if the effects described by the model are sufficiently large and there are sufficient data to estimate model parameters accurately. Cross-validation controls for model complexity since overly complex models will tend to fit noise in the data and, as a result, generalize poorly. Alternative methods for model selection include AIC and BIC, and these methods produce similar results (see Supporting <xref ref-type="supplementary-material" rid="pcbi.1003079.s001">Figure S1</xref>).</p>
<p>In all visual field maps, we find that the SOC model has the highest cross-validation accuracy (<xref ref-type="fig" rid="pcbi-1003079-g006">Figure 6</xref>). The accuracy of the SOC model is slightly lower than the noise ceiling, i.e., the maximum performance that can be expected given the noise in the data. Using the metric of explainable variance which takes into account the noise ceiling (see <xref ref-type="sec" rid="s4">Methods</xref>), we find that on average, the SOC model accounts for 88%, 92%, 89%, and 84% of the explainable variance in V1, V2, V3, and hV4, respectively (median across voxels in each map). These values indicate the high predictive power of the SOC model.</p>
<fig id="pcbi-1003079-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g006</object-id><label>Figure 6</label><caption>
<title>SOC model has high cross-validation accuracy.</title>
<p>Five-fold cross-validation was used to quantify the accuracy of the CC, DN, CSS, and SOC models. Vertical bars indicate the median accuracy across voxels in a given visual field map. Solid horizontal lines indicate the maximum possible performance given the noise in the data, and dotted horizontal lines indicate the performance of a control model that simply predicts the same response for every stimulus. The numbers at the top indicate the median performance of the SOC model, expressed in terms of explainable variance (see <xref ref-type="sec" rid="s4">Methods</xref>). Within each visual field map, all pairwise differences between models are statistically significant (<italic>p</italic>&lt;0.05, two-tailed sign test) with the exception of DN vs. CSS in V2.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g006" position="float" xlink:type="simple"/></fig>
<p>Metrics like variance explained are convenient for summarizing model accuracy, but it is important to examine the specific aspects of the data that drive these metrics. To visualize results from a large number of voxels on a single plot, we adopt the strategy of averaging data across voxels and averaging the predictions of each model across voxels. Note that this averaging is only for sake of visualization; cross-validation accuracy is computed on a voxel-by-voxel basis and does not involve averaging data.</p>
<p>Examining the data and model predictions for a representative visual field map, we see that the SOC model clearly outperforms the other models (<xref ref-type="fig" rid="pcbi-1003079-g007">Figure 7</xref>). In interpreting this plot, keep in mind that the predictions of a model may depend on the specific stimuli to which the model is fit. For example, when fit to a wide range of stimuli, the DN model fails to predict responses to the grating stimuli (<xref ref-type="fig" rid="pcbi-1003079-g007">Figure 7</xref>, orange curve), despite the fact that the DN model succeeds when the model is fit only to the grating stimuli (see <xref ref-type="fig" rid="pcbi-1003079-g003">Figure 3</xref>). As another example, the CC model performs quite poorly for the stimuli tested in this study (<xref ref-type="fig" rid="pcbi-1003079-g007">Figure 7</xref>, red curve), which may seem surprising given previous reports that the CC model (or variants thereof) can characterize responses to grayscale natural images <xref ref-type="bibr" rid="pcbi.1003079-Kay1">[7]</xref> and retinotopic mapping stimuli <xref ref-type="bibr" rid="pcbi.1003079-Dumoulin1">[15]</xref>. However, the results are not inconsistent. The key realization is that the CC model may perform well if fit and tested on stimuli that probe a limited range of stimulus dimensions (e.g. a limited range of contrasts). With a wide range of stimuli, failures of the CC model become evident, and more complex models are necessary to explain the data.</p>
<fig id="pcbi-1003079-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g007</object-id><label>Figure 7</label><caption>
<title>Data and cross-validated model predictions.</title>
<p>Here we visualize the cross-validation results by averaging across voxels in a visual field map. Black bars indicate the median response across voxels, and colored curves indicate the median model prediction across voxels. The CC model captures qualitative features of the data but fails quantitatively. The DN and CSS models fare better than the CC model but systematically underestimate and overestimate certain responses. The SOC model does well quantitatively predicting the full range of responses.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g007" position="float" xlink:type="simple"/></fig>
<p>We developed the SOC model using carefully controlled stimuli and have demonstrated that the model accurately characterizes responses to these stimuli. A major advantage of controlled stimuli is ease of interpretation: with controlled stimuli, it is relatively easy to identify the stimulus properties that drive effects in the data <xref ref-type="bibr" rid="pcbi.1003079-Rust1">[18]</xref>. However, a stimulus set composed of controlled stimuli is inherently biased towards certain stimulus types at the exclusion of others, leaving open the question of how well the model characterizes responses to stimuli in general.</p>
<p>To estimate general accuracy, in a separate experiment we measured responses to 35 objects and quantified how well the SOC model—with parameters derived from the controlled stimuli—predicts the responses. On average, the SOC model accounts for 65%, 72%, 69%, and 59% of the explainable variance in V1, V2, V3, and hV4, respectively (median across voxels in each map). These values are lower than the corresponding values obtained for the controlled stimuli, underscoring the fact that summary metrics of model performance are highly dependent on the type of stimuli used. Nevertheless, the values are encouragingly high and confirm that the SOC model has predictive power for ecologically relevant stimuli <xref ref-type="bibr" rid="pcbi.1003079-Felsen1">[19]</xref>. One interpretation of the reduced performance on object stimuli is that such stimuli contain higher-order features that are not accurately represented by the SOC model; investigating these features can be the focus of future studies.</p>
<p>In the divisive normalization stage of the SOC model, the population activity used to normalize filter outputs consists of the sum of the outputs of filters at the same position but different orientations (see <xref ref-type="sec" rid="s4">Methods</xref>). The reason we assumed the population has the same spatial extent as the filter outputs is simplicity: by making that assumption, the space of model parameters is vastly reduced and the interpretation of the divisive normalization stage is simplified. However, divisive normalization models of V1 neurons often consist of a central excitatory region that is normalized by a larger surround region <xref ref-type="bibr" rid="pcbi.1003079-Cavanaugh1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Sceniak1">[21]</xref>, and such models are used to account for surround suppression, a phenomenon that is closely related to second-order contrast (see <xref ref-type="sec" rid="s3">Discussion</xref>). Thus, one might speculate that if the spatial extent of the population were enlarged, the resulting model might be sufficient to account for our data.</p>
<p>To address this issue, we tested a version of the DN model in which the spatial scale over which normalization occurs is flexible and fit to the data. The hypothesis is that this model might account for the data as well as (or better than) the more complex SOC model. We find that the DN model with flexible normalization (<xref ref-type="fig" rid="pcbi-1003079-g008">Figure 8B</xref>, yellow bar) outperforms the original DN model (<xref ref-type="fig" rid="pcbi-1003079-g008">Figure 8B</xref>, orange bar) but does not achieve the same accuracy as the SOC model (<xref ref-type="fig" rid="pcbi-1003079-g008">Figure 8B</xref>, green bar). This indicates that simply enlarging the normalization pool is not sufficient and that the additional computations in the SOC model are necessary to account for the data. We also tested several other control models, including a model that demonstrates that the squaring operation in the computation of second-order contrast is critical (<xref ref-type="fig" rid="pcbi-1003079-g008">Figure 8B</xref>, cyan bar).</p>
<fig id="pcbi-1003079-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g008</object-id><label>Figure 8</label><caption>
<title>Additional control models.</title>
<p>(A) Schematic of models. Six variants of the SOC model were tested. Text annotations indicate modifications to model components (see <xref ref-type="sec" rid="s4">Methods</xref> for details). (B) Cross-validation accuracy. Format same as in <xref ref-type="fig" rid="pcbi-1003079-g006">Figure 6</xref> except that accuracy is now expressed in terms of explainable variance (the CC model is omitted as it falls outside the visible range). No model outperforms the SOC model. The RM2 model—which is a variant of the SOC model that omits the <italic>Divisive normalization</italic> component—performs about as well as the SOC model. This can be explained by the fact that there is some degree of overlap in functionality between the <italic>Divisive normalization</italic> and <italic>Compressive nonlinearity</italic> components of the SOC model.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g008" position="float" xlink:type="simple"/></fig>
<p>One of the control models (RM2) omits the <italic>Divisive normalization</italic> component of the SOC model, and performs about as well as the full SOC model. This can be attributed to the fact that the effect of <italic>Divisive normalization</italic> on the overall response of the model can be approximated, through suitable choice of parameters, by the other components of the model, most notably the <italic>Compressive nonlinearity</italic> component. For a simple example of this phenomenon, suppose we have a cascade of two power-law nonlinearities, each with exponent 0.5. If the first nonlinearity is omitted, the overall input-output relationship can still be preserved if the exponent of the second nonlinearity is set to 0.25. While a compressive nonlinearity is not an exact substitute for divisive normalization, it approximates many of the same effects within our measurements. We have chosen to include the <italic>Divisive normalization</italic> component in the SOC model for two reasons. One is to maintain historical continuity, as previous studies have incorporated divisive normalization immediately following a linear filtering stage <xref ref-type="bibr" rid="pcbi.1003079-Carandini2">[e.g. 9]</xref>. The second reason is that even though normalization (immediately after the linear filtering stage) is not essential for the current set of data, it is likely that normalization will prove essential at finer scales of measurement (sub-millimeter voxels). For example, a major effect explained by normalization is cross-orientation suppression at the level of single neurons in V1 <xref ref-type="bibr" rid="pcbi.1003079-Heeger1">[10]</xref>; this effect is largely obscured at the current scale of measurement (2.5-mm voxels). This observation highlights the fact that the model inferences we make are limited by the resolution of our BOLD measurements and that there is value in developing models at finer scales of measurement.</p>
</sec><sec id="s2c">
<title>Model parameters</title>
<p>We now turn to examining the parameters of the SOC model. There are three parameters of interest, σ, <italic>n</italic>, and <italic>c</italic>. The σ parameter controls the size of the 2D Gaussian over which contrast-energy is summed, the <italic>n</italic> parameter controls the strength of the compressive nonlinearity, and the <italic>c</italic> parameter controls the strength of the variance-like nonlinearity that generates selectivity for second-order contrast (see <xref ref-type="sec" rid="s4">Methods</xref> for details). To summarize the <italic>n</italic> and <italic>c</italic> parameters, we calculate the median parameter value across voxels in each map. To summarize the σ parameter, we fit a line relating receptive field eccentricity and σ and extract the σ value at 2° eccentricity.</p>
<p>For each parameter of interest, we plot the summary value observed in each visual field map (<xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9</xref>, top). Because raw parameter values are difficult to interpret, we also perform simulations that clarify the effect of the parameter values on the overall stimulus-response relationship (<xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9</xref>, bottom). In these simulations, we calculate the response of the SOC model using the typical parameter values found in each visual field map (thus, four instances of the SOC model were simulated). These simulations directly reflect the behavior of the SOC model as fitted to each map and do not incorporate any assumptions beyond what is determined from the data and the model.</p>
<fig id="pcbi-1003079-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g009</object-id><label>Figure 9</label><caption>
<title>Parameters of the SOC model vary systematically across visual field maps.</title>
<p>(A) Size parameter (σ). The top panel shows the estimated σ value at 2° eccentricity for each visual field map. To quantify receptive field size, we compute model responses to small white spots (0.25°×0.25°) and fit 2D Gaussians to the results. The bottom panel shows contours at ±2 s.d. of the fitted Gaussians. (B) Exponent parameter (<italic>n</italic>). The top panel shows the median <italic>n</italic> value for each visual field map. To demonstrate the effect of <italic>n</italic>, we compute model responses to full-field noise patterns varying in contrast (same patterns used for the spatial stimuli). The bottom panel shows the resulting contrast response functions, normalized such that the maximum response is 1. (C) Second-order parameter (<italic>c</italic>). The top panel shows the median <italic>c</italic> value for each visual field map. To interpret the effect of <italic>c</italic>, we compute model responses to a 20%-contrast plaid pattern covering the entire receptive field and the same plaid pattern covering half of the receptive field. The bottom panel shows responses to the full and half plaids, normalized such that the response to the full plaid is 1. For reference we also show results obtained when <italic>c</italic> is set to 0.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g009" position="float" xlink:type="simple"/></fig>
<p>Inspecting the variation in parameter values, we find that the σ parameter increases from V1 to V2 to V3 to hV4, reflecting an increase in receptive field size (<xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9A</xref>). We find that the <italic>n</italic> parameter decreases from V1 to V2 to V3 to hV4, reflecting an increase in normalization (<xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9B</xref>). Finally, we find that the <italic>c</italic> parameter is higher in V2 and V3 than it is in V1 and hV4, reflecting increased selectivity for second-order contrast (<xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9C</xref>). All pairwise differences between visual field maps are statistically significant (<italic>p</italic>&lt;0.05, two-tailed randomization test) with the exception of <italic>n</italic> in V3 vs. hV4 and <italic>c</italic> in V2 vs. V3.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>We describe a computational model, termed the second-order contrast (SOC) model, that predicts BOLD responses in early visual cortex to grayscale band-pass filtered images. The model builds on earlier modeling work <xref ref-type="bibr" rid="pcbi.1003079-Kay1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Heeger1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Dumoulin1">[15]</xref> and introduces a variance-like nonlinearity that generates selectivity for second-order contrast. The parameters of the model vary systematically across visual field maps, reflecting differences in receptive field size, differences in the strength of normalization, and differences in selectivity for second-order contrast.</p>
<sec id="s3a">
<title>Building functional models of visual responses</title>
<p>We have developed a model that predicts BOLD responses to a wide range of stimuli. Stimulus-driven BOLD responses arise principally from metabolic demands of peri-synaptic neural activity <xref ref-type="bibr" rid="pcbi.1003079-Logothetis1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Logothetis2">[23]</xref>. Hence, BOLD is one of the many ways that neural activity can be measured, and our model of BOLD responses is a model of neural population responses. However, the spatial resolution of our BOLD measurements (2.5-mm voxels) is lower than the resolution required to analyze and dissect neural circuits, and this may lead some to conclude that our model of BOLD responses does not actually provide much insight into neural computation. We believe this view to be in error.</p>
<p>To explain our position, it is useful to highlight the distinction between <italic>functional models</italic> and <italic>circuit models</italic>. Functional models are stimulus-referred (i.e. start with the stimulus) and specify what aspects of the stimulus drive responses in a given area. Building functional models has a long history in electrophysiology <xref ref-type="bibr" rid="pcbi.1003079-Carandini3">[for review]</xref>, , where researchers explain the spiking activity of neurons in terms of relatively simple computations applied to the stimulus. Circuit models go further than functional models by identifying the specific neural circuitry that gives rise to the observed responses. Hence, functional models may be simpler than circuit models and multiple competing circuit models may be consistent with a given functional model. There is value in functional characterizations of neural responses, especially if one seeks to link neural circuits to perceptual judgments and behavior <xref ref-type="bibr" rid="pcbi.1003079-Carandini4">[26]</xref>.</p>
<p>To illustrate the distinction between functional models and circuit models, consider a model that explains the spiking activity of a V1 simple cell by the application of an oriented linear filter to the stimulus, followed by a rectification nonlinearity. This model, known as an LN or linear-nonlinear model <xref ref-type="bibr" rid="pcbi.1003079-Carandini3">[24]</xref>, is a functional but not a circuit model—it describes how stimuli relate to responses, but does not characterize the many stages of processing performed by the visual system before V1 (e.g. retina, LGN) nor the specific neural circuit by which orientation tuning arises <xref ref-type="bibr" rid="pcbi.1003079-Priebe1">[e.g. feedforward computation on LGN afferents or intracortical processing within V1—see 27]</xref>. Nevertheless, the model is useful for understanding how stimuli are represented in the visual system.</p>
<p>The SOC model developed in this paper is a functional model—it characterizes the relationship between visual stimuli and measured BOLD responses. Like functional models of neuronal responses, the SOC model does not propose specific neural circuits. Rather, the SOC model provides insight at the functional level, that is, in identifying the aspects of the stimulus that drive responses in different visual field maps. For example, the model indicates that second-order contrast is an important factor that drives population responses in V2 and V3, and we can reasonably infer that this same stimulus property drives responses of individual neurons in these maps. To test and expand upon this hypothesis, one could adapt the stimuli and model used in this study to single-unit electrophysiology and assess how well neuronal responses are accounted for. In doing so, we may find it necessary to extend the model to account for response properties that are evident at the level of individual neurons but which are not readily observed at the population level.</p>
</sec><sec id="s3b">
<title>Nonlinearities in neurovascular coupling</title>
<p>Neural activity is coupled to the BOLD response through a complex set of neurovascular mechanisms <xref ref-type="bibr" rid="pcbi.1003079-Logothetis2">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Heeger2">[28]</xref>. Thus, physiological responses measured using BOLD fMRI reflect both neural activity and these coupling mechanisms. Since the coupling mechanisms are not explicitly modeled in the present work, an implicit assumption in the interpretation of our results is that the BOLD response provides a linear (or approximately linear) measure of some aggregated neural activity. Under this assumption, we attribute the various nonlinear operations in the SOC model to nonlinearities arising in neural processing. However, there may be nonlinearities in neurovascular coupling, and this possibility limits the inferences we can make from our BOLD measurements. For example, if there is a nonlinearity in the relationship between the total amount of neural activity in a voxel and the strength of the BOLD response measured from that voxel, then the level of compression estimated by the <italic>Compressive nonlinearity</italic> component of the SOC model may differ from the level of compression associated with the underlying neural activity. Going forward, we believe that developing a better understanding of the different types of neural activity (e.g. synaptic activity, spiking activity) and the mechanisms that couple these various types of neural activity to the BOLD response is of high importance.</p>
</sec><sec id="s3c">
<title>Cascade architecture of the SOC model</title>
<p>The SOC model has a cascade architecture, consisting of a series of computations that are applied to the stimulus. The success of the SOC model is consistent with the long-standing hypothesis that the visual system can be characterized as a cascade of operations <xref ref-type="bibr" rid="pcbi.1003079-DiCarlo1">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1003079-Wang1">[34]</xref>. However, cascade models come in a variety of different forms and vary in essential characteristics such as the number of stages in the model and the computations that are applied at each stage. Our work contributes to the field by proposing a specific model and showing that this model quantitatively accounts for a sizable range of experimental measurements in the living human brain.</p>
<p>The SOC model is most similar to the cascade model that is being developed by Heeger, Landy, and colleagues <xref ref-type="bibr" rid="pcbi.1003079-Wang1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Hallum1">[35]</xref>. These authors propose that the stimulus is transformed through two or more stages of canonical operations, each stage consisting of filtering, which is a linear operation (L); rectification, which is a nonlinear operation (N); and normalization, which is a nonlinear operation (N). Mapping these operations onto the SOC model, we see that the SOC model is a two-stage cascade model with an overall form of LNNLNN (<xref ref-type="fig" rid="pcbi-1003079-g002">Figure 2A</xref>).</p>
<p>There are differences between the SOC model and the Heeger-Landy model. First, the SOC model is fully computable, starting with images and predicting physiological responses. Second, the filtering operation in the second stage of the SOC model is generic: variance in contrast-energy drives responses irrespective of how contrast-energy is arranged in the stimulus. In contrast, the Heeger-Landy model uses oriented second-order filters. Third, the normalization operation in the second stage of the SOC model is implemented as a compressive nonlinearity. This is reasonable because under certain conditions, the effects of divisive normalization can be approximated with a compressive nonlinearity <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[11]</xref>.</p>
<p>It is common in cascade models to designate different stages as corresponding to different visual areas. Thus, it is tempting to view the first stage of operations in the SOC model (the first LNN) as corresponding to primary visual cortex (V1) and the second stage of operations (the second LNN) as corresponding to extrastriate areas. However, this interpretation is complicated by the fact that the full two-stage SOC model predicts V1 responses more accurately than the one-stage DN model (see <xref ref-type="fig" rid="pcbi-1003079-g006">Figure 6</xref>). To reconcile this finding, we hypothesize that the computation of first-order contrast (the first LNN) occurs in V1 (or is inherited from earlier processing), the computation of second-order contrast (the second LNN) occurs downstream from V1, and feedback introduces second-order effects into V1 responses. Some support for this circuit-level hypothesis comes from studies reporting that surround suppression—which, as we later explain, is intimately related to second-order contrast—is mediated by feedback from extrastriate areas to V1 <xref ref-type="bibr" rid="pcbi.1003079-Angelucci1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Bair1">[37]</xref>.</p>
</sec><sec id="s3d">
<title>Second-order contrast in the visual system</title>
<p>A key component of the SOC model is a nonlinearity that computes variance in contrast-energy within a specific region of the visual field. This nonlinearity enhances responses to stimuli that have heterogeneous distribution of contrast-energy and suppresses responses to stimuli that have homogeneous distribution of contrast-energy. We find that the nonlinearity is substantially stronger in extrastriate areas V2 and V3 compared to V1, suggesting that selectivity for second-order contrast is mainly a feature of extrastriate cortex. We do find, however, that the strength of the nonlinearity in hV4 is comparable to that in V1, indicating that in hV4 first-order contrast is relatively effective at driving responses.</p>
<p>The concept of second-order contrast—or, more generally, second-order stimuli—has a long history in visual psychophysics <xref ref-type="bibr" rid="pcbi.1003079-Graham1">[for review]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Landy1">[ see 12,13]</xref> and other sensory modalities <xref ref-type="bibr" rid="pcbi.1003079-Joris1">[38]</xref>. Second-order stimuli involve modulation of a stimulus property (e.g. contrast) across space or time in such a way that the modulation cannot be detected by a first-order filter. For example, consider a sinusoidal grating whose amplitude is modulated by a sinusoidal grating of lower spatial frequency. Such a stimulus varies in contrast across space, but this variation cannot be detected by a first-order luminance filter since average luminance remains constant throughout the extent of the stimulus. To explain the perception of second-order stimuli, researchers have proposed filter-rectify-filter (FRF) models in which first-order filters are applied to the stimulus, the outputs of these filters are rectified, and second-order filters are applied to the rectified outputs.</p>
<p>Extending results from animal models <xref ref-type="bibr" rid="pcbi.1003079-ElShamayleh1">[e.g. 39]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Song1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Tanaka1">[41]</xref>, several fMRI studies have found evidence of second-order processing in human visual cortex <xref ref-type="bibr" rid="pcbi.1003079-Hallum1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Larsson1">[42]</xref>. These studies used adaptation techniques to infer selectivity for second-order modulation of contrast <xref ref-type="bibr" rid="pcbi.1003079-Larsson1">[42]</xref> and orientation <xref ref-type="bibr" rid="pcbi.1003079-Hallum1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Larsson1">[42]</xref>, and proposed a variant of the FRF model to account for their results <xref ref-type="bibr" rid="pcbi.1003079-Hallum1">[35]</xref>. Our results are consistent with these adaptation studies in finding that second-order effects exist in many visual field maps including V1. We extend these studies by executing a different experimental and modeling approach: We demonstrate second-order effects directly in visually evoked responses. Moreover, we develop a model that operates on images and quantitatively predicts responses at the level of single voxels.</p>
<p>Our finding that selectivity for second-order contrast is particularly strong in extrastriate areas is consistent with the fact that sparsely distributed contours strongly activate such areas <xref ref-type="bibr" rid="pcbi.1003079-Dumoulin2">[43]</xref>. This is because sparsely distributed contours give rise to large amounts of contrast variation. Our results are also consistent with the results of a study that developed and compared models of neural responses in V1 and V2 <xref ref-type="bibr" rid="pcbi.1003079-Willmore1">[44]</xref>. In that study, neural responses were characterized using a model in which V1-like filters are applied to the stimulus, the outputs of the filters are rectified, and then a flexible set of weights on the rectified filter outputs is used to predict responses. Importantly, fitted weights tended to be more negative in V2 than in V1. This suppression may serve to reduce responses to stimuli that are spatially homogeneous in contrast-energy, similar to the variance-like nonlinearity we propose in the SOC model. A quantitative comparison of these models is an important future direction.</p>
</sec><sec id="s3e">
<title>Relationship between second-order contrast and surround suppression</title>
<p>Second-order contrast is a key feature of the SOC model, and it is useful to clarify the connection between second-order contrast and phenomena that have been extensively studied in the visual system. One such phenomenon is surround suppression, which has been studied both psychophysically and physiologically and is thought to underlie perceptual processes such as scene segmentation <xref ref-type="bibr" rid="pcbi.1003079-Walker1">[45]</xref>, perceptual constancies <xref ref-type="bibr" rid="pcbi.1003079-Solomon1">[46]</xref>, and enhancement of salience differences <xref ref-type="bibr" rid="pcbi.1003079-Petrov1">[47]</xref>. A basic form of surround suppression is size tuning, whereby the response of a neuron is highest for a grating of a certain size and is suppressed if the grating is enlarged <xref ref-type="bibr" rid="pcbi.1003079-Cavanaugh1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Sceniak2">[48]</xref>. The SOC model was not specifically designed to account for size tuning, but a simulation demonstrates that the SOC model does in fact exhibit size tuning (<xref ref-type="fig" rid="pcbi-1003079-g010">Figure 10</xref>). Intuitively, response suppression for large gratings stems from the absence of variation in contrast-energy; conversely, response enhancement for small gratings stems from the presence of variation in contrast-energy. This simulation demonstrates the close relationship between second-order contrast and surround suppression.</p>
<fig id="pcbi-1003079-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g010</object-id><label>Figure 10</label><caption>
<title>SOC model exhibits surround suppression.</title>
<p>(A) Simulation results. Stimuli consisted of a horizontal grating presented within circles of different sizes. Using the typical parameter values found in V2 (see <xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9</xref>), we simulated the response of an array of model units tiling the visual field. Responses are strongest for units positioned at the edge of the grating since responses are driven primarily by variation in contrast-energy. (B) Responses of one unit (marked by a white dot in panel A). With increasing stimulus size, the response rises and then falls, consistent with surround-suppression effects found in electrophysiology <xref ref-type="bibr" rid="pcbi.1003079-Cavanaugh1">[e.g. 20]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Sceniak2">[48]</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g010" position="float" xlink:type="simple"/></fig>
<p>The SOC model's explanation of surround suppression differs from that provided by traditional models of surround suppression. In such models, a central excitatory region is divisively normalized by a larger surround region, and response suppression for large gratings stems from increased stimulation of the surround <xref ref-type="bibr" rid="pcbi.1003079-Cavanaugh1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Sceniak1">[21]</xref>. The fact that surround suppression might have different computational explanations—either divisive normalization over a large spatial extent or second-order mechanisms—has been previously recognized <xref ref-type="bibr" rid="pcbi.1003079-Hallum1">[35]</xref>. We find that divisive normalization by itself does not fully account for our data, even if the spatial extent of normalization is enlarged (see <xref ref-type="fig" rid="pcbi-1003079-g008">Figure 8B</xref>, yellow bar). Thus, our results suggest that second-order mechanisms play an essential role in producing surround suppression effects. The ability to tease apart computational explanations such as these is made possible by our approach of measuring responses to a wide range of stimuli and testing general models that operate on arbitrary stimuli.</p>
</sec><sec id="s3f">
<title>Prevalence of second-order contrast in natural images</title>
<p>Second-order contrast also has an interesting connection to the statistics of natural images. The distribution of local contrast in a natural image tends to be sparse, with local contrast often near zero <xref ref-type="bibr" rid="pcbi.1003079-Baddeley1">[50]</xref>–<xref ref-type="bibr" rid="pcbi.1003079-Tadmor1">[53]</xref>. We reasoned that because of this sparseness, the amount of second-order contrast in natural images should be relatively high. To verify this hypothesis, we constructed a collection of natural image patches and quantified the amount of second-order contrast in each image by computing the response of the SOC model to the image. For comparison we also computed responses of the SOC model after scrambling the phase spectrum of each patch.</p>
<p>The responses of the SOC model are, on average, higher for the natural image patches (<xref ref-type="fig" rid="pcbi-1003079-g011">Figure 11A</xref>). Reduced responses to the phase-scrambled patches can be attributed to the fact that phase-scrambling takes localized structures (which induce high variation in contrast-energy) and disperses them throughout the image (<xref ref-type="fig" rid="pcbi-1003079-g011">Figure 11B</xref>). The fact that natural stimuli have relatively high amounts of second-order contrast is consistent with previous analyses of natural image statistics <xref ref-type="bibr" rid="pcbi.1003079-Johnson1">[54]</xref>. We suggest that selectivity for second-order contrast can be interpreted as an efficient coding strategy in which the visual system is tuned to the statistical features of natural scenes <xref ref-type="bibr" rid="pcbi.1003079-Simoncelli1">[49]</xref>. Stated simply, the idea is that the visual system is tuned in such a way that commonly experienced stimuli (e.g. stimuli with second-order contrast) evoke stronger responses than less commonly experienced stimuli (e.g. stimuli without second-order contrast).</p>
<fig id="pcbi-1003079-g011" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003079.g011</object-id><label>Figure 11</label><caption>
<title>Natural images have relatively large amounts of second-order contrast.</title>
<p>(A) Simulation results. We prepared a collection of band-pass filtered natural image patches and phase-scrambled versions of these patches. We then quantified the amount of second-order contrast in each patch by computing the response of the SOC model to the patch (model parameters were set to the typical values found in V2). The median and interquartile range of responses are shown. For comparison we show results obtained when the second-order parameter <italic>c</italic> is set to 0. The SOC model but not the control model exhibits larger responses to the natural image patches. (B) Example patches. The natural image patch exhibits spatial variation in contrast, whereas its phase-scrambled counterpart is relatively homogeneous in contrast across space. Natural images were obtained from the McGill Colour Image Database <xref ref-type="bibr" rid="pcbi.1003079-Olmos1">[73]</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003079.g011" position="float" xlink:type="simple"/></fig>
<p>Our simulations show that scrambling the phase spectra of natural image patches reduces variation in contrast-energy and leads to reduced responses from the SOC model. In general, reduction in contrast-energy variation may explain why phase scrambling tends to reduce activation levels in the visual system. For example, phase-scrambling line and edge stimuli reduces variation in contrast-energy and, as expected, reduces BOLD responses in early visual areas <xref ref-type="bibr" rid="pcbi.1003079-Perna1">[55]</xref>. Of course, the phase spectrum consists of other stimulus characteristics besides variation in contrast-energy, and the visual system might also be sensitive to these characteristics. One example is alignment of phases across spatial frequencies, which occurs at edges in natural images <xref ref-type="bibr" rid="pcbi.1003079-Henriksson1">[56]</xref>.</p>
</sec><sec id="s3g">
<title>Future improvements to the SOC model</title>
<p>The SOC model has high accuracy but is not perfect, especially when tested on naturalistic object stimuli (see <xref ref-type="sec" rid="s2">Results</xref>). To improve performance, future work could continue the approach taken in the present study of designing controlled stimuli, assessing model predictions, and introducing new model components as necessary. It may be productive to consider how well the SOC model predicts responses to simple icons and shapes as such stimuli have been previously used to study the tuning properties of extrastriate areas <xref ref-type="bibr" rid="pcbi.1003079-Brincat1">[57]</xref>–<xref ref-type="bibr" rid="pcbi.1003079-Ito1">[59]</xref>.</p>
<p>Future work could also be directed towards expanding the range of stimuli for which the SOC model operates. For tractability we restricted the stimuli in this study to a band-pass range of spatial frequencies. A natural step would be to extend the SOC model to operate on stimuli with arbitrary spatial frequency content. This could be done, for example, by replicating the model architecture at multiple spatial scales and allowing the predicted response to be a weighted sum across scales. Ultimately, additional stimulus properties such as color, motion, and depth will need to be considered.</p>
</sec></sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Subjects</title>
<p>Three experienced fMRI subjects (three males; age range 29–39; mean age 33) participated in this study. All subjects had normal or corrected-to-normal visual acuity. Informed written consent was obtained from all subjects, and the experimental protocol was approved by the Stanford University Institutional Review Board. One subject (JW) was an author. Subjects participated in 1–2 scan sessions for the main experiment, and one subject participated in an additional scan session for the object experiment. Subjects also participated in 1–4 separate scan sessions to identify visual field maps <xref ref-type="bibr" rid="pcbi.1003079-Winawer1">[details in 60]</xref>.</p>
</sec><sec id="s4b">
<title>Visual stimuli</title>
<sec id="s4b1">
<title>Display and task</title>
<p>Stimuli were presented using a Samsung SyncMaster 305T LCD monitor positioned at the head of the scanner bed. Subjects viewed the monitor via a mirror mounted on the RF coil. The monitor operated at a resolution of 1280×800 at 60 Hz, and the luminance response of the monitor was linearized using a lookup table based on spectrophotometer measurements (maximum luminance 117 cd/m<sup>2</sup>). Stimuli subtended 12.5–12.8° of visual angle (viewing distance 179–183 cm). A MacBook Pro computer controlled display calibration and stimulus presentation using code based on Psychophysics Toolbox <xref ref-type="bibr" rid="pcbi.1003079-Brainard1">[61]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Pelli1">[62]</xref>. Behavioral responses were recorded using a button box.</p>
<p>For subject 1, a small dot (0.1°×0.1°) at the center of the stimulus served as the fixation point. The color of the dot changed randomly between red, green, and blue every 5–9 s. The subject was instructed to fixate the dot and to press a button whenever the dot changed color. For subjects 2–3, a more demanding attentional task was used <xref ref-type="bibr" rid="pcbi.1003079-Hallum1">[35]</xref>. A small digit (0.25°×0.25°) at the center of the stimulus served as the fixation point. The identity of the digit (0–9) changed every 0.67 s: each digit was presented for 0.5 s and was followed by a delay of 0.17 s. To minimize visual adaptation, the digit color alternated between black and white on successive presentations. Subjects were instructed to fixate the digit and to press a button whenever the same digit repeated. Digit repetitions occurred with a probability of 1/6, with a maximum of two successive identical digits allowed.</p>
</sec><sec id="s4b2">
<title>General stimulus characteristics</title>
<p>Stimuli were constructed at a resolution of 256 pixels×256 pixels and were upsampled to 800 pixels×800 pixels for display purposes. All stimuli were presented within a circular aperture filling the height of the display; the rest of the display was filled with neutral gray. The outer 0.5° of the circular aperture was smoothly blended into the background using a half-cosine function.</p>
<p>Stimuli consisted of grayscale images restricted to a band-pass range of spatial frequencies centered at 3 cycles per degree. To enforce this restriction, a custom band-pass filter was used in the generation of some of the stimuli. The filter was a zero-mean isotropic 2D Difference-of-Gaussians filter whose amplitude spectrum peaks at 3 cycles per degree and drops to half-maximum at 1.4 and 4.7 cycles per degree. Restricting the spatial frequency content of the stimuli avoids the complications of building multi-scale models and helps constrain the scope of the modeling endeavor. Even with the spatial frequency restriction, it is possible to construct a rich diversity of stimuli including objects and other naturalistic stimuli.</p>
</sec><sec id="s4b3">
<title>Main experiment (subjects 1–3)</title>
<p>This experiment consisted of 156 stimuli. Data corresponding to 103 of the stimuli are reported in this paper; data corresponding to the remaining 53 stimuli are not used and therefore not described in further detail. Each stimulus consisted of nine distinct images that were presented in quick succession. The purpose of this design was to take advantage of the slow dynamics of the BOLD response and average over stimulus dimensions of no interest (e.g. using sinusoidal gratings differing in phase to average over phase).</p>
<p><italic>SPACE (69 stimuli).</italic> These stimuli consisted of noise patterns covering different portions of the visual field. Noise patterns were created by low-pass filtering white noise at a cutoff frequency of 0.5 cycles per degree, thresholding the result, performing edge detection using derivative filters, inverting image polarity such that edges are black, and applying the custom band-pass filter (described previously). We generated nine distinct noise patterns and scaled the contrast of the patterns to fill the full luminance range. We then varied the location of the noise patterns by masking the patterns with spatial apertures. The design of the apertures was identical to that used in a previous study <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[11]</xref>. A total of 69 apertures were used: 31 vertical apertures proceeding left to right, 31 horizontal apertures proceeding bottom to top, and 7 circular apertures expanding in size from the center. To maintain the band-pass characteristic of the stimuli, aperture edges were smoothly transitioned into the background using half-cosine functions 1/6° in width.</p>
<p><italic>ORIENTATION (8 stimuli).</italic> These stimuli consisted of full-contrast sinusoidal gratings at eight different orientations. The spatial frequency of the gratings was fixed at 3 cycles per degree. Each stimulus consisted of gratings with the same orientation but nine different phases (equally spaced from 0 to 2π).</p>
<p><italic>GRATING (4 stimuli).</italic> These stimuli consisted of horizontal sinusoidal gratings at 2%, 4%, 9%, and 20% Michelson contrast. The spatial frequency of the gratings was fixed at 3 cycles per degree. Each stimulus consisted of gratings with the same contrast but nine different phases (equally spaced from 0 to 2π).</p>
<p><italic>PLAID (4 stimuli).</italic> These stimuli consisted of plaids at 2%, 4%, 9%, and 20% contrast (defined below). Each condition comprised nine plaids, and each plaid was constructed as the sum of a horizontal and a vertical sinusoidal grating (spatial frequency 3 cycles per degree, random phase). The plaids were scaled in contrast to match the root-mean-square (RMS) contrast of the GRATING stimuli. For example, the plaids in the 9% condition were scaled such that the average RMS contrast of the plaids is identical to the average RMS contrast of the gratings in the 9% GRATING stimulus.</p>
<p><italic>CIRCULAR (4 stimuli).</italic> These stimuli were identical to the PLAID stimuli except that sixteen different orientations were used instead of two.</p>
<p><italic>CONTRAST (10 stimuli).</italic> These stimuli were constructed by varying the contrast of the noise patterns used in SPACE. Ten different contrast levels were used: 1%, 2%, 3%, 4%, 6%, 9%, 14%, 21%, 32%, and 50%. These contrast levels are relative to the contrast of the patterns used in SPACE, which is taken to be 100%.</p>
<p><italic>SEPARATION (4 stimuli).</italic> These stimuli used the same type of noise patterns as SPACE but varied the amount of separation between contours. We generated noise patterns using cutoff frequencies of 2.8, 1.6, 0.9, 0.5, and 0.3 cycles per degree, and numbered these from 1 (smallest separation) to 5 (largest separation). The noise patterns used in SPACE correspond to separation 4; thus, we only constructed stimuli for the remaining separations 1, 2, 3, and 5. The noise patterns occupied the full stimulus extent (no aperture masking).</p>
</sec><sec id="s4b4">
<title>Object experiment (subject 3)</title>
<p>This experiment consisted of 35 stimuli, each of which corresponds to a single band-pass filtered object flashed nine times in quick succession (same temporal pattern as the stimuli in the main experiment). To construct the object stimuli, we obtained pre-segmented objects used in a previous study <xref ref-type="bibr" rid="pcbi.1003079-Kriegeskorte1">[63]</xref>. Objects were converted to grayscale, scaled to 200 pixels×200 pixels (9.9°×9.9°), and centered at fixation. Each image was whitened (to remove low-frequency bias) and then filtered with the custom band-pass filter (described previously). Finally, the contrast of each image was scaled to fill the full luminance range.</p>
</sec></sec><sec id="s4c">
<title>Experimental design</title>
<p>We used a randomized event-related design to minimize anticipatory and attentional effects. Stimuli were presented in 8-s trials, one stimulus per trial. During the first 3 s of a trial, the nine images comprising a given stimulus were presented in random order at a rate of 3 images per second (duty cycle: 167-ms ON/167-ms OFF). Then for the next 5 s, no stimulus was presented.</p>
<p>For the main experiment, the 156 stimuli were randomly divided into four groups. In each run, the stimuli from one of the groups were presented once and in random order. To establish the baseline signal level, each run also included null trials in which no stimuli were presented (“blank” stimuli). Two null trials were inserted at the beginning and end of each run, and one null trial was inserted after every five stimulus trials. Each run lasted 6.7 minutes. Each scan session consisted of three sets of four runs (thus, each stimulus was presented three times over the course of the session). For the object experiment, the 35 stimuli were presented once and in random order in each run. Null trials were included to establish the baseline signal level as in the main experiment. Each run lasted 6.0 minutes, and each scan session consisted of ten runs.</p>
<p>To improve signal-to-noise ratio for the main experiment in subjects 1 and 2, two independent scan sessions were conducted. The stimulus ordering in the second session was matched to that in the first session, and the data from the two sessions were directly averaged together (after data pre-processing).</p>
</sec><sec id="s4d">
<title>MRI data acquisition</title>
<p>Functional MRI data were collected at the Stanford Center for Cognitive and Neurobiological Imaging using a 3T GE Signa MR750 scanner and a Nova 32-channel RF head coil. In each scan session, 22 slices roughly parallel to the parieto-occipital sulcus were defined: slice thickness 2.5 mm, slice gap 0 mm, field-of-view 160 mm×160 mm, phase-encode direction anterior-posterior. A T2*-weighted, single-shot, gradient-echo EPI pulse sequence was used: matrix size 64×64, TR 1.337702 s, TE 28 ms, flip angle 68°, nominal spatial resolution 2.5×2.5×2.5 mm<sup>3</sup>. The TR was matched to the refresh rate of the display such that there were exactly 6 TRs for each 8-s trial.</p>
<p>For post-hoc correction of EPI spatial distortion, measurements of the <italic>B</italic><sub>0</sub> magnetic field were performed. Field maps were collected in the same slices as the functional data using a 16-shot, gradient-echo spiral-trajectory pulse sequence. Two volumes were successively acquired, one with TE set to 9.091 ms and one with TE increased by 2.272 ms, and the phase difference between the volumes was used as an estimate of the magnetic field. To track slow drifts in the magnetic field (e.g. due to gradient heating), field maps were collected before and after the functional runs as well as periodically between functional runs.</p>
</sec><sec id="s4e">
<title>Data analysis</title>
<p>Voxels in each visual field map were pooled across subjects. Unless otherwise indicated, error bars represent ±1 standard error (68% confidence intervals) across voxels and were obtained using bootstrapping.</p>
<sec id="s4e1">
<title>Data pre-processing</title>
<p>The first five volumes of each functional run were discarded to allow magnetization to reach steady-state. Differences in slice acquisition times were corrected using sinc interpolation. Field maps were phase-unwrapped using FSL's <italic>prelude</italic> utility (<ext-link ext-link-type="uri" xlink:href="http://fsl.fmrib.ox.ac.uk" xlink:type="simple">http://fsl.fmrib.ox.ac.uk</ext-link>), spatially smoothed using local linear regression <xref ref-type="bibr" rid="pcbi.1003079-Hastie1">[64]</xref>, and then interpolated over time to estimate the field strength at the acquisition time of each functional volume. These field estimates were then used to undistort the functional volumes <xref ref-type="bibr" rid="pcbi.1003079-Jezzard1">[65]</xref>. Motion was estimated from the undistorted volumes using utilities in SPM (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/" xlink:type="simple">http://www.fil.ion.ucl.ac.uk/spm/</ext-link>). Motion estimates were restricted to a manually defined 3D ellipse to avoid artifact-prone regions (e.g. near the ear canals), and were low-pass filtered at 1/90 Hz to remove high-frequency modulations that may have been caused by BOLD activations <xref ref-type="bibr" rid="pcbi.1003079-Freire1">[66]</xref>. Finally, the combined effects of distortion and motion were corrected using a single cubic interpolation of the slice-time corrected functional volumes. Raw scanner units were converted to units of percent BOLD signal change by dividing by the mean signal intensity in each voxel.</p>
<p>For each subject, data from all scan sessions were co-registered to data from the initial scan session. This was accomplished by determining rigid-body transformations that align the functional volumes of additional scan sessions to the functional volumes of the initial scan session and incorporating these transformations into the interpolation procedure that corrects distortion and motion.</p>
</sec><sec id="s4e2">
<title>GLM analysis</title>
<p>We analyzed the time-series data from each experiment using a variant of the general linear model (GLM) commonly used in fMRI <xref ref-type="bibr" rid="pcbi.1003079-Monti1">[a general review of the GLM can be found in 67]</xref>. The GLM variant that we used consisted of a flexible hemodynamic response function (HRF) characterizing the shape of the timecourse of the BOLD response, beta weights characterizing the amplitude of the BOLD response to each stimulus, polynomial regressors characterizing the baseline signal level, and global noise regressors characterizing BOLD fluctuations unrelated to the stimulus. Cross-validation (i.e. predicting left-out runs) was used to estimate the accuracy of the GLM, and bootstrapping (i.e. sampling with replacement from the runs) was used to estimate the reliability of the GLM (including error bars on response amplitudes). All subsequent analyses involved analyzing the response amplitudes estimated by the GLM. <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[See 11 for additional details on the GLM analysis.]</xref></p>
</sec><sec id="s4e3">
<title>Second-order contrast (SOC) model</title>
<p>The second-order contrast (SOC) model attempts to characterize how the images shown to the subject are encoded in the response amplitudes of each voxel. In this section we describe the computations that comprise the model; in later sections we address other issues such as model fitting and model accuracy.</p>
<p><italic>Stimulus pre-processing.</italic> The original stimulus image has a resolution of 800 pixels×800 pixels and values in the range [0,254]. The model starts by remapping the values to the range [−0.5,0.5] (which has the effect of mapping the neutral-gray background to 0) and downsampling the image to 150 pixels×150 pixels. The image is then enlarged to 180 pixels×180 pixels by padding with zeros on all sides.</p>
<p><italic>V1 energy.</italic> The first component of the model is an adaptation of a simple V1 model that we previously developed <xref ref-type="bibr" rid="pcbi.1003079-Kay1">[7]</xref>. The image is projected onto a set of isotropic Gabor filters occurring at 8 orientations, 2 quadrature phases, and a range of positions (90×90 grid). Filters occur at a single scale (appropriate since the stimuli are band-pass), with a peak spatial frequency of 3 cycles per degree and a spatial frequency bandwidth of 1 octave (full-width at half-maximum of the amplitude spectrum). Each filter is scaled such that the response to a full-contrast optimal grating is 1. Outputs of quadrature-phase filters are squared, summed, and square-rooted, analogous to the complex-cell energy model <xref ref-type="bibr" rid="pcbi.1003079-Adelson1">[68]</xref>. The results can be expressed as<disp-formula id="pcbi.1003079.e001"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e001" xlink:type="simple"/></disp-formula>where <italic>cc<sub>pos</sub></italic><sub>,<italic>or</italic></sub> indicates the complex-cell output at a given position and orientation, <italic>stimulus</italic> indicates the pre-processed stimulus image, <italic>filter<sub>pos</sub></italic><sub>,<italic>or</italic>,<italic>ph</italic></sub> indicates the filter at a particular position, orientation, and phase, and · indicates dot product.</p>
<p><italic>Divisive normalization</italic>. Each complex-cell output is divisively normalized by local population activity <xref ref-type="bibr" rid="pcbi.1003079-Carandini2">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Heeger1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Albrecht2">[69]</xref>. Local population activity is taken to be the average complex-cell output across the orientations at a given position. Formally, the operation is given by<disp-formula id="pcbi.1003079.e002"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e002" xlink:type="simple"/></disp-formula>where <italic>ncc<sub>pos</sub></italic><sub>,<italic>or</italic></sub> is the normalized complex-cell output at a given position and orientation, <italic>numor</italic> is the total number of orientations, and <italic>r</italic> and <italic>s</italic> are parameters that control the strength of the normalization.</p>
<p><italic>Spatial summation</italic>. The normalized complex-cell outputs are summed across orientation, yielding a measure of local contrast-energy at each position:<disp-formula id="pcbi.1003079.e003"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e003" xlink:type="simple"/></disp-formula>where α<italic><sub>i</sub></italic> is the amount of contrast-energy at position <italic>i</italic>. Contrast-energy is then summed across space using isotropic 2D Gaussian weights:<disp-formula id="pcbi.1003079.e004"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e004" xlink:type="simple"/></disp-formula>where <italic>w<sub>i</sub></italic><sub> = (<italic>x</italic>′,<italic>y</italic>′)</sub> is the weight at position <italic>i</italic> indexed by coordinates <italic>x</italic>′ and <italic>y</italic>′; <italic>x</italic> and <italic>y</italic> are parameters that control the center of the Gaussian; and σ is a parameter that controls the standard deviation of the Gaussian. Note that because of the scaling term, the sum of the weights equals one:<disp-formula id="pcbi.1003079.e005"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e005" xlink:type="simple"/></disp-formula></p>
<p><italic>Second-order contrast.</italic> The summation of contrast-energy across space is not linear but involves a nonlinear squaring operation (which can be understood more generally as a rectification-type nonlinearity). Specifically, the summation is computed as<disp-formula id="pcbi.1003079.e006"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e006" xlink:type="simple"/></disp-formula>where <italic>SOC</italic> is the result of the summation and <italic>c</italic> is a parameter that controls the strength of the nonlinearity. The summation term inside the parentheses computes a spatially-weighted average of contrast-energy, and the overall expression computes spatially-weighted variance in contrast-energy. To ease interpretation, we bounded the <italic>c</italic> parameter between 0 and 1. When <italic>c</italic> is 0, the variance effect is absent and the computation is analogous to mean contrast-energy; when <italic>c</italic> is 1, the variance effect is strong and the computation is analogous to variance in contrast-energy; and when <italic>c</italic> is between 0 and 1, the computation is in between pure mean and pure variance.</p>
<p><italic>Compressive nonlinearity.</italic> The final component of the model is a compressive power-law nonlinearity that is applied after spatial summation. The predicted response of the model is given by<disp-formula id="pcbi.1003079.e007"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e007" xlink:type="simple"/></disp-formula>where <italic>RESP</italic> is the predicted response, <italic>n</italic> is an exponent parameter that controls the strength of the compression, and <italic>g</italic> is a gain parameter.</p>
<p><italic>Overall summary.</italic> There are eight free parameters in the SOC model: <italic>r</italic> and <italic>s</italic> control the strength of divisive normalization, <italic>x</italic>, <italic>y</italic>, and σ control the region over which spatial summation occurs, <italic>c</italic> controls the strength of the second-order contrast effect, <italic>n</italic> controls the strength of the compressive nonlinearity, and <italic>g</italic> controls the overall gain of the predicted responses. Note that the model does not include an offset parameter. This ensures that the predicted response to a blank stimulus is 0, which is appropriate since response amplitudes reflect changes in the BOLD signal relative to a blank stimulus.</p>
</sec></sec><sec id="s4f">
<title>Model fitting</title>
<p>We fit the SOC model to each voxel using response amplitudes to the SPACE, ORIENTATION, GRATING, PLAID, CIRCULAR, and CONTRAST stimuli. Model fitting was performed using nonlinear optimization (MATLAB Optimization Toolbox) with the objective of minimizing squared error. The predicted response to a given stimulus was obtained by computing the response of the model to each of the nine images comprising the stimulus and then taking the average across these responses.</p>
<p>Fitting all of the parameters in the SOC model (<italic>r</italic>, <italic>s</italic>, <italic>x</italic>, <italic>y</italic>, σ, <italic>c</italic>, <italic>n</italic>, <italic>g</italic>) simultaneously is computationally prohibitive. To reduce computational requirements, we determined a single set of canonical values for the <italic>r</italic> and <italic>s</italic> parameters before fitting the remaining parameters (detailed below). This strategy has the additional benefit of simplifying the interpretation of the model; for example, voxel-to-voxel differences in the overall strength of normalization can be solely attributed to differences in the <italic>n</italic> parameter and not differences in the <italic>r</italic> and <italic>s</italic> parameters (see <xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9B</xref>).</p>
<p>Our fitting approach was as follows. To determine a single set of canonical values for the <italic>r</italic> and <italic>s</italic> parameters, we selected from each subject the ten voxels in V1 with the highest GLM cross-validation accuracy and exhaustively evaluated each combination of <italic>r</italic> and <italic>s</italic>, where <italic>r</italic> is chosen from {.01 .05 .1 .2 .3 .4 .5 .6 .7 1 1.5 2} and <italic>s</italic> is chosen from {.002 .005 .01 .02 .05 .1 .2 .5 1 2 4 8}. For each combination of <italic>r</italic> and <italic>s</italic>, we optimized <italic>x</italic>, <italic>y</italic>, σ, and <italic>g</italic> with <italic>c</italic> fixed to 0.9 and <italic>n</italic> fixed to 0.5, and then optimized all of these parameters simultaneously. On average across voxels, the values that produced the best fits were <italic>r</italic> = 1 and <italic>s</italic> = 0.5. We then fixed the <italic>r</italic> and <italic>s</italic> parameters to these values and fit the remaining parameters of the model for every voxel. To guard against local minima, we used a variety of initial seeds for the <italic>c</italic> and <italic>n</italic> parameters. For every combination of <italic>c</italic> and <italic>n</italic>, where <italic>c</italic> is chosen from {.1 .4 .7 .8 .85 .9 .95 .975 .99 .995} and <italic>n</italic> is chosen from {.05 .1 .2 .3 .4 .5 .6 .7 1}, we optimized <italic>x</italic>, <italic>y</italic>, σ, and <italic>g</italic> with <italic>c</italic> and <italic>n</italic> fixed, and then optimized all of these parameters simultaneously.</p>
<p>The SOC model was fit using two different resampling schemes. In the <italic>full fit</italic> scheme, we fit the model to the entire set of responses. This was used to derive best estimates of the parameters of the SOC model. In the <italic>cross-validation</italic> scheme, we fit the model using five-fold cross-validation (random selection of folds). This was used to obtain unbiased estimates of the accuracy of the SOC model.</p>
</sec><sec id="s4g">
<title>Model accuracy</title>
<p>Accuracy was quantified as the percentage of variance explained (<italic>R</italic><sup>2</sup>) in the measured response amplitudes by the cross-validated predictions of the response amplitudes:<disp-formula id="pcbi.1003079.e008"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e008" xlink:type="simple"/></disp-formula>where <italic>d<sub>i</sub></italic> indicates the <italic>i</italic>th measured response amplitude and <italic>m<sub>i</sub></italic> indicates the <italic>i</italic>th predicted response amplitude. The <italic>R</italic><sup>2</sup> value indicates the percentage of variance relative to 0 that is predicted by the model. Note that defining <italic>R</italic><sup>2</sup> with respect to deviations from 0 as opposed to deviations from the mean (which is the typical statistical formulation) avoids the arbitrariness of the mean, which varies depending on the specific data points under consideration.</p>
<p>Model accuracy was compared to the <italic>noise ceiling</italic>, defined as the maximum accuracy that a model can be expected to achieve given the level of noise in the data <xref ref-type="bibr" rid="pcbi.1003079-David1">[70]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Sahani1">[71]</xref>. Noise ceiling estimates were obtained using Monte Carlo simulations in which a known signal and noisy measurements of the signal are generated and the expected <italic>R</italic><sup>2</sup> between the signal and the measurements is calculated. In these simulations, the signal and noise are assumed to be Gaussian-distributed with parameters matched to the response amplitudes and associated error bars obtained from each voxel <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[see 11 for additional details]</xref>. Model accuracy was also compared to a <italic>flat response</italic> model that simply predicts the mean response for every stimulus.</p>
<p>To obtain a metric of model accuracy that is adjusted for the noise ceiling and the flat response model, we define <italic>percent explainable variance</italic> as<disp-formula id="pcbi.1003079.e009"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003079.e009" xlink:type="simple"/></disp-formula>where <italic>R</italic><sup>2</sup> indicates the raw performance of the model, <italic>FR</italic> indicates the performance achieved by the flat response model, and <italic>NC</italic> indicates the noise ceiling. For example, 50% explainable variance means that the amount of variance predicted by a model is halfway between the amount of variance predicted by the flat response model and the maximum amount of variance that can be predicted given the noise in the data.</p>
<p>As an additional assessment of model accuracy, we took the fits of the SOC model from the main experiment (full fit scheme) and predicted the response amplitudes in the object experiment. To compensate for instability in the gain of response amplitudes across scan sessions (e.g. due to imperfections in co-registration), we allowed a non-negative scale factor to be applied to the predicted response amplitudes before computing <italic>R</italic><sup>2</sup> values. For fair comparison, the simulations used to estimate the noise ceiling for the object predictions also included the scale adjustment.</p>
<sec id="s4g1">
<title>Simplified versions of the SOC model</title>
<p>We compared the SOC model with the CC, DN, and CSS models, which are simplified versions of the SOC model (see <xref ref-type="fig" rid="pcbi-1003079-g002">Figure 2C</xref>). Model fitting proceeded similarly for the simplified models, including using cross-validation to estimate model accuracy. For the CSS model, we exhaustively evaluated each combination of <italic>r</italic> and <italic>s</italic>; the remaining parameters were optimized by first optimizing <italic>x</italic>, <italic>y</italic>, σ, and <italic>g</italic> with <italic>n</italic> fixed to 0.5, and then optimizing the parameters simultaneously. We also tested an alternative version of the CSS model in which canonical values for the <italic>r</italic> and <italic>s</italic> parameters are determined before fitting the remaining parameters of the model, similar to the fitting strategy for the SOC model. The performance of this model was similar to the fully-optimized CSS model, so we report results for only the latter model. For the CC and DN models in <xref ref-type="fig" rid="pcbi-1003079-g003">Figure 3</xref>, since the grating stimuli do not vary in space, we fit both models assuming spatial summation at the center of the visual field. For the DN and CSS models in <xref ref-type="fig" rid="pcbi-1003079-g004">Figure 4</xref>, the parameters controlling the strength of divisive normalization (<italic>r</italic>, <italic>s</italic>) were fixed to the values determined in the example of <xref ref-type="fig" rid="pcbi-1003079-g003">Figure 3</xref>.</p>
</sec><sec id="s4g2">
<title>Additional control models</title>
<p>Besides the CC, DN, and CSS models, several additional control models were evaluated. The linear second-order (LSO) model is identical to the SOC model except that the squaring operation in the computation of second-order contrast is omitted. The flexible spatial pool (FSP) model is identical to the DN model except that the spatial scale over which normalization occurs is flexible and fit to the data. The FSP model was implemented by smoothing the map of population activity with a 2D Gaussian before divisive normalization. For each voxel we performed an exhaustive search over a range of Gaussian sizes to determine the optimal model fit. Reduced models 1–4 (RM1, RM2, RM3, RM4) are simplified versions of the SOC model (see <xref ref-type="fig" rid="pcbi-1003079-g008">Figure 8A</xref>). The RM1 and RM4 models use a fixed square-root nonlinearity after the computation of second-order contrast in order to maintain the scale of the computation. Versions of these models that omit the nonlinearity altogether perform even worse (results not shown).</p>
</sec><sec id="s4g3">
<title>Alternative methods for model selection</title>
<p>Cross-validation is a simple but computationally intensive technique for estimating the prediction error of a model (i.e. the error of the model on data not used to train the model). Alternatively, there are analytic methods that estimate prediction error—these include Akaike's information criterion (AIC) and Bayesian information criterion (BIC). Assuming Gaussian noise and adding a correction for small sample sizes, AIC is equal (up to additive constants that do not depend on the model) to <italic>n</italic> log(<italic>SSE</italic>/<italic>n</italic>)+2<italic>k</italic>+2<italic>k</italic>(<italic>k</italic>+1)/(<italic>n</italic>–<italic>k</italic>–1) where <italic>n</italic> is the number of data points, <italic>SSE</italic> is the sum of the squares of the residuals of the model fit, and <italic>k</italic> is the number of free parameters in the model. Assuming Gaussian noise, BIC is equal (up to additive constants) to <italic>n</italic> log(<italic>SSE</italic>/<italic>n</italic>)+<italic>k</italic> log(<italic>n</italic>). The model that minimizes AIC (or BIC) is selected as the best model <xref ref-type="bibr" rid="pcbi.1003079-Hastie1">[for details]</xref>, <xref ref-type="bibr" rid="pcbi.1003079-Burnham1">[ see 64,72]</xref>. We calculated AIC and BIC for the CC, DN, CSS, and SOC models and confirmed that these metrics provide similar results to cross-validation (see Supporting <xref ref-type="supplementary-material" rid="pcbi.1003079.s001">Figure S1</xref>). Note that AIC and BIC are sensitive to the scale of the data, so to aid interpretation the data from each voxel were <italic>z</italic>-scored prior to the calculation of AIC and BIC.</p>
</sec><sec id="s4g4">
<title>Estimation of receptive field location</title>
<p>Although receptive field location can be inferred from the fits of the SOC model, it is simpler and more convenient to derive receptive field location from the fits of a purely spatial model. We used a spatial model <xref ref-type="bibr" rid="pcbi.1003079-Kay2">[11]</xref> in which the predicted response is obtained by computing a weighted (isotropic 2D Gaussian) sum of an image indicating the location of the stimulus, followed by a static nonlinearity (power-law function). We fit this spatial model to each voxel using response amplitudes to the SPACE stimuli. We then derived receptive field location as a contour at two standard deviations of a 2D Gaussian that describes the response of the model to point stimuli. [This Gaussian has the same center as the model Gaussian but has a standard deviation equal to the standard deviation of the model Gaussian divided by the square root of the power-law exponent; see 11.] Receptive field locations derived in this manner are used in <xref ref-type="fig" rid="pcbi-1003079-g004">Figure 4</xref> and in voxel selection procedures as described below.</p>
</sec><sec id="s4g5">
<title>Voxel selection</title>
<p>After fitting the GLM to each voxel, we selected for further consideration all voxels that have positive GLM cross-validation accuracy (indicating that responses exhibit a reliable relationship to the stimulus) and response amplitudes that are positive on average (this excludes peripheral voxels which typically exhibit negative BOLD responses to centrally presented stimuli). These voxels were then used for all subsequent analyses, with the following exceptions.</p>
<p>One exception was the cross-validation procedure for quantifying model accuracy in the main experiment (<xref ref-type="fig" rid="pcbi-1003079-g006">Figures 6</xref>–<xref ref-type="fig" rid="pcbi-1003079-g008">8</xref>). For this procedure we selected from each visual field map in each subject the 10 voxels with the highest GLM cross-validation accuracy (30 voxels total for each map). Note that GLM cross-validation accuracy is not biased towards any particular stimulus-response model. The number 10 was chosen to reduce computational requirements to tractable levels while also being sufficiently large to produce reliable results (e.g. see error bars on <xref ref-type="fig" rid="pcbi-1003079-g006">Figure 6</xref>). To verify that results do not depend on this particular threshold level, we performed an additional analysis in which we analyzed a larger number of voxels (50 voxels from each map in each subject; 150 voxels total for each map) and systematically varied the number of voxels used for model comparison (Supporting <xref ref-type="supplementary-material" rid="pcbi.1003079.s001">Figure S1</xref>).</p>
<p>Another exception was the summary of model parameters (<xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9</xref>). For this we selected all voxels for which at least 90% of the receptive field (as derived from the simple spatial model) is contained within the stimulus bounds. This is a liberal criterion that simply excludes voxels that were inadequately sampled by the stimulus protocol.</p>
</sec><sec id="s4g6">
<title>Natural image simulations</title>
<p>To prepare a collection of natural image patches, we obtained photographs from the McGill Colour Image Database <xref ref-type="bibr" rid="pcbi.1003079-Olmos1">[73]</xref>. The photographs were converted to grayscale luminance values based on supplied calibration information and downsampled by a factor of two to reduce high-frequency noise. From the photographs we randomly extracted 10,000 image patches (33 pixels×33 pixels) and filtered these patches using the same band-pass filter used to construct the experimental stimuli. We then took each patch, created a version of the patch in which the phases of the Fourier components are randomized, and jointly scaled the contrast of the intact patch and the phase-scrambled patch to fill the full luminance range.</p>
<p>We computed the response of the SOC model to the full set of image patches. The <italic>n</italic> and <italic>c</italic> parameters of the model were matched to typical values found in V2 (<italic>n</italic> = 0.13, <italic>c</italic> = 0.993; see <xref ref-type="fig" rid="pcbi-1003079-g009">Figures 9b and 9c</xref>) and the <italic>g</italic> parameter was set such that the average response across all patches is 1. For simplicity, the parameters relating to spatial weighting (<italic>x</italic>, <italic>y</italic>, σ) were omitted from the model, and spatial constraints were enforced by simply matching the patch size to the typical receptive field size in V2 at 2° eccentricity (2.8°; see <xref ref-type="fig" rid="pcbi-1003079-g009">Figure 9A</xref>). We also computed the response of a control model identical to the original model except that the <italic>c</italic> parameter is set to 0. Setting <italic>c</italic> to 0 eliminates the second-order contrast effect from the SOC model.</p>
</sec></sec><sec id="s4h">
<title>Public datasets and software code</title>
<p>Example datasets and code implementing the SOC model are provided at <ext-link ext-link-type="uri" xlink:href="http://kendrickkay.net/socmodel/" xlink:type="simple">http://kendrickkay.net/socmodel/</ext-link>.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003079.s001" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003079.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p><bold>Model selection using alternative metrics and different threshold levels.</bold> As an alternative to cross-validation, we evaluated the accuracy of the CC, DN, CSS, and SOC models using Akaike's information criterion (AIC) and Bayesian information criterion (BIC). Here we plot model accuracy as a function of the number of voxels considered (voxels are selected based on GLM cross-validation accuracy; see <xref ref-type="sec" rid="s4">Methods</xref>). Lines indicate the median accuracy across voxels in a given visual field map, and shaded regions indicate standard error (68% confidence intervals). Trends in model performance are consistent across metrics and are robust with respect to the number of voxels used in the model comparison.</p>
<p>(TIF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank R. Kiani and N. Kriegeskorte for providing the object stimuli used in this study; A. Takahashi for spiral pulse sequence development; and M. Ben-Shachar, S. David, J. DiCarlo, K. Grill-Spector, T. Hastie, and A. Norcia for helpful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003079-Albrecht1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Albrecht</surname><given-names>DG</given-names></name>, <name name-style="western"><surname>Hamilton</surname><given-names>DB</given-names></name> (<year>1982</year>) <article-title>Striate cortex of monkey and cat: contrast response function</article-title>. <source>J Neurophysiol</source> <volume>48</volume>: <fpage>217</fpage>–<lpage>237</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Carandini1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sengpiel</surname><given-names>F</given-names></name> (<year>2004</year>) <article-title>Contrast invariance of functional maps in cat primary visual cortex</article-title>. <source>J Vis</source> <volume>4</volume>: <fpage>130</fpage>–<lpage>143</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Davidenko1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Davidenko</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Remus</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Grill-Spector</surname><given-names>K</given-names></name> (<year>2012</year>) <article-title>Face-likeness and image variability drive responses in human face-selective ventral regions</article-title>. <source>Hum Brain Mapp</source> <volume>33</volume>: <fpage>2334</fpage>–<lpage>2349</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Pasupathy1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pasupathy</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Connor</surname><given-names>CE</given-names></name> (<year>2001</year>) <article-title>Shape representation in area V4: position-specific tuning for boundary conformation</article-title>. <source>J Neurophysiol</source> <volume>86</volume>: <fpage>2505</fpage>–<lpage>2519</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Kastner1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kastner</surname><given-names>S</given-names></name>, <name name-style="western"><surname>De Weerd</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Ungerleider</surname><given-names>LG</given-names></name> (<year>2000</year>) <article-title>Texture segregation in the human visual cortex: A functional MRI study</article-title>. <source>J Neurophysiol</source> <volume>83</volume>: <fpage>2453</fpage>–<lpage>2457</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Thielscher1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thielscher</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kolle</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Neumann</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Spitzer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gron</surname><given-names>G</given-names></name> (<year>2008</year>) <article-title>Texture segmentation in human perception: a combined modeling and fMRI study</article-title>. <source>Neuroscience</source> <volume>151</volume>: <fpage>730</fpage>–<lpage>736</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Kay1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Naselaris</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Prenger</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2008</year>) <article-title>Identifying natural images from human brain activity</article-title>. <source>Nature</source> <volume>452</volume>: <fpage>352</fpage>–<lpage>355</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Busse1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Busse</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Wade</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title>. <source>Neuron</source> <volume>64</volume>: <fpage>931</fpage>–<lpage>942</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Carandini2"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name> (<year>1997</year>) <article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title>. <source>J Neurosci</source> <volume>17</volume>: <fpage>8621</fpage>–<lpage>8644</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Heeger1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>1992</year>) <article-title>Normalization of cell responses in cat striate cortex</article-title>. <source>Vis Neurosci</source> <volume>9</volume>: <fpage>181</fpage>–<lpage>197</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Kay2"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kay</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Winawer</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Mezer</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wandell</surname><given-names>B</given-names></name> (<year>2013</year>) <article-title>Compressive spatial summation in human visual cortex</article-title>. <source>J Neurophysiol</source> <comment>doi <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152jn.00105.2013/jn.00105.2013" xlink:type="simple">10.1152jn.00105.2013/jn.00105.2013</ext-link></comment>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Graham1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graham</surname><given-names>NV</given-names></name> (<year>2011</year>) <article-title>Beyond multiple pattern analyzers modeled as linear filters (as classical V1 simple cells): useful additions of the last 25 years</article-title>. <source>Vision Res</source> <volume>51</volume>: <fpage>1397</fpage>–<lpage>1430</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Landy1"><label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Landy MS, Graham N (2004) Visual perception of texture. In: Chalupa LM, Werner JS, editors. The Visual Neurosciences. Cambridge: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Gavish1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gavish</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Donoho</surname><given-names>D</given-names></name> (<year>2012</year>) <article-title>Three Dream Applications of Verifiable Computational Results</article-title>. <source>Computing in Science &amp; Engineering</source> <volume>14</volume>: <fpage>26</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Dumoulin1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dumoulin</surname><given-names>SO</given-names></name>, <name name-style="western"><surname>Wandell</surname><given-names>BA</given-names></name> (<year>2008</year>) <article-title>Population receptive field estimates in human visual cortex</article-title>. <source>Neuroimage</source> <volume>39</volume>: <fpage>647</fpage>–<lpage>660</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Brouwer1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brouwer</surname><given-names>GJ</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>2011</year>) <article-title>Cross-orientation suppression in human visual cortex</article-title>. <source>J Neurophysiol</source> <volume>106</volume>: <fpage>2108</fpage>–<lpage>2119</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-McDonald1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McDonald</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Mannion</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Clifford</surname><given-names>CW</given-names></name> (<year>2012</year>) <article-title>Gain control in the response of human visual cortex to plaids</article-title>. <source>J Neurophysiol</source> <volume>107</volume>: <fpage>2570</fpage>–<lpage>2580</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Rust1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name> (<year>2005</year>) <article-title>In praise of artifice</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1647</fpage>–<lpage>1650</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Felsen1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Felsen</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name> (<year>2005</year>) <article-title>A natural approach to studying vision</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1643</fpage>–<lpage>1646</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Cavanaugh1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cavanaugh</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Bair</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name> (<year>2002</year>) <article-title>Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons</article-title>. <source>J Neurophysiol</source> <volume>88</volume>: <fpage>2530</fpage>–<lpage>2546</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Sceniak1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sceniak</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Hawken</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Shapley</surname><given-names>R</given-names></name> (<year>2001</year>) <article-title>Visual spatial characterization of macaque V1 neurons</article-title>. <source>J Neurophysiol</source> <volume>85</volume>: <fpage>1873</fpage>–<lpage>1887</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Logothetis1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name> (<year>2008</year>) <article-title>What we can do and what we cannot do with fMRI</article-title>. <source>Nature</source> <volume>453</volume>: <fpage>869</fpage>–<lpage>878</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Logothetis2"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name>, <name name-style="western"><surname>Wandell</surname><given-names>BA</given-names></name> (<year>2004</year>) <article-title>Interpreting the BOLD signal</article-title>. <source>Annu Rev Physiol</source> <volume>66</volume>: <fpage>735</fpage>–<lpage>769</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Carandini3"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Demb</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Mante</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Do we know what the early visual system does?</article-title> <source>J Neurosci</source> <volume>25</volume>: <fpage>10577</fpage>–<lpage>10597</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Wu1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wu</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>David</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2006</year>) <article-title>Complete functional characterization of sensory neurons by system identification</article-title>. <source>Annu Rev Neurosci</source> <volume>29</volume>: <fpage>477</fpage>–<lpage>505</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Carandini4"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>From circuits to behavior: a bridge too far?</article-title> <source>Nat Neurosci</source> <volume>15</volume>: <fpage>507</fpage>–<lpage>509</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Priebe1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Priebe</surname><given-names>NJ</given-names></name>, <name name-style="western"><surname>Ferster</surname><given-names>D</given-names></name> (<year>2008</year>) <article-title>Inhibition, spike threshold, and stimulus selectivity in primary visual cortex</article-title>. <source>Neuron</source> <volume>57</volume>: <fpage>482</fpage>–<lpage>497</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Heeger2"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Ress</surname><given-names>D</given-names></name> (<year>2002</year>) <article-title>What does fMRI tell us about neuronal activity?</article-title> <source>Nat Rev Neurosci</source> <volume>3</volume>: <fpage>142</fpage>–<lpage>151</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-DiCarlo1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DiCarlo</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Zoccolan</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name> (<year>2012</year>) <article-title>How does the brain solve visual object recognition?</article-title> <source>Neuron</source> <volume>73</volume>: <fpage>415</fpage>–<lpage>434</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Fukushima1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fukushima</surname><given-names>K</given-names></name> (<year>1980</year>) <article-title>Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position</article-title>. <source>Biol Cybern</source> <volume>36</volume>: <fpage>193</fpage>–<lpage>202</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Heeger3"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name> (<year>1996</year>) <article-title>Computational models of cortical visual processing</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>93</volume>: <fpage>623</fpage>–<lpage>627</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Rolls1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name> (<year>2012</year>) <article-title>Invariant Visual Object and Face Recognition: Neural and Computational Bases, and a Model, VisNet</article-title>. <source>Front Comput Neurosci</source> <volume>6</volume>: <fpage>35</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Serre1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Serre</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kreiman</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Kouh</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Cadieu</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Knoblich</surname><given-names>U</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>A quantitative theory of immediate visual recognition</article-title>. <source>Prog Brain Res</source> <volume>165</volume>: <fpage>33</fpage>–<lpage>56</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Wang1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>HX</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name> (<year>2012</year>) <article-title>Responses to second-order texture modulations undergo surround suppression</article-title>. <source>Vision Res</source> <volume>62</volume>: <fpage>192</fpage>–<lpage>200</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Hallum1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hallum</surname><given-names>LE</given-names></name>, <name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>2011</year>) <article-title>Human primary visual cortex (V1) is selective for second-order spatial frequency</article-title>. <source>J Neurophysiol</source> <volume>105</volume>: <fpage>2121</fpage>–<lpage>2131</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Angelucci1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Angelucci</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Bressloff</surname><given-names>PC</given-names></name> (<year>2006</year>) <article-title>Contribution of feedforward, lateral and feedback connections to the classical receptive field center and extra-classical receptive field surround of primate V1 neurons</article-title>. <source>Prog Brain Res</source> <volume>154</volume>: <fpage>93</fpage>–<lpage>120</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Bair1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bair</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Cavanaugh</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name> (<year>2003</year>) <article-title>Time course and time-distance relationships for surround suppression in macaque V1 neurons</article-title>. <source>J Neurosci</source> <volume>23</volume>: <fpage>7690</fpage>–<lpage>7701</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Joris1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Joris</surname><given-names>PX</given-names></name>, <name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name>, <name name-style="western"><surname>Rees</surname><given-names>A</given-names></name> (<year>2004</year>) <article-title>Neural processing of amplitude-modulated sounds</article-title>. <source>Physiol Rev</source> <volume>84</volume>: <fpage>541</fpage>–<lpage>577</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-ElShamayleh1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>El-Shamayleh</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name> (<year>2011</year>) <article-title>Neuronal responses to texture-defined form in macaque visual area V2</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>8543</fpage>–<lpage>8555</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Song1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Song</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Baker</surname><given-names>CL</given-names><suffix>Jr</suffix></name> (<year>2007</year>) <article-title>Neuronal response to texture- and contrast-defined boundaries in early visual cortex</article-title>. <source>Vis Neurosci</source> <volume>24</volume>: <fpage>65</fpage>–<lpage>77</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Tanaka1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tanaka</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name> (<year>2009</year>) <article-title>Surround suppression of V1 neurons mediates orientation-based representation of high-order visual features</article-title>. <source>J Neurophysiol</source> <volume>101</volume>: <fpage>1444</fpage>–<lpage>1462</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Larsson1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Larsson</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>2006</year>) <article-title>Orientation-selective adaptation to first- and second-order patterns in human visual cortex</article-title>. <source>J Neurophysiol</source> <volume>95</volume>: <fpage>862</fpage>–<lpage>881</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Dumoulin2"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dumoulin</surname><given-names>SO</given-names></name>, <name name-style="western"><surname>Dakin</surname><given-names>SC</given-names></name>, <name name-style="western"><surname>Hess</surname><given-names>RF</given-names></name> (<year>2008</year>) <article-title>Sparsely distributed contours dominate extra-striate responses to complex scenes</article-title>. <source>Neuroimage</source> <volume>42</volume>: <fpage>890</fpage>–<lpage>901</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Willmore1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willmore</surname><given-names>BD</given-names></name>, <name name-style="western"><surname>Prenger</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2010</year>) <article-title>Neural representation of natural images in visual area V2</article-title>. <source>J Neurosci</source> <volume>30</volume>: <fpage>2102</fpage>–<lpage>2114</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Walker1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Walker</surname><given-names>GA</given-names></name>, <name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name> (<year>1999</year>) <article-title>Asymmetric suppression outside the classical receptive field of the visual cortex</article-title>. <source>J Neurosci</source> <volume>19</volume>: <fpage>10536</fpage>–<lpage>10553</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Solomon1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Solomon</surname><given-names>SG</given-names></name>, <name name-style="western"><surname>Peirce</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>Lennie</surname><given-names>P</given-names></name> (<year>2004</year>) <article-title>The impact of suppressive surrounds on chromatic properties of cortical neurons</article-title>. <source>J Neurosci</source> <volume>24</volume>: <fpage>148</fpage>–<lpage>160</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Petrov1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Petrov</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>McKee</surname><given-names>SP</given-names></name> (<year>2006</year>) <article-title>The effect of spatial configuration on surround suppression of contrast sensitivity</article-title>. <source>J Vis</source> <volume>6</volume>: <fpage>224</fpage>–<lpage>238</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Sceniak2"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sceniak</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Ringach</surname><given-names>DL</given-names></name>, <name name-style="western"><surname>Hawken</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Shapley</surname><given-names>R</given-names></name> (<year>1999</year>) <article-title>Contrast's effect on spatial summation by macaque V1 neurons</article-title>. <source>Nat Neurosci</source> <volume>2</volume>: <fpage>733</fpage>–<lpage>739</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Simoncelli1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>, <name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name> (<year>2001</year>) <article-title>Natural image statistics and neural representation</article-title>. <source>Annu Rev Neurosci</source> <volume>24</volume>: <fpage>1193</fpage>–<lpage>1216</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Baddeley1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baddeley</surname><given-names>R</given-names></name> (<year>1996</year>) <article-title>Searching for filters with ‘interesting’ output distributions: an uninteresting direction to explore?</article-title> <source>Network</source> <volume>7</volume>: <fpage>409</fpage>–<lpage>421</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Brady1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brady</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>2000</year>) <article-title>Local contrast in natural images: normalisation and coding efficiency</article-title>. <source>Perception</source> <volume>29</volume>: <fpage>1041</fpage>–<lpage>1055</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Scholte1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scholte</surname><given-names>HS</given-names></name>, <name name-style="western"><surname>Ghebreab</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Waldorp</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Smeulders</surname><given-names>AW</given-names></name>, <name name-style="western"><surname>Lamme</surname><given-names>VA</given-names></name> (<year>2009</year>) <article-title>Brain responses strongly correlate with Weibull image statistics when processing natural images</article-title>. <source>J Vis</source> <volume>9</volume>: <fpage>29.1</fpage>–<lpage>15</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Tadmor1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tadmor</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name> (<year>2000</year>) <article-title>Calculating the contrasts that retinal ganglion cells and LGN neurones encounter in natural scenes</article-title>. <source>Vision Res</source> <volume>40</volume>: <fpage>3145</fpage>–<lpage>3157</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Johnson1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnson</surname><given-names>AP</given-names></name>, <name name-style="western"><surname>Baker</surname><given-names>CL</given-names><suffix>Jr</suffix></name> (<year>2004</year>) <article-title>First- and second-order information in natural images: a filter-based approach to image statistics</article-title>. <source>J Opt Soc Am A</source> <volume>21</volume>: <fpage>913</fpage>–<lpage>925</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Perna1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perna</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Tosetti</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Montanaro</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Morrone</surname><given-names>MC</given-names></name> (<year>2008</year>) <article-title>BOLD response to spatial phase congruency in human brain</article-title>. <source>J Vis</source> <volume>8</volume>: <fpage>15.1</fpage>–<lpage>15</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Henriksson1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Henriksson</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Hyvarinen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Vanni</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Representation of cross-frequency spatial phase relationships in human visual cortex</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>14342</fpage>–<lpage>14351</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Brincat1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brincat</surname><given-names>SL</given-names></name>, <name name-style="western"><surname>Connor</surname><given-names>CE</given-names></name> (<year>2004</year>) <article-title>Underlying principles of visual shape selectivity in posterior inferotemporal cortex</article-title>. <source>Nat Neurosci</source> <volume>7</volume>: <fpage>880</fpage>–<lpage>886</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Hegde1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hegde</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Van Essen</surname><given-names>DC</given-names></name> (<year>2007</year>) <article-title>A comparative study of shape representation in macaque visual areas V2 and V4</article-title>. <source>Cereb Cortex</source> <volume>17</volume>: <fpage>1100</fpage>–<lpage>1116</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Ito1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ito</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Goda</surname><given-names>N</given-names></name> (<year>2011</year>) <article-title>Mechanisms underlying the representation of angles embedded within contour stimuli in area V2 of macaque monkeys</article-title>. <source>Eur J Neurosci</source> <volume>33</volume>: <fpage>130</fpage>–<lpage>142</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Winawer1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Winawer</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Horiguchi</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Sayres</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Amano</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Wandell</surname><given-names>BA</given-names></name> (<year>2010</year>) <article-title>Mapping hV4 and ventral occipital cortex: The venous eclipse</article-title>. <source>J Vis</source> <volume>10</volume>: <fpage>1</fpage>–<lpage>22</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Brainard1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brainard</surname><given-names>DH</given-names></name> (<year>1997</year>) <article-title>The Psychophysics Toolbox</article-title>. <source>Spat Vis</source> <volume>10</volume>: <fpage>433</fpage>–<lpage>436</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Pelli1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pelli</surname><given-names>DG</given-names></name> (<year>1997</year>) <article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title>. <source>Spat Vis</source> <volume>10</volume>: <fpage>437</fpage>–<lpage>442</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Kriegeskorte1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Mur</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ruff</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Kiani</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bodurka</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Matching categorical object representations in inferior temporal cortex of man and monkey</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>1126</fpage>–<lpage>1141</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Hastie1"><label>64</label>
<mixed-citation publication-type="other" xlink:type="simple">Hastie T, Tibshirani R, Friedman JH (2001) The elements of statistical learning: data mining, inference, and prediction. New York: Springer. 533 p.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Jezzard1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jezzard</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Balaban</surname><given-names>RS</given-names></name> (<year>1995</year>) <article-title>Correction for geometric distortion in echo planar images from B0 field variations</article-title>. <source>Magn Reson Med</source> <volume>34</volume>: <fpage>65</fpage>–<lpage>73</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Freire1"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freire</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Mangin</surname><given-names>JF</given-names></name> (<year>2001</year>) <article-title>Motion correction algorithms may create spurious brain activations in the absence of subject motion</article-title>. <source>Neuroimage</source> <volume>14</volume>: <fpage>709</fpage>–<lpage>722</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Monti1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Monti</surname><given-names>MM</given-names></name> (<year>2011</year>) <article-title>Statistical Analysis of fMRI Time-Series: A Critical Review of the GLM Approach</article-title>. <source>Front Hum Neurosci</source> <volume>5</volume>: <fpage>28</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Adelson1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>, <name name-style="western"><surname>Bergen</surname><given-names>JR</given-names></name> (<year>1985</year>) <article-title>Spatiotemporal energy models for the perception of motion</article-title>. <source>J Opt Soc Am A</source> <volume>2</volume>: <fpage>284</fpage>–<lpage>299</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Albrecht2"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Albrecht</surname><given-names>DG</given-names></name>, <name name-style="western"><surname>Geisler</surname><given-names>WS</given-names></name> (<year>1991</year>) <article-title>Motion selectivity and the contrast-response function of simple cells in the visual cortex</article-title>. <source>Vis Neurosci</source> <volume>7</volume>: <fpage>531</fpage>–<lpage>546</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-David1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>David</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2005</year>) <article-title>Predicting neuronal responses during natural vision</article-title>. <source>Network</source> <volume>16</volume>: <fpage>239</fpage>–<lpage>260</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Sahani1"><label>71</label>
<mixed-citation publication-type="other" xlink:type="simple">Sahani M, Linden JF (2003) How linear are auditory cortical responses? In: Becker S, Thrun S, Obermayer K, editors. Advances in Neural Information Processing Systems 15. Cambridge: MIT Press. pp. 109–116.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Burnham1"><label>72</label>
<mixed-citation publication-type="other" xlink:type="simple">Burnham KP, Anderson DR (2002) Model Selection and Multimodel Inference. New York: Springer. 488 p.</mixed-citation>
</ref>
<ref id="pcbi.1003079-Olmos1"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olmos</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kingdom</surname><given-names>FA</given-names></name> (<year>2004</year>) <article-title>A biologically inspired algorithm for the recovery of shading and reflectance images</article-title>. <source>Perception</source> <volume>33</volume>: <fpage>1463</fpage>–<lpage>1473</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-01365</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003970</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>High-Fidelity Coding with Correlated Neurons</article-title>
<alt-title alt-title-type="running-head">High-Fidelity Coding with Correlated Neurons</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>da Silveira</surname><given-names>Rava Azeredo</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Berry</surname><given-names>Michael J.</given-names><suffix>II</suffix></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Department of Physics, Ecole Normale Supérieure, Paris, France</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Laboratoire de Physique Statistique, Centre National de la Recherche Scientifique, Université Pierre et Marie Curie, Université Denis Diderot, Paris, France</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Princeton Neuroscience Institute, Princeton University, Princeton, New Jersey, United States of America</addr-line></aff>
<aff id="aff4"><label>4</label><addr-line>Department of Molecular Biology, Princeton University, Princeton, New Jersey, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Graham</surname><given-names>Lyle J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Université Paris Descartes, Centre National de la Recherche Scientifique, France</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">rava@ens.fr</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: RAdS MJB. Performed the experiments: RAdS MJB. Analyzed the data: RAdS MJB. Contributed reagents/materials/analysis tools: RAdS MJB. Wrote the paper: RAdS MJB.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>11</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>20</day><month>11</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>11</issue>
<elocation-id>e1003970</elocation-id>
<history>
<date date-type="received"><day>15</day><month>9</month><year>2011</year></date>
<date date-type="accepted"><day>6</day><month>10</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Azeredo da Silveira, Berry II</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Positive correlations in the activity of neurons are widely observed in the brain. Previous studies have shown these correlations to be detrimental to the fidelity of population codes, or at best marginally favorable compared to independent codes. Here, we show that positive correlations can enhance coding performance by astronomical factors. Specifically, the probability of discrimination error can be suppressed by many orders of magnitude. Likewise, the number of stimuli encoded—the capacity—can be enhanced more than tenfold. These effects do not necessitate unrealistic correlation values, and can occur for populations with a few tens of neurons. We further show that both effects benefit from heterogeneity commonly seen in population activity. Error suppression and capacity enhancement rest upon a pattern of correlation. Tuning of one or several effective parameters can yield a limit of perfect coding: the corresponding pattern of positive correlation leads to a ‘lock-in’ of response probabilities that eliminates variability in the subspace relevant for stimulus discrimination. We discuss the nature of this pattern and we suggest experimental tests to identify it.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>Traditionally, sensory neuroscience has focused on correlating inputs from the physical world with the response of a single neuron. Two stimuli can be distinguished solely from the response of one neuron if one stimulus elicits a response and the other does not. But as soon as one departs from extremely simple stimuli, single-cell coding becomes less effective, because cells often respond weakly and unreliably. High fidelity coding then relies upon populations of cells, and correlation among those cells can greatly affect the neural code. While previous theoretical studies have demonstrated a potential coding advantage of correlation, they allowed only a marginal improvement in coding power. Here, we present a scenario in which a pattern of correlation among neurons in a population yields an improvement in coding performance by several orders of magnitude. By “improvement” we mean that a neural population is much better at both distinguishing stimuli and at encoding a large number of them. The scenario we propose does not invoke unrealistic values of correlation. What is more, it is even effective for small neural populations and in subtle cases in which single-cell coding fails utterly. These results demonstrate a previously unappreciated potential for correlated population coding.</p>
</abstract>
<funding-group><funding-statement>This work was supported by the CNRS through UMR 8550 (RAdS), the Globa Scholars Program at Princeton University (RAdS), and the NIH through grant EY014196 (MJB). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="25"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Many of the classic studies relating behavior to the activity of neurons, such as studies of single photon counting, have focused on behaviors that are near the threshold of perception <xref ref-type="bibr" rid="pcbi.1003970-Barlow1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-HechtSShlaer1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Klein1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Newsome1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Watson1">[5]</xref>, where performance is uncertain and can suffer a substantial error rate. One of the surprises of these studies is that in this limit, the variability of single neurons often matches the variability in performance, such that single neurons can account for the behavior <xref ref-type="bibr" rid="pcbi.1003970-Newsome1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Barlow2">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Parker1">[7]</xref>. However, most of our everyday visual experience involves judgments made with great accuracy and certainty. As is illustrated by phrases like “seeing is believing” and Shakespeare's “ocular proof,” we often dismiss any doubt about an aspect of the world once it is perceived visually. In this ‘high-fidelity’ limit, perception must cope with single neuron variability by relying upon populations of neurons. Our visual system not only yields perception with certainty, but it also allows us to make complex judgments very rapidly—a fact that places additional constraints on the population neural code <xref ref-type="bibr" rid="pcbi.1003970-Kirchner1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Liu1">[9]</xref>.</p>
<p>In a neural population, correlations in the activity of neurons provide additional variables with which information can be represented. While details may vary from one neural circuit to another, a fairly common pattern of correlation is observed across many brain regions, including the retina, LGN, cerebral cortex, and cerebellum <xref ref-type="bibr" rid="pcbi.1003970-Hatsopoulos1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Mastronarde1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Ozden1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Perkel1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Sasaki1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shlens1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Usrey1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Vaadia1">[17]</xref>. Correlations vary from pair to pair, with a positive mean and a standard deviation comparable to the mean <xref ref-type="bibr" rid="pcbi.1003970-Bair1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Fiser1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Kohn1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Smith1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Lee1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Zohary1">[23]</xref> (but see Ref. <xref ref-type="bibr" rid="pcbi.1003970-Ecker1">[24]</xref>). Whereas noise correlations adopt moderate values in the retina and may not contribute much to the coding accuracy, their larger values—possibly reflecting the underlying recurrent neural dynamics—in cortex suggest that, there, they may have greater incidence upon coding properties.</p>
<p>How do these affect coding? This question has been investigated by a number of authors <xref ref-type="bibr" rid="pcbi.1003970-Johnson1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Vogels1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Oram1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Abbott1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Panzeri1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Sompolinsky1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Romo1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Golledge1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Pola1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck2">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck3">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Josic1">[40]</xref>, who find that in many cases positive correlations are detrimental to coding performance; in some cases, however, positive correlations can enhance the coding performance of a neural population. Using specific choices of neural response and correlation properties, this effect was probed quantitatively in models of pairs of neurons, small populations, or large populations. In all these cases, the presence of positive correlation boosted coding performance to a relatively modest degree: the mutual (Shannon) information or the Fisher information (depending on the study) in the correlated population exceeded that in the equivalent independent population by a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e001" xlink:type="simple"/></inline-formula>. For typical choices of correlation values, the improvement was calculated to be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e002" xlink:type="simple"/></inline-formula>. These results can be translated into the units of capacity used in this study and correspond to an improvement of a fraction of a percent to a few percents (see <xref ref-type="sec" rid="s3">Discussion</xref> below), which in turn correspond to a negligible increase of the information encoded per neuron. Recently <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref> (see also Ref. <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>), the Fisher information and related quantities were revisited for more general cases of either the tuning properties of neurons <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref> or the structure of pairwise correlation <xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref>. In the resulting picture, earlier statements about the detrimental effect of positive correlation are nuanced. These analyses demonstrate, in particular, that correlation can be helpful in the presence of neuron-to-neuron variability of the tuning curve <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref> or when correlation adopts more complicated structures than the ones considered in earlier work <xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref>.</p>
<p>Here, we focus upon the case of stimulus-independent correlation. We pose the problem in much the same way as it was posed in a number of earlier studies <xref ref-type="bibr" rid="pcbi.1003970-Sompolinsky1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Romo1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Golledge1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck2">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck3">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Josic1">[40]</xref> extending the work of Abbott and Dayan <xref ref-type="bibr" rid="pcbi.1003970-Abbott1">[28]</xref>, and which itself can be traced, possibly, to similar ideas that appeared earlier in the literature (see, e.g., <xref ref-type="bibr" rid="pcbi.1003970-Johnson1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Vogels1">[26]</xref>). Namely, we ask how the structure of the correlation – specifically, of the covariance matrix – affects coding performance. We exploit the same idea that was used in the papers just referenced: correlation can enhance coding performance by a simple mechanism—relegating the variability of neural response into non-informative modes of the population activity. For a more precise statement, note that, because of variability each stimulus is represented by a distribution of response patterns in the population, and the overlap between neighboring distributions results in coding ambiguity. While, generically, positive correlations broaden response distributions, depending upon the interplay between the mean response properties of neurons and their correlations, probability distributions can be, instead, deformed by correlations in such a way as to suppress overlap.</p>
<p>While much of the earlier literature on this topic is set in the context of continuous stimuli, here we focus upon the case of discrete stimuli (‘categorical perception’). (This does not represent a fundamental conceptual shift, but the case of discrete stimuli begs for different mathematical objects, such as the discrimination error rate and the information capacity, rather than information theoretic quantities which depend upon a continuous stimulus such as the Fisher information.) First, we shall investigate the coding performance in a discrimination task that involves two stimuli. In this case, by construction, a subset of the neural population will respond preferentially to one stimulus, while the remaining neurons in the population will be more responsive to the other stimulus; hence, this ‘staggered preference’ is assumed without any loss of generality. (This ‘staggered preference’, also, plays a similar role to that of putative negative signal correlations in earlier work – see our comments on this issue, below.) In this context, we shall demonstrate that some patterns of positive correlations can serve to suppress discrimination errors by many orders of magnitude. Second, we shall consider the more general case in which the discrimination task involves a large number of stimuli—the question then becomes one of capacity: how many stimuli can be encoded by a population of neurons at very low error rates? We shall show that the capacity can be enhanced significantly by the presence of correlation; specifically, the information per neuron can be boosted by factors of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e003" xlink:type="simple"/></inline-formula> (or even greater), as compared with an equivalent independent population. Interestingly, an astronomical enhancement in coding performance does not require a large population; it can occurs in small populations with tens or hundreds of neurons and, also, it can occur in cases in which independent coding breaks down entirely. Along the way, we shall discuss some auxiliary results, such as the favorable role of neuron-to-neuron variability in the response properties and a possible experimental approach to our ideas, as well as quantitative relations between our work and earlier results.</p>
<p>If one or several parameters are fine-tuned, the system reaches a ‘lock-in’ limit in which coding can become perfect: the distribution of population responses becomes ‘compressed’ into a lower-dimensional object. While in this limit some population patterns are forbidden, population responses are still variable and pairwise correlation coefficients can have moderate values similar to the ones measured experimentally. If the population is close to this singular, fine-tuned limit, then even though coding is not perfect one can obtain an astronomical enhancement of the coding performance as compared to that of a population of independent neurons. Furthermore, this enhancement is robust to variations in the additional (‘untuned’) parameters in the system. The resulting picture results from a collective phenomenon. Earlier work exploited the basic mechanism in models in which the role of correlation involved, in effect, pairs or very small numbers of neurons. In our work, we invoke a pooling mechanism: even in the presence of only weak correlations, a moderately small sub-population can behave like a nearly deterministic, ‘macro-neuron’. Thus, at the cost of losing some amount of coding performance by having homogeneous pools within the population, we obtain a tremendous enhancement because the variability in the informative directions can be severely suppressed.</p>
</sec><sec id="s2">
<title>Results</title>
<p>Our results amount to the answers to two complementary questions. Given a pair sensory stimuli, how well can a population of correlated neurons discriminate between them? Or, more precisely, what is the discrimination error rate? Conversely, given a discrimination error rate, what is the capacity of a correlated population? That is, how many stimuli can it encode with tolerable error? In natural situations, discrimination errors are exceedingly rare and, hence, neural populations are expected to achieve very low error rates. (See <xref ref-type="sec" rid="s3">Discussion</xref> for a detailed argument and quantitative estimates of low error rates.) The present work is set in this low-error regime.</p>
<p>Since we are interested in rapid coding, we focus on short time windows. The biophysical time scale of neurons—a few tens of milliseconds—affords us with a natural choice. This time scale also happens to correspond to the spike timing jitter of individual neurons in the early visual pathway in response to a natural movie clip <xref ref-type="bibr" rid="pcbi.1003970-Butts1">[43]</xref>. We consider short time bins in which each neuron can only fire one spike or none at all. (This last assumption is not essential; in the more general case in which many spikes can fit in a time bin, our qualitative conclusions remain unchanged or may even become stronger. Furthermore, in some examples we shall assume a relatively high firing rate—say, 50%. In those cases we can still assume a binary output by identifying all cases in which there is at least one spike per time bin, i.e., by saying that a cell is either silent or firing in a time bin. A perceptron-like decoder can implement this identification by an appropriate saturating non-linearity which collapses unto the same output all inputs with one or more spikes.) The situation we have in mind is one in which a stimulus is presented once every time bin, and the corresponding population response is recorded.</p>
<sec id="s2a">
<title>Positive correlations can suppress discrimination error rates by orders of magnitude</title>
<p>We consider two stimuli, which we henceforth refer to as Target and Distracter, and we consider a situation in which these have to be discriminated by the response of a neural population in a short time window during which each neuron fires <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e004" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e005" xlink:type="simple"/></inline-formula> spike. Each neuron is bound to respond more vigorously on average either to Target or to Distracter. Thus, it is natural to divide the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e006" xlink:type="simple"/></inline-formula>-neuron population into two pools of neurons (“Pool 1” and “Pool 2”), each more responsive to one of the two stimuli, as it has been done customarily in studies on stimulus discrimination (see, e.g., <xref ref-type="bibr" rid="pcbi.1003970-Newsome1">[4]</xref>). For the sake of simplicity, in this 2-Pool model we allocate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e007" xlink:type="simple"/></inline-formula> neurons to each pool (<xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1A</xref>). We denote by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e008" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e009" xlink:type="simple"/></inline-formula> the number of active neurons in Pools 1 and 2 respectively. We start with a symmetric case: neurons in Pools 1 and 2 respond with firing rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e010" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e011" xlink:type="simple"/></inline-formula> respectively to the Target and, conversely, with firing rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e012" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e013" xlink:type="simple"/></inline-formula> respectively to the Distracter. Moreover, correlations in the activity of pairs of neurons may take different values within Pool 1 (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e014" xlink:type="simple"/></inline-formula>), within Pool 2 (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e015" xlink:type="simple"/></inline-formula>), and across pools (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e016" xlink:type="simple"/></inline-formula>). We denote by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e017" xlink:type="simple"/></inline-formula> the elements of the covariance matrix and by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e018" xlink:type="simple"/></inline-formula> the normalized pairwise correlations; normalized values are often quoted in the literature and present the advantage of being bounded by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e019" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e020" xlink:type="simple"/></inline-formula>. (See <xref ref-type="sec" rid="s4">Materials and Methods</xref> for mathematical definitions.) While we shall present most of our quantitative results for symmetric choices of the parameters, our qualitative conclusions hold in general.</p>
<fig id="pcbi-1003970-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g001</object-id><label>Figure 1</label><caption>
<title>Simple model of a population code.</title>
<p><bold>A.</bold> Schematics of our model with two pools with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e021" xlink:type="simple"/></inline-formula> neurons each. Correlation within Pool 1 is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e022" xlink:type="simple"/></inline-formula> for all pairs; correlation within Pool 2 is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e023" xlink:type="simple"/></inline-formula> for all pairs; correlation between the two pools is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e024" xlink:type="simple"/></inline-formula> for all pairs. Firing probability in a single window of time for Pool 1 is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e025" xlink:type="simple"/></inline-formula> for Target and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e026" xlink:type="simple"/></inline-formula> for Distracter; firing probabilities are the opposite for Pool 2. <bold>B.</bold> Probability contours (lightest shade represents highest probability) for Target stimulus (red) and Distracter (blue) stimuli in the case of independent neurons (left). Correlation can shrink the distribution along the line separating them and extend the distribution perpendicular to their separation (right). Variances along the two principle axes are denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e027" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e028" xlink:type="simple"/></inline-formula>; the angle between the long axis and the horizontal line is denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e029" xlink:type="simple"/></inline-formula>. Variances along the axes of Pool 1 and 2 are denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e030" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e031" xlink:type="simple"/></inline-formula>, respectively; the variance across Pools 1 and 2 is denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e032" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g001" position="float" xlink:type="simple"/></fig>
<p>In the discrimination case just outlined, between two individual stimuli (e.g., a given black cat and a given tabby cat), any correlations in question are what is often referred to in the literature as noise correlations; these reflect the dynamics of the neural network, not any structure inherent to stimuli. In order to relate this setup to that of earlier studies involving continuous stimuli, we mention that, although we cannot define signal correlation, here, the ‘staggered preference’ in the population (i.e., the fact that different pools of neurons respond preferentially to different stimuli) plays a similar role to that of negative signal correlation in earlier work.</p>
<p>One can also define a discrimination task between an individual stimulus and a stimulus category (e.g., a given black and all other cats) or between two stimulus categories (e.g., all black cats and all tabby cats). In the case of these problems, the correlations at play are combinations of noise correlations and signal correlations; the latter reflect both the response properties of neurons and the structure of the stimulus ensemble. At the level of the mathematical treatments in our study, the distinction between noise and signal correlations is irrelevant: our derivations make use of the matrix of activity covariances without reference to their origin. The same goes for the actual problem faced by the brain: a readout neuron does not ‘know’ whether the correlations it sees are noise or signal correlations. However, for the sake of conceptual clarity, we shall phrase our discrimination problem as one between two individual stimuli; thus, the reader can think of the elements of the covariance matrix and the normalized correlation coefficients as representing noise correlations.</p>
<p>If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e033" xlink:type="simple"/></inline-formula> is larger than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e034" xlink:type="simple"/></inline-formula>, Pool 1 consists of the neurons ‘tuned’ to Target while Pool 2 consists of the neurons ‘tuned’ to Distracter. A useful visual representation of the probability distributions of responses to Target and Distracter makes use of contour lines (<xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1B</xref>). In the case of independent neurons (with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e035" xlink:type="simple"/></inline-formula>), the principal axes of the two distributions are horizontal and vertical, and their contour lines are nearly circular unless <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e036" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e037" xlink:type="simple"/></inline-formula> take extreme values. As a result, the overlap between the two distributions tends to be significant (<xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1B</xref>), with the consequence of a non-negligible coding error rate. In such a situation, positive correlations can improve coding by causing the distributions to elongate along the diagonal and, conversely, to shrink along the line that connects the two centers (<xref ref-type="fig" rid="pcbi-1003970-g001">Fig 1B</xref>).</p>
<p>To illustrate this generic mechanism, we have computed the error rate numerically for specific choices of parameters of the firing rates and correlations in the population. (See <xref ref-type="sec" rid="s4">Materials and Methods</xref> for a reminder of the maximum likelihood error and for details on the numerics.) By way of comparison, in an independent population with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e038" xlink:type="simple"/></inline-formula> neurons the error rate drops exponentially as a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e039" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003970-g002">Fig. 2A</xref>). While the error rates for independent and correlated populations start out very similar for small population size, they diverge dramatically as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e040" xlink:type="simple"/></inline-formula> increases to 90 neurons (<xref ref-type="fig" rid="pcbi-1003970-g002">Fig. 2A</xref>). We can define a factor of coding improvement due to correlations as the ratio of the two error rates; this factor exceeds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e041" xlink:type="simple"/></inline-formula> for large populations (<xref ref-type="fig" rid="pcbi-1003970-g002">Fig. 2B</xref>). We can also explore the way in which the error rate changes as we vary the strength of the pairwise correlations at fixed population size. Increasing the strength of correlation across pools, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e042" xlink:type="simple"/></inline-formula>, sharply reduces the error rate, while increasing the strength of correlation within pools, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e043" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e044" xlink:type="simple"/></inline-formula>, enhances the error rate (<xref ref-type="fig" rid="pcbi-1003970-g002">Figs. 2C and D</xref>).</p>
<fig id="pcbi-1003970-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g002</object-id><label>Figure 2</label><caption>
<title>Positive correlation can dramatically suppress the error.</title>
<p><bold>A.</bold> Probability of discrimination error for a 2-Pool model of a neural population, as a function of the number of neurons, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e045" xlink:type="simple"/></inline-formula>, for independent (dashed; all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e046" xlink:type="simple"/></inline-formula>) and correlated (circles) populations; parameters are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e047" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e048" xlink:type="simple"/></inline-formula> for both, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e049" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e050" xlink:type="simple"/></inline-formula> in the correlated case. Numerical (circles) and analytic (solid line) results are compared. <bold>B.</bold> Suppression factor due to correlation, defined as the ratio between the error probability of independent and correlated populations, as a function of the number of neurons, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e051" xlink:type="simple"/></inline-formula>; numeric (circles) and analytic (solid line) results. <bold>C.</bold> Error probability as a function of the cross-pool correlation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e052" xlink:type="simple"/></inline-formula>, for independent (dashed line) and correlated (circles, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e053" xlink:type="simple"/></inline-formula>) populations; analytic results for correlated population (solid line). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e054" xlink:type="simple"/></inline-formula>. <bold>D.</bold> Error probability as a function of the correlation within Pool 1, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e055" xlink:type="simple"/></inline-formula>, for independent (dashed line) and correlated (circles, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e056" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e057" xlink:type="simple"/></inline-formula>) populations; analytic results for correlated population (solid line). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e058" xlink:type="simple"/></inline-formula>. <bold>E.</bold> Probability contours for three examples of neural populations; independent (green cross, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e059" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e060" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e061" xlink:type="simple"/></inline-formula>), near lock-in correlation (pink dot, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e062" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e063" xlink:type="simple"/></inline-formula>), and uneven correlation (blue diamond, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e064" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e065" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e066" xlink:type="simple"/></inline-formula>). Colored symbols correspond to points on plots in previous panels.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g002" position="float" xlink:type="simple"/></fig>
<p>The important point, here, is that improvements by orders of magnitude do not result from growing the population to unrealistically large numbers of neurons or from boosting the values of pairwise correlations to limiting values close to 1. Correlations may be more or less fine-tuned at a population level, so that the probability of some activity pattern in the population becomes vanishingly small, but no fine-tuning is apparent at the level of <italic>pairwise</italic> correlation. Furthermore, we have focused here on ‘rapid coding’ – situations in which it is not possible to suppress variability by temporal integration. Even then, the massive suppression of error rates occurs in populations of fewer than a hundred neurons and in the presence of realistic correlations ranging from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e067" xlink:type="simple"/></inline-formula> 0.01 to 0.03. (Most correlation values reported in the literature have been measured over somewhat longer time scales than the tens of milliseconds of interest here, but see Ref. <xref ref-type="bibr" rid="pcbi.1003970-Smith1">[21]</xref>.) Strong error suppression occurs because, even in populations of relatively modest size, weak correlations can significantly deform the shape of the probability distributions of population responses (<xref ref-type="fig" rid="pcbi-1003970-g002">Fig. 2E</xref>).</p>
<p>In fact, the suppression of the coding error down to negligible values by positive correlation does not even require populations with as many as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e068" xlink:type="simple"/></inline-formula> neurons. Such suppression can be obtained in much smaller populations, with a total number of neurons, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e069" xlink:type="simple"/></inline-formula>, between 8 and 20 and with values of correlations below or not much higher than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e070" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003970-g003">Figs. 3A and B</xref>). Such values of correlations are still well within the experimentally measured range. We also explore another case which, naively, prohibits low-error coding: that in which the firing rates in the two neuron pools differ by very little; specifically, when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e071" xlink:type="simple"/></inline-formula> is of order one. This condition implies that the overall activities in a given pool, in response to Target and Distracter respectively, differ by one or a few spikes. In this limiting case, coding with pools of independent neurons fails entirely, with error rates of order one, since the absolute amplitude of fluctuations exceeds unity. In a correlated population, we find, again, a massive suppression of error rates by orders of magnitude, for realistic values of correlation (<xref ref-type="fig" rid="pcbi-1003970-g003">Figs. 3C and D</xref>).</p>
<fig id="pcbi-1003970-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g003</object-id><label>Figure 3</label><caption>
<title>Small correlated populations.</title>
<p><bold>A.</bold> Probability of error as a function of the cross-pool correlation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e072" xlink:type="simple"/></inline-formula>, for a small neural population (circles, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e073" xlink:type="simple"/></inline-formula> neurons, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e074" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e075" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e076" xlink:type="simple"/></inline-formula>), with analytic result for correlated population (solid line) and independent population (dashed line) for the sake of comparison. <bold>B.</bold> Probability of error <italic>versus</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e077" xlink:type="simple"/></inline-formula> for populations of different sizes (colors); independent population (dashed lines) and analytic results for correlated population (solid lines). <bold>C.</bold> Probability of error versus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e078" xlink:type="simple"/></inline-formula> for a neural population with responses differing by an average of 2 spikes (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e079" xlink:type="simple"/></inline-formula> neurons, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e080" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e081" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e082" xlink:type="simple"/></inline-formula>); numeric solutions (circles), analytic result (solid line), and independent comparison population (dashed line). <bold>D.</bold> Probability of error versus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e083" xlink:type="simple"/></inline-formula> for populations having different sizes but with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e084" xlink:type="simple"/></inline-formula> held constant at 2 spikes (colors); independent population (dashed lines) and analytic results for correlated population (solid lines).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g003" position="float" xlink:type="simple"/></fig></sec><sec id="s2b">
<title>Analysis of low-error coding</title>
<p>In addition to our direct numerical investigations, we have performed analytic calculations using a Gaussian approximation of the probability distribution (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for derivations). The analytic results agree very closely with the numeric results (<xref ref-type="fig" rid="pcbi-1003970-g002">Figs. 2</xref> and <xref ref-type="fig" rid="pcbi-1003970-g003">3</xref>, solid line vs. circles) and yield simple expressions for the dependence of the error rate upon the parameters of our model, useful for a more precise understanding of the effect of correlation.</p>
<p>The analytic expression of the error rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e085" xlink:type="simple"/></inline-formula>, reads <disp-formula id="pcbi.1003970.e086"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e086" xlink:type="simple"/><label>(1)</label></disp-formula></p>
<p>The numerator in the argument behaves as expected for a population of independent neurons: it yields an exponential decay of the error rate as a function of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e087" xlink:type="simple"/></inline-formula>, with a sharpness that increases with the difference between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e088" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e089" xlink:type="simple"/></inline-formula>. But the denominator,<disp-formula id="pcbi.1003970.e090"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e090" xlink:type="simple"/><label>(2)</label></disp-formula>where<disp-formula id="pcbi.1003970.e091"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e091" xlink:type="simple"/><label>(3)</label></disp-formula>and we have assumed the symmetric case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e092" xlink:type="simple"/></inline-formula> for the sake of simplicity, provides a strong modulation as a function of correlations (<xref ref-type="fig" rid="pcbi-1003970-g002">Figs. 2</xref> and <xref ref-type="fig" rid="pcbi-1003970-g003">3</xref>). The quantity in Eq. (2) approaches zero when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e093" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e094" xlink:type="simple"/></inline-formula>. Thus, in a population of tens or hundreds of neurons, it is sufficient that the two terms in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e095" xlink:type="simple"/></inline-formula> differ by less than a few percent for the coding error to become vanishingly small.</p>
<p>From Eq. (1), it is apparent that the error rate converges rapidly to zero with decreasing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e096" xlink:type="simple"/></inline-formula>, and has an essential singularity at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e097" xlink:type="simple"/></inline-formula>. For any well-defined probability distribution, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e098" xlink:type="simple"/></inline-formula> remains non-negative, but it can take arbitrarily small values. When correlations are such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e099" xlink:type="simple"/></inline-formula> is small enough, we are in a regime of high-fidelity coding. The error vanishes for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e100" xlink:type="simple"/></inline-formula>; in this limit, the probability distributions corresponding to Target and Distracter are both parallel and infinitely thin. The value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e101" xlink:type="simple"/></inline-formula> alone does not specify the geometry of the probability distributions entirely; even with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e102" xlink:type="simple"/></inline-formula>, there remain free parameters, namely, the angles along which the elongated distributions lie in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e103" xlink:type="simple"/></inline-formula> plane (denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e104" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1B</xref>). In <xref ref-type="sec" rid="s4">Materials and Methods</xref>, we demonstrate that these additional parameters need not be fine-tuned for high-fidelity coding. In fact, angles can vary by as much as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e105" xlink:type="simple"/></inline-formula> while the error rate remains below <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e106" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s2c">
<title>Neural diversity is favorable to high-fidelity coding</title>
<p>The simplest version of the 2-Pool model, discussed hitherto, assigns homogeneous firing rate and correlation values within and across each of the two neural sub-populations. Similar homogeneity assumptions are frequent in modeling and data analysis: while response properties vary from neuron to neuron in data, average values are often chosen to represent a population as a whole and to evaluate coding performances. It is legitimate, however, to ask to what extent error rates are shifted in a more realistic setting which includes neural diversity and, in fact, whether high-fidelity coding survives at all in the presence of neuron-to-neuron heterogeneity. We find that not only does it survive but that, in fact, neural diversity further suppresses the error rate.</p>
<p>We generalized the 2-Pool model of a correlated population to include neuron-to-neuron diversity, by randomly and independently varying the firing rate and correlation values according to a Gaussian distribution with standard deviation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e107" xlink:type="simple"/></inline-formula>, measured as a fraction of the original value. We then computed the error rate in this generalized model and compared it to the corresponding quantity in the homogeneous 2-Pool model. (See <xref ref-type="sec" rid="s4">Materials and Methods</xref> for the precise definition of the heterogeneous model and details on the derivation of error rates.) We found that every single instantiation of neural diversity yielded an improvement in the coding performance (<xref ref-type="fig" rid="pcbi-1003970-g004">Figs. 4A and B</xref>). More diverse neural populations with larger values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e108" xlink:type="simple"/></inline-formula> display stronger suppressions of the error rate (<xref ref-type="fig" rid="pcbi-1003970-g004">Fig 4C</xref>). As <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e109" xlink:type="simple"/></inline-formula> increases, the suppression factor grows both in mean and in skewness, so that a significant fraction of the instantiations of heterogeneity yields a large improvement of the coding performance over the homogeneous case (<xref ref-type="fig" rid="pcbi-1003970-g004">Figs. 4A</xref> <italic>vs.</italic> B).</p>
<fig id="pcbi-1003970-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g004</object-id><label>Figure 4</label><caption>
<title>Heterogeneous neural populations.</title>
<p><bold>A, B.</bold> Histogram of the error suppression (error in the homogeneous, 2-Pool model divided by the error in the fully heterogeneous model) for variability values <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e110" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e111" xlink:type="simple"/></inline-formula>, respectively. All suppression values are greater than one. <bold>C.</bold> Value of the error suppression (geometric mean) <italic>versus</italic> the degree of population variability; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e112" xlink:type="simple"/></inline-formula> neurons, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e113" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e114" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e115" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e116" xlink:type="simple"/></inline-formula>. (With these parameters, correlation suppresses the error probability by a factor of 4350 relative to the matched independent population.)</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g004" position="float" xlink:type="simple"/></fig>
<p>The degree of error suppression depends, of course, on how much correlation reduces the error relative to the matched independent population in the first place. For the population shown here, neuron-to-neuron variations on a range commonly seen in experiments lead to a suppression of the error rate by a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e117" xlink:type="simple"/></inline-formula> on average and a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e118" xlink:type="simple"/></inline-formula> for some instantiations of the heterogeneity (<xref ref-type="fig" rid="pcbi-1003970-g004">Fig. 4B</xref>). These results would differ quantitatively, and may differ qualitatively, in the extreme cases already poised very near lock-in in the absence of neuron-to-neuron variability of the correlation values, as the lock-in limit corresponds to a boundary in the space of covariance matrices.</p>
<p>Above, we have examined the effect of heterogeneity for a simple and contrived case: in a model with homogeneous pools, we have perturbed firing rates and correlation coefficients by small amounts. The results may be different for other forms of heterogeneity. We relegate to a separate publication a more detailed investigation of the quantitative effect of heterogeneity and of the corresponding mechanisms by which coding is improved. We mention, however, that the coding benefit of heterogeneity appears to be a rather general phenomenon <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Osborne1">[44]</xref>.</p>
</sec><sec id="s2d">
<title>The mechanism for high-fidelity coding and the ‘lock-in’ phenomenon</title>
<p>The mechanism of dramatic error suppression from positive correlations may be explained in a general manner that does not invoke a specific model or approximation. A powerful description is given in terms of the ‘macroscopic’ variances and covariances of the spike count within and across the two pools: we call <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e119" xlink:type="simple"/></inline-formula> the variance in the spike count, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e120" xlink:type="simple"/></inline-formula>, within Pool 1, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e121" xlink:type="simple"/></inline-formula> the variance in the spike count, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e122" xlink:type="simple"/></inline-formula>, within Pool 2, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e123" xlink:type="simple"/></inline-formula> the covariance of spike counts across the two pools. (See <xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1B</xref> for a visual definition of these quantities, <xref ref-type="sec" rid="s4">Materials and Methods</xref> for mathematical definitions as well as derivations of the results discussed below.)</p>
<p>The variances of the probability distribution of the neural response in the plane <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e124" xlink:type="simple"/></inline-formula> take the form<disp-formula id="pcbi.1003970.e125"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e125" xlink:type="simple"/><label>(4)</label></disp-formula></p>
<p>The angles along which these variances are measured can also be computed similarly (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). In the case of positive correlation, the angle along which the distribution elongates (<italic>i.e.</italic>, the angle long which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e126" xlink:type="simple"/></inline-formula> extends, denoted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e127" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1B</xref>) lies between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e128" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e129" xlink:type="simple"/></inline-formula>. The small variance, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e130" xlink:type="simple"/></inline-formula>, lies at right angle and governs error rate suppression. The smaller <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e131" xlink:type="simple"/></inline-formula> and the more parallel the compressed distributions, the smaller the error rates. The expressions for the variances (above) and the angles (given in <xref ref-type="sec" rid="s4">Materials and Methods</xref>) are general—they do not depend upon the shapes of the distributions or the details of the correlation among neurons—and they give a sense of the extent to which probability distributions of the population response are deformed by correlations. In the specific 2-Pool models we treated above, positive correlations induce massive suppressions of the coding error rate. We expect similar high-fidelity coding whenever the tails of probability distributions fall off sufficiently rapidly.</p>
<p>The limiting case of an infinitely thin distribution occurs when <disp-formula id="pcbi.1003970.e132"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e132" xlink:type="simple"/><label>(5)</label></disp-formula>in this case, <disp-formula id="pcbi.1003970.e133"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e133" xlink:type="simple"/><label>(6)</label></disp-formula>and <disp-formula id="pcbi.1003970.e134"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e134" xlink:type="simple"/><label>(7)</label></disp-formula></p>
<p>We refer to Eq. (5) as the ‘lock-in’ condition. When the cross-pool covariance becomes this large, the width of the probability distribution vanishes and the dimensionality of the response space is effectively reduced by one. In the case of homogeneous pools of neurons, we can reformulate this condition using ‘microscopic’ correlations, as <disp-formula id="pcbi.1003970.e135"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e135" xlink:type="simple"/><label>(8)</label></disp-formula>(see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). If the lock-in condition in Eq. (5) (alternatively, Eq. (8)) is satisfied and and _ (alternatively, _ and _) are chosen such as to yield compressed distributions that are parallel, then error rates vanish. (See <xref ref-type="sec" rid="s3">Discussion</xref> for remarks on the nature of the locked-in state.</p>
<p>As we have seen above, even if the cross-pool correlation approaches this lock-in limit without achieving it, still the error rate can be suppressed dramatically. Furthermore, the angles of the two distributions need not be precisely equal. Thus, this amounts to a robust mechanism by which coding and discrimination may be achieved with near-perfect reliability. It does not require fine tuning of the parameters such as the distribution widths and their tilt angles; in particular, we need not limit ourselves to symmetric choices of parameters, as we have done above for the sake of simplicity.</p>
<p>The general arguments presented here also indicate that the ‘<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e136" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e137" xlink:type="simple"/></inline-formula> spike’ assumption is inessential and, in fact, that relaxing it may lead to even stronger effects. If individual neurons can fire several spikes in a time window of interest, the code can be combinatorial, but a simple spike count code will do <italic>at least as well</italic> as a more sophisticated combinatorial one. If we stick to the spike count code, the general formulation remains valid. In this situation, allowing many spikes per neurons corresponds effectively to increasing the total number of neurons and, hence, can yield stronger effects for comparable correlation values.</p>
</sec><sec id="s2e">
<title>Correlated populations can code for large sets of stimuli with high fidelity</title>
<p>In most natural situations, the task of organisms is not to tell two stimuli apart but rather to identify an actual stimulus among a wealth of other, possibly occurring stimuli. Visual decoding must be able to assign a given response pattern to one of many probability distributions, with low error. In other words, any pair of probability distributions of neural activity, corresponding to two stimuli among a large set of stimuli, must have little overlap. Thus, the problem of low-error coding of a large set of stimuli amounts to fitting, within the space of neural activity, a large number of probability distributions, while keeping them sufficiently well separated that their overlap be small.</p>
<p>It is easy to see pictorially why the presence of correlation is favorable to the solution of this problem. The state of the 2-Pool model is specified by the number of active neurons in Pools 1 and 2, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e138" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e139" xlink:type="simple"/></inline-formula> respectively. If neurons are independent, probability distributions (corresponding to different stimuli) have a near-circular shape with variances along the horizontal and the vertical axes of order <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e140" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e141" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5A</xref>). As a result, the only way to prevent tails from overlapping too much is to separate the peaks of the distributions sufficiently. By contrast, since correlated distributions are elongated, their centers can be placed near each other while their tails overlap very little (<xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5B</xref>). Thus, many more correlated distributions than independent distributions can be packed in a given region in the space of neural responses (<xref ref-type="fig" rid="pcbi-1003970-g005">Figs. 5A and B</xref>).</p>
<fig id="pcbi-1003970-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g005</object-id><label>Figure 5</label><caption>
<title>Number of encoded stimuli for independent <italic>versus</italic> correlated populations.</title>
<p><bold>A, B.</bold> Schematics of the optimal arrangement of the probability distributions for independent (A) and correlated (B) populations. Each set of contours represents the log probability distribution of neural activity given a stimulus (hotter colors indicate higher probability). Spacing is set by the criterion that adjacent pairs of distributions have a discrimination error threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e142" xlink:type="simple"/></inline-formula>. <bold>C.</bold> Number of stimuli encoded at low error, per neuron, <italic>versus</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e143" xlink:type="simple"/></inline-formula>, for correlated (thin dashed line for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e144" xlink:type="simple"/></inline-formula>, thick dashed line for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e145" xlink:type="simple"/></inline-formula>) and independent (solid lines) populations, for different values of the error criterion, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e146" xlink:type="simple"/></inline-formula> (colors). <bold>D.</bold> Number of encoded stimuli per neuron, for correlated (thin dashed line for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e147" xlink:type="simple"/></inline-formula>, thick dashed line for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e148" xlink:type="simple"/></inline-formula>) and independent (solid lines) populations, <italic>versus</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e149" xlink:type="simple"/></inline-formula>, for different values of the number of neurons, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e150" xlink:type="simple"/></inline-formula> (colors).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g005" position="float" xlink:type="simple"/></fig>
<p>We call <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e151" xlink:type="simple"/></inline-formula> the maximum number of stimuli that a population of neurons can code with an error rate less than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e152" xlink:type="simple"/></inline-formula> in the discrimination of any stimulus pair. In the case of independent neurons (<xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5A</xref>), a simple calculation yields <disp-formula id="pcbi.1003970.e153"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e153" xlink:type="simple"/><label>(9)</label></disp-formula>where we have chosen the value of the error threshold to be small enough that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e154" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for derivations). In the correlated case (<xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5B</xref>), distributions are elongated and, provided the correlations values are chosen appropriately, error rates become vanishingly small even if the average firing rates of nearby distributions differ by no more than a few, say <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e155" xlink:type="simple"/></inline-formula>, spikes. We then obtain <disp-formula id="pcbi.1003970.e156"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e156" xlink:type="simple"/><label>(10)</label></disp-formula>since distribution centers can be arranged along a line that cuts through the space of responses—a square with side <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e157" xlink:type="simple"/></inline-formula> in the positive <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e158" xlink:type="simple"/></inline-formula> quadrant. (Note that more than one row of distributions may be fitted into the response space of the neural populations if the distributions are not too broad in their elongated direction, with a resulting enhancement of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e159" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1003970-g005">Figure 5B</xref> illustrates a case in which three rows are accommodated. We do not include these extra encoded stimuli in our calculations, thus remaining more conservative in our estimate of coding capacity.) According to our earlier results (<xref ref-type="fig" rid="pcbi-1003970-g003">Fig. 3D</xref>), even in moderately small populations the error rate becomes exceedingly small for realistic choices of the correlation values when the distribution centers are two spikes away from each other. Thus, we can choose the value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e160" xlink:type="simple"/></inline-formula> to obtain an estimate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e161" xlink:type="simple"/></inline-formula>. Putting all this together, find that for low enough <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e162" xlink:type="simple"/></inline-formula> correlated coding always wins over independent coding (<xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5C</xref>) because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e163" xlink:type="simple"/></inline-formula> depends upon <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e164" xlink:type="simple"/></inline-formula> much more strongly than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e165" xlink:type="simple"/></inline-formula> does. Furthermore, in the uncorrelated case and in the limit of small error thresholds, increasing the population size yields only a negligible enhancement of the number of faithfully encoded stimuli, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e166" xlink:type="simple"/></inline-formula>, because this quantity is largely insensitive to the size of the population (<xref ref-type="fig" rid="pcbi-1003970-g005">Figs. 5D</xref>).</p>
</sec><sec id="s2f">
<title>Positive correlations in a diverse neural population can enhance capacity by orders of magnitude</title>
<p>Our arguments suggest that we ought to examine the behavior of the capacity of heterogeneous neural populations because a greater degree of heterogeneity amounts to higher dimensional versions of the situations depicted in <xref ref-type="fig" rid="pcbi-1003970-g005">Figs. 5A and B</xref>, as we explain now. We define the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e167" xlink:type="simple"/></inline-formula>-Pool model: a heterogeneous generalization of the 2-Pool model in which the neural population is divided into <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e168" xlink:type="simple"/></inline-formula> sub-populations. As before, firing rates and correlations are homogeneous within each pool and across pool pairs. For the sake of simplicity, we consider symmetric pools with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e169" xlink:type="simple"/></inline-formula> neurons each; we also expect this arrangement to be optimal for coding. The state of the model is completely defined by the number of active neurons in each pool.</p>
<p>In order to estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e170" xlink:type="simple"/></inline-formula>, we have to examine how probability distributions corresponding to different stimuli can be fitted within a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e171" xlink:type="simple"/></inline-formula>-dimensional box enclosing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e172" xlink:type="simple"/></inline-formula> neural states. And overlaps among distributions have to respect the prescribed error rate threshold. In the case of independent neurons we have to fit in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e173" xlink:type="simple"/></inline-formula>-dimensional near-circular objects, whereas in the case of correlated neurons we have to fit in slender objects. It is intuitive that it is easier to pack cucumbers in a box than to pack melons of a comparable volume, because a greater amount of empty space is wasted in the case of spherical objects such as melons, and indeed we find here that a greater number of correlated distributions, as compared to independent distributions, can be packed in the space of responses. The calculation gives<disp-formula id="pcbi.1003970.e174"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e174" xlink:type="simple"/><label>(11)</label></disp-formula>(<xref ref-type="fig" rid="pcbi-1003970-g006">Fig. 6A</xref>, see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for derivations). Notice that the number of possible stimuli encoded by the independent population increases for greater heterogeneity (larger <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e175" xlink:type="simple"/></inline-formula>).</p>
<fig id="pcbi-1003970-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g006</object-id><label>Figure 6</label><caption>
<title>Coding capacity of heterogeneous populations.</title>
<p><bold>A.</bold> Number of encoded stimuli <italic>versus</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e176" xlink:type="simple"/></inline-formula>, for an independent population divided into different numbers of pools, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e177" xlink:type="simple"/></inline-formula> (colors); the error criterion is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e178" xlink:type="simple"/></inline-formula>. <bold>B.</bold> Ratio of the number of encoded stimuli in a correlated population and the number of encoded stimuli in a matched independent population, for different numbers of pools <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e179" xlink:type="simple"/></inline-formula> (colors). <bold>C.</bold> Optimal pool size, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e180" xlink:type="simple"/></inline-formula>, <italic>versus</italic> error criterion, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e181" xlink:type="simple"/></inline-formula>, for correlated (dashed line, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e182" xlink:type="simple"/></inline-formula>) and independent (solid line) populations. <bold>D.</bold> Optimal capacity per neuron, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e183" xlink:type="simple"/></inline-formula>, <italic>versus</italic> error criterion, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e184" xlink:type="simple"/></inline-formula>, for correlated (dashed line, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e185" xlink:type="simple"/></inline-formula>) and independent (solid line) populations.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g006" position="float" xlink:type="simple"/></fig>
<p>In the case of correlated neurons, distributions may be compressed along one, two,…, or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e186" xlink:type="simple"/></inline-formula> directions, by tuning one, two,…, or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e187" xlink:type="simple"/></inline-formula> effective parameters, respectively, in such a way that the matrix of covariances come with one, two,…, or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e188" xlink:type="simple"/></inline-formula> near-vanishing eigenvalues. In the latter case, indeed the most favorable scenario, we have to pack near-one-dimensional objects. As before in the case of a two-pool population, we can assume that neighboring distributions centers are separated by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e189" xlink:type="simple"/></inline-formula> spikes, and we obtain<disp-formula id="pcbi.1003970.e190"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e190" xlink:type="simple"/><label>(12)</label></disp-formula></p>
<p>This simple result follows from the observation that distribution centers can be arranged on a hyperplane that cuts through the hypercube of the space of responses (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for a more detailed discussion and a slightly more careful bound). From these expressions we can conclude that the enhancement in capacity due to correlation is significant, and that the enhancement increases with the degree of heterogeneity (<xref ref-type="fig" rid="pcbi-1003970-g006">Fig. 6B</xref>).</p>
<p>The number of stimuli encoded with tolerable error rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e191" xlink:type="simple"/></inline-formula>, scales differently with model parameters in the independent and correlated cases. In order to focus on this scaling behavior, we define the ‘capacity per neuron’, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e192" xlink:type="simple"/></inline-formula>, by analogy to the information conveyed by each neuron in a population of perfectly deterministic neurons. In the latter case, the population has access to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e193" xlink:type="simple"/></inline-formula> response patterns that can code for stimuli with perfect reliability. Each neuron conveys <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e194" xlink:type="simple"/></inline-formula> bit of information. Consequently, we define the capacity per neuron as<disp-formula id="pcbi.1003970.e195"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e195" xlink:type="simple"/><label>(13)</label></disp-formula></p>
<p>It is a measure of the mutual (Shannon) information per neuron in the population in the limit of very small <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e196" xlink:type="simple"/></inline-formula>.</p>
<p>To explore the scaling behavior of correlated <italic>versus</italic> independent populations, it is reasonable to ask what degree of heterogeneity, as measured by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e197" xlink:type="simple"/></inline-formula>, maximizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e198" xlink:type="simple"/></inline-formula> for each value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e199" xlink:type="simple"/></inline-formula>. Equivalently, we can ask what pool size, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e200" xlink:type="simple"/></inline-formula>, maximizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e201" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003970-g006">Fig. 6C</xref>, see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). In the correlated case, the optimal capacity obtains when heterogeneity is strong, in fact so strong that the number of neurons per pool, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e202" xlink:type="simple"/></inline-formula>, is as small as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e203" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e204" xlink:type="simple"/></inline-formula> neurons for the choice <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e205" xlink:type="simple"/></inline-formula>. From the optimal pool size, we find that the optimal value of the capacity per neuron is given by<disp-formula id="pcbi.1003970.e206"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e206" xlink:type="simple"/><label>(14)</label></disp-formula>and<disp-formula id="pcbi.1003970.e207"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e207" xlink:type="simple"/><label>(15)</label></disp-formula>in the independent and correlated cases respectively (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for derivations). The independent capacity becomes very small at low-error thresholds, while the correlated capacity remains fixed and in fact of the same order as the capacity of a perfectly reliable neuron (<xref ref-type="fig" rid="pcbi-1003970-g006">Fig. 6D</xref>). Thus, in the limit of low error, the capacity and hence information encoded per neuron exceeds the corresponding quantity in an independent population by more than a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e208" xlink:type="simple"/></inline-formula>. By comparison, one often finds analogous effects measured in a few percent in other studies.</p>
<p>We have put forth the following picture. For a neural population to code for a large set of inputs reliably, it breaks up into small pools with about ten neurons, with correlation across pools stronger than correlation within pools. These pools are small enough that their number is large, and consequently the response space is high-dimensional. But, at the same time, the pools are large enough that realistic correlations lock them in and yield effectively lower-dimensional response distributions. In a sense, a pool behaves like a ‘deterministic meta-neuron’ which obeys a near-digital code. In the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e209" xlink:type="simple"/></inline-formula>-dimensional space of population activity, variability is confined to one (or more) directions. In the extreme case in which the population responses for different stimuli differ by no more than one or two spikes (as illustrated in <xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5B</xref>), the orthogonal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e210" xlink:type="simple"/></inline-formula> (or fewer) directions are relieved from variability and the code is near-digital in that sub-space. Clearly, this represents the most extreme case of high-fidelity coding; even away from this limit, when there is a degree of variability along all directions, correlation can significantly enhance capacity. We emphasize, also, that, even in the limiting case, the suppression of the variability can be checked only in simultaneous measurements of at least all the neurons in a given pool; measurements of, e.g., pairs of neurons will yield as much variability as if neurons were independent.</p>
</sec><sec id="s2g">
<title>Experimental test of favorable correlations</title>
<p>If neural populations rely upon correlation to achieve high-fidelity coding, we expect that patterns of correlations resembling those postulated in our model can be found in data. Namely, our hypothesis predicts that subsets of similarly tuned pools of neurons will exhibit weaker within-pool correlations than cross-pool correlations. In order to check this prediction, the response of a neural population to a pair of stimuli or a pair of stimulus classes has to be recorded (<xref ref-type="fig" rid="pcbi-1003970-g007">Fig. 7A</xref>). This population is divided into a group of cells that fire more strongly to the first stimulus and the rest that fire more strongly to the second stimulus (<xref ref-type="fig" rid="pcbi-1003970-g007">Fig. 7B</xref>). Note that this step is always possible and that all cells can be thus assigned.</p>
<fig id="pcbi-1003970-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g007</object-id><label>Figure 7</label><caption>
<title>Schematics of an experimental test of high-fidelity correlated coding.</title>
<p><bold>A.</bold> Representation of a population of 50 neurons recorded under two stimulus conditions. Each cell displays firing rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e211" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e212" xlink:type="simple"/></inline-formula> in response to the two stimuli, respectively; the color scale shows the difference in rates, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e213" xlink:type="simple"/></inline-formula>. <bold>B.</bold> The population is divided into two groups, depending on whether their cells fire more significantly in response to the first (preferred) or the second (anti-preferred) stimulus. <bold>C.</bold> Matrix of correlation values among all pairs of neurons (red  =  large, blue  =  small, black  =  average), divided into preferred and anti-preferred groups. Although the overall correlation is stronger for neurons with the same stimulus tuning (average correlation of pref-pref  = 0.206, anti-anti  = 0.217, and pref-anti  = 0.111), a subset of neurons (Pool 1 and Pool 2) are identified which have the pattern of correlation favorable to lock-in. <bold>D.</bold> Matrix of pairwise correlations after re-labeling cells in order to sort out Pools 1 and 2. Now the favorable pattern of correlation is visible.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g007" position="float" xlink:type="simple"/></fig>
<p>Next, one would have to identify pools of neurons, within the population, such that the correlations relative to these pools are near lock-in. But this is a stringent requirement, which would involve exceedingly heavy numerical processing. Instead, one can search for subsets of the population that have stronger correlation across the groups than within (<xref ref-type="fig" rid="pcbi-1003970-g007">Fig. 7C</xref>), as this is a definite requirement in the proposed scenario—and the one that may appear counter-intuitive. For recordings with several tens of cells, there is a very large number of possible subsets, so an exhaustive search may not be feasible. Instead, there exist a number of faster search strategies. For instance, one can score each cell according to the sum of its pairwise correlation to all cells in the other group minus the sum to all cells within its stimulus-tuned group. This yields a rank ordering of cells, which can be used for selecting favorable subsets. In addition, searches can be made iteratively, starting with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e214" xlink:type="simple"/></inline-formula> cells and finding the best next cell to add to the subset. Once a subset is identified, a quick assessment of the role of correlation can be made using average firing rates and correlations to calculate the error rate in the Gaussian approximation (Eq. (1)). As seen in <xref ref-type="fig" rid="pcbi-1003970-g002">Figs. 2</xref> and <xref ref-type="fig" rid="pcbi-1003970-g003">3</xref>, this approximation is highly accurate. Then, for the most favorable subsets, a maximum entropy calculation can be carried out to estimate the discrimination error taking into account the true experimentally observed heterogeneity. As indicated by <xref ref-type="fig" rid="pcbi-1003970-g004">Fig. 4</xref>, the homogeneous approximation is not only quite close to the real error rate, but it also serves as an upper bound on the error. In this manner, subsets of neurons with correlation patterns favorable to lock-in can be identified in neurophysiological recordings.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>Summary</title>
<p>We have shown that a class of patterns of positive correlation can suppress <italic>coding errors</italic> in a two-alternative discrimination task (<xref ref-type="fig" rid="pcbi-1003970-g002">Figs. 2A and B</xref>). The idea that correlations among neurons may be favorable to coding was noted earlier. What is new, here, is the demonstration of the extreme degree of the enhancement in coding fidelity from positive correlation — several orders of magnitude rather than a few tens of a percent. Furthermore, this generic result does not require unrealistic values of correlation or population size: it can operate at the moderate values of correlations recorded experimentally (<xref ref-type="fig" rid="pcbi-1003970-g002">Figs. 2C and D</xref>) and in populations with as few as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e215" xlink:type="simple"/></inline-formula> neurons (<xref ref-type="fig" rid="pcbi-1003970-g003">Figs. 3A and B</xref>). In fact, massive error suppression may occur even when average activities in a neural pool in response to different stimuli differ by one or a few spikes (<xref ref-type="fig" rid="pcbi-1003970-g003">Figs. 3C and D</xref>)—a limiting, but realistic, situation in which coding with independent neurons fails completely.</p>
<p>We have also shown that correlations can boost dramatically the <italic>capacity</italic> of a neural population, <italic>i.e.</italic>, the number of stimuli that can be discriminated with low error (<xref ref-type="fig" rid="pcbi-1003970-g005">Figs. 5</xref> and <xref ref-type="fig" rid="pcbi-1003970-g006">6</xref>). For independent neurons, the mean firing rates of the population in response to different stimuli must differ by a substantial amount to allow low error, because the firing variability about the mean is not harnessed by correlation. By contrast, in the presence of correlation, neural response distributions can deform into slender objects, effectively lower-dimensional objects, which can be fitted much more efficiently within the population's response space (<xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5B</xref>).</p>
<p>At lock-in, response distributions become strictly lower-dimensional (one-dimensional in the extreme case); in this limiting case, small pools of neurons within the population behave like ‘deterministic meta-neurons’ which obey a near-digital code. While our calculations have focused on this extreme limit of ‘lock-in’, the brain need not achieve it strictly. The logic is that if this upper bound is insignificant then one can rule out this coding scheme, but that if the upper bound is highly significant – as we show here – then it is more plausible that the brain might find beneficial adaptations to make use of the mechanism. We note that, even in the lock-in limit, it is not possible to read off the high reliability of the population response from ‘local’ quantities such as pairwise correlation coefficients. The latter display as much variability as in the case of independent neurons. High-fidelity coding is a collective phenomenon.</p>
<p>Furthermore, we have demonstrated that diversity in neuron-to-neuron response, and more generally heterogeneity of the population response, further enhances the effect of correlation (<xref ref-type="fig" rid="pcbi-1003970-g004">Fig. 4</xref> and <xref ref-type="fig" rid="pcbi-1003970-g006">Figs. 6A and B</xref>). Indeed, the advantageous role of heterogeneity seems to be a rather general feature of population coding, and it has been illustrated within various approaches <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Osborne1">[44]</xref>. We refer to the phenomenon in which neural correlation suppresses the discrimination errors to negligible values and dramatically boosts the capacity of a population as <italic>high-fidelity coding</italic>. In passing, we note that high-fidelity coding does not, in principle, require equal-time correlation: the same mechanism can be at play when the correlations that matter involve different time bins, such as in ‘spike-latency codes’ <xref ref-type="bibr" rid="pcbi.1003970-Gollisch1">[45]</xref>. Finally, we have proposed a possible analysis of neural data that aims at uncovering favorable patterns of correlation (<xref ref-type="fig" rid="pcbi-1003970-g007">Fig. 7</xref>).</p>
</sec><sec id="s3b">
<title>How extreme is lock-in?</title>
<p>We showed that, in the limit of large enough populations or strong enough pairwise correlations, the distribution of activity of the population can ‘lock in’ to a state of lower dimensionality. While, in this state, <italic>macroscopic</italic> correlations (among spike counts in sub-populations) reach limiting values, one may wonder about the nature of the <italic>microscopic</italic> correlations. Furthermore, we can ask how finely the parameters of the model ought to be tuned for a significant effect on coding to obtain.</p>
<p>The positivity of probability implies constraints upon moments of the neural activity; in particular, we have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e216" xlink:type="simple"/></inline-formula>. This bound is achieved by the lock-in condition given in Eq. (5). Thus, lock-in embodies the limiting case of maximum macroscopic correlation between Pools 1 and 2, but there remains a significant amount of (microscopic) variability even at lock-in. The specificity of lock-in is that it forbids a subset of the microscopic patterns, i.e., that these occur with vanishing probability. However, at lock-in the system is not confined to a single output pattern. A large set of patterns can occur with non-negligible probability each—hence the variability—and the remaining patterns are ruled out—hence the vanishing overlaps and error rates.</p>
<p>In fact, generically, positive correlations will enhance the marginals of the probability distributions of activity patterns. For example, the variability in a given pool will be boosted by correlations. Thus, for measurements within a given pool, responses will appear <italic>more</italic> variable than independent ones, even at the lock-in limit. Furthermore, while the distribution of population states reaches a singular limit at lock-in, this cannot be read off from individual measurements of pairwise correlations (even is the pair of neuron straddles two different pools). While macroscopic correlation coefficients have been pushed to their limiting values at lock-in, microscopic correlation coefficients remain moderate (and well below any limit one would obtain by considering pairs or small groups of neurons).</p>
<p>In the Gaussian approximation of the two-pool model, only patterns with a fixed ratio between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e217" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e218" xlink:type="simple"/></inline-formula> are allowed at lock-in. In the absence of correlations, allowed output patterns fill a two-dimensional space—the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e219" xlink:type="simple"/></inline-formula> plane. When correlations push the system to lock-in, output patterns are confined to a one-dimensional space—the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e220" xlink:type="simple"/></inline-formula> line. This dimensionality reduction results in error rate suppression and in increased capacity. In the higher-dimensional case of full heterogeneity (and Gaussian variability), the question of lock-in amounts to asking whether one or several eigenvalues of the covariance matrix become vanishingly small. A population attains the actual lock-in state only for specific values of pairwise correlation and firing rate; however, we have shown that the error rate can reach near-vanishing values for a range of parameters that do not bring the population all the way to the lock-in condition. This result on robustness is generic as it relies only upon the rapid fall-off of the tails of the response probability distribution.</p>
<p>This points to the second question we posed above, namely, to what extent are the parameters in the model fine-tuned. Clearly, in order to reach the singular, lock-in limit, an effective parameter—a combination of firing rates and correlation coefficients—has to be fine-tuned. There are, however, two important points to note. First, as mentioned above, astronomical enhancement of coding performance occurs <italic>near</italic> lock-in already; there is no need to be <italic>at</italic> lock-in. Second, while one effective parameter ought to be fine-tuned, others do not have to be. In <xref ref-type="sec" rid="s4">Materials and Methods</xref>, we provide a detailed study of the coding performance as a function of variations in these additional parameters, and we demonstrate that the enhancement of performance is highly robust to parameter perturbations.</p>
<p>Finally, we point out an important distinction, which may play a major role in the issue of fine-tuning. Throughout, we have been referring to ‘parameters’ when discussing the response properties, i.e., firing rates, correlation coefficients, and combinations of these. But, in reality, ‘neural processing parameters’ or ‘biophysical parameters’ (such as temporal filters, non-linear transfer functions, synaptic weights, etc) are the ones which are putatively tuned, in an actual brain area. Ultimately, one would like to know to what extent fine-tuning is stringent in the space of these parameters. While a detailed answer to this question certainly lies beyond the scope of the present paper, we can offer a preliminary comment. Intuition as well as exploratory numerical work indicate that, in the space of the ‘biophysical parameters’, rather than fine-tuning parameters, what will matter for a high coding performance is that some parameters be sufficiently strong (e.g., synaptic weights sufficiently large to build up significant correlation). Thus, while high-fidelity coding may require (a relatively) fine tuning in the space of ‘correlation parameters’, fine-tuning is not necessarily required in the space of the ‘biophysical parameters’.</p>
</sec><sec id="s3c">
<title>Relation with earlier work on coding with correlated neurons</title>
<p>A number of theoretical studies have explored the role of correlation in neural coding, with the use of different neuron models and information theoretic measures <xref ref-type="bibr" rid="pcbi.1003970-Johnson1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Vogels1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Oram1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Abbott1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Panzeri1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Sompolinsky1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Romo1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Golledge1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Pola1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck2">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck3">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Josic1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref>. If response properties are homogeneous among neurons, positive correlation is detrimental to coding: it tends to induce neurons to behave alike, and thereby suppresses the advantage of coding with a population rather than with a single cell (see <xref ref-type="supplementary-material" rid="pcbi.1003970.s001">Text S1</xref>, Supplementary discussion for detailed arguments). By contrast, if response properties vary among neurons, positive correlation can be either unfavorable or favorable <xref ref-type="bibr" rid="pcbi.1003970-Abbott1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Panzeri1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Sompolinsky1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Pola1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck3">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref>. Put more generally, when the scale of correlation is comparable to that of the informative mode in the system (dictated, <italic>e.g.</italic>, by the response tuning curve), then correlation enhances the confounding effect of noise (see <xref ref-type="supplementary-material" rid="pcbi.1003970.s001">Text S1</xref>, Supplementary discussion for a simple illustration of this mechanism). But when the scale and structure of correlation is very different — as in the case of uniform positive correlations, in the case of negative correlations (anti-correlations), or in models with heterogeneity — correlation can relegate noise to a non-informative mode <xref ref-type="bibr" rid="pcbi.1003970-Abbott1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Sompolinsky1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref>. (We recall that we are focusing exclusively upon the case of stimulus-independent covariance matrices and, hence, stimulus-independent pairwise correlations. Experiments indicate the presence of both stimulus-independent and stimulus-dependent correlations.)</p>
<p>In the case of stimulus-independent, positive correlation, earlier studies have formulated a mechanism by which correlation can relegate noise to non-informative models and, hence, enhance coding fidelity <xref ref-type="bibr" rid="pcbi.1003970-Johnson1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Oram1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Abbott1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Petersen1">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Sompolinsky1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Romo1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck2">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck3">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref>. Namely, that negative signal correlations (anti-correlations) should be supplemented with positive noise correlations. To be explicit, this means that when neurons respond differentially to different stimuli, on average, then the variability about this average response should be correlated positively; this mechanism is illustrated in <xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1B</xref> and sets the starting point of our study. Conversely, negative correlations (anti-correlations) are favorable in the case of positive signal correlation. These statements have been established following different routes in the literature. They can be read off in full generality, that is, without invoking any particular neuron model or form of the neural response, from the expression of the mutual (Shannon) information <xref ref-type="bibr" rid="pcbi.1003970-Panzeri1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Golledge1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Pola1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Averbeck3">[39]</xref>. This is done by rewriting the mutual information in a form that displays contributions from firing rates, correlations, and the interplay of firing rate and correlation patterns. Approaches using the mutual information have the merit of elegance and generality. However, for quantitative estimates they require the implementation of specific response models; furthermore, they are difficult to apply to large populations of neurons because of sampling limitations and mathematical difficulties.</p>
<p>Similar results can be derived from the form of the Fisher information <xref ref-type="bibr" rid="pcbi.1003970-Abbott1">[28]</xref>,<xref ref-type="bibr" rid="pcbi.1003970-Sompolinsky1">[30]</xref>,<xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>,<xref ref-type="bibr" rid="pcbi.1003970-Averbeck3">[39]</xref>,<xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref>,<xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref>, often used to establish bounds on the estimation variability in the case of continuous stimuli. Most studies consider neurons with broad tuning properties and find that positive correlations are unfavorable if they decay on the scale of the tuning curve. Positive correlations were observed to be favorable in cases in which they are uniform among all neurons or have a non-monotonic profile according to which similarly tuned neurons are less correlated than neurons that differ greatly in their tuning. In all cases, however, positive correlation enhanced the coding fidelity by modest amounts. In the next section, we discuss these quantitative aspects in greater detail, as well as their correspondence with our formulation and results.</p>
<p>In models of broadly tuned neurons with uniform pairwise correlation over the entire population, coding becomes increasingly reliable as the quantity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e221" xlink:type="simple"/></inline-formula> tends to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e222" xlink:type="simple"/></inline-formula>. For example, the Fisher information is boosted by a factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e223" xlink:type="simple"/></inline-formula> as compared to the case of independent neurons <xref ref-type="bibr" rid="pcbi.1003970-Abbott1">[28]</xref>. Thus, strong correlation-induced improvement in coding performance occurs only in the unrealistic limit of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e224" xlink:type="simple"/></inline-formula> close to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e225" xlink:type="simple"/></inline-formula>. The situation is different in our simple models. There, high-fidelity coding requires that the modified quantity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e226" xlink:type="simple"/></inline-formula> approach <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e227" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e228" xlink:type="simple"/></inline-formula> is a weighted difference of cross-pool correlation values and within-pool values, be small (see, e.g., Eqs. (2)). The presence of similarly tuned pools of neurons, within the population, amplifies the effect of weak pairwise correlation to produce profound changes in the activity patterns of the neural population. Since correlation values are in the range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e229" xlink:type="simple"/></inline-formula>, values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e230" xlink:type="simple"/></inline-formula> as modest as a few tens or a few hundreds are sufficient to bring the quantity of interest, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e231" xlink:type="simple"/></inline-formula>, extremely close to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e232" xlink:type="simple"/></inline-formula>.</p>
<p>Similarly, Ref. <xref ref-type="bibr" rid="pcbi.1003970-Sompolinsky1">[30]</xref> showed that coding can be enhanced by a large factor in the presence of anti-correlations as weak as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e233" xlink:type="simple"/></inline-formula> (as quoted, also, in Ref. <xref ref-type="bibr" rid="pcbi.1003970-Averbeck3">[39]</xref>) and Refs. <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref> reported significant boosts of the Fisher information of positively correlated neurons in the presence of heterogeneous tuning functions. This occurs for populations with hundreds of neurons and it is yet another illustration of the significant effect that can take place when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e234" xlink:type="simple"/></inline-formula>. In the present work, we have shown that similarly large effects can occur due to the experimentally more typical positive correlations, and in the context of much smaller neural population with no more than a few tens of neurons.</p>
<p>We remark in passing that there are other mechanisms by which confounding noise can be relegated to non-informative dimensions. In the context of broadly-tuned neurons and long-range correlation—the usual setup of studies which make use of Fisher information—the presence of neuron-to-neuron variability (e.g., in the firing rates) can do the trick <xref ref-type="bibr" rid="pcbi.1003970-Wilke1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shamir2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Ecker2">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Hu1">[42]</xref>. In the absence of variability, positive correlation suppresses the coding performance as compared with an independent population. Neuron-to-neuron variability introduces a new dimension, namely, modulations much finer-grained than the scale of tuning and correlation, in which information is stored. Then, in a correlated population one retrieves, roughly, the coding performance of an independent population. This mechanism cannot, to our knowledge, generate substantial improvement in coding performance over that of an independent population.</p>
<p>A separate line of investigation of the properties of coding in the presence of correlation focuses upon ‘interactions’ (parameters of the probability distribution of population activity) instead of correlation coefficients as its central objects <xref ref-type="bibr" rid="pcbi.1003970-Schneidman1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Shlens2">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Tkacik1">[49]</xref>. When a maximization procedure is applied to the mutual information between the distribution of parameters and that of population activity, in a noisy regime one obtains positive interactions and, correspondingly, positive correlation, which enhance the encoded information appreciably compared to an independent population <xref ref-type="bibr" rid="pcbi.1003970-Tkaik1">[50]</xref>. We note that, there, and at odds with the case we studied here, correlations depend upon the stimulus since some parameters are stimulus-dependent.</p>
</sec><sec id="s3d">
<title>Quantitative comparisons among information theoretic measures</title>
<p>As mentioned in the introduction and in the previous section, earlier investigations which exhibit an improvement of the coding performance due to positive correlation find that the latter is rather limited quantitatively. Specifically, the Shannon information or the Fisher information (depending on the study) in the correlated population exceed that in the equivalent independent population by less than a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e235" xlink:type="simple"/></inline-formula>. As stated above, the Fisher information can be boosted by a factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e236" xlink:type="simple"/></inline-formula> as compared to its counterpart for a population of independent neurons; for typical choices of correlation values, this yields an improvement of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e237" xlink:type="simple"/></inline-formula>. By contrast, in the present study we claim that positive correlation can enhance coding fidelity by massive factors, and that this effect can exist even in small populations of neurons. But how are we to compare our results to earlier results, since the former are expressed in terms of error rate and capacity while the latter are expressed in terms of information measures?</p>
<p>In the case of an unbiased estimator, the Fisher information, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e238" xlink:type="simple"/></inline-formula>, bounds from below the discrimination error, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e239" xlink:type="simple"/></inline-formula>, of a continuously variable stimulus: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e240" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003970-Cover1">[51]</xref>. Thus, if the stimulus spans a space of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e241" xlink:type="simple"/></inline-formula> then the number of stimuli that can be distinguished reliably is calculated as<disp-formula id="pcbi.1003970.e242"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e242" xlink:type="simple"/><label>(16)</label></disp-formula>so that the capacity per neuron scales with the Fisher information as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e243" xlink:type="simple"/></inline-formula>. (A rigorous version of this result was derived for a population of independent neurons in Refs. <xref ref-type="bibr" rid="pcbi.1003970-Brunel1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1003970-Kang1">[53]</xref>.) If correlation enhances the Fisher information by a factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e244" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e245" xlink:type="simple"/></inline-formula>, then the number of distinguishable stimuli is correspondingly enhanced according to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e246" xlink:type="simple"/></inline-formula>. Thus, we have<disp-formula id="pcbi.1003970.e247"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e247" xlink:type="simple"/><label>(17)</label></disp-formula>and<disp-formula id="pcbi.1003970.e248"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e248" xlink:type="simple"/><label>(18)</label></disp-formula>or<disp-formula id="pcbi.1003970.e249"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e249" xlink:type="simple"/><label>(19)</label></disp-formula></p>
<p>We can now relate the earlier results in terms of Fisher information to our results in terms of capacity through these formulæ.</p>
<p>An enhancement of the Fisher information given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e250" xlink:type="simple"/></inline-formula> or, to be more specific, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e251" xlink:type="simple"/></inline-formula> as suggested by earlier theoretical studies, amounts to a small increase of the number of distinguishable stimuli by a factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e252" xlink:type="simple"/></inline-formula>. Similarly, the difference between correlated and independent capacity per neuron decays inversely proportionately with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e253" xlink:type="simple"/></inline-formula>; in a large population, the improvement becomes negligible. By contrast, we found that the ratio <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e254" xlink:type="simple"/></inline-formula> can attain large values (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e255" xlink:type="simple"/></inline-formula>, <xref ref-type="fig" rid="pcbi-1003970-g006">Fig. 6B</xref>) and that the difference between the correlated capacity per neuron, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e256" xlink:type="simple"/></inline-formula>, and the independent capacity per neuron, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e257" xlink:type="simple"/></inline-formula>, can be significant (<xref ref-type="fig" rid="pcbi-1003970-g006">Fig. 6D</xref>). In brief, earlier studies have demonstrated that, in spite of positive correlations, coding can be as efficient as in an independent population or even slightly better. Here, we show that, provided true population effects are taken into account, positive correlation can have a profound quantitative effect in that they can modulate the way coding measures scale with the number of neurons in the population and, as a result, yield a massive enhancement in coding fidelity.</p>
<p>To conclude the comparison among information measures, we note that, for continuous stimuli, the Fisher information is a natural performance metric. In this case, stimulus entropy always exceeds that of the population response, and the estimation variability decreases with population size, so that one is interested in quantifying the precision of estimation in the large-<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e258" xlink:type="simple"/></inline-formula> limit. By contrast, here we treat the case of a discrete stimulus, where the entropy is small and discrimination can be achieved with great reliability. This regime is clearly relevant to tasks like decision-making, language, and abstract thought: each categorization error imposes a cost on the organism, making it relevant to characterize coding performance using the error rate rather than the mutual information. Much of computational neuroscience work devoted to networks of neuron has focused upon large-<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e259" xlink:type="simple"/></inline-formula> situations. The regime at hand here is somewhat new in character: the largest number is not <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e260" xlink:type="simple"/></inline-formula>, the population size, but rather <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e261" xlink:type="simple"/></inline-formula>, the inverse discrimination error. In fact, a number of neurons as small as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e262" xlink:type="simple"/></inline-formula> can achieve inverse error rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e263" xlink:type="simple"/></inline-formula>, several orders of magnitude larger. Given the breadth and accuracy of cerebral function, and the brain's limited size, we expect this regime to be relevant to diverse instances of neural processing.</p>
</sec><sec id="s3e">
<title>Relation with recorded cortical data</title>
<p>A detailed analysis of neurophysiological data must await a subsequent study. Here, we mention several observations which are consistent with our experimental prediction. Patterns of correlations with stronger cross-pool values may at first seem unlikely; this intuition comes mainly from our knowledge of the primary visual cortex and area MT, in which neurons with similar orientation tuning or directional preference are more strongly correlated, on average. But recent results in the literature hint to the fact that inverse patterns of correlation, with stronger cross-pool values, may well be present in the brain and favorable to coding. Romo and colleagues have reported precisely this phenomenon in S2 cortex: in some fraction of their data (but not in others) they found positive correlation among pairs of neurons with opposite frequency-tuning curves <xref ref-type="bibr" rid="pcbi.1003970-Romo1">[32]</xref>. This pattern of correlation resulted in an improvement in the threshold for discrimination between different frequencies of tactile stimulation. Maynard et al. similarly found that a model that incorporated correlation reduced discrimination errors, as compared to an independent model, for groups of up to 16 cells in M1 during a reaching task <xref ref-type="bibr" rid="pcbi.1003970-Maynard1">[54]</xref>. Here, correlations elongated the response distributions precisely in the manner depicted in <xref ref-type="fig" rid="pcbi-1003970-g002">Fig. 2B</xref>. Interestingly, Cohen and Newsome observed that MT neurons with widely different direction preferences displayed stronger positive noise correlation when the discrimination task was designed in such a way that, effectively, they belonged to different stimulus-tuned pools <xref ref-type="bibr" rid="pcbi.1003970-Cohen1">[55]</xref>. In another cortical study, Poort and Roelfsema demonstrated that noise correlation can improve coding between V1 cells with different tuning, partially canceling its negative effect on cells with similar tuning <xref ref-type="bibr" rid="pcbi.1003970-Poort1">[56]</xref>. Finally, Gutnisky and Dragoi <xref ref-type="bibr" rid="pcbi.1003970-Gutnisky1">[57]</xref> observed that after rapid (400 ms) adaptation to a static grating, pairwise correlation coefficients among neurons with similar tuning decreased more than for neurons with somewhat different tuning preferences — a trend in adaptation which agrees with the proposed favorable pattern of correlation. However, we note that correlation among neurons with very different tuning preferences also dropped after adaptation, so that the trend may be mixed.</p>
</sec><sec id="s3f">
<title>Read-out and decoding from correlated neurons</title>
<p>In this paper, we have been concerned with establishing bounds on the information that can be extracted from a population of correlated neurons, by calculating the error rate of an optimal deterministic decoder and by estimating the encoding capacity of the population. A separate question is: How do actual, read-out neural circuits ‘decode’ the information contained in the activity of a correlated population? While this question is a very interesting one, which, quite generally, pertains to almost all studies of the neural code, it is also a difficult one because of a biological issue and a conceptual issue. The biological issue is that we don't yet know enough about the constraints that apply to decoding: the architecture of read-out circuits, the relevant biophysical properties of read-out neurons, etc. The conceptual issue is that we don't know in what form the information is decoded: even if, ultimately, the information is represented by some kind of ‘grand-mother cell’, the latter may result from many layers of processing. Thus, decoding circuits may be highly non-trivial.</p>
<p>There are many examples in the literature in which decoding is discussed in the context of a one- or two-layer perceptron-like read-out model. The motivation for such models is that they can be implemented accurately by the known, basic properties of neurons; hence, they make simple and likely candidates for actual read-out networks. Here, we illustrate a similar model devised as a decoder from a correlated population.</p>
<p>The read-out circuit ought to implement the optimal decision boundaries. We focus, first, on a two-pool model of correlated population. In the simplest case with symmetric parameters (<xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1</xref>), the decision boundary is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e264" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e265" xlink:type="simple"/></inline-formula> is the spike count in Pool <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e266" xlink:type="simple"/></inline-formula>. In the case of non-symmetric choices of parameters, the decision boundary becomes <disp-formula id="pcbi.1003970.e267"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e267" xlink:type="simple"/><label>(20)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e268" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e269" xlink:type="simple"/></inline-formula> are constants. In the presence of many stimuli, the decision boundaries between pairs of stimuli are given by Eq. (20) with different values of the constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e270" xlink:type="simple"/></inline-formula> for different stimulus pairs (<xref ref-type="fig" rid="pcbi-1003970-g008">Fig. 8A</xref>). (For stimulus-independent correlation, the constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e271" xlink:type="simple"/></inline-formula> is fixed.) Thus, if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e272" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e273" xlink:type="simple"/></inline-formula> correspond to two ‘neighboring’ decision boundaries, then the intervening stimulus is uniquely identifies if both inequalities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e274" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e275" xlink:type="simple"/></inline-formula> are satisfied (<xref ref-type="fig" rid="pcbi-1003970-g008">Fig. 8A</xref>). The task of a ‘decoder neuron’ is to be active when both these inequalities are satisfied and inactive otherwise: its activity then represents the presence of a given stimulus. This is achieved trivially by a two-layer perceptron in which excitatory and inhibitory inputs from Pool 1 and Pool 2 are summed non-linearly (<xref ref-type="fig" rid="pcbi-1003970-g008">Fig. 8B</xref>). The constants <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e276" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e277" xlink:type="simple"/></inline-formula> are implemented by the strengths of the synapses and the value of the perceptron threshold (equivalently, baseline), respectively.</p>
<fig id="pcbi-1003970-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g008</object-id><label>Figure 8</label><caption>
<title>Illustration of a proposed decoding mechanism and circuit.</title>
<p><bold>A.</bold> The decoding mechanism is illustrated in the case of a two-pool model, in which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e278" xlink:type="simple"/></inline-formula> denotes the spike count in Pool <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e279" xlink:type="simple"/></inline-formula>. The stimulus to be decoded elicits the distribution of activities represented by the yellow-red contour lines; other distributions, in blue-grey, flank it and result from different stimuli. Optimal decision boundaries (dashed lines), defined by simple inequalities, are implemented by the read-out circuit. <bold>B.</bold> The read-out circuit is a two-layer perceptron. In its first layer, excitatory and inhibitory inputs from both pools are non-linearly summed into two intermediary read-out neurons; the synaptic weights and thresholds (equivalently, baselines) are chosen such that the two intermediary neurons implement the inequalities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e280" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e281" xlink:type="simple"/></inline-formula>, respectively. Their two outputs are then summed non-linearly in turn, so that the ‘decoder neuron’ is active only if both inequalities are satisfied.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g008" position="float" xlink:type="simple"/></fig>
<p>In the case of a many-pool model of correlated population, the decoding rule is, conceptually, the same, but is calculationally more involved as it is carried out in a higher-dimensional space. In the case of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e282" xlink:type="simple"/></inline-formula> homogeneous pools of correlated neurons, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e283" xlink:type="simple"/></inline-formula> dimensions along which the probability distributions are ‘compressed’ (in our examples above, we had chosen <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e284" xlink:type="simple"/></inline-formula>), a given stimulus is identified by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e285" xlink:type="simple"/></inline-formula> pairs of inequalities analog to the above ones. In other words, to identify a given stimuli, the decoder has to carry out at most <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e286" xlink:type="simple"/></inline-formula> pairs of binary decisions.</p>
<p>A few comments are in order, here, about this model of decoding. First, we note that this simple perceptron read-out achieves optimal decoding, as it implements the optimal decision boundaries (up to processing noise). Second, we point out that the complexity of the proposed decoder is comparable to that of a decoder from independent neurons; thus, the presence of correlations does not render decoding more problematic. Third, we emphasize that, when reading out many stimuli from a given, correlated population, the decoder cells do not need to collect their inputs from different sub-divisions of the population, nor do different arrays of synaptic weights need be learned for each stimulus. Fourth, and finally, we mention that in the more realistic case of a heterogeneous neural population, an optimal decoder would have to implement a non-linear decision boundary (instead of the linear ones illustrated in <xref ref-type="fig" rid="pcbi-1003970-g008">Fig. 8A</xref>). As a result, the read-out circuit would be more involved. However, one might still be able to recover nearly optimal performance with simpler decoders if the heterogeneity is not too severe.</p>
</sec><sec id="s3g">
<title>Sensory coding requires extremely low error rates</title>
<p>Everyday vision occurs in a different regime than that probed in many of the classic studies in visual psychophysics. Our retina is presented with complicated scenes in rapid succession—either because of saccadic eye movements or because of motion in the scene itself—from an enormous set of possibilities. Often, we seek to recognize the presence of a target stimulus or stimulus class and distinguish it from every other possible stimulus. For example, we might want to recognize a friend's face in a particular spatial location. That location might contain another person's face, or a flower, or myriad other objects, which we do not want to mistake for our friend's face. Alternatively, the target stimulus is often a class of related stimuli, such as that friend's face from a variety of angles or the presence of any human face, so that a class of visual patterns on the retina, rather than a single fixed pattern, is to be identified.</p>
<p>In this regime, one distinguishes two kinds of coding error: <italic>misses</italic> and <italic>false alarms</italic>. In the former, one does not pick up on the target stimulus; in the latter, an absent target stimulus is erroneously perceived. While both kinds of error take place occasionally (think of mistaking a wavy tree branch for a snake, as a false alarm), the effortless feat of the visual system in avoiding them most of the time is rather bewildering. If we pause a moment on what this feat means at the neural level, as illustrated by the following example, we realize that it requires extremely precise coding.</p>
<p>Imagine stretching out on your hotel bed in a tropical country. If there were a very large spider on the ceiling, you most likely would want to detect it and detect it promptly. For the sake of concreteness, let us imagine that the spider has a size of three centimeters and is three meters away, subtending a visual angle of 0.01 radians. Thus, there are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e287" xlink:type="simple"/></inline-formula> possible spider locations on the ceiling. If you are able to detect the spider in any of these locations, it implies that your brain must effectively have a ‘spider-detector’ circuit that reads out activity from a retinal population that subtends each of these spatial locations. If you would like to detect the spider quickly, say in 100 milliseconds, then there are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e288" xlink:type="simple"/></inline-formula> possible spider-detection events per second. Now, if each detector operates at a false alarm rate that would naively seem low enough to be acceptable, say 0.001—i.e., a probability of error of a tenth of a percent— you would still perceive 100 virtual spiders per second! If we impose the additonal cautionary constraint that spider detection be possible only within the parafoveal region, which covers about 0.1 radians, the numbers would be further divided by a factor of 100, but this would still correspond to perceiving about 1 virtual spider per second. While we do not wish to insist too heavily on a quantitative argument, we want to show that it is not implausible that, even in our everyday experience, the brain may need to encode sensory signals with exceedingly low error probabilities.</p>
<p>One can think of a number of resolutions to this ‘spider-on-the-wall problem’ (changing hotel rooms will not do). Temporal integration, for one, may be used to suppress errors. Also, error rates ought to be influenced by the prior expectation of an event—a quantity we have not included explicitly in our argument. That said, both temporal integration and prior expectation involve trade-offs. Extensive temporal integration requires longer viewing times, and many behaviors need to occur quickly. Relying too heavily upon prior expectation could leave one unable to recognize novel objects.</p>
<p>A more direct way of ensuring reliable discrimination is to employ neural populations that are organized to suppress false alarm (and miss) rates down to extremely low values. In the present paper, we focus on this strategy. As an illustration of the stringency of the requirement, imagine that no more than one virtual spider ought to be perceived in the hour it takes you to fall asleep (as such spider detections could prevent sleep). This condition is satisfied if the false alarm rate remains below <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e289" xlink:type="simple"/></inline-formula> per detection circuit. And of course, the visual system can recognize many objects other than spiders, implying even lower false alarm rates in any one kind of detector so that the total false alarm rate remain very low.</p>
</sec><sec id="s3h">
<title>Other strategies for low-error coding</title>
<p>As was have just explained, infinitesimal error is not a luxury, but a necessity in rapid coding if one wishes to avoid relatively frequent false alarms. We have shown here how correlations can enable population codes to perform with negligible error rates. However, other possible strategies for reducing false alarm errors exist: temporal integration and prior expectation. Both strategies effectively involve raising the detection threshold to suppress the false alarm rate. But both strategies involve trade-offs as well.</p>
<p>First, most stimuli in natural settings are present over periods of time longer than a few tens of milliseconds. Thus, in rapid coding a miss can be corrected: for a miss rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e290" xlink:type="simple"/></inline-formula> in a fundamental time window of 20 ms, a stimulus present during a period of 200 ms allows <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e291" xlink:type="simple"/></inline-formula> opportunities of detection. These multiple opportunities of detection reduce the overall miss rate to roughly <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e292" xlink:type="simple"/></inline-formula>, a <italic>much</italic> smaller quantity. However, the consequence is that the false alarm rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e293" xlink:type="simple"/></inline-formula> is the short time window, increases to roughly <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e294" xlink:type="simple"/></inline-formula> (assuming <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e295" xlink:type="simple"/></inline-formula>) in the long time window. This imbalance can be corrected by raising the detection threshold, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e296" xlink:type="simple"/></inline-formula> (with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e297" xlink:type="simple"/></inline-formula> instead of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e298" xlink:type="simple"/></inline-formula>), so that the false alarm rate goes down for detection in each fundamental time window. Because the false alarm rate is suppressed exponentially by raising the threshold, but only increased linearly by allowing detection in several successive time bins, such a strategy can be favorable. For instance, in the case of the <italic>independent</italic> code in <xref ref-type="fig" rid="pcbi-1003970-g003">Fig. 3</xref>, if the threshold is raised to boost the miss rate to about 10% (which corresponds to an increase by a factor of 53), then the false alarm rate is reduced from about 0.1% down to 0.0001% (which corresponds to a suppression by a factor of 850). The obvious cost of this strategy is that the presence of new objects in the visual world will be noted slowly, and if there are important objects that require rapid detection this delay and variability in detection may be unfavorable.</p>
<p>Second, prior expectation can modulate the balance between misses and false alarms in a favorable manner. The miss rate and the false alarm rate are weighed by the frequency of occurrence of stimuli, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e299" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e300" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). In practice, these quantities are not known and must be estimated by a freely behaving animal. Changing their values amounts to weighing the two kinds of error—misses and false alarms—by their expectation with regards to the occurrence of stimuli. Mathematically, this is equivalent to weighing miss and false alarm rates as a function of the costs associated with them. Thus, the effects of expectation and cost can both be subsumed in the choice of the decoding boundary, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e301" xlink:type="simple"/></inline-formula>. If the boundary is displaced toward the distribution corresponding to Target, then the miss rate increases while the false alarm rate decreases. The reverse occurs if the boundary is displaced toward the distribution corresponding to Distracter. Therefore, an object expected to be incredibly unlikely in a given environment can have its detection threshold raised substantially to prevent unwanted false alarms.</p>
<p>This strategy has the obvious drawback that if the rare object <italic>is</italic> actually present, it will be detected with difficulty. A behaving animal continually updates its internal representations of expectation and cost as a function of experience — a strategy often referred to as Bayesian decision-making. In a new overall visual context, an otherwise rare object may be more likely present, and the animal may consequently lower its detection threshold and, hence, render that object more easily visible. In addition, temporal integration can enhance the detectability of unexpected objects, thus helping to overcome a high detection threshold. But of course, both these methods require more time, so that they will not be effective for rapid detection. Furthermore, there are limits as to how high the miss rate can be allowed to increase without adverse behavioral consequences, which places limits on how effective these strategies can be in achieving very low false alarm rates.</p>
<p>For all these reasons, it is likely that these strategies are combined with population codes having intrinsically low error. In fact, the suppression of the false alarm rate by raising the threshold is much more effective if the distributions of neural activity are already well separated: in the example of the <italic>correlated</italic> code in <xref ref-type="fig" rid="pcbi-1003970-g003">Fig. 3</xref>, increasing the miss rate to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e302" xlink:type="simple"/></inline-formula> reduces the false alarm rate by another factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e303" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Maximum likelihood error bound</title>
<p>In the absence of detailed knowledge about the decoding algorithm employed by readout neurons, we can still establish a bound on performance. This bound is derived from maximum likelihood decoding—an algorithm that minimizes the error rate of deterministic decoding <xref ref-type="bibr" rid="pcbi.1003970-Cover1">[51]</xref>. It assigns Target to a response pattern, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e304" xlink:type="simple"/></inline-formula>, if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e305" xlink:type="simple"/></inline-formula> and, conversely, it assigns Distracter to a response pattern, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e306" xlink:type="simple"/></inline-formula>, if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e307" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e308" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e309" xlink:type="simple"/></inline-formula> denote the probability that Target and Distracter, respectively, were presented given that the response pattern is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e310" xlink:type="simple"/></inline-formula>. The <italic>miss rate</italic>—the fraction of instances in which Distracter is mistaken for Target—is then calculated as <disp-formula id="pcbi.1003970.e311"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e311" xlink:type="simple"/><label>(21)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e312" xlink:type="simple"/></inline-formula> is the probability to record a response pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e313" xlink:type="simple"/></inline-formula> (regardless of the stimulus presented). Similarly, the <italic>false alarm rate</italic>—the fraction of instances in which Target is mistaken for Distracter—is calculated as<disp-formula id="pcbi.1003970.e314"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e314" xlink:type="simple"/><label>(22)</label></disp-formula></p>
<p>The <italic>total error rate</italic> committed by maximum likelihood decoding,<disp-formula id="pcbi.1003970.e315"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e315" xlink:type="simple"/><label>(23)</label></disp-formula>is a lower bound to the error rate committed by any deterministic decoder. Readout neurons make at least <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e316" xlink:type="simple"/></inline-formula> errors per unit time. Throughout, we use the error rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e317" xlink:type="simple"/></inline-formula>, as a measure of the fidelity of the neural population to contrast the coding performance of independent neural populations <italic>versus</italic> correlated neural populations.</p>
<p>Since experiments record the rate of occurrence of neural responses given the stimuli, namely the probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e318" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e319" xlink:type="simple"/></inline-formula>, and not the other way around, it is often advantageous to express the miss and false alarm rates in terms of these measurable quantities, as<disp-formula id="pcbi.1003970.e320"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e320" xlink:type="simple"/><label>(24)</label></disp-formula>and<disp-formula id="pcbi.1003970.e321"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e321" xlink:type="simple"/><label>(25)</label></disp-formula></p>
<p>In the laboratory, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e322" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e323" xlink:type="simple"/></inline-formula> are controlled by the experimenter; in natural situations, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e324" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e325" xlink:type="simple"/></inline-formula> can be thought of as the subject's expectation of the chances of occurrence of the respective stimuli.</p>
<p>In general misses and false alarms are not symmetric, as they represent different kinds of errors. In some situations, one may wish to limit the rate of false alarms more stringently than that of misses, or <italic>vice versa</italic>. A convenient way to impose such a condition is to introduce a threshold, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e326" xlink:type="simple"/></inline-formula>, greater or smaller than one, when comparing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e327" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e328" xlink:type="simple"/></inline-formula>, and consequently to generalize the error rates to<disp-formula id="pcbi.1003970.e329"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e329" xlink:type="simple"/><label>(26)</label></disp-formula><disp-formula id="pcbi.1003970.e330"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e330" xlink:type="simple"/><label>(27)</label></disp-formula></p>
<p>We discuss the asymmetry between misses and false alarms, and the corresponding role of the threshold, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e331" xlink:type="simple"/></inline-formula>, in <xref ref-type="sec" rid="s3">Discussion</xref>.</p>
</sec><sec id="s4b">
<title>Definitions of ‘macroscopic’ and ‘microscopic’ correlations</title>
<p>We consider a neural population divided into <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e332" xlink:type="simple"/></inline-formula> homogeneous pools, labeled by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e333" xlink:type="simple"/></inline-formula>, and we call <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e334" xlink:type="simple"/></inline-formula> the number of spikes fired in Pool <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e335" xlink:type="simple"/></inline-formula> in a given time bin. The ‘macroscopic’ correlation among pools, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e336" xlink:type="simple"/></inline-formula>, is defined as<disp-formula id="pcbi.1003970.e337"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e337" xlink:type="simple"/><label>(28)</label></disp-formula></p>
<p>The ‘microscopic’ variable which characterizes the state of the neural population is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e338" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e339" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e340" xlink:type="simple"/></inline-formula>depending upon whether the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e341" xlink:type="simple"/></inline-formula>th neuron in Pool <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e342" xlink:type="simple"/></inline-formula> is silent or fires a spike, respectively. The ‘microscopic’ correlation between neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e343" xlink:type="simple"/></inline-formula> in Pool <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e344" xlink:type="simple"/></inline-formula> and neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e345" xlink:type="simple"/></inline-formula> in Pool <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e346" xlink:type="simple"/></inline-formula> is then defined as<disp-formula id="pcbi.1003970.e347"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e347" xlink:type="simple"/><label>(29)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e348" xlink:type="simple"/></inline-formula> is the firing rate in Pool <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e349" xlink:type="simple"/></inline-formula>.</p>
<p>Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e350" xlink:type="simple"/></inline-formula>, the ‘macroscopic’ correlations are related to the ‘microscopic’ correlations according to<disp-formula id="pcbi.1003970.e351"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e351" xlink:type="simple"/><label>(30)</label></disp-formula><disp-formula id="pcbi.1003970.e352"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e352" xlink:type="simple"/><label>(31)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e353" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e354" xlink:type="simple"/></inline-formula> is the total number of neurons in the population and where we have assumed that all pools have the same size. Hence the identity between Eqs. (5) and (8).</p>
</sec><sec id="s4c">
<title>2-Pool model of correlated neurons: Coding error—numerical treatment</title>
<p>The numerical procedure begins by dividing a population with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e355" xlink:type="simple"/></inline-formula> neurons into two homogeneous pools with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e356" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e357" xlink:type="simple"/></inline-formula> neurons respectively. The maximum entropy distribution over the microscopic variables <xref ref-type="bibr" rid="pcbi.1003970-Schneidman1">[47]</xref>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e358" xlink:type="simple"/></inline-formula>, induces a distribution over the spike counts in each pool, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e359" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e360" xlink:type="simple"/></inline-formula>, which takes the form<disp-formula id="pcbi.1003970.e361"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e361" xlink:type="simple"/><label>(32)</label></disp-formula>where<disp-formula id="pcbi.1003970.e362"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e362" xlink:type="simple"/><label>(33)</label></disp-formula>and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e363" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e364" xlink:type="simple"/></inline-formula> (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e365" xlink:type="simple"/></inline-formula> labels the identity of the stimulus). The combinatorial prefactors appear, above, because we consider here the maximum entropy distribution of the microscopic variables (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e366" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e367" xlink:type="simple"/></inline-formula>and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e368" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e369" xlink:type="simple"/></inline-formula>and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e370" xlink:type="simple"/></inline-formula>, the spiking output of each neuron), rather than the distribution of population variables (i.e., of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e371" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e372" xlink:type="simple"/></inline-formula>, the spiking output in each pool). Thus, the five parameters, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e373" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e374" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e375" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e376" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e377" xlink:type="simple"/></inline-formula>, are found by direct numerical solution, such that the firing rates of individual neurons in each other the two pools, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e378" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e379" xlink:type="simple"/></inline-formula>, and the normalized pairwise correlations, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e380" xlink:type="simple"/></inline-formula> (within Pool 1), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e381" xlink:type="simple"/></inline-formula> (within Pool 2), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e382" xlink:type="simple"/></inline-formula> (across Pools 1 and 2), take given values. (Throughout, we borrow symmetric choices (<xref ref-type="fig" rid="pcbi-1003970-g002">Fig. 2A</xref>). That is, in response to Target the firing rates are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e383" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e384" xlink:type="simple"/></inline-formula> in Pools 1 and 2 respectively, while in response to Distracter the firing rates are swapped, i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e385" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e386" xlink:type="simple"/></inline-formula>, in Pools 1 and 2 respectively. The same holds for the correlation values <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e387" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e388" xlink:type="simple"/></inline-formula>.) After finding the maximum entropy distribution corresponding to a given choice of firing rates and pairwise correlations, we used maximum likelihood decoding (described above) to define errors. Specifically, we evaluated Eqs. (24) and (25) for every value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e389" xlink:type="simple"/></inline-formula> using a threshold of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e390" xlink:type="simple"/></inline-formula> for minimum total error. Thus, our calculation of total error was exact with no approximation made to the decoder's decision boundary.</p>
<p>For the case of a fully heterogeneous population, all of the firing rates and pairwise correlations were randomly perturbed from their homogenous values. For a cell with firing probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e391" xlink:type="simple"/></inline-formula>, we set its new firing probability to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e392" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e393" xlink:type="simple"/></inline-formula> is a Gaussian random variable with vanishing mean and variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e394" xlink:type="simple"/></inline-formula>. Similarly, for each cell pair with correlation coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e395" xlink:type="simple"/></inline-formula>, we set its new correlation to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e396" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e397" xlink:type="simple"/></inline-formula> is also a Gaussian random variable with vanishing mean and variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e398" xlink:type="simple"/></inline-formula>. Thus, random instantiations of firing rates and correlations had, on average, the same mean as the matched homogeneous population and a standard deviation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e399" xlink:type="simple"/></inline-formula>, measured as a percentage of the original value. Next, we solved numerically for the pairwise maximum entropy model consistent with the specified firing probabilities and pairwise correlation coefficients. If we denote the activity state of the population by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e400" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e401" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e402" xlink:type="simple"/></inline-formula> is the activity state of cell <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e403" xlink:type="simple"/></inline-formula>, the energy of the full pairwise maximum entropy model reads<disp-formula id="pcbi.1003970.e404"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e404" xlink:type="simple"/><label>(34)</label></disp-formula></p>
<p>Because the population size was small (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e405" xlink:type="simple"/></inline-formula>), we were able to relate the parameters of the maximum entropy model, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e406" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e407" xlink:type="simple"/></inline-formula>, to the firing rates and pairwise correlations, using exact numerical integration over all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e408" xlink:type="simple"/></inline-formula> activity states rather than approximating this integral using Monte Carlo methods. Error rates were obtained from maximum likelihood decoding, with the use of the exact decision boundary over all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e409" xlink:type="simple"/></inline-formula> activity states. Clearly, the error rate depended upon the specific random instantiation of firing probabilities and pairwise correlations. In <xref ref-type="fig" rid="pcbi-1003970-g004">Figs. 4A and B</xref>, we show the error rate for 300 random instantiations of heterogeneous populations; in <xref ref-type="fig" rid="pcbi-1003970-g004">Fig. 4C</xref>, we plot the average error rate over all 300 random instantiations along with the standard deviation as an error bar.</p>
<p>The choice of maximum entropy distributions is a reasonable one for establishing upper bounds on the error rate, as these distributions are ‘as spread out as possible’ given the constraints on firing rates and correlations. Strictly speaking, true bounds are obtained from minimum mutual information distributions, but we expect the results to be close to those obtained from maximum entropy distributions. This expectation is substantiated by the results obtained from Gaussian approximations—see the remarks at the end of the next section.</p>
</sec><sec id="s4d">
<title>2-Pool model of correlated neurons: Coding error—Gaussian approximation</title>
<p>We consider a 2-Pool population with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e410" xlink:type="simple"/></inline-formula> neurons. For the sake of simplicity, we focus on a symmetric case with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e411" xlink:type="simple"/></inline-formula> neurons in each pool, firing rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e412" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e413" xlink:type="simple"/></inline-formula> in response to Target and Distracter, respectively, in Pool 1, and vice versa firing rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e414" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e415" xlink:type="simple"/></inline-formula> in response to Target and Distracter, respectively, in Pool 2. For the sake of simplicity, also, we specify the calculation to the symmetric case with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e416" xlink:type="simple"/></inline-formula>, the within-pool correlation coefficients, but the calculation runs along similar lines for more general cases. The pairwise correlation across the two pools is denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e417" xlink:type="simple"/></inline-formula>. With these hypotheses, a Gaussian approximation to the probability of response to Target reads <disp-formula id="pcbi.1003970.e418"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e418" xlink:type="simple"/><label>(35)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e419" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e420" xlink:type="simple"/></inline-formula> are the spike counts in Pools 1 and 2 respectively. Here, we use the vector notation with<disp-formula id="pcbi.1003970.e421"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e421" xlink:type="simple"/><label>(36)</label></disp-formula><disp-formula id="pcbi.1003970.e422"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e422" xlink:type="simple"/><label>(37)</label></disp-formula><disp-formula id="pcbi.1003970.e423"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e423" xlink:type="simple"/><label>(38)</label></disp-formula>and the covariance matrix<disp-formula id="pcbi.1003970.e424"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e424" xlink:type="simple"/><label>(39)</label></disp-formula></p>
<p>A similar expression approximates the probability of response to Distracter, but with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e425" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e426" xlink:type="simple"/></inline-formula> swapped. (The firing rates depend upon the stimulus, but the correlations do not.) For calculational ease, we give a name to the inverse covariance matrix:<disp-formula id="pcbi.1003970.e427"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e427" xlink:type="simple"/><label>(40)</label></disp-formula></p>
<p>We calculate the probability of error by integrating the tails of the two distributions, corresponding to the two stimuli, as delineated by the maximum likelihood boundary. For the rather symmetric choice of parameters with which we are concerned here, the maximum likelihood boundary in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e428" xlink:type="simple"/></inline-formula>-plane is given by the condition<disp-formula id="pcbi.1003970.e429"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e429" xlink:type="simple"/><label>(41)</label></disp-formula></p>
<p>Thus, the maximum likelihood lies along the diagonal in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e430" xlink:type="simple"/></inline-formula>-plane; however, the tail of the distribution to be integrated over (in order to obtain the maximum likelihood error) switches from one side of this boundary to the other when the first factor changes sign. What is going on, here, is easy to understand if one considers the angles along which the elongated axes of the distributions are aligned (see Eq. (62), below, for an analytical expression). If the two angles corresponding to the two distributions are not equal, then the two distributions (i.e., their long axes) are not parallel, and ‘they will cross’; at that ‘crossing point’, the maximum likelihood condition switches sign. For several reasons, however, we can safely ignore this complication in the calculation. First, for all cases in which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e431" xlink:type="simple"/></inline-formula>, the sign switch occurs for an unphysical negative value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e432" xlink:type="simple"/></inline-formula>; and, indeed, all the examples illustrated in this paper obey the inequality <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e433" xlink:type="simple"/></inline-formula> as one would expect for sparse neural responses. Second, we are interested in cases in which the two distributions of neural activity have similar means, and in this case the two elongated distributions in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e434" xlink:type="simple"/></inline-formula>-plane are nearly parallel. Indeed, the deviation from a parallel scenario occurs because the firing rates of neurons in response to two stimuli are different (as, otherwise, their correlations do not depend upon the stimulus); this is what yields the stimulus-dependence of the angle of the macroscopic distributions in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e435" xlink:type="simple"/></inline-formula>-plane. If their means are close, then the distributions are nearly parallel. Finally, in practice, distributions ‘cross’ in any significant way in cases in which they are broad or correlations are unfavorable.</p>
<p>For the remainder of the calculation, it is convenient to parametrize the plane of neural activities in the two pools in coordinates, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e436" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e437" xlink:type="simple"/></inline-formula>, which take the point of maximum equiprobability, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e438" xlink:type="simple"/></inline-formula>, as origin and lie along the maximum likelihood boundary and the orthogonal direction, respectively. Specifically, we set<disp-formula id="pcbi.1003970.e439"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e439" xlink:type="simple"/><label>(42)</label></disp-formula><disp-formula id="pcbi.1003970.e440"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e440" xlink:type="simple"/><label>(43)</label></disp-formula></p>
<p>The error rate is then obtained the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e441" xlink:type="simple"/></inline-formula>-dimensional integral of the probability distribution, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e442" xlink:type="simple"/></inline-formula> ranging from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e443" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e444" xlink:type="simple"/></inline-formula> (so that we include a small overestimate that comes from unphysical negative values of the spike counts) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e445" xlink:type="simple"/></inline-formula> ranging from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e446" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e447" xlink:type="simple"/></inline-formula>. (In order to calculate the total error, we have to take into account both misses and false alarms, i.e., the ‘two tails’ on the two sides of the maximum likelihood boundary. But we also have to normalize this result by the stimulus probability, i.e., by a factor of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e448" xlink:type="simple"/></inline-formula>.) Thus, <disp-formula id="pcbi.1003970.e449"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e449" xlink:type="simple"/><label>(44)</label></disp-formula></p>
<p>The probability distribution can be written in terms of the new variables, as<disp-formula id="pcbi.1003970.e450"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e450" xlink:type="simple"/><label>(45)</label></disp-formula>with<disp-formula id="pcbi.1003970.e451"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e451" xlink:type="simple"/><label>(46)</label></disp-formula><disp-formula id="pcbi.1003970.e452"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e452" xlink:type="simple"/><label>(47)</label></disp-formula><disp-formula id="pcbi.1003970.e453"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e453" xlink:type="simple"/><label>(48)</label></disp-formula><disp-formula id="pcbi.1003970.e454"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e454" xlink:type="simple"/><label>(49)</label></disp-formula><disp-formula id="pcbi.1003970.e455"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e455" xlink:type="simple"/><label>(50)</label></disp-formula><disp-formula id="pcbi.1003970.e456"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e456" xlink:type="simple"/><label>(51)</label></disp-formula>where we have used the shorthand<disp-formula id="pcbi.1003970.e457"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e457" xlink:type="simple"/><label>(52)</label></disp-formula><disp-formula id="pcbi.1003970.e458"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e458" xlink:type="simple"/><label>(53)</label></disp-formula></p>
<p>Performing the Gaussian integral over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e459" xlink:type="simple"/></inline-formula>, we obtain<disp-formula id="pcbi.1003970.e460"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e460" xlink:type="simple"/><label>(54)</label></disp-formula></p>
<p>Finally, this integral can be immediately rewritten as a complementary error function which, in turn, can be expanded:<disp-formula id="pcbi.1003970.e461"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e461" xlink:type="simple"/><label>(55)</label></disp-formula>where we have defined<disp-formula id="pcbi.1003970.e462"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e462" xlink:type="simple"/><label>(56)</label></disp-formula></p>
<p>Finally, keeping only the dominant term and simplifying the expression, we compute the error according to<disp-formula id="pcbi.1003970.e463"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e463" xlink:type="simple"/><label>(57)</label></disp-formula></p>
<p>We obtain Eq. (1), (2), and (3) when we replace <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e464" xlink:type="simple"/></inline-formula> and Det<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e465" xlink:type="simple"/></inline-formula> by their expressions in terms of firing rates and correlation coefficients.</p>
<p>We note that, above, we have simply integrated the tails of the distributions as delineated by the maximum likelihood bound. In simple (symmetric) cases, this can be recast as a linear estimation problem, and the error rate can be related to the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e466" xlink:type="simple"/></inline-formula>- (or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e467" xlink:type="simple"/></inline-formula>-) score. Furthermore, the term appearing in the argument of the exponential is closely related to the linear Fisher information, and can be intuited as such.</p>
<p>We emphasize the agreement between the numerical and the analytical results (dots versus solid lines in <xref ref-type="fig" rid="pcbi-1003970-g002">Figs. 2A-D</xref> and <xref ref-type="fig" rid="pcbi-1003970-g003">Figs. 3A and C</xref>), which is not to be expected in general and is encouraging here. Indeed, numerical results are derived by making use of maximum entropy distributions. These are as broad as the constraints on firing rates of individual neurons and pairwise correlations allow, yet when expressed in terms of spike counts their tails fall off more rapidly than Gaussian tails. Estimations of the error rate from maximum entropy distributions and from Gaussian distributions coincide. We recall that the maximum likelihood error is dominated by the height of the distributions at equiprobability. So the quantitative similarity between numerical and Gaussian results means that, even for very stringent error thresholds, the asymptotic behavior of the tails does not play a dominant role.</p>
</sec><sec id="s4e">
<title>Robustness of high-fidelity coding with respect to parameter variations</title>
<p>High-fidelity coding results from the suppression of overlap among response probability distributions corresponding to different stimuli. By tuning one combination of the correlation parameters, distributions become thin (<italic>i.e.</italic>, favorable), and we have demonstrated that this can occur for realistic values of the correlations. But even in the singular limit of infinitely thin (<italic>i.e.</italic>, locked-in) distributions, independent parameters are left free, namely, the orientations of the principal axes of the distributions or, equivalently, the angles along which the elongated distributions lie in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e468" xlink:type="simple"/></inline-formula> plane. We have denoted this angle by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e469" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1B</xref>). An important question is whether these parameters have to be fine-tuned for high-fidelity coding. We show, here, that no fine-tuning is necessary: high-fidelity coding operates over a wide range of parameter choices (<xref ref-type="fig" rid="pcbi-1003970-g009">Fig. 9</xref>).</p>
<fig id="pcbi-1003970-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003970.g009</object-id><label>Figure 9</label><caption>
<title>Robustness to parameter variations.</title>
<p><bold>A.</bold> Probability of error as a function of the cross-pool correlation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e470" xlink:type="simple"/></inline-formula> for populations with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e471" xlink:type="simple"/></inline-formula> neurons and different angles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e472" xlink:type="simple"/></inline-formula> of their probability distributions in the space of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e473" xlink:type="simple"/></inline-formula>; parameters are (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e474" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e475" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e476" xlink:type="simple"/></inline-formula>) with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e477" xlink:type="simple"/></inline-formula> set to give the chosen angle (Eq. (62)). <bold>B.</bold> Probability of error as a function of angle for fixed difference in spike count, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e478" xlink:type="simple"/></inline-formula>, intersects the error criterion <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e479" xlink:type="simple"/></inline-formula> at two angles, which defines the angular bandwidth. <bold>C.</bold> Angular bandwidth plotted as a function of within pool correlation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e480" xlink:type="simple"/></inline-formula>, for different values of the difference in spike count, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e481" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003970.g009" position="float" xlink:type="simple"/></fig>
<p>Consider, for example, the dependence of the error rate upon the cross-pool correlation strength, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e482" xlink:type="simple"/></inline-formula>, for several choices of the angle <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e483" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003970-g009">Fig. 9A</xref>). Clearly, when the two distributions corresponding to Target and Distracter are elongated along the same direction (here the diagonal, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e484" xlink:type="simple"/></inline-formula>, because of our choice of symmetric parameters), the error rate plunges down to vanishing numbers for appropriate correlation values. If the two distributions are not parallel, there always remains some overlap, even if they are infinitely thin. However, this overlap is so small that, even when the angle differs from the diagonal by as much as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e485" xlink:type="simple"/></inline-formula>, the error rate is suppressed by more than ten orders of magnitude (<xref ref-type="fig" rid="pcbi-1003970-g009">Fig. 9A</xref>).</p>
<p>In order to explore the parameter dependence of the error rate, we set a (small) ‘error rate threshold’, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e486" xlink:type="simple"/></inline-formula>, not to be exceeded. The closer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e487" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e488" xlink:type="simple"/></inline-formula> are, <italic>i.e.</italic>, the more similar the mean responses to Target and the response to Distracter, then the more stringent becomes the threshold condition, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e489" xlink:type="simple"/></inline-formula>, upon the parameters of the model. An arbitrary threshold—here, we choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e490" xlink:type="simple"/></inline-formula>—defines a corresponding ‘angle bandwidth’: a range of distribution angles, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e491" xlink:type="simple"/></inline-formula>, within which the error rate remains below threshold (<xref ref-type="fig" rid="pcbi-1003970-g009">Fig. 9B</xref>). We selected the value of the error threshold to be sufficiently low that networks within the angle bandwidth contribute fewer than a single error per human lifetime. Clearly, the angle bandwidth depends upon all other model parameters. The closer the firing rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e492" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e493" xlink:type="simple"/></inline-formula> in response to Target and Distracter respectively, the closer the two distributions lie and, hence, the more precisely their angle has to be tuned for error rate suppression. Yet, even when the average activities in the two pools differ by as little as two to five spikes, the angle bandwidth remains as large as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e494" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e495" xlink:type="simple"/></inline-formula> over a wide range of correlation values (<xref ref-type="fig" rid="pcbi-1003970-g009">Figs. 9B and C</xref>). Thus, error rate suppression is robust to small parameter variations.</p>
</sec><sec id="s4f">
<title>Arguments for lock-in beyond a Gaussian approximation</title>
<p>Here, we present general arguments on the role of correlation in high-fidelity coding, which do not rely on a Gaussian approximation of probability distributions. We assume only that the probability distributions of spike counts in response to Target and Distracter are ‘well-behaved’; specifically, that they each have a single maximum and that their tails decay rapidly enough. Then the knowledge of the correlation structure is sufficient to discuss the degree of their overlap and, hence, the coding error rate. For the sake of simplicity we still consider a 2-Pool model, but our arguments can be transposed to the general case of a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e496" xlink:type="simple"/></inline-formula>-Pool model.</p>
<p>We start by examining the quantity<disp-formula id="pcbi.1003970.e497"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e497" xlink:type="simple"/><label>(58)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e498" xlink:type="simple"/></inline-formula> is a unit vector along the direction given by the angle <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e499" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e500" xlink:type="simple"/></inline-formula> is the vector of spike counts. This quantity is calculated as<disp-formula id="pcbi.1003970.e501"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e501" xlink:type="simple"/><label>(59)</label></disp-formula><italic>i.e.</italic>, it is the variance along the direction prescribed by the unit vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e502" xlink:type="simple"/></inline-formula> in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e503" xlink:type="simple"/></inline-formula>-plane of spike counts. Optimizing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e504" xlink:type="simple"/></inline-formula> with respect to the rotation angle, we find that it reaches its minimal and maximal values,<disp-formula id="pcbi.1003970.e505"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e505" xlink:type="simple"/><label>(60)</label></disp-formula>along the two orthogonal angles given by<disp-formula id="pcbi.1003970.e506"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e506" xlink:type="simple"/><label>(61)</label></disp-formula></p>
<p>This expression can also be written in terms of the microscopic correlations as<disp-formula id="pcbi.1003970.e507"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e507" xlink:type="simple"/><label>(62)</label></disp-formula></p>
<p>For positive correlation, the angle along which the distribution elongates, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e508" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003970-g001">Fig. 1B</xref>), lies between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e509" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e510" xlink:type="simple"/></inline-formula>. The other solution of this equation lies at right angle with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e511" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e512" xlink:type="simple"/></inline-formula>, and defines the direction of ‘probability compression’. The quantities that govern overlap suppression are the small variances, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e513" xlink:type="simple"/></inline-formula>, and the angles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e514" xlink:type="simple"/></inline-formula>, for each of the two distributions corresponding to Target and Distracter. The error rates decrease with smaller <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e515" xlink:type="simple"/></inline-formula> and more parallel distributions.</p>
<p>The positivity of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e516" xlink:type="simple"/></inline-formula> implies a constraint upon the values of the macroscopic correlations: <disp-formula id="pcbi.1003970.e517"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e517" xlink:type="simple"/><label>(63)</label></disp-formula></p>
<p>In terms of the microscopic correlations, the inequality reads<disp-formula id="pcbi.1003970.e518"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e518" xlink:type="simple"/><label>(64)</label></disp-formula></p>
<p>This condition amounts to the positivity of probability. When equality is achieved, the corresponding probability distribution becomes infinitely thin along one direction, <italic>i.e.</italic>, the probability of any state in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e519" xlink:type="simple"/></inline-formula>-plane away from this line vanishes. When equality is achieved, we say that the neural population is ‘<italic>locked-in</italic>’; in this case, the coding error rate can vanish. When correlation values are such that the inequality is satisfied, and hence the coding error rate can be massively suppressed, we refer to the pattern of correlation as ‘<italic>favorable</italic>’.</p>
<p>We note in passing that a vanishing error in the Gaussian approximation, <italic>i.e.</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e520" xlink:type="simple"/></inline-formula> (see Eq. (2)), corresponds to two ‘infinitely thin’ probability distributions whose directions of largest variance are parallel. Indeed, the condition <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e521" xlink:type="simple"/></inline-formula>, which occurs when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e522" xlink:type="simple"/></inline-formula>, together with the condition <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e523" xlink:type="simple"/></inline-formula> (see Eq. (61) above) imply<disp-formula id="pcbi.1003970.e524"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e524" xlink:type="simple"/><label>(65)</label></disp-formula><disp-formula id="pcbi.1003970.e525"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e525" xlink:type="simple"/><label>(66)</label></disp-formula><italic>i.e.</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e526" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4g">
<title><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e527" xlink:type="simple"/></inline-formula>-Pool model of independent neurons: Coding capacity</title>
<p>For an estimate of the coding capacity of a population of independent neurons, we approximate the spike count distribution by a Gaussian with appropriate mean and variance. In the 1-Pool case with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e528" xlink:type="simple"/></inline-formula> neurons, this distribution reads<disp-formula id="pcbi.1003970.e529"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e529" xlink:type="simple"/><label>(67)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e530" xlink:type="simple"/></inline-formula> is the mean spike count and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e531" xlink:type="simple"/></inline-formula> the variance. We then ask, given one such distribution with parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e532" xlink:type="simple"/></inline-formula>, how far away along the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e533" xlink:type="simple"/></inline-formula>-line should a distribution, with parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e534" xlink:type="simple"/></inline-formula>, be placed so that the probability not exceed a small value, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e535" xlink:type="simple"/></inline-formula>, a the point of equiprobability, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e536" xlink:type="simple"/></inline-formula>: <disp-formula id="pcbi.1003970.e537"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e537" xlink:type="simple"/><label>(68)</label></disp-formula></p>
<p>If this bound is achieved, the form of Eq. (67) implies the relation<disp-formula id="pcbi.1003970.e538"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e538" xlink:type="simple"/><label>(69)</label></disp-formula>for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e539" xlink:type="simple"/></inline-formula>. Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e540" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e541" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e542" xlink:type="simple"/></inline-formula>, we obtain<disp-formula id="pcbi.1003970.e543"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e543" xlink:type="simple"/><label>(70)</label></disp-formula>i.e., a lower bound on the distance between the mean of the distribution and the point of equiprobability. Similarly, for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e544" xlink:type="simple"/></inline-formula>, we have<disp-formula id="pcbi.1003970.e545"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e545" xlink:type="simple"/><label>(71)</label></disp-formula></p>
<p>Combining the two inequalities, we obtain a lower bound on the distance between the means of the two distributions, as<disp-formula id="pcbi.1003970.e546"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e546" xlink:type="simple"/><label>(72)</label></disp-formula>or<disp-formula id="pcbi.1003970.e547"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e547" xlink:type="simple"/><label>(73)</label></disp-formula></p>
<p>We can then iterate this argument for successive distributions, corresponding to different stimuli, and for each pair of distributions the bound<disp-formula id="pcbi.1003970.e548"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e548" xlink:type="simple"/><label>(74)</label></disp-formula>holds, up to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e549" xlink:type="simple"/></inline-formula>. For a total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e550" xlink:type="simple"/></inline-formula> distributions to my fit along the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e551" xlink:type="simple"/></inline-formula>-axis, the means of half of these will be between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e552" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e553" xlink:type="simple"/></inline-formula>, while the other half will be between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e554" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e555" xlink:type="simple"/></inline-formula>. Thus,<disp-formula id="pcbi.1003970.e556"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e556" xlink:type="simple"/><label>(75)</label></disp-formula></p>
<p>From this relation, we obtain the final bound on the capacity of a homogeneous population of independent neurons, as<disp-formula id="pcbi.1003970.e557"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e557" xlink:type="simple"/><label>(76)</label></disp-formula></p>
<p>In the 2-Pool case, we calculate similarly the number, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e558" xlink:type="simple"/></inline-formula>, of well-separated probability distributions that can be fit within the positive quadrant of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e559" xlink:type="simple"/></inline-formula>-plane of spike counts. Here, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e560" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e561" xlink:type="simple"/></inline-formula> each run from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e562" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e563" xlink:type="simple"/></inline-formula>, so <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e564" xlink:type="simple"/></inline-formula> is roughly evaluated as <disp-formula id="pcbi.1003970.e565"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e565" xlink:type="simple"/><label>(77)</label></disp-formula></p>
<p>Similarly, in the general <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e566" xlink:type="simple"/></inline-formula>-Pool case, each axis of the response space runs from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e567" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e568" xlink:type="simple"/></inline-formula>, so that<disp-formula id="pcbi.1003970.e569"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e569" xlink:type="simple"/><label>(78)</label></disp-formula></p>
<p>By analogy with a population of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e570" xlink:type="simple"/></inline-formula> deterministic neurons, we define the capacity per neuron, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e571" xlink:type="simple"/></inline-formula>, as<disp-formula id="pcbi.1003970.e572"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e572" xlink:type="simple"/><label>(79)</label></disp-formula></p>
<p>In the deterministic case, the population as a whole codes for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e573" xlink:type="simple"/></inline-formula> states and the capacity per neuron is equal to 1 bit. In the case of independent, but stochastic, neurons,<disp-formula id="pcbi.1003970.e574"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e574" xlink:type="simple"/><label>(80)</label></disp-formula>where<disp-formula id="pcbi.1003970.e575"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e575" xlink:type="simple"/><label>(81)</label></disp-formula>is the number of neurons per pool. The capacity decreases with decreasing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e576" xlink:type="simple"/></inline-formula>. For a given value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e577" xlink:type="simple"/></inline-formula>, the capacity is maximal for a characteristic pool size which depends upon <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e578" xlink:type="simple"/></inline-formula> but does not depend upon <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e579" xlink:type="simple"/></inline-formula> and which can be calculated perturbatively. Indeed, the minimization of the capacity yields the optimal pool size as the implicit solution of the equation<disp-formula id="pcbi.1003970.e580"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e580" xlink:type="simple"/><label>(82)</label></disp-formula></p>
<p>Solving this equation perturbatively to the next-to-lowest order, we obtain an approximate optimal pool size, as<disp-formula id="pcbi.1003970.e581"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e581" xlink:type="simple"/><label>(83)</label></disp-formula>and a maximal capacity per neuron given by<disp-formula id="pcbi.1003970.e582"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e582" xlink:type="simple"/><label>(84)</label></disp-formula></p>
<p>Equivalently, the number of stimuli that a population of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e583" xlink:type="simple"/></inline-formula> independent neurons can encode with an error threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e584" xlink:type="simple"/></inline-formula> is limited by<disp-formula id="pcbi.1003970.e585"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e585" xlink:type="simple"/><label>(85)</label></disp-formula></p>
</sec><sec id="s4h">
<title><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e586" xlink:type="simple"/></inline-formula>-Pool model of correlated neurons: Coding capacity</title>
<p>We derive an estimate of the capacity in the correlated case by evaluating how many ‘thin probability distributions’ can be fitted in the quadrant of possible response patterns defined by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e587" xlink:type="simple"/></inline-formula>. In a 2-Pool population (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e588" xlink:type="simple"/></inline-formula>), we can arrange one row of ‘parallel distributions’ along the diagonal that connects the points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e589" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e590" xlink:type="simple"/></inline-formula> in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e591" xlink:type="simple"/></inline-formula> plane. (Three such rows are displayed in <xref ref-type="fig" rid="pcbi-1003970-g006">Fig. 6B</xref>.) If neighboring distribution centers differ by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e592" xlink:type="simple"/></inline-formula> spike, this manipulation yields a number<disp-formula id="pcbi.1003970.e593"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e593" xlink:type="simple"/><label>(86)</label></disp-formula>of well separated probability distributions that the population can code for. Similarly, in the general <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e594" xlink:type="simple"/></inline-formula>-Pool case we arrange a set of correlated distributions across a hyperplane within the hypercube with edge <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e595" xlink:type="simple"/></inline-formula> in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e596" xlink:type="simple"/></inline-formula> space. Such a configuration immediately yields a scaling<disp-formula id="pcbi.1003970.e597"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e597" xlink:type="simple"/><label>(87)</label></disp-formula>where<disp-formula id="pcbi.1003970.e598"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e598" xlink:type="simple"/><label>(88)</label></disp-formula>is the number of neurons per pool, as before. To be more precise, we can bound <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e599" xlink:type="simple"/></inline-formula> from below. If we are concerned that distributions may overlap near the faces of the hypercube, we can, for example, allow them to fill only a central half of the hyperplane. Furthermore, if neighboring distribution centers are separated by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e600" xlink:type="simple"/></inline-formula> spikes, we obtain<disp-formula id="pcbi.1003970.e601"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e601" xlink:type="simple"/><label>(89)</label></disp-formula></p>
<p>This quantity behaves differently from its counterpart in the independent case: for a wide range of even vanishingly small error thresholds, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e602" xlink:type="simple"/></inline-formula> is essentially independent of the error threshold as realistic values of the correlation coefficients can be chosen so as to make the distributions much narrower than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e603" xlink:type="simple"/></inline-formula>. For fixed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e604" xlink:type="simple"/></inline-formula>, this bound scales with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e605" xlink:type="simple"/></inline-formula> in a trivial manner akin to the independent case. Indeed, the capacity per neurons,<disp-formula id="pcbi.1003970.e606"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e606" xlink:type="simple"/><label>(90)</label></disp-formula>here becomes<disp-formula id="pcbi.1003970.e607"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e607" xlink:type="simple"/><label>(91)</label></disp-formula></p>
<p>The capacity per neuron is maximized for<disp-formula id="pcbi.1003970.e608"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e608" xlink:type="simple"/><label>(92)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e609" xlink:type="simple"/></inline-formula> is Euler's number, and is evaluated as<disp-formula id="pcbi.1003970.e610"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e610" xlink:type="simple"/><label>(93)</label></disp-formula></p>
<p>We find<disp-formula id="pcbi.1003970.e611"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e611" xlink:type="simple"/><label>(94)</label></disp-formula>and<disp-formula id="pcbi.1003970.e612"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e612" xlink:type="simple"/><label>(95)</label></disp-formula></p>
<p>Correspondingly,<disp-formula id="pcbi.1003970.e613"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e613" xlink:type="simple"/><label>(96)</label></disp-formula>and<disp-formula id="pcbi.1003970.e614"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003970.e614" xlink:type="simple"/><label>(97)</label></disp-formula></p>
<p>As opposed to the case of independent neurons, here one does not need to invoke large values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e615" xlink:type="simple"/></inline-formula> for low-error coding. This is because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e616" xlink:type="simple"/></inline-formula> is not the only parameter from which the system can take advantage to suppress error rates; for each value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e617" xlink:type="simple"/></inline-formula>, the correlation coefficients may be tuned to suppress error rates. We emphasize that the result for optimality, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e618" xlink:type="simple"/></inline-formula>, is self-consistent: low-error coding can indeed occur with such small pool sizes (see <xref ref-type="fig" rid="pcbi-1003970-g003">Fig. 3</xref>).</p>
<p>We find that, in a correlated population, each neuron can carry as much as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e619" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e620" xlink:type="simple"/></inline-formula> bits of information. This result is to be contrasted with the absolute maximum of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e621" xlink:type="simple"/></inline-formula> bit of information in the case of independent, deterministic neurons and with the corresponding result for independent, stochastic neurons, Eq. (84). In the correlated case, the optimal capacity per neuron is fixed, whereas in the independent case it drops with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e622" xlink:type="simple"/></inline-formula>. In particular, from Eqs. (84) and (93) with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e623" xlink:type="simple"/></inline-formula>, we conclude that individual neurons are more informative in a correlated population, as compared to an independent population, as soon as the error rate threshold, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e624" xlink:type="simple"/></inline-formula>, falls below <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e625" xlink:type="simple"/></inline-formula>. Thus, for any realistically small value of the error rate threshold, correlated populations are favored.</p>
<p>Taking the 2-Pool model as an example, we note that only for relatively large values of the parameters (e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e626" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e627" xlink:type="simple"/></inline-formula>) does <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e628" xlink:type="simple"/></inline-formula> compare with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e629" xlink:type="simple"/></inline-formula>. At relatively low threshold values (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e630" xlink:type="simple"/></inline-formula>), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e631" xlink:type="simple"/></inline-formula> remains well below <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e632" xlink:type="simple"/></inline-formula> for any reasonable (and even large) value of the population size (<xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5D</xref>), as the behavior of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e633" xlink:type="simple"/></inline-formula> is dominated by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e634" xlink:type="simple"/></inline-formula> rather than by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e635" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003970-g005">Fig. 5D</xref>). This behavior obtains because the nearly isotropic tails of the distributions for independent neurons forbid the presence of more than one or a few distribution centers within the space of neural responses, if the error threshold is stringent.</p>
<p>It is worth mentioning that for loose error thresholds <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e636" xlink:type="simple"/></inline-formula> may exceed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e637" xlink:type="simple"/></inline-formula>. This results from the fact that independent distributions are arranged on a two-dimensional grid, whereas correlated distributions, which are compressed along one direction, are arranged along a line (along the ‘compressed direction’). Thus, independent distributions can take advantage of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e638" xlink:type="simple"/></inline-formula> possible positions of their centers, whereas correlated distributions have only <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003970.e639" xlink:type="simple"/></inline-formula> choices.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003970.s001" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003970.s001" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p><bold>High-Fidelity Coding with Correlated Neurons–supplementary material.</bold> Supplementary methods. Supplementary discussion, with one supplementary figure.</p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We are grateful to M. Kardar and J.-P. Nadal for discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003970-Barlow1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name>, <name name-style="western"><surname>Levick</surname><given-names>WR</given-names></name> (<year>1969</year>) <article-title>Three factors limiting the reliable detection of light by retinal ganglion cells of the cat</article-title>. <source>J Physiol</source> <volume>200</volume>: <fpage>1</fpage>–<lpage>24</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-HechtSShlaer1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hecht S Shlaer</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Pirenne</surname><given-names>M</given-names></name> (<year>1942</year>) <article-title>Energy, quanta, and vision</article-title>. <source>J. Gen. Physiol.</source> <volume>25</volume>: <fpage>819</fpage>–<lpage>840</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Klein1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname><given-names>SA</given-names></name>, <name name-style="western"><surname>Levi</surname><given-names>DM</given-names></name> (<year>1985</year>) <article-title>Hyperacuity thresholds of 1 sec: theoretical predictions and empirical validation</article-title>. <source>J Opt Soc Am A</source> <volume>2</volume>: <fpage>1170</fpage>–<lpage>90</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Newsome1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name>, <name name-style="western"><surname>Britten</surname><given-names>KH</given-names></name>, <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name> (<year>1989</year>) <article-title>Neuronal correlates of a perceptual decision</article-title>. <source>Nature</source> <volume>341</volume>: <fpage>52</fpage>–<lpage>4</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Watson1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watson</surname><given-names>AB</given-names></name>, <name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name>, <name name-style="western"><surname>Robson</surname><given-names>JG</given-names></name> (<year>1983</year>) <article-title>What does the eye see best</article-title>? <source>Nature</source> <volume>302</volume>: <fpage>419</fpage>–<lpage>22</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Barlow2"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name>, <name name-style="western"><surname>Levick</surname><given-names>WR</given-names></name>, and <name name-style="western"><surname>Yoon</surname><given-names>M</given-names></name> (<year>1971</year>) <article-title>Responses to single quanta of light in retinal ganglion cells of the cat</article-title>. <source>Vision Res</source>, <volume>Suppl 3</volume>:<fpage>87</fpage>–<lpage>101</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Parker1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parker</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hawken</surname><given-names>M</given-names></name> (<year>1985</year>) <article-title>Capabilities of monkey cortical cells in spatial-resolution tasks</article-title>. <source>J Opt Soc Am A</source> <volume>2</volume>: <fpage>1101</fpage>–<lpage>14</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Kirchner1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kirchner</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Thorpe</surname><given-names>SJ</given-names></name> (<year>2006</year>) <article-title>Ultra-rapid object detection with saccadic eye movements: visual processing speed revisited</article-title>. <source>Vision Res</source> <volume>46</volume>: <fpage>1762</fpage>–<lpage>76</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Liu1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Agam</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Madsen</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Kreiman</surname><given-names>G</given-names></name> (<year>2009</year>) <article-title>Timing, timing, timing: fast decoding of object information from intracranial field potentials in human visual cortex</article-title>. <source>Neuron</source> <volume>62</volume>: <fpage>281</fpage>–<lpage>90</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Hatsopoulos1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hatsopoulos</surname><given-names>NG</given-names></name>, <name name-style="western"><surname>Ojakangas</surname><given-names>CL</given-names></name>, <name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Donoghue</surname><given-names>JP</given-names></name> (<year>1998</year>) <article-title>Information about movement direction obtained from synchronous activity of motor cortical neurons</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>95</volume>: <fpage>15706</fpage>–<lpage>11</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Mastronarde1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mastronarde</surname><given-names>DN</given-names></name> (<year>1989</year>) <article-title>Correlated firing of retinal ganglion cells</article-title>. <source>Trends Neurosci</source> <volume>12</volume>: <fpage>75</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Ozden1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ozden</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>HM</given-names></name>, <name name-style="western"><surname>Sullivan</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>SS</given-names></name> (<year>2008</year>) <article-title>Identification and clustering of event patterns from in vivo multiphoton optical recordings of neuronal ensembles</article-title>. <source>J Neurophysiol</source> <volume>100</volume>: <fpage>495</fpage>–<lpage>503</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Perkel1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perkel</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Gerstein</surname><given-names>GL</given-names></name>, <name name-style="western"><surname>Moore</surname><given-names>GP</given-names></name> (<year>1967</year>) <article-title>Neuronal spike trains and stochastic point processes. ii. simultaneous spike trains</article-title>. <source>Biophys J</source> <volume>7</volume>: <fpage>419</fpage>–<lpage>40</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Sasaki1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sasaki</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Bower</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Llinas</surname><given-names>R</given-names></name> (<year>1989</year>) <article-title>Multiple purkinje cell recording in rodent cerebellar cortex</article-title>. <source>Eur J Neurosci</source> <volume>1</volume>: <fpage>572</fpage>–<lpage>586</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Shlens1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shlens</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname><given-names>E</given-names></name> (<year>2008</year>) <article-title>Synchronized firing in the retina</article-title>. <source>Curr Opin Neurobiol</source> <volume>18</volume>: <fpage>396</fpage>–<lpage>402</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Usrey1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Usrey</surname><given-names>WM</given-names></name>, <name name-style="western"><surname>Reid</surname><given-names>RC</given-names></name> (<year>1999</year>) <article-title>Synchronous activity in the visual system</article-title>. <source>Annu Rev Physiol</source> <volume>61</volume>: <fpage>435</fpage>–<lpage>56</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Vaadia1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vaadia</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Haalman</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bergman</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Prut</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>1995</year>) <article-title>Dynamics of neuronal interactions in monkey cortex in relation to behavioural events</article-title>. <source>Nature</source> <volume>373</volume>: <fpage>515</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Bair1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bair</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Zohary</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name> (<year>2001</year>) <article-title>Correlated firing in macaque visual area mt: time scales and relationship to behavior</article-title>. <source>J Neurosci</source> <volume>21</volume>: <fpage>1676</fpage>–<lpage>97</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Fiser1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fiser</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Chiu</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Weliky</surname><given-names>M</given-names></name> (<year>2004</year>) <article-title>Small modulation of ongoing cortical dynamics by sensory input during natural vision</article-title>. <source>Nature</source> <volume>431</volume>: <fpage>573</fpage>–<lpage>8</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Kohn1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kohn</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>MA</given-names></name> (<year>2005</year>) <article-title>Stimulus dependence of neuronal correlation in primary visual cortex of the macaque</article-title>. <source>J Neurosci</source> <volume>25</volume>: <fpage>3661</fpage>–<lpage>73</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Smith1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Kohn</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>Spatial and temporal scales of neuronal correlation in primary visual cortex</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>12591</fpage>–<lpage>12603</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Lee1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Port</surname><given-names>NL</given-names></name>, <name name-style="western"><surname>Kruse</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Georgopoulos</surname><given-names>AP</given-names></name> (<year>1998</year>) <article-title>Variability and correlated noise in the discharge of neurons in motor and parietal areas of the primate cortex</article-title>. <source>J Neurosci</source> <volume>18</volume>: <fpage>1161</fpage>–<lpage>70</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Zohary1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zohary</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Shadlen</surname><given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name> (<year>1994</year>) <article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title>. <source>Nature</source> <volume>370</volume>: <fpage>140</fpage>–<lpage>3</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Ecker1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ecker</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Berens</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Keliris</surname><given-names>GA</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Decorrelated neuronal firing in cortical microcircuits</article-title>. <source>Science</source> <volume>327</volume>: <fpage>584</fpage>–<lpage>587</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Johnson1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johnson</surname><given-names>KO</given-names></name> (<year>1980</year>) <article-title>Sensory discrimination: decision process</article-title>. <source>J Neurophysiol</source> <volume>43</volume>: <fpage>1771</fpage>–<lpage>92</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Vogels1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vogels</surname><given-names>R</given-names></name> (<year>1990</year>) <article-title>Population coding of stimulus orientation by striate cortical cells</article-title>. <source>Biological Cybernetics</source> <volume>64</volume>: <fpage>25</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Oram1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oram</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Foldiak</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Perrett</surname><given-names>DI</given-names></name>, <name name-style="western"><surname>Sengpiel</surname><given-names>F</given-names></name> (<year>1998</year>) <article-title>The ‘ideal homunculus’: decoding neural population signals</article-title>. <source>Trends Neurosci</source> <volume>21</volume>: <fpage>259</fpage>–<lpage>65</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Abbott1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name> (<year>1999</year>) <article-title>The effect of correlated variability on the accuracy of a population code</article-title>. <source>Neural Comput</source> <volume>11</volume>: <fpage>91</fpage>–<lpage>101</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Panzeri1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Schultz</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name> (<year>1999</year>) <article-title>On decoding the responses of a population of neurons from short time windows</article-title>. <source>Neural Comput</source> <volume>11</volume>: <fpage>1553</fpage>–<lpage>77</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Sompolinsky1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Yoon</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Kang</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Shamir</surname><given-names>M</given-names></name> (<year>2001</year>) <article-title>Population coding in neuronal systems with correlated noise</article-title>. <source>Phys Rev E Stat Nonlin Soft Matter Phys</source> <volume>64</volume>: <fpage>051904</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Wilke1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilke</surname><given-names>SD</given-names></name>, <name name-style="western"><surname>Eurich</surname><given-names>CW</given-names></name> (<year>2002</year>) <article-title>Representational accuracy of stochastic neural populations</article-title>. <source>Neural Comput</source> <volume>14</volume>: <fpage>155</fpage>–<lpage>89</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Romo1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Romo</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hernandez</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Zainos</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Salinas</surname><given-names>E</given-names></name> (<year>2003</year>) <article-title>Correlated neuronal discharges that increase coding efficiency during perceptual discrimination</article-title>. <source>Neuron</source> <volume>38</volume>: <fpage>649</fpage>–<lpage>57</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Golledge1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Golledge</surname><given-names>HD</given-names></name>, <name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Zheng</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Pola</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Scannell</surname><given-names>JW</given-names></name>, <etal>et al</etal>. (<year>2003</year>) <article-title>Correlations, feature-binding and population coding in primary visual cortex</article-title>. <source>Neuroreport</source> <volume>14</volume>: <fpage>1045</fpage>–<lpage>50</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Pola1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pola</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Thiele</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hoffmann</surname><given-names>KP</given-names></name>, <name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name> (<year>2003</year>) <article-title>An exact method to quantify the information transmitted by different mechanisms of correlational coding</article-title>. <source>Network</source> <volume>14</volume>: <fpage>35</fpage>–<lpage>60</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Averbeck1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Averbeck</surname><given-names>BB</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>D</given-names></name> (<year>2003</year>) <article-title>Neural noise and movement-related codes in the macaque supplementary motor area</article-title>. <source>J Neurosci</source> <volume>23</volume>: <fpage>7630</fpage>–<lpage>41</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Shamir1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shamir</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name> (<year>2004</year>) <article-title>Nonlinear population codes</article-title>. <source>Neural Comput</source> <volume>16</volume>: <fpage>1105</fpage>–<lpage>36</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Shamir2"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shamir</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name> (<year>2006</year>) <article-title>Implications of neuronal diversity on population coding</article-title>. <source>Neural Comput</source> <volume>18</volume>: <fpage>1951</fpage>–<lpage>86</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Averbeck2"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Averbeck</surname><given-names>BB</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>D</given-names></name> (<year>2006</year>) <article-title>Effects of noise correlations on information encoding and decoding</article-title>. <source>J Neurophysiol</source> <volume>95</volume>: <fpage>3633</fpage>–<lpage>44</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Averbeck3"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Averbeck</surname><given-names>BB</given-names></name>, <name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Neural correlations, population coding and computation</article-title>. <source>Nat Rev Neurosci</source> <volume>7</volume>: <fpage>358</fpage>–<lpage>66</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Josic1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Josic</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Doiron</surname><given-names>B</given-names></name>, <name name-style="western"><surname>de la Rocha</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>Stimulus-dependent correlations and population codes</article-title>. <source>Neural Comput</source> <volume>21</volume>: <fpage>2774</fpage>–<lpage>804</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Ecker2"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ecker</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Berens</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Tolias A</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>The effect of noise correlations in populations of diversely tuned neurons</article-title>. <source>The Journal of Neuroscience</source> <volume>31</volume>: <fpage>14272</fpage>–<lpage>14283</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Hu1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Zylberberg</surname><given-names>J</given-names></name>, and <name name-style="western"><surname>Shea-Brown</surname><given-names>E</given-names></name> (<year>2013</year>) <article-title>The sign rule and beyond: Boundary effects, flexibility, and optimal noise correlations in neural population codes</article-title>. <source>arXiv preprint arXiv</source>:<fpage>1307.3235</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Butts1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Butts</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Weng</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Jin</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Yeh</surname><given-names>CI</given-names></name>, <name name-style="western"><surname>Lesica</surname><given-names>NA</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Temporal precision in the neural code and the timescales of natural vision</article-title>. <source>Nature</source> <volume>449</volume>: <fpage>92</fpage>–<lpage>5</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Osborne1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Osborne</surname><given-names>LC</given-names></name>, <name name-style="western"><surname>Palmer</surname><given-names>SE</given-names></name>, <name name-style="western"><surname>Lisberger</surname><given-names>SG</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name> (<year>2008</year>) <article-title>The neural basis for combinatorial coding in a cortical population response</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>13522</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Gollisch1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gollisch</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Meister</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Rapid neural coding in the retina with relative spike latencies</article-title>. <source>Science</source> <volume>319</volume>: <fpage>1108</fpage>–<lpage>1111</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Petersen1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Petersen</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Diamond</surname><given-names>ME</given-names></name> (<year>2001</year>) <article-title>Population coding of stimulus location in rat somatosensory cortex</article-title>. <source>Neuron</source> <volume>32</volume>: <fpage>503</fpage>–<lpage>514</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Schneidman1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Berry</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Segev</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name> (<year>2006</year>) <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population</article-title>. <source>Nature</source> <volume>440</volume>: <fpage>1007</fpage>–<lpage>12</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Shlens2"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shlens</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>GD</given-names></name>, <name name-style="western"><surname>Gauthier</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Grivich</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Petrusca</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>The structure of multi-neuron firing patterns in primate retina</article-title>. <source>The Journal of neuroscience</source> <volume>26</volume>: <fpage>8254</fpage>–<lpage>8266</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Tkacik1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tkacik</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Marre</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Amodei</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Spin glass models for a network of real neurons</article-title>. <source>PLoS Computational Biology</source> <volume>10</volume>: <fpage>e1003408</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Tkaik1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tkačik</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Prentice</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Balasubramanian</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name> (<year>2010</year>) <article-title>Optimal population coding by noisy spiking neurons</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>107</volume>: <fpage>14419</fpage>–<lpage>14424</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Cover1"><label>51</label>
<mixed-citation publication-type="other" xlink:type="simple">Cover T and Thomas J (1991) Elements of information theory.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Brunel1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brunel</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Nadal</surname><given-names>JP</given-names></name> (<year>1998</year>) <article-title>Mutual information, fisher information, and population coding</article-title>. <source>Neural Computation</source> <volume>10</volume>: <fpage>1731</fpage>–<lpage>1757</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Kang1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kang</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name> (<year>2001</year>) <article-title>Mutual information of population codes and distance measures in probability space</article-title>. <source>Physical Review Letters</source> <volume>86</volume>: <fpage>4958</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Maynard1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maynard</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Hatsopoulos</surname><given-names>NG</given-names></name>, <name name-style="western"><surname>Ojakangas</surname><given-names>CL</given-names></name>, <name name-style="western"><surname>Acuna</surname><given-names>BD</given-names></name>, <name name-style="western"><surname>Sanes</surname><given-names>JN</given-names></name>, <etal>et al</etal>. (<year>1999</year>) <article-title>Neuronal interactions improve cortical population coding of movement direction</article-title>. <source>J Neurosci</source> <volume>19</volume>: <fpage>8083</fpage>–<lpage>93</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Cohen1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name> (<year>2008</year>) <article-title>Context-dependent changes in functional circuitry in visual area mt</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>162</fpage>–<lpage>173</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Poort1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Poort</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Roelfsema</surname><given-names>PR</given-names></name> (<year>2009</year>) <article-title>Noise correlations have little influence on the coding of selective attention in area v1</article-title>. <source>Cereb Cortex</source> <volume>19</volume>: <fpage>543</fpage>–<lpage>53</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003970-Gutnisky1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gutnisky</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Dragoi</surname><given-names>V</given-names></name> (<year>2008</year>) <article-title>Adaptive coding of visual information in neural populations</article-title>. <source>Nature</source> <volume>452</volume>: <fpage>220</fpage>–<lpage>4</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
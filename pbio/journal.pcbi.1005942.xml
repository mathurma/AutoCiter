<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-01247</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005942</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Speech</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Grammar</subject><subj-group><subject>Phonology</subject><subj-group><subject>Phonemes</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Phonetics</subject><subj-group><subject>Vowels</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory pathway</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory pathway</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory pathway</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Earth sciences</subject><subj-group><subject>Geology</subject><subj-group><subject>Sedimentary geology</subject><subj-group><subject>Perturbation (geology)</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Somatosensory system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Somatosensory system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Somatosensory system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>What drives the perceptual change resulting from speech motor adaptation? Evaluation of hypotheses in a Bayesian modeling framework</article-title>
<alt-title alt-title-type="running-head">Modeling perceptual change after speech motor adaptation</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1838-9512</contrib-id>
<name name-style="western">
<surname>Patri</surname> <given-names>Jean-François</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Perrier</surname> <given-names>Pascal</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Schwartz</surname> <given-names>Jean-Luc</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Diard</surname> <given-names>Julien</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Univ. Grenoble Alpes, CNRS, GIPSA-Lab UMR 5216, F-38000 Grenoble, France</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Univ. Grenoble Alpes, CNRS, LPNC UMR 5105, F-38000 Grenoble, France</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Theunissen</surname> <given-names>Frédéric E.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of California at Berkeley, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">jeanfrancoispatri@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>1</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>22</day>
<month>1</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>1</issue>
<elocation-id>e1005942</elocation-id>
<history>
<date date-type="received">
<day>25</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>12</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Patri et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005942"/>
<abstract>
<p>Shifts in perceptual boundaries resulting from speech motor learning induced by perturbations of the auditory feedback were taken as evidence for the involvement of motor functions in auditory speech perception. Beyond this general statement, the precise mechanisms underlying this involvement are not yet fully understood. In this paper we propose a quantitative evaluation of some hypotheses concerning the motor and auditory updates that could result from motor learning, in the context of various assumptions about the roles of the auditory and somatosensory pathways in speech perception. This analysis was made possible thanks to the use of a Bayesian model that implements these hypotheses by expressing the relationships between speech production and speech perception in a joint probability distribution. The evaluation focuses on how the hypotheses can (1) predict the location of perceptual boundary shifts once the perturbation has been removed, (2) account for the magnitude of the compensation in presence of the perturbation, and (3) describe the correlation between these two behavioral characteristics. Experimental findings about changes in speech perception following adaptation to auditory feedback perturbations serve as reference. Simulations suggest that they are compatible with a framework in which motor adaptation updates both the auditory-motor internal model and the auditory characterization of the perturbed phoneme, and where perception involves both auditory and somatosensory pathways.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Experimental evidence suggest that motor learning influences categories in speech perception. These observations are consistent with studies of arm motor control showing that motor learning alters the perception of the arm location in the space, and that these perceptual changes are associated with increased connectivity between regions of the motor cortex. Still, the interpretation of experimental findings is severely handicapped by a lack of precise hypotheses about underlying mechanisms. We reanalyze the results of the most advanced experimental studies of this kind in speech, in light of a systematic and computational evaluation of hypotheses concerning motor and auditory updates that could result from motor learning. To do so, we mathematically translate these hypotheses into a unified Bayesian model that integrates for the first time speech production and speech perception in a coherent architecture. We show that experimental findings are best accounted for when motor learning is assumed to generate updates of the auditory-motor internal model and the auditory characterization of phonemes, and when perception is assumed to involve both auditory and somatosensory pathways. This strongly reinforces the view that auditory and motor knowledge intervene in speech perception, and suggests likely mechanisms for motor learning in speech production.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>ERC Speech Unit(e)s</institution>
</funding-source>
<award-id>339152</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Schwartz</surname> <given-names>Jean-Luc</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>The research leading to these results has received funding from the European Research Council under the European Community’s Seventh Framework Programme (FP7/2007-2013 Grant Agreement no. 339152, "Speech Unit(e)s", PI: Jean-Luc-Schwartz). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="16"/>
<table-count count="0"/>
<page-count count="38"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-02-01</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The fact that perception has an influence on motor learning is known and has been the focus of a large number of studies. The converse, i.e. that motor learning would influence perception, seems more intriguing and unclear. For speech, shifts in perceptual boundaries have been shown to result from motor learning induced by perturbations of the auditory feedback [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref002">2</xref>] or perturbations of the articulatory gestures [<xref ref-type="bibr" rid="pcbi.1005942.ref003">3</xref>]. In the context of the well-known historical debates about the primitives (auditory/articulatory/motor) of speech perception [<xref ref-type="bibr" rid="pcbi.1005942.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref008">8</xref>], these findings could be interpreted as evidence in support of theories assuming the involvement of speech production processes in speech perception. However, an influence of speech motor learning on perceptual categorization of speech sounds does not necessarily imply an involvement of brain motor areas in speech perception. Indeed, the unusual auditory signals experienced during the adaptation process may by themselves be responsible for the observed perceptual shift.</p>
<p>From this observation, and building up on Shiller et al.’s experiment [<xref ref-type="bibr" rid="pcbi.1005942.ref002">2</xref>], Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>] specifically attempted to disentangle the respective influence of motor functions and altered sensory inputs on the perceptual boundary shifts. To do so, they developed an experimental protocol designed to assess separately the learning effects induced by changes in auditory feedback, on the one hand, and those arising from changes in motor control, on the other hand. They concluded that the origin of the perceptual change is indeed motor rather than sensory.</p>
<p>Lametti et al.’s study is very rich and relies on a solid experimental methodology. However we argue that their reasoning, because it is only qualitative, is incomplete, and does not enable to fully understand the nature of the mechanisms underlying the link observed after motor learning between changes in motor functions and perceptual changes.</p>
<p>In the present work we propose to dig into these questions using a previously defined Bayesian model [<xref ref-type="bibr" rid="pcbi.1005942.ref009">9</xref>]. This model was previously used to study the relative roles of auditory and proprioceptive representations in speech gesture planning; here we adapt this model to identify, implement and compare different hypotheses concerning motor adaptation. We analyze the consequences of these different hypotheses on perception and production mechanisms and suggest additional tentative interpretations of the experimental findings reported by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>]. This constitutes, in our view, an important step to better relate experimental data to theories of speech production and speech perception, and further enlighten the possible role of motor processes in speech perception. Importantly, the Bayesian model we use enables to translate classical and transversal questions about motor control, perception, learning and adaptation into computations and predictions. Such a model is a methodological tool to tackle these issues widely in speech production and speech perception, as well as in arm motor control [<xref ref-type="bibr" rid="pcbi.1005942.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref011">11</xref>].</p>
<p>The body of this paper is divided into four sections. The remaining of this section gives an overview of the main experimental paradigms and facts reported by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>]. We then present our modeling framework to deal with these experimental findings; this is presented in Section “Model”. The interpretation of the results of simulations are presented in Section “Results”, and discussed in Section “Discussion”.</p>
<sec id="sec002">
<title>Influence of motor learning upon speech perception: Overview of experimental facts</title>
<p>The influence of speech motor learning on speech perception was first reported by Shiller et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref002">2</xref>] (this study is called “S-09” henceforth). Motor learning was implemented by perturbing the auditory feedback of subjects when they were producing the fricative /s/: it consisted in shifting down the first spectral moment of /s/ in such a way that it sounded more like /∫/. They observed that subjects adapted their articulation after training in order to compensate, partially, for the perturbation, and the perceptual test after adaptation revealed a shift of the perceptual boundary between /s/ and /∫/ toward /∫/ (more sounds were perceived like /s/).</p>
<p>Five years later, Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>] published a new study (referred to as “L-14” henceforth) aiming at clarifying whether the observed perceptual change was related to “the change to motor function that occurs during learning, [to the] perceptual learning related to the altered sensory inputs, [or to] some combination of the two”(p 10339). To this end they proposed an original experimental design supposed to disentangle the effects of sensory vs. motor processes on perceptual categorization. While in S-09 a perturbation of the fricative /s/ was introduced in only one direction (toward the fricative /∫/), in L-14 the vowel /ɛ/ was perturbed in two directions. For one group of subjects, the perturbation was applied toward the vowel /a/ by increasing the frequency of the first formant <italic>F</italic><sub>1</sub> (left panel in <xref ref-type="fig" rid="pcbi.1005942.g001">Fig 1</xref>). For the other group it was applied toward the vowel /i/ by decreasing <italic>F</italic><sub>1</sub> (right panel in <xref ref-type="fig" rid="pcbi.1005942.g001">Fig 1</xref>).</p>
<fig id="pcbi.1005942.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Illustration of results obtained by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>].</title>
<p>Perceptual categorization curves before and after motor learning. Left panel: perturbation of vowel /ɛ/ toward vowel /a/. Right panel: perturbation of vowel /ɛ/ toward vowel /i/. Subjects compensate by producing sounds opposed to the direction of perturbation, closer to /i/ in the first case, and closer to /a/ in the second. Perceptual boundary shifts are observed for both directions of perturbations. The shift goes in the same direction as the perturbation, and is present only in the portion of auditory space corresponding to the productions of subjects during the compensation. Adapted from Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g001" xlink:type="simple"/>
</fig>
<p>To make the reasoning in L-14 clear, let us analyze the case of the perturbation toward /a/ (see <xref ref-type="fig" rid="pcbi.1005942.g001">Fig 1</xref>, left panel). The shift of the auditory percept along the /ɛ-a/ continuum generated a compensatory movement of the tongue frontwards, which corresponds in the absence of perturbation to an auditory percept along the /ɛ-i/ continuum. Since compensation is never complete, it results with altered auditory feedback in /ɛ/ sounds that remain partly perturbed and belong to the /ɛ-a/ region, while speaker’s gestures and their corresponding somatosensory information actually belong to the /ɛ-i/ region. This is the clever method used by the authors to attempt to disentangle auditory and motor interpretations of the perturbation effects. Indeed, in their reasoning, measuring the shift of the perceptual boundary between /ɛ/ and /a/ provides a measure of the effect of the altered sensory inputs on perceptual categories, while measuring the shift of the perceptual boundary between /ɛ/ and /i/ provides a measure of the effects of the changed articulation, i.e. of the motor function, on perceptual categories. A symmetric reasoning applies for the perturbation toward /i/ (<xref ref-type="fig" rid="pcbi.1005942.g001">Fig 1</xref>, right panel).</p>
<p>Concerning motor learning, consistent with S-09 and other auditory perturbation studies in speech, motor compensation was observed and its magnitude was on average below 40% of the amplitude of perturbation. Concerning perception, a significant boundary shift was also observed in L-14. Consistent with observations reported in S-09, the resulting perceptual shifts were in the same direction as the perturbation. However, contrary to S-09, no significant shift was observed in L-14 in the region of the altered auditory inputs (i.e. the /ɛ-a/ continuum for a perturbation towards /a/); the significant shift was found in the region corresponding to the altered articulation (i.e. the /ɛ-i/ continuum for a perturbation toward /a/, see <xref ref-type="fig" rid="pcbi.1005942.g001">Fig 1</xref>, left panel). A control group in which subjects produced the same sequence of sounds without alteration of the auditory feedback did not show any perceptual boundary shift.</p>
<p>The authors concluded that their findings are “consistent with the idea that changes to central motor commands associated with speech learning are the source of changes observed in the perceptual classification of speech sounds” [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>, p 10340]. Notice that if it is true that the origin of the observed perceptual shift is due to motor functions, greater changes in motor functions should induce greater changes in perception, inducing after learning positive correlations between the amount of compensation and the amplitude of the resulting perceptual shift. Intriguingly, an absence of significant correlation was reported in L-14.</p>
</sec>
<sec id="sec003">
<title>Summary of experimental results we aim at modeling</title>
<p>Our aim is to exploit a previously defined computational framework [<xref ref-type="bibr" rid="pcbi.1005942.ref012">12</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref014">14</xref>] modelling the interactions of perception and production in speech communication, and to apply it to model and better understand the experimental data of L-14. In our modeling approach our prime concern is to extract the deeper meaning of the experimental observations and to specify a limited number of facts that best characterize them. The following summary presents the main experimental facts on which we will focus in our modeling work.</p>
<list list-type="order">
<list-item>
<p><bold>Changes in speech production induced by auditory perturbations</bold>.
<list list-type="alpha-lower">
<list-item>
<p><bold>Motor compensation:</bold> speaker’s articulatory movements are modified to reduce the impact of the perturbation on the perceived sound.</p>
</list-item>
<list-item>
<p><bold>Incomplete compensation:</bold> compensatory maneuvers never fully cancel the effects of the perturbation. On average, compensatory spectral changes are always below 40% of the magnitude of perturbation.</p>
</list-item>
<list-item>
<p><bold>Motor adaptation:</bold> when the perturbation is removed after the learning phase, changes in speech production remain during a certain number of trials. This so called after-effect reflects a reorganization of the motor planning process that precedes motor execution of speech gestures.</p>
</list-item>
</list></p>
</list-item>
<list-item>
<p><bold>Changes in speech perception</bold>. Both motor adaptation studies, S-09 and L-14, report shifts in boundaries between phonemic perceptual categories. The key-observations are:
<list list-type="alpha-lower">
<list-item>
<p><bold>Consistency in the direction:</bold> on average, across subjects, the direction of the shift is the same as the direction of the perturbation in both L-14 and S-09.</p>
</list-item>
<list-item>
<p><bold>Presence of an asymmetry:</bold> in L-14 a significant perceptual boundary shift was observed only in the portion of the auditory space related to the articulation of subjects when compensating for the perturbation, and not in the portion of auditory space related to what subjects heard in presence of the perturbation. This asymmetry was not explored in S-09 on fricative /s/ because there is no phoneme category beyond /s/ in a direction opposite to /∫/ along the spectral continuum /s-∫/. It should be noted though that the results of S-09 tend to contradict the interpretation provided in L-14 since they describe a perceptual shift in the portion of the space related to what subjects heard in the presence of the auditory perturbation.</p>
</list-item>
</list></p>
</list-item>
<list-item>
<p><bold>Absence of correlations between amounts of motor compensation and perceptual shift</bold>. Both the amount of motor compensation and the amount of perceptual boundary shift differ across subjects. While one would expect a relation between the amount of compensation and the resulting perceptual shift, no significant correlation was found in L-14.</p>
</list-item>
</list>
</sec>
</sec>
<sec id="sec004">
<title>Model</title>
<p>This section introduces our model, which is an instance of the Bayesian algorithmic modeling framework [<xref ref-type="bibr" rid="pcbi.1005942.ref015">15</xref>], that is, the application of Bayesian Programming [<xref ref-type="bibr" rid="pcbi.1005942.ref016">16</xref>] to Marr’s algorithmic level of cognitive modeling [<xref ref-type="bibr" rid="pcbi.1005942.ref017">17</xref>]. With this framework, we have previously developed a series of models, under the COSMO moniker, to study speech perception and speech production in different contexts, such as speech communication and the emergence of phonological systems [<xref ref-type="bibr" rid="pcbi.1005942.ref013">13</xref>], speech perception in adverse conditions [<xref ref-type="bibr" rid="pcbi.1005942.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref014">14</xref>], sensorimotor learning [<xref ref-type="bibr" rid="pcbi.1005942.ref018">18</xref>] and the emergence of speech idiosyncrasies [<xref ref-type="bibr" rid="pcbi.1005942.ref019">19</xref>]. Variants have also been applied, in speech production, to token-to-token variability [<xref ref-type="bibr" rid="pcbi.1005942.ref020">20</xref>], the incorporation of multiple constraints in speech planning [<xref ref-type="bibr" rid="pcbi.1005942.ref021">21</xref>] and the modeling of multisensory (acoustic and somatosensory) speech targets [<xref ref-type="bibr" rid="pcbi.1005942.ref009">9</xref>]. It is this last variant that we adapt here to our current study.</p>
<p>In the Bayesian algorithmic modeling approach, an overarching feature is that perception and production processes are not directly modeled. Instead, we build an undirected model of speech-relevant knowledge using probability distributions. Then, from this model, we compute distributions using Bayesian inference to simulate perception and production tasks. Perception and production processes, therefore, if they involve the same knowledge, become related. Let us consider the case of speech: in our approach, we commonly assume that the description of acoustic targets in speech planning is the same piece of knowledge as would be used in a purely auditory decoder in speech perception. This distinction between the knowledge stored in the model and its use to generate processes makes our framework ideal for the study of the links between production and perception mechanisms, such as those addressed in this work.</p>
<p>The model includes selected aspects of speech production and speech perception that are described in Section “Selected aspects for modeling”. Their implementation in the model is explained in Sections “Model definition” and “Formulation of speech production and perception questions”. The strategy used to simulate the experimental paradigm of L-14 is detailed in Section “Implementation of the experimental paradigm: Normal vs. adapted conditions”. Finally, the simulation results and their analysis are presented in Section “Results”.</p>
<sec id="sec005">
<title>Selected aspects for modeling</title>
<p>Our aim is to study the interaction between speech production and speech perception processes in light of the experimental results provided in L-14. The first step in such a modeling approach consists in reducing the complexity of the experimental world into a core set of simplified components likely to capture its essential ingredients. This simplification phase should result in constraining and focusing both model implementation and results interpretation. We have selected a reduced number of aspects in speech production and speech perception that we consider to be crucial and sufficiently representative for the investigation of the interaction between motor learning and perception of isolated phonemes—here, isolated vowels /i/, /ɛ/ and /a/.</p>
<list list-type="order">
<list-item>
<p><bold>Considering the stable states before and after learning</bold>. We do not consider the particular details of the trial-to-trial evolution of the adaptation process during the training phase. Instead, we only focus on the stable states preceding and reached at the end of the adaptation process.</p>
</list-item>
<list-item>
<p><bold>Priority is given to speech motor planning</bold>. We do not include any modeling of the execution of speech production gestures, ignoring in particular online feedback correction mechanisms, and only focus on the early offline planning stage preceding motor execution.</p>
</list-item>
<list-item>
<p><bold>Time independent states</bold>. In the context of the two previous assumptions, we further simplify the speech production and perception systems by considering only time independent motor and sensory states that would correspond to stable vowel utterances.</p>
</list-item>
<list-item>
<p><bold>One-dimensional linear description</bold>. Since both experimental designs in S-09 and L-14 studied perturbation and perception along a single dimension of the auditory space, we formally reduce the high dimensionality of motor and sensory spaces to a unique dimension. In addition, as a first order approximation, we assume that the relation between motor and sensory spaces is linear. This one-dimensional-linear simplification cannot account for the well-known many-to-one relationships between motor commands and articulatory configurations (most evident in co-contraction [<xref ref-type="bibr" rid="pcbi.1005942.ref022">22</xref>]), on the one hand, and articulatory configuration and acoustic signal on the other hand [<xref ref-type="bibr" rid="pcbi.1005942.ref023">23</xref>]. However, while this aspect would be crucial in motor learning based on articulatory perturbation (bite-block, lip-tube, jaw perturbation) requiring the use of motor-equivalence strategies for the subjects to compensate for the perturbation, it is not at the core of the mechanisms investigated in S-09 and L-14. Hence, for the sake of computational simplicity and interpretability of the results, we discard this complexity from the present analysis. This enables to take a coarse grain view and to focus on qualitative effects concerning different possible assumptions about motor adaptation, which will be introduced in Section “Implementation of the experimental paradigm: Normal vs. adapted conditions”.</p>
</list-item>
<list-item>
<p><bold>Auditory and somatosensory properties of the sensory representations of speech units</bold>. Finally, a fundamental question underlying the definition of our model concerns the sensory nature of speech units. Sensory representations are usually assumed to account for classification of speech sounds in perception and for the definition of motor goals in production. Concerning production, the presence of compensatory behavior induced by auditory perturbations has been a main argument supporting the hypothesis that speech motor goals are essentially characterized in auditory terms [<xref ref-type="bibr" rid="pcbi.1005942.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref025">25</xref>]. However, somatosensory perturbation studies have also reported significant compensation in speech related movement, also suggesting the existence of somatosensory characterizations of speech motor goals [<xref ref-type="bibr" rid="pcbi.1005942.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref027">27</xref>]. Concerning perception, auditory representations of course play a key role. This has been confirmed for the perception of self-generated speech via perturbation experiments such as those using lip tubes or perturbation of the auditory feedback [<xref ref-type="bibr" rid="pcbi.1005942.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref029">29</xref>] and it is in line with all reviews of the neuroanatomy of speech perception (e.g. [<xref ref-type="bibr" rid="pcbi.1005942.ref030">30</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref033">33</xref>]). However it remains unclear whether these are the only sensory representations that may be involved. In particular, a number of studies show an influence of somatosensory inputs on the perception of speech sounds [<xref ref-type="bibr" rid="pcbi.1005942.ref034">34</xref>] and neurocognitive data converge on the view that somatosensory regions are involved in speech processing (see a recent review by Skipper et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref035">35</xref>]), suggesting a possible involvement of somatosensory representations as well. Our position with respect to these questions is the following:
<list list-type="alpha-lower">
<list-item>
<p><bold>In production</bold>, we assume the involvement of both auditory and somatosensory representations.</p>
</list-item>
<list-item>
<p><bold>In perception</bold>, we consider two alternatives and evaluate their consequences in our framework: either perception of speech sounds involves auditory representations only or it involves both auditory and somatosensory representations. This will provide the underlying key question of this work, namely whether the data reported in L-14 do support the involvement of the speech production system in speech perception through the somatosensory system.</p>
</list-item>
</list></p>
</list-item>
</list>
</sec>
<sec id="sec006">
<title>Model definition</title>
<p>The structure of the model consists in implementing a chain of probabilistic dependencies between phonological, motor and sensory variables. Variables and their dependencies are illustrated in <xref ref-type="fig" rid="pcbi.1005942.g002">Fig 2</xref>, and we now describe the most salient aspects of the model (a more complete mathematical description is provided in Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s001">S1 Text</xref>.</p>
<fig id="pcbi.1005942.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Graphical representation of model dependencies.</title>
<p>Nodes represent variables and arrows display dependency relations. Variable Φ corresponds to phonemes, which are characterized in terms of auditory and somatosensory variables <italic>A</italic><sub>Φ</sub> and <italic>S</italic><sub>Φ</sub>. Variables <italic>A</italic><sub><italic>M</italic></sub> and <italic>S</italic><sub><italic>M</italic></sub> represent the predicted auditory and somatosensory consequences of the motor commands <italic>M</italic>. Variables <italic>C</italic><sub><italic>A</italic></sub> and <italic>C</italic><sub><italic>S</italic></sub> implement two sensory-matching constraints that allow the connection of the corresponding sensory pathways.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g002" xlink:type="simple"/>
</fig>
<sec id="sec007">
<title>Variables</title>
<p>Variables in the model can be grouped into three sets. The first set is structured around variable <italic>M</italic>, which represents the set of motor commands that drive speech gestures. Associated to this variable are two “sensory-motor” variables, <italic>A</italic><sub><italic>M</italic></sub> and <italic>S</italic><sub><italic>M</italic></sub>, which represent respectively the expected auditory and somatosensory consequences of motor commands <italic>M</italic>. As stated previously, both motor and sensory-motor variables are assumed to be one-dimensional continuous variables.</p>
<p>The second set is structured around variable Φ, which represents the units of speech to be produced or perceived. As stated previously, we only consider vowels /i/, /ɛ/ and /a/. Associated to variable Φ are two “sensory-phonological” variables, <italic>A</italic><sub>Φ</sub> and <italic>S</italic><sub>Φ</sub>, which characterize these speech units in auditory and somatosensory terms respectively. As for sensory-motor variables, sensory-phonological variables are assumed to be one-dimensional continuous variables.</p>
<p>The last set of variables link sensory-phonological and sensory-motor variables. <italic>C</italic><sub><italic>A</italic></sub> and <italic>C</italic><sub><italic>S</italic></sub> are two coherence variables, which are “probabilistic connectors” between variables <italic>A</italic><sub><italic>M</italic></sub> and <italic>A</italic><sub>Φ</sub>, for <italic>C</italic><sub><italic>A</italic></sub>, and between variables <italic>S</italic><sub><italic>M</italic></sub> and <italic>S</italic><sub>Φ</sub>, for <italic>C</italic><sub><italic>S</italic></sub>. These connectors can be either left “open”, in which case the variables they link are mathematically independent, or “closed”, in which case the variables they link are forced to have the same value by a matching constraint. As such, these coherence variables can be interpreted as a “mathematical trick” to implement Bayesian switches [<xref ref-type="bibr" rid="pcbi.1005942.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref036">36</xref>] controlling the propagation of information in the model.</p>
</sec>
<sec id="sec008">
<title>Dependencies: Decomposition of the joint probability distribution</title>
<p>The joint probability distribution is decomposed as a product of elementary terms:
<disp-formula id="pcbi.1005942.e001"><alternatives><graphic id="pcbi.1005942.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mi>M</mml:mi> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>S</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="center"><mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>M</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>M</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>M</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>S</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
This decomposition, illustrated in <xref ref-type="fig" rid="pcbi.1005942.g002">Fig 2</xref>, relies on a certain number of conditional independence hypotheses that we do not discuss here (but see Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s001">S1 Text</xref> for details).</p>
</sec>
<sec id="sec009">
<title>Parametric forms</title>
<p>We now define each probability distribution of <xref ref-type="disp-formula" rid="pcbi.1005942.e001">Eq (1)</xref>. Concerning prior distributions <italic>P</italic>(<italic>M</italic>) and <italic>P</italic>(Φ), we assume no prior knowledge concerning values of variables <italic>M</italic> and Φ. Therefore, we identify <italic>P</italic>(<italic>M</italic>) and <italic>P</italic>(Φ) with uniform distributions.</p>
<p><italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>) and <italic>P</italic>(<italic>S</italic><sub><italic>M</italic></sub> | <italic>M</italic>) represent knowledge relating motor commands to their predicted sensory consequences. They correspond to sensory-motor internal forward models often assumed to be involved in motor planning [<xref ref-type="bibr" rid="pcbi.1005942.ref037">37</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref039">39</xref>] (but see [<xref ref-type="bibr" rid="pcbi.1005942.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref041">41</xref>] for debates). As explained in Section “Selected aspects for modeling”, for the sake of computational simplicity, we assume that these stored relations are linear. The corresponding auditory-motor and somatosensory-motor mappings, <italic>ρ</italic><sub><italic>A</italic></sub>(<italic>m</italic>) and <italic>ρ</italic><sub><italic>S</italic></sub>(<italic>m</italic>), are defined as follows:
<disp-formula id="pcbi.1005942.e002"><alternatives><graphic id="pcbi.1005942.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>m</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>.</mml:mo> <mml:mi>m</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>β</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula> <disp-formula id="pcbi.1005942.e003"><alternatives><graphic id="pcbi.1005942.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>m</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>.</mml:mo> <mml:mi>m</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>β</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where values of parameters <italic>α</italic><sub><italic>A</italic></sub>, <italic>α</italic><sub><italic>S</italic></sub>, <italic>β</italic><sub><italic>A</italic></sub> and <italic>β</italic><sub><italic>S</italic></sub> depend on further hypotheses that will be specified in Section “Implementation of the experimental paradigm: Normal vs. adapted conditions”. Finally, we further assume that the stored sensory-motor internal models have infinite precision and are therefore deterministic, such that <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>) and <italic>P</italic>(<italic>S</italic><sub><italic>M</italic></sub> | <italic>M</italic>) are identified with Dirac delta functions:
<disp-formula id="pcbi.1005942.e004"><alternatives><graphic id="pcbi.1005942.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mi>M</mml:mi> <mml:mo>=</mml:mo> <mml:mi>m</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>m</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula> <disp-formula id="pcbi.1005942.e005"><alternatives><graphic id="pcbi.1005942.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mi>M</mml:mi> <mml:mo>=</mml:mo> <mml:mi>m</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>m</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula></p>
<p><italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ) and <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ) correspond to the auditory and somatosensory characterizations of phonemes. As it is common in other modeling studies [<xref ref-type="bibr" rid="pcbi.1005942.ref042">42</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref046">46</xref>], we identify them with Gaussian distributions specified by their means and standard-deviations <inline-formula id="pcbi.1005942.e006"><alternatives><graphic id="pcbi.1005942.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e007"><alternatives><graphic id="pcbi.1005942.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> for each phoneme <italic>ϕ</italic> in auditory and somatosensory terms. Values of parameters <inline-formula id="pcbi.1005942.e008"><alternatives><graphic id="pcbi.1005942.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e009"><alternatives><graphic id="pcbi.1005942.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> depend on further hypotheses and will be specified in Section “Implementation of the experimental paradigm: Normal vs. adapted conditions” and “Update of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>)”.</p>
<p><italic>P</italic>(<italic>C</italic><sub><italic>A</italic></sub> | <italic>A</italic><sub><italic>M</italic></sub> <italic>A</italic><sub>Φ</sub>) and <italic>P</italic>(<italic>C</italic><sub><italic>S</italic></sub> | <italic>S</italic><sub><italic>M</italic></sub> <italic>S</italic><sub>Φ</sub>) implement the sensory matching constraints relating sensory-motor and sensory-phonological variables in the following way:
<disp-formula id="pcbi.1005942.e010"><alternatives><graphic id="pcbi.1005942.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mrow><mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/></mml:mrow> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>ϕ</mml:mi></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>a</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>ϕ</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd> <mml:mtd columnalign="left"><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable> <mml:mo/></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula> <disp-formula id="pcbi.1005942.e011"><alternatives><graphic id="pcbi.1005942.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>ϕ</mml:mi></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>s</mml:mi> <mml:mi>m</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>ϕ</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd> <mml:mtd columnalign="left"><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable> <mml:mo/></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula></p>
</sec>
</sec>
<sec id="sec010">
<title>Formulation of speech production and perception questions</title>
<p>In the previous section we proposed a computational definition of the joint probability distribution of the model. This definition was based on particular assumptions concerning relations between variables. The Bayesian formalism allows to simulate speech production and perception by defining and computing probability distributions of interest, that we call “questions”.</p>
<sec id="sec011">
<title>Speech production questions</title>
<p>Speech production questions correspond to the inference of motor commands for the production of a desired phoneme. The dependence structure of <xref ref-type="fig" rid="pcbi.1005942.g002">Fig 2</xref> shows that if coherence variables <italic>C</italic><sub><italic>A</italic></sub> and <italic>C</italic><sub><italic>S</italic></sub> are not assumed to be 1, that is to say, if they are “Bayesian switches” left open, there is no dependency between <italic>M</italic> and Φ, which would correspond to an unrealistic situation (see Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s002">S2 Text</xref> for further details). Instead, inferring motor commands for the production of a given phoneme with either variable <italic>C</italic><sub><italic>A</italic></sub> or variable <italic>C</italic><sub><italic>S</italic></sub> or both set to 1, leads to three planning processes that can be characterized as follows.</p>
<p>
<list list-type="order">
<list-item>
<p>The first planning process is based on the auditory pathway only and corresponds to:
<disp-formula id="pcbi.1005942.e012"><alternatives><graphic id="pcbi.1005942.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>P</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:mi>M</mml:mi> <mml:mo>=</mml:mo> <mml:mi>m</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">]</mml:mo> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>∝</mml:mo> <mml:mi>P</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>m</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula></p>
</list-item>
<list-item>
<p>The second planning process is based on the somatosensory pathway only and corresponds to:
<disp-formula id="pcbi.1005942.e013"><alternatives><graphic id="pcbi.1005942.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e013" xlink:type="simple"/><mml:math display="block" id="M13"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>P</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:mi>M</mml:mi> <mml:mo>=</mml:mo> <mml:mi>m</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">]</mml:mo> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:mo>∝</mml:mo> <mml:mi>P</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>m</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula></p>
</list-item>
<list-item>
<p>The third planning process is based on the fusion of auditory and somatosensory pathways and corresponds to:
<disp-formula id="pcbi.1005942.e014"><alternatives><graphic id="pcbi.1005942.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e014" xlink:type="simple"/><mml:math display="block" id="M14"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:mi>M</mml:mi> <mml:mo>=</mml:mo> <mml:mi>m</mml:mi> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo stretchy="false">]</mml:mo> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mo>∝</mml:mo> <mml:mi>P</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>m</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mi>P</mml:mi> <mml:mo stretchy="false">(</mml:mo> <mml:mo stretchy="false">[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo stretchy="false">(</mml:mo> <mml:mi>m</mml:mi> <mml:mo stretchy="false">)</mml:mo> <mml:mo stretchy="false">]</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mo stretchy="false">)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula></p>
</list-item>
</list>
These equations are obtained by the application of Bayesian inference rules to the joint probability distribution given by <xref ref-type="disp-formula" rid="pcbi.1005942.e001">Eq (1)</xref>. Derivations are provided in Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s002">S2 Text</xref>. All terms on the right hand sides of Eqs <xref ref-type="disp-formula" rid="pcbi.1005942.e012">(8)</xref>, <xref ref-type="disp-formula" rid="pcbi.1005942.e013">(9)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005942.e014">(10)</xref> were defined in Section “Parametric forms”.</p>
<p>The probability of selecting a particular motor command <italic>m</italic> is hence proportional to the probability that the predicted sensory consequences of <italic>m</italic> (expressed by <italic>ρ</italic><sub><italic>A</italic></sub>(<italic>m</italic>) and <italic>ρ</italic><sub><italic>S</italic></sub>(<italic>m</italic>) in auditory and somatsoensory terms) are in agreement with the sensory characterization of the intended phoneme in the corresponding sensory pathway.</p>
</sec>
<sec id="sec012">
<title>Speech perception questions</title>
<p>Perception questions correspond to the categorization of auditory inputs into phoneme identity. We consider that the perceived auditory stimulus is a value of the auditory-motor variable <italic>A</italic><sub><italic>M</italic></sub>. Similar to the previous production questions, we can define three categorization questions depending on the activation of variables <italic>C</italic><sub><italic>A</italic></sub> or <italic>C</italic><sub><italic>S</italic></sub>.</p>
<list list-type="order">
<list-item>
<p>The assumption that categorization is based only on the auditory pathway (as in auditory theories of speech perception) corresponds to:
<disp-formula id="pcbi.1005942.e015"><alternatives><graphic id="pcbi.1005942.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr> <mml:mtd columnalign="right"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:msup><mml:mi>ϕ</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mi>ϕ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula></p>
</list-item>
<list-item>
<p>The assumption that categorization is based only on the somatosensory pathway (as in the direct realist theory [<xref ref-type="bibr" rid="pcbi.1005942.ref047">47</xref>]) corresponds to:
<disp-formula id="pcbi.1005942.e016"><alternatives><graphic id="pcbi.1005942.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e016" xlink:type="simple"/><mml:math display="block" id="M16"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr> <mml:mtd columnalign="center"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>∘</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:msup><mml:mi>ϕ</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>∘</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mi>ϕ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula></p>
</list-item>
<list-item>
<p>The assumption that categorization is based on the fusion of both auditory and somatosensory pathways (as in perceptuo-motor theories [<xref ref-type="bibr" rid="pcbi.1005942.ref008">8</xref>]) corresponds to:
<disp-formula id="pcbi.1005942.e017"><alternatives><graphic id="pcbi.1005942.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>∘</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:msup><mml:mi>ϕ</mml:mi> <mml:mo>′</mml:mo></mml:msup></mml:msub> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mi>ϕ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mo>Φ</mml:mo></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>∘</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mi>ϕ</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula></p>
</list-item>
</list>
<p>The symbol ∘ in Eqs <xref ref-type="disp-formula" rid="pcbi.1005942.e016">(12)</xref> and <xref ref-type="disp-formula" rid="pcbi.1005942.e017">(13)</xref> denotes the composition operator, and therefore <inline-formula id="pcbi.1005942.e018"><alternatives><graphic id="pcbi.1005942.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:msub><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>∘</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> corresponds to the somatosensory image of the auditory value <italic>a</italic> as obtained first by the identification of motor commands <italic>m</italic> achieving the production of <italic>a</italic> (<inline-formula id="pcbi.1005942.e019"><alternatives><graphic id="pcbi.1005942.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:mi>m</mml:mi> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>) and then by the prediction of the somatosensory variable <italic>s</italic> generated from the inferred motor commands (<italic>s</italic> = <italic>ρ</italic><sub><italic>S</italic></sub>(<italic>m</italic>)). Solutions for these three inference questions are obtained from the joint probability distribution given by <xref ref-type="disp-formula" rid="pcbi.1005942.e001">Eq (1)</xref>. Details of the derivation are provided in Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s002">S2 Text</xref>.</p>
<p>These equations express the way Bayesian computation yields categorization processes from the structure and knowledge encoded in the model. Under the auditory pathway case, the probability of categorizing an auditory input <italic>a</italic> into phoneme <italic>ϕ</italic> is obtained by evaluating the probability that this auditory input would correspond to the auditory characterization of the considered phoneme (<italic>P</italic>([<italic>A</italic><sub>Φ</sub> = <italic>a</italic>] | [Φ = <italic>ϕ</italic>]) in the numerator), and comparing it to the probability that it would correspond to the auditory characterization of any of the possible phonemes (the sum over <italic>ϕ</italic>′ on the denominator). When this ratio is close to 1, the auditory value is categorized as phoneme <italic>ϕ</italic> with full certainty. The smaller the ratio, the lower the probability of this categorization.</p>
<p>Consider, for instance, the case of the categorization of an auditory input <italic>a</italic> into the phoneme /i/ (among the three vowels /i, ɛ, a/ in our example) as given by <xref ref-type="disp-formula" rid="pcbi.1005942.e015">Eq (11)</xref>. Replacing <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ) with their definition as Gaussian probability distributions yields:
<disp-formula id="pcbi.1005942.e020"><alternatives><graphic id="pcbi.1005942.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>Φ</mml:mo> <mml:mo>=</mml:mo> <mml:mo>/</mml:mo> <mml:mtext>i</mml:mtext> <mml:mo>/</mml:mo> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr> <mml:mtd columnalign="center"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msubsup></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup> <mml:mrow><mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>i</mml:mi></mml:msubsup></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϵ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϵ</mml:mi></mml:msubsup></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>a</mml:mi> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>a</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>a</mml:mi></mml:msubsup></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
This function is illustrated in <xref ref-type="fig" rid="pcbi.1005942.g003">Fig 3</xref> for parameter values in the normal condition, as specified in Section “Normal condition: Initial values of parameters”. The corresponding categorization functions under the somatosensory and fusion of pathways are derived essentially in the same way.</p>
<fig id="pcbi.1005942.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Auditory characterizations and corresponding phoneme categorization functions.</title>
<p>Top panel: auditory characterization, <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ), for phoneme /i/ (red), phoneme /ɛ/ (green) and phoneme /a/ (blue). Bottom panel: categorization functions under the auditory pathway approach, <italic>P</italic>(Φ | <italic>A</italic><sub><italic>M</italic></sub> [<italic>C</italic><sub><italic>A</italic></sub> = 1]), obtained from auditory characterizations according to <xref ref-type="disp-formula" rid="pcbi.1005942.e015">Eq (11)</xref>. <xref ref-type="disp-formula" rid="pcbi.1005942.e020">Eq (14)</xref> gives the explicit form for phoneme /i/.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec013">
<title>Selection of production and perception questions</title>
<p>We have derived 3 perception and 3 production questions that differ with respect to the sensory pathways assumed to be involved in these processes. For the sake of brevity, we limit the presentation of simulations and do not consider the outcome of all of the 9 combinations of questions, in order to focus on those that correspond to the richest scientific contributions. Therefore, as pointed out in Section “Selected aspects for modeling”, concerning production we consider only the question assuming the fusion of auditory and somatosensory pathways, <italic>P</italic>(<italic>M</italic> | Φ [<italic>C</italic><sub><italic>A</italic></sub> = 1] [<italic>C</italic><sub><italic>S</italic></sub> = 1]). Concerning perception we keep and compare questions assuming the involvement of the auditory pathway alone, <italic>P</italic>(Φ | <italic>A</italic><sub><italic>M</italic></sub> [<italic>C</italic><sub><italic>A</italic></sub> = 1]), and the fusion of sensory pathways, <italic>P</italic>(Φ | <italic>A</italic><sub><italic>M</italic></sub> [<italic>C</italic><sub><italic>A</italic></sub> = 1] [<italic>C</italic><sub><italic>S</italic></sub> = 1]).</p>
<p>In order to simplify notations, we denote the selected production and perception questions by:
<disp-formula id="pcbi.1005942.e021"><alternatives><graphic id="pcbi.1005942.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e021" xlink:type="simple"/><mml:math display="block" id="M21"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:mtd> <mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mi>M</mml:mi> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>Φ</mml:mo> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:mtd> <mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mo>Φ</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:mtd> <mml:mtd><mml:mo>≔</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mo>Φ</mml:mo> <mml:mspace width="3.33333pt"/><mml:mo>|</mml:mo> <mml:mspace width="3.33333pt"/><mml:msub><mml:mi>A</mml:mi> <mml:mi>M</mml:mi></mml:msub> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mspace width="3.33333pt"/><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>S</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
</sec>
</sec>
<sec id="sec014">
<title>Implementation of the experimental paradigm: Normal vs. adapted conditions</title>
<p>Our aim is to simulate and compare the outcome of the production and perception tests in L-14, prior to the auditory perturbation and after the training phase, i.e. when perturbation is removed and adaptation has been reached. These tests are naturally implemented in the model as the outcome of the production and perception questions defined in the previous section.</p>
<p>Adaptation is implemented as the update of a part of the knowledge included in the model. This knowledge is represented by the four relations defined in Section “Parametric forms”: the two sensory-motor internal models, <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>) and <italic>P</italic>(<italic>S</italic><sub><italic>M</italic></sub> | <italic>M</italic>), and the two sensory characterizations of phonemes, <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ) and <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ). In this context, normal and adapted conditions are implemented by different values of the parameters characterizing these relations. Values of parameters in normal condition are arbitrary initial values. This is why we chose them to be as simple as possible. They are specified in Section “Normal condition: Initial values of parameters”.</p>
<p>Two fundamental questions remain to be answered in order to specify how adaptation will affect these initial values: (1) which of the four relations is changed during adaptation, and (2) how? The first question actually rephrases in computational terms the question raised in L-14 (p 10339), and quoted in its original formulation in Section “Influence of motor learning upon speech perception: overview of experimental facts”, extending it to behavioral changes in both production and perception: “So what produces the [behavioral changes] during motor learning? Is it the change to [parameters of the sensory-motor internal models], that occurs during learning? Is it changes to [parameters of the sensory characterizations of phonemes], related to the altered sensory inputs? Or is it some combination of the two?”.</p>
<p>In the following sections, we address these two questions in two steps. In Section “Adaptation hypotheses” we partially answer the first question by motivating the selection of a subset of possible changes induced by adaptation. In Section “Results” we further answer these questions by evaluating the outcome of different implementations of the selected changes and by comparing them with the experimental facts summarized in Section “Summary of experimental results we aim at modeling”.</p>
<sec id="sec015">
<title>Normal condition: Initial values of parameters</title>
<p>We now specify parameters of the two sensory-motor internal models, <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>) and <italic>P</italic>(<italic>S</italic><sub><italic>M</italic></sub> | <italic>M</italic>), and the two sensory characterizations of phonemes, <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ) and <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ).</p>
<p>The two sensory-motor internal models are defined in terms of auditory-motor and somatosensory-motor mappings <italic>ρ</italic><sub><italic>A</italic></sub> and <italic>ρ</italic><sub><italic>S</italic></sub>, which are characterized by parameters <italic>α</italic><sub><italic>A</italic></sub>, <italic>β</italic><sub><italic>A</italic></sub> and <italic>α</italic><sub><italic>S</italic></sub>, <italic>β</italic><sub><italic>S</italic></sub>. Without loss of generality, we define metric units of motor and sensory spaces in order to have <italic>α</italic><sub><italic>A</italic></sub> = <italic>α</italic><sub><italic>S</italic></sub> = 1 and <italic>β</italic><sub><italic>A</italic></sub> = <italic>β</italic><sub><italic>S</italic></sub> = 0 in normal condition. Therefore, with <inline-formula id="pcbi.1005942.e022"><alternatives><graphic id="pcbi.1005942.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>n</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e023"><alternatives><graphic id="pcbi.1005942.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>n</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> being the auditory-motor and somatosensory-motor mappings in normal conditions respectively, we have:
<disp-formula id="pcbi.1005942.e024"><alternatives><graphic id="pcbi.1005942.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>m</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>m</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula> <disp-formula id="pcbi.1005942.e025"><alternatives><graphic id="pcbi.1005942.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>m</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>m</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
The left panels of <xref ref-type="fig" rid="pcbi.1005942.g004">Fig 4</xref> illustrate these sensory-motor mappings.</p>
<fig id="pcbi.1005942.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Stored sensory-motor mappings and sensory characterizations of phonemes under normal conditions.</title>
<p>Left panels: auditory-motor internal mapping <inline-formula id="pcbi.1005942.e029"><alternatives><graphic id="pcbi.1005942.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>n</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (top) and somatosensory-motor internal mapping <inline-formula id="pcbi.1005942.e030"><alternatives><graphic id="pcbi.1005942.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>n</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (bottom). Both mappings are assumed to be identity. Right panels: auditory (top) and somatosensory (bottom) characterization of phonemes. Probability distributions are all Gaussian, evenly distributed in each space, and with equal standard-deviations, equal to <inline-formula id="pcbi.1005942.e031"><alternatives><graphic id="pcbi.1005942.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>8</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> of the distance between phonemes.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g004" xlink:type="simple"/>
</fig>
<p>The two sensory characterizations of phonemes are defined as Gaussian probability distributions with means and standard-deviations, <inline-formula id="pcbi.1005942.e026"><alternatives><graphic id="pcbi.1005942.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e027"><alternatives><graphic id="pcbi.1005942.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>For the sake of simplicity, we assume that in normal condition these sensory characterizations are evenly distributed in both sensory spaces with the same standard-deviations equal to <inline-formula id="pcbi.1005942.e028"><alternatives><graphic id="pcbi.1005942.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>8</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> of the distance between neighboring phonemes (see Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s004">S4 Text</xref> for further details). The right panels of <xref ref-type="fig" rid="pcbi.1005942.g004">Fig 4</xref> illustrate the corresponding probability distributions.</p>
<p>Since the model is now completely defined in normal conditions, we can study the outcome of the production and perception questions, which correspond to production and perception pretests in L-14. The corresponding functions are displayed in <xref ref-type="fig" rid="pcbi.1005942.g005">Fig 5</xref>.</p>
<fig id="pcbi.1005942.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Outcome of the production question (left panel) and perception questions (right panels) under normal conditions.</title>
<p>The categorization function corresponding to vowel /ɛ/ is not represented for clarity of the figure and since it corresponds to the complementary of the two other curves (as it can be seen in the bottom panel of <xref ref-type="fig" rid="pcbi.1005942.g003">Fig 3</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g005" xlink:type="simple"/>
</fig>
<p>Concerning production, <xref ref-type="disp-formula" rid="pcbi.1005942.e014">Eq (10)</xref> indicates that the outcome of the planning process is a product of two Gaussian probability distributions. The product is known to result into a new Gaussian probability distribution with smaller variance [<xref ref-type="bibr" rid="pcbi.1005942.ref048">48</xref>], as it can be seen in the left panel displayed in <xref ref-type="fig" rid="pcbi.1005942.g005">Fig 5</xref>.</p>
<p>Concerning perception, the outcome of the two perception processes corresponds to categorization functions with the same positions of the boundaries, but with boundary slopes that are different. In this context, the fusion of sensory pathways results in a steeper slope than the auditory pathway alone.</p>
</sec>
<sec id="sec016">
<title>Adaptation hypotheses</title>
<p>We focus now on the adapted state. Which of the two sensory-motor internal models, <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>) and <italic>P</italic>(<italic>S</italic><sub><italic>M</italic></sub> | <italic>M</italic>), or the two sensory characterizations of phonemes, <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ) and <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ) is being updated during the training phase? We consider that any of these relations may be updated if the perturbation introduced during the training phase leads to considering that they are no longer correct.</p>
<p>Since the perturbation of the auditory feedback only affects the relation between motor commands and auditory outputs, we do not introduce any change to the somatosensory-motor internal model, <italic>P</italic>(<italic>S</italic><sub><italic>M</italic></sub> | <italic>M</italic>), but we assume that the auditory-motor internal model, <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>), may be updated in order to learn the new auditory-motor relation.</p>
<p>The auditory perturbation also induces a mismatch between the perturbed auditory output and the learned phoneme characterization <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ). This mismatch can be resolved by an update of the auditory-motor internal model alone, <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>), so that under the perturbed condition new motor commands are associated to the usual auditory region characterizing the produced phoneme. However, modifying the auditory characterization of phonemes, <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ), may also contribute to the reduction of this mismatch. In S-09 the reported results were interpreted as a combination of these two hypotheses. The authors suggested that “speech adaptation to altered auditory feedback is not limited to the motor domain, but rather involves changes in both motor output and auditory representations of speech sounds that together act to reduce the impact of the perturbation” [<xref ref-type="bibr" rid="pcbi.1005942.ref002">2</xref>, p 1103, abstract]. In other words, subjects could reduce the impact of the perturbation by changing the motor commands associated to the production of the phoneme, but also by modifying their stored auditory characterizations of speech sounds. Furthermore, as in L-14 we only focus on the perturbation of vowel /ɛ/. Hence, among the stored auditory characterizations we consider that only <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]), corresponding to vowel /ɛ/, may be updated.</p>
<p>The motor command change resulting from the compensation for the auditory perturbation also induces a somatosensory mismatch. Indeed, somatosensory values resulting from compensation deviate from the stored somatosensory characterization of the intended phoneme. Therefore, once the compensation for the auditory perturbation starts to be efficient, the stored somatosensory characterization of the intended phoneme, <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ), may also change in order to match the new somatosensory patterns associated with the modified articulation. Furthermore, since we only focus on the perturbation of vowel /ɛ/, we consider that among the stored somatosensory characterizations only <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | [Φ = /ɛ/]) may be updated.</p>
<p>In summary, we retain three possible changes that may be induced by motor adaptation:</p>
<list list-type="order">
<list-item>
<p>An update of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>);</p>
</list-item>
<list-item>
<p>An update of the auditory characterization of the perturbed vowel <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]);</p>
</list-item>
<list-item>
<p>An update of the somatosensory characterization of the perturbed vowel <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | [Φ = /ɛ/]).</p>
</list-item>
</list>
<p>These three possible changes result in 7 possible adaptation hypotheses, depending on whether we combine one, two or the three of them.</p>
<p>Section “Results” aims to evaluate which of these adaptation hypotheses may account for the experimental facts reported in L-14. This evaluation is performed by comparing the consequences of each hypothesis with respect to compensation and perceptual boundary shift as reported in Section “Summary of experimental results we aim at modeling”.</p>
<p>We assess the direction and amount of compensation via the displacement of the motor planning distribution <inline-formula id="pcbi.1005942.e032"><alternatives><graphic id="pcbi.1005942.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> associated with /ɛ/ in the motor command space. We evaluate the amount of perceptual boundary shift via the displacement of the point where the categorization function <inline-formula id="pcbi.1005942.e033"><alternatives><graphic id="pcbi.1005942.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> or <inline-formula id="pcbi.1005942.e034"><alternatives><graphic id="pcbi.1005942.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> takes value <inline-formula id="pcbi.1005942.e035"><alternatives><graphic id="pcbi.1005942.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>.</p>
<p>Finally, since the behavior of the model is symmetric around vowel /ɛ/, we focus only on the case of a perturbation in the direction of vowel /a/ (left panel of <xref ref-type="fig" rid="pcbi.1005942.g001">Fig 1</xref>). All simulations are therefore performed assuming a perturbation with a magnitude of 40% of the distance between neighboring phonemes and in the direction of vowel /a/.</p>
</sec>
</sec>
</sec>
<sec id="sec017" sec-type="results">
<title>Results</title>
<p>The primary goal of this section is to evaluate which of the 7 adaptation hypotheses account for the experimental facts reported in L-14. To do so, we proceed sequentially: we first focus on perception and evaluate results corresponding to the two categorization questions <inline-formula id="pcbi.1005942.e036"><alternatives><graphic id="pcbi.1005942.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e037"><alternatives><graphic id="pcbi.1005942.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. For the hypotheses that are compatible with the perceptual boundary shift observed in L-14, the associated compensation in production is evaluated, and again only the hypotheses that are compatible with the results of L-14 are kept. Finally, in a third step, we further evaluate the selected adaptation hypotheses with respect to the corresponding correlations between the amount of compensation in production and the magnitude of perceptual boundary shift.</p>
<sec id="sec018">
<title>Evaluation with respect to perception</title>
<sec id="sec019">
<title>Update of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>)</title>
<p>We begin by considering the consequences of an update of the auditory-motor internal forward model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>) (see <xref ref-type="fig" rid="pcbi.1005942.g006">Fig 6</xref>) characterized by the mapping <italic>ρ</italic><sub><italic>A</italic></sub>(<italic>m</italic>) and parameters <italic>α</italic><sub><italic>A</italic></sub> and <italic>β</italic><sub><italic>A</italic></sub> (see <xref ref-type="disp-formula" rid="pcbi.1005942.e002">Eq (2)</xref>).</p>
<fig id="pcbi.1005942.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Changes in perception questions resulting from updates of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>).</title>
<p>Left panels: general update. Right panels: local update. Yellow panels represent the auditory-motor mapping before (solid lines) and after update (dashed lines). The magnitude and direction of update is equal to the assumed perturbation magnitude. Green panels represent the outcome of the two perception questions in normal (solid lines) vs. adapted conditions (dashed lines). Only categorization functions for vowel /i/ (red plots) and /a/ (blue plots) are displayed (categorization function for vowel /ɛ/ being complementary to the two others). The direction and magnitude of the perturbation is indicated by the horizontal arrow.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g006" xlink:type="simple"/>
</fig>
<p>Since the perturbation corresponds to a constant shift <italic>δ</italic><sub><italic>A</italic></sub> in auditory space, a straightforward update of the auditory-motor mapping induced by training under the perturbed condition, <inline-formula id="pcbi.1005942.e038"><alternatives><graphic id="pcbi.1005942.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, can be obtained from the mapping in normal condition, <inline-formula id="pcbi.1005942.e039"><alternatives><graphic id="pcbi.1005942.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, as:
<disp-formula id="pcbi.1005942.e040"><alternatives><graphic id="pcbi.1005942.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>m</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>m</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>m</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>δ</mml:mi> <mml:mi>A</mml:mi></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
that is to say, parameter <italic>α</italic><sub><italic>A</italic></sub> in <xref ref-type="disp-formula" rid="pcbi.1005942.e002">Eq (2)</xref> remains unchanged (value 1) and <italic>β</italic><sub><italic>A</italic></sub> is updated by the amount of shift <italic>δ</italic><sub><italic>A</italic></sub>.</p>
<p>This first implementation corresponds to a general update of the internal model, which is not limited to the domain of variation of the motor commands experienced by the subject during the perturbation experiment. Assuming such a generalization is a strong hypothesis that has been questioned in different experimental studies (including in speech [<xref ref-type="bibr" rid="pcbi.1005942.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref050">50</xref>], and in arm movements [<xref ref-type="bibr" rid="pcbi.1005942.ref051">51</xref>]). Consequently, we also consider a second, more local, update of the internal model that is limited to the range of motor commands experienced by the subject when speaking with the perturbation. We will compare the predictions of these two assumptions on the two perception questions.</p>
<p>We begin by considering the general update hypothesis. The left panels of <xref ref-type="fig" rid="pcbi.1005942.g006">Fig 6</xref> present the outcome for the perception questions, under the auditory pathway hypothesis <inline-formula id="pcbi.1005942.e041"><alternatives><graphic id="pcbi.1005942.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and under the fusion of sensory pathways hypothesis <inline-formula id="pcbi.1005942.e042"><alternatives><graphic id="pcbi.1005942.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, assuming the general update of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>). We firstly observe that updating the auditory-motor internal model results in no change in the categorization process under the auditory pathway <inline-formula id="pcbi.1005942.e043"><alternatives><graphic id="pcbi.1005942.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, consistent with <xref ref-type="disp-formula" rid="pcbi.1005942.e015">Eq (11)</xref> in which only <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ) is involved.</p>
<p>In addition, we observe a perceptual boundary shift under the fusion of pathways <inline-formula id="pcbi.1005942.e044"><alternatives><graphic id="pcbi.1005942.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. This is consistent with <xref ref-type="disp-formula" rid="pcbi.1005942.e017">Eq (13)</xref> where the auditory categorization under the fusion of sensory pathways involves the inverse of the auditory-motor mapping, <inline-formula id="pcbi.1005942.e045"><alternatives><graphic id="pcbi.1005942.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, that has been updated. Importantly, it should be noted that the direction of perceptual boundary shifts (from the solid to the dotted line) is the same as the direction of the perturbation (horizontal arrow). This is consistent with the findings reported in S-09 and L-14. However, we notice that boundary shifts are present on both sides of vowel /ɛ/ in the auditory space, contrary to the asymmetry reported in L-14.</p>
<p>Let us consider now the local update hypothesis. The right panels of <xref ref-type="fig" rid="pcbi.1005942.g006">Fig 6</xref> present the outcome for the perception questions, <inline-formula id="pcbi.1005942.e046"><alternatives><graphic id="pcbi.1005942.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e047"><alternatives><graphic id="pcbi.1005942.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, assuming a local update of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>). Details about the specification of this local update are provided in Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s003">S3 Text</xref>.</p>
<p>The main results are consistent with those of the general update, except that the perceptual boundary shift observed under the fusion of pathways is now restricted to the region of the auditory space associated with the interval of the motor commands space where the internal model was updated, i.e. in the domain located between /i/ and /ɛ/. The resulting asymmetry is in agreement with the observations reported by L-14. However, it is important to specify that the magnitude of the shift as well as the characteristics of the asymmetry are sensitive to the choice of the parameters determining the local update of the internal model. Here, parameters implement the hypothesis that learning is limited to a portion of motor space consistent with what subjects may have explored when speaking with the perturbation.</p>
</sec>
<sec id="sec020">
<title>Update of the auditory characterization <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ)</title>
<p>The auditory characterization of phonemes, <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ), was identified, in Section “Parametric forms”, with Gaussian distributions with parameters <inline-formula id="pcbi.1005942.e048"><alternatives><graphic id="pcbi.1005942.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>ϕ</italic> indicates the considered phoneme. In the present case, we are interested in the auditory characterization of phoneme /ɛ/, that is, in the Gaussian distribution <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]) with parameters <inline-formula id="pcbi.1005942.e049"><alternatives><graphic id="pcbi.1005942.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e049" xlink:type="simple"/><mml:math display="inline" id="M49"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. We consider adaptation to the auditory perturbation that moves /ɛ/ toward /a/ and assume that it may update either <inline-formula id="pcbi.1005942.e050"><alternatives><graphic id="pcbi.1005942.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> or <inline-formula id="pcbi.1005942.e051"><alternatives><graphic id="pcbi.1005942.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> or both. Updating <inline-formula id="pcbi.1005942.e052"><alternatives><graphic id="pcbi.1005942.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> modifies the location of the Gaussian, whereas updating <inline-formula id="pcbi.1005942.e053"><alternatives><graphic id="pcbi.1005942.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e053" xlink:type="simple"/><mml:math display="inline" id="M53"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> modifies its width. We will first evaluate the effect induced by an update of each parameter independently, and then consider a combined update.</p>
<p>The top panel of <xref ref-type="fig" rid="pcbi.1005942.g007">Fig 7</xref> present the outcome of the two perception questions <inline-formula id="pcbi.1005942.e054"><alternatives><graphic id="pcbi.1005942.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e054" xlink:type="simple"/><mml:math display="inline" id="M54"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e055"><alternatives><graphic id="pcbi.1005942.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e055" xlink:type="simple"/><mml:math display="inline" id="M55"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> after a shift of <inline-formula id="pcbi.1005942.e056"><alternatives><graphic id="pcbi.1005942.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> in the direction of vowel /a/. The middle panels of <xref ref-type="fig" rid="pcbi.1005942.g007">Fig 7</xref> illustrate the outcome of the two perception questions resulting from a reduction of <inline-formula id="pcbi.1005942.e057"><alternatives><graphic id="pcbi.1005942.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>.</p>
<fig id="pcbi.1005942.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Changes in perception questions resulting from different updates of the auditory characterization of the perturbed vowel, <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]).</title>
<p>Top and middle panels correspond to independent updates of the mean <inline-formula id="pcbi.1005942.e058"><alternatives><graphic id="pcbi.1005942.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and the standard deviation <inline-formula id="pcbi.1005942.e059"><alternatives><graphic id="pcbi.1005942.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e059" xlink:type="simple"/><mml:math display="inline" id="M59"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> respectively. Bottom panels correspond to a combined shift of <inline-formula id="pcbi.1005942.e060"><alternatives><graphic id="pcbi.1005942.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and reduction of <inline-formula id="pcbi.1005942.e061"><alternatives><graphic id="pcbi.1005942.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e061" xlink:type="simple"/><mml:math display="inline" id="M61"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>. The outcome of simulations before update (solid lines) are superimposed to those after update (dashed lines).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g007" xlink:type="simple"/>
</fig>
<p>We observe that modifying parameters <inline-formula id="pcbi.1005942.e062"><alternatives><graphic id="pcbi.1005942.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e062" xlink:type="simple"/><mml:math display="inline" id="M62"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e063"><alternatives><graphic id="pcbi.1005942.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e063" xlink:type="simple"/><mml:math display="inline" id="M63"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> induces changes in auditory categorization both with the auditory pathway only <inline-formula id="pcbi.1005942.e064"><alternatives><graphic id="pcbi.1005942.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e064" xlink:type="simple"/><mml:math display="inline" id="M64"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and with the fusion of sensory pathways <inline-formula id="pcbi.1005942.e065"><alternatives><graphic id="pcbi.1005942.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. However, the perceptual changes vary according to the parameter that is modified. Shifting parameter <inline-formula id="pcbi.1005942.e066"><alternatives><graphic id="pcbi.1005942.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> (top panel) induces a shift of <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]), resulting in a boundary shift that is similar on both sides of /ɛ/ along the auditory continuum and goes in the same direction as the shift in location of <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]). Reducing parameter <inline-formula id="pcbi.1005942.e067"><alternatives><graphic id="pcbi.1005942.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e067" xlink:type="simple"/><mml:math display="inline" id="M67"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> of <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]) (middle panel) induces boundary shifts that are in opposite direction on both sides of /ɛ/ along the auditory continuum. The boundaries follow the narrowing of <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]) on both sides, and get closer to the center of the Gaussian distribution characterizing /ɛ/.</p>
<p>Therefore, it appears that an adequate combination of <inline-formula id="pcbi.1005942.e068"><alternatives><graphic id="pcbi.1005942.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e069"><alternatives><graphic id="pcbi.1005942.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e069" xlink:type="simple"/><mml:math display="inline" id="M69"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> modifications may produce a pattern in agreement with the one observed by L-14, with a boundary shift in the direction of the perturbation, obtained just on the /ɛ/-/i/ side but not on the /ɛ/-/a/ side (see <xref ref-type="fig" rid="pcbi.1005942.g007">Fig 7</xref>, bottom panel). The relation between <inline-formula id="pcbi.1005942.e070"><alternatives><graphic id="pcbi.1005942.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e070" xlink:type="simple"/><mml:math display="inline" id="M70"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e071"><alternatives><graphic id="pcbi.1005942.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e071" xlink:type="simple"/><mml:math display="inline" id="M71"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> implemented in the simulations of <xref ref-type="fig" rid="pcbi.1005942.g007">Fig 7</xref> is provided in Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s004">S4 Text</xref>. Note that this relation has been specifically designed in order to reproduce the desired asymmetrical boundary shift, but we attach no claim of cognitive plausibility to this specific relation. We will discuss the theoretical implication of this ad-hoc choice in Section “Discussion”.</p>
</sec>
<sec id="sec021">
<title>Update of the somatosensory characterization <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ)</title>
<p>The somatosensory characterization of phonemes <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ) was identified with Gaussian distributions parameterized by <inline-formula id="pcbi.1005942.e072"><alternatives><graphic id="pcbi.1005942.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e072" xlink:type="simple"/><mml:math display="inline" id="M72"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. The articulatory changes enabling compensation for the perturbation during adaptation could generate an update of the somatosensory characterization of the produced phoneme in order to account for the somatosensory correlates corresponding to the new articulatory postures. For an auditory perturbation of vowel /ɛ/ toward /a/, the compensatory behavior leads to articulatory configurations closer to /i/. One would therefore expect a change of <inline-formula id="pcbi.1005942.e073"><alternatives><graphic id="pcbi.1005942.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e073" xlink:type="simple"/><mml:math display="inline" id="M73"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>S</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> in the direction of phoneme /i/.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005942.g008">Fig 8</xref> presents the outcome of the two perception questions <inline-formula id="pcbi.1005942.e074"><alternatives><graphic id="pcbi.1005942.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e074" xlink:type="simple"/><mml:math display="inline" id="M74"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e075"><alternatives><graphic id="pcbi.1005942.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> after a shift of <inline-formula id="pcbi.1005942.e076"><alternatives><graphic id="pcbi.1005942.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>S</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> in the direction of /i/. Plots are organized in the same manner as in previous Figures. The left panel illustrates the shift in location of the somatosensory characterization of phoneme /ɛ/ after training, once adaptation is achieved. We observe that the update of <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ) does not induce any change in perceptual categories under the auditory pathway hypothesis <inline-formula id="pcbi.1005942.e077"><alternatives><graphic id="pcbi.1005942.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. This is consistent with <xref ref-type="disp-formula" rid="pcbi.1005942.e015">Eq (11)</xref> where the somatosensory characterization <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ) is not involved. However, we observe a shift in auditory categorization under the fusion of pathways hypothesis <inline-formula id="pcbi.1005942.e078"><alternatives><graphic id="pcbi.1005942.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e078" xlink:type="simple"/><mml:math display="inline" id="M78"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. This again is consistent with <xref ref-type="disp-formula" rid="pcbi.1005942.e017">Eq (13)</xref> where the somatosensory characterization term <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ) is involved. It must be noted though, that the direction of the perceptual shift is opposite to the perturbation, contrary to the experimental findings reported in S-09 and L-14.</p>
<fig id="pcbi.1005942.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Changes in perception questions resulting from update of the somatosensory characterization of the perturbed vowel <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | [Φ = /ɛ/]).</title>
<p>The update corresponds to a shift of the mean value <inline-formula id="pcbi.1005942.e079"><alternatives><graphic id="pcbi.1005942.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e079" xlink:type="simple"/><mml:math display="inline" id="M79"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>S</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> in the direction of phoneme /i/, as would result from compensation to an auditory perturbation towards /a/ (horizontal arrow). The outcome of simulations before update (solid lines) are superimposed to those after update (dashed lines).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g008" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec022">
<title>Effects of combined update hypotheses</title>
<p>Until now we have only considered individual update hypotheses. The conclusion of these individual evaluations is that the local update of the auditory-motor internal model and the coordinated shift and narrowing of the auditory characterization of phoneme /ɛ/ are the only updates that correctly account for the experimental observations (direction of the shift of the boundaries between perceptual categories and asymmetry of the magnitude of the shift on both sides of vowel /ɛ/) in L-14. These updates are not exclusive and they could be involved simultaneously during adaptation. Hence, in this section we investigate the consequence for the perception questions of the combination of these two updates. Note that we are not discarding an additional update of the somatosensory characterization of phonemes in combination with the two other ones. It could be actually involved and result in a reduction of the perceptual shift induced by any of the two other hypotheses. Since this would only act as an amplification/reduction factor of the main phenomenon, we do not consider it in the remaining of this study.</p>
<p><xref ref-type="fig" rid="pcbi.1005942.g009">Fig 9</xref> presents the outcome of the two perception questions <inline-formula id="pcbi.1005942.e080"><alternatives><graphic id="pcbi.1005942.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e080" xlink:type="simple"/><mml:math display="inline" id="M80"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e081"><alternatives><graphic id="pcbi.1005942.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e081" xlink:type="simple"/><mml:math display="inline" id="M81"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> after combination of these update hypotheses. Plots are organized in the same manner as in previous Figures. The two left panels illustrate the changes of the auditory characterization of phoneme /ɛ/ (top) and the auditory-motor mapping (bottom). Consistent with the results presented in Figs <xref ref-type="fig" rid="pcbi.1005942.g006">6</xref> and <xref ref-type="fig" rid="pcbi.1005942.g007">7</xref>, we observe that after these two combined updates both the auditory and the sensory fusion accounts of perception, <inline-formula id="pcbi.1005942.e082"><alternatives><graphic id="pcbi.1005942.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e082" xlink:type="simple"/><mml:math display="inline" id="M82"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e083"><alternatives><graphic id="pcbi.1005942.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e083" xlink:type="simple"/><mml:math display="inline" id="M83"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, result in asymmetric perceptual shifts. These shifts go in the direction of the auditory perturbation and are visible only in the portion of auditory space located with respect to vowel /ɛ/ on the opposite side of the region in which the auditory perturbation was applied, in agreement with the experimental findings reported in L-14.</p>
<fig id="pcbi.1005942.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Changes in perception questions resulting from a combined local update of the internal model and an update of the auditory characterization of the perturbed phoneme combining a shift in mean and reduction in variance.</title>
<p>Dashed lines correspond to the perturbed condition. The perturbation goes in the direction of /a/ (horizontal arrow).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g009" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec023">
<title>Summary</title>
<p>In summary, based on the results of the simulations presented in this section, we select 3 adaptation hypotheses that, combined with at least one of the two perception hypotheses (<inline-formula id="pcbi.1005942.e084"><alternatives><graphic id="pcbi.1005942.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e084" xlink:type="simple"/><mml:math display="inline" id="M84"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> or <inline-formula id="pcbi.1005942.e085"><alternatives><graphic id="pcbi.1005942.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e085" xlink:type="simple"/><mml:math display="inline" id="M85"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>), reproduce the key-observations described in L-14 concerning the perceptual boundary shifts after adaptation to the auditory perturbation of vowel /ɛ/:</p>
<list list-type="bullet">
<list-item>
<p>
<inline-formula id="pcbi.1005942.e086">
<alternatives>
<graphic id="pcbi.1005942.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e086" xlink:type="simple"/>
<mml:math display="inline" id="M86">
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Ad</mml:mtext>
<mml:mi>M</mml:mi>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula>: the auditory-motor internal model is locally updated during adaptation, in the region where the subject articulates speech during the training phase leading to adaptation. No other update occurs.</p>
</list-item>
<list-item>
<p>
<inline-formula id="pcbi.1005942.e087">
<alternatives>
<graphic id="pcbi.1005942.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e087" xlink:type="simple"/>
<mml:math display="inline" id="M87">
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Ad</mml:mtext>
<mml:mo>Φ</mml:mo>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula>: only the auditory characterization of vowel /ɛ/ is modified and this modification involves a combined update of its location and width.</p>
</list-item>
<list-item>
<p>
<inline-formula id="pcbi.1005942.e088">
<alternatives>
<graphic id="pcbi.1005942.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e088" xlink:type="simple"/>
<mml:math display="inline" id="M88">
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Ad</mml:mtext>
<mml:mrow>
<mml:mi>M</mml:mi>
<mml:mo>Φ</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula>: both stored knowledge mentioned in <inline-formula id="pcbi.1005942.e089"><alternatives><graphic id="pcbi.1005942.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e089" xlink:type="simple"/><mml:math display="inline" id="M89"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e090"><alternatives><graphic id="pcbi.1005942.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e090" xlink:type="simple"/><mml:math display="inline" id="M90"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> are simultaneously updated.</p>
</list-item>
</list>
<p>
<xref ref-type="fig" rid="pcbi.1005942.g010">Fig 10</xref> illustrates the different stages of our evaluation process. The three selected hypotheses are represented on the third level of <xref ref-type="fig" rid="pcbi.1005942.g010">Fig 10</xref> from the top. The fourth level represents the outcomes of the evaluation of each hypothesis with respect to perception. The two last levels will be discussed in the next sections.</p>
<fig id="pcbi.1005942.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Evaluation of hypotheses about speech perception and adaptation in our modeling work.</title>
<p>The model (Section 1 Model definition) enables to define different hypotheses about the sensory pathways involved in speech perception (Section 2 Formulation of speech production and perception questions) and the learning mechanisms involved in adaptation (Section 3 Adaptation hypotheses). Concerning speech perception, we evaluate hypotheses <inline-formula id="pcbi.1005942.e091"><alternatives><graphic id="pcbi.1005942.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e091" xlink:type="simple"/><mml:math display="inline" id="M91"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e092"><alternatives><graphic id="pcbi.1005942.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e092" xlink:type="simple"/><mml:math display="inline" id="M92"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, corresponding to the involvement of the auditory pathway only, or the fusion of somatosensory and auditory pathways. Concerning adaptation, we evaluate hypotheses <inline-formula id="pcbi.1005942.e093"><alternatives><graphic id="pcbi.1005942.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e093" xlink:type="simple"/><mml:math display="inline" id="M93"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005942.e094"><alternatives><graphic id="pcbi.1005942.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e094" xlink:type="simple"/><mml:math display="inline" id="M94"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e095"><alternatives><graphic id="pcbi.1005942.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e095" xlink:type="simple"/><mml:math display="inline" id="M95"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, corresponding respectively to an update of the auditor-motor internal model, an update of the auditory characterization of the perturbed phoneme, or both updates simultaneously. Combining hypotheses about perception and adaptation further enables to identify and test different scenarios simulating the experimental paradigm of Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>]. Scenarios leading to perceptual changes incompatible with those observed by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>] are discarded (x-boxes, Section 4 Evaluation with respect to perception). The remaining scenarios (✓-boxes) are evaluated with respect to their predictions of compensation in production (Section 5 Evaluation with respect to production) and only those that are consistent with results of Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>] are kept. Finally, we evaluate the last scenarios with respect to correlations between perceptual boundary shift and compensation magnitude (Section 6 Evaluation with respect to correlations). The only scenario that matches the no-correlation observation of Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>] is gray-shaded.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g010" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec024">
<title>Evaluation with respect to production</title>
<p>Let us now evaluate the effect of the three previous adaptation hypotheses, <inline-formula id="pcbi.1005942.e096"><alternatives><graphic id="pcbi.1005942.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e096" xlink:type="simple"/><mml:math display="inline" id="M96"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005942.e097"><alternatives><graphic id="pcbi.1005942.e097g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e097" xlink:type="simple"/><mml:math display="inline" id="M97"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e098"><alternatives><graphic id="pcbi.1005942.e098g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e098" xlink:type="simple"/><mml:math display="inline" id="M98"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> with respect to the production question <inline-formula id="pcbi.1005942.e099"><alternatives><graphic id="pcbi.1005942.e099g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e099" xlink:type="simple"/><mml:math display="inline" id="M99"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>.</p>
<sec id="sec025">
<title>Evaluation of <inline-formula id="pcbi.1005942.e100"><alternatives><graphic id="pcbi.1005942.e100g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e100" xlink:type="simple"/><mml:math display="inline" id="M100"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula></title>
<p>
<xref ref-type="fig" rid="pcbi.1005942.g011">Fig 11</xref> presents the outcome of the planning process <inline-formula id="pcbi.1005942.e101"><alternatives><graphic id="pcbi.1005942.e101g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e101" xlink:type="simple"/><mml:math display="inline" id="M101"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (right panel) before (solid lines) and after (dashed lines) updating the internal model. We observe a shift of the distribution of the motor commands selected for vowel /ɛ/ after adaptation, which is in a direction opposite to the perturbation (shift toward /i/, when the auditory perturbation goes toward /a/), in agreement with the reported compensatory behavior.</p>
<fig id="pcbi.1005942.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Changes in production question <inline-formula id="pcbi.1005942.e102"><alternatives><graphic id="pcbi.1005942.e102g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e102" xlink:type="simple"/><mml:math display="inline" id="M102"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> resulting from a local update of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>).</title>
<p>The update magnitude is equal to the perturbation magnitude (horizontal arrow). The vertical dashed line indicates the shift in control space that would result in complete compensation.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g011" xlink:type="simple"/>
</fig>
<p>Consistent with numerous experimental findings [<xref ref-type="bibr" rid="pcbi.1005942.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref052">52</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref054">54</xref>] our model predicts that the compensation for the perturbation of the auditory feedback is not complete. Yet, in the model, the local update of the internal model has been designed in order to enable a full compensation (the magnitude of the change matches the magnitude of the auditory perturbation). However, full compensation does not occur, because the speech planning process takes in consideration both the auditory and the somatosensory characterization of the phoneme. Full compensation would enable a perfect achievement of the auditory characteristics, but at the price of such a large change of the motor commands, that the corresponding somatosensory consequences would not be compatible any longer with the specified somatosensory characterization of the phoneme. Hence, the incomplete compensation is the result of a compromise between the requirements in terms of auditory and somatosensory characteristics. Note as well that the compensatory change in production is restricted to the vowel /ɛ/. This is a consequence of the locality of the internal model update, which is consistent with experimental observations of transfer of motor learning in speech production [<xref ref-type="bibr" rid="pcbi.1005942.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref055">55</xref>].</p>
</sec>
<sec id="sec026">
<title>Evaluation of <inline-formula id="pcbi.1005942.e103"><alternatives><graphic id="pcbi.1005942.e103g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e103" xlink:type="simple"/><mml:math display="inline" id="M103"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula></title>
<p>
<xref ref-type="fig" rid="pcbi.1005942.g012">Fig 12</xref> presents the outcome of the planning process <inline-formula id="pcbi.1005942.e104"><alternatives><graphic id="pcbi.1005942.e104g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e104" xlink:type="simple"/><mml:math display="inline" id="M104"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (right panel) before (solid lines) and after (dashed lines) updating the auditory characterization of vowel /ɛ/, according to the adaptation hypothesis <inline-formula id="pcbi.1005942.e105"><alternatives><graphic id="pcbi.1005942.e105g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e105" xlink:type="simple"/><mml:math display="inline" id="M105"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>. Since, in the context of this hypothesis, all the other representations are unchanged, in particular the auditory-motor internal model, this change of the auditory characterization of vowel /ɛ/ toward vowel /a/ induces a change of the motor commands that is also toward the articulation of /a/, i.e. in the same direction as the auditory perturbation. This is contrary to the compensatory behavior reported in all the experimental studies involving a perturbation of the auditory feedback.</p>
<fig id="pcbi.1005942.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Changes in production question <inline-formula id="pcbi.1005942.e106"><alternatives><graphic id="pcbi.1005942.e106g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e106" xlink:type="simple"/><mml:math display="inline" id="M106"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> resulting from an update of the auditory characterization of phoneme /ɛ/ <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]).</title>
<p>The update correspond to a combined shift of mean, <inline-formula id="pcbi.1005942.e107"><alternatives><graphic id="pcbi.1005942.e107g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e107" xlink:type="simple"/><mml:math display="inline" id="M107"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and reduction in standard-deviation <inline-formula id="pcbi.1005942.e108"><alternatives><graphic id="pcbi.1005942.e108g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e108" xlink:type="simple"/><mml:math display="inline" id="M108"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> as previously defined (see <xref ref-type="fig" rid="pcbi.1005942.g011">Fig 11</xref> for additional details).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g012" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec027">
<title>Evaluation of <inline-formula id="pcbi.1005942.e109"><alternatives><graphic id="pcbi.1005942.e109g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e109" xlink:type="simple"/><mml:math display="inline" id="M109"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula></title>
<p>
<xref ref-type="fig" rid="pcbi.1005942.g013">Fig 13</xref> presents the outcome of the planning process <inline-formula id="pcbi.1005942.e110"><alternatives><graphic id="pcbi.1005942.e110g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e110" xlink:type="simple"/><mml:math display="inline" id="M110"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (right panel) before (solid lines) and after (dashed lines) the combined updates of the auditory-motor internal model and the auditory characterization of vowel /ɛ/, according to the adaptation hypothesis <inline-formula id="pcbi.1005942.e111"><alternatives><graphic id="pcbi.1005942.e111g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e111" xlink:type="simple"/><mml:math display="inline" id="M111"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. We observe that, after these two combined updates, the outcome of the planning process (right panel) is shifted in a direction opposite to the perturbation, in agreement with the reported compensatory behavior. Similarly to the previous evaluation of <inline-formula id="pcbi.1005942.e112"><alternatives><graphic id="pcbi.1005942.e112g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e112" xlink:type="simple"/><mml:math display="inline" id="M112"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, comparing the magnitude of the shift with the amplitude of the perturbation (horizontal arrow) indicates that compensation is not complete. In the present case, the incomplete compensation has a double origin. The shift of the auditory characterization of the perturbed phoneme is an explanation for this phenomenon since this change reduces the need to change articulation in order for the production to match this characterization. In addition, as for <inline-formula id="pcbi.1005942.e113"><alternatives><graphic id="pcbi.1005942.e113g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e113" xlink:type="simple"/><mml:math display="inline" id="M113"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> in <xref ref-type="fig" rid="pcbi.1005942.g011">Fig 11</xref>, compensation is incomplete due to the fact that the new auditory-motor relation leads to auditory and somatosensory states that cannot simultaneously satisfy the two sensory characterizations of phonemes.</p>
<fig id="pcbi.1005942.g013" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Changes in production question <inline-formula id="pcbi.1005942.e114"><alternatives><graphic id="pcbi.1005942.e114g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e114" xlink:type="simple"/><mml:math display="inline" id="M114"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> resulting from the combination of the local update of the internal model and the update of the auditory characterization of vowel /ɛ/.</title>
<p>See <xref ref-type="fig" rid="pcbi.1005942.g011">Fig 11</xref> for additional details.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g013" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec028">
<title>Summary</title>
<p>From the three selected adaptation hypotheses, only <inline-formula id="pcbi.1005942.e115"><alternatives><graphic id="pcbi.1005942.e115g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e115" xlink:type="simple"/><mml:math display="inline" id="M115"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e116"><alternatives><graphic id="pcbi.1005942.e116g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e116" xlink:type="simple"/><mml:math display="inline" id="M116"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are compatible with the compensatory change in production observed in experimental studies. Altogether, as illustrated in <xref ref-type="fig" rid="pcbi.1005942.g010">Fig 10</xref>, we are hence left with three combined perception–adaptation hypotheses that all reproduce the experimental results in perception and production reported in L-14:</p>
<list list-type="bullet">
<list-item>
<p>
<inline-formula id="pcbi.1005942.e117">
<alternatives>
<graphic id="pcbi.1005942.e117g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e117" xlink:type="simple"/>
<mml:math display="inline" id="M117">
<mml:mrow>
<mml:msubsup>
<mml:mi>Q</mml:mi>
<mml:mtext>Per</mml:mtext>
<mml:mi>F</mml:mi>
</mml:msubsup>
<mml:mo>⊕</mml:mo>
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Ad</mml:mtext>
<mml:mi>M</mml:mi>
</mml:msubsup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>: auditory perception is based on the fusion of auditory and somatosensory pathways (<inline-formula id="pcbi.1005942.e118"><alternatives><graphic id="pcbi.1005942.e118g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e118" xlink:type="simple"/><mml:math display="inline" id="M118"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) and only the auditory-motor internal model is locally updated during adaptation (<inline-formula id="pcbi.1005942.e119"><alternatives><graphic id="pcbi.1005942.e119g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e119" xlink:type="simple"/><mml:math display="inline" id="M119"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>).</p>
</list-item>
<list-item>
<p>
<inline-formula id="pcbi.1005942.e120">
<alternatives>
<graphic id="pcbi.1005942.e120g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e120" xlink:type="simple"/>
<mml:math display="inline" id="M120">
<mml:mrow>
<mml:msubsup>
<mml:mi>Q</mml:mi>
<mml:mtext>Per</mml:mtext>
<mml:mi>A</mml:mi>
</mml:msubsup>
<mml:mo>⊕</mml:mo>
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Ad</mml:mtext>
<mml:mrow>
<mml:mi>M</mml:mi>
<mml:mo>Φ</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>: auditory perception is based only on the auditory pathway (<inline-formula id="pcbi.1005942.e121"><alternatives><graphic id="pcbi.1005942.e121g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e121" xlink:type="simple"/><mml:math display="inline" id="M121"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) and both the auditory-motor internal model and the auditory characterization of the perturbed vowel are modified, with a local update for the first and a combined shift and narrowing for the second (<inline-formula id="pcbi.1005942.e122"><alternatives><graphic id="pcbi.1005942.e122g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e122" xlink:type="simple"/><mml:math display="inline" id="M122"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>).</p>
</list-item>
<list-item>
<p>
<inline-formula id="pcbi.1005942.e123">
<alternatives>
<graphic id="pcbi.1005942.e123g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e123" xlink:type="simple"/>
<mml:math display="inline" id="M123">
<mml:mrow>
<mml:msubsup>
<mml:mi>Q</mml:mi>
<mml:mtext>Per</mml:mtext>
<mml:mi>F</mml:mi>
</mml:msubsup>
<mml:mo>⊕</mml:mo>
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Ad</mml:mtext>
<mml:mrow>
<mml:mi>M</mml:mi>
<mml:mo>Φ</mml:mo>
</mml:mrow>
</mml:msubsup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>: auditory perception is based on the fusion of sensory pathways (<inline-formula id="pcbi.1005942.e124"><alternatives><graphic id="pcbi.1005942.e124g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e124" xlink:type="simple"/><mml:math display="inline" id="M124"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) and both the auditory-motor internal model and the auditory characterization of the perturbed vowel are modified, with a local update for the first and a combined shift and narrowing for the second (<inline-formula id="pcbi.1005942.e125"><alternatives><graphic id="pcbi.1005942.e125g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e125" xlink:type="simple"/><mml:math display="inline" id="M125"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>).</p>
</list-item>
</list>
<p>
<xref ref-type="fig" rid="pcbi.1005942.g014">Fig 14</xref> summarizes the corresponding results in production and perception for each of these three selected hypotheses.</p>
<fig id="pcbi.1005942.g014" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g014</object-id>
<label>Fig 14</label>
<caption>
<title>Summary of simulations under each of the three combined hypotheses accounting for the results in L-14.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g014" xlink:type="simple"/>
</fig>
<p>As highlighted above in Section “Update of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>)”, the asymmetry of the perceptual boundary shift explained by these three hypotheses is sensitive to the particular values of the parameters involved in the updates according to either hypothesis <inline-formula id="pcbi.1005942.e126"><alternatives><graphic id="pcbi.1005942.e126g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e126" xlink:type="simple"/><mml:math display="inline" id="M126"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> or hypothesis <inline-formula id="pcbi.1005942.e127"><alternatives><graphic id="pcbi.1005942.e127g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e127" xlink:type="simple"/><mml:math display="inline" id="M127"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. Other parameter values can lead to boundary changes in both sides of the auditory continuum. The apparent contradiction between studies S-09 and L-14, highlighted in Section “Summary of experimental results we aim at modeling”, could thus be interpreted in this context. Refer to Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s005">S5 Text</xref> for variations around this theme.</p>
</sec>
</sec>
<sec id="sec029">
<title>Evaluation with respect to correlations</title>
<p>These three combined hypotheses are equivalent in terms of the qualitative effects predicted with respect to changes in production and perception; they all account for incomplete compensation and for the asymmetric perceptual boundary shift in the direction of perturbation. However, the magnitudes of the perceptual boundary shift and of the motor command shift associated with the compensation differ across the three hypotheses. Experimental studies display large differences across subjects in their capacity to compensate for a perturbation of the auditory feedback [<xref ref-type="bibr" rid="pcbi.1005942.ref056">56</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref058">58</xref>]. Moreover, in L-14 and S-09 subjects differ in the amount of perceptual boundary shift induced by adaptation to the perturbation. If, as suggested in L-14, the perceptual change is mainly due to a change in motor functions, one would expect that subjects who compensate more would exhibit a greater perceptual boundary shift. However, no significant correlation between these two phenomena was found in L-14.</p>
<p>In the present section we focus on this question. First, we identify possible origins for the reported differences concerning the amount of compensation and perceptual shift among subjects. Then, we implement these origins under each of the three combined hypotheses and evaluate their predictions in terms of the correlations between compensation magnitudes and amount of perceptual boundary shift.</p>
<sec id="sec030">
<title>Hypotheses on the origins of variability in the magnitude of compensation and perceptual shift</title>
<p>Up to now, we have compared simulations in which for each hypothesis we have arbitrarily chosen a unique set of new parameters for the piece of knowledge that is assumed to be modified during the adaptation process. However, since compensation and adaptation mechanisms in presence of perturbation are highly subject-dependent, we can see our approach as the modeling of a specific subject behavior. In this section we will consider some variations in the changes associated to adaptation in order to investigate the possible consequences of inter-subject variability in the compensation/adaptation process on the categorical boundary shifts in perception.</p>
<p>The adaptation assumptions selected in Section “Effects of combined update hypotheses” involved the local update of the auditory-motor internal model <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>) and the update of the auditory characterization of the perturbed phoneme <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]). Therefore, inter-subject differences in adaptation can be attributed in the model to different update magnitudes in either of these two terms. These different magnitudes may result from inter-subject differences in learning rates, in novelty or error detection, etc. This leads to the two following hypotheses:</p>
<list list-type="bullet">
<list-item>
<p>
<inline-formula id="pcbi.1005942.e128">
<alternatives>
<graphic id="pcbi.1005942.e128g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e128" xlink:type="simple"/>
<mml:math display="inline" id="M128">
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Var</mml:mtext>
<mml:mi>M</mml:mi>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula>: subjects differ in the magnitude of update of their auditory-motor internal model, <italic>P</italic>(<italic>A</italic><sub><italic>M</italic></sub> | <italic>M</italic>), some of them achieving a complete update and some others only a partial update.</p>
</list-item>
<list-item>
<p>
<inline-formula id="pcbi.1005942.e129">
<alternatives>
<graphic id="pcbi.1005942.e129g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e129" xlink:type="simple"/>
<mml:math display="inline" id="M129">
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Var</mml:mtext>
<mml:mo>Φ</mml:mo>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula>: subjects differ in the amount of shift of their auditory characterization of the perturbed phoneme, <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | [Φ = /ɛ/]) (still assuming the relation between mean and variance used in Section “Update of the auditory characterization <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ)”, i.e such that the perceptual boundary shift is present only on one side of the auditory continuum).</p>
</list-item>
</list>
<p>In addition to the two previous hypotheses, we previously noted that, in our model, incomplete compensation resulted from a trade-off between the constraints associated with the auditory and the somatosensory characterizations of the phonemes, which are no longer compatible after adaptation. It is important to point out that the result of this trade-off depends only on the relative strength of the constraint imposed by each sensory pathway. In our previous simulations, both sensory constraints were equivalent (same values of parameters characterizing the Gaussian distributions and linear relation between the two sensory domains), meaning that perturbations to each modality would be equally compensated. However, individual differences in the amount of compensation to auditory and somatosensory perturbations have been reported in speech production: subjects that adapt more to one sensory perturbation tend to adapt less to the other [<xref ref-type="bibr" rid="pcbi.1005942.ref059">59</xref>]. This has been suggested as evidence that some subjects may rely more on the auditory modality and others more on the somatosensory modality. Such sensory preferences could originate from individual differences in the sensitivity to each kind of sensory feedback [<xref ref-type="bibr" rid="pcbi.1005942.ref060">60</xref>], which can be modeled in line with the suggestions of Perkell et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref061">61</xref>], by differences in the parameters <inline-formula id="pcbi.1005942.e130"><alternatives><graphic id="pcbi.1005942.e130g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e130" xlink:type="simple"/><mml:math display="inline" id="M130"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e131"><alternatives><graphic id="pcbi.1005942.e131g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e131" xlink:type="simple"/><mml:math display="inline" id="M131"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. Small <inline-formula id="pcbi.1005942.e132"><alternatives><graphic id="pcbi.1005942.e132g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e132" xlink:type="simple"/><mml:math display="inline" id="M132"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (resp. <inline-formula id="pcbi.1005942.e133"><alternatives><graphic id="pcbi.1005942.e133g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e133" xlink:type="simple"/><mml:math display="inline" id="M133"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) values means that the auditory (resp. somatosensory) characterization of the phoneme is very accurate and that the subject strongly relies on this sensory pathway. Large <inline-formula id="pcbi.1005942.e134"><alternatives><graphic id="pcbi.1005942.e134g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e134" xlink:type="simple"/><mml:math display="inline" id="M134"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (resp. <inline-formula id="pcbi.1005942.e135"><alternatives><graphic id="pcbi.1005942.e135g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e135" xlink:type="simple"/><mml:math display="inline" id="M135"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) values means either that the sensory characterization is quite inaccurate or that the subject does not rely much on this sensory pathway.</p>
<p>Therefore, we consider a third possible hypothesis concerning the origin of the reported differences in compensation between subjects:</p>
<list list-type="bullet">
<list-item>
<p>
<inline-formula id="pcbi.1005942.e136">
<alternatives>
<graphic id="pcbi.1005942.e136g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e136" xlink:type="simple"/>
<mml:math display="inline" id="M136">
<mml:msubsup>
<mml:mi>H</mml:mi>
<mml:mtext>Var</mml:mtext>
<mml:mi>σ</mml:mi>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula>: subjects differ in the relative precision of their sensory characterizations of phonemes. Some may have greater values of parameter <inline-formula id="pcbi.1005942.e137"><alternatives><graphic id="pcbi.1005942.e137g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e137" xlink:type="simple"/><mml:math display="inline" id="M137"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> compared to <inline-formula id="pcbi.1005942.e138"><alternatives><graphic id="pcbi.1005942.e138g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e138" xlink:type="simple"/><mml:math display="inline" id="M138"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <italic>vice versa</italic>.</p>
</list-item>
</list>
</sec>
<sec id="sec031">
<title>Implementing hypotheses and exploring correlations between the magnitude of compensation and perceptual shift</title>
<p>The three previous hypotheses represent three possible origins of the reported differences in the way subjects adapt to perturbations. These hypotheses are not exclusive and all of them may be involved simultaneously. However, in order to simplify the presentation of the results, we firstly focus on the combined effects of hypotheses <inline-formula id="pcbi.1005942.e139"><alternatives><graphic id="pcbi.1005942.e139g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e139" xlink:type="simple"/><mml:math display="inline" id="M139"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e140"><alternatives><graphic id="pcbi.1005942.e140g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e140" xlink:type="simple"/><mml:math display="inline" id="M140"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>. In other words, we first implement simulations combining different values of update of the auditory-motor internal model (<inline-formula id="pcbi.1005942.e141"><alternatives><graphic id="pcbi.1005942.e141g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e141" xlink:type="simple"/><mml:math display="inline" id="M141"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>), and different values of shift of the auditory characterization of the perturbed phoneme (<inline-formula id="pcbi.1005942.e142"><alternatives><graphic id="pcbi.1005942.e142g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e142" xlink:type="simple"/><mml:math display="inline" id="M142"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>). Hence, in this first set of simulation we ignore hypothesis <inline-formula id="pcbi.1005942.e143"><alternatives><graphic id="pcbi.1005942.e143g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e143" xlink:type="simple"/><mml:math display="inline" id="M143"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>σ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and keep values of <inline-formula id="pcbi.1005942.e144"><alternatives><graphic id="pcbi.1005942.e144g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e144" xlink:type="simple"/><mml:math display="inline" id="M144"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e145"><alternatives><graphic id="pcbi.1005942.e145g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e145" xlink:type="simple"/><mml:math display="inline" id="M145"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> equal.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref> presents the outcome of simulations for different updates of the auditory-motor internal model and different shifts of the auditory characterization of the perturbed phoneme, for a magnitude of the perturbation representing 40% of the distance between neighboring phonemes and towards phoneme /a/. For the internal model, we specified six update amplitudes in order to enable a compensation varying gradually from 0% to 100% of the magnitude of perturbation (when no influence of other factors reduces compensation) (top left panel of <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>). For the auditory characterization of vowel /ɛ/, we implemented six values of parameter <inline-formula id="pcbi.1005942.e146"><alternatives><graphic id="pcbi.1005942.e146g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e146" xlink:type="simple"/><mml:math display="inline" id="M146"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, evenly distributed from the original value, used in the normal condition, to half of this value. The six corresponding values for <inline-formula id="pcbi.1005942.e147"><alternatives><graphic id="pcbi.1005942.e147g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e147" xlink:type="simple"/><mml:math display="inline" id="M147"><mml:msubsup><mml:mi>μ</mml:mi> <mml:mi>A</mml:mi> <mml:mo>ɛ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> (top right panel of <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>) were computed from the relation that was already used in Section “Update of the auditory characterization <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ)” (as stated in hypothesis <inline-formula id="pcbi.1005942.e148"><alternatives><graphic id="pcbi.1005942.e148g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e148" xlink:type="simple"/><mml:math display="inline" id="M148"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>).</p>
<fig id="pcbi.1005942.g015" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g015</object-id>
<label>Fig 15</label>
<caption>
<title>Relation between amplitude of perceptual boundary shift and amount of compensation for hypothesis <inline-formula id="pcbi.1005942.e149"><alternatives><graphic id="pcbi.1005942.e149g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e149" xlink:type="simple"/><mml:math display="inline" id="M149"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and hypothesis <inline-formula id="pcbi.1005942.e150"><alternatives><graphic id="pcbi.1005942.e150g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e150" xlink:type="simple"/><mml:math display="inline" id="M150"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>.</title>
<p>Top panels: considered amplitude of update in the auditory-motor internal model (left) and the amplitude of shift in the auditory characterization of the perturbed phoneme (right). Middle panels: relation between degree of compensation and amount of perceptual shift for each adaptation hypothesis in the case of a local update of the internal model. Colors correspond to the different magnitudes of internal model updates, as indicated in the top left panel. Darkness indicates the amplitude of shift of the auditory characterization of the perturbed phoneme, as indicated in the top right panel. Bottom panel: corresponding amplitude of correlations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g015" xlink:type="simple"/>
</fig>
<p>Middle panels present the magnitude of compensation and perceptual shifts resulting from the combination of previous updates under the three combined hypotheses, <inline-formula id="pcbi.1005942.e151"><alternatives><graphic id="pcbi.1005942.e151g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e151" xlink:type="simple"/><mml:math display="inline" id="M151"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (left panel of <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>), <inline-formula id="pcbi.1005942.e152"><alternatives><graphic id="pcbi.1005942.e152g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e152" xlink:type="simple"/><mml:math display="inline" id="M152"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (middle panel of <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>) and <inline-formula id="pcbi.1005942.e153"><alternatives><graphic id="pcbi.1005942.e153g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e153" xlink:type="simple"/><mml:math display="inline" id="M153"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (right panel of <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>). Colors correspond to the different magnitudes of internal model update and darkness indicates the amplitude of shift of the auditory characterization of the perturbed phoneme, as indicated by plots in the top panels. X-axis represents the magnitude of compensation in units of the perturbation but in the opposite direction. In other words, value 1 corresponds to a shift in production of the same magnitude but opposite direction of the perturbation (complete compensation), value 0 corresponds to no compensation and value -1 corresponds to a shift in production of the same magnitude and same direction as the perturbation. Y-axis represents the amount of perceptual shift in units of the perturbation and in the same direction.</p>
<p>The bottom panel indicates the correlation coefficient between compensation and perceptual shift for the set of data points obtained from the different simulations under each of the three combined hypotheses. Simulations assuming hypothesis <inline-formula id="pcbi.1005942.e154"><alternatives><graphic id="pcbi.1005942.e154g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e154" xlink:type="simple"/><mml:math display="inline" id="M154"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (left middle panel in <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>) show a noticeable positive correlation between magnitude of compensation and perceptual shift. In order to understand this result, it is important to remember that in the context of hypothesis <inline-formula id="pcbi.1005942.e155"><alternatives><graphic id="pcbi.1005942.e155g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e155" xlink:type="simple"/><mml:math display="inline" id="M155"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> only an update of the auditory-motor internal model is assumed. Hence, hypothesis <inline-formula id="pcbi.1005942.e156"><alternatives><graphic id="pcbi.1005942.e156g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e156" xlink:type="simple"/><mml:math display="inline" id="M156"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> does not apply, and only the effect of inter-subject differences in internal model updates (hypothesis <inline-formula id="pcbi.1005942.e157"><alternatives><graphic id="pcbi.1005942.e157g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e157" xlink:type="simple"/><mml:math display="inline" id="M157"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) can be considered. The magnitude of the articulatory changes associated with compensation is strongly related with the magnitude of the changes provided to the internal model (displacement along the horizontal axis in the figure). Our simulations show that the perceptual boundary shift increases with the magnitude of the changes, but non monotonously: it increases first and becomes stable after. This “saturation” effect is due to the fact that the update of the internal model is local. Altogether, the influence of the update of the internal model in production and perception results in a noticeable positive correlation between the amount of compensation and perceptual shift, contrary to what was reported in L-14.</p>
<p>Simulations assuming hypothesis <inline-formula id="pcbi.1005942.e158"><alternatives><graphic id="pcbi.1005942.e158g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e158" xlink:type="simple"/><mml:math display="inline" id="M158"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> for the perceptual boundary shift (center panel in <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>) show a negative and moderate correlation between amount of compensation and perceptual shift. It should be reminded that in the context of hypothesis <inline-formula id="pcbi.1005942.e159"><alternatives><graphic id="pcbi.1005942.e159g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e159" xlink:type="simple"/><mml:math display="inline" id="M159"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> adaptation induces both a local update of the motor-auditory internal model and an update of the auditory characterization of vowel /ɛ/, and that perception only involves the auditory pathway. In the absence of any other constraint, the magnitude of the update of the auditory-motor internal model (hypothesis <inline-formula id="pcbi.1005942.e160"><alternatives><graphic id="pcbi.1005942.e160g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e160" xlink:type="simple"/><mml:math display="inline" id="M160"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) strongly determines the magnitude of the compensation. We have shown above that, when perception only involves the auditory pathway, the update of the auditory-motor internal model has no influence of the perceptual boundary shift. Hence, the update of the internal model does not induce any correlation between the amount of compensation and the magnitude of the perceptual boundary shift. This can be seen in the present simulations where data points corresponding to a given location of the auditory characterization (same darkness) but different values of update of the internal model (different colors) are aligned horizontally.</p>
<p>On the contrary, a shift in the auditory characterization of vowel /ɛ/ has a direct impact on the perceptual boundary shift (positive correlation) and on the amount of compensation (the larger the shift, the smaller the amount of compensation). Thus inter-subject differences in the magnitude of the shift of the auditory characterization of vowel /ɛ/ (hypothesis <inline-formula id="pcbi.1005942.e161"><alternatives><graphic id="pcbi.1005942.e161g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e161" xlink:type="simple"/><mml:math display="inline" id="M161"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>) result in a negative correlation between the amount of compensation and the magnitude of the perceptual boundary shift. Altogether, in the context of hypothesis <inline-formula id="pcbi.1005942.e162"><alternatives><graphic id="pcbi.1005942.e162g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e162" xlink:type="simple"/><mml:math display="inline" id="M162"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, the combination of hypotheses <inline-formula id="pcbi.1005942.e163"><alternatives><graphic id="pcbi.1005942.e163g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e163" xlink:type="simple"/><mml:math display="inline" id="M163"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e164"><alternatives><graphic id="pcbi.1005942.e164g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e164" xlink:type="simple"/><mml:math display="inline" id="M164"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> results in a mild negative correlation between the amount of compensation and the magnitude of the perceptual boundary shift, contrary to what was reported in L-14.</p>
<p>Simulations assuming hypothesis <inline-formula id="pcbi.1005942.e165"><alternatives><graphic id="pcbi.1005942.e165g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e165" xlink:type="simple"/><mml:math display="inline" id="M165"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> for the perceptual boundary shift (right middle panel in <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>) show an almost vanishing correlation between amount of compensation and perceptual boundary shift. Hypothesis <inline-formula id="pcbi.1005942.e166"><alternatives><graphic id="pcbi.1005942.e166g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e166" xlink:type="simple"/><mml:math display="inline" id="M166"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> can be roughly seen as combining <inline-formula id="pcbi.1005942.e167"><alternatives><graphic id="pcbi.1005942.e167g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e167" xlink:type="simple"/><mml:math display="inline" id="M167"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e168"><alternatives><graphic id="pcbi.1005942.e168g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e168" xlink:type="simple"/><mml:math display="inline" id="M168"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Since <inline-formula id="pcbi.1005942.e169"><alternatives><graphic id="pcbi.1005942.e169g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e169" xlink:type="simple"/><mml:math display="inline" id="M169"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> induces a positive correlation and <inline-formula id="pcbi.1005942.e170"><alternatives><graphic id="pcbi.1005942.e170g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e170" xlink:type="simple"/><mml:math display="inline" id="M170"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> a negative one, the combination of these two influences in <inline-formula id="pcbi.1005942.e171"><alternatives><graphic id="pcbi.1005942.e171g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e171" xlink:type="simple"/><mml:math display="inline" id="M171"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> tends to counterbalance each other, resulting in a much smaller correlation than the two previous ones. For a given shift of the auditory characterization of vowel /ɛ/ (same darkness) simulations with different updates of the internal model (different colors) result in a similar pattern as in the simulations assuming <inline-formula id="pcbi.1005942.e172"><alternatives><graphic id="pcbi.1005942.e172g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e172" xlink:type="simple"/><mml:math display="inline" id="M172"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>However two variations of this pattern can be observed when the shift of the auditory characterization increases. First, the non-linearity induced by the locality of update of the internal model (see above) disappears when the shift increases (darkest <italic>versus</italic> lighter data points). This is due to the fact that the shift in the auditory characterization brings the boundary between phonemes closer to the center of the updated region and reduces the influence of the limits of the local update. (Simulations assuming the general update of the internal model were performed in order to clarify which part of the effects arises from our locality assumption. The obtained results show the same key-properties for both updates of the internal model, which indicates that the obtained pattern of correlations is not an artifact of the particular choice of our local update assumption.)</p>
<p>The second difference is that the slope of the relation between perceptual shift and compensation reduces for greater shifts of the auditory characterization. This is due to the fact that the increase in the magnitude of the shift goes together with a decrease in the width of the auditory characterization of vowel /ɛ/. This results in a stronger influence of the auditory pathway relative to the somatosensory one. Since the influence of the internal model on the perceptual boundary shift is mediated through the somatosensory pathway, the magnitude of the effect reduces when the auditory pathway is stronger. This is consistent with the horizontal alignment obtained under <inline-formula id="pcbi.1005942.e173"><alternatives><graphic id="pcbi.1005942.e173g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e173" xlink:type="simple"/><mml:math display="inline" id="M173"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> where the somatosensory pathway is assumed not to contribute to perception.</p>
<p>In summary, hypothesis <inline-formula id="pcbi.1005942.e174"><alternatives><graphic id="pcbi.1005942.e174g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e174" xlink:type="simple"/><mml:math display="inline" id="M174"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is more in line with the lack of correlation between compensation and perceptual shift reported in L-14.</p>
<p>We now consider the additional influence of hypothesis <inline-formula id="pcbi.1005942.e175"><alternatives><graphic id="pcbi.1005942.e175g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e175" xlink:type="simple"/><mml:math display="inline" id="M175"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>σ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, assuming variable relative precision of the sensory characterizations of phonemes across subjects. We implemented the same simulations as above for different values of parameter <inline-formula id="pcbi.1005942.e176"><alternatives><graphic id="pcbi.1005942.e176g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e176" xlink:type="simple"/><mml:math display="inline" id="M176"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, as illustrated in the top right panel of <xref ref-type="fig" rid="pcbi.1005942.g016">Fig 16</xref>. We retained values of <inline-formula id="pcbi.1005942.e177"><alternatives><graphic id="pcbi.1005942.e177g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e177" xlink:type="simple"/><mml:math display="inline" id="M177"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> only greater or equal to the value of <inline-formula id="pcbi.1005942.e178"><alternatives><graphic id="pcbi.1005942.e178g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e178" xlink:type="simple"/><mml:math display="inline" id="M178"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (corresponding to preference on the auditory pathway as compared to the somatosensory pathway), in order to be consistent with the fact that in L-14 only subjects who showed significant compensation to auditory perturbations were kept. Notice that simulations implementing reciprocal values for <inline-formula id="pcbi.1005942.e179"><alternatives><graphic id="pcbi.1005942.e179g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e179" xlink:type="simple"/><mml:math display="inline" id="M179"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e180"><alternatives><graphic id="pcbi.1005942.e180g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e180" xlink:type="simple"/><mml:math display="inline" id="M180"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> were also performed. Results are qualitatively similar to those presented below, indicating that they are not a consequence of the particular asymmetric choice implemented here. In <xref ref-type="fig" rid="pcbi.1005942.g016">Fig 16</xref>, the level of darkness of the colors indicates an increasing precision of the somatosensory regions.</p>
<fig id="pcbi.1005942.g016" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005942.g016</object-id>
<label>Fig 16</label>
<caption>
<title>Influence of the combination of hypotheses <inline-formula id="pcbi.1005942.e181"><alternatives><graphic id="pcbi.1005942.e181g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e181" xlink:type="simple"/><mml:math display="inline" id="M181"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005942.e182"><alternatives><graphic id="pcbi.1005942.e182g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e182" xlink:type="simple"/><mml:math display="inline" id="M182"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mo>Φ</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e183"><alternatives><graphic id="pcbi.1005942.e183g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e183" xlink:type="simple"/><mml:math display="inline" id="M183"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>σ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> on the relation between compensation and perceptual boundary shift.</title>
<p>Changes implemented for the internal model and the auditory characterization are the same as in <xref ref-type="fig" rid="pcbi.1005942.g015">Fig 15</xref>. They are illustrated in the top left and top middle panels. In addition to the previous simulations where parameters of the sensory characterizations, <inline-formula id="pcbi.1005942.e184"><alternatives><graphic id="pcbi.1005942.e184g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e184" xlink:type="simple"/><mml:math display="inline" id="M184"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e185"><alternatives><graphic id="pcbi.1005942.e185g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e185" xlink:type="simple"/><mml:math display="inline" id="M185"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>A</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, where both equal, here we implement two additional values of parameters <inline-formula id="pcbi.1005942.e186"><alternatives><graphic id="pcbi.1005942.e186g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e186" xlink:type="simple"/><mml:math display="inline" id="M186"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, corresponding to greater variance of the somatosensory characterization, and therefore reduced weight of the somatosensory pathway. The three values of <inline-formula id="pcbi.1005942.e187"><alternatives><graphic id="pcbi.1005942.e187g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e187" xlink:type="simple"/><mml:math display="inline" id="M187"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>S</mml:mi> <mml:mi>ϕ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> implemented are <inline-formula id="pcbi.1005942.e188"><alternatives><graphic id="pcbi.1005942.e188g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e188" xlink:type="simple"/><mml:math display="inline" id="M188"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>8</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> (equal weights of sensory pathways), <inline-formula id="pcbi.1005942.e189"><alternatives><graphic id="pcbi.1005942.e189g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e189" xlink:type="simple"/><mml:math display="inline" id="M189"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>6</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e190"><alternatives><graphic id="pcbi.1005942.e190g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e190" xlink:type="simple"/><mml:math display="inline" id="M190"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>4</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> (smaller weight for the somatosensory pathway) of the distance between neighboring phonemes. The corresponding changes of the somatosensory characterization are illustrated in the top right panel. Darkness of the colors indicates an increase of the weight of the auditory pathway relatively to the somatosensory pathway.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.g016" xlink:type="simple"/>
</fig>
<p>Results are consistent with the idea that relative precision of sensory characterizations modulates the influence of each sensory pathway: wider somatosensory characterizations (light colors) are associated with a larger influence of the auditory pathway. As a consequence, in the case of <inline-formula id="pcbi.1005942.e191"><alternatives><graphic id="pcbi.1005942.e191g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e191" xlink:type="simple"/><mml:math display="inline" id="M191"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="fig" rid="pcbi.1005942.g016">Fig 16</xref>, left column) this results in smaller slopes in the relation between perceptual shift and compensation (middle horizontal panel), and decreases the positive correlation between compensation and perceptual shift accordingly (lower horizontal panel). However, for hypothesis <inline-formula id="pcbi.1005942.e192"><alternatives><graphic id="pcbi.1005942.e192g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e192" xlink:type="simple"/><mml:math display="inline" id="M192"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="fig" rid="pcbi.1005942.g016">Fig 16</xref>, center column) in which the somatosensory pathway is assumed not to contribute to perception, varying somatosensory weight has no consequence on perceptual shift (middle horizontal panel) nor on the resulting correlation (lower horizontal panel). Finally, we observe that hypothesis <inline-formula id="pcbi.1005942.e193"><alternatives><graphic id="pcbi.1005942.e193g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e193" xlink:type="simple"/><mml:math display="inline" id="M193"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>σ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> has a small impact on the correlation coefficient obtained assuming <inline-formula id="pcbi.1005942.e194"><alternatives><graphic id="pcbi.1005942.e194g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e194" xlink:type="simple"/><mml:math display="inline" id="M194"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="fig" rid="pcbi.1005942.g016">Fig 16</xref>, right column) which remains close to zero.</p>
<p>In summary, including hypothesis <inline-formula id="pcbi.1005942.e195"><alternatives><graphic id="pcbi.1005942.e195g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e195" xlink:type="simple"/><mml:math display="inline" id="M195"><mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Var</mml:mtext> <mml:mi>σ</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> in our simulations, which corresponds to the implementation of individual differences on the weighting of each sensory pathway, confirms that the absence of correlation reported by L-14 may be best attributed to hypothesis <inline-formula id="pcbi.1005942.e196"><alternatives><graphic id="pcbi.1005942.e196g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e196" xlink:type="simple"/><mml:math display="inline" id="M196"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>.</p>
</sec>
</sec>
</sec>
<sec id="sec032" sec-type="conclusions">
<title>Discussion</title>
<p>Using our model, implemented in the Bayesian programming framework, we have been able to implement and test different hypotheses concerning speech motor adaptation to perturbed auditory feedback. In this framework, processes are not directly modeled but are derived from a common set of knowledge, which is represented by means of a joint probability distribution. Hence, in this approach, perception and production processes become naturally related since changes to the underlying knowledge may impact them together. Note that this framework is not restricted to speech, but may be of interest in other areas where production and perception processes have been shown to interact (for instance in the arm motor control literature, see Haith et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref062">62</xref>] and Ito et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref063">63</xref>] for alternative approaches, see also Gilet et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref036">36</xref>] in the context of joint modeling of perception and production of isolated cursive letters).</p>
<p>We have applied this framework to study the perceptual changes that result from motor learning in adaptation to an auditory perturbation in speech. To do so, we have proposed a number of hypotheses about the changes to the common underlying knowledge that may result from motor learning and we have investigated how these changes may give rise to the observed changes in perception and production. This approach has allowed us to identify different possible origins that all may contribute to these changes, supporting but also specifying the interpretation proposed by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>].</p>
<p>Our experimental simulations provide a number of major results: (1) the induced perceptual shift may actually be compatible with either an auditory or a combined auditory and somatosensory characterization of perceptual targets; (2) the incomplete motor response to auditory perturbations may be due to a mixture of components, related to the combined specification of the phonemic targets for speech production in auditory and somatosensory terms; (3) the asymmetry in perceptual compensation observed in L-14 is also compatible with both theoretical frameworks in speech perception, but actually appears to be sensitive to fine tuning of the experimental parameters in the simulations; (4) patterns of correlations between perceptual and motor responses may be driven by various factors that shed a crucial light on final interpretations of the experimental data.</p>
<p>Of course, these simulations quantitatively depend on a number of modeling choices introduced in Section “Selected aspects for modeling”, that are aimed at making simulations tractable and easy to analyze and interpret. This basically includes: (1) the assumption that sensory and motor spaces are one-dimensional, (2) the assumption that sensory-motor mappings are linear (Eqs (<xref ref-type="disp-formula" rid="pcbi.1005942.e002">2</xref>–<xref ref-type="disp-formula" rid="pcbi.1005942.e005">5</xref>, <xref ref-type="disp-formula" rid="pcbi.1005942.e024">15</xref> and <xref ref-type="disp-formula" rid="pcbi.1005942.e025">16</xref>), and (3) the specific tuning of parameters considered in the update hypotheses for adaptation. Still, it is important to stress that the four major results summarized previously have an intrinsic validity, which makes them largely independent of the specific modeling choices. This is due to two major reasons. Firstly, the modeling framework introduced in this work has actually been developed over the years completely independently of the experimental data discussed here. This framework is essentially conceived as a general architecture for formalizing classical assumptions about perceptuo-motor relationships in speech communication [<xref ref-type="bibr" rid="pcbi.1005942.ref012">12</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref014">14</xref>].</p>
<p>Secondly, the four major results appear as general, and likely to be obtained whatever the specific choices in the model. Indeed, the first, second and fourth of these results express direct consequences of the model architecture, in which multisensory fusion (between auditory and somatosensory representations) in speech production and possibly in speech perception naturally result in trading relationships leading to (1) perceptual adaptation in response to the motor adaptation (2) incomplete response to perturbation and (3) various types of correlation patterns between motor and perceptual adaptation. The case of the third result (asymmetry in perceptual compensation) is quite interesting in this respect. Indeed, it is, contrary to the others, largely ad hoc and related to the specific modeling choices (i.e., the precise relation between mean and variance and parameters of the local update of the internal model, see Supporting information <xref ref-type="supplementary-material" rid="pcbi.1005942.s003">S3</xref> and <xref ref-type="supplementary-material" rid="pcbi.1005942.s004">S4</xref> Text). This makes it fragile and probably not very robust experimentally. But this fragility can also be construed as a prediction: it means that asymmetries should vary from one study to the other, and that this observation is probably not as reliable as what was expected by the authors of L-14 (see for instance a recent study by Schuerman et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref064">64</xref>] where no significant boundary shift was obtained).</p>
<p>Interestingly, the symmetric vs. asymmetric nature of the perceptuo-motor adaptation process should also largely depend on the nature of the motor-to-sensory internal model, and it is quite well-known that the motor-to-sensory relationship is indeed highly nonlinear, and likely to vary greatly depending on the involved region of the motor or sensory space. This could well explain the difference between the study by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>] on vowels, that shows a lack of perceptual shift in the region of the auditory space related to what subjects heard in presence of the perturbation, and the study by Shiller et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref002">2</xref>] in which a perceptual shift in the corresponding regions with fricatives was observed.</p>
<p>Finally, with respect to the one-dimensional assumption, including additional dimensions in sensory and motor spaces may certainly bring interesting behaviors, such as trading relations between dimensions in compensation. However, the /i ɛ a/ continuum considered in L-14 can be basically seen as one-dimensional both in the articulatory space in which the location of the highest point of the tongue is controlled along the high/front—low/back dimension thanks to strong correlations between jaw opening and tongue position [<xref ref-type="bibr" rid="pcbi.1005942.ref065">65</xref>], —and in the acoustic space with correlated variations between F1 and F2 respectively increasing and decreasing from /i/ to /a/ [<xref ref-type="bibr" rid="pcbi.1005942.ref066">66</xref>]. Therefore, such additional effects would likely bring only a modulatory change to the magnitude of the resulting shifts in production and perception, without changing the general patterns of results in our simulation.</p>
<p>Therefore, we consider that the simulation results presented here have intrinsic validity. As a consequence, it is of interest to discuss them as some new evidence that can be confronted to important questions related to perceptuo-motor adaptation as discussed in the literature. This is what we will do now, around two points that are the nature of perceptual representations and the origins of incomplete compensation, before introducing some predictions and proposals for new experiments in the field.</p>
<sec id="sec033">
<title>Revisiting the interpretation presented in L-14</title>
<p>The first stage of our simulations (Section “Evaluation with respect to perception”) both supports and challenges the interpretation by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>], whereby their data would provide evidence for the role of motor knowledge in speech perception. On the one hand, hypothesis <inline-formula id="pcbi.1005942.e197"><alternatives><graphic id="pcbi.1005942.e197g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e197" xlink:type="simple"/><mml:math display="inline" id="M197"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, involving only an update of motor functions, is compatible with their interpretation and in fact also specifies it. Indeed, under this hypothesis a local compensation for the perturbation is required to generate a pattern of perceptual adaptation fitting the asymmetry reported in L-14. On the other hand, in the context of hypothesis <inline-formula id="pcbi.1005942.e198"><alternatives><graphic id="pcbi.1005942.e198g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e198" xlink:type="simple"/><mml:math display="inline" id="M198"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, involving both a local update of the auditory-motor internal model and a modification of the auditory characterization of the perturbed phoneme, a pure auditory theory of speech perception (<inline-formula id="pcbi.1005942.e199"><alternatives><graphic id="pcbi.1005942.e199g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e199" xlink:type="simple"/><mml:math display="inline" id="M199"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) also provides a pattern of perceptual shifts compatible with their data, even including asymmetries that were considered as key in their reasoning against auditory theories. In this case, changes in the auditory characterization of a phoneme, involving a coordinated shift of the center of its characterization and a reduction of its variance, are required to explain their results.</p>
<p>It is important to note that it is not unrealistic to assume that motor learning can induce such coordinated changes. Indeed, the shift in location may be explained by a mechanism aligning the auditory characterization of a vowel with its actual realization in presence of the auditory feedback perturbation. The reduction of variance could be attributed to the well-known selective adaptation phenomenon, as suggested by Kleinschmidt et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref067">67</xref>]: the repeated exposure to the same sound tends to make listeners more sensitive to variations of this sound. Note that, in S-09, selective adaptation was mentioned in order to explain the small perceptual boundary shift observed in their control group after the repeated exposure to the unaltered fricative /s/.</p>
<p>Therefore, at this stage, both an audio-motor and a pure auditory theory may be compatible with the data in L-14. However, the analysis, based on correlations between the amplitude of the perceptual shift and the magnitude of the compensation, indicates that none of the two previous interpretations is compatible with the observations described in L-14. Only hypothesis <inline-formula id="pcbi.1005942.e200"><alternatives><graphic id="pcbi.1005942.e200g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e200" xlink:type="simple"/><mml:math display="inline" id="M200"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, assuming the fusion of sensory pathways in speech perception and adaptation involving the combined updates of the auditory-motor internal model and the auditory characterization of the perturbed phoneme, was compatible with the absence of significant correlation reported in L-14.</p>
<p>In summary, our results support and clarify the initial interpretation of Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>]. By exploiting perceptuo-motor correlations, our results support the claim that both sensory and motor processes intervene in the observed perceptual shift. This result certainly speaks in favor of perceptuo-motor theories of speech perception, though further work should be done in order to better assess the relative contributions of each of these two sets of processes [<xref ref-type="bibr" rid="pcbi.1005942.ref014">14</xref>].</p>
</sec>
<sec id="sec034">
<title>Three suggested origins for incomplete compensation</title>
<p>Interestingly, in our model, all possible explanations of the link between motor learning and perceptual boundary shift are associated with incomplete compensation for the perturbation, even if the magnitude of the local update of the auditory-motor internal model fully matches the amplitude of the auditory perturbation. This is an important prediction of our model, since incomplete compensations have been systematically observed in all experiments involving a perturbation of the auditory feedback during speech production.</p>
<p>Three mechanisms can indeed be at the origin of incomplete compensation. Firstly, if motor learning induces only an update of the auditory-motor internal model in the context of a bi-modal speech production process, incomplete compensation comes from the interaction between the somatosensory and the auditory specifications of vowels. Secondly, if motor learning also induces a shift and a reduction of variance of the auditory specification of the perturbed phoneme, this provides an additional counter-influence to compensation and the magnitude of the change of the auditory characterization contributes to incomplete compensation. Thirdly, in all cases, if motor learning induces an update of the auditory-motor internal model, the magnitude of this update influences the extent of the compensation: the smaller the update, the more incomplete the compensation.</p>
<p>All these potential explanations of incomplete compensation for perturbations of the auditory feedback have been previously suggested in the literature. In particular, Katseff et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref068">68</xref>], among other hypotheses, compared the respective influences on the compensation magnitude of a possible interaction between the auditory and the somatosensory feedback <italic>versus</italic> of a possible shift of the auditory region characterizing the pronounced phoneme. They concluded that behavioral data about compensation for auditory perturbation published in the literature (including those in S-09) are more compatible with an interaction between the two sensory feedbacks.</p>
<p>According to them, in the case of the data in S-09, if the perceptual boundary shift is due to a shift of the auditory characterization of the perturbed phoneme, this latter shift should have the same small amplitude as the former one. Such a small shift of the auditory characterization of the phoneme could not explain the large magnitude of the reduction in compensation.</p>
<p>Our results allow us to qualify their conclusion. Indeed, we have shown that when the shift of the auditory characterization is associated with a reduction of its variance, the magnitude of this shift can be much larger than the magnitude of the perceptual boundary shift. In this case, the shift of the auditory characterization of the perturbed phoneme would perfectly account for the amplitude of the compensation.</p>
</sec>
<sec id="sec035">
<title>Caveats and future directions</title>
<p>At this stage, we have at our disposal a modeling framework to account for the links between production and perception processes. However, the present work focuses on adaptation, by comparing states before and after learning. Investigating the dynamic process occurring during adaptation could provide interesting further insights into the phenomena associated with adaptation. More specifically, the manner with which compensation strategies integrate sensory feedback would inform about the way the sensory-motor characteristics of speech production are updated during the learning phase. For instance, the completeness of compensation appears to be dependent on the amplitude of the perturbation: greater amplitudes of perturbation induce greater sensory errors which appear to result in smaller percentage of total compensation compared to smaller sensory errors. This result seems to be a general property of sensorimotor learning: indeed it has been reported for speech [<xref ref-type="bibr" rid="pcbi.1005942.ref053">53</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref068">68</xref>], for eye and arm movements [<xref ref-type="bibr" rid="pcbi.1005942.ref069">69</xref>, <xref ref-type="bibr" rid="pcbi.1005942.ref070">70</xref>] and even for bird song [<xref ref-type="bibr" rid="pcbi.1005942.ref071">71</xref>]. Still, the mechanisms responsible for this decrease in relative adaptation in the case of increasing sensory errors remain unclear.</p>
<p>Our model, in its current state, does not address this question, since it deals only with the consequences of parameters updates, and not with how these updates happen during the learning phase. However, the three possible origins of incomplete compensation (discussed in Section “Three suggested origins for incomplete compensation”) actually suggest three possible mechanisms whereby different magnitudes of sensory error would result in different degrees of compensation completeness. First, at the level of the sensory motor mappings, larger sensory errors may drive slower update in order to avoid a faulty reorganization of the learned mapping in the case of totally unexpected and inappropriate sensory signals (see for instance the work of [<xref ref-type="bibr" rid="pcbi.1005942.ref072">72</xref>] for a modeling approach in line with this idea). Second, at the level of the relative weighting of sensory pathways, the magnitude of sensory errors could disadvantage the pathway with larger errors, assuming that large unexpected errors would arise from inaccurate sensors, which would then be considered unreliable. Finally, at the level of the sensory characterization of the target, larger sensory perturbations may drive larger shifts of the intended target, resulting in smaller amounts of compensation compared to baseline. Each of these hypotheses deserves more careful analysis in light of the existing experimental data: for example, the third hypothesis appears unlikely, since, after the removal of the perturbation, subjects usually return close to the original baseline. Still, these three hypotheses definitely deserve further experimental focus.</p>
<p>Interestingly, our model gives different predictions for these three hypotheses. For instance, if larger sensory errors disadvantage the weighting of one of the sensory pathways, the model would predict that subjects would begin to compensate more for perturbations in the other sensory modality. Such sensory preferences have been reported previously in speech production [<xref ref-type="bibr" rid="pcbi.1005942.ref059">59</xref>]; however, to our knowledge, no study has explored the possibility that these preferences may be experimentally modulated by providing larger perturbations to one of the sensory modalities. On the other hand, if sensory errors only influence the update of the sensory-motor mapping or the shift of the sensory characterization of the target, the model would predict no influence of the amount of compensation to perturbations on the other sensory modality. Furthermore, evaluating the influence of the amplitude of perturbation with respect to the resulting perceptual shift could also allow distinguishing between these last two hypotheses. Indeed, if larger sensory errors decrease the update of the sensory-motor mapping, the model would predict a decrease in the amount of perceptual shift, whereas the contrary would happen if larger sensory errors drive greater shifts in the sensory characterization of the target.</p>
<p>Furthermore, as we suggested above, the present model is not limited to the study of auditory perturbations, and investigating the consequences of somatosensory perturbations would allow further evaluation of its pertinence. Indeed, another interesting prediction of the model is that, if adaptation to a somatosensory perturbation updates the somatosensory-motor mapping, it would also induce a boundary shift in the auditory categorization of the perturbed phoneme (but in an opposite direction to perturbation, contrary to the case of auditory perturbations). Such perceptual change following adaptation to a somatosensory perturbation has been actually reported in speech by Nasir and Ostry [<xref ref-type="bibr" rid="pcbi.1005942.ref003">3</xref>]. Future development of the model would be needed to account for their results, since Nasir and Ostry’s paradigm uses a perturbation of the jaw along the horizontal direction, making thus possible a perturbation of the somatosensory feedback without inducing changes in the auditory domain.</p>
<p>More generally, the present model provides a powerful framework for testing hypotheses on the relative roles of auditory and somatosensory representations and processes in perceptual and motor responses to perturbations. Indeed, any means likely to modulate one or the other input (e.g., by exploiting inter-individual variability—or by decreasing the salience of one modality relative to the other, by various techniques such as masking or inhibition of a given channel) should modify the amount of response to perturbations, and thus generate specific quantitative predictions to be compared with new experimental data (e.g., [<xref ref-type="bibr" rid="pcbi.1005942.ref073">73</xref>]).</p>
<p>Finally, it could be interesting to relate our computational framework with putative neuroanatomical networks suggested by neurocognitive data from the literature. As a matter of fact, a number of studies have explored the neuroanatomy of circuits in charge of monitoring responses to auditory or somatosensory perturbations in speech production (e.g., [<xref ref-type="bibr" rid="pcbi.1005942.ref074">74</xref>–<xref ref-type="bibr" rid="pcbi.1005942.ref081">81</xref>]). Even though this is out of the focus of the present study, we have already undertaken studies suggesting possible neuroanatomical correlates of the generic COSMO model [<xref ref-type="bibr" rid="pcbi.1005942.ref082">82</xref>], which is compatible with the current computational model. A future step in this direction is to adapt the generic architecture to the specific processes associated to perturbation compensation. This would be necessary for better addressing the dynamic adaptation processes mentioned previously in this section.</p>
</sec>
<sec id="sec036">
<title>Conclusions</title>
<p>In order to better understand the mechanisms underlying the observations reported by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>], we have elaborated a simplified Bayesian model of speech production and speech perception in which phonemes are characterized both in somatosensory and auditory terms. Speech production is assumed to be guided by both sensory characterizations (hypothesis <inline-formula id="pcbi.1005942.e201"><alternatives><graphic id="pcbi.1005942.e201g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e201" xlink:type="simple"/><mml:math display="inline" id="M201"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Prod</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>). Two hypotheses concerning speech perception processes were evaluated: (1) speech perception relies only on the auditory pathway (hypothesis <inline-formula id="pcbi.1005942.e202"><alternatives><graphic id="pcbi.1005942.e202g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e202" xlink:type="simple"/><mml:math display="inline" id="M202"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>), or (2) speech perception relies on the fusion of both auditory and somatosensory pathways (hypothesis <inline-formula id="pcbi.1005942.e203"><alternatives><graphic id="pcbi.1005942.e203g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e203" xlink:type="simple"/><mml:math display="inline" id="M203"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>). We have also considered different hypotheses on the possible consequences of motor adaptation: (1) an update of the auditory-motor internal model, (2) an update of the auditory characterization of the perturbed phoneme, and (3) an update of its somatosensory characterization. Taken separately or in combination, these three update hypotheses lead to seven possible adaptation hypotheses. Combined with the two perception hypotheses <inline-formula id="pcbi.1005942.e204"><alternatives><graphic id="pcbi.1005942.e204g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e204" xlink:type="simple"/><mml:math display="inline" id="M204"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005942.e205"><alternatives><graphic id="pcbi.1005942.e205g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e205" xlink:type="simple"/><mml:math display="inline" id="M205"><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, these adaptation hypotheses lead to different possible scenarios for explaining the observations of the study of Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>].</p>
<p>In the context of our Bayesian model, we have compared the predictions of these possible scenarios with the experimental observations reported by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>]. Considering results in perception and production, our simulations indicate that three combined perception-adaptation hypotheses can reproduce the characteristics of the perceptual boundary shift observed in L-14: (1) speech perception relies both on the somatosensory and auditory pathways, and motor adaptation induces only a local update of the auditory-motor internal model (<inline-formula id="pcbi.1005942.e206"><alternatives><graphic id="pcbi.1005942.e206g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e206" xlink:type="simple"/><mml:math display="inline" id="M206"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mi>M</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>); (2) speech perception relies only on the auditory pathway and motor adaptation induces both a local update of the auditory-motor internal model and the combined shift and size reduction of the auditory characterization of the perturbed phoneme (<inline-formula id="pcbi.1005942.e207"><alternatives><graphic id="pcbi.1005942.e207g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e207" xlink:type="simple"/><mml:math display="inline" id="M207"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>A</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>), (3) speech perception relies both on the somatosensory and auditory pathways and motor adaptation induces both a local update of the auditory-motor internal model and the combined shift and size reduction of the perturbed phoneme (<inline-formula id="pcbi.1005942.e208"><alternatives><graphic id="pcbi.1005942.e208g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e208" xlink:type="simple"/><mml:math display="inline" id="M208"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>).</p>
<p>From that basis, these three selected hypotheses were further evaluated with respect to the predicted correlation between compensation in production and perceptual shift. Our results indicate that only the third hypothesis (<inline-formula id="pcbi.1005942.e209"><alternatives><graphic id="pcbi.1005942.e209g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005942.e209" xlink:type="simple"/><mml:math display="inline" id="M209"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi> <mml:mtext>Per</mml:mtext> <mml:mi>F</mml:mi></mml:msubsup> <mml:mo>⊕</mml:mo> <mml:msubsup><mml:mi>H</mml:mi> <mml:mtext>Ad</mml:mtext> <mml:mrow><mml:mi>M</mml:mi> <mml:mo>Φ</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>) is able to account for the absence of correlation reported by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>].</p>
<p>Altogether, this computational approach strengthens and specifies the interpretation by Lametti et al. [<xref ref-type="bibr" rid="pcbi.1005942.ref001">1</xref>] of their experimental data in favor of perceptuo-motor links in speech perception. Our model provides novel insights into the mechanisms influencing speech perception and production after adaptation to perturbations of the auditory feedback. Future work should focus on the dynamics of adaptation as well as on the relation between the degree of adaptation and the amount of perceptual changes.</p>
</sec>
</sec>
<sec id="sec037">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005942.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Detailed model definition.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005942.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Derivation of Bayesian inference equations.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005942.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.s003" xlink:type="simple">
<label>S3 Text</label>
<caption>
<title>Specification of parameters for the local update of the auditory-motor mapping <italic>ρ</italic><sub><italic>A</italic></sub>.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005942.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.s004" xlink:type="simple">
<label>S4 Text</label>
<caption>
<title>Specification of parameters of the sensory characterizations of phonemes <italic>P</italic>(<italic>A</italic><sub>Φ</sub> | Φ) and <italic>P</italic>(<italic>S</italic><sub>Φ</sub> | Φ).</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005942.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005942.s005" xlink:type="simple">
<label>S5 Text</label>
<caption>
<title>From L-14 to S-09: Variations around the theme.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1005942.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lametti</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Rochet-Capellan</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Neufeld</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Shiller</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Plasticity in the Human Speech Motor System Drives Changes in Speech Perception</article-title>. <source>Journal of Neuroscience</source>. <year>2014</year>;<volume>34</volume>(<issue>31</issue>):<fpage>10339</fpage>–<lpage>10346</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0108-14.2014" xlink:type="simple">10.1523/JNEUROSCI.0108-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25080594</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shiller</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Sato</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gracco</surname> <given-names>VL</given-names></name>, <name name-style="western"><surname>Baum</surname> <given-names>SR</given-names></name>. <article-title>Perceptual recalibration of speech sounds following speech motor learning</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2009</year>;<volume>125</volume>(<issue>2</issue>):<fpage>1103</fpage>–<lpage>1113</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.3058638" xlink:type="simple">10.1121/1.3058638</ext-link></comment> <object-id pub-id-type="pmid">19206885</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nasir</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Auditory plasticity and speech motor learning</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2009</year>;<volume>106</volume>(<issue>48</issue>):<fpage>20470</fpage>–<lpage>20475</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0907032106" xlink:type="simple">10.1073/pnas.0907032106</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Blumstein</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Stevens</surname> <given-names>KN</given-names></name>. <article-title>Phonetic features and acoustic invariance in speech</article-title>. <source>Cognition</source>. <year>1981</year>;<volume>10</volume>(<issue>1-3</issue>):<fpage>25</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0010-0277(81)90021-4" xlink:type="simple">10.1016/0010-0277(81)90021-4</ext-link></comment> <object-id pub-id-type="pmid">7198546</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liberman</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Mattingly</surname> <given-names>IG</given-names></name>. <article-title>The motor theory of speech perception revised</article-title>. <source>Cognition</source>. <year>1985</year>;<volume>21</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>36</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0010-0277(85)90021-6" xlink:type="simple">10.1016/0010-0277(85)90021-6</ext-link></comment> <object-id pub-id-type="pmid">4075760</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stevens</surname> <given-names>KN</given-names></name>. <article-title>On the quantal nature of speech</article-title>. <source>Journal of Phonetics</source>. <year>1989</year>;<volume>17</volume>:<fpage>3</fpage>–<lpage>45</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fowler</surname> <given-names>CA</given-names></name>. <article-title>Listeners do hear sounds, not tongues</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>1996</year>;<volume>99</volume>(<issue>3</issue>):<fpage>1730</fpage>–<lpage>1741</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.415237" xlink:type="simple">10.1121/1.415237</ext-link></comment> <object-id pub-id-type="pmid">8819862</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartz</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Basirat</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ménard</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sato</surname> <given-names>M</given-names></name>. <article-title>The Perception-for-Action-Control Theory (PACT): A perceptuo-motor theory of speech perception</article-title>. <source>Journal of Neurolinguistics</source>. <year>2012</year>;<volume>25</volume>(<issue>5</issue>):<fpage>336</fpage>–<lpage>354</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneuroling.2009.12.004" xlink:type="simple">10.1016/j.jneuroling.2009.12.004</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref009">
<label>9</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Patri</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Perrier</surname> <given-names>P</given-names></name>. <chapter-title>Modélisation bayésienne de la planification motrice des gestes de parole: Évaluation du rôle des différentes modalités sensorielles</chapter-title>. In: <source>J.E.P. 2016</source>. <volume>vol. 1</volume>; <year>2016</year>. p. <fpage>419</fpage>–<lpage>427</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cressman</surname> <given-names>EK</given-names></name>, <name name-style="western"><surname>Henriques</surname> <given-names>DYP</given-names></name>. <article-title>Sensory recalibration of hand position following visuomotor adaptation</article-title>. <source>Journal of Neurophysiology</source>. <year>2009</year>;<volume>102</volume>(<issue>6</issue>):<fpage>3505</fpage>–<lpage>3518</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00514.2009" xlink:type="simple">10.1152/jn.00514.2009</ext-link></comment> <object-id pub-id-type="pmid">19828727</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Darainy</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mattar</surname> <given-names>AAG</given-names></name>, <name name-style="western"><surname>Wong</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gribble</surname> <given-names>PL</given-names></name>. <article-title>Somatosensory plasticity and motor learning</article-title>. <source>The Journal of Neuroscience</source>. <year>2010</year>;<volume>30</volume>(<issue>15</issue>):<fpage>5384</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4571-09.2010" xlink:type="simple">10.1523/JNEUROSCI.4571-09.2010</ext-link></comment> <object-id pub-id-type="pmid">20392960</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Moulin-Frier</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Laurent</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bessière</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>. <article-title>Adverse conditions improve distinguishability of auditory, motor and perceptuo-motor theories of speech perception: an exploratory Bayesian modeling study</article-title>. <source>Language and Cognitive Processes</source>. <year>2012</year>;<volume>27</volume>(<issue>7–8</issue>):<fpage>1240</fpage>–<lpage>1263</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/01690965.2011.645313" xlink:type="simple">10.1080/01690965.2011.645313</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Moulin-Frier</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Bessière</surname> <given-names>P</given-names></name>. <article-title>COSMO (“Communicating about Objects using Sensory-Motor Operations”): a Bayesian modeling framework for studying speech communication and the emergence of phonological systems</article-title>. <source>Journal of Phonetics (special issue “On the cognitive nature of speech sound systems”)</source>. <year>2015</year>;<volume>53</volume>:<fpage>5</fpage>–<lpage>41</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laurent</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Barnaud</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Bessière</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>. <article-title>The complementary roles of auditory and motor information evaluated in a Bayesian perceptuo-motor model of speech perception</article-title>. <source>Psychological Review</source>. <year>2017</year>;. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/rev0000069" xlink:type="simple">10.1037/rev0000069</ext-link></comment> <object-id pub-id-type="pmid">28471206</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref015">
<label>15</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>. <source>Bayesian Algorithmic Modeling in Cognitive Science [Habilitation à Diriger des Recherches (HDR)]</source>. <publisher-name>Université Grenoble Alpes</publisher-name>; <year>2015</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref016">
<label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bessière</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Mazer</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Ahuactzin</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Mekhnacha</surname> <given-names>K</given-names></name>. <source>Bayesian Programming</source>. <publisher-loc>Boca Raton, Florida</publisher-loc>: <publisher-name>CRC Press</publisher-name>; <year>2013</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref017">
<label>17</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Marr</surname> <given-names>D</given-names></name>. <source>Vision. A Computational Investigation into the Human Representation and Processing of Visual Information</source>. <publisher-loc>New York, USA</publisher-loc>: <publisher-name>W.H. Freeman and Company</publisher-name>; <year>1982</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref018">
<label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Barnaud ML, Schwartz JL, Diard J, Bessière P. Sensorimotor learning in a Bayesian computational model of speech communication. In: The Sixth Joint IEEE International Conference Developmental Learning and Epigenetic Robotics (ICDL-EPIROB 2016). IEEE; 2016. p. 27–32.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref019">
<label>19</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Barnaud</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bessière</surname> <given-names>P</given-names></name>. <chapter-title>Assessing idiosyncrasies in a Bayesian model of speech communication</chapter-title>. In: <source>Interspeech 2016</source>; <year>2016</year>. p. <fpage>2080</fpage>–<lpage>2084</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Patri</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Perrier</surname> <given-names>P</given-names></name>. <article-title>Optimal speech motor control and token-to-token variability: a Bayesian modeling approach</article-title>. <source>Biological Cybernetics</source>. <year>2015</year>;<volume>109</volume>(<issue>6</issue>):<fpage>611</fpage>–<lpage>626</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00422-015-0664-4" xlink:type="simple">10.1007/s00422-015-0664-4</ext-link></comment> <object-id pub-id-type="pmid">26497359</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref021">
<label>21</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Patri</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Perrier</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>. <chapter-title>Bayesian modeling in speech motor control: a principled structure for the integration of various constraints</chapter-title>. In: <source>Interspeech 2016</source>. <publisher-loc>San Francisco</publisher-loc>; <year>2016</year>. p. <fpage>3588</fpage>–<lpage>3592</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sanguineti</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Laboissière</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>A dynamic biomechanical model for neural control of speech production</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>1998</year>;<volume>103</volume>(<issue>3</issue>):<fpage>1615</fpage>–<lpage>1627</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.421296" xlink:type="simple">10.1121/1.421296</ext-link></comment> <object-id pub-id-type="pmid">9514026</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Atal</surname> <given-names>BS</given-names></name>, <name name-style="western"><surname>Chang</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Mathews</surname> <given-names>MV</given-names></name>, <name name-style="western"><surname>Tukey</surname> <given-names>JW</given-names></name>. <article-title>Inversion of articulatory-to-acoustic transformation in the vocal tract by a computer-sorting technique</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>1978</year>;<volume>63</volume>(<issue>5</issue>):<fpage>1535</fpage>–<lpage>1555</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.381848" xlink:type="simple">10.1121/1.381848</ext-link></comment> <object-id pub-id-type="pmid">690333</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cai</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ghosh</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Guenther</surname> <given-names>FH</given-names></name>, <name name-style="western"><surname>Perkell</surname> <given-names>JS</given-names></name>. <article-title>Focal Manipulations of Formant Trajectories Reveal a Role of Auditory Feedback in the Online Control of Both Within-Syllable and Between-Syllable Speech Timing</article-title>. <source>Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>45</issue>):<fpage>16483</fpage>–<lpage>16490</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3653-11.2011" xlink:type="simple">10.1523/JNEUROSCI.3653-11.2011</ext-link></comment> <object-id pub-id-type="pmid">22072698</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Purcell</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Munhall</surname> <given-names>KG</given-names></name>. <article-title>Compensation following real-time manipulation of formants in isolated vowels</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2006</year>;<volume>119</volume>(<issue>4</issue>):<fpage>2288</fpage>–<lpage>2297</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.2173514" xlink:type="simple">10.1121/1.2173514</ext-link></comment> <object-id pub-id-type="pmid">16642842</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tremblay</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Shiller</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Somatosensory basis of speech production</article-title>. <source>Nature</source>. <year>2003</year>;<volume>423</volume>(<issue>6942</issue>):<fpage>866</fpage>–<lpage>869</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature01710" xlink:type="simple">10.1038/nature01710</ext-link></comment> <object-id pub-id-type="pmid">12815431</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nasir</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Speech motor learning in profoundly deaf adults</article-title>. <source>Nature Neuroscience</source>. <year>2008</year>;<volume>11</volume>(<issue>10</issue>):<fpage>1217</fpage>–<lpage>22</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2193" xlink:type="simple">10.1038/nn.2193</ext-link></comment> <object-id pub-id-type="pmid">18794839</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Savariaux</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Perrier</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Orliaguet</surname> <given-names>JP</given-names></name>. <article-title>Compensation strategies for the perturbation of the rounded vowel [u] using a lip tube: a study of the control space in speech production</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>1995</year>;<volume>98</volume>(<issue>5</issue>):<fpage>2428</fpage>–<lpage>2442</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.413277" xlink:type="simple">10.1121/1.413277</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Houde</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>Sensorimotor adaptation of speech I: compensation and adaptation</article-title>. <source>Journal of Speech, Language, and Hearing Research</source>. <year>2002</year>;<volume>45</volume>(<issue>2</issue>):<fpage>295</fpage>–<lpage>310</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1044/1092-4388(2002/023)" xlink:type="simple">10.1044/1092-4388(2002/023)</ext-link></comment> <object-id pub-id-type="pmid">12003512</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Scott</surname> <given-names>SK</given-names></name>, <name name-style="western"><surname>Wise</surname> <given-names>RJS</given-names></name>. <article-title>The functional neuroanatomy of prelexical processing in speech perception</article-title>. <source>Cognition</source>. <year>2004</year>;<volume>92</volume>(<issue>1-2</issue>):<fpage>13</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2002.12.002" xlink:type="simple">10.1016/j.cognition.2002.12.002</ext-link></comment> <object-id pub-id-type="pmid">15037125</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hickok</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Poeppel</surname> <given-names>D</given-names></name>. <article-title>The cortical organization of speech processing</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2007</year>;<volume>8</volume>(<issue>5</issue>):<fpage>393</fpage>–<lpage>402</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn2113" xlink:type="simple">10.1038/nrn2113</ext-link></comment> <object-id pub-id-type="pmid">17431404</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rauschecker</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Scott</surname> <given-names>SK</given-names></name>. <article-title>Maps and streams in the auditory cortex: nonhuman primates illuminate human speech processing</article-title>. <source>Nature Neuroscience</source>. <year>2009</year>;<volume>12</volume>(<issue>6</issue>):<fpage>718</fpage>–<lpage>724</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2331" xlink:type="simple">10.1038/nn.2331</ext-link></comment> <object-id pub-id-type="pmid">19471271</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Friederici</surname> <given-names>AD</given-names></name>. <article-title>The cortical language circuit: from auditory perception to sentence comprehension</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2012</year>;<volume>16</volume>(<issue>5</issue>):<fpage>262</fpage>–<lpage>268</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2012.04.001" xlink:type="simple">10.1016/j.tics.2012.04.001</ext-link></comment> <object-id pub-id-type="pmid">22516238</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ito</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tiede</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Somatosensory function in speech perception</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2009</year>;<volume>106</volume>(<issue>4</issue>):<fpage>1245</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0810063106" xlink:type="simple">10.1073/pnas.0810063106</ext-link></comment> <object-id pub-id-type="pmid">19164569</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Skipper</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Devlin</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Lametti</surname> <given-names>DR</given-names></name>. <article-title>The hearing ear is always found close to the speaking tongue: review of the role of the motor system in speech perception</article-title>. <source>Brain and Language</source>. <year>2017</year>;<volume>164</volume>:<fpage>77</fpage>–<lpage>105</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.bandl.2016.10.004" xlink:type="simple">10.1016/j.bandl.2016.10.004</ext-link></comment> <object-id pub-id-type="pmid">27821280</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gilet</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Diard</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bessière</surname> <given-names>P</given-names></name>. <article-title>Bayesian action—perception computational model: interaction of production and recognition of cursive letters</article-title>. <source>PLOS ONE</source>. <year>2011</year>;<volume>6</volume>(<issue>6</issue>):<fpage>e20387</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0020387" xlink:type="simple">10.1371/journal.pone.0020387</ext-link></comment> <object-id pub-id-type="pmid">21674043</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kawato</surname> <given-names>M</given-names></name>. <article-title>Internal models for motor control and trajectory planning</article-title>. <source>Current Opinion in Neurobiology</source>. <year>1999</year>;<volume>9</volume>(<issue>6</issue>):<fpage>718</fpage>–<lpage>727</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0959-4388(99)00028-8" xlink:type="simple">10.1016/S0959-4388(99)00028-8</ext-link></comment> <object-id pub-id-type="pmid">10607637</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Miall</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Kawato</surname> <given-names>M</given-names></name>. <article-title>Internal models in the cerebellum</article-title>. <source>Trends in Cognitive Sciences</source>. <year>1998</year>;<volume>2</volume>(<issue>9</issue>):<fpage>338</fpage>–<lpage>347</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1364-6613(98)01221-2" xlink:type="simple">10.1016/S1364-6613(98)01221-2</ext-link></comment> <object-id pub-id-type="pmid">21227230</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Rumelhart</surname> <given-names>DE</given-names></name>. <article-title>Forward models: supervised learning with a distal teacher</article-title>. <source>Cognitive Science</source>. <year>1992</year>;<volume>16</volume>(<issue>3</issue>):<fpage>307</fpage>–<lpage>354</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1207/s15516709cog1603_1" xlink:type="simple">10.1207/s15516709cog1603_1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Feldman</surname> <given-names>AG</given-names></name>. <article-title>A critical evaluation of the force control hypothesis in motor control</article-title>. <source>Experimental Brain Research</source>. <year>2003</year>;<volume>153</volume>(<issue>3</issue>):<fpage>275</fpage>–<lpage>288</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00221-003-1624-0" xlink:type="simple">10.1007/s00221-003-1624-0</ext-link></comment> <object-id pub-id-type="pmid">14610628</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pilon</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>De Serres</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Feldman</surname> <given-names>AG</given-names></name>. <article-title>Threshold position control of arm movement with anticipatory increase in grip force</article-title>. <source>Experimental Brain Research</source>. <year>2007</year>;<volume>181</volume>(<issue>1</issue>):<fpage>49</fpage>–<lpage>67</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00221-007-0901-8" xlink:type="simple">10.1007/s00221-007-0901-8</ext-link></comment> <object-id pub-id-type="pmid">17340124</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kleinschmidt</surname> <given-names>DF</given-names></name>, <name name-style="western"><surname>Jaeger</surname> <given-names>TF</given-names></name>. <article-title>Robust speech perception: recognize the familiar, generalize to the similar, and adapt to the novel</article-title>. <source>Psychological Review</source>. <year>2015</year>;<volume>122</volume>(<issue>2</issue>):<fpage>148</fpage>–<lpage>203</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0038695" xlink:type="simple">10.1037/a0038695</ext-link></comment> <object-id pub-id-type="pmid">25844873</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>De Boer</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Kuhl</surname> <given-names>PK</given-names></name>. <article-title>Investigating the role of infant-directed speech with a computer model</article-title>. <source>Acoustics Research Letters Online</source>. <year>2003</year>;<volume>4</volume>(<issue>4</issue>):<fpage>129</fpage>–<lpage>134</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.1613311" xlink:type="simple">10.1121/1.1613311</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clayards</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tanenhaus</surname> <given-names>MK</given-names></name>, <name name-style="western"><surname>Aslin</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Jacobs</surname> <given-names>RA</given-names></name>. <article-title>Perception of speech reflects optimal use of probabilistic speech cues</article-title>. <source>Cognition</source>. <year>2008</year>;<volume>108</volume>:<fpage>804</fpage>–<lpage>809</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cognition.2008.04.004" xlink:type="simple">10.1016/j.cognition.2008.04.004</ext-link></comment> <object-id pub-id-type="pmid">18582855</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref045">
<label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Clayards M, Aslin RN, Tanenhaus MK, Jacobs RA. Within category phonetic variability affects perceptual uncertainty. In: Proc. 16th International Congress of Phonetic Sciences, Saarbrücken, Germany; 2007. p. 701–704.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Feldman</surname> <given-names>NH</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Morgan</surname> <given-names>JL</given-names></name>. <article-title>The influence of categories on perception: explaining the perceptual magnet effect as optimal statistical inference</article-title>. <source>Psychological Review</source>. <year>2009</year>;<volume>116</volume>(<issue>4</issue>):<fpage>752</fpage>–<lpage>782</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0017196" xlink:type="simple">10.1037/a0017196</ext-link></comment> <object-id pub-id-type="pmid">19839683</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref047">
<label>47</label>
<mixed-citation publication-type="other" xlink:type="simple">Fowler CA. An event approach to the study of speech perception from a direct-realist perspective. Status Report on Speech Research, edited by IG Mattingly and N O’Brien, Haskins Laboratories, New Haven, CT. 1986; p. 139–169.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source>. <year>2002</year>;<volume>415</volume>(<issue>6870</issue>):<fpage>429</fpage>–<lpage>433</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/415429a" xlink:type="simple">10.1038/415429a</ext-link></comment> <object-id pub-id-type="pmid">11807554</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tremblay</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Houle</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Specificity of Speech Motor Learning</article-title>. <source>The Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>10</issue>):<fpage>2426</fpage>–<lpage>2434</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4196-07.2008" xlink:type="simple">10.1523/JNEUROSCI.4196-07.2008</ext-link></comment> <object-id pub-id-type="pmid">18322088</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rochet-Capellan</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Richer</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Nonhomogeneous transfer reveals specificity in speech motor learning</article-title>. <source>Journal of Neurophysiolgy</source>. <year>2012</year>;<volume>107</volume>(<issue>6</issue>):<fpage>1711</fpage>–<lpage>1717</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00773.2011" xlink:type="simple">10.1152/jn.00773.2011</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mattar</surname> <given-names>AAG</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Modifiability of generalization in dynamics learning</article-title>. <source>Journal of Neurophysiology</source>. <year>2007</year>;<volume>98</volume>:<fpage>3321</fpage>–<lpage>3329</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00576.2007" xlink:type="simple">10.1152/jn.00576.2007</ext-link></comment> <object-id pub-id-type="pmid">17928561</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Villacorta</surname> <given-names>VM</given-names></name>, <name name-style="western"><surname>Perkell</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Guenther</surname> <given-names>FH</given-names></name>. <article-title>Sensorimotor adaptation to perturbations of vowel acoustics and its relation to perception</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2007</year>;<volume>122</volume>(<issue>4</issue>):<fpage>2306</fpage>–<lpage>2319</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.2773966" xlink:type="simple">10.1121/1.2773966</ext-link></comment> <object-id pub-id-type="pmid">17902866</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>MacDonald</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Goldberg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Munhall</surname> <given-names>KG</given-names></name>. <article-title>Compensations in response to real-time formant perturbations of different magnitudes</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2010</year>;<volume>127</volume>(<issue>2</issue>):<fpage>1059</fpage>–<lpage>1068</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.3278606" xlink:type="simple">10.1121/1.3278606</ext-link></comment> <object-id pub-id-type="pmid">20136227</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref054">
<label>54</label>
<mixed-citation publication-type="other" xlink:type="simple">Caudrelier T, Perrier P, Schwartz JL, Rochet-Capellan A. Does auditory-motor learning of speech transfer from the CV syllable to the CVCV word? In: Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH. vol. 08-12-Sept; 2016. p. 2095–2099.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rochet-Capellan</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Simultaneous acquisition of multiple auditory-motor transformations in speech</article-title>. <source>The Journal of Neuroscience: the official journal of the Society for Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>7</issue>):<fpage>2657</fpage>–<lpage>2662</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.6020-10.2011" xlink:type="simple">10.1523/JNEUROSCI.6020-10.2011</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Houde</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>Sensorimotor Adaptation in Speech Production</article-title>. <source>Science (New York, NY)</source>. <year>1998</year>;<volume>1</volume>(<issue>5354</issue>):<fpage>1213</fpage>–<lpage>1216</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.279.5354.1213" xlink:type="simple">10.1126/science.279.5354.1213</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cai</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ghosh</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Guenther</surname> <given-names>FH</given-names></name>, <name name-style="western"><surname>Perkell</surname> <given-names>JS</given-names></name>. <article-title>Adaptive auditory feedback control of the production of formant trajectories in the Mandarin triphthong /iau/ and its pattern of generalization</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2010</year>;<volume>128</volume>(<issue>4</issue>):<fpage>2033</fpage>–<lpage>48</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.3479539" xlink:type="simple">10.1121/1.3479539</ext-link></comment> <object-id pub-id-type="pmid">20968374</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>MacDonald</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Purcell</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Munhall</surname> <given-names>KG</given-names></name>. <article-title>Probing the independence of formant control using altered auditory feedback</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2011</year>;<volume>129</volume>(<issue>2</issue>):<fpage>955</fpage>–<lpage>965</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.3531932" xlink:type="simple">10.1121/1.3531932</ext-link></comment> <object-id pub-id-type="pmid">21361452</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lametti</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Nasir</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Sensory preference in speech production revealed by simultaneous alteration of auditory and somatosensory feedback</article-title>. <source>The Journal of Neuroscience: the official journal of the Society for Neuroscience</source>. <year>2012</year>;<volume>32</volume>(<issue>27</issue>):<fpage>9351</fpage>–<lpage>9358</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0404-12.2012" xlink:type="simple">10.1523/JNEUROSCI.0404-12.2012</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yates</surname> <given-names>AJ</given-names></name>. <article-title>Delayed auditory feedback and shadowing</article-title>. <source>The Quarterly Journal of Experimental Psychology</source>. <year>1965</year>;<volume>17</volume>(<issue>2</issue>):<fpage>125</fpage>–<lpage>131</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/17470216508416421" xlink:type="simple">10.1080/17470216508416421</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref061">
<label>61</label>
<mixed-citation publication-type="other" xlink:type="simple">Perkell JS, Lane H, Ghosh S, Matthies ML. Mechanisms of vowel production: auditory goals and speaker acuity. In: Proceedings of the Eighth International Seminar on speech production, Strasbourg, France; 2008. p. 29–32.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref062">
<label>62</label>
<mixed-citation publication-type="other" xlink:type="simple">Haith A, Jackson CP, Miall RC, Vijayakumar S. Unifying the sensory and motor components of sensorimotor adaptation. In: Advances in Neural Information Processing Systems; 2009. p. 593–600.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ito</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Darainy</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sasaki</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>DJ</given-names></name>. <article-title>Computational model of motor learning and perceptual change</article-title>. <source>Biological Cybernetics</source>. <year>2013</year>;<volume>107</volume>(<issue>6</issue>):<fpage>653</fpage>–<lpage>667</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00422-013-0565-3" xlink:type="simple">10.1007/s00422-013-0565-3</ext-link></comment> <object-id pub-id-type="pmid">23989535</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schuerman</surname> <given-names>WL</given-names></name>, <name name-style="western"><surname>Meyer</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>McQueen</surname> <given-names>JM</given-names></name>. <article-title>Mapping the speech code: cortical responses linking the perception and production of vowels</article-title>. <source>Frontiers in Human Neuroscience</source>. <year>2017</year>;<volume>11</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2017.00161" xlink:type="simple">10.3389/fnhum.2017.00161</ext-link></comment> <object-id pub-id-type="pmid">28439232</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref065">
<label>65</label>
<mixed-citation publication-type="other" xlink:type="simple">Lindau M. Vowel features. Language. 1978; p. 541–563.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref066">
<label>66</label>
<mixed-citation publication-type="other" xlink:type="simple">Fant G. Feature analysis of Swedish vowels–a revisit. KTH, STL-QPSR. 1983; p. 2–3.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref067">
<label>67</label>
<mixed-citation publication-type="other" xlink:type="simple">Kleinschmidt D, Jaeger TF. A Bayesian belief updating model of phonetic recalibration and selective adaptation. In: 2nd Workshop on Cognitive Modeling and Computational Linguistics. June; 2011. p. 10–19.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Katseff</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Houde</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>K</given-names></name>. <article-title>Partial compensation for altered auditory feedback: a tradeoff with somatosensory feedback?</article-title> <source>Language and Speech</source>. <year>2012</year>;<volume>55</volume>(<issue>2</issue>):<fpage>295</fpage>–<lpage>308</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0023830911417802" xlink:type="simple">10.1177/0023830911417802</ext-link></comment> <object-id pub-id-type="pmid">22783636</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Robinson</surname> <given-names>FR</given-names></name>, <name name-style="western"><surname>Noto</surname> <given-names>CT</given-names></name>, <name name-style="western"><surname>Bevans</surname> <given-names>SE</given-names></name>. <article-title>Effect of visual error size on saccade adaptation in monkey</article-title>. <source>Journal of Neurophysiology</source>. <year>2003</year>;<volume>90</volume>(<issue>2</issue>):<fpage>1235</fpage>–<lpage>44</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00656.2002" xlink:type="simple">10.1152/jn.00656.2002</ext-link></comment> <object-id pub-id-type="pmid">12711711</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wei</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Körding</surname> <given-names>K</given-names></name>. <article-title>Relevance of error: what drives motor adaptation?</article-title> <source>Journal of Neurophysiology</source>. <year>2009</year>;<volume>101</volume>:<fpage>655</fpage>–<lpage>664</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.90545.2008" xlink:type="simple">10.1152/jn.90545.2008</ext-link></comment> <object-id pub-id-type="pmid">19019979</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sober</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Brainard</surname> <given-names>MS</given-names></name>. <article-title>Vocal learning is constrained by the statistics of sensorimotor experience</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2012</year>;<volume>109</volume>(<issue>51</issue>):<fpage>21099</fpage>–<lpage>103</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1213622109" xlink:type="simple">10.1073/pnas.1213622109</ext-link></comment> <object-id pub-id-type="pmid">23213223</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hahnloser</surname> <given-names>RHR</given-names></name>, <name name-style="western"><surname>Narula</surname> <given-names>G</given-names></name>. <article-title>A Bayesian account of vocal adaptation to pitch-shifted auditory feedback</article-title>. <source>PlOS ONE</source>. <year>2016</year>; p. <fpage>1</fpage>–<lpage>13</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005942.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schuerman</surname> <given-names>WL</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>McQueen</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Houde</surname> <given-names>J</given-names></name>. <article-title>Sensorimotor adaptation affects perceptual compensation for coarticulation</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>2017</year>;<volume>141</volume>(<issue>4</issue>):<fpage>2693</fpage>–<lpage>2704</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.4979791" xlink:type="simple">10.1121/1.4979791</ext-link></comment> <object-id pub-id-type="pmid">28464681</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Houde</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Sekihara</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Modulation of the auditory cortex during speech: an MEG study</article-title>. <source>Journal of Cognitive Neuroscience</source>. <year>2002</year>;<volume>14</volume>(<issue>8</issue>):<fpage>1125</fpage>–<lpage>1138</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089892902760807140" xlink:type="simple">10.1162/089892902760807140</ext-link></comment> <object-id pub-id-type="pmid">12495520</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Golfinopoulos</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Tourville</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Bohland</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Ghosh</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Nieto-Castanon</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Guenther</surname> <given-names>FH</given-names></name>. <article-title>fMRI investigation of unexpected somatosensory feedback perturbation during speech</article-title>. <source>NeuroImage</source>. <year>2011</year>;<volume>55</volume>(<issue>3</issue>):<fpage>1324</fpage>–<lpage>1338</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2010.12.065" xlink:type="simple">10.1016/j.neuroimage.2010.12.065</ext-link></comment> <object-id pub-id-type="pmid">21195191</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eliades</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name>. <article-title>Neural substrates of vocalization feedback monitoring in primate auditory cortex</article-title>. <source>Nature</source>. <year>2008</year>;<volume>453</volume>(<issue>7198</issue>):<fpage>1102</fpage>–<lpage>1106</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature06910" xlink:type="simple">10.1038/nature06910</ext-link></comment> <object-id pub-id-type="pmid">18454135</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref077">
<label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Christoffels</surname> <given-names>IK</given-names></name>, <name name-style="western"><surname>Formisano</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Schiller</surname> <given-names>NO</given-names></name>. <article-title>Neural correlates of verbal feedback processing: an fMRI study employing overt speech</article-title>. <source>Human Brain Mapping</source>. <year>2007</year>;<volume>28</volume>(<issue>9</issue>):<fpage>868</fpage>–<lpage>879</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.20315" xlink:type="simple">10.1002/hbm.20315</ext-link></comment> <object-id pub-id-type="pmid">17266104</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref078">
<label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hashimoto</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Sakai</surname> <given-names>KL</given-names></name>. <article-title>Brain activations during conscious self-monitoring of speech production with delayed auditory feedback: an fMRI study</article-title>. <source>Human Brain Mapping</source>. <year>2003</year>;<volume>20</volume>(<issue>1</issue>):<fpage>22</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.10119" xlink:type="simple">10.1002/hbm.10119</ext-link></comment> <object-id pub-id-type="pmid">12953303</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fu</surname> <given-names>CHY</given-names></name>, <name name-style="western"><surname>Vythelingum</surname> <given-names>GN</given-names></name>, <name name-style="western"><surname>Brammer</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>SCR</given-names></name>, <name name-style="western"><surname>Amaro</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Andrew</surname> <given-names>CM</given-names></name>, <etal>et al</etal>. <article-title>An fMRI study of verbal self-monitoring: neural correlates of auditory verbal feedback</article-title>. <source>Cerebral Cortex</source>. <year>2006</year>;<volume>16</volume>(<issue>7</issue>):<fpage>969</fpage>–<lpage>977</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhj039" xlink:type="simple">10.1093/cercor/bhj039</ext-link></comment> <object-id pub-id-type="pmid">16195470</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref080">
<label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tourville</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Reilly</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Guenther</surname> <given-names>FH</given-names></name>. <article-title>Neural mechanisms underlying auditory feedback control of speech</article-title>. <source>NeuroImage</source>. <year>2008</year>;<volume>39</volume>(<issue>3</issue>):<fpage>1429</fpage>–<lpage>1443</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2007.09.054" xlink:type="simple">10.1016/j.neuroimage.2007.09.054</ext-link></comment> <object-id pub-id-type="pmid">18035557</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref081">
<label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zheng</surname> <given-names>ZZ</given-names></name>, <name name-style="western"><surname>Munhall</surname> <given-names>KG</given-names></name>, <name name-style="western"><surname>Johnsrude</surname> <given-names>IS</given-names></name>. <article-title>Functional overlap between regions involved in speech perception and in monitoring one’s own voice during speech production</article-title>. <source>Journal of Cognitive Neuroscience</source>. <year>2010</year>;<volume>22</volume>(<issue>8</issue>):<fpage>1770</fpage>–<lpage>1781</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn.2009.21324" xlink:type="simple">10.1162/jocn.2009.21324</ext-link></comment> <object-id pub-id-type="pmid">19642886</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005942.ref082">
<label>82</label>
<mixed-citation publication-type="other" xlink:type="simple">Barnaud ML, Diard J, Bessière P, Schwartz JL. Computational simulations of perceptuo-motor idiosyncrasies support the involvement of motor knowledge in speech perception. Brain and Language. Forthcoming.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
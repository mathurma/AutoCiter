<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-01338</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005068</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Numerical analysis</subject><subj-group><subject>Extrapolation</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Motion</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Motion</subject><subj-group><subject>Velocity</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Psychophysics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>The Flash-Lag Effect as a Motion-Based Predictive Shift</article-title>
<alt-title alt-title-type="running-head">The Flash-Lag Effect as a Motion-Based Predictive Shift</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Khoei</surname> <given-names>Mina A.</given-names></name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Masson</surname> <given-names>Guillaume S.</given-names></name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9536-010X</contrib-id>
<name name-style="western">
<surname>Perrinet</surname> <given-names>Laurent U.</given-names></name>
<xref ref-type="aff" rid="aff001"/>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>Institut de Neurosciences de la Timone, UMR7289, CNRS / Aix-Marseille Université, Marseille, France</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Sporns</surname> <given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Indiana University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p>
<list list-type="simple">
<list-item>
<p><bold>Conceived and designed the experiments:</bold> MAK LUP GSM.</p>
</list-item>
<list-item>
<p><bold>Performed the experiments:</bold> MAK LUP.</p>
</list-item>
<list-item>
<p><bold>Analyzed the data:</bold> MAK LUP.</p>
</list-item>
<list-item>
<p><bold>Contributed reagents/materials/analysis tools:</bold> MAK LUP.</p>
</list-item>
<list-item>
<p><bold>Wrote the paper:</bold> MAK LUP GSM.</p>
</list-item>
</list>
</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">Laurent.Perrinet@univ-amu.fr</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>1</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>26</day>
<month>1</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>1</issue>
<elocation-id>e1005068</elocation-id>
<history>
<date date-type="received">
<day>9</day>
<month>8</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>21</day>
<month>7</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Khoei et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005068"/>
<abstract>
<p>Due to its inherent neural delays, the visual system has an outdated access to sensory information about the current position of moving objects. In contrast, living organisms are remarkably able to track and intercept moving objects under a large range of challenging environmental conditions. Physiological, behavioral and psychophysical evidences strongly suggest that position coding is extrapolated using an explicit and reliable representation of object’s motion but it is still unclear how these two representations interact. For instance, the so-called flash-lag effect supports the idea of a differential processing of position between moving and static objects. Although elucidating such mechanisms is crucial in our understanding of the dynamics of visual processing, a theory is still missing to explain the different facets of this visual illusion. Here, we reconsider several of the key aspects of the flash-lag effect in order to explore the role of motion upon neural coding of objects’ position. First, we formalize the problem using a Bayesian modeling framework which includes a graded representation of the degree of belief about visual motion. We introduce a motion-based prediction model as a candidate explanation for the perception of coherent motion. By including the knowledge of a fixed delay, we can model the dynamics of sensory information integration by extrapolating the information acquired at previous instants in time. Next, we simulate the optimal estimation of object position with and without delay compensation and compared it with human perception under a broad range of different psychophysical conditions. Our computational study suggests that the explicit, probabilistic representation of velocity information is crucial in explaining position coding, and therefore the flash-lag effect. We discuss these theoretical results in light of the putative corrective mechanisms that can be used to cancel out the detrimental effects of neural delays and illuminate the more general question of the dynamical representation at the present time of spatial information in the visual pathways.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Visual illusions are powerful tools to explore the limits and constraints of human perception. One of them has received considerable empirical and theoretical interests: the so-called “flash-lag effect”. When a visual stimulus moves along a continuous trajectory, it may be seen <italic>ahead</italic> of its veridical position with respect to an unpredictable event such as a punctuate flash. This illusion tells us something important about the visual system: contrary to classical computers, neural activity travels at a relatively slow speed. It is largely accepted that the resulting delays cause this perceived spatial lag of the flash. Still, after three decades of debates, there is no consensus regarding the underlying mechanisms. Herein, we re-examine the original hypothesis that this effect may be caused by the extrapolation of the stimulus’ motion that is naturally generated in order to compensate for neural delays. Contrary to classical models, we propose a novel theoretical framework, called parodiction, that optimizes this process by explicitly using the precision of both sensory and predicted motion. Using numerical simulations, we show that the parodiction theory subsumes many of the previously proposed models and empirical studies. More generally, the parodiction hypothesis proposes that neural systems implement generic neural computations that can systematically compensate the existing neural delays in order to represent the predicted visual scene at the present time. It calls for new experimental approaches to directly explore the relationships between neural delays and predictive coding.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>FACETS-ITN (EU funding)</institution>
</funding-source>
<award-id>FP7-PEOPLE-ITN-2008-237955</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Khoei</surname> <given-names>Mina</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>BrainScaleS (EU funding)</institution>
</funding-source>
<award-id>FP7-FET-2010-269921</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Masson</surname> <given-names>Guillaume S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>BrainScaleS (EU funding)</institution>
</funding-source>
<award-id>FP7-FET-2010-269921</award-id>
<principal-award-recipient>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9536-010X</contrib-id>
<name name-style="western">
<surname>Perrinet</surname> <given-names>Laurent Udo</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution>Agence Nationale de la Recherche (FR)</institution>
</funding-source>
<award-id>ANR-13-SHS2-0006</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Masson</surname> <given-names>Guillaume S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001665</institution-id>
<institution>Agence Nationale de la Recherche</institution>
</institution-wrap>
</funding-source>
<award-id>ANR-13-SHS2-0006</award-id>
<principal-award-recipient>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9536-010X</contrib-id>
<name name-style="western">
<surname>Perrinet</surname> <given-names>Laurent Udo</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by projects FACETS-ITN (EU funding, grant number 237955) and ‘BrainScaleS’ (EU funding, grant number FP7-269921). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="2"/>
<page-count count="31"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/laurentperrinet/Khoei_2017_PLoSCB" xlink:type="simple">https://github.com/laurentperrinet/Khoei_2017_PLoSCB</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<sec id="sec002">
<title>Neural delays and motion-induced position shifts</title>
<p>Though it is barely noticeable in everyday life, visual signals captured on the retina take a significant amount of time before they can elicit even the simplest actions such as eye movements. This neural delay is composed of two terms: a fixed delay caused by the axonal transfer of sensory signals up to motor effectors and a variable delay associated with the neural processing time occurring at each computational step. Moreover, different neural systems can lead to different delays, even for the simplest feed-forward sensorimotor transformations where most of the computational load occurs at sensory level. Just to mention, a delay of 90 ms is observed between the onset of retinal image motion and the first acceleration of tracking eye movements in humans [<xref ref-type="bibr" rid="pcbi.1005068.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref003">3</xref>] while the exact same sensorimotor transformation takes less than 60 ms in monkeys [<xref ref-type="bibr" rid="pcbi.1005068.ref002">2</xref>]. Furthermore, increasing signal uncertainty would further increase these delays [<xref ref-type="bibr" rid="pcbi.1005068.ref002">2</xref>] illustrating the fact that neural delays also vary with many environmental or contextual factors. A mere consequence of these unavoidable neural delays should be that we perceive sensory events with a slight, but permanent lag [<xref ref-type="bibr" rid="pcbi.1005068.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref005">5</xref>]. This is well illustrated in a position estimation task such as the one faced by a soccer referee. If a ball is shot at an unexpected instant by one fixed player, in the direction of another running player, he will generally perceive the moving player “ahead” of its actual position [<xref ref-type="bibr" rid="pcbi.1005068.ref006">6</xref>] and signal an off-side position despite the fact that the players’ physical positions were strictly aligned to that of the referee (see <xref ref-type="fig" rid="pcbi.1005068.g001">Fig 1</xref>). As a general rule, if no mechanism would intervene to compensate for such neural delays, one would expect severe inefficiencies in sensory computations as well as in goal-directed action control. On the contrary, there are ample evidences that animals can in fact cope with neural delays in order to plan and execute timely goal-directed actions. Thus, it seems evident that throughout natural evolution, some sophisticated compensatory mechanisms based on internal models have been selected [<xref ref-type="bibr" rid="pcbi.1005068.ref007">7</xref>]. Thus, studying neural delays and how they may be compensated is a critical question that needs to be resolved in order to decipher how basic neural computations such as the dynamical processing of sensory information can be efficiently performed (for a review, see [<xref ref-type="bibr" rid="pcbi.1005068.ref008">8</xref>]). Solving this enigma would have several theoretical consequences such as, in particular, understanding how neural activity can encode both space and time [<xref ref-type="bibr" rid="pcbi.1005068.ref009">9</xref>].</p>
<fig id="pcbi.1005068.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.g001</object-id>
<label>Fig 1</label>
<caption>
<title>The flash-lag effect (FLE) as a motion-induced predictive shift.</title>
<p>To follow the example given by [<xref ref-type="bibr" rid="pcbi.1005068.ref006">6</xref>], a football (soccer) player that would run along a continuous path (the green path, where the gradient of color denotes the flow of time) is perceived to be ahead (the red position) of its actual position at the unexpected moment a ball is shot (red star) even if these positions are physically aligned. A referee would then signal an “offside” position. Similarly, such a flash-lag effect (FLE) is observed systematically in psychophysical experiments by showing a moving and a flashed stimuli (here, a square). By varying their characteristics (speed, relative position), one can explore the fundamental principles of the FLE.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.g001" xlink:type="simple"/>
</fig>
<p>Although these neural delays are usually rather short, they can easily be unveiled by psychophysical experiments. This Flash-lag effect (FLE) is a well-studied perceptual illusion which is intimately linked with the existence of neural delays [<xref ref-type="bibr" rid="pcbi.1005068.ref010">10</xref>]. In a standard empirical variant of the FLE, a first stimulus moves continuously along the central horizontal axis of the screen display. At the time this moving stimulus reaches the center of the screen, a second stimulus is flashed in its near vicinity but in perfect vertical alignment with it. Despite the fact that horizontal positions of the two stimuli are physically identical at the time of the flash, the moving stimulus is most often perceived <italic>ahead</italic> of the flashed one (see the square stimulus in <xref ref-type="fig" rid="pcbi.1005068.g001">Fig 1</xref>). The flash-lag effect falls in the vast category of motion-induced position shifts (e.g. the Fröhlich effect or the representational momentum effect [<xref ref-type="bibr" rid="pcbi.1005068.ref011">11</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref013">13</xref>]), in which the perceived position of an object is biased by its own visual motion or by other motion signals from its visual surrounding. How can we relate the FLE with the existence of the aforementioned neural delays? Several experimental studies have suggested that this visual illusion unveils predictive mechanisms that could compensate for the existing neural delays by extrapolating the object’s motion [<xref ref-type="bibr" rid="pcbi.1005068.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref013">13</xref>]. Since in natural scenes smooth trajectories are more probable than jittered ones, an internal representation may dynamically integrate information along the trajectory in order to predict the most expected position of the stimulus forward in time, <italic>knowing</italic> an average estimate of the different neural delays. Though computationally simple, this algorithmic solution requires that neural computations can build and use an internal representation of position and velocity over time, that is, that they can manipulate the dynamic representation of a variable.</p>
<p>The aim of our theoretical work is to better understand the interactions between position and motion coding that are based on predictive mechanisms and that could be implemented within the early visual system. To do so, we introduce a generic probabilistic model that was previously shown to efficiently solve other classical problems in sensory processing such as the aperture problem and motion extrapolation [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. This computational framework allows to quantify the relative efficiency of these different coding mechanisms and to explain the main empirical psychophysical observations. We propose a novel solution for introducing neural delays in the dynamics of probabilistic inference and discuss how this approach is related to previous models of motion diffusion and position coding. Taking the Flash-lag effect as a well-documented illustration of the generic problem of computing with delays, we show that our model can coalesce most of the cardinal perceptual aspects of FLE and thus, unite the previous models described below. More generally, such generic computational principles could be shared by other sensory modalities facing similar delays.</p>
</sec>
<sec id="sec003">
<title>A brief overview of the Flash-lag effect</title>
<p>The Flash-lag effect was first discovered by Metzger [<xref ref-type="bibr" rid="pcbi.1005068.ref018">18</xref>] and subsequently investigated by MacKay [<xref ref-type="bibr" rid="pcbi.1005068.ref010">10</xref>]. After these early studies, the phenomenon did not attract much attention until Nijhawan begun to study a similar question. In his empirical approach, a moving and a static (flashed) stimuli are presented with a perfect spatial and temporal alignment at the time of the flash but most subjects perceive the moving object as leading in space (see <xref ref-type="fig" rid="pcbi.1005068.g001">Fig 1</xref>). Such perceptual effect was reproduced in other species, in particular in monkeys [<xref ref-type="bibr" rid="pcbi.1005068.ref019">19</xref>]. Motion extrapolation is the correction of the object’s position based on an estimate of its own motion over the time period introduced by neural delays. Nijhawan proposed that such motion extrapolation can explain this perceived spatial offset between the two stimuli. In this theoretical framework, the visual system is predictive and takes advantage of the available information about object’s motion in order to correct for the positional error caused by neural delays.</p>
<p>The seminal work of Nijhawan resurrected the interest for the FLE phenomenon. Since then, the perceptual mechanisms underlying the FLE have been extensively explored by the group of Nijhawan [<xref ref-type="bibr" rid="pcbi.1005068.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref022">22</xref>] and others [<xref ref-type="bibr" rid="pcbi.1005068.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref027">27</xref>] (for a review see [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref029">29</xref>]). Different variants of the original experiment were designed in order to challenge the different motion extrapolation models. These studies revealed a flaw in Nijhawan’s motion extrapolation theory since it cannot account for the experimental observations made with two specific variants of the FLE, often called half-cycle FLEs [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>]. Their common principle is to manipulate the position of the flash relative to the trajectory of the moving object. While in the standard FLE, the flash appears in the middle of the motion path, the flash can now appear either at the beginning or at the end of the motion trajectory, thus defining the flash-initiated and flash-terminated cycle FLEs, respectively. The motion extrapolation hypothesis predicts that, at the beginning of the trajectory, the flashed and moving objects are not likely to be differentiated. However, this prediction was contradicted by the psychophysical results showing a comparable position shift in both the flash-initiated cycle and the standard FLE. Furthermore, extrapolating a trajectory should impose an inertial component even in the presence of sudden changes in the visual motion properties, such as motion termination or reversal. By consequence, the motion extrapolation hypothesis predicts a perceptual overshoot that is similar in both flash-terminated and standard FLE. Again, this prediction was contradicted by psychophysical evidence demonstrating a lack of position shift in the flash-terminated cycle FLE [<xref ref-type="bibr" rid="pcbi.1005068.ref027">27</xref>]. Lastly, several studies suggested that the motion extrapolation hypothesis needs to be supplemented with complementary mechanisms such as the a posteriori correction of the predicted position, in order to account for the perceived position after an abrupt change in the motion trajectory [<xref ref-type="bibr" rid="pcbi.1005068.ref030">30</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref032">32</xref>].</p>
<p>These new empirical evidences called for alternative hypotheses able to unify all of these different aspects of FLE. A first set of studies proposed that moving and static objects are processed with different latencies in the early visual system. Hence, the perceived lag in FLE could be explained by the faster processing of moving objects, as compared to flashed inputs [<xref ref-type="bibr" rid="pcbi.1005068.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref015">15</xref>]. There may exist multiple origins at retinal and cortical levels for a more rapid processing of moving objects. Some authors reasoned that, since both flashed and moving stimuli are processed and transmitted within a single (magno-cellular) retino-thalamo-cortical pathway, any difference would be explained by intra-cortical mechanisms that would process differently predictable and unpredictable events [<xref ref-type="bibr" rid="pcbi.1005068.ref015">15</xref>]. However, there is still a lack of solid neurophysiological empirical evidences in support of this differential latency hypothesis. A second hypothesis suggested that the FLE may be explained by the position persistence for the flashed visual input [<xref ref-type="bibr" rid="pcbi.1005068.ref034">34</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref035">35</xref>]. The central idea is that motion information is averaged within a 500 ms window. By consequence, the perceived position of the flash would persist, while the averaged position for the moving object is perceived ahead of its actual position, along its motion path. The main flaw of this hypothesis is that the supposed time constant (500 ms) is unrealistically long with respect to the known dynamics of motion integration.</p>
<p>More recently, Wojtach et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>] proposed that the FLE may be seen as a mere consequence of the distribution of speeds that are empirically observed during our visual experience. Using the perspective transform from the three-dimensional physical space to the two-dimensional plane of the retinotopic space, they assigned empirical probabilities of the observed retinal speeds from the mapping of objects’ velocities in the physical world. By doing so, they defined an <italic>a priori</italic> probability distribution of speeds which can be combined with sensory evidence. This solution proposes a probabilistic framework inferring an optical estimate of motion speed. Such estimate is then used in a motion extrapolation model compensating for the neural delay. The authors estimated the amplitude of the lag in respect to an extended speed range of object motion. Their model depicts a nonlinear relationship between motion speed and the perceptual lag, similar to the one observed with the standard flash-lag experiment. Thus, the model from Wojtach et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>] provides an ingenious extension of the motion extrapolation model using inferred speed. However, this model was not tested against the aforementioned complete, and challenging set of empirical studies probing the FLE at different epochs of the motion trajectory.</p>
<p>One last approach is the <italic>postdiction</italic> hypothesis [<xref ref-type="bibr" rid="pcbi.1005068.ref027">27</xref>] postulating that visual awareness attributes the position of a moving stimuli at the instant of the flash appearance according to the information collected within an ≈80ms time window following the flash. In particular, the flash is considered as a reset for motion integration and, as such, this would be sufficient in explaining why the FLE is not perceived in the flash-terminated cycle. The postdiction hypothesis relies on two main assumptions. First, both moving and flashed inputs have the same neural delays. Second, the flash acts as a resetting mechanism. By consequence, the model predicts that observers shall perceive both a spatial lag of the flash and a change in the speed of the moving object. However, such a speed increment has never been reported in the context of FLE [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>]. The postdiction model is thus an elegant hypothesis that allows us to understand a wide range of variants of the FLE but fails to explain this later aspect of FLE. In summary, the half-cycles variants of the FLE introduced by Eagleman and Sejnowski [<xref ref-type="bibr" rid="pcbi.1005068.ref027">27</xref>] remain challenging for all current theoretical approaches of the FLE, despite the fact that they might reveal how the visual system processes motion onset and offset and their impact on position coding.</p>
</sec>
<sec id="sec004">
<title>The parodiction hypothesis</title>
<p>Overall, previous theoretical studies can be grouped according to two main hypotheses. On one hand, models based on latency difference or motion extrapolation rely on how the neural representation of position information is encoded. On the other hand, the postdiction hypothesis is based on how visual awareness decodes objects’ positions from neural activity in a short temporal window. In the present theoretical study, we will propose a new hypothesis which subsumes both of these aspects. Our theoretical approach is based upon two major constraints faced by any neural system, in comparison to a conventional computer, when estimating the position of an object: First, there is no access to a central clock, that is, the present, exteroceptive, physical timing is hidden (or latent in machine learning terms) to the nervous system. Second, the internal representation encoded in the neural activity is distributed and dynamical. In particular, the system is confronted to non-stationary sources of noises and has to provide for an optimal estimate at any time for upstream neural networks.</p>
<p>Driven by these constraints, a biologically-realistic hypothesis is that a perceived position corresponds to the most likely position at the present time [<xref ref-type="bibr" rid="pcbi.1005068.ref037">37</xref>]. According to the probabilistic brain hypothesis (see [<xref ref-type="bibr" rid="pcbi.1005068.ref008">8</xref>] for a generic application to eye movements), an optimal solution is that the internal representation encodes beliefs in the form of probability distribution functions (pdf) and that the optimal estimate is computed knowing both the instantaneous sensory data and the internal representation. When the represented variable, such as the position, is predictable, this process involves that the internal representation uses a generative model of its dynamics to progressively refine the estimation. As a result, using a probabilistic formulation of predictive coding, it is possible to explicitly represent the instantaneous information about object’s motion and its precision, coherently with the role played by perceptual precision in the FLE [<xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>]. Consequently, we propose that a generic goal of these neural computations is to optimally align the position represented in the neural activity with that at the veridical, but hidden, physical time. We will call this approach the <italic>parodiction</italic> hypothesis, from the ancient Greek <italic>παρóν</italic>, the present time.</p>
<p>Herein, we will show that probabilistic motion extrapolation can efficiently compensate for the neural delays and explain the shift in perceived positions in the different variants of the FLE. The paper is organized as follows. First, we will define the probabilistic motion extrapolation model and we will describe how delays can be taken into account. This model extends a simple motion-based predictive model based on the temporal coherency of visual trajectories that we proposed earlier [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>] and is also a novel formulation of the original motion extrapolation model proposed by Nijhawan [<xref ref-type="bibr" rid="pcbi.1005068.ref004">4</xref>]. Second, we present the results of this model with the standard FLE and in particular we titrate the role of the velocity of the moving object. Then, we will show that the model can account for both standard and half-cycle FLEs. In particular, we will show that within this optimal integration scheme, the relative precision of sensory and internal information may modulate the gain of their interaction. This is first illustrated by challenging the model with a motion reversal experiment. To further investigate this behavior, we manipulated the contrast of the stimuli. This allowed us to dynamically switch the system from a purely feed-forward model, exhibiting differential latencies, to a model showing a pure motion extrapolation behavior. We will finally discuss the advantages and limitations of our <italic>parodiction</italic> hypothesis, in comparison with the previously proposed models.</p>
</sec>
</sec>
<sec id="sec005" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec006">
<title>Motion-based prediction and the diagonal models</title>
<p>This computational study explores the potential role of predictive coding in explaining the dynamics of position coding. Similar to most predictive models, a natural choice for the representation of information is to use probabilities. Thus, the motion of an object is best described by the probability distribution function (pdf) of its instantaneous position (<italic>x</italic>, <italic>y</italic>) and velocity (<italic>u</italic>, <italic>v</italic>) [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>]. Note that these coordinates are defined in the planar visual space, under the assumption that we model small displacements in the vicinity of the visual axis. The pdf <italic>p</italic>(<italic>x</italic>, <italic>y</italic>, <italic>u</italic>, <italic>v</italic>) represents at a given time the degree of belief among a set of possible positions and velocities. In this framework, a Bayesian predictive model will optimally integrate the sensory information available from the sensory inputs (likelihood) with an internal model (i. e. an <italic>a priori</italic> distribution) of state transition in order to compute an <italic>a posteriori</italic> pdf of motion. Typically, the likelihood is computed using a model of sensory noise, an approach that fits well to the motion energy model of the direction-selective cells in the cortex [<xref ref-type="bibr" rid="pcbi.1005068.ref039">39</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref041">41</xref>]. By sequentially combining at any given time <italic>t</italic> the <italic>a posteriori</italic> estimate with the likelihood using the prior on state transition, we implement a Markov chain forming a dynamical predictive system.</p>
<p>One novelty of motion-based prediction is to encapsulate the coherency of motion trajectory in the internal model, that is, in the prior of state transition. In particular, this prior knowledge instantiates a preference for smooth transitions of successive motion states, as expected from the statistics of natural visual motion trajectories [<xref ref-type="bibr" rid="pcbi.1005068.ref040">40</xref>]. Such an internal model was first proposed in a neural network implementing the detection of a single moving dot embedded in very high level of noise [<xref ref-type="bibr" rid="pcbi.1005068.ref042">42</xref>]. More recently, we have shown that this motion-based prediction model can explain the dynamics of the neural solution to both the aperture problem [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>] and motion extrapolation [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. In the present study, we will show that it can also be used to compensate for known neural delays [<xref ref-type="bibr" rid="pcbi.1005068.ref008">8</xref>]. It is important to recall that our model is reminiscent of the diagonal model originally proposed by [<xref ref-type="bibr" rid="pcbi.1005068.ref021">21</xref>] (called thereafter Nijhawan’s diagonal model), but with one important distinction: motion information is now represented by probabilities.</p>
</sec>
<sec id="sec007">
<title>A probabilistic implementation of the Nijhawan’s diagonal model</title>
<p>In order to define a predictive system, one can use a classical Markov chain formed by sequentially combining, at any given time, the likelihood with a prior on state transition. When describing visual motion (i.e., position and velocity) at time <italic>t</italic> by the instantaneous state vector <italic>z</italic><sub><italic>t</italic></sub> = (<italic>x</italic><sub><italic>t</italic></sub>, <italic>y</italic><sub><italic>t</italic></sub>, <italic>u</italic><sub><italic>t</italic></sub>, <italic>v</italic><sub><italic>t</italic></sub>), the master equations of this Markov chain become:
<disp-formula id="pcbi.1005068.e001"><alternatives><graphic id="pcbi.1005068.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mrow><mml:mtext mathvariant="italic">estimation</mml:mtext> <mml:mo>:</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula> <disp-formula id="pcbi.1005068.e002"><alternatives><graphic id="pcbi.1005068.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mrow><mml:mtext mathvariant="italic">prediction</mml:mtext> <mml:mo>:</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
where <italic>p</italic>(<italic>I</italic><sub><italic>t</italic> − <italic>δt</italic>:<italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic></sub>) is the likelihood computed over the infinitesimally small temporal window [<italic>t</italic> − <italic>δt</italic>, <italic>t</italic>), that is, the time window of width <italic>δt</italic> before present time <italic>t</italic>. By definition, the pdf <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic></sub>) corresponds to the belief in the motion <italic>z</italic><sub><italic>t</italic></sub> at time <italic>t</italic>, knowing the sensory information <italic>I</italic> being integrated over the temporal window starting at the beginning of the observations (<italic>t</italic> = 0) and extending to the current time <italic>t</italic>. Notice that the probabilistic notations will allow us to conveniently describe the current belief on the state vector before observing a new sensory information as the pdf <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>δt</italic></sub>). Importantly, this dynamical system is biologically realistic as it describes the belief in a macroscopic time window [0, <italic>t</italic>), based only on the integration of the information available at the present time [<italic>t</italic> − <italic>δt</italic>, <italic>t</italic>).</p>
<p>Intuitively, this model combines the two basic operations of probability theory. First, in the estimation stage, the multiplication corresponds to the combination of two independent pieces of information: one element is derived from the measurements (i.e. the likelihood <italic>p</italic>(<italic>I</italic><sub><italic>t</italic> − <italic>δt</italic>:<italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic></sub>)) and the other is the current knowledge about the state before the measurements. Information is assumed to be conditionally independent because the source of noise in the likelihood (measurement noise) is assumed to be independently generated from the internally generated state estimation noise. This first stage corresponds to a <sc>AND</sc> operator in boolean logic. Second, in the prediction state, the possible state <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>δt</italic></sub>) is inferred by an addition over all possible previous states, given by the integral sign. The integrals sum over the whole distribution of estimated positions at <italic>t</italic> − <italic>δt</italic> the possible state transitions that would yield <italic>z</italic><sub><italic>t</italic></sub>. By consequence, very unlikely states (at time <italic>t</italic> − <italic>δt</italic>) and state transitions (for instance, incoherent non-smooth motions) will have little weight in this summation. This computational step corresponds to a <sc>OR</sc> operator in boolean logic. These two steps implement the classical “predict-update cycle” of the Markov model and are sufficient to define our dynamical predictive coding model.</p>
<p>However, in this mathematical framework, one needs to gain an immediate access to sensory information, that is, to know the image <italic>I</italic> at time <italic>t</italic>, in order to compute <italic>p</italic>(<italic>I</italic><sub><italic>t</italic>−<italic>δt</italic>: <italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic></sub>). This is impossible in the presence of neural delays. Considering a known (fixed) neural delay <italic>τ</italic>, at time <italic>t</italic> the system only had access to <italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub> and thus one needs to estimate <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0: <italic>t</italic>−<italic>τ</italic></sub>). An essential property of motion-based predictive coding is the ability to extrapolate motion when sensory information is transiently absent [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. As illustrated in <xref ref-type="fig" rid="pcbi.1005068.g002">Fig 2-A</xref>, the probability distribution function <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>) may be predicted by “pushing forward” the information <italic>p</italic>(<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>) such as to compensate for the delay, while being still recursively computed in a way similar to a classical Markov chain model (see the bottom part of <xref ref-type="fig" rid="pcbi.1005068.g002">Fig 2-A</xref>). Thus, a classical Markov chain in the presence of a known delay can be redrawn in a “diagonal” mode. It is similar to the original suggestion made by Nijhawan and Wu [<xref ref-type="bibr" rid="pcbi.1005068.ref021">21</xref>] in order to explain the detailed mechanism of motion extrapolation in retinal ganglion cells. Here, we generalize this diagonal mode as a probabilistic model of predictive motion estimation.</p>
<fig id="pcbi.1005068.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Diagonal Markov chain.</title>
<p>In the current study, the estimated state vector <italic>z</italic> = {<italic>x</italic>, <italic>y</italic>, <italic>u</italic>, <italic>v</italic>} is composed of the 2D position (<italic>x</italic> and <italic>y</italic>) and velocity (<italic>u</italic> and <italic>v</italic>) of a (moving) stimulus. <monospace>(A)</monospace> First, we extend a classical Markov chain using Nijhawan’s diagonal model in order to take into account the known neural delay <italic>τ</italic>: At time <italic>t</italic>, information is integrated until time <italic>t</italic> − <italic>τ</italic>, using a Markov chain and a model of state transitions <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>δt</italic></sub>) such that one can infer the state until the last accessible information <italic>p</italic>(<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>). This information can then be “pushed” forward in time by predicting its trajectory from <italic>t</italic> − <italic>τ</italic> to <italic>t</italic>. In particular <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>) can be predicted by the same internal model by using the state transition at the time scale of the delay, that is, <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>). This is virtually equivalent to a motion extrapolation model but without sensory measurements during the time window between <italic>t</italic> − <italic>τ</italic> and <italic>t</italic>. Note that both predictions in this model are based on the same model of state transitions. <monospace>(B)</monospace> One can write a second, equivalent “pull” mode for the diagonal model. Now, the current state is directly estimated based on a Markov chain on the sequence of delayed estimations. While being equivalent to the push-mode described above, such a direct computation allows to more easily combine information from areas with different delays. Such a model implements Nijhawan’s “diagonal model”, but now motion information is probabilistic and therefore, inferred motion may be modulated by the respective precisions of the sensory and internal representations. <monospace>(C)</monospace> Such a diagonal delay compensation can be demonstrated in a two-layered neural network including a source (input) and a target (predictive) layer [<xref ref-type="bibr" rid="pcbi.1005068.ref044">44</xref>]. The source layer receives the delayed sensory information and encodes both position and velocity topographically within the different retinotopic maps of each layer. For the sake of simplicity, we illustrate only one 2D map of the motions (<italic>x</italic>, <italic>v</italic>). The integration of coherent information can either be done in the source layer (push mode) or in the target layer (pull mode). Crucially, to implement a delay compensation in this motion-based prediction model, one may simply connect each source neuron to a predictive neuron corresponding to the corrected position of stimulus (<italic>x</italic> + <italic>v</italic> ⋅ <italic>τ</italic>, <italic>v</italic>) in the target layer. The precision of this anisotropic connectivity map can be tuned by the width of convergence from the source to the target populations. Using such a simple mapping, we have previously shown that the neuronal population activity can infer the current position along the trajectory despite the existence of neural delays [<xref ref-type="bibr" rid="pcbi.1005068.ref044">44</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.g002" xlink:type="simple"/>
</fig>
<p>As a consequence, the master equations of this diagonal model can be written as:
<disp-formula id="pcbi.1005068.e003"><alternatives><graphic id="pcbi.1005068.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mrow><mml:mtext mathvariant="italic">estimation</mml:mtext> <mml:mo>:</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula> <disp-formula id="pcbi.1005068.e004"><alternatives><graphic id="pcbi.1005068.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mrow><mml:mtext mathvariant="italic">prediction</mml:mtext> <mml:mo>:</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula> <disp-formula id="pcbi.1005068.e005"><alternatives><graphic id="pcbi.1005068.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mrow><mml:mtext mathvariant="italic">extrapolation</mml:mtext> <mml:mo>:</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
As evidenced by these equations, Eqs <xref ref-type="disp-formula" rid="pcbi.1005068.e003">3</xref> and <xref ref-type="disp-formula" rid="pcbi.1005068.e004">4</xref> are similar to Eqs <xref ref-type="disp-formula" rid="pcbi.1005068.e001">1</xref> and <xref ref-type="disp-formula" rid="pcbi.1005068.e002">2</xref>, except that these are now delayed by <italic>τ</italic>, the known sensory delay. This information <italic>p</italic>(<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>) is then “pushed” forward in time using the extrapolation step (see <xref ref-type="disp-formula" rid="pcbi.1005068.e005">Eq 5</xref>), in a similar fashion to the predictive step on the infinitesimal period (Eqs <xref ref-type="disp-formula" rid="pcbi.1005068.e002">2</xref> and <xref ref-type="disp-formula" rid="pcbi.1005068.e004">4</xref>) but now on the possibly longer period of the sensory delay (in general <italic>τ</italic> ≫ <italic>δt</italic>). As a result, we obtain the estimate of motion at the current time, knowing the information acquired until <italic>t</italic> − <italic>τ</italic>, that is, <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>). Finally, the next states correspond to the integration of the estimations at the actual current stimulus position and motion, overcoming the restrictive effect of delay [<xref ref-type="bibr" rid="pcbi.1005068.ref008">8</xref>]. Note that the earliest part of the trajectory is necessarily missed since motion estimation begins integrating sensory information only after the delay <italic>τ</italic>, as there is no sensory input before. Decisively, this model is now compatible with our initial hypothesis that sensory information is only available after a delay.</p>
<p>Although this first model (i.e. the “pushing” mode) is the easiest to understand with respect to a Markov chain, it is less practical to consider within a biological setting since it defines that, at time <italic>t</italic>, the state is inferred from a representation of a past state <italic>p</italic>(<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>). For neural networks implementations, the internal representation (as encoded by the neural activity) is only accessible at the present time. As a consequence, it may be more convenient to derive a set of predictive steps that would directly act on the estimation of the state at the current time <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0: <italic>t</italic>−<italic>τ</italic></sub>). This question is particularly acute for complex architectures mimicking the deep hierarchies of low-level visual cortical areas where information should not be conditioned by the delays arising at each processing layer but rather be based on a common temporal reference such as the current time <italic>t</italic>. In that objective, one notes that, by merging the estimation and prediction steps in the master equation, we obtain:
<disp-formula id="pcbi.1005068.e006"><alternatives><graphic id="pcbi.1005068.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mo>∝</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mo>∝</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula> <disp-formula id="pcbi.1005068.e007"><alternatives><graphic id="pcbi.1005068.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
Regrouping terms, it becomes:
<disp-formula id="pcbi.1005068.e008"><alternatives><graphic id="pcbi.1005068.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula></p>
<p>The term within brackets can be written as an argument of an extrapolation from <italic>t</italic> − <italic>τ</italic> to <italic>t</italic>, yielding to:
<disp-formula id="pcbi.1005068.e009"><alternatives><graphic id="pcbi.1005068.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
As frequently assumed, the transition matrix is stationary: our prior assumption on the internal model (here, the parameters with which we model the coherence of trajectories) do not change over time. Finally, regrouping terms, we obtain:
<disp-formula id="pcbi.1005068.e010"><alternatives><graphic id="pcbi.1005068.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
Therefore, the master equation to the “push” mode are equivalent to:
<disp-formula id="pcbi.1005068.e011"><alternatives><graphic id="pcbi.1005068.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mrow><mml:mtext mathvariant="italic">estimation</mml:mtext> <mml:mo>:</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(11)</label></disp-formula> <disp-formula id="pcbi.1005068.e012"><alternatives><graphic id="pcbi.1005068.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mrow><mml:mtext mathvariant="italic">prediction</mml:mtext> <mml:mo>:</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula> <disp-formula id="pcbi.1005068.e013"><alternatives><graphic id="pcbi.1005068.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e013" xlink:type="simple"/><mml:math display="block" id="M13"><mml:mrow><mml:mtext mathvariant="italic">extrapolation</mml:mtext> <mml:mo>:</mml:mo> <mml:mspace width="3.33333pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(13)</label></disp-formula>
We will call this second mode the “pulling” mode and is illustrated in <xref ref-type="fig" rid="pcbi.1005068.g002">Fig 2-B</xref>.</p>
<p>The two modes that have been presented above share the same processing logic but have different implications about the manner with which both the internal model and the likelihood function might be implemented. In the pushing mode, the motion state <italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub> is estimated from both a delayed sensory input <italic>I</italic><sub><italic>t</italic>−<italic>τ</italic>−<italic>δt</italic>:<italic>t</italic>−<italic>τ</italic></sub> and the motion coherency. <xref ref-type="disp-formula" rid="pcbi.1005068.e003">Eq 3</xref> calculates the probability of a desired motion state, using the likelihood of that state (measured from the sensory information with a delay <italic>τ</italic>) and the predicted belief given by <xref ref-type="disp-formula" rid="pcbi.1005068.e004">Eq 4</xref>. At the next step, the estimated motion is extrapolated for a period of duration <italic>τ</italic>, similar to a “virtual blank” during which there is no sensory measurements [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. Thus, the extrapolation step shown by <xref ref-type="disp-formula" rid="pcbi.1005068.e005">Eq 5</xref> is purely predictive, under the constraint of motion coherency (see <xref ref-type="disp-formula" rid="pcbi.1005068.e012">Eq 12</xref>) and with the available information about the delay <italic>τ</italic>. In the pulling mode, the probabilistic representation is different as the current state is directly estimated from the delayed measurements and the extrapolative step is “hidden” in the probability <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic>−<italic>δt</italic></sub>). Under the stationarity assumption, both modes are mathematically equivalent and produce the same probabilistic representation of instantaneous states based on delayed measurements.</p>
<p>In summary, the information about the motion estimates (position, velocity) at time <italic>t</italic> knowing the sensory information observed between 0 and <italic>t</italic> − <italic>τ</italic> is contained in the pdf <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>). As we have seen above, it can be computed using the diagonal model in push mode and summarized in the following master equations:
<disp-formula id="pcbi.1005068.e014"><alternatives><graphic id="pcbi.1005068.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e014" xlink:type="simple"/><mml:math display="block" id="M14"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(14)</label></disp-formula> <disp-formula id="pcbi.1005068.e015"><alternatives><graphic id="pcbi.1005068.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(15)</label></disp-formula>
Eqs <xref ref-type="disp-formula" rid="pcbi.1005068.e014">14</xref> and <xref ref-type="disp-formula" rid="pcbi.1005068.e015">15</xref> are the master equations of Nijhawan’s diagonal model when framing it in a probabilistic setting. Importantly, the inferred motion may be modulated by the respective precisions of the sensory (<italic>p</italic>(<italic>I</italic><sub><italic>t</italic>−<italic>τ</italic>−<italic>δt</italic>:<italic>t</italic>−<italic>τ</italic></sub>|<italic>z</italic><sub><italic>t</italic></sub>)) and internal (<italic>p</italic>(<italic>z</italic><sub><italic>t</italic>−<italic>δt</italic></sub>|<italic>I</italic><sub>0: <italic>t</italic>−<italic>τ</italic>−<italic>δt</italic></sub>)) representations. The model gives a probabilistic distribution of the estimated motion state <italic>z</italic><sub><italic>t</italic></sub>, based on delayed motion measurements <italic>I</italic><sub><italic>t</italic>−<italic>τ</italic></sub>. In the next section, we will describe how the transition probability distribution functions <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>) and <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>δt</italic></sub>) are computed.</p>
</sec>
<sec id="sec008">
<title>Diagonal motion-based prediction (dMBP)</title>
<p>We have seen above that one needs to characterize the temporal coherency of motion for different temporal steps, as represented by <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic>−Δ<italic>t</italic></sub>) with Δ<italic>t</italic> = <italic>δt</italic> or Δ<italic>t</italic> = <italic>τ</italic>. Assuming that motion is <italic>transported</italic> in time during this time period of Δ<italic>t</italic> (with a drift similar to a Brownian motion and characterized by some given diffusion parameters), we obtain [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>]:
<disp-formula id="pcbi.1005068.e016"><alternatives><graphic id="pcbi.1005068.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e016" xlink:type="simple"/><mml:math display="block" id="M16"><mml:mfenced close="" open="{" separators=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4pt"/><mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>u</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>·</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ν</mml:mi> <mml:mi>x</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4pt"/><mml:msub><mml:mi>y</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>·</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ν</mml:mi> <mml:mi>y</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math></alternatives> <label>(16)</label></disp-formula> <disp-formula id="pcbi.1005068.e017"><alternatives><graphic id="pcbi.1005068.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mfenced close="" open="{" separators=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4pt"/><mml:msub><mml:mi>u</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo>γ</mml:mo> <mml:mo>·</mml:mo> <mml:msub><mml:mi>u</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ν</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4pt"/><mml:msub><mml:mi>v</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo>γ</mml:mo> <mml:mo>·</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ν</mml:mi> <mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:math></alternatives> <label>(17)</label></disp-formula>
Here, <inline-formula id="pcbi.1005068.e018"><alternatives><graphic id="pcbi.1005068.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:mo>γ</mml:mo> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mfrac><mml:msub><mml:mi>D</mml:mi> <mml:mi>V</mml:mi></mml:msub> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>p</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> is the damping factor introduced by the prior on slowness of motion [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. As defined by Weiss and Fleet [<xref ref-type="bibr" rid="pcbi.1005068.ref040">40</xref>], this prior information about slowness and smoothness of visual motion can be parameterized by its variance <inline-formula id="pcbi.1005068.e019"><alternatives><graphic id="pcbi.1005068.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>p</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> and <italic>γ</italic> ≈ 1 for a high value of <italic>σ</italic><sub><italic>p</italic></sub>.</p>
<p>The diffusion parameters characterize the precision of the temporal motion coherency and are parameterized by the variance of the Gaussian distributions that define the additive noise <italic>ν</italic><sub><italic>x</italic></sub>, <italic>ν</italic><sub><italic>y</italic></sub> in the transport equations. First, the variance <italic>D</italic><sub><italic>X</italic></sub> ⋅ |Δ<italic>t</italic>| setting the blur in position define the noise distribution as:
<disp-formula id="pcbi.1005068.e020"><alternatives><graphic id="pcbi.1005068.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mrow><mml:msub><mml:mi>ν</mml:mi> <mml:mi>x</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ν</mml:mi> <mml:mi>y</mml:mi></mml:msub> <mml:mrow><mml:mo>∝</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>;</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow> <mml:msub><mml:mi>D</mml:mi> <mml:mi>X</mml:mi></mml:msub> <mml:mo>·</mml:mo> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(18)</label></disp-formula>
where <inline-formula id="pcbi.1005068.e021"><alternatives><graphic id="pcbi.1005068.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>y</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>;</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the two dimensional normal distribution on real numbers <italic>x</italic> and <italic>y</italic> of mean <inline-formula id="pcbi.1005068.e022"><alternatives><graphic id="pcbi.1005068.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:mi>μ</mml:mi> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> and variance <italic>σ</italic><sup>2</sup> (assuming isotropy of the noise, the covariance matrix is unitary). Concerning velocity, this models assumes similarly that <italic>ν</italic><sub><italic>u</italic></sub> and <italic>ν</italic><sub><italic>v</italic></sub> are modeled by Gaussian distributions:
<disp-formula id="pcbi.1005068.e023"><alternatives><graphic id="pcbi.1005068.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mrow><mml:msub><mml:mi>ν</mml:mi> <mml:mi>u</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>ν</mml:mi> <mml:mi>v</mml:mi></mml:msub> <mml:mrow><mml:mo>∝</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>v</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>;</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>p</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>D</mml:mi> <mml:mrow><mml:mi>V</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>·</mml:mo> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(19)</label></disp-formula>
where the diffusion parameter <italic>D</italic><sub><italic>V</italic></sub> parameterizes the dynamics of the motion vector. Finally, the variance equals to <inline-formula id="pcbi.1005068.e024"><alternatives><graphic id="pcbi.1005068.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>p</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>D</mml:mi> <mml:mrow><mml:mi>V</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>·</mml:mo> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Note that for a very weak prior for slow speeds, <inline-formula id="pcbi.1005068.e025"><alternatives><graphic id="pcbi.1005068.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>p</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>≈</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005068.e026"><alternatives><graphic id="pcbi.1005068.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>p</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>D</mml:mi> <mml:mrow><mml:mi>V</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>≈</mml:mo> <mml:msub><mml:mi>D</mml:mi> <mml:mi>V</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> such that it is then similar to the Brownian diffusion equation on position. This updating rule (see [<xref ref-type="bibr" rid="pcbi.1005068.ref041">41</xref>] for a derivation) assumes independence of the prior on slow speeds with respect to predictive prior on smooth trajectories (see [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>] for more details).</p>
<p>From these generative equations, one may then compute both <italic>p</italic>(<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic>−<italic>δt</italic></sub>) and <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>) using Eqs <xref ref-type="disp-formula" rid="pcbi.1005068.e016">16</xref> and <xref ref-type="disp-formula" rid="pcbi.1005068.e017">17</xref> and the assumption in Eqs <xref ref-type="disp-formula" rid="pcbi.1005068.e020">18</xref> and <xref ref-type="disp-formula" rid="pcbi.1005068.e023">19</xref>. Note also that in all generality, we have used a formulation where extrapolation can be performed forwards in time (Δ<italic>t</italic> &gt; 0), but also backwards (Δ<italic>t</italic> &lt; 0), as it may be useful in some cases to guess a position in a past state, when only knowing the state at the present time. By including the compensation for the neural delay in the motion-based prediction (MBP) model, this defines a novel, more general diagonal model that we call diagonal motion-based prediction (dMBP).</p>
</sec>
<sec id="sec009">
<title>A neural interpretation of the dMBP model</title>
<p>From a biological perspective, it seems very unlikely that sensory neurons can store complex time series about past variables. A strong constraint in understanding the biologically-plausible mechanisms for delay compensation is to build models which would only use the neural activity available at the present time. As such, one solution may arise from generalized representation of variables where a given variable (e.g. position) is represented at any given time <italic>t</italic> by its value and its instantaneous time derivatives (e.g. velocity, acceleration and so on). In a previous computational study on the compensation of delays in neural networks [<xref ref-type="bibr" rid="pcbi.1005068.ref008">8</xref>], we introduced the idea that sensory delays can be (internally) simulated and corrected by applying delays to sensory inputs producing sensory prediction errors. In a biologically-realistic network, the application of delay operators can be implemented by changing synaptic connection strengths in order to capture different mixtures of generalized sensations and their prediction errors. The precision of this compensation (and therefore on the range of delays it can compensate) is highly dependent upon the number of orders in the generalized representation and on their respective precision, as measured by the inverse of their variance (for a detailed mathematical account, see [<xref ref-type="bibr" rid="pcbi.1005068.ref043">43</xref>]). In other words, in a neural network encoding both position and velocity, a compensation for delays in the sort we described above may be easily achieved solely by appropriately setting the matrix of connectivity weights.</p>
<p>The present motion-based predictive coding can be implemented in a simple two-layered neural network as illustrated in <xref ref-type="fig" rid="pcbi.1005068.g002">Fig 2-C</xref>. The source layer implements a neural representation of sensory inputs and activates specific populations of the target layer. More specifically, the neural activity within the input layer represents the likelihood of the sensory input at time <italic>t</italic> knowing the delay <italic>τ</italic>, that is, <italic>p</italic>(<italic>I</italic><sub><italic>t</italic>−<italic>τ</italic>−<italic>δt</italic>:<italic>t</italic>−<italic>τ</italic></sub>|<italic>z</italic><sub><italic>t</italic></sub>). In particular, the mapping between the source and target layers is fixed but anisotropic (as it is implementing <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>)), the bias depending upon the estimated velocity and neural delay <italic>τ</italic>. For instance, in the case of the example neuron displayed in <xref ref-type="fig" rid="pcbi.1005068.g002">Fig 2-C</xref>, its efferents in the target layer may be interpreted as a neural population which is stimulated by the sensory information received by some “rightward” neurons centered on its left. Finally, a third stream of information allows to update the dynamics of the internal model (that is, of <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0: <italic>t</italic>−<italic>τ</italic></sub>)) using lateral connectivity. From the mathematical equivalence between the push mode and the pull mode that was presented above, this could be implemented indifferently in the source layer by implementing <italic>p</italic>(<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic>−<italic>δt</italic></sub>) or in the target layer by implementing <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>z</italic><sub><italic>t</italic>−<italic>δt</italic></sub>). It shall be noticed that the architecture of this model is not fundamentally different from our previous model of motion extrapolation during a transient blanking of the sensory flow [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. Now the sensory delay consists in a “virtual blank” during which sensory information is not sensed. Since the architecture of our previous model has been already implemented in a spiking neural network (SNN) using anisotropic connectivity patterns [<xref ref-type="bibr" rid="pcbi.1005068.ref044">44</xref>], one could easily provide a similar neural network implementation of this dMBP model.</p>
<p>Once the dMBP model is defined, it is important to briefly highlight its analogies with other implementations. For instance, instead of considering a parametric model for the prior distributions, we may use an empirical prior, such as the one defined for speed by Wojtach et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>]. It is however important to note that a departure of our model with that of Wojtach et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>] is the fact that, instead of using the inferred speed from the likelihood and the speed prior, we use the probability distribution function for the representation of motion. In particular, the precision of the information in the source and target layers will be essential to weight the dynamical integration of information during the flow of sensory information. This proved to be essential in a dynamical display such as the FLE. More generally speaking, when the sensory input is best described by a Gaussian distribution, our model is equivalent to a Kalman filter, in the form of an optimal smoother, as previously introduced by Rao et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref045">45</xref>] (see also [<xref ref-type="bibr" rid="pcbi.1005068.ref008">8</xref>] for a more rigorous and extended mathematical formulation). However, this latter model used a sequential representation of the activity both in external (physical) and internal temporal spaces. There is no neurophysiological evidence that such a representation could be implemented. Rather, we reasoned that all information should be available at the present time.</p>
</sec>
</sec>
<sec id="sec010" sec-type="results">
<title>Results</title>
<p>We tested our model with the different instances of the FLE conditions and manipulated the parameters of the static (flashed) and moving stimuli in order to explore the advantages of motion-based position coding with respect to previous models. The dMBP model was implemented with a particle filter method which has been previously detailed in [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>]. An extensive parameter scan for simulations was performed on a cluster of Linux nodes (Debian Wheezy) using python (version 3.5.0) and numpy (version 1.10.1). The code written to produce all figures and supplementary materials is available on the corresponding author’s website at <ext-link ext-link-type="uri" xlink:href="http://invibe.net/LaurentPerrinet/Publications/KhoeiMassonPerrinet17" xlink:type="simple">http://invibe.net/LaurentPerrinet/Publications/KhoeiMassonPerrinet17</ext-link>. On a standard laptop computer (early 2015 MacBook pro Retina with 3,1 GHz Intel Core i7 and 16 GB DDR3 memory), a video of resolution 256 × 256 at 100 frames per second is approximately processed at half real time such that reproducing all the figures presented herein takes approximately one hour of processing.</p>
<p>The model and its simulations are controlled by a limited set of parameters. The MBP model originally described in [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>] was controlled only by the 2 diffusion parameters (<italic>D</italic><sub><italic>X</italic></sub> and <italic>D</italic><sub><italic>V</italic></sub>), the width of the slow speed prior and, lastly the parameters of the motion energy model used to estimate the likelihoods (that is, the estimate of background noise’s variance and a gain element). In particular, the likelihood is computed using a motion energy based on a generative model of the motion of objects in natural scenes [<xref ref-type="bibr" rid="pcbi.1005068.ref046">46</xref>]. We used the same values as in [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>], which have been shown as yielding to the emergence of a stable tracking behavior when presented with a smooth rectilinear trajectory (see <xref ref-type="table" rid="pcbi.1005068.t001">Table 1</xref>). The present extension of this MBP model to the current dMBP model adds a single new parameter, the sensory latency <italic>τ</italic>.</p>
<table-wrap id="pcbi.1005068.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.t001</object-id>
<label>Table 1</label>
<caption>
<title>Model’s parameters.</title>
<p>The model is implemented using the same paradigm as detailed in [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>] while the extrapolation uses the same formalism as in [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. We used a similar set of parameters and controlled by a set of iPython notebooks that are available on the corresponding author’s website. Note that the speed and diffusion parameters are given relative to one spatio-temporal period.</p>
</caption>
<alternatives>
<graphic id="pcbi.1005068.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Name</th>
<th align="left">Value</th>
<th align="left">Role</th>
<th align="left">Range</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><italic>D</italic><sub><italic>X</italic></sub></td>
<td align="left">1</td>
<td align="left">diffusion parameter in position</td>
<td align="left">
<inline-formula id="pcbi.1005068.e027">
<alternatives>
<graphic id="pcbi.1005068.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e027" xlink:type="simple"/>
<mml:math display="inline" id="M27">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>D</italic><sub><italic>V</italic></sub></td>
<td align="left">1</td>
<td align="left">diffusion parameter in speed</td>
<td align="left">
<inline-formula id="pcbi.1005068.e028">
<alternatives>
<graphic id="pcbi.1005068.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e028" xlink:type="simple"/>
<mml:math display="inline" id="M28">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub><italic>p</italic></sub></td>
<td align="left">3</td>
<td align="left">characteristic value for the speed prior</td>
<td align="left">
<inline-formula id="pcbi.1005068.e029">
<alternatives>
<graphic id="pcbi.1005068.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e029" xlink:type="simple"/>
<mml:math display="inline" id="M29">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>N</italic><sub><italic>T</italic></sub>, <italic>δ</italic><sub><italic>t</italic></sub></td>
<td align="left">100, <italic>T</italic>/<italic>N</italic><sub><italic>T</italic></sub> = .01</td>
<td align="left">number of frames, time step (in seconds)</td>
<td align="left">
<inline-formula id="pcbi.1005068.e030">
<alternatives>
<graphic id="pcbi.1005068.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e030" xlink:type="simple"/>
<mml:math display="inline" id="M30">
<mml:msup>
<mml:mi mathvariant="double-struck">Z</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>τ</italic></td>
<td align="left">10/<italic>N</italic><sub><italic>T</italic></sub> = .1</td>
<td align="left">fixed delay (latency, in seconds)</td>
<td align="left">
<inline-formula id="pcbi.1005068.e031">
<alternatives>
<graphic id="pcbi.1005068.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e031" xlink:type="simple"/>
<mml:math display="inline" id="M31">
<mml:msup>
<mml:mi mathvariant="double-struck">Z</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>N</italic><sub><italic>X</italic></sub>, <italic>N</italic><sub><italic>Y</italic></sub></td>
<td align="left">256, 256</td>
<td align="left">number of pixels</td>
<td align="left">
<inline-formula id="pcbi.1005068.e032">
<alternatives>
<graphic id="pcbi.1005068.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e032" xlink:type="simple"/>
<mml:math display="inline" id="M32">
<mml:msup>
<mml:mi mathvariant="double-struck">Z</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub><italic>I</italic></sub></td>
<td align="left">.25</td>
<td align="left">standard deviation in the motion energy model</td>
<td align="left">
<inline-formula id="pcbi.1005068.e033">
<alternatives>
<graphic id="pcbi.1005068.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e033" xlink:type="simple"/>
<mml:math display="inline" id="M33">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub><italic>noise</italic></sub></td>
<td align="left">0.05</td>
<td align="left">standard deviation of the assumed noise</td>
<td align="left">
<inline-formula id="pcbi.1005068.e034">
<alternatives>
<graphic id="pcbi.1005068.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e034" xlink:type="simple"/>
<mml:math display="inline" id="M34">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Finally, the parameters of the visual stimulation were the speed and length of the moving dot trajectory, as well as the position and duration of the flash (see <xref ref-type="table" rid="pcbi.1005068.t002">Table 2</xref>). To efficiently titrate the role of these parameters, we built a computational framework to test different parameters ranges. This code is available as a collection of iPython notebooks which allow to reproduce each figure of this paper but also to track the role of each respective parameter. In particular, results with different FLE conditions (i.e. short flashes, dot visibility after motion stop…) were qualitatively similar. The respective contributions of both model and visual stimuli parameters will be described below.</p>
<table-wrap id="pcbi.1005068.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.t002</object-id>
<label>Table 2</label>
<caption>
<title>Stimuli’s parameters.</title>
<p>Stimuli are generated on a space defined in absolute values (ranging arbitrarily from −1 to 1) and time defined from <italic>t</italic> = 0 to <italic>t</italic> = <italic>T</italic> (in seconds). As such, stimulus parameters are defined in these units. To avoid border effects, the spatio-temporal domain is defined as a 3-dimensional torus (that is the cartesian product of the periodic real spaces <inline-formula id="pcbi.1005068.e035"><alternatives><graphic id="pcbi.1005068.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mi mathvariant="double-struck">Z</mml:mi> <mml:mo>⊗</mml:mo> <mml:mi mathvariant="double-struck">R</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mi mathvariant="double-struck">Z</mml:mi> <mml:mo>⊗</mml:mo> <mml:mi mathvariant="double-struck">R</mml:mi> <mml:mo>/</mml:mo> <mml:mi>T</mml:mi> <mml:mi mathvariant="double-struck">Z</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>). By convention, a speed of 1 is defined as a motion of one spatial period in one temporal period.</p>
</caption>
<alternatives>
<graphic id="pcbi.1005068.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Name</th>
<th align="left">Value</th>
<th align="left">Role</th>
<th align="left">Range</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><italic>T</italic></td>
<td align="left">1</td>
<td align="left">duration (in seconds) of the stimuli)</td>
<td align="left">
<inline-formula id="pcbi.1005068.e036">
<alternatives>
<graphic id="pcbi.1005068.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e036" xlink:type="simple"/>
<mml:math display="inline" id="M36">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>dot</italic><sub><italic>size</italic></sub></td>
<td align="left">0.05</td>
<td align="left">size of the dot</td>
<td align="left">
<inline-formula id="pcbi.1005068.e037">
<alternatives>
<graphic id="pcbi.1005068.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e037" xlink:type="simple"/>
<mml:math display="inline" id="M37">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>V</italic></td>
<td align="left">1</td>
<td align="left">speed of the dot</td>
<td align="left">
<inline-formula id="pcbi.1005068.e038">
<alternatives>
<graphic id="pcbi.1005068.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e038" xlink:type="simple"/>
<mml:math display="inline" id="M38">
<mml:mi mathvariant="double-struck">R</mml:mi>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>dot</italic><sub><italic>start</italic></sub></td>
<td align="left">.2</td>
<td align="left">start of trajectory (in seconds)</td>
<td align="left">[0, <italic>T</italic>]</td>
</tr>
<tr>
<td align="left"><italic>dot</italic><sub><italic>stop</italic></sub></td>
<td align="left">.8</td>
<td align="left">end of trajectory (in seconds)</td>
<td align="left">[<italic>dot</italic><sub><italic>start</italic></sub>, <italic>T</italic>]</td>
</tr>
<tr>
<td align="left"><italic>I</italic><sub><italic>noise</italic></sub></td>
<td align="left">.05</td>
<td align="left">std of noise in images</td>
<td align="left">
<inline-formula id="pcbi.1005068.e039">
<alternatives>
<graphic id="pcbi.1005068.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e039" xlink:type="simple"/>
<mml:math display="inline" id="M39">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left"><italic>T</italic><sub><italic>f</italic></sub></td>
<td align="left">0.05</td>
<td align="left">flash duration (in seconds)</td>
<td align="left">
<inline-formula id="pcbi.1005068.e040">
<alternatives>
<graphic id="pcbi.1005068.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e040" xlink:type="simple"/>
<mml:math display="inline" id="M40">
<mml:msup>
<mml:mi mathvariant="double-struck">R</mml:mi>
<mml:mo>+</mml:mo>
</mml:msup>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<sec id="sec011">
<title>Diagonal motion-based prediction (dMBP) and the flash-lag effect (FLE)</title>
<p>The standard FLE experiment is composed of a simple moving stimulus (a dot) and a static flash that appears in perfect alignment as the stimulus crosses the middle of its trajectory (<xref ref-type="fig" rid="pcbi.1005068.g001">Fig 1</xref>). We reproduced these exact conditions to test our model. Defining the spatial coordinates between −1 and 1, the dot started at <italic>t</italic> = 0.2 s for rightward motion from <italic>x</italic> = −0.6, moved toward <italic>x</italic> = 0.6 and then disappeared at this position. Thanks to the symmetry between left- and rightward motions, we will only show the results for the pure horizontal rightward motion of a small dot. We defined an absolute time in arbitrary units for which motion begun at <italic>t</italic> = 200 ms and ended at <italic>t</italic> = 800 ms. In the simulations, this period of time was subdivided into 100 frames such that every frame of stimulus was arbitrarily set to 10 ms of biological time and one temporal period lasted 1 second. In all experiments, the flash persisted for 5% of display duration (5 frames out of 100, that is, frames #48 to #52). Notice that such flash duration is much longer than the microsecond duration used in psychophysical experiments [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>]. Such ultrashort duration was set to avoid retinal persistence and other perceptual effects that could interact with the perceived timing but was irrelevant for the current modeling study. Still, we run the model with a range of these timing values and checked that the results remain qualitatively similar. Lastly, all results were computed over 20 independent repetitions by changing the seed of the number generator that governs the generation of sensory and internal noise.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3</xref> summarizes the main results when simulating the FLE with the dMBP model for <italic>τ</italic> = 100 ms, a realistic delay for human motion perception. In <xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3-A</xref>, we plot the estimated positions of both static (flashing) and moving stimuli. The position of the moving dot shows a spatial lead similar to what was reported in the psychophysical literature. <xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3-B</xref> illustrates the responses of the dMBP model together with a control condition, the position-based prediction (PBP) model where the predictive term relative to motion was discarded. This PBP model is simply defined by using the same equations but assuming that, first, the precision in <xref ref-type="disp-formula" rid="pcbi.1005068.e023">Eq 19</xref> is zero, meaning that the diffusion parameter <italic>D</italic><sub><italic>V</italic></sub> is infinite and second, that the speed prior defines an isotropic diffusion factor similar to that of the diffusion in position. Thus the PBP and dMBP models differ in regards of the information used (position only vs position and velocity) and thus of the shape of the diffusion (isotropic vs anisotropic). For the two models, we analyzed their estimated responses as spatial histograms with 50 bins over the range of horizontal spatial positions (that is, (−1, 1)). In particular, the positional bias reported for the FLE was computed as the inferred position of the moving dot at the instant at which the flashed stimulus reached its maximum precision, that is to say when the standard deviation of its inferred position was minimal. In <xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3-B</xref>, we plot the two frames before and after that instant. As the flash was an unexpected event, this maximum was achieved after the fixed delay period and a variable processing delay that we robustly observed to be of about one frame (≈10 ms) in our simulations. It is evident from <xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3-B</xref> that, at the moment at which the flash was maximally activating the dMBP model, the estimation of the position of the moving stimuli was ahead of the location of the flash. By comparison, the PBP model did not show this effect, suggesting that motion-based prediction is indeed necessary to account for the Flash-lag effect.</p>
<fig id="pcbi.1005068.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.g003</object-id>
<label>Fig 3</label>
<caption>
<title>The diagonal motion-based prediction (dMBP) model accounts for the Flash-lag effect.</title>
<p>
<monospace>(A)</monospace> We plot the histogram of estimated positions from the dMBP model with a neural delay <italic>τ</italic> = 100 ms for the moving and the flashed stimuli. These estimated positions are averaged across the five frames centered around the time at which the response to the flash reaches its maximal precision and across 20 trials. Comparing the distribution of estimated positions for the moving (green) and flashed (in red) stimuli shows that, at this particular instant, the (left) moving dot is perceived ahead of the estimated position of the flash. <monospace>(B)</monospace> We quantified this spatial lead by plotting the histograms of the inferred horizontal positions during these frames, both for the position-based predictive (PBP) and dMBP models. The red and green dashed vertical lines represent the average positions of the flashed and moving stimuli, respectively. One can observe a significant spatial lead in the dMBP model, but not in the PBP model. The motion component of the dMBP model is thus essential to explain the flash-lag effect. <monospace>(C)</monospace> We varied the speed of the dot motion to titrate its role in the amplitude of the spatial lead. The black dashed line illustrates the predicted linear relationship from an extrapolation model with a perfect knowledge about target speed (slope one). One can observe a nearly linear relationship at slow speeds, followed by a saturation for higher speeds. At the fastest extrema of the speed range, ones observes a decrease in the spatial lead of the moving spot, together with an higher variability across trials (error bars: ±1 SD), consistent with the experimental data from [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>]. The nonlinear relationship in our model emerges from the decrease of precision in the representation of motion at higher speeds. It highlights the putative role of the dynamic, explicit representation of precision in explaining the flash-lag effect.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.g003" xlink:type="simple"/>
</fig>
<p>As expected, the speed of the moving dot affected the perceived spatial lead. When running the dMBP model with <italic>τ</italic> = 100 ms, the spatial lead of the moving dot monotonically increased with dot speed, until it reached a saturation value for very high speeds (<xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3-C</xref>). This result is consistent with the empirical observations of Wojtach et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>] but also that reviewed in [<xref ref-type="bibr" rid="pcbi.1005068.ref047">47</xref>]. However, such nonlinear relationship between spatial lead and stimulus velocity was obtained without the need for a specific speed-tuned prior, as postulated in the model of Wojtach et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>]. The saturation observed for high speeds was concomitant with a sharp increase in the variance of the position estimates. Thus, inferred motion was less precise for higher speeds, despite the fact that (spatial) trajectory length remained constant. Again, this result is consistent with psychophysical data on global and local (dot) motion perception (e.g. [<xref ref-type="bibr" rid="pcbi.1005068.ref048">48</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref050">50</xref>]). Overall, the non-linear relationship between spatial lead and the dot motion speed results from both the optimal integration of information within the system and the decrease in precision of the sensory information at higher speeds. Thus, the dMBP model highlights the importance of having a probabilistic representation of visual motion in order to elaborate mechanisms which are able to compensate for neural delays.</p>
</sec>
<sec id="sec012">
<title>Standard FLE versus half-cycle FLEs</title>
<p>Next, we simulated the spatial lead of a moving dot in the case of half-cycle FLEs where the flash appeared either at the beginning or at the end of the motion trajectory. As discussed above, the half-cycle FLEs described by Nijhawan [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>] have challenged the diagonal model of FLE. Therefore, our goal was to test whether our diagonal motion-based prediction (dMBP) can account for these different conditions.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005068.g004">Fig 4</xref> illustrates the model’s output for the two different half-cycle FLEs by plotting the probability distributions for the inferred positions of both the flashed (red curves) and moving (green curves) dots. The estimated perceived positions were computed as the maximum a posteriori values, across the five frames duration of the flash (respectively numbered from <italic>i</italic> − 2 to <italic>i</italic> + 2). These a posteriori probability distribution functions represent the peak (most probable) inferred position as well as the spatial uncertainty which are essential components in motion-induced perceptual shifts [<xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>]. In the flash-initiated half cycle, the flash appeared at the beginning of the moving dot trajectory. The simulations unveiled two phenomena. First, the precision of the estimated positions of the flash gradually increased over time (lower left panel). Moreover, we observed that the center of the distribution of the inferred positions was always aligned with respect to the physical location of the flashing dot (see <xref ref-type="fig" rid="pcbi.1005068.g004">Fig 4-A</xref>). Second, ones can see a rapid sharpening for the position of the moving dot over time. This increase in precision was concomitant with a smooth shift of the moving dot’s perceived position along the motion direction, corresponding to the classical FLE. As such, our model simulate a position bias in the flash-initiated condition that is consistent with the psychophysical observations [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>].</p>
<fig id="pcbi.1005068.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Both flash-initiated and flash-terminated conditions can be explained by the diagonal motion-based prediction (dMBP) model.</title>
<p>With the same format as <xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3-B</xref>, we plot the temporal evolution of the probability distributions of the inferred position for both the flashed (in red) and moving (in green) dots, in the <monospace>(A)</monospace> flash-initiated and <monospace>(B)</monospace> flash-terminated conditions. As in <xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3-B</xref>, each curve corresponds to the five frames (respectively numbered from <italic>i</italic> − 2 to <italic>i</italic> + 2) centered on the time of the model’s maximal response to the flash. Dashed vertical lines indicate at each frame the estimated positions from the maximum a posteriori of the probability distributions for either the flash (red) or the moving (green) dot, together with the veridical position of the flashed dot (black). As expected, one can observe that the distribution of inferred positions is approximately correct for the flashed stimulus in all conditions. In the flash-initiated FLE condition, the distribution for the moving dot is biased towards its direction and develops very rapidly. Notice however that these biases are smaller than observed with the standard FLE. In the flash-terminated conditions, the bias is observed in the last frames before the maximum of the flash and then competes with another estimate with no bias which dominates near the moment of the flash’s maximum. Note that the a posteriori probability distributions around the flash’s maximum are very broad and indicate a high spatial uncertainty. Altogether, the absence of bias in the flash-terminated condition is similar to that reported psychophysically with human observers [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.g004" xlink:type="simple"/>
</fig>
<p>The dynamics was different in the flash-terminated condition (<xref ref-type="fig" rid="pcbi.1005068.g004">Fig 4-B</xref>). Consistent with the standard FLE, we observed first a bias in the two frames occurring before the maximum of the flash. Moreover, the distribution was very broad, consistent with a high uncertainty about the position of the dot. Gradually, the maximum of the position’s distribution shifts towards the flash location. Hence, near the moment of the flash’s maximum response, we obtained a bimodal distribution corresponding to a competition of the early extrapolated position with a second, unbiased distribution. At the time the flash was perceived, the two peaks corresponding to the estimated positions of both flashed and moving stimuli were now closely matched. These reported positions were now consistent with the classical psychophysical observations that, in flash-terminated cycles, there is no perceived spatial lead at the moment the moving dot disappears. When interpreting the disappearance of bias in the flash-terminated condition, Eagleman and Sejnowski proposed that the movement occurring before the flash was not sufficient to induce a flash-lag illusion and therefore proposed an alternative theoretical framework, the postdiction model [<xref ref-type="bibr" rid="pcbi.1005068.ref027">27</xref>]. Other studies have reported that under some stimulus conditions, the FLE does occur in the flash-terminated cycle (e.g. [<xref ref-type="bibr" rid="pcbi.1005068.ref051">51</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>]) in particular when the uncertainty about the position in space of the moving stimulus is high. The simulated dynamics of the estimated position during the flash-terminated cycle shows that the probabilistic representation of visual inputs underlying the dMBP model is sufficient to reconcile those apparently contradictory results. Thus, the dMBP provides a powerful framework to account for the different variants of the FLE and a broad range of their experimental conditions. We will now explain why the dMBP model can account for these different variants of the FLE.</p>
<p>A first step was to further detail the internal dynamics of the dMBP model during the motion of the dot. As shown in <xref ref-type="fig" rid="pcbi.1005068.g005">Fig 5</xref>, we investigated the temporal dynamics of the estimations of both position and velocity by plotting their spatial histograms as a function of time, over the complete trajectory. We focused on three different epochs of motion trajectory, corresponding to the standard, flash-initiated and flash-terminated conditions. For each epoch, the vertical dotted black lines indicate the physical time of the flash and the green lines signal the delayed input with the known delay (<italic>τ</italic> = 100 ms). Both the source and target layers are illustrated for each of three different phases. First, we found a rapid build-up of the precision of the target after the first appearance of the moving dot (at <italic>t</italic> = 300 ms). Consistent with the Frölich effect, the beginning of the trajectory was seen ahead of its physical position as indicated by the maximum of probability distributions lying in between the oblique green and back dotted lines. During the second phase, the moving dot was correctly tracked as both its velocity and position are correctly inferred. In the source layer, there was no extrapolation and the trajectory followed the delayed trajectory of the dot (green dotted line). In the target layer, motion extrapolation correctly predicted the position at the present time and the position followed the actual physical position of the dot (black dotted line). Finally, the third phase corresponded to the motion termination. The moving dot disappeared and the corresponding activity gradually vanished in the source layer at <italic>t</italic> = 900 ms. However, between <italic>t</italic> = 800 ms and <italic>t</italic> = 900 ms, the dot position was extrapolated and predicted ahead of the terminal position in the target layer. At <italic>t</italic> = 900 ms, sensory visual motion information was now absent and the prior for slow speeds dominated. Both the quick drop of the estimated velocity after the dot’s disappearance and the diffusion of this information in both position and velocity spaces led to the progressive extinction of position extrapolation ahead of the sensed position. Consistently with this new information, the position information was now gradually extrapolated thanks to the broad, zero-centered prior distribution for speeds. As such, the inferred position in the target layer was now extrapolated isotropically from that of the source layer at <italic>t</italic> = 900 ms, that is to say, at the terminal horizontal position. Although this distribution was much less precise, the average position of the moving dot at flash termination was invariably perceived at the same position as that of the flash.</p>
<fig id="pcbi.1005068.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Histogram of the estimated positions as a function of time for the dMBP model.</title>
<p>Histograms of the inferred horizontal positions (blueish bottom panel) and horizontal velocity (reddish top panel), as a function of time frame, from the dMBP model. Darker levels correspond to higher probabilities, while a light color corresponds to an unlikely estimation. We highlight three successive epochs along the trajectory, corresponding to the flash initiated, standard (mid-point) and flash terminated cycles. The timing of the flashes are respectively indicated by the dashed vertical lines. In dark, the physical time and in green the delayed input knowing <italic>τ</italic> = 100 ms. Histograms are plotted at two different levels of our model in the push mode. The left-hand column illustrates the source layer that corresponds to the integration of delayed sensory information, including the prior on motion. The right-hand illustrates the target layer corresponding to the same information but after the occurrence of some motion extrapolation compensating for the known neural delay <italic>τ</italic>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.g005" xlink:type="simple"/>
</fig>
<p>The termination epoch illustrates some key differences between our probabilistic model and previous theoretical explanations. The dMBP model explicitly differentiates between a zero motion (i.e. “I know that the stimulus does not move”) and an absence of knowledge, as represented by the prior distributions for velocities. In particular, we do not need to postulate the existence of a resetting mechanism. For instance, the FLE is present at termination when introducing spatial uncertainty (for instance at a higher eccentricity) but disappears again in the same configuration when the dot stops and does not not disappear [<xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>]. A second key difference is the introduction of a compensation for the latency which is controlled by the precision of the sensory and internal beliefs. The important distinction is that the system is tuned to give the most probable state at the current time even if the incoming information is from the past (delayed by <italic>τ</italic>). In particular, at the end of the trajectory, the system updates its prediction after the delay of <italic>τ</italic> = 100 ms, according to the collected information at <italic>t</italic> = 800 ms and which is sensed at <italic>t</italic> = 900 ms. At this particular moment, instead of keeping the prediction that the dot moved during this period, the dMBP model updates its state with the knowledge that the dot disappeared at the physical time corresponding to motion offset and is more likely to be near the last observed position at <italic>t</italic> = 900 ms (and that corresponds to the physical time <italic>t</italic> = 800 ms). One prediction of the dMBP model is therefore that, with a long enough delay (as is the case here), the predicted position should be first estimated ahead of the actual position and then, <italic>with hindsight</italic>, shifts back to the position accounting for the end of motion (see <xref ref-type="fig" rid="pcbi.1005068.g004">Fig 4-B</xref>). Overall, this dynamics explains the perceptual difference observed between the flash-terminated and flash-initiated FLEs and provides a simple and parsimonious alternative to the postdiction theory.</p>
</sec>
<sec id="sec013">
<title>The FLE and beyond: Motion reversal</title>
<p>Extending the previous results, we investigated the inferred position when the motion of the dot is not interrupted, but reversed. As such, we simulated the experiment reported by Whitney and Murakami [<xref ref-type="bibr" rid="pcbi.1005068.ref023">23</xref>] and modeled by Rao et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref045">45</xref>]. In this variant of the FLE, the moving dot reverses direction at the middle of the trajectory, and then maintains its new trajectory. To implement this stimulus, we used the same stimulus as in <xref ref-type="fig" rid="pcbi.1005068.g003">Fig 3</xref>, but mirrored vertically the image for the frames occurring in the second half of the movie. Results are shown in the left column of <xref ref-type="fig" rid="pcbi.1005068.g006">Fig 6</xref>, using the same format as the target layer in <xref ref-type="fig" rid="pcbi.1005068.g005">Fig 5</xref>. As expected, the model’s behavior is consistent with that observed with the flash-initiated cycle condition. First, the estimated position follows the first half of the trajectory and continues to be extrapolated after the time <italic>t</italic> of reversal and until the moment <italic>t</italic> + <italic>τ</italic> at which the sensory evidences about the motion reversal has reached the system. From this moment in time, the source layer updates the target layer according to the new visual information. As in the previous case with the flash-terminated FLE, the estimated velocity is rapidly updated and converges to the new motion direction. Using the parodiction hypothesis, the model updates at this instant the velocity used in the extrapolation of the present position as it acquires this novel knowledge (that is, with some hindsight). The estimated position in the target layer thus “jumps” to the new location and then follows the second half of the trajectory.</p>
<fig id="pcbi.1005068.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Estimating the dot position from the dMBP model during the motion reversal experiment.</title>
<p>In the motion reversal experiment, the moving dot reverses its direction at the middle of the trajectory (i.e., at <italic>t</italic> = 500 ms, as indicated by the mid-point vertical dashed line). In the left column (target layer) and as in <xref ref-type="fig" rid="pcbi.1005068.g005">Fig 5</xref>, we show the histogram of inferred positions during the dot motion and a trace of its position with the highest probability as a function of time. As expected, results are identical to <xref ref-type="fig" rid="pcbi.1005068.g005">Fig 5</xref> in the first half period. At the moment of the motion reversal, the model output is consistent with previous psychophysical reports. First, the estimated position follows the extrapolated trajectory until the (delayed) sensory information about the motion reversal reaches the system (at <italic>t</italic> = 600 ms, green vertical dashed line). Then, the velocity is quickly reset and converges to the new (reversed) motion such that the estimated position “jumps” to a position corresponding to the updated velocity. In the right column (smoothed layer), we show the results of the same data after a smoothing operation of <italic>τ</italic><sub><italic>s</italic></sub> = 100 ms in subjective time. This different read-out from the inferred positions corresponds to the behavioral results obtained in some experiments, such as that from Whitney and Murakami [<xref ref-type="bibr" rid="pcbi.1005068.ref023">23</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.g006" xlink:type="simple"/>
</fig>
<p>Overall, the model’s behavior is qualitatively similar to the filtering model reported by Rao et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref045">45</xref>]. Under some generic hypothesis about the noise distribution, the dMBP model is in fact equivalent to a Kalman filter with a fixed delay [<xref ref-type="bibr" rid="pcbi.1005068.ref008">8</xref>]. It is therefore consistent with the optimal filtering model of Rao et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref045">45</xref>]. At first sight, the response of our model may seem at odd with the behavioral results reported by Whitney and Murakami [<xref ref-type="bibr" rid="pcbi.1005068.ref023">23</xref>] where no overshoot (and thus no jump) was found in the estimated position after motion reversal, as predicted in the optimal smoother model proposed by [<xref ref-type="bibr" rid="pcbi.1005068.ref045">45</xref>]. This model extrapolates the current position knowing the past positions within a temporal window corresponding to some subjective latency. It is based on the postdiction hypothesis postulating that the position that is accessible to visual awareness is evaluated after some additional delay <italic>τ</italic><sub><italic>s</italic></sub>. Thus, position is reported in the reference frame of a delayed, subjective time which is the same for the two stimuli (the moving and flashed dots). Similarly to that model, we may use our probabilistic framework to update the information after this delay: The postdiction hypothesis thus states that the evaluation for the position at the present time <italic>t</italic> is done in the future at time <italic>t</italic> + <italic>τ</italic><sub><italic>s</italic></sub>. The information at this time is <italic>p</italic>(<italic>z</italic><sub><italic>t</italic>+<italic>τ</italic><sub><italic>s</italic></sub></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic>+<italic>τ</italic><sub><italic>s</italic></sub></sub>) and similarly to the extrapolation which is performed over future times (see <xref ref-type="disp-formula" rid="pcbi.1005068.e005">Eq 5</xref>), we may extrapolate over past times (that is, backwards in time) using a similar hypothesis:
<disp-formula id="pcbi.1005068.e041"><alternatives><graphic id="pcbi.1005068.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005068.e041" xlink:type="simple"/><mml:math display="block" id="M41"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>d</mml:mi> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mrow><mml:mn>0</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(20)</label></disp-formula></p>
<p>The output of this transformation is shown in the right column (labelled smoothed layer) of <xref ref-type="fig" rid="pcbi.1005068.g006">Fig 6</xref>, with <italic>τ</italic><sub><italic>s</italic></sub> = 100 ms and the values of subjective time being realigned to physical time for the sake of clarity. Now, our results show qualitatively no overshoot and the model’s dynamics is similar to the optimal smoother model proposed by Rao et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref045">45</xref>]. Note that a similar transformation applied to the flash-terminated cycle would qualitatively smooth the estimate of the position using past frames and thus enhance the absence of bias in this case.</p>
<p>This transformation applied to the probabilistic information illustrates two key properties of the dMBP model. First, it shows that the model can explain the experimental data from Whitney and Murakami [<xref ref-type="bibr" rid="pcbi.1005068.ref023">23</xref>] by explicitly modeling the decoding used in this experiment. In particular, our model can explain why the spatial position of the moving dot begins to deviate <italic>before</italic> the random time of the reversal. Such probabilistic framework can also account for the contradicting results obtained in the flash-terminated cycle where, for instance the FLE was reported by Eagleman and Sejnowski [<xref ref-type="bibr" rid="pcbi.1005068.ref027">27</xref>] but not by others [<xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref051">51</xref>] and was found to be in fact dependent upon the uncertainty about the position of the moving dot. Second, it demonstrates the flexibility of the representation used in the parodiction hypothesis and its capacity of subsuming the differential latency, motion extrapolation and postdiction hypotheses. Hence, the diversity of alternative models drawn to account for the various FLE experiments is not necessary, thanks to the probabilistic mechanisms used by the visual system to decode this information.</p>
</sec>
<sec id="sec014">
<title>Modeling the effects of stimulus contrast and duration on the flash-lag effect</title>
<p>We have shown above that the dMBP model can explain the different variants of the FLE. In order to further understand how the precision of the probabilistic representation shapes the FLE, we manipulated a small set of key visual parameters which are known to tune the dynamics of the dMBP model: stimulus contrast and duration. As shown in our previous modeling study about the role of motion extrapolation in object tracking [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>], decreasing the contrast of a moving stimulus results in a modified dynamics of the predicted state. One important consequence is that a predictable, moving stimulus may then be detected at lower contrasts than an unpredictable flash since the system integrates sensory information along the motion trajectory. This is consistent with previous psychophysical observations about single dot motion detection in a noisy display [<xref ref-type="bibr" rid="pcbi.1005068.ref052">52</xref>]. However, since contrast differentially modulates the processing of either flashed or moving stimuli, it is important to investigate its effects upon simulated FLE. A prediction is that a flashed stimulus shall be more affected by lowering the contrast than a moving one, resulting in different effects upon FLE. We could then unify several empirical evidences that have led to different theoretical interpretation of FLE (e.g. [<xref ref-type="bibr" rid="pcbi.1005068.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>]).</p>
<p>We first simulated the relationship between FLE and the relative contrast between the dot and the flash, in two different conditions, the standard cycle (i.e. flash at mid-point) and the flash-initiated cycle. These two conditions correspond to cases where we observe the precision of the dot position early or late along a similar motion trajectory. The results are illustrated in <xref ref-type="fig" rid="pcbi.1005068.g007">Fig 7-A</xref>. Using the same conventions as in <xref ref-type="fig" rid="pcbi.1005068.g005">Fig 5</xref>, the estimated distributions of horizontal positions are plotted against time. These spatial distributions are the average over 20 trials and are shown for a time lapse centered around the maximal precision of flash stimulus. The first two columns show these distribution as estimated at two different time epochs, that is early or late during a motion trajectory, respectively corresponding to flash-initiated or standard FLE conditions. Early distributions are strongly sensitive to dot and flash contrast, with almost no reliable estimate at very low contrast (i.e. below <italic>C</italic> ≈ 0.4). By comparison, the distributions for the dot at the standard FLE cycle emerge at very low contrast, and rapidly reach their stable solution. In the temporal domain, we also observed that for lower contrasts, the dynamics of integration became slower such that the peak was reached slightly later. <xref ref-type="fig" rid="pcbi.1005068.g007">Fig 7-B</xref> quantitatively reports the effects of contrast on the precision of the estimated position (that we define here as the inverse of the standard deviation). During the flash-initiated cycle, we found a smooth increase in precision with higher contrast of either the moving dot (blue curve) or the flash (red curve). The contrast-precision function was much more step-wise in the standard cycle condition where dot position is estimated at the mid-point of the motion path. The precision was also much larger in this later condition. From these, we estimated the spatial lag (second column, <xref ref-type="fig" rid="pcbi.1005068.g007">Fig 7-B</xref>) against contrast. A prediction of our model is that a broader distribution in position, such as observed with a lower stimulus contrast, would be associated with a coarser velocity estimation. Such uncertainty would impact the extrapolation of positional error and thus the spatial lag. As expected, we found a large increase in the spatial lag as the contrast of the dot increased in the flash-initiated cycle (blue line). This effect was largely reduced in the classical FLE condition (green line). We also varied the contrast of the flash and found, for a contrast above <italic>C</italic> ≈ 0.5, a decrease in the spatial lag as contrast increased, as expected from the precision measurements. Notice that estimating the spatial lag for very low contrasts is very unreliable given the high spatial uncertainty in the position estimation (see <xref ref-type="fig" rid="pcbi.1005068.g007">Fig 7-A</xref>, lower rows).</p>
<fig id="pcbi.1005068.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005068.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Dependence of the FLE with respect to contrast and duration of the stimuli.</title>
<p>
<monospace>(A)</monospace> Using the same data format as in <xref ref-type="fig" rid="pcbi.1005068.g005">Fig 5</xref>, we show the spatial distribution of the estimated response (zoomed around its physical position at the perceived time of the flash at full contrast which is indicated by a cross) for different different relative contrast levels <italic>C</italic> indicated at each row. The different columns correspond from left to right to different conditions where the contrast of the dot is manipulated (first two columns)—respectively at the beginning of the cycle (i.e. flash-initiated) cycle, the mid-point (i.e. standard cycle)— or where the contrast of the flash is varied (right-end column). Note that in the standard FLE case (middle column), the model already responds to very low values of dot contrast in a nearly all-or-none fashion. By comparison, the responses to the dot or the flash during the initial phase of the trajectory gradually increased with contrast. In particular, the dot’s lag seems to increase more rapidly with respect to contrast. <monospace>(B)</monospace> These qualitative results are best illustrated by plotting in the first column the precision of the response as measured by the inverse standard deviation of the estimated position as a function of contrast of the different conditions. Coherent with the results illustrated in (A), the precision of the representation varies gradually against contrast of the flash or moving dot in the early phase whereas it changes more rapidly and abruptly as a function of the moving dot’s contrast in the standard FLE. Consequently, we estimated in the second column the spatial lag that is expected when changing the contrast of the stimuli (± one standard deviation). Coherently with psychophysical results, increasing the contrast of the moving dot gradually increases the FLE in the flash-initiated cycle but has only limited effects in the standard FLE when above a given precision as it rapidly reaches a saturating value of ≈0.2 corresponding to a full compensation of the fixed delay. Consistent with [<xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>], these results show the role of spatial uncertainty in dynamically tuning the estimated position and, ultimately, in influencing the spatial lag in the FLE. <monospace>(C)</monospace> As shown by [<xref ref-type="bibr" rid="pcbi.1005068.ref047">47</xref>], flash duration modulates FLE. We show here the precision for the flash as a function of time with respect to duration. While the peak remained at <italic>t</italic> = .5 s (that is, at <italic>t</italic> = .6 s when including the delay), we tested for different durations, respectively .03, .05, .08, .13, .25 in s (as marked by colored horizontal bars). The respective measured time to reach the maximal precision are given by <italic>t</italic><sub><italic>max</italic></sub> (in s), showing that precision was high for <italic>T</italic> ≥.05 s (that is, 50 ms). Notice that this value was used for all the experiments described above.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005068.g007" xlink:type="simple"/>
</fig>
<p>Overall, the dMBP model can simulate the main effects of the relative contrast between the flash and the dot, in different conditions. These simulated relationships can be compared with previous empirical studies that investigated the impact of contrast upon perceived FLE [<xref ref-type="bibr" rid="pcbi.1005068.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>] (see [<xref ref-type="bibr" rid="pcbi.1005068.ref029">29</xref>] for a review). Consistent with previous results [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>], we observed that contrast affects the precision of position estimates mostly at the beginning of the motion trajectory, as in the flash-initiated cycle for instance. Since the model started to efficiently track the dot at a later time point, a weaker flash-initiated FLE is observed at lower contrast values. By comparison, at trajectory points that are more distant from the motion onset, as in the standard FLE condition, the tracking remained very precise at low contrast and thus, the size of the FLE was only marginally affected. Overall, our model unifies the different observations that the uncertainty generated by a lower effective contrast (and other stimulus conditions) results in lower FLEs [<xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>]. Our model also allows to compare the relative effects of the moving versus flashed dots. For instance, the spatial lag increases with the relative contrast of the moving dot, but slightly reduces with it. This is consistent with a previous empirical study [<xref ref-type="bibr" rid="pcbi.1005068.ref033">33</xref>]. It shall be noticed that these authors have manipulated the relative luminance of the stimuli rather than contrast. However, assuming a stationary exogenous noise source, luminance and contrast changes shall yield to similar model outputs. Thus, our model is compatible with their results but it does so by compensating for a fixed delay, without the need of postulating different latencies for moving and flashed inputs [<xref ref-type="bibr" rid="pcbi.1005068.ref033">33</xref>]</p>
<p>As a final control, we manipulated flash duration. While we did not observe any effect of this stimulus parameter on the mean estimated position, the precision was dynamically modulated by it (see <xref ref-type="fig" rid="pcbi.1005068.g007">Fig 7-C</xref>). We observed a characteristic integration time controlled by the <italic>σ</italic><sub><italic>I</italic></sub> parameter of the likelihood model (see <xref ref-type="table" rid="pcbi.1005068.t001">Table 1</xref>). By consequence, precision at the peak decreased with very short durations (3 frames, that is, 30 ms). Then, the precision quickly stabilized over the stimulation duration, consistently with the stationary solution of the master equations of the MBP model. The varying timing corresponding to the optimal precision with respect to flash duration thus has a consequence on the FLE. However, such consequences are harder to estimate in our framework, in particular for durations longer than <italic>τ</italic>. In these particular cases, the maximum of the estimated position was ambiguously defined and did not necessarily correspond to the middle of the flash. Rather, since information was progressively integrated, the precision was in theory increasing and should be reported to peak as the flash disappears. As such, the spatial lag in the FLE should decrease with longer flash durations. This is consistent with experimental reports on the disappearance of the FLE for flash durations longer than 80 ms [<xref ref-type="bibr" rid="pcbi.1005068.ref047">47</xref>]. This result also justifies that in the present study we used a short flash of 5 frames, that is, 50 ms.</p>
</sec>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>Discussion</title>
<sec id="sec016">
<title>Motion-based prediction, position coding and the flash-lag effect</title>
<p>In this computational study, we have investigated the role of prediction in a challenging and popular example of motion-induced position shifts, the flash-lag effect (FLE). When elaborating a novel theoretical framework for both experimental and modeling studies on FLE is an essential step to better understand the perceptual mechanisms of visual position coding and the compensation for the delays inherent to any neural mechanism. As stated above, at least three main explanations of the FLE have been proposed in the literature but none of them can account for all the properties of the FLE. Based on our previous work on predictive coding and visual motion processing [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref053">53</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref044">44</xref>], we propose that the FLE and its different variants are a mere consequence of a motion-based predictive coding mechanism that is compatible with low-level visual processing.</p>
<p>Our simulations demonstrate that the motion of a localized target can shift the estimation of its position along the motion direction. We introduced a second flashed input lasting 5% of the trajectory length which we presented at the beginning, middle and end of the trajectory, matching the three main empirical cases used to probe the FLE [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>]. We show that the diagonal motion-based prediction (dMBP) model can explain the presence or absence of a spatial lead of the moving stimulus in all these three variants of the FLE. In particular, the model can simulate one main perceptual fact: the spatial offset is seen in the flash initiated cycle but not in the flash terminated cycle. For the first time, our model can thus provide an explanation for all three empirical results, as a consequence of the optimal extrapolation in the positional coding of a moving object in the direction of its motion.</p>
<p>This approach can be seen as an extension of the motion extrapolation theory originally proposed by Nijhawan [<xref ref-type="bibr" rid="pcbi.1005068.ref004">4</xref>] and which has been highly disputed over the last two decades. Our dMBP model is a generic motion estimation algorithm which uses a probabilistic representations that explicitly estimates the distribution of beliefs about the motion of the stimulus by using both position and velocity information about the object trajectory. The dMBP model is able to compensate for a known neural delay and to differentiate between moving (predictable) and static, flashed (unpredictable) objects. Moreover, we have shown that the precision of this belief tunes the gain of the predictive coding mechanism similarly to the range of psycho-physical observations. It thus provides a rationale for coding the estimated position of both the flashed and the moving stimuli in the FLE.</p>
</sec>
<sec id="sec017">
<title>Experimental evidences for the dMBP model</title>
<p>This study provides several theoretical insights on the role of motion signals in the dynamical representation of objects’ positions and its dependency upon several visual factors such as speed, contrast, duration or the timing of the flash respective to the motion trajectory. Several psychophysical and neurophysiological studies have shown that the perceived position of a moving object is shifted into the direction of motion, a phenomenon called motion extrapolation (e.g. [<xref ref-type="bibr" rid="pcbi.1005068.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref055">55</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref057">57</xref>]). Motion extrapolation has been assumed to be caused by an anisotropic pattern of connectivity between position-coding cells in the retina [<xref ref-type="bibr" rid="pcbi.1005068.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref054">54</xref>] or the early visual cortex [<xref ref-type="bibr" rid="pcbi.1005068.ref015">15</xref>]. Thus, different modeling studies have simulated motion-induced position shifts by using position-tuned cells and dynamical effects of lateral interactions in neural networks [<xref ref-type="bibr" rid="pcbi.1005068.ref058">58</xref>–<xref ref-type="bibr" rid="pcbi.1005068.ref061">61</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref011">11</xref>]. We show here a similar behavior, resulting from the interactions between position and velocity coding. We suggest that a predictive bias of the neural representation of position can result from these interactions, a general rule of early visual processing stages within retinotopic maps. Moreover, contrary to most of previous models, the dMBP model can simulate the relationships between the perceived positional shift in the FLE and properties of the object’s motion. This later relationship is coherent with previously reported psychophysical studies [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>] and highlights the interactions between position and velocity coding.</p>
<p>In particular, from previous computational studies in motion extrapolation, one may expect a smaller spatial lead in the flash-initiated cycle. In the earliest frames of the trajectory, position estimation will in fact lag behind the actual, physical position of the stimulus. We have not found this effect with the dMBP model. Only a few frames within the flash duration were sufficient to modulate the position estimation of the moving object and to compensate for the delay. Thus, the dMBP model does predict no significant difference between the size of spatial leads simulated in flash-initiated and standard FLEs. On the other hand, in the response of the dMBP model to the flash terminated FLE, there is a close match between the estimated positions of both flashed and moving stimuli, consistent with the psychophysical evidence. This effect is easily explained by the interplay between the input sensory layer and the predictive target layer at the instant when the flash is sensed. At this precise time, the estimated velocity for the moving dot is updated with hindsight to a distribution centered on a zero speed, causing a static extrapolation at the end of the trajectory and correcting for the wrongly assumed motion of the dot during the delay period. This causes the “jump” from the extrapolated trajectory to that observed at the instant of the flash. Such prediction should be investigated at perceptual and physiological levels in future work.</p>
<p>Another empirical aspect of the FLE is the dependence of the spatial lead with respect to contrast [<xref ref-type="bibr" rid="pcbi.1005068.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>]. In fact, the dMBP model is based on the accumulation of information along the trajectory, without any pre-determined contrast gain control mechanism. As a result, a low contrast would only result in a slower build-up of the tracking behavior, as previously observed [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>]. Here, the dMBP model highlights two important points in the contrast dependence of the FLE. First, for the flash initiated cycle, a higher contrast would result in a larger spatial lead of the moving object. Second, for both standard and flash terminated cycles, that is, for positions located late enough along the object’s motion trajectory, the dependence of spatial lead on contrast can be mostly explained by the contrast of the flashed input, as shown by the relationship illustrated in <xref ref-type="fig" rid="pcbi.1005068.g007">Fig 7</xref>. Indeed, consistent with experimental evidence [<xref ref-type="bibr" rid="pcbi.1005068.ref038">38</xref>], the model’s response to a low contrast flashed stimulus takes longer to reach the detection threshold such that the moving stimulus will further advance along the trajectory before the input arrives, resulting in a larger positional lead.</p>
</sec>
<sec id="sec018">
<title>Shortcomings of the motion extrapolation theory</title>
<p>It is important to highlight some key differences between our dMBP model and previously published models based on motion extrapolation. In the literature, two main shortcomings of motion extrapolation were raised. First, it was found experimentally that the spatial lead of moving object in flash-initiated cycle is comparable with the spatial lead observed in standard FLE. This is in contradiction with the fact that, according to the motion extrapolation hypothesis, the positions of the two objects should not be distinguishable enough during the earliest phase of the motion trajectory. By contrast, the dMBP model shows a quantitatively similar positional lead in flash-initiated cycle. This result resolves an apparent shortcoming of the motion extrapolation theory: the duration of the flash is enough to initiate the integration of motion signals along its trajectory and to correctly compensate for the positional error caused by neural delays.</p>
<p>Another classical shortcoming of the motion extrapolation theory is related to the flash-terminated cycle. Empirically, no spatial lead or overshoot is perceived for flashes occurring at the end of trajectory whereas the motion extrapolation model would predict one. Because of this contradiction, several of the existing models decided to ignore the flash-termination FLE. For instance, the model of Wojtach et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref036">36</xref>] did not use probabilities to represent motion but simply the optimal estimate of speed using an empirical prior. One consequence is that, as in the motion extrapolation model of Nijhawan [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>], such models do not predict the lack of effect for flash terminated cycle. In contrast, the dMBP presented herein implements a velocity-dependent position extrapolation based on a probabilistic representation, which is flexible enough to cease prediction of the trajectory after the motion’s stop.</p>
<p>As argued by Nijhawan [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>], the motion extrapolation model is a powerful hypothesis for the estimation of the motion of smoothly moving objects. However, as soon as a significant transient input modifies the stimulus, other supplementary mechanisms must be postulated to modulate the extrapolation computation. In the dMBP model, the internal model of visual motion progressively integrates confidence about the trajectory. We have shown previously that this mechanism may be sufficient to fill a short blank along the trajectory [<xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. Still, even in this “tracking state” [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>], the dynamical system is sensitive enough to be modulated by changes of the stimulus’ state, such as a sudden stop or a motion reversal. Knowing the neural delay, this stop will correct the path of the trajectory over this period in order to update the actual position of the object at the present time. A strong improvement over other motion extrapolation models is that the dMBP model does not have to postulate any other specific mechanism such as the resetting mechanism in the postdiction hypothesis. This correction is entirely handled within the motion-based predictive mechanism by the probabilistic computations. We thus provide a new computational evidence that motion extrapolation is a successful explanation for the FLE when separating the smooth prediction of the trajectory which is based on motion coherency (i.e. <italic>p</italic>(<italic>z</italic><sub><italic>t</italic>−<italic>τ</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>)) from its projection at the present time (i.e., <italic>p</italic>(<italic>z</italic><sub><italic>t</italic></sub>|<italic>I</italic><sub>0:<italic>t</italic>−<italic>τ</italic></sub>)). Therefore, the inferred trajectory does not necessarily need to be smooth as it can be corrected with the hindsight corresponding to the known delay. In summary, our new theoretical framework of the motion extrapolation hypothesis can reproduce the experimental data of the main variants of the FLE, a clear advantage over all other previous models. Overall, we show that an internal representation of object motion can provide a substrate for the coherency of its perceived motion despite the existing neural delays as well as a transient interruption in the sensory inflow [<xref ref-type="bibr" rid="pcbi.1005068.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref017">17</xref>]. It can thus provide a more reliable interpretation of the visual input. Herein, we have investigated the functional advantages of using both position and velocity information in building this internal model.</p>
</sec>
<sec id="sec019">
<title>Comparison with other neuromimetic models for FLE</title>
<p>How does our theoretical work relate to previous modeling work using neuromimetic networks? The neural field model of Erlhagen [<xref ref-type="bibr" rid="pcbi.1005068.ref058">58</xref>] is the most relevant study demonstrating that the emergence of a spatial lead in the FLE can result from the interplay between an internal model and a feedforward flow of stimulus-induced neural activity (but see also [<xref ref-type="bibr" rid="pcbi.1005068.ref011">11</xref>]). Their network was made of excitatory and inhibitory populations of position coding cells. Motion extrapolation of the trajectory emerges from both lateral interactions and network’s dynamics. This model showed that the priming of a position field is caused by the accumulation of sub-threshold activities of excitatory populations. Our model also highlights the role of the internal model of trajectory, where the internal model was based on the accumulation of motion information. The main difference between the dMBP and Erlhagen’s models is the use of velocity information and not only position coding. Still, both models stress the critical role of sub-threshold neural activities in the emergence of motion anticipation and extrapolation. In Erlhagen’s model, this is achieved by finely setting some parameters of the neural field. On the contrary, motion anticipation and extrapolation both emerge in the dMBP model from the probabilistic accumulation of motion-based position estimation along the motion trajectory.</p>
<p>Only a few other neural network models have directly addressed both delay compensation, motion extrapolation and FLE. For instance, the model of Baldo and Caticha [<xref ref-type="bibr" rid="pcbi.1005068.ref059">59</xref>] investigated how motion extrapolation and FLE may arise from a simple feed-forward network of leaky integrate and fire neurons. Other neural network models have addressed the question of neural delays and motion extrapolation at the single neuron level [<xref ref-type="bibr" rid="pcbi.1005068.ref060">60</xref>, <xref ref-type="bibr" rid="pcbi.1005068.ref061">61</xref>]. In these models, neurons are sensitive to the rate of change in the input and, via extrapolative activations they can estimate the state of external world at time <italic>t</italic> + <italic>τ</italic> instead of time <italic>t</italic>. On one hand, facilitatory activity is derived from the present and past activity of network and on the other hand, synaptic efficacy implements a smoothness constraint in the spiking activity which implements motion coherency. Therefore, spiking activity is extrapolated in the direction of change via a spike-time dependent learning rule along with facilitated synapses. However, these models have investigated spatial priming of neurons via lateral and facilitatory connections, ignoring the facilitatory effect that may arise from velocity coding.</p>
<p>Last, the dMBP model is partly consistent with the theoretical framework underpinning the postdiction model of FLE [<xref ref-type="bibr" rid="pcbi.1005068.ref027">27</xref>]. Both models infer variables using a state space model from a dynamical model of the moving stimulus. Prediction and postdiction mechanisms can be related to two essential components of dynamical systems in engineering: filtering and smoothing, respectively. The former has access to the immediate past of the signal to estimate the current state and the later model estimates the current state based on the immediate future. The main difference between the two models is that we use a filtering approach while the formulation proposed by Rao et al. [<xref ref-type="bibr" rid="pcbi.1005068.ref045">45</xref>] rather adds a smoothing component. As we have illustrated in the motion reversal experiment, we can also easily integrate such a smoothing but we have shown that this additional component is not necessary to explain other aspects of the FLE. As such, both models can reproduce the Fröhlich effect as a mis-estimation of earliest part of the trajectory, but the postdiction model interprets that the visual system attributes a position to a visual event only when it accumulated enough sensory evidence within the sensory integration time window. However our simulations suggested the important role of velocity information in this compensation, while the postdiction theory would propose that the position of stimulus is always pushed forward based on trajectory information received in a short time interval after time <italic>t</italic>. Lastly, contrary to the dMBP model, the postdiction model fails to account that in the standard FLE, no velocity increment for moving stimulus has been reported psychophysically [<xref ref-type="bibr" rid="pcbi.1005068.ref028">28</xref>]. In brief, while having similar mathematical formulations, the postdiction and dMBP models make different predictions, in particular regarding the earliest part of the motion trajectory. These predictions could be tested psychophysically in future work.</p>
</sec>
<sec id="sec020">
<title>Parodiction: An unified model for motion extrapolation</title>
<p>Our computational study suggests that the psychophysical evidences for the different variants of the FLE are the signatures of a fundamental neural mechanism that attempts to represent as best as possible the available information at the veridical physical time. The central nervous system is a complex dynamical, distributed machinery for which timing is essential. However, there is no evidence for the existence of a central clock as used in modern computers. Instead, neural computations are thought to be based on an <italic>asynchronous</italic> processing machinery. Even worse, some of these information bits are retarded by a range of inevitable transmission and computing delays. We suggest that an explicit neural representation of variables’s trajectories could compensate for these delays in order to represent each physical input at its present, physical time. Knowing these delays, motion extrapolation pushes the estimated position forward using the trajectory’s information. This paper thus proposes that the visual system exhibits the trace of an universal neural signature of a predictive processes compensating for neural delays. As such, in contrast to prediction and postdiction, a better term to explain this neural signature is <italic>parodiction</italic>, from the ancient Greek <italic>παρóν</italic>, the present time.</p>
<p>In the dMBP model, the dynamics for position coding is based on optimizing the probabilistic accumulation of information along the trajectory such as to be the most consistent at the present time. The dMBP model builds motion estimations at time <italic>t</italic> based on sensory information from the past (at time <italic>t</italic> − <italic>τ</italic>) and thus explains how neural delays may be compensated in visual processing. As a consequence, our model should be considered as an effort in understanding why phenomena such as the FLE should emerge. An utterly important question remains as to <italic>how</italic> this is achieved. Such attempts were advanced in several studies using a single paradigm for the different variants of the FLE [<xref ref-type="bibr" rid="pcbi.1005068.ref011">11</xref>]. Further modeling accounts were proposed to show that such a function could be implemented using asymmetric traveling waves [<xref ref-type="bibr" rid="pcbi.1005068.ref062">62</xref>] (see [<xref ref-type="bibr" rid="pcbi.1005068.ref015">15</xref>] for a more formal account). Our model offers to bridge and unify these different theories beyond the existing debate between proponents of differential latency and motion extrapolation. In particular, we propose an architecture which is parameterized by an anisotropic pattern of connectivity (see <xref ref-type="fig" rid="pcbi.1005068.g002">Fig 2-C</xref>). Key in that endeavor is a more precise knowledge as to how neural activity can dynamically code or decode a probabilistic representation of motion.</p>
<p>More generally, our new parodiction theory anchors any neural representation to the actual present time. Indeed, when considering any neurophysiological recording it is often assumed that the exact timing of each event, such as a spike, is known by the corresponding neural system relative to an absolute clock (for instance, that of the experimenter). However, the situation is different when overturning the problem relative to each individual neuron: For a neuron, the absolute time is unknown and only some relative timing of other neural events (their origin being sensory, motor or associative) may be known from previous experience. Also, the neuron has no access to past information and can only use traces of past neural activity at the present time. We claim that this problem is a generic problem in neuroscience as it raises the problem of the neural representation in time [<xref ref-type="bibr" rid="pcbi.1005068.ref008">8</xref>]. To conclude, we have proposed a theory, parodiction, which accounts for the FLE, but whose predictions remain to be validated in neurophysiology.</p>
</sec>
</sec>
</body>
<back>
<ack>
<p>LUP would like to thank Rick Adams and Karl Friston for fruitful discussions and the Wellcome Trust for NeuroImaging for supporting this collaboration.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005068.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lisberger</surname> <given-names>SG</given-names></name>. <article-title>Visual guidance of smooth-pursuit eye movements: sensation, action, and what happens in between</article-title>. <source>Neuron</source>. <year>2010</year> <month>May</month>;<volume>66</volume>(<issue>4</issue>):<fpage>477</fpage>–<lpage>91</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.03.027" xlink:type="simple">http://dx.doi.org/10.1016/j.neuron.2010.03.027</ext-link>. <object-id pub-id-type="pmid">20510853</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Masson</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>. <article-title>The behavioral receptive field underlying motion integration for primate tracking eye movements</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>. <year>2012</year> <month>Jan</month>;<volume>36</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>25</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neubiorev.2011.03.009" xlink:type="simple">http://dx.doi.org/10.1016/j.neubiorev.2011.03.009</ext-link>. <object-id pub-id-type="pmid">21421006</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref003">
<label>3</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Montagnini</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>, <name name-style="western"><surname>Masson</surname> <given-names>GS</given-names></name>. 27. In: <name name-style="western"><surname>Keil</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cristóbal</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>, editors. <source>Visual motion processing and human tracking behavior</source>. <publisher-name>Wiley</publisher-name>, <publisher-loc>New-York</publisher-loc>; <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/9783527680863.ch12" xlink:type="simple">10.1002/9783527680863.ch12</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>. <article-title>Motion extrapolation in catching</article-title>. <source>Nature</source>. <year>1994</year> <month>Jul</month>;<volume>370</volume> (<issue>6487</issue>). Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/370256b0" xlink:type="simple">http://dx.doi.org/10.1038/370256b0</ext-link>. <object-id pub-id-type="pmid">8035873</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Inui</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kakigi</surname> <given-names>R</given-names></name>. <article-title>Temporal Analysis of the Flow From V1 to the Extrastriate Cortex in Humans</article-title>. <source>Journal of Neurophysiology</source>. <year>2006</year>;<volume>96</volume>(<issue>2</issue>):<fpage>775</fpage>–<lpage>784</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00103.2006" xlink:type="simple">10.1152/jn.00103.2006</ext-link></comment> <object-id pub-id-type="pmid">16835365</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Baldo</surname> <given-names>MVC</given-names></name>, <name name-style="western"><surname>Ranvaud</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Morya</surname> <given-names>E</given-names></name>. <article-title>Flag errors in soccer games: the flash-lag effect brought to real life</article-title>. <source>Perception</source>. <year>2002</year>;<volume>31</volume>(<issue>10</issue>):<fpage>1205</fpage>–<lpage>1210</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1068/p3422" xlink:type="simple">http://dx.doi.org/10.1068/p3422</ext-link>. <object-id pub-id-type="pmid">12430947</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Franklin</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>D</given-names></name>. <article-title>Computational mechanisms of sensorimotor control</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>72</volume>:<fpage>425</fpage>–<lpage>442</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.10.006" xlink:type="simple">10.1016/j.neuron.2011.10.006</ext-link></comment> <object-id pub-id-type="pmid">22078503</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>. <article-title>Active Inference, eye movements and oculomotor delays</article-title>. <source>Biological Cybernetics</source>. <year>2014</year>;. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-014-0620-8" xlink:type="simple">10.1007/s00422-014-0620-8</ext-link></comment> <object-id pub-id-type="pmid">25128318</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref009">
<label>9</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Khurana</surname> <given-names>B</given-names></name>, editors. <source>Space and Time in Perception and Action</source>. <publisher-name>Cambridge Univ Press</publisher-name>; <year>2010</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/CBO9780511750540" xlink:type="simple">10.1017/CBO9780511750540</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>MacKay</surname> <given-names>DM</given-names></name>. <article-title>Perceptual Stability of a Stroboscopically Lit Visual Field containing Self-Luminous Objects</article-title>. <source>Nature</source>. <year>1958</year> <month>Feb</month>;<volume>181</volume>(<issue>4607</issue>):<fpage>507</fpage>–<lpage>508</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/181507a0" xlink:type="simple">http://dx.doi.org/10.1038/181507a0</ext-link>. <object-id pub-id-type="pmid">13517199</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Müsseler</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Stork</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kerzel</surname> <given-names>D</given-names></name>. <article-title>Comparing mislocalizations with moving stimuli: The Fröhlich effect, the flash-lag, and representational momentum</article-title>. <source>Visual Cognition</source>. <year>2002</year> <month>feb</month>;<volume>9</volume>(<issue>1–2</issue>):<fpage>120</fpage>–<lpage>138</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.tandfonline.com/doi/abs/10.1080/13506280143000359" xlink:type="simple">http://www.tandfonline.com/doi/abs/10.1080/13506280143000359</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eagleman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>T</given-names></name>. <article-title>Motion signals bias localization judgments: a unified explanation for the flash-lag, flash-drag, flash-jump, and Frohlich illusions</article-title>. <source>Journal of vision</source>. <year>2007</year>;<volume>7</volume>(<issue>4</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/7.4.3" xlink:type="simple">10.1167/7.4.3</ext-link></comment> <object-id pub-id-type="pmid">17461687</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref013">
<label>13</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Jancke</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Erlhagen</surname> <given-names>W</given-names></name>. <chapter-title>Bridging the gap: a model of common neural mechanisms underlying the Fröhlich effect, the flash-lag effect, and the representational momentum effect</chapter-title>. In: <name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Khurana</surname> <given-names>B</given-names></name>, editors. <source>Space and Time in Perception and Action</source>. <publisher-name>Cambridge Univ Press</publisher-name>; <year>2010</year>. p. <fpage>422</fpage>–<lpage>440</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/CBO9780511750540.025" xlink:type="simple">10.1017/CBO9780511750540.025</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berry</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Brivanlou</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>. <article-title>Anticipation of moving stimuli by the retina</article-title>. <source>Nature</source>. <year>1999</year>;<volume>398</volume>(<issue>6725</issue>):<fpage>334</fpage>–<lpage>338</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/18678" xlink:type="simple">10.1038/18678</ext-link></comment> <object-id pub-id-type="pmid">10192333</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jancke</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Erlhagen</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Schöner</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Dinse</surname> <given-names>H</given-names></name>. <article-title>Shorter latencies for motion trajectories than for flashes in population responses of cat primary visual cortex</article-title>. <source>The Journal of Physiology</source>. <year>2004</year>;<volume>556</volume>(<issue>3</issue>):<fpage>971</fpage>–<lpage>982</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1113/jphysiol.2003.058941" xlink:type="simple">10.1113/jphysiol.2003.058941</ext-link></comment> <object-id pub-id-type="pmid">14978201</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>, <name name-style="western"><surname>Masson</surname> <given-names>GS</given-names></name>. <article-title>Motion-Based Prediction Is Sufficient to Solve the Aperture Problem</article-title>. <source>Neural Computation</source>. <year>2012</year> <month>Oct</month>;<volume>24</volume>(<issue>10</issue>):<fpage>2726</fpage>–<lpage>2750</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00332" xlink:type="simple">http://dx.doi.org/10.1162/NECO_a_00332</ext-link>. <object-id pub-id-type="pmid">22734489</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Khoei</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Masson</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Perrinet</surname> <given-names>L</given-names></name>. <article-title>Motion-based prediction explains the role of tracking in motion extrapolation</article-title>. <source>Journal of Physiology-Paris</source>. <year>2013</year>;<volume>107</volume>(<issue>5</issue>):<fpage>409</fpage>–<lpage>420</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jphysparis.2013.08.001" xlink:type="simple">10.1016/j.jphysparis.2013.08.001</ext-link></comment> <object-id pub-id-type="pmid">24036184</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Metzger</surname> <given-names>W</given-names></name>. <article-title>Versuch einer gemeinsamen Theorie der Phänomene Fröhlichs und Hazelhoffs und Kritik ihrer Verfahren zur Messung der Empfindungszeit</article-title>. <source>Psychologische Forschung</source>. <year>1932</year>;<volume>16</volume>:<fpage>176</fpage>–<lpage>200</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Subramaniyan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ecker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Berens</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Tolias</surname> <given-names>AS</given-names></name>. <article-title>Macaque monkeys perceive the flash lag illusion</article-title>. <source>PloS one</source>. <year>2013</year> <month>jan</month>;<volume>8</volume>(<issue>3</issue>):<fpage>e58788</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3602542&amp;tool=pmcentrez&amp;rendertype=abstract" xlink:type="simple">http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3602542&amp;tool=pmcentrez&amp;rendertype=abstract</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0058788" xlink:type="simple">10.1371/journal.pone.0058788</ext-link></comment> <object-id pub-id-type="pmid">23527024</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Watanabe</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Beena</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Shimojo</surname> <given-names>S</given-names></name>. <article-title>Compensation of neural delays in visual-motor behaviour: No evidence for shorter afferent delays for visual motion</article-title>. <source>Visual cognition</source>. <year>2004</year>;<volume>11</volume>(<issue>2–3</issue>):<fpage>275</fpage>–<lpage>298</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://web.ebscohost.com.gate1.inist.fr/ehost/detail?vid=3&amp;#38;sid=c40531b5-4a8d-48e4-8916-00de4c522855%40sessionmgr198&amp;#38;hid=108&amp;#38;bdata=Jmxhbmc9ZnImc2l0ZT1laG9zdC1saXZl#db=pbh&amp;#38;AN=12252348" xlink:type="simple">http://web.ebscohost.com.gate1.inist.fr/ehost/detail?vid=3&amp;#38;sid=c40531b5-4a8d-48e4-8916-00de4c522855%40sessionmgr198&amp;#38;hid=108&amp;#38;bdata=Jmxhbmc9ZnImc2l0ZT1laG9zdC1saXZl#db=pbh&amp;#38;AN=12252348</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/13506280344000347" xlink:type="simple">10.1080/13506280344000347</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wu</surname> <given-names>S</given-names></name>. <article-title>Compensating time delays with neural predictions: are predictions sensory or motor?</article-title> <source>Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences</source>. <year>2009</year>;<volume>367</volume>(<issue>1891</issue>):<fpage>1063</fpage>–<lpage>1078</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsta.2008.0270" xlink:type="simple">10.1098/rsta.2008.0270</ext-link></comment> <object-id pub-id-type="pmid">19218151</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref022">
<label>22</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Maus</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Khurana</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>. <chapter-title>Space and Time in Perception and Action: History and theory of flash-lag: past, present, and future</chapter-title>. In: <source>History and theory of flash-lag: past, present, and future</source>. <publisher-name>Cambridge University Press</publisher-name> <publisher-loc>New York, NY</publisher-loc>; <year>2010</year>. p. <fpage>477</fpage>–<lpage>499</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Murakami</surname> <given-names>I</given-names></name>. <article-title>Latency difference, not spatial extrapolation</article-title>. <source>Nat Neurosci</source>. <year>1998</year> <month>Dec</month>;<volume>1</volume>(<issue>8</issue>):<fpage>656</fpage>–<lpage>657</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/3659" xlink:type="simple">http://dx.doi.org/10.1038/3659</ext-link>. <object-id pub-id-type="pmid">10196580</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Murakami</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Cavanagh</surname> <given-names>P</given-names></name>. <article-title>Illusory spatial offset of a flash relative to a moving stimulus is caused by differential latencies for moving and flashed stimuli</article-title>. <source>Vision Research</source>. <year>2000</year> <month>Jan</month>;<volume>40</volume>(<issue>2</issue>):<fpage>137</fpage>–<lpage>149</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/s0042-6989(99)00166-2" xlink:type="simple">http://dx.doi.org/10.1016/s0042-6989(99)00166-2</ext-link>. <object-id pub-id-type="pmid">10793892</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Krekelberg</surname></name>, <name name-style="western"><surname>Lappe</surname></name>, <name name-style="western"><surname>Whitney</surname></name>, <name name-style="western"><surname>Cavanagh</surname></name>, <name name-style="western"><surname>Eagleman</surname></name>, <name name-style="western"><surname>Sejnowski</surname></name>. <article-title>The Position of Moving Objects</article-title>. <source>Science</source>. <year>2000</year> <month>Aug</month>;<volume>289</volume>(<issue>5482</issue>):<fpage>1107</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.289.5482.1107a" xlink:type="simple">http://dx.doi.org/10.1126/science.289.5482.1107a</ext-link>. <object-id pub-id-type="pmid">10970214</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schlag</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cai</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Dorfman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mohempour</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schlag-Rey</surname> <given-names>M</given-names></name>. <article-title>Neuroscience: Extrapolating movement without retinal motion</article-title>. <source>Nature</source>. <year>2000</year> <month>Jan</month>;<volume>403</volume>(<issue>6765</issue>):<fpage>38</fpage>–<lpage>39</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/47402" xlink:type="simple">http://dx.doi.org/10.1038/47402</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eagleman</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>Motion Integration and Postdiction in Visual Awareness</article-title>. <source>Science</source>. <year>2000</year> <month>Mar</month>;<volume>287</volume>(<issue>5460</issue>):<fpage>2036</fpage>–<lpage>2038</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.287.5460.2036" xlink:type="simple">http://dx.doi.org/10.1126/science.287.5460.2036</ext-link>. <object-id pub-id-type="pmid">10720334</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>. <article-title>Neural delays, visual motion and the flash-lag effect</article-title>. <source>Trends in cognitive sciences</source>. <year>2002</year> <month>Sep</month>;<volume>6</volume>(<issue>9</issue>). Available from: <ext-link ext-link-type="uri" xlink:href="http://view.ncbi.nlm.nih.gov/pubmed/12200181" xlink:type="simple">http://view.ncbi.nlm.nih.gov/pubmed/12200181</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1364-6613(02)01963-0" xlink:type="simple">10.1016/S1364-6613(02)01963-0</ext-link></comment> <object-id pub-id-type="pmid">12200181</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hubbard</surname> <given-names>TL</given-names></name>. <article-title>The flash-lag effect and related mislocalizations: findings, properties, and theories</article-title>. <source>Psychol Bull</source>. <year>2014</year> <month>Jan</month>;<volume>140</volume>(<issue>1</issue>):<fpage>308</fpage>–<lpage>338</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0032899" xlink:type="simple">10.1037/a0032899</ext-link></comment> <object-id pub-id-type="pmid">23796268</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maus</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>. <article-title>Forward displacements of fading objects in motion: the role of transient signals in perceiving position</article-title>. <source>Vision research</source>. <year>2006</year>;<volume>46</volume>(<issue>26</issue>):<fpage>4375</fpage>–<lpage>4381</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2006.08.028" xlink:type="simple">10.1016/j.visres.2006.08.028</ext-link></comment> <object-id pub-id-type="pmid">17045627</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>. <article-title>Predictive perceptions, predictive actions, and beyond</article-title>. <source>Behavioral and Brain Sciences</source>. <year>2008</year>;<volume>31</volume>(<issue>02</issue>):<fpage>222</fpage>–<lpage>239</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0140525X08004068" xlink:type="simple">10.1017/S0140525X08004068</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maus</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>. <article-title>Going, going, gone: localizing abrupt offsets of moving objects</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>. <year>2009</year>;<volume>35</volume>(<issue>3</issue>):<fpage>611</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0012317" xlink:type="simple">10.1037/a0012317</ext-link></comment> <object-id pub-id-type="pmid">19485681</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Purushothaman</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Patel</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Bedell</surname> <given-names>HE</given-names></name>, <name name-style="western"><surname>Ogmen</surname> <given-names>H</given-names></name>. <article-title>Moving ahead through differential visual latency</article-title>. <source>Nature</source>. <year>1998</year> <month>Dec</month>;<volume>396</volume>(<issue>6710</issue>):<fpage>424</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/24766" xlink:type="simple">http://dx.doi.org/10.1038/24766</ext-link>. <object-id pub-id-type="pmid">9853748</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Krekelberg</surname></name>. <article-title>The persistence of position</article-title>. <source>Vision Research</source>. <year>2001</year> <month>Feb</month>;<volume>41</volume>(<issue>4</issue>):<fpage>529</fpage>–<lpage>539</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/s0042-6989(00)00281-9" xlink:type="simple">http://dx.doi.org/10.1016/s0042-6989(00)00281-9</ext-link>. <object-id pub-id-type="pmid">11166055</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Krekelberg</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Lappe</surname> <given-names>M</given-names></name>. <article-title>A model of the perceived relative positions of moving objects based upon a slow averaging process</article-title>. <source>Vision Research</source>. <year>2000</year> <month>Jan</month>;<volume>40</volume>(<issue>2</issue>):<fpage>201</fpage>–<lpage>215</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/s0042-6989(99)00168-6" xlink:type="simple">http://dx.doi.org/10.1016/s0042-6989(99)00168-6</ext-link>. <object-id pub-id-type="pmid">10793897</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wojtach</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Sung</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Truong</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Purves</surname> <given-names>D</given-names></name>. <article-title>An empirical explanation of the flash-lag effect</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2008</year>;<volume>105</volume>(<issue>42</issue>):<fpage>16338</fpage>–<lpage>16343</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0808916105" xlink:type="simple">10.1073/pnas.0808916105</ext-link></comment> <object-id pub-id-type="pmid">18852459</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Changizi</surname> <given-names>M</given-names></name>. <article-title>‘Perceiving the present’ as a framework for ecological explanations of the misperception of projected angle and angular size</article-title>. <source>Perception</source>. <year>2001</year>;<volume>30</volume>(<issue>2</issue>):<fpage>195</fpage>–<lpage>208</lpage>. <object-id pub-id-type="pmid">11296501</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kanai</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Sheth</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Shimojo</surname> <given-names>S</given-names></name>. <article-title>Stopping the motion and sleuthing the flash-lag effect: spatial uncertainty is the key to perceptual mislocalization</article-title>. <source>Vision research</source>. <year>2004</year> <month>Oct</month>;<volume>44</volume>(<issue>22</issue>):<fpage>2605</fpage>–<lpage>2619</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2003.10.028" xlink:type="simple">http://dx.doi.org/10.1016/j.visres.2003.10.028</ext-link>. <object-id pub-id-type="pmid">15358076</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Adelson</surname> <given-names>EH</given-names></name>, <name name-style="western"><surname>Bergen</surname> <given-names>JR</given-names></name>. <article-title>Spatiotemporal energy models for the perception of motion</article-title>. <source>Journal of Optical Society of America, A</source>. <year>1985</year> <month>Feb</month>;<volume>2</volume>(<issue>2</issue>):<fpage>284</fpage>–<lpage>99</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/josaa.2.000284" xlink:type="simple">http://dx.doi.org/10.1364/josaa.2.000284</ext-link>. <object-id pub-id-type="pmid">3973762</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref040">
<label>40</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Weiss</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Fleet</surname> <given-names>DJ</given-names></name>. <chapter-title>Velocity likelihoods in biological and machine vision</chapter-title>. In: <source>In Probabilistic Models of the Brain: Perception and Neural Function</source>; <year>2001</year>. p. <fpage>81</fpage>–<lpage>100</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.1021" xlink:type="simple">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.1021</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>, <name name-style="western"><surname>Masson</surname> <given-names>GS</given-names></name>. <article-title>Modeling spatial integration in the ocular following response using a probabilistic framework</article-title>. <source>Journal of Physiology-Paris</source>. <year>2007</year> <month>Jan</month>;<volume>101</volume>(<issue>1–3</issue>):<fpage>46</fpage>–<lpage>55</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jphysparis.2007.10.011" xlink:type="simple">http://dx.doi.org/10.1016/j.jphysparis.2007.10.011</ext-link>. <object-id pub-id-type="pmid">18042358</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Burgi</surname> <given-names>PY</given-names></name>, <name name-style="western"><surname>Yuille</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Grzywacz</surname> <given-names>N</given-names></name>. <article-title>Probabilistic Motion Estimation Based on Temporal Coherence</article-title>. <source>Neural Comput</source>. <year>2000</year> <month>Aug</month>;<volume>12</volume>(<issue>8</issue>):<fpage>1839</fpage>–<lpage>67</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://portal.acm.org/citation.cfm?id=1121336" xlink:type="simple">http://portal.acm.org/citation.cfm?id=1121336</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976600300015169" xlink:type="simple">10.1162/089976600300015169</ext-link></comment> <object-id pub-id-type="pmid">10953241</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>. <article-title>Generalised Filtering</article-title>. <source>Mathematical Problems in Engineering</source>. <year>2010</year>;<volume>2010</volume>:<fpage>1</fpage>–<lpage>35</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1155/2010/621670" xlink:type="simple">http://dx.doi.org/10.1155/2010/621670</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref044">
<label>44</label>
<mixed-citation publication-type="other" xlink:type="simple">Kaplan BA, Khoei MA, Lansner A, Perrinet LU. Signature of an anticipatory response in area V1 as modeled by a probabilistic model and a spiking neural network. In: Proceedings of the 2014 International Joint Conference on Neural Networks; Beijing, China; 2014.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rao</surname> <given-names>RPN</given-names></name>, <name name-style="western"><surname>Eagleman</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>Optimal Smoothing in Visual Motion Perception</article-title>. <source>Neural Computation</source>. <year>2001</year> <month>Jun</month>;<volume>13</volume>(<issue>6</issue>):<fpage>1243</fpage>–<lpage>1253</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://invibe.net/cgi-bin/biblio_database_access.cgi/Show?_id=aeb1" xlink:type="simple">http://invibe.net/cgi-bin/biblio_database_access.cgi/Show?_id=aeb1</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/08997660152002843" xlink:type="simple">10.1162/08997660152002843</ext-link></comment> <object-id pub-id-type="pmid">11387045</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref046">
<label>46</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Vacher</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Meso</surname> <given-names>AI</given-names></name>, <name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>, <name name-style="western"><surname>Peyré</surname> <given-names>G</given-names></name>. <chapter-title>Biologically Inspired Dynamic Textures for Probing Motion Perception</chapter-title>. In: <name name-style="western"><surname>Cortes</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lawrence</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Sugiyama</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Garnett</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Garnett</surname> <given-names>R</given-names></name>, editors. <source>Advances in Neural Information Processing Systems 28</source>. <publisher-name>Curran Associates, Inc</publisher-name>.; <year>2015</year>. p. <fpage>1909</fpage>–<lpage>1917</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1511.02705" xlink:type="simple">http://arxiv.org/abs/1511.02705</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cantor</surname> <given-names>CRL</given-names></name>, <name name-style="western"><surname>Schor</surname> <given-names>CM</given-names></name>. <article-title>Stimulus dependence of the flash-lag effect</article-title>. <source>Vision Research</source>. <year>2007</year>;<volume>47</volume>(<issue>22</issue>):<fpage>2841</fpage>–<lpage>2854</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2007.06.023" xlink:type="simple">10.1016/j.visres.2007.06.023</ext-link></comment> <object-id pub-id-type="pmid">17868767</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Simoncini</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>, <name name-style="western"><surname>Montagnini</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mamassian</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Masson</surname> <given-names>GS</given-names></name>. <article-title>More is not always better: adaptive gain control explains dissociation between perception and action</article-title>. <source>Nature Neurosci</source>. <year>2012</year> <month>Nov</month>;<volume>15</volume>(<issue>11</issue>):<fpage>1596</fpage>–<lpage>1603</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3229" xlink:type="simple">http://dx.doi.org/10.1038/nn.3229</ext-link>. <object-id pub-id-type="pmid">23023292</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Orban</surname> <given-names>GA</given-names></name>, <name name-style="western"><surname>deÂ Wolf</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Maes</surname> <given-names>H</given-names></name>. <article-title>Factors influencing velocity coding in the human visual system</article-title>. <source>Vision Research</source>. <year>1984</year> <month>jan</month>;<volume>24</volume>(<issue>1</issue>):<fpage>33</fpage>–<lpage>39</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://linkinghub.elsevier.com/retrieve/pii/004269898490141X" xlink:type="simple">http://linkinghub.elsevier.com/retrieve/pii/004269898490141X</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0042-6989(84)90141-X" xlink:type="simple">10.1016/0042-6989(84)90141-X</ext-link></comment> <object-id pub-id-type="pmid">6695505</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Orban</surname> <given-names>Ga</given-names></name>, <name name-style="western"><surname>Van Calenbergh</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>De Bruyn</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Maes</surname> <given-names>H</given-names></name>. <article-title>Velocity discrimination in central and peripheral visual field</article-title>. <source>Journal of the Optical Society of America A</source>. <year>1985</year> <month>nov</month>;<volume>2</volume>(<issue>11</issue>):<fpage>1836</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.osapublishing.org/abstract.cfm?URI=josaa-2-11-1836" xlink:type="simple">https://www.osapublishing.org/abstract.cfm?URI=josaa-2-11-1836</ext-link>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1364/JOSAA.2.001836" xlink:type="simple">10.1364/JOSAA.2.001836</ext-link></comment> <object-id pub-id-type="pmid">4067694</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fu</surname> <given-names>YX</given-names></name>, <name name-style="western"><surname>Shen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dan</surname> <given-names>Y</given-names></name>. <article-title>Motion-Induced Perceptual Extrapolation of Blurred Visual Targets</article-title>. <source>The Journal of Neuroscience</source>. <year>2001</year> <month>Oct</month>;<volume>21</volume>(<issue>20</issue>):<fpage>RC172</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://view.ncbi.nlm.nih.gov/pubmed/11588202" xlink:type="simple">http://view.ncbi.nlm.nih.gov/pubmed/11588202</ext-link>. <object-id pub-id-type="pmid">11588202</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Watamaniuk</surname> <given-names>SNJ</given-names></name>, <name name-style="western"><surname>McKee</surname> <given-names>SP</given-names></name>, <name name-style="western"><surname>Grzywacz</surname> <given-names>N</given-names></name>. <article-title>Detecting a trajectory embedded in random-direction motion noise</article-title>. <source>Vision Research</source>. <year>1995</year> <month>Jan</month>;<volume>35</volume>(<issue>1</issue>). Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0042-6989(94)E0047-O" xlink:type="simple">http://dx.doi.org/10.1016/0042-6989(94)E0047-O</ext-link>. <object-id pub-id-type="pmid">7839611</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kaplan</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Lansner</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Masson</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Perrinet</surname> <given-names>LU</given-names></name>. <article-title>Anisotropic connectivity implements motion-based prediction in a spiking neural network</article-title>. <source>Frontiers in computational neuroscience</source>. <year>2013</year>;<volume>7</volume>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2013.00112" xlink:type="simple">http://dx.doi.org/10.3389/fncom.2013.00112</ext-link>. <object-id pub-id-type="pmid">24062680</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>. <article-title>The influence of visual motion on perceived position</article-title>. <source>Trends in cognitive sciences</source>. <year>2002</year>;<volume>6</volume>(<issue>5</issue>):<fpage>211</fpage>–<lpage>216</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S1364-6613(02)01887-9" xlink:type="simple">10.1016/S1364-6613(02)01887-9</ext-link></comment> <object-id pub-id-type="pmid">11983584</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maus</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Weigelt</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Muckli</surname> <given-names>L</given-names></name>. <article-title>Does Area V3A Predict Positions of Moving Objects?</article-title> <source>Frontiers in psychology</source>. <year>2010</year>;<volume>1</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fpsyg.2010.00186" xlink:type="simple">10.3389/fpsyg.2010.00186</ext-link></comment> <object-id pub-id-type="pmid">21897824</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maus</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Fischer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>. <article-title>Motion-Dependent Representation of Space in Area MT+</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>78</volume>(<issue>3</issue>):<fpage>554</fpage>–<lpage>562</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.03.010" xlink:type="simple">10.1016/j.neuron.2013.03.010</ext-link></comment> <object-id pub-id-type="pmid">23664618</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maus</surname> <given-names>GW</given-names></name>, <name name-style="western"><surname>Ward</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Nijhawan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>. <article-title>The perceived position of moving objects: transcranial magnetic stimulation of area MT+ reduces the flash-lag effect</article-title>. <source>Cerebral cortex (New York, NY: 1991)</source>. <year>2013</year>;<volume>23</volume>(<issue>1</issue>):<fpage>241</fpage>–<lpage>247</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhs021" xlink:type="simple">10.1093/cercor/bhs021</ext-link></comment> <object-id pub-id-type="pmid">22302116</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Erlhagen</surname> <given-names>W</given-names></name>. <article-title>Internal models for visual perception</article-title>. <source>Biological cybernetics</source>. <year>2003</year>;<volume>88</volume>(<issue>5</issue>):<fpage>409</fpage>–<lpage>417</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-002-0387-1" xlink:type="simple">10.1007/s00422-002-0387-1</ext-link></comment> <object-id pub-id-type="pmid">12750903</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Baldo</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Caticha</surname> <given-names>N</given-names></name>. <article-title>Computational neurobiology of the flash-lag effect</article-title>. <source>Vision research</source>. <year>2005</year>;<volume>45</volume>(<issue>20</issue>):<fpage>2620</fpage>–<lpage>2630</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2005.04.014" xlink:type="simple">10.1016/j.visres.2005.04.014</ext-link></comment> <object-id pub-id-type="pmid">15993457</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref060">
<label>60</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Lim</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Choe</surname> <given-names>Y</given-names></name>. <chapter-title>Compensating for neural transmission delay using extrapolatory neural activation in evolutionary neural networks</chapter-title>. In: <source>Neural Information Processing Letters and Reviews</source>; <year>2006</year>. p. <fpage>147</fpage>–<lpage>161</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.8178" xlink:type="simple">http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.90.8178</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1005068.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lim</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Choe</surname> <given-names>Y</given-names></name>. <article-title>Extrapolative delay compensation through facilitating synapses and its relation to the flash-lag effect</article-title>. <source>IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council</source>. <year>2008</year> <month>Oct</month>;<volume>19</volume>(<issue>10</issue>):<fpage>1678</fpage>–<lpage>1688</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/tnn.2008.2001002" xlink:type="simple">http://dx.doi.org/10.1109/tnn.2008.2001002</ext-link>. <object-id pub-id-type="pmid">18842473</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005068.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kirschfeld</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kammer</surname> <given-names>T</given-names></name>. <article-title>The Fröhlich effect: a consequence of the interaction of visual focal attention and metacontrast</article-title>. <source>Vision research</source>. <year>1999</year> <month>nov</month>;<volume>39</volume>(<issue>22</issue>):<fpage>3702</fpage>–<lpage>9</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/10746140" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/10746140</ext-link>. <object-id pub-id-type="pmid">10746140</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-00161</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005655</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Developmental biology</subject><subj-group><subject>Life cycles</subject><subj-group><subject>Larvae</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Developmental biology</subject><subj-group><subject>Life cycles</subject><subj-group><subject>Pupae</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Systems science</subject><subj-group><subject>Dynamical systems</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems science</subject><subj-group><subject>Dynamical systems</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Animals</subject><subj-group><subject>Invertebrates</subject><subj-group><subject>Arthropoda</subject><subj-group><subject>Insects</subject><subj-group><subject>Beetles</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Random variables</subject><subj-group><subject>Covariance</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Hybrid modeling and prediction of dynamical systems</article-title>
<alt-title alt-title-type="running-head">Hybrid modeling and prediction of dynamical systems</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5048-7705</contrib-id>
<name name-style="western">
<surname>Hamilton</surname> <given-names>Franz</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lloyd</surname> <given-names>Alun L.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Flores</surname> <given-names>Kevin B.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Department of Mathematics, North Carolina State University, Raleigh, North Carolina, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Center for Quantitative Sciences in Biomedicine, North Carolina State University, Raleigh, North Carolina, United States of America</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Biomathematics Graduate Program, North Carolina State University, Raleigh, North Carolina, United States of America</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Center for Research in Scientific Computation, North Carolina State University, Raleigh, North Carolina, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Saucerman</surname> <given-names>Jeffrey J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of Virginia, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">fwhamilt@ncsu.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>7</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>10</day>
<month>7</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>7</issue>
<elocation-id>e1005655</elocation-id>
<history>
<date date-type="received">
<day>27</day>
<month>1</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>6</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Hamilton et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005655"/>
<abstract>
<p>Scientific analysis often relies on the ability to make accurate predictions of a system’s dynamics. Mechanistic models, parameterized by a number of unknown parameters, are often used for this purpose. Accurate estimation of the model state and parameters prior to prediction is necessary, but may be complicated by issues such as noisy data and uncertainty in parameters and initial conditions. At the other end of the spectrum exist nonparametric methods, which rely solely on data to build their predictions. While these nonparametric methods do not require a model of the system, their performance is strongly influenced by the amount and noisiness of the data. In this article, we consider a hybrid approach to modeling and prediction which merges recent advancements in nonparametric analysis with standard parametric methods. The general idea is to replace a subset of a mechanistic model’s equations with their corresponding nonparametric representations, resulting in a hybrid modeling and prediction scheme. Overall, we find that this hybrid approach allows for more robust parameter estimation and improved short-term prediction in situations where there is a large uncertainty in model parameters. We demonstrate these advantages in the classical Lorenz-63 chaotic system and in networks of Hindmarsh-Rose neurons before application to experimentally collected structured population data.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The question of how best to predict the evolution of a dynamical system has received substantial interest in the scientific community. While traditional mechanistic modeling approaches have dominated, data-driven approaches which rely on data to build predictive models have gained increasing popularity. The reality is, both approaches have their drawbacks and limitations. In this article we ask the question of whether or not a hybrid approach to prediction, which combines characteristics of both mechanistic modeling and data-driven modeling, can offer improvements over the standalone methodologies. We analyze the performance of these methods in two model systems and then evaluate them on experimentally collected population data.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>RTG/DMS-1246991</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Lloyd</surname> <given-names>Alun L.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>DMS-1514929</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Flores</surname> <given-names>Kevin B.</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This research was partially supported by grants RTG/DMS-1246991 (ALL) and DMS-1514929 (KBF) from the National Science Foundation and grant P01-AI098670 (ALL) from the National Institutes of Health. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="2"/>
<page-count count="20"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-07-24</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Parametric modeling involves defining an underlying set of mechanistic equations which describe a system’s dynamics. These mechanistic models often contain a number of unknown parameters as well as an uncertain state, both of which need to be quantified prior to use of the model for prediction. The success of parametric prediction is tied closely to the ability to construct accurate estimates of the model parameters and state. This can be particularly challenging in high dimensional estimation problems as well as in chaotic systems [<xref ref-type="bibr" rid="pcbi.1005655.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref002">2</xref>]. Additionally, there is often a degree of model error, or a discrepancy between the structure of the model and that of the system, further complicating the estimation process and hindering prediction accuracy.</p>
<p>Despite these potential issues, mechanistic models are frequently utilized in data analysis. The question we aim to address is when is it advantageous to use them? Under suitable conditions where model error is relatively small and parameters can be reliably estimated, parametric predictions can provide a great deal of accuracy. However, as we will see in the subsequent examples, a large uncertainty in the initial parameter values often leads to inaccurate estimates resulting in poor model-based predictions.</p>
<p>An alternative approach to modeling and prediction abandons the use of any mechanistic equations, instead relying on predictive models built from data. These nonparametric methods have received considerable attention, in particular those methods based on Takens’ delay-coordinate method for attractor reconstruction [<xref ref-type="bibr" rid="pcbi.1005655.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1005655.ref017">17</xref>]. The success of nonparametric methods is strongly influenced by the amount of data available as well as the dimension of the dynamical system. If only a sparse amount of training data is available, the result is often inaccurate predictions due to the lack of suitable nearby neighbors in delay-coordinate space. Furthermore, as the dimension and complexity of the dynamical system increases, nonparametric prediction becomes significantly more difficult due to the necessary data requirements [<xref ref-type="bibr" rid="pcbi.1005655.ref017">17</xref>].</p>
<p>Several recent works have investigated the situation where only a portion of a mechanistic model is known [<xref ref-type="bibr" rid="pcbi.1005655.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref019">19</xref>]. Our motivation here though is to explore how best to use a full mechanistic model when it is available. We consider a hybrid methodology to modeling and prediction that combines the complementary features of both parametric and nonparametric methods. In our proposed hybrid method, a subset of a mechanistic model’s equations are replaced by nonparametric evolution. These nonparametrically advanced variables are then incorporated into the remaining mechanistic equations during the data fitting and prediction process. The result of this approach is a more robust estimation of model parameters as well as an improvement in short-term prediction accuracy when initial parameter uncertainty is large.</p>
<p>Our proposed hybrid method is in a sense related to the field of grey-box modeling and identification [<xref ref-type="bibr" rid="pcbi.1005655.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1005655.ref025">25</xref>]. This broad class of methods is referred to as “grey” since they exist somewhere between white-box/clear models (physical definitions and principles only) and black-box models (data-based only). For example, a grey method resulting from the combination of semi-physical and black-box modeling was proposed in [<xref ref-type="bibr" rid="pcbi.1005655.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref027">27</xref>], where a black-box artificial neural network was used to explain the error residuals from the physical portion of the model. Our hybrid method offers a novel take on this grey box philosophy, merging white and black-box modeling to obtain robust estimation of model parameters.</p>
<p>The utility of the hybrid method is demonstrated in several example systems. The assumption throughout is that noisy training data from a system are available as well as a mechanistic model that describes the underlying dynamics. However, several of the model parameters are unknown and the model state is uncertain due to the noisy measurements. The goal is to make accurate predictions of the system state up to some forecast horizon beyond the end of the training data. We compare the prediction accuracy of the standard parametric and nonparametric methodologies with the novel hybrid method presented here.</p>
<p>We begin our analysis by examining prediction in the classical Lorenz-63 system [<xref ref-type="bibr" rid="pcbi.1005655.ref028">28</xref>], which exhibits chaotic dynamics. Motivated by the success of the hybrid method in the Lorenz-63 system, we consider a more sophisticated example of predicting the spiking dynamics of a neuron in a network of Hindmarsh-Rose [<xref ref-type="bibr" rid="pcbi.1005655.ref029">29</xref>] cells. Finally, we examine the prediction problem in a well-known experimental dataset from beetle population dynamics [<xref ref-type="bibr" rid="pcbi.1005655.ref030">30</xref>].</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<p>The assumption throughout is that a set of noisy data is available over the time interval [<italic>t</italic>(0), <italic>t</italic>(<italic>T</italic>)]. This is referred to as the <italic>training data</italic> of the system. Using these training data, the question is how best to predict the system dynamics over the interval [<italic>t</italic>(<italic>T</italic> + 1), <italic>t</italic>(<italic>T</italic> + <italic>T</italic><sub><italic>F</italic></sub>)], known as the <italic>prediction interval</italic>. Standard parametric and nonparametric methods are presented before our discussion of the novel hybrid method which blends the two approaches.</p>
<sec id="sec003">
<title>Parametric modeling and prediction</title>
<p>When a full set of mechanistic equations is used for modeling and prediction, we refer to this as the parametric approach. Assume a general nonlinear system of the form
<disp-formula id="pcbi.1005655.e001"><alternatives><graphic id="pcbi.1005655.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">f</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">y</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="bold">h</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">p</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <bold>x</bold> = [<italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>n</italic></sub>]<sup><italic>T</italic></sup> is an <italic>n</italic>-dimensional vector of model state variables and <bold>p</bold> = [<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, …, <italic>p</italic><sub><italic>l</italic></sub>]<sup><italic>T</italic></sup> is an <italic>l</italic>-dimensional vector of model parameters which may be known from first principles, partially known or completely unknown. <bold>f</bold> represents our system dynamics which describe the evolution of the state <bold>x</bold> over time and <bold>h</bold> is an observation function which maps <bold>x</bold> to an <italic>m</italic>-dimensional vector of model observations, <bold>y</bold> = [<italic>y</italic><sub>1</sub>, <italic>y</italic><sub>2</sub>, …, <italic>y</italic><sub><italic>m</italic></sub>]<sup><italic>T</italic></sup>. To simplify the description of our analysis, we assume that the training data maps directly to some subset of <bold>x</bold>. <bold>w</bold>(<italic>k</italic>) and <bold>v</bold>(<italic>k</italic>) are assumed to be mean <bold>0</bold> Gaussian noise terms with covariances <bold>Q</bold> and <bold>R</bold> respectively. While discrete notation is used in <xref ref-type="disp-formula" rid="pcbi.1005655.e001">Eq 1</xref> for notational convenience, the evolution of <bold>x</bold> is often described by continuous-time systems. In this situation numerical solvers, such as Runge-Kutta or Adams-Moulton methods, are used to obtain solutions to the continuous-time system at discrete time points.</p>
<p>When the state of a system is uncertain due to noisy or incomplete observations, nonlinear Kalman filtering can be used for state estimation [<xref ref-type="bibr" rid="pcbi.1005655.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref031">31</xref>–<xref ref-type="bibr" rid="pcbi.1005655.ref043">43</xref>]. Here we choose the unscented Kalman filter (UKF), which approximates the propagation of the mean and covariance of a random variable through a nonlinear function using a deterministic ensemble selected through the unscented transformation [<xref ref-type="bibr" rid="pcbi.1005655.ref044">44</xref>–<xref ref-type="bibr" rid="pcbi.1005655.ref046">46</xref>]. We initialize the filter with state vector <bold>x</bold><sup>+</sup>(0) and covariance matrix <bold>P</bold><sup>+</sup>(0). At the <italic>k</italic>th step of the filter there is an estimate of the state <bold>x</bold><sup>+</sup>(<italic>k</italic> − 1) and the covariance matrix <bold>P</bold><sup>+</sup>(<italic>k</italic> − 1). In the UKF, the singular value decomposition is used to find the square root of the matrix <bold>P</bold><sup>+</sup>(<italic>k</italic> − 1), which is used to form an ensemble of 2<italic>n</italic> + 1 state vectors.</p>
<p>The model <bold>f</bold> is applied to the ensemble, advancing it forward one time step, and then observed with <bold>h</bold>. The weighted average of the resulting state ensemble gives the prior state estimate <bold>x</bold><sup><bold>−</bold></sup>(<italic>k</italic>) and the weighted average of the observed ensemble is the model-predicted observation <bold>y</bold><sup>−</sup>(<italic>k</italic>). Covariance matrices <bold>P</bold><sup><bold>−</bold></sup>(<italic>k</italic>) and <bold>P</bold><sup><bold>y</bold></sup>(<italic>k</italic>) of the resulting state and observed ensemble, and the cross-covariance matrix <bold>P</bold><sup><bold>xy</bold></sup>(<italic>k</italic>) between the state and observed ensembles, are formed and the equations
<disp-formula id="pcbi.1005655.e002"><alternatives><graphic id="pcbi.1005655.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="bold">K</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold">P</mml:mi> <mml:mtext mathvariant="bold">xy</mml:mtext></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="1pt"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">P</mml:mi> <mml:mi mathvariant="bold">y</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">P</mml:mi> <mml:mo>+</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold">P</mml:mi> <mml:mo>-</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">P</mml:mi> <mml:mrow><mml:mi>x</mml:mi> <mml:mi>y</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="1pt"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">P</mml:mi> <mml:mi>y</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mspace width="1pt"/><mml:msup><mml:mi mathvariant="bold">P</mml:mi> <mml:mrow><mml:mi>y</mml:mi> <mml:mi>x</mml:mi></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>+</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>-</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">K</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">y</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">y</mml:mi> <mml:mo>-</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
are used to update the state and covariance estimates with the observation <bold>y</bold>(<italic>k</italic>).</p>
<p>The UKF algorithm described above can be extended to include the <italic>joint estimation</italic> problem allowing for parameter estimation. In this framework, the parameters <bold>p</bold> are considered as auxiliary state variables with trivial dynamics, namely <bold>p</bold><sub><italic>k</italic>+1</sub> = <bold>p</bold><sub><italic>k</italic></sub>. An augmented <italic>n</italic> + <italic>l</italic> dimensional state vector can then be formed consisting of the original <italic>n</italic> state variables and <italic>l</italic> model parameters allowing for simultaneous state and parameter estimation [<xref ref-type="bibr" rid="pcbi.1005655.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref043">43</xref>].</p>
<p>To implement parametric prediction, the UKF is used to process the training data and obtain an estimate of <bold>p</bold>, as well as the state at the end of the training set, <bold>x</bold>(<italic>T</italic>). The parameter values are fixed and <xref ref-type="disp-formula" rid="pcbi.1005655.e001">Eq 1</xref> is forward solved from <italic>t</italic>(<italic>T</italic>) to generate predictions of the system dynamics over the prediction interval [<italic>t</italic>(<italic>T</italic> + 1), <italic>t</italic>(<italic>T</italic> + <italic>T</italic><sub><italic>F</italic></sub>)]. Namely, predictions <bold>x</bold>(<italic>T</italic> + 1), <bold>x</bold>(<italic>T</italic> + 2), …, <bold>x</bold>(<italic>T</italic> + <italic>T</italic><sub><italic>F</italic></sub>) are calculated.</p>
</sec>
<sec id="sec004">
<title>Takens’ method for nonparametric prediction</title>
<p>Instead of using the mechanistic model described by <xref ref-type="disp-formula" rid="pcbi.1005655.e001">Eq 1</xref>, the system can be represented nonparametrically. Without loss of generality consider the observed variable <italic>x</italic><sub><italic>j</italic></sub>. Using Takens’ theorem [<xref ref-type="bibr" rid="pcbi.1005655.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref048">48</xref>], the <italic>d</italic> + 1 dimensional delay coordinate vector <inline-formula id="pcbi.1005655.e003"><alternatives><graphic id="pcbi.1005655.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mi>j</mml:mi> <mml:mi>d</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mspace width="1pt"/><mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is formed which represents the state of the system at time <italic>t</italic>(<italic>T</italic>). Here <italic>d</italic> is the number of delays and <italic>τ</italic> is the time-delay.</p>
<p>The goal of nonparametric prediction is to utilize the training data in the interval [<italic>t</italic>(0), <italic>t</italic>(<italic>T</italic>)] to build local models for predicting the dynamics over the interval [<italic>t</italic>(<italic>T</italic> + 1), <italic>t</italic>(<italic>T</italic> + <italic>T</italic><sub><italic>F</italic></sub>)]. Here, the method of <italic>direct prediction</italic> is chosen. Prior to implementation of direct prediction, a library of delay vectors is formed from the training data of <italic>x</italic><sub><italic>j</italic></sub>.</p>
<p>Direct prediction begins by finding the <italic>κ</italic> nearest neighbors, as a function of Euclidean distance, to the current delay-coordinate vector <inline-formula id="pcbi.1005655.e004"><alternatives><graphic id="pcbi.1005655.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mi>j</mml:mi> <mml:mi>d</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> within the library of delay vectors. Neighboring delay vectors
<disp-formula id="pcbi.1005655.e005"><alternatives><graphic id="pcbi.1005655.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mi>j</mml:mi> <mml:mi>d</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mspace width="1pt"/><mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mi>j</mml:mi> <mml:mi>d</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mspace width="1pt"/><mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd> <mml:mtd/></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi> <mml:mi>j</mml:mi> <mml:mi>d</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mi>κ</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mi>κ</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mi>κ</mml:mi></mml:msup> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mi>κ</mml:mi></mml:msup> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mspace width="1pt"/><mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mi>κ</mml:mi></mml:msup> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
are found within the training data and the known <italic>x</italic><sub><italic>j</italic></sub>(<italic>T</italic>′ + <italic>i</italic>), <italic>x</italic><sub><italic>j</italic></sub>(<italic>T</italic>′′ + <italic>i</italic>), …, <italic>x</italic><sub><italic>j</italic></sub>(<italic>T</italic><sup><italic>κ</italic></sup> + <italic>i</italic>) points are used in a local model to predict the unknown value <italic>x</italic><sub><italic>j</italic></sub>(<italic>T</italic> + <italic>i</italic>) where <italic>i</italic> = 1, 2, …, <italic>T</italic><sub><italic>F</italic></sub>. In this article, a locally constant model is chosen
<disp-formula id="pcbi.1005655.e006"><alternatives><graphic id="pcbi.1005655.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msubsup> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mo>…</mml:mo> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mi>κ</mml:mi></mml:msubsup> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mi>κ</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where <inline-formula id="pcbi.1005655.e007"><alternatives><graphic id="pcbi.1005655.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:mspace width="1pt"/><mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mi>κ</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> are the weights for the <italic>j</italic><sup><italic>th</italic></sup> state that determine the contribution of each neighbor in building the prediction. In its simplest form, <xref ref-type="disp-formula" rid="pcbi.1005655.e006">Eq 3</xref> is an average of the nearest neighbors where <inline-formula id="pcbi.1005655.e008"><alternatives><graphic id="pcbi.1005655.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mo>…</mml:mo> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>j</mml:mi> <mml:mi>κ</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>κ</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. More sophisticated weighting schemes can be chosen, for example assigning the weights based on the Euclidean distance from each neighbor to the current delay vector [<xref ref-type="bibr" rid="pcbi.1005655.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref050">50</xref>]. Selection of values for <italic>d</italic>, <italic>τ</italic> and <italic>κ</italic> is necessary for implementation of the direct prediction algorithm. There is a wide range of literature on the selection of embedding parameters <italic>d</italic> and <italic>τ</italic> (see for example [<xref ref-type="bibr" rid="pcbi.1005655.ref051">51</xref>–<xref ref-type="bibr" rid="pcbi.1005655.ref058">58</xref>]). These parameters can also be chosen using a cross-validation approach whereby the training data are partitioned into a smaller training set and a validation set to allow for within-sample prediction and evaluation. The known training data can thus be used to select <italic>d</italic>, <italic>τ</italic> and <italic>κ</italic> prior to the out-of-sample prediction that occurs during the prediction interval [<italic>t</italic>(<italic>T</italic> + 1), <italic>t</italic>(<italic>T</italic> + <italic>T</italic><sub><italic>F</italic></sub>)]. Parameters for nonparametric prediction were chosen within each example.</p>
<p>The accuracy of the predicted <italic>x</italic><sub><italic>j</italic></sub>(<italic>T</italic> + <italic>i</italic>) is subject to several factors. The presence of noise in the training data plays a substantial role in decreasing prediction accuracy. However, recent advancements in nonparametric analysis have addressed the problem of filtering time series without use of a mechanistic model. In [<xref ref-type="bibr" rid="pcbi.1005655.ref017">17</xref>], a nonparametric filter was developed which merged Kalman filtering theory and Takens’ method. The resulting Kalman-Takens filter was demonstrated to be able to reduce significant amounts of noise in data. Application of the method was extended in [<xref ref-type="bibr" rid="pcbi.1005655.ref059">59</xref>] to the case of filtering stochastic variables without a model. In the results presented below, the training data used for nonparametric prediction are filtered first using the method of [<xref ref-type="bibr" rid="pcbi.1005655.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref059">59</xref>].</p>
</sec>
<sec id="sec005">
<title>Hybrid modeling and prediction: Merging parametric and nonparametric methods</title>
<p>As an alternative to the parametric and nonparametric methods described above, we propose a hybrid approach which blends the two methods together. In this framework, we assume that a full mechanistic model as described by <xref ref-type="disp-formula" rid="pcbi.1005655.e001">Eq 1</xref> is available. However, rather than using the full model, a subset of the mechanistic equations are used and the remainder of the variables are represented nonparametrically using delay-coordinates.</p>
<p>In formulating this method it is convenient to first think of <xref ref-type="disp-formula" rid="pcbi.1005655.e001">Eq 1</xref> without vector notation
<disp-formula id="pcbi.1005655.e009"><alternatives><graphic id="pcbi.1005655.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd> <mml:mtd/></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
Now assume only the first <italic>n</italic> − 1 equations of <xref ref-type="disp-formula" rid="pcbi.1005655.e009">Eq 4</xref> are used to model state variables <italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>n</italic>−1</sub>, while <italic>x</italic><sub><italic>n</italic></sub> is described nonparametrically
<disp-formula id="pcbi.1005655.e010"><alternatives><graphic id="pcbi.1005655.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mo>⋮</mml:mo></mml:mtd> <mml:mtd/></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd><mml:mo>≈</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi> <mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>+</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msubsup> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mrow><mml:mo>′</mml:mo> <mml:mo>′</mml:mo></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mo>…</mml:mo> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>w</mml:mi> <mml:mrow><mml:mi>n</mml:mi></mml:mrow> <mml:mi>κ</mml:mi></mml:msubsup> <mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>T</mml:mi> <mml:mi>κ</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
We refer to <xref ref-type="disp-formula" rid="pcbi.1005655.e010">Eq 5</xref> as the <italic>hybrid model</italic>. Note, in <xref ref-type="disp-formula" rid="pcbi.1005655.e010">Eq 5</xref> only <italic>x</italic><sub><italic>n</italic></sub> is assumed to be advanced nonparametrically. This is done purely for ease of presentation and the hybrid model can instead contain several variables whose equations are replaced by nonparametric advancement. Nonparametric advancement in the hybrid model similarly requires setting the number of delays, time-delay and the number of nearest neighbors with which to build the local model. Throughout our examples, these values are kept the same as those used by the standalone nonparametric method to ensure fair comparison.</p>
<p>The hybrid model has several distinguishing features. Notice, in this framework nonparametrically advanced dynamics are incorporated into mechanistic equations, essentially merging the two lines of mathematical thought. Furthermore, equations for state variables within <xref ref-type="disp-formula" rid="pcbi.1005655.e009">Eq 4</xref> can be replaced only if there are observations which map directly to them, otherwise their dynamics can not be nonparametrically advanced. Finally, the process of replacing equations in the hybrid method will generally result in a reduction in the number of unknown model parameters to be estimated. We will observe two benefits of this methodology. By reducing the number of mechanistic equations, and consequently the number of unknown parameters, we are able to obtain a more robust estimation of the model parameters in the mechanistic portion of the model. This is to be expected since in a sense, the hybrid approach allows us to reduce the dimension and complexity of the parameter space over which we have to optimize, allowing us to obtain better estimates of the parameters compared to the full dimensional estimation problem required by standard parametric modeling. This improvement is particularly noticeable when there is large uncertainty in the initial parameter values. Secondly, as a consequence of this robust estimation, the hybrid method offers improved predictions for those variables it models mechanistically. The more accurate parameterization results in improved short-term prediction accuracy when compared to the other methods.</p>
<p>In this hybrid scheme, obtaining an estimate of the unknown parameters in the <italic>n</italic> − 1 mechanistic equations and an estimate of <bold>x</bold>(<italic>T</italic>) requires a combination of the nonparametric analysis developed in [<xref ref-type="bibr" rid="pcbi.1005655.ref017">17</xref>] and traditional parametric methodology. The state variable <italic>x</italic><sub><italic>n</italic></sub>, which is not defined by a mechanistic equation in <xref ref-type="disp-formula" rid="pcbi.1005655.e009">Eq 4</xref>, is represented by delay coordinates within the UKF. Therefore at step <italic>k</italic> we have the hybrid state
<disp-formula id="pcbi.1005655.e011"><alternatives><graphic id="pcbi.1005655.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>H</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>-</mml:mo> <mml:mi>d</mml:mi> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
The UKF as described above is implemented with this hybrid state <bold>x</bold><sup><italic>H</italic></sup>(<italic>k</italic>) and the model described by <xref ref-type="disp-formula" rid="pcbi.1005655.e010">Eq 5</xref>. Notice that in the case of the hybrid model when we have to advance the state dynamics and form the prior estimate in the UKF, the advancement is done parametrically for the first <italic>n</italic> − 1 states and nonparametrically for the <italic>n</italic><sup><italic>th</italic></sup> state. Similarly to before, we can augment <bold>x</bold><sup><italic>H</italic></sup> with the unknown parameters in the <italic>n</italic> − 1 mechanistic equations allowing for simultaneous parameter estimation. Once the training data are processed and an estimate of <bold>x</bold><sup><italic>H</italic></sup>(<italic>T</italic>) and the parameters are obtained, the hybrid model in <xref ref-type="disp-formula" rid="pcbi.1005655.e010">Eq 5</xref> is implemented to generate predictions <bold>x</bold><sup><italic>H</italic></sup>(<italic>T</italic> + 1), <bold>x</bold><sup><italic>H</italic></sup>(<italic>T</italic> + 2), …, <bold>x</bold><sup><italic>H</italic></sup>(<italic>T</italic> + <italic>T</italic><sub><italic>F</italic></sub>).</p>
<p>The natural question to ask is which mechanistic equations should be replaced by nonparametric representation in this hybrid scheme? This is a complicated question and inevitably is situation dependent. In some situations, which hybrid model to choose may not be clear a priori, and several different models may need to be considered in combination with an uncertainty analysis on the results to determine the optimal hybridization. In other situations, the mechanistic equations to replace may be clearer. For example, if the researcher is less confident in the mechanistic description of certain variables, or certain equations include parameters about which one has less confidence, then those equations should be replaced by their nonparametric counterpart to reduce the overall error in the model. If one is only interested in certain parameters or processes, then the appropriate mechanistic equations need to be included and the remainder of the equations can be replaced by nonparametric evolution to reduce the estimation complexity and obtain better estimates and predictions for the included equations. Nevertheless, individual experimental situations will dictate if and how much confidence we have in our mechanistic model as well as which portions are most important to our analysis. These factors must be used as guidance for constructing the preferred hybrid formulation.</p>
</sec>
</sec>
<sec id="sec006" sec-type="results">
<title>Results</title>
<p>We demonstrate the utility of the hybrid methodology, with comparison to standard parametric and nonparametric modeling and prediction, in the following example systems. When conducting this analysis, two types of error are considered. The first, error in the observations, manifests itself as noise in the training data which all three methods will have to confront. The second type, error in the parameters, takes the form of an uncertainty in the initial parameter values used by the UKF for parameter estimation. Only the parametric and hybrid methods will have to deal with this parameter error. Throughout, we will refer to a percentage uncertainty which corresponds to the standard deviation of the distribution from which the initial parameter value is drawn relative to the mean. For example, if the true value for a parameter <italic>p</italic><sub>1</sub> is 12 and we have 50% uncertainty in this value, then the initial parameter value used for estimating <italic>p</italic><sub>1</sub> will be drawn from the distribution <italic>N</italic>(12, (0.5 * 12)<sup>2</sup>).</p>
<p>To quantify prediction accuracy, the normalized root-mean-square-error, or SRMSE, is calculated for each prediction method as a function of forecast horizon. Normalization is done with respect to the standard deviation of the variable as calculated from the training data. In using the SRMSE metric, the goal is to be more accurate than if the prediction was simply the mean of the training data (corresponding to SRMSE = 1). Thus a prediction is better than a naive prediction when SRMSE &lt; 1, though for chaotic systems prediction accuracy will eventually converge to this error level since only short-term prediction is possible.</p>
<sec id="sec007">
<title>Prediction in the Lorenz-63 system</title>
<p>As a demonstrative example, consider the Lorenz-63 system [<xref ref-type="bibr" rid="pcbi.1005655.ref028">28</xref>]
<disp-formula id="pcbi.1005655.e012"><alternatives><graphic id="pcbi.1005655.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˙</mml:mo></mml:mover></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>σ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>y</mml:mi> <mml:mo>-</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>˙</mml:mo></mml:mover></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>ρ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mi>y</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>˙</mml:mo></mml:mover></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>x</mml:mi> <mml:mi>y</mml:mi> <mml:mo>-</mml:mo> <mml:mi>β</mml:mi> <mml:mi>z</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
where <italic>σ</italic> = 10, <italic>ρ</italic> = 28, <italic>β</italic> = 8/3. Data are generated from this system using a fourth-order Adams-Moulton method with sample rate <italic>h</italic> = 0.05. We assume that 500 training data points of the <italic>x</italic>, <italic>y</italic> and <italic>z</italic> variables are available, or 25 units of time. The Lorenz-63 system oscillates approximately once every unit of time, meaning the training set consists of about 25 oscillations. The goal is to accurately predict the dynamics of <italic>x</italic>, <italic>y</italic> and <italic>z</italic> one time unit after the end of the training set. However, the observations of each variable are corrupted by Gaussian observational noise with mean zero and variance equal to 4. Additionally the true value of parameters <italic>σ</italic>, <italic>ρ</italic> and <italic>β</italic> are unknown. <xref ref-type="fig" rid="pcbi.1005655.g001">Fig 1</xref> shows an example simulation of this system.</p>
<fig id="pcbi.1005655.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005655.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Example of Lorenz-63 realization.</title>
<p>500 samples, or 25 units of time, of noisy training data (grey circles) are available for (a) <italic>x</italic>, (b) <italic>y</italic> and (c) <italic>z</italic>. Note, we have only shown the last 5 units of time worth of training data for visualization purposes. From the end of the training data (indicated by dashed black line), we want to accurately predict the system dynamics within the next unit of time (solid black line).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005655.g001" xlink:type="simple"/>
</fig>
<p>The parametric method utilizes <xref ref-type="disp-formula" rid="pcbi.1005655.e012">Eq 6</xref> to estimate the model state and parameters, and to predict the <italic>x</italic>, <italic>y</italic> and <italic>z</italic> dynamics. For the nonparametric method, delay coordinates of the variables are formed with <italic>d</italic> = 9 and <italic>τ</italic> = 1. The local constant model for prediction is built using <italic>κ</italic> = 20 nearest neighbors. For the hybrid method, the mechanistic equation governing the dynamics of <italic>y</italic> are replaced nonparametrically resulting in the reduced Lorenz-63 model
<disp-formula id="pcbi.1005655.e013"><alternatives><graphic id="pcbi.1005655.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e013" xlink:type="simple"/><mml:math display="block" id="M13"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˙</mml:mo></mml:mover></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>σ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>y</mml:mi> <mml:mo>-</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>˙</mml:mo></mml:mover></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>x</mml:mi> <mml:mi>y</mml:mi> <mml:mo>-</mml:mo> <mml:mi>β</mml:mi> <mml:mi>z</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
Note, this hybrid model in <xref ref-type="disp-formula" rid="pcbi.1005655.e013">Eq 7</xref> does not require estimation of the <italic>ρ</italic> parameter since the mechanistic equation for <italic>y</italic> is removed.</p>
<p><xref ref-type="fig" rid="pcbi.1005655.g002">Fig 2</xref> shows a comparison of parametric (black), nonparametric (blue) and hybrid (red) prediction error as a function of forecast horizon. SRMSE results averaged over 500 system realizations with error bars denoting standard error. With an initial parameter uncertainty level of 80% (solid lines), the hybrid method offers improved short-term prediction of the Lorenz-63 <italic>x</italic> (<xref ref-type="fig" rid="pcbi.1005655.g002">Fig 2a</xref>), <italic>y</italic> (<xref ref-type="fig" rid="pcbi.1005655.g002">Fig 2b</xref>) and <italic>z</italic> (<xref ref-type="fig" rid="pcbi.1005655.g002">Fig 2c</xref>) variables over standalone parametric prediction. Note that parametric prediction at this uncertainty level does very poorly and in the cases of <italic>y</italic> and <italic>z</italic> its result is not seen due to the scale of the error.</p>
<fig id="pcbi.1005655.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005655.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Comparison of the prediction methods in the Lorenz-63 system.</title>
<p>Results of predicting the Lorenz-63 (a) <italic>x</italic>, (b) <italic>y</italic> and (c) <italic>z</italic> variables averaged over 500 realizations. Error bars denote standard error over the 500 realizations. Training data consists of 500 data points generated from <xref ref-type="disp-formula" rid="pcbi.1005655.e012">Eq 6</xref> with <italic>σ</italic> = 10, <italic>ρ</italic> = 28 and <italic>β</italic> = 8/3 with sample rate <italic>h</italic> = 0.05. Data are corrupted by Gaussian observational noise with mean 0 and variance of 4. Parametric (black), nonparametric (blue) and hybrid (red) prediction accuracy with parameter uncertainty of 80% (solid line) plotted as a function of forecast horizon. Hybrid prediction, which utilizes mechanistic equations in describing <italic>x</italic> and <italic>z</italic> but nonparametrically represents <italic>y</italic>, offers an improvement in short-term prediction accuracy over standalone nonparametric prediction. Parametric prediction at this uncertainty level performs poorly in predicting all three variables and in the case of (b) and (c) is not seen due to the scale of the error. For comparison purposes, the parametric method with 50% (dotted line) and 20% (dashed line) uncertainty is also considered. As the uncertainty shrinks, performance of the parametric method improves. However, only at a small uncertainty level does it outperform the short-term improvement in prediction afforded by the hybrid method.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005655.g002" xlink:type="simple"/>
</fig>
<p>The success of the hybrid method can be traced to more accurate estimates of the model parameters in the mechanistic equations that it uses. <xref ref-type="table" rid="pcbi.1005655.t001">Table 1</xref> shows the resulting hybrid and parametric estimation of the Lorenz-63 parameters. The hybrid method is able to construct accurate estimates of both <italic>σ</italic> and <italic>β</italic>, with a mean close to the true value and a small standard deviation of the estimates. The parametric method at the same 80% uncertainty level is unable to obtain reliable estimates, exemplified by the large standard deviation of the estimates.</p>
<table-wrap id="pcbi.1005655.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005655.t001</object-id>
<label>Table 1</label>
<caption>
<title>Summary of Lorenz-63 parameter estimation results.</title>
<p>Mean and standard deviation calculated over 500 realizations. The hybrid method, which only needs to estimate <italic>σ</italic> and <italic>β</italic>, is robust to a large initial parameter uncertainty. The parametric method on the other hand is unable to obtain reliable estimates of the Lorenz-63 parameters unless the uncertainty is small enough.</p>
</caption>
<alternatives>
<graphic id="pcbi.1005655.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005655.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="4">Lorenz-63 Parameter Estimation Results</th>
</tr>
<tr>
<th align="center">True Parameter</th>
<th align="center">Method</th>
<th align="center">Mean</th>
<th align="center">Standard Deviation</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="4"><italic>σ</italic> = 10</td>
<td align="center">Hybrid (80% Uncertainty)</td>
<td align="center">9.77</td>
<td align="center">0.75</td>
</tr>
<tr>
<td align="center">Parametric (80% Uncertainty)</td>
<td align="center">8.03</td>
<td align="center">4.81</td>
</tr>
<tr>
<td align="center">Parametric (50% Uncertainty)</td>
<td align="center">9.84</td>
<td align="center">3.06</td>
</tr>
<tr>
<td align="center">Parametric (20% Uncertainty)</td>
<td align="center">10.06</td>
<td align="center">0.95</td>
</tr>
<tr>
<td align="center" rowspan="4"><italic>ρ</italic> = 28</td>
<td align="center">Hybrid (80% Uncertainty)</td>
<td align="center">NA</td>
<td align="center">NA</td>
</tr>
<tr>
<td align="center">Parametric (80% Uncertainty)</td>
<td align="center">24.55</td>
<td align="center">14.07</td>
</tr>
<tr>
<td align="center">Parametric (50% Uncertainty)</td>
<td align="center">25.63</td>
<td align="center">6.37</td>
</tr>
<tr>
<td align="center">Parametric (20% Uncertainty)</td>
<td align="center">27.89</td>
<td align="center">0.83</td>
</tr>
<tr>
<td align="center" rowspan="4"><italic>β</italic> = 2.67</td>
<td align="center">Hybrid (80% Uncertainty)</td>
<td align="center">2.58</td>
<td align="center">0.11</td>
</tr>
<tr>
<td align="center">Parametric (80% Uncertainty)</td>
<td align="center">1.61</td>
<td align="center">1.34</td>
</tr>
<tr>
<td align="center">Parametric (50% Uncertainty)</td>
<td align="center">2.20</td>
<td align="center">0.98</td>
</tr>
<tr>
<td align="center">Parametric (20% Uncertainty)</td>
<td align="center">2.63</td>
<td align="center">0.19</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>For comparison purposes, we consider the parametric method at smaller parameter uncertainty levels of 50% (<xref ref-type="fig" rid="pcbi.1005655.g002">Fig 2</xref>, dotted line) and 20% (<xref ref-type="fig" rid="pcbi.1005655.g002">Fig 2</xref>, dashed line). As the uncertainty decreases for the parametric method, its performance improves. Similarly in <xref ref-type="table" rid="pcbi.1005655.t001">Table 1</xref>, we observe that the shrinking uncertainty results in a more accurate estimation of the model parameters. However at 50% uncertainty, the parametric method is still outperformed by the hybrid method with a higher uncertainty level. When the uncertainty is small, parametric prediction offers better performance, which is to be expected since it has access to the true model equations and starts out with close to optimal parameter values. The hybrid method was tested at these additional uncertainty levels, however its performance did not change substantially. This can be attributed to the fact that the hybrid method already obtains an accurate estimation of the model parameters at 80% uncertainty and thus shrinking the initial parameter uncertainty does not drastically change the results.</p>
<p>The hybrid method also provides improved prediction of the <italic>x</italic> and <italic>z</italic> variables compared to standalone nonparametric prediction. We note that hybrid and nonparametric prediction of <italic>y</italic> is comparable, which is to be expected since <italic>y</italic> is represented nonparametrically in the hybrid model chosen. This is a subtle, but important point to note and throughout our results we will see that the hybrid method offers improved prediction only for those variables that it models mechanistically. Those that are modeled nonparametrically will have similar performance to standalone nonparametric prediction.</p>
<p>The formulation chosen in <xref ref-type="disp-formula" rid="pcbi.1005655.e013">Eq 7</xref> is of course one of several possible hybrid model decompositions. As another example, we can consider the hybrid model
<disp-formula id="pcbi.1005655.e014"><alternatives><graphic id="pcbi.1005655.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e014" xlink:type="simple"/><mml:math display="block" id="M14"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mi>σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>y</mml:mi> <mml:mo>-</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
where <italic>y</italic> and <italic>z</italic> are represented nonparametrically. Notice that for this hybrid model, nonparametric advancement of <italic>z</italic> does not enter into the mechanistic equation. <xref ref-type="fig" rid="pcbi.1005655.g003">Fig 3</xref> shows a comparison in predicting the <italic>x</italic> variable between the hybrid model in <xref ref-type="disp-formula" rid="pcbi.1005655.e014">Eq 8</xref> with 80% uncertainty (solid red curve) and standalone nonparametric prediction (solid blue curve) for three different noise levels. Results are averaged over 500 realizations with error bars denoting standard error. In <xref ref-type="fig" rid="pcbi.1005655.g003">Fig 3a</xref> the training data are corrupted by noise with variance of 1, <xref ref-type="fig" rid="pcbi.1005655.g003">Fig 3b</xref> noise with variance of 4 and in <xref ref-type="fig" rid="pcbi.1005655.g003">Fig 3c</xref> noise with variance of 16. At all three noise levels, the hybrid method outperforms the nonparametric method in predicting <italic>x</italic>. Prediction of <italic>y</italic> and <italic>z</italic> are comparable between the two methods in this instance since these variables are represented nonparametrically by this hybrid model. Prediction accuracy for both methods decreases as the noise level increases due to growing inaccuracies in the state and parameter estimates as well as inaccurate nearest neighbors.</p>
<fig id="pcbi.1005655.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005655.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Predicting Lorenz-63 <italic>x</italic> dynamics at three different noise levels.</title>
<p>Training data corrupted by noise with variance of (a) 1, (b) 4 and (c) 16. Error bars denote standard error over 500 realizations. Hybrid prediction with 80% uncertainty (solid red line), which utilizes mechanistic equations in describing <italic>x</italic> only and nonparametrically represents <italic>y</italic> and <italic>z</italic>, offers an improvement in prediction accuracy over standalone nonparametric prediction (solid blue line). While the accuracy of both methods decreases as the noise level increases, the hybrid method offers improved prediction accuracy.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005655.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec008">
<title>Predicting neuronal network dynamics</title>
<p>We now consider the difficult high dimensional estimation and prediction problem posed by neuronal network studies. If we are only interested in predicting a portion of the network, then we can use the proposed hybrid method to refine our estimation and prediction while simultaneously reducing estimation complexity. As an example of this potential network application we consider the prediction of spiking dynamics in a network of <italic>M</italic> Hindmarsh-Rose neurons [<xref ref-type="bibr" rid="pcbi.1005655.ref029">29</xref>]
<disp-formula id="pcbi.1005655.e015"><alternatives><graphic id="pcbi.1005655.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mi>i</mml:mi> <mml:mn>3</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>.</mml:mo> <mml:mn>2</mml:mn> <mml:mo>+</mml:mo> <mml:mspace width="1pt"/><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>m</mml:mi></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:mspace width="1pt"/><mml:mfrac><mml:msub><mml:mi>β</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mn>9</mml:mn> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>10</mml:mn> <mml:msub><mml:mi>x</mml:mi> <mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:msub><mml:mi>x</mml:mi> <mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mi>i</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>5</mml:mn> <mml:mo>×</mml:mo> <mml:msup><mml:mn>10</mml:mn> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:msup> <mml:mspace width="1pt"/><mml:mo>[</mml:mo> <mml:mn>4</mml:mn> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>8</mml:mn> <mml:mn>5</mml:mn></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
where <italic>i</italic> = 1, 2, …, <italic>M</italic>. <italic>x</italic><sub><italic>i</italic></sub> corresponds to the spiking potential while <italic>y</italic><sub><italic>i</italic></sub> and <italic>z</italic><sub><italic>i</italic></sub> describe the fast and slow-scale dynamics, respectively, of neuron <italic>i</italic>. Each individual neuron in the network has parameters <italic>a</italic><sub><italic>i</italic></sub> = 1, <italic>b</italic><sub><italic>i</italic></sub> = 3 and <italic>c</italic><sub><italic>i</italic></sub> = 5 which are assumed to be unknown. <italic>β</italic><sub><italic>im</italic></sub> represents the connectivity coefficient from neuron <italic>i</italic> to neuron <italic>m</italic>. For a network of size <italic>M</italic>, we have <italic>M</italic><sup>2</sup> − <italic>M</italic> possible connection parameters since neuron self connections are not allowed (i.e. <italic>β</italic><sub><italic>ii</italic></sub> = 0). These connection parameters are also assumed to be unknown. The neurons in this network are coupled to one another through the voltages by an exponential term which acts as a gating function, allowing the transfer of information only when a neuron is about to spike. This prevents constant communication across the network, and has biophysical plausibility [<xref ref-type="bibr" rid="pcbi.1005655.ref040">40</xref>].</p>
<p>For this example we examine networks of size <italic>M</italic> = 3 with 5 random connections. Data from these networks are generated using a fourth-order Adams-Moulton method with sample rate <italic>h</italic> = 0.08 ms. We assume that the training data consists of 3000 observations, or 240 ms, of the <italic>x</italic><sub>1</sub>, <italic>x</italic><sub>2</sub>, <italic>x</italic><sub>3</sub> variables each of which are corrupted by Gaussian noise with mean 0 and variance of 0.2. Under the stated parameter regime, the neurons in the network spike approximately every 6 ms, meaning our training set has on average around 40 spikes per neuron. In this example, we restrict our focus to predicting 8 ms of the <italic>x</italic><sub>3</sub> variable (though a similar analysis follows for the prediction of <italic>x</italic><sub>1</sub> and <italic>x</italic><sub>2</sub>). <xref ref-type="fig" rid="pcbi.1005655.g004">Fig 4a</xref> shows a representative realization of this problem.</p>
<fig id="pcbi.1005655.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005655.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Predicting neuron potential <italic>x</italic><sub>3</sub> in random 3-neuron Hindmarsh-Rose networks.</title>
<p>(a) 3000 samples (or 240 ms) of training data (grey circles) are available from each neuron in the network. From the end of the training data (indicated by dashed black line), we want to accurately predict the next 8 ms of <italic>x</italic><sub>3</sub> (solid black line). (b) Forecast accuracy in predicting 8 ms of <italic>x</italic><sub>3</sub> when using parametric (black), nonparametric (blue) and hybrid (red) methods. Results averaged over 200 randomly generated 3-neuron Hindmarsh-Rose network realizations and error bars, shown only for every tenth forecast point, denote standard error. At 80% uncertainty (solid line), the hybrid method outperforms both parametric and nonparametric methods. When considering the parametric method with 50% uncertainty, prediction accuracy between it and the hybrid method is comparable over the first 2 ms.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005655.g004" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1005655.g004">Fig 4b</xref> shows the resulting accuracy in predicting <italic>x</italic><sub>3</sub> when using parametric (black), nonparametric (blue) and hybrid (red) methods. Results are averaged over 200 realizations with error bars denoting standard error. Error bars are only shown for every tenth forecast point so as to aid in visualization. At the 80% uncertainty level (solid line), the parametric method performs poorly. The parametric approach uses the full mechanistic model described by <xref ref-type="disp-formula" rid="pcbi.1005655.e015">Eq 9</xref> for modeling and prediction, requiring estimation of the <italic>x</italic>, <italic>y</italic> and <italic>z</italic> state variables and parameters <italic>a</italic>, <italic>b</italic> and <italic>c</italic> for each neuron, as well as the full connectivity matrix. Notice that once again with 80% uncertainty, the scale of error for the parametric method is much larger compared to the other methods.</p>
<p>The nonparametric method for this example (<italic>τ</italic> = 1, <italic>d</italic> = 9) uses <italic>κ</italic> = 10 neighbors for building the local model for prediction. Network level dynamics such as these can prove problematic for nonparametric prediction due to the increased complexity of the system dynamics. As the size of the network grows, the requisite data needed to make accurate multi-step-ahead predictions substantially increases. For the small network in this example, the nonparametric method is still able to provide fairly accurate predictions. However, dimensionality of the system and the required data needed is a considerable limiting factor when analyzing high-dimensional networks.</p>
<p>The benefit of the hybrid method in analyzing this network is that since we are only interested in neuron 3, we can assume a mechanistic equation for only this neuron
<disp-formula id="pcbi.1005655.e016"><alternatives><graphic id="pcbi.1005655.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e016" xlink:type="simple"/><mml:math display="block" id="M16"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>y</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mn>3</mml:mn> <mml:mn>3</mml:mn></mml:msubsup> <mml:mo>+</mml:mo> <mml:msub><mml:mi>b</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mn>3</mml:mn> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>.</mml:mo> <mml:mn>2</mml:mn> <mml:mo>+</mml:mo> <mml:mspace width="1pt"/><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mn>3</mml:mn> <mml:mo>≠</mml:mo> <mml:mi>m</mml:mi></mml:mrow> <mml:mi>M</mml:mi></mml:munderover> <mml:mspace width="1pt"/><mml:mfrac><mml:msub><mml:mi>β</mml:mi> <mml:mrow><mml:mn>3</mml:mn> <mml:mi>m</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mn>9</mml:mn> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>10</mml:mn> <mml:msub><mml:mi>x</mml:mi> <mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:msub><mml:mi>x</mml:mi> <mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:msubsup><mml:mi>x</mml:mi> <mml:mn>3</mml:mn> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mn>3</mml:mn></mml:msub></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mn>5</mml:mn> <mml:mo>×</mml:mo> <mml:msup><mml:mn>10</mml:mn> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:msup> <mml:mspace width="1pt"/><mml:mo>[</mml:mo> <mml:mn>4</mml:mn> <mml:mspace width="1pt"/><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>8</mml:mn> <mml:mn>5</mml:mn></mml:mfrac> <mml:mo>)</mml:mo> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
and nonparametrically represent neuron 1 and neuron 2. The hybrid model in <xref ref-type="disp-formula" rid="pcbi.1005655.e016">Eq 10</xref> results in a substantial reduction in the complexity of the estimation problem while still giving us some information about the dynamics of neuron 3. This blending once again results in improved prediction accuracy. We see that the the hybrid method outperforms both parametric and nonparametric predictions. For comparison purposes, we show the parametric method at a smaller uncertainty level of 50% (<xref ref-type="fig" rid="pcbi.1005655.g004">Fig 4b</xref>, dotted line). The hybrid method with higher uncertainty offers comparable prediction within the first 2 ms to the parametric method with this lower uncertainty level. Note that unlike in the Lorenz-63 example, we do not consider the parametric method with 20% uncertainty since reasonable parameter estimates and predictions are obtained with 50% uncertainty. <xref ref-type="table" rid="pcbi.1005655.t002">Table 2</xref> shows the robustness of the hybrid method in estimating the individual parameters for neuron 3. Even with a high uncertainty, the hybrid method is able to obtain accurate and reliable estimates of the neuron parameters compared to the parametric method at both the high and medium uncertainty levels.</p>
<table-wrap id="pcbi.1005655.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005655.t002</object-id>
<label>Table 2</label>
<caption>
<title>Summary of neuron 3 parameter estimation results.</title>
<p>Mean and standard deviation calculated over 200 realizations. The hybrid method once again is robust to a large initial parameter uncertainty. The parametric method on the other hand is unable to obtain reliable estimates of the neuron parameters with large uncertainty.</p>
</caption>
<alternatives>
<graphic id="pcbi.1005655.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005655.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center" colspan="4">Neuron 3 Parameter Estimation Results</th>
</tr>
<tr>
<th align="center">True Parameter</th>
<th align="center">Method</th>
<th align="center">Mean</th>
<th align="center">Standard Deviation</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="3"><italic>a</italic><sub>3</sub> = 1</td>
<td align="center">Hybrid (80% Uncertainty)</td>
<td align="char" char=".">0.98</td>
<td align="char" char=".">0.04</td>
</tr>
<tr>
<td align="center">Parametric (80% Uncertainty)</td>
<td align="char" char=".">1.07</td>
<td align="char" char=".">0.51</td>
</tr>
<tr>
<td align="center">Parametric (50% Uncertainty)</td>
<td align="char" char=".">0.98</td>
<td align="char" char=".">0.15</td>
</tr>
<tr>
<td align="center" rowspan="3"><italic>b</italic><sub>3</sub> = 3</td>
<td align="center">Hybrid (80% Uncertainty)</td>
<td align="char" char=".">2.96</td>
<td align="char" char=".">0.10</td>
</tr>
<tr>
<td align="center">Parametric (80% Uncertainty)</td>
<td align="char" char=".">2.92</td>
<td align="char" char=".">0.88</td>
</tr>
<tr>
<td align="center">Parametric (50% Uncertainty)</td>
<td align="char" char=".">2.92</td>
<td align="char" char=".">0.26</td>
</tr>
<tr>
<td align="center" rowspan="3"><italic>c</italic><sub>3</sub> = 5</td>
<td align="center">Hybrid (80% Uncertainty)</td>
<td align="char" char=".">4.93</td>
<td align="char" char=".">0.16</td>
</tr>
<tr>
<td align="center">Parametric (80% Uncertainty)</td>
<td align="char" char=".">4.66</td>
<td align="char" char=".">1.04</td>
</tr>
<tr>
<td align="center">Parametric (50% Uncertainty)</td>
<td align="char" char=".">4.83</td>
<td align="char" char=".">0.43</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec009">
<title>Predicting flour beetle population dynamics</title>
<p>We now investigate the prediction problem in a well-known data set from an ecological study involving the cannibalistic red flour beetle <italic>Tribolium castaneum</italic>. In [<xref ref-type="bibr" rid="pcbi.1005655.ref030">30</xref>], the authors present experimentally collected data and a mechanistic model describing the life cycle dynamics of <italic>T. castaneum</italic>. Their discrete time model describing the progression of the beetle through the larvae, pupae, and adult stages is given by
<disp-formula id="pcbi.1005655.e017"><alternatives><graphic id="pcbi.1005655.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>L</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>b</mml:mi> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>l</mml:mi></mml:mrow></mml:msub> <mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>e</mml:mi> <mml:mi>a</mml:mi></mml:mrow></mml:msub> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>l</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>a</mml:mi></mml:mrow></mml:msub> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>a</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
where <italic>L</italic>, <italic>P</italic> and <italic>A</italic> correspond to larvae, pupae and adult populations, respectively. The essential interactions described by this model are (i) flour beetles become reproductive only in the adult stage, (ii) adults produce new larvae, (iii) adults and larvae can both cannibalize larvae, and (iv) adults cannibalize pupae. We note that since <xref ref-type="disp-formula" rid="pcbi.1005655.e017">Eq 11</xref> only approximates the life cycle dynamics of the beetle, there is a degree of model error in the proposed system, unlike the previous examples.</p>
<p>The authors of [<xref ref-type="bibr" rid="pcbi.1005655.ref030">30</xref>] experimentally set the adult mortality rate (<italic>μ</italic><sub><italic>a</italic></sub>) to 0.96 and the recruitment rate (<italic>c</italic><sub><italic>pa</italic></sub>) from pupae to adult to seven different values (0, 0.05, 0.10, 0.25, 0.35, 0.50, 1.0). Experiments at each recruitment rate value were replicated three times resulting in 21 different datasets. Each dataset consists of total numbers of larvae, pupae, and adults measured bi-weekly over 82 weeks resulting in 41 measurements for each life stage. These data were fit to Eq 11 in [<xref ref-type="bibr" rid="pcbi.1005655.ref030">30</xref>] and parameter estimates <italic>b</italic> = 6.598, <italic>c</italic><sub><italic>el</italic></sub> = 1.209 × 10<sup>−2</sup>, <italic>c</italic><sub><italic>ea</italic></sub> = 1.155 × 10<sup>−2</sup> and <italic>μ</italic><sub><italic>l</italic></sub> = 0.2055 were obtained. We treat these parameter values as ground truth when considering the different parameter uncertainty levels for fitting the data to the model.</p>
<p>In our analysis of this system, we treat the first 37 measurements (or 74 weeks) within an experiment as training data and use the remaining 4 time points (or 8 weeks) for forecast evaluation. <xref ref-type="fig" rid="pcbi.1005655.g005">Fig 5</xref> shows an example of this setup for a representative dataset. <xref ref-type="fig" rid="pcbi.1005655.g006">Fig 6</xref> shows the results of predicting the larvae (<xref ref-type="fig" rid="pcbi.1005655.g006">Fig 6a</xref>), pupae (<xref ref-type="fig" rid="pcbi.1005655.g006">Fig 6b</xref>) and adult (<xref ref-type="fig" rid="pcbi.1005655.g006">Fig 6c</xref>) populations using parametric (black), nonparametric (blue) and hybrid prediction methods with 80% (solid lines) parameter uncertainty. Error bars correspond to the standard error over the 21 datasets. The parametric method uses the full mechanistic model described in <xref ref-type="disp-formula" rid="pcbi.1005655.e017">Eq 11</xref> to estimate the population state and parameters <italic>b</italic>, <italic>c</italic><sub><italic>el</italic></sub>, <italic>c</italic><sub><italic>ea</italic></sub> and <italic>μ</italic><sub><italic>l</italic></sub> before prediction. We note in <xref ref-type="fig" rid="pcbi.1005655.g006">Fig 6</xref> that the parametric method is not seen due to the scale of the error, and is significantly outperformed by the nonparametric prediction (<italic>τ</italic> = 1, <italic>d</italic> = 2, <italic>κ</italic> = 5). For the hybrid method, we only consider the mechanistic equations for pupae and adult population dynamics
<disp-formula id="pcbi.1005655.e018"><alternatives><graphic id="pcbi.1005655.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005655.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>A</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mrow><mml:mi>p</mml:mi> <mml:mi>a</mml:mi></mml:mrow></mml:msub> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mi>A</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>a</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
and nonparametrically represent larvae. Similarly to our previous examples, the hybrid method outperforms parametric prediction at the 80% uncertainty level. The parametric method with a smaller uncertainty of 50% (dotted lines) offers comparable performance to the hybrid method with larger uncertainty. As a result of the hybrid model described by <xref ref-type="disp-formula" rid="pcbi.1005655.e018">Eq 12</xref>, prediction accuracy for larvae (<xref ref-type="fig" rid="pcbi.1005655.g006">Fig 6a</xref>) should be comparable between the hybrid and nonparametric methods, and we do in fact see overlap between the two prediction curves. However, the hybrid method in this example does give us improved one-step ahead (2 weeks) prediction of pupae levels and improved two-step ahead (4 weeks) prediction for adult population levels over standalone nonparametric prediction. After these forecast horizons, there is overlap in the error bars between the two methods.</p>
<fig id="pcbi.1005655.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005655.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Example data set from <italic>T. castaneum</italic> experiment presented in [<xref ref-type="bibr" rid="pcbi.1005655.ref030">30</xref>].</title>
<p>37 observations, or 74 weeks, of training data (grey circles) are available for (a) larvae, (b) pupae and (c) adult population levels. From the end of the training data (indicated by dashed black line), we want to accurately predict the next 8 weeks of population dynamics (solid black line).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005655.g005" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005655.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005655.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Results for predicting population levels of <italic>T. castaneum</italic>.</title>
<p>Average SRMSE over 21 experimental datasets when using parametric (black curve), nonparametric (blue curve) and hybrid (red curve) methods for predicting (a) larvae, (b) pupae and (c) adult population levels with uncertainty of 80% (solid line) and 50% (dashed-dotted line). Error bars correspond to standard error over the 21 datasets. Hybrid prediction with 80% uncertainty offers improved prediction over both nonparametric and parametric with 80% uncertainty (not visible due to scale of error), and comparable performance to parametric with 50% uncertainty.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005655.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec010">
<title>Conclusion</title>
<p>By blending characteristics of parametric and nonparametric methodologies, the proposed hybrid method for modeling and prediction offers several advantages over standalone methods. From the perspective of model fitting and the required parameter estimation that arises in this process, we have shown that the hybrid approach allows for a more robust estimation of model parameters. Particularly for situations where there is a large uncertainty in the true parameter values, the hybrid method is able to construct accurate estimates of model parameters when the standard parametric model fitting fails to do so. At first this may seem counter-intuitive, but in fact it is not that surprising. The replacement of mechanistic equations with their nonparametric representations in effect reduces the dimension of the parameter space that we have to optimize in, resulting in better parameter estimates. As we have demonstrated in the above examples, this refinement in the parameter estimates leads to an improvement in short-term prediction accuracy for the mechanistic equations used by the hybrid model.</p>
<p>The limitations of the hybrid method are similar to those of parametric and nonparametric methods in that if not enough training data are available then accurate estimation and prediction becomes difficult. However, the demonstrated robustness of the hybrid method to large parameter uncertainty is encouraging, particularly when considering experimental situations where we may not have a good prior estimate of the model parameters. One could consider implementing the hybrid method in an iterative fashion, estimating the parameters of each equation separately, then piecing the model back together for analysis and prediction. We can think of this as an <italic>iterative hybrid method</italic>, and is the subject of future work.</p>
<p>We view this work as complementary to recent publications on forecasting [<xref ref-type="bibr" rid="pcbi.1005655.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref060">60</xref>]. The authors of [<xref ref-type="bibr" rid="pcbi.1005655.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005655.ref050">50</xref>] advocate nonparametric methods over parametric methods in general, while a letter [<xref ref-type="bibr" rid="pcbi.1005655.ref060">60</xref>] addressing the work of [<xref ref-type="bibr" rid="pcbi.1005655.ref049">49</xref>] showed that a more sophisticated method for model fitting results in better parameter estimates and therefore model-based predictions which outperform model-free methods. Our results support the view that no one method is uniformly better than the other. As we showed in the above examples, in situations where the model error and uncertainty in initial parameters are relatively small, the parametric approach outperforms other prediction methods. Furthermore it gives us system relevant parameter values that have some quantifiable interpretation. Often in experimental studies though, we are not operating in this ideal situation and instead are working with a model that has substantial error with a large uncertainty in parameters which can lead to inaccurate system inference. In situations such as these, nonparametric methods are particularly useful given their reliance on data only. Of course their limitation is that they sacrifice the potential for biophysical interpretability during the model fitting process.</p>
<p>The main appeal of the hybrid method is that we can confront these situations without having to completely abandon the use of either parametric or nonparametric methodologies, effectively operating within the grey spectrum of mathematical modeling. While we explored in detail the robustness of the hybrid method to large levels of parameter uncertainty in the mechanistic portion of the model, its usefulness stretches well beyond that. In some instances, we may only have a model for some of the states, or portions of the model may have higher error than others. By supplementing these parts with their nonparametric representation, the hybrid method would allow us to only use the parts of the model we are confident in and thus improve our analysis. The quantification of model error and uncertainty is thus an important future direction to incorporate into this hybrid modeling framework. Uncertainty quantification methods will allow us to further evaluate the confidence of the various estimates and predictions. Additionally, incorporating ideas from adaptive filtering [<xref ref-type="bibr" rid="pcbi.1005655.ref038">38</xref>] would give us a framework with which to evaluate the error present during the data fitting process for each model. Leveraging these fields of mathematical analysis would provide us with additional guidance in forming these hybrid models.</p>
</sec>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1005655.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Voss</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Timmer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kurths</surname> <given-names>J</given-names></name>. <article-title>Nonlinear dynamical system identification from uncertain and indirect measurements</article-title>. <source>Int J Bif Chaos</source>. <year>2002</year>;<volume>14</volume>:<fpage>1905</fpage>–<lpage>1924</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1142/S0218127404010345" xlink:type="simple">10.1142/S0218127404010345</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Baake</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Baake</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bock</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Briggs</surname> <given-names>K</given-names></name>. <article-title>Fitting ordinary differential equations to chaotic data</article-title>. <source>Physical Review A</source>. <year>1992</year>;<volume>45</volume>:<fpage>5524</fpage>–<lpage>5529</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevA.45.5524" xlink:type="simple">10.1103/PhysRevA.45.5524</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Farmer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sidorowich</surname> <given-names>J</given-names></name>. <article-title>Predicting chaotic time series</article-title>. <source>Phys Rev Lett</source>. <year>1987</year>;<volume>59</volume>:<fpage>845</fpage>–<lpage>848</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.59.845" xlink:type="simple">10.1103/PhysRevLett.59.845</ext-link></comment> <object-id pub-id-type="pmid">10035887</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Casdagli</surname> <given-names>M</given-names></name>. <article-title>Nonlinear prediction of chaotic time series</article-title>. <source>Physica D: Nonlinear Phenomena</source>. <year>1989</year>;<volume>35</volume>(<issue>3</issue>):<fpage>335</fpage>–<lpage>356</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0167-2789(89)90074-2" xlink:type="simple">10.1016/0167-2789(89)90074-2</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sugihara</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>May</surname> <given-names>RM</given-names></name>. <article-title>Nonlinear forecasting as a way of distinguishing chaos from measurement error in time series</article-title>. <source>Nature</source>. <year>1990</year>;<volume>344</volume>(<issue>6268</issue>):<fpage>734</fpage>–<lpage>741</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/344734a0" xlink:type="simple">10.1038/344734a0</ext-link></comment> <object-id pub-id-type="pmid">2330029</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smith</surname> <given-names>LA</given-names></name>. <article-title>Identification and prediction of low dimensional dynamics</article-title>. <source>Physica D: Nonlinear Phenomena</source>. <year>1992</year>;<volume>58</volume>(<issue>1</issue>):<fpage>50</fpage>–<lpage>76</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0167-2789(92)90101-R" xlink:type="simple">10.1016/0167-2789(92)90101-R</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jimenez</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Moreno</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ruggeri</surname> <given-names>G</given-names></name>. <article-title>Forecasting on chaotic time series: A local optimal linear-reconstruction method</article-title>. <source>Phys Rev A</source>. <year>1992</year>;<volume>45</volume>(<issue>6</issue>):<fpage>3553</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevA.45.3553" xlink:type="simple">10.1103/PhysRevA.45.3553</ext-link></comment> <object-id pub-id-type="pmid">9907403</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref008">
<label>8</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sauer</surname> <given-names>T</given-names></name>. <chapter-title>Time series prediction by using delay coordinate embedding</chapter-title>. In: <source>Time Series Prediction: Forecasting the Future and Understanding the Past</source>. <publisher-name>Addison Wesley</publisher-name>; <year>1994</year>. p. <fpage>175</fpage>–<lpage>193</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sugihara</surname> <given-names>G</given-names></name>. <article-title>Nonlinear forecasting for the classification of natural time series</article-title>. <source>Philosophical Transactions of the Royal Society of London Series A: Physical and Engineering Sciences</source>. <year>1994</year>;<volume>348</volume>(<issue>1688</issue>):<fpage>477</fpage>–<lpage>495</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsta.1994.0106" xlink:type="simple">10.1098/rsta.1994.0106</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schroer</surname> <given-names>CG</given-names></name>, <name name-style="western"><surname>Sauer</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ott</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Yorke</surname> <given-names>JA</given-names></name>. <article-title>Predicting chaos most of the time from embeddings with self-intersections</article-title>. <source>Phys Rev Lett</source>. <year>1998</year>;<volume>80</volume>(<issue>7</issue>):<fpage>1410</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.80.1410" xlink:type="simple">10.1103/PhysRevLett.80.1410</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kugiumtzis</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Lingjærde</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Christophersen</surname> <given-names>N</given-names></name>. <article-title>Regularized local linear prediction of chaotic time series</article-title>. <source>Physica D: Nonlinear Phenomena</source>. <year>1998</year>;<volume>112</volume>(<issue>3</issue>):<fpage>344</fpage>–<lpage>360</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0167-2789(97)00171-1" xlink:type="simple">10.1016/S0167-2789(97)00171-1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yuan</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lozier</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pratt</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Helfrich</surname> <given-names>K</given-names></name>. <article-title>Estimating the predicability of an oceanic time series using linear and nonlinear methods</article-title>. <source>J Geophys Res</source>. <year>2004</year>;<volume>109</volume>:<fpage>C08002</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1029/2003JC002148" xlink:type="simple">10.1029/2003JC002148</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hsieh</surname> <given-names>CH</given-names></name>, <name name-style="western"><surname>Glaser</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Lucas</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Sugihara</surname> <given-names>G</given-names></name>. <article-title>Distinguishing random environmental fluctuations from ecological catastrophes for the North Pacific Ocean</article-title>. <source>Nature</source>. <year>2005</year>;<volume>435</volume>(<issue>7040</issue>):<fpage>336</fpage>–<lpage>340</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature03553" xlink:type="simple">10.1038/nature03553</ext-link></comment> <object-id pub-id-type="pmid">15902256</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Strelioff</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Hübler</surname> <given-names>AW</given-names></name>. <article-title>Medium-term prediction of chaos</article-title>. <source>Phys Rev Lett</source>. <year>2006</year>;<volume>96</volume>(<issue>4</issue>):<fpage>044101</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.96.044101" xlink:type="simple">10.1103/PhysRevLett.96.044101</ext-link></comment> <object-id pub-id-type="pmid">16486826</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Regonda</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rajagopalan</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Lall</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Moon</surname> <given-names>YI</given-names></name>. <article-title>Local polynomial method for ensemble forecast of time series</article-title>. <source>Nonlin Proc in Geophys</source>. <year>2005</year>;<volume>12</volume>:<fpage>397</fpage>–<lpage>406</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.5194/npg-12-397-2005" xlink:type="simple">10.5194/npg-12-397-2005</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref016">
<label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Schelter</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Winterhalder</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Timmer</surname> <given-names>J</given-names></name>. <source>Handbook of time series analysis: recent theoretical developments and applications</source>. <publisher-name>John Wiley and Sons</publisher-name>; <year>2006</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hamilton</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sauer</surname> <given-names>T</given-names></name>. <article-title>Ensemble Kalman filtering without a model</article-title>. <source>Physcial Review X</source>. <year>2016</year>;<volume>6</volume>:<fpage>011021</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevX.6.011021" xlink:type="simple">10.1103/PhysRevX.6.011021</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hamilton</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sauer</surname> <given-names>T</given-names></name>. <article-title>Predicting chaotic time series with a partial model</article-title>. <source>Physical Review E</source>. <year>2015</year>;<volume>92</volume>(<issue>1</issue>):<fpage>010902</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.92.010902" xlink:type="simple">10.1103/PhysRevE.92.010902</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berry</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Harlim</surname> <given-names>J</given-names></name>. <article-title>Semiparametric forecasting and filtering: correcting low-dimensional model error in parametric models</article-title>. <source>Journal of Computational Physics</source>. <year>2016</year>;<volume>308</volume>:<fpage>305</fpage>–<lpage>321</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jcp.2015.12.043" xlink:type="simple">10.1016/j.jcp.2015.12.043</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bohlin</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Graebe</surname> <given-names>S</given-names></name>. <article-title>Issues in nonlinear stochastic grey box identification</article-title>. <source>International Journal of Adaptive Control and Signal Processing</source>. <year>1995</year>;<volume>9</volume>:<fpage>465</fpage>–<lpage>490</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/acs.4480090603" xlink:type="simple">10.1002/acs.4480090603</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sadegh</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Holst</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Madsen</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Melgaard</surname> <given-names>H</given-names></name>. <article-title>Experiment design for grey box identification</article-title>. <source>International Journal of Adaptive Control and Signal Processing</source>. <year>1995</year>;<volume>9</volume>:<fpage>491</fpage>–<lpage>507</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/acs.4480090604" xlink:type="simple">10.1002/acs.4480090604</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jorgensen</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Hangos</surname> <given-names>K</given-names></name>. <article-title>Grey box modelling for control: qualitative models as a unifying framework</article-title>. <source>International Journal of Adaptive Control and Signal Processing</source>. <year>1995</year>;<volume>9</volume>:<fpage>547</fpage>–<lpage>562</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/acs.4480090607" xlink:type="simple">10.1002/acs.4480090607</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lindskog</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ljung</surname> <given-names>L</given-names></name>. <article-title>Tools for semiphysical modelling</article-title>. <source>International Journal of Adaptive Control and Signal Processing</source>. <year>1995</year>;<volume>9</volume>:<fpage>509</fpage>–<lpage>523</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/acs.4480090605" xlink:type="simple">10.1002/acs.4480090605</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Karny</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Halouskova</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Nedoma</surname> <given-names>P</given-names></name>. <article-title>Recursive approximation by ARX model: A tool for grey box modelling</article-title>. <source>International Journal of Adaptive Control and Signal Processing</source>. <year>1995</year>;<volume>9</volume>:<fpage>525</fpage>–<lpage>546</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/acs.4480090606" xlink:type="simple">10.1002/acs.4480090606</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref025">
<label>25</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hauth</surname> <given-names>J</given-names></name>. <source>Grey-box modelling for nonlinear systems</source>. <publisher-name>The Technical University of Kaiserslautern</publisher-name>; <year>2008</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref026">
<label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Forssell U, Lindskog P. Combining semi-physical and neural network modeling: An example of its usefulness. In: 11th IFAC Symposium on System Identification (SYSID’97); 1997.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref027">
<label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Lindskog P, Sjöberg J. A comparison between semi-physical and black-box neural net modeling: A case study. In: Proc. Int. Conf. Eng. App. Artifical Neural Networks; 1995.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lorenz</surname> <given-names>E</given-names></name>. <article-title>Deterministic nonperiodic flow</article-title>. <source>J Atmos Sci</source>. <year>1963</year>;<volume>20</volume>:<fpage>130</fpage>–<lpage>141</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1175/1520-0469(1963)020%3C0130:DNF%3E2.0.CO;2" xlink:type="simple">10.1175/1520-0469(1963)020%3C0130:DNF%3E2.0.CO;2</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hindmarsh</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rose</surname> <given-names>R</given-names></name>. <article-title>A model of neuronal bursting using three coupled first order differential equations</article-title>. <source>Proc Roy Soc</source>. <year>1984</year>;<volume>221</volume>:<fpage>87</fpage>–<lpage>102</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.1984.0024" xlink:type="simple">10.1098/rspb.1984.0024</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Constantino</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Desharnais</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Cushing</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Dennis</surname> <given-names>B</given-names></name>. <article-title>Chaotic dynamics in an insect population</article-title>. <source>Science</source>. <year>1997</year>;<volume>276</volume>:<fpage>1881</fpage>–<lpage>1882</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref031">
<label>31</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Kalnay</surname> <given-names>E</given-names></name>. <source>Atmospheric modeling, data assimilation, and predictability</source>. <publisher-name>Cambridge Univ. Press</publisher-name>; <year>2003</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref032">
<label>32</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Evensen</surname> <given-names>G</given-names></name>. <source>Data assimilation: The Ensemble Kalman Filter</source>. <publisher-name>Springer</publisher-name>: <publisher-loc>Heidelberg</publisher-loc>; <year>2009</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rabier</surname> <given-names>F</given-names></name>. <article-title>Overview of global data assimilation developments in numerical weather-prediction centres</article-title>. <source>Quarterly Journal of the Royal Meteorological Society</source>. <year>2005</year>;<volume>131</volume>(<issue>613</issue>):<fpage>3215</fpage>–<lpage>3233</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1256/qj.05.129" xlink:type="simple">10.1256/qj.05.129</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cummings</surname> <given-names>JA</given-names></name>. <article-title>Operational multivariate ocean data assimilation</article-title>. <source>Quarterly Journal of the Royal Meteorological Society</source>. <year>2005</year>;<volume>131</volume>(<issue>613</issue>):<fpage>3583</fpage>–<lpage>3604</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1256/qj.05.105" xlink:type="simple">10.1256/qj.05.105</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yoshida</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Yamaguchi</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kaneda</surname> <given-names>Y</given-names></name>. <article-title>Regeneration of Small Eddies by Data Assimilation in Turbulence</article-title>. <source>Phys Rev Lett</source>. <year>2005</year>;<volume>94</volume>:<fpage>014501</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.94.014501" xlink:type="simple">10.1103/PhysRevLett.94.014501</ext-link></comment> <object-id pub-id-type="pmid">15698086</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Law</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Stuart</surname> <given-names>A</given-names></name>. <article-title>Evaluating data stimulation algorithms</article-title>. <source>Mon Wea Rev</source>. <year>2012</year>;<volume>140</volume>:<fpage>3757</fpage>–<lpage>3782</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1175/MWR-D-11-00257.1" xlink:type="simple">10.1175/MWR-D-11-00257.1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref037">
<label>37</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Schiff</surname> <given-names>SJ</given-names></name>. <source>Neural control engineering</source>. <publisher-name>MIT Press</publisher-name>; <year>2012</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berry</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Sauer</surname> <given-names>T</given-names></name>. <article-title>Adaptive ensemble Kalman filtering of nonlinear systems</article-title>. <source>Tellus A</source>. <year>2013</year>;<volume>65</volume>:<fpage>20331</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3402/tellusa.v65i0.20331" xlink:type="simple">10.3402/tellusa.v65i0.20331</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hamilton</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Cressman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Peixoto</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Sauer</surname> <given-names>T</given-names></name>. <article-title>Reconstructing neural dynamics using data assimilation with multiple models</article-title>. <source>Europhysics Letters</source>. <year>2014</year>;<volume>107</volume>:<fpage>68005</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1209/0295-5075/107/68005" xlink:type="simple">10.1209/0295-5075/107/68005</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hamilton</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Peixoto</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Sauer</surname> <given-names>T</given-names></name>. <article-title>Real-time tracking of neuronal network structure using data assimilation</article-title>. <source>Physical Review E</source>. <year>2013</year>;<volume>88</volume>:<fpage>052715</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.88.052715" xlink:type="simple">10.1103/PhysRevE.88.052715</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ullah</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Schiff</surname> <given-names>S</given-names></name>. <article-title>Tracking and control of neuronal Hodgkin-Huxley dynamics</article-title>. <source>Phys Rev E</source>. <year>2009</year>;<volume>79</volume>:<fpage>040901</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.79.040901" xlink:type="simple">10.1103/PhysRevE.79.040901</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ullah</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Schiff</surname> <given-names>S</given-names></name>. <article-title>Assimilating seizure dynamics</article-title>. <source>PLoS Computational Biology</source>. <year>2010</year>;<volume>6</volume>:<fpage>e1000776</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000776" xlink:type="simple">10.1371/journal.pcbi.1000776</ext-link></comment> <object-id pub-id-type="pmid">20463875</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sitz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schwarz</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Kurths</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Voss</surname> <given-names>H</given-names></name>. <article-title>Estimation of parameters and unobserved components for nonlinear systems from noisy time series</article-title>. <source>Physical Review E</source>. <year>2002</year>;<volume>66</volume>:<fpage>16210</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.66.016210" xlink:type="simple">10.1103/PhysRevE.66.016210</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref044">
<label>44</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Simon</surname> <given-names>D</given-names></name>. <source>Optimal State Estimation: Kalman, H<sub>∞</sub>, and Nonlinear Approaches</source>. <publisher-name>John Wiley and Sons</publisher-name>; <year>2006</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Julier</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Uhlmann</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Durrant-Whyte</surname> <given-names>H</given-names></name>. <article-title>A new method for the nonlinear transformation of means and covariances in filters and estimators</article-title>. <source>IEEE Trans Automat Control</source>. <year>2000</year>;<volume>45</volume>:<fpage>477</fpage>–<lpage>482</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/9.847726" xlink:type="simple">10.1109/9.847726</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Julier</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Uhlmann</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Durrant-Whyte</surname> <given-names>H</given-names></name>. <article-title>Unscented filtering and nonlinear estimation</article-title>. <source>Proc IEEE</source>. <year>2004</year>;<volume>92</volume>:<fpage>401</fpage>–<lpage>422</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/JPROC.2004.837637" xlink:type="simple">10.1109/JPROC.2004.837637</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref047">
<label>47</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Takens</surname> <given-names>F</given-names></name>. <source>Detecting strange attractors in turbulence</source>. Lecture Notes in Math <publisher-name>Springer-Verlag</publisher-name>: <publisher-loc>Berlin</publisher-loc>. <year>1981</year>;<volume>898</volume>:<fpage>366</fpage>–<lpage>381</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sauer</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Yorke</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Casdagli</surname> <given-names>M</given-names></name>. <article-title>Embedology</article-title>. <source>J Stat Phys</source>. <year>1991</year>;<volume>65</volume>:<fpage>579</fpage>–<lpage>616</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF01053745" xlink:type="simple">10.1007/BF01053745</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Perretti</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Munch</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sugihara</surname> <given-names>G</given-names></name>. <article-title>Model-free forecasting outperforms the correct mechanistic model for simulated and experimental data</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2013</year>;<volume>110</volume>:<fpage>5253</fpage>–<lpage>5257</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1216076110" xlink:type="simple">10.1073/pnas.1216076110</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Perretti</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sugihara</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Munch</surname> <given-names>S</given-names></name>. <article-title>Nonparametric forecasting outperforms parametric methods for a simulated multispecies system</article-title>. <source>Ecology</source>. <year>2013</year>;<volume>94</volume>:<fpage>794</fpage>–<lpage>800</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1890/12-0904.1" xlink:type="simple">10.1890/12-0904.1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Abarbanel</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Sidorowich</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Tsimring</surname> <given-names>L</given-names></name>. <article-title>The analysis of observed chaotic data in physical systems</article-title>. <source>Reviews of Modern Physics</source>. <year>1993</year>;<volume>65</volume>:<fpage>1331</fpage>–<lpage>1392</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/RevModPhys.65.1331" xlink:type="simple">10.1103/RevModPhys.65.1331</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Albano</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Passamante</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Farrell</surname> <given-names>M</given-names></name>. <article-title>Using higher-order correlations to define an embedding window</article-title>. <source>Physica D</source>. <year>1991</year>;<volume>54</volume>:<fpage>85</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0167-2789(91)90110-U" xlink:type="simple">10.1016/0167-2789(91)90110-U</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liebert</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Pawelzik</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Schuster</surname> <given-names>H</given-names></name>. <article-title>Optimal embeddings of chaotic attractors from topological considerations</article-title>. <source>Europhysics Letters</source>. <year>1991</year>;<volume>14</volume>:<fpage>521</fpage>–<lpage>526</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1209/0295-5075/14/6/004" xlink:type="simple">10.1209/0295-5075/14/6/004</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Buzug</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Pfister</surname> <given-names>G</given-names></name>. <article-title>Comparison of algorithms calculating optimal embedding parameters for delay time coordinates</article-title>. <source>Physica D</source>. <year>1992</year>;<volume>58</volume>:<fpage>127</fpage>–<lpage>137</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0167-2789(92)90104-U" xlink:type="simple">10.1016/0167-2789(92)90104-U</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rosenstein</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Collins</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Luca</surname> <given-names>CD</given-names></name>. <article-title>Reconstruction expansion as a geometry-based framework for choosing proper delay times</article-title>. <source>Physica D</source>. <year>1994</year>;<volume>73</volume>:<fpage>82</fpage>–<lpage>98</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0167-2789(94)90226-7" xlink:type="simple">10.1016/0167-2789(94)90226-7</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kember</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Fowler</surname> <given-names>A</given-names></name>. <article-title>A correlation function for choosing time delays in phase portrait reconstructions</article-title>. <source>Physics Letters A</source>. <year>1993</year>;<volume>179</volume>:<fpage>72</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0375-9601(93)90653-H" xlink:type="simple">10.1016/0375-9601(93)90653-H</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kugiumtzis</surname> <given-names>D</given-names></name>. <article-title>State space reconstruction parameters in the analysis of chaotic time series- the role of time window length</article-title>. <source>Physica D</source>. <year>1996</year>;<volume>95</volume>:<fpage>13</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0167-2789(96)00054-1" xlink:type="simple">10.1016/0167-2789(96)00054-1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kim</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Eykholt</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Salas</surname> <given-names>J</given-names></name>. <article-title>Nonlinear dynamics, delay times, and embedding windows</article-title>. <source>Physica D</source>. <year>1999</year>;<volume>127</volume>:<fpage>48</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0167-2789(98)00240-1" xlink:type="simple">10.1016/S0167-2789(98)00240-1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005655.ref059">
<label>59</label>
<mixed-citation publication-type="other" xlink:type="simple">Hamilton F, Berry T, Sauer T. Kalman-Takens filtering in the presence of dynamical noise. To appear, European Physical Journal;.</mixed-citation>
</ref>
<ref id="pcbi.1005655.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hartig</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Dormann</surname> <given-names>C</given-names></name>. <article-title>Does model-free forecasting really outperform the true model?</article-title> <source>Proceedings of the National Academy of Sciences</source>. <year>2013</year>;<volume>110</volume>:<fpage>E3975</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1308603110" xlink:type="simple">10.1073/pnas.1308603110</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>
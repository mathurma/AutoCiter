<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
   <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
         <publisher-name>Public Library of Science</publisher-name>
         <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
   <article-meta><article-id pub-id-type="publisher-id">10-PLCB-RA-2586R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1001047</article-id><article-categories>
         <subj-group subj-group-type="heading">
            <subject>Research Article</subject>
         </subj-group>
         <subj-group subj-group-type="Discipline">
<subject>Computational Biology/Protein Homology Detection</subject>
         </subj-group>
      </article-categories><title-group><article-title>Detecting Remote Evolutionary Relationships among Proteins by Large-Scale Semantic Embedding</article-title><alt-title alt-title-type="running-head">Detecting Remote Evolutionary Relationships</alt-title></title-group><contrib-group>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Melvin</surname><given-names>Iain</given-names></name>
            <xref ref-type="aff" rid="aff1"><sup>1</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Weston</surname><given-names>Jason</given-names></name>
            <xref ref-type="aff" rid="aff2"><sup>2</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Noble</surname><given-names>William Stafford</given-names></name>
            <xref ref-type="aff" rid="aff3"><sup>3</sup></xref>
            <xref ref-type="corresp" rid="cor1"><sup>*</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Leslie</surname><given-names>Christina</given-names></name>
            <xref ref-type="aff" rid="aff4"><sup>4</sup></xref>
            <xref ref-type="corresp" rid="cor1"><sup>*</sup></xref>
         </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>NEC Laboratories America, Princeton, New Jersey, United States of America</addr-line>
      </aff><aff id="aff2"><label>2</label><addr-line>Google, New York, New York, United States of America</addr-line>
      </aff><aff id="aff3"><label>3</label><addr-line>Department of Genome Sciences, University of Washington, Seattle, Washington, United States of America</addr-line>
      </aff><aff id="aff4"><label>4</label><addr-line>Computational Biology Program, Memorial Sloan-Kettering Cancer Center, New York, New York, United States of America</addr-line>
      </aff><contrib-group>
         <contrib contrib-type="editor" xlink:type="simple">
            <name name-style="western"><surname>Levitt</surname><given-names>Michael</given-names></name>
            <role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib>
      </contrib-group><aff id="edit1">Stanford University, United States of America</aff><author-notes>
         <corresp id="cor1">* E-mail: <email xlink:type="simple">william-noble@u.washington.edu (WSN)</email> (WN); <email xlink:type="simple">cleslie@cbio.mskcc.org (CL)</email> (CL)</corresp>
         <fn fn-type="con">
            <p>Conceived and designed the experiments: JW WSN CL. Performed the experiments: IM. Analyzed the data: IM JW. Wrote the paper: IM JW WSN CL.</p>
         </fn>
      <fn fn-type="conflict">
         <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
         <month>1</month>
         <year>2011</year>
      </pub-date><pub-date pub-type="epub">
         <day>27</day>
         <month>1</month>
         <year>2011</year>
      </pub-date><volume>7</volume><issue>1</issue><elocation-id>e1001047</elocation-id><history>
         <date date-type="received">
            <day>24</day>
            <month>7</month>
            <year>2010</year>
         </date>
         <date date-type="accepted">
            <day>2</day>
            <month>12</month>
            <year>2010</year>
         </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Melvin et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
         <p>Virtually every molecular biologist has searched a protein or DNA sequence database to find sequences that are evolutionarily related to a given query. Pairwise sequence comparison methods—i.e., measures of similarity between query and target sequences—provide the engine for sequence database search and have been the subject of 30 years of computational research. For the difficult problem of detecting remote evolutionary relationships between protein sequences, the most successful pairwise comparison methods involve building <italic>local</italic> models (e.g., profile hidden Markov models) of protein sequences. However, recent work in massive data domains like web search and natural language processing demonstrate the advantage of exploiting the <italic>global</italic> structure of the data space. Motivated by this work, we present a large-scale algorithm called P<sc>rot</sc>E<sc>mbed</sc>, which learns an embedding of protein sequences into a low-dimensional “semantic space.” Evolutionarily related proteins are embedded in close proximity, and additional pieces of evidence, such as 3D structural similarity or class labels, can be incorporated into the learning process. We find that P<sc>rot</sc>E<sc>mbed</sc> achieves superior accuracy to widely used pairwise sequence methods like PSI-BLAST and HHSearch for remote homology detection; it also outperforms our previous R<sc>ank</sc>P<sc>rop</sc> algorithm, which incorporates global structure in the form of a protein similarity network. Finally, the P<sc>rot</sc>E<sc>mbed</sc> embedding space can be visualized, both at the global level and local to a given query, yielding intuition about the structure of protein sequence space.</p>
      </abstract><abstract abstract-type="summary">
         <title>Author Summary</title>
         <p>Searching a protein or DNA sequence database to find sequences that are evolutionarily related to a query is one of the foundational problems in computational biology. These database searches rely on pairwise comparisons of sequence similarity between the query and targets, but despite years of method refinements, pairwise comparisons still often fail to detect more distantly related targets. In this study, we adapt recent work from natural language processing to exploit the global structure of the data space in this detection problem. In particular, we borrow the idea of a semantic embedding, where by training on a large text data set, one learns an embedding of words into a low-dimensional semantic space such that words embedded close to each other are likely to be semantically related. We present the ProtEmbed algorithm, which learns an embedding of protein sequences into a semantic space where evolutionarily-related proteins are embedded in close proximity. The flexible training algorithm allows additional pieces of evidence, such as 3D structural information, to be incorporated in the learning process and enables ProtEmbed to achieve state-of-the-art performance for the task of detecting targets that have remote evolutionary relationships to the query.</p>
      </abstract><funding-group><funding-statement>This work was supported by NIH grant R01GM074257. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
<page-count count="8"/>
</counts></article-meta>
</front>
<body>
   <sec id="s1">
      <title>Introduction</title>
      <p>Using sequence similarity between proteins to detect evolutionary relationships—protein homology detection—is one of the most fundamental and longest studied problems in computational biology. A protein's function is strongly correlated with its 3D structure, and due to evolutionary pressure, protein structures diverge much more slowly than primary sequences. Because protein sequence data will always be far more abundant than high-quality 3D structural data, the computational challenge is to infer evolutionarily conserved structure and function from subtle sequence similarities. When the evolutionary distance is large and the sequence signal faint—so-called <italic>remote homology detection</italic>—this problem is still unsolved.</p>
      <p>Stated in purely computational terms, remote homology detection involves searching a protein database for sequences that are evolutionarily related (even remotely) to a given query sequence. Most work in this area has focused on developing more sensitive pairwise comparisons between the query and target sequences, including sequence-sequence local alignments (BLAST <xref ref-type="bibr" rid="pcbi.1001047-Altschul1">[1]</xref>, Smith-Waterman <xref ref-type="bibr" rid="pcbi.1001047-Smith1">[2]</xref>); profile-sequence (PSI-BLAST <xref ref-type="bibr" rid="pcbi.1001047-Altschul2">[3]</xref>) and HMM-sequence comparisons (HMMER <xref ref-type="bibr" rid="pcbi.1001047-Eddy1">[4]</xref>); and, most recently, profile-profile <xref ref-type="bibr" rid="pcbi.1001047-Rychlewski1">[5]</xref> and HMM-HMM (HHPred/HHSearch <xref ref-type="bibr" rid="pcbi.1001047-Soding1">[6]</xref>) comparisons. From a machine learning point of view, these recent methods involve building a model of the <italic>neighborhood</italic> of the query and of the target in protein sequence space and using the local neighborhood models to compute a better similarity measure. However, recent advances in massive data domains such as web search and natural language processing suggest that the <italic>global</italic> structure of the data space can also be exploited. For example, motivated by the success of Google's PageRank algorithm, we previously developed R<sc>ank</sc>P<sc>rop</sc> <xref ref-type="bibr" rid="pcbi.1001047-Weston1">[7]</xref>, an algorithm that uses graph diffusion on the <italic>protein similarity network</italic>, defined on a large protein sequence database, in order to re-rank target sequences relative to the query and substantially improve remote homology detection.</p>
      <p>In the current study, we are motivated by large-scale learning of language models in recent work in natural language processing (NLP) <xref ref-type="bibr" rid="pcbi.1001047-Bai1">[8]</xref>. This NLP work exploited large online text data sets (e.g., Wikipedia) to learn an <italic>embedding</italic> of words into a low-dimensional semantic space, inducing an embedding of sentence fragments. The embedding algorithm iteratively pushes pairs of real sentence fragments together and pulls pairs of real and randomized sentence fragments apart. Thus, at the end of training, words that are near each other in the embedding space are likely to be semantically related. Moreover, the embedding representation can be leveraged to simultaneously train models to solve multiple NLP tasks, using the framework of multitask learning <xref ref-type="bibr" rid="pcbi.1001047-Collobert1">[9]</xref>.</p>
      <p>Here, we present an algorithm called P<sc>rot</sc>E<sc>mbed</sc> that learns an embedding of protein domain sequences into a semantic space such that proximity in the embedding space captures homology relationships. After this large-scale training procedure, remote homologs of a query sequence can be detected by mapping the query to the embedding space and retrieving its nearest neighbors. Furthermore, as in the NLP case, we can use multitask learning to incorporate auxiliary information, where available, to improve the embedding, including structural class labels from databases such as SCOP <xref ref-type="bibr" rid="pcbi.1001047-Murzin1">[10]</xref> or structural similarity scores for pairs of training examples where both 3D structures are known. It is important to note that our embedding is defined naturally on protein domain sequences rather than multidomain sequences. In particular, inclusion of multidomain sequences in the training data can lead to incompatible distance relationships in the semantic space due to lack of transitivity, resulting in a worse embedding. At testing time, it may be possible to resolve the domain structure of a multidomain query sequence using the learned embedding (see <xref ref-type="sec" rid="s4">Discussion</xref>); however, we only evaluate performance on domain sequence queries in the current study.</p>
      <p>We show that P<sc>rot</sc>E<sc>mbed</sc> achieves state-of-the-art performance for remote protein homology detection, outperforming our previous algorithm R<sc>ank</sc>P<sc>rop</sc>, which also exploits global structure but uses a <italic>fixed</italic> weighted similarity network rather than a <italic>learned</italic> embedding. Our procedure also yields statistical confidence estimates and enables a visualization of the learned protein embedding space, giving new intuition about the global structure of the protein sequence space.</p>
   </sec>
   <sec id="s2" sec-type="methods">
      <title>Methods</title>
      <sec id="s2a">
         <title>Semantic protein indexing</title>
         <p>The main idea of our approach is to learn a mapping of protein domain sequences into a vector space that captures their “semantic similarity”, i.e. closeness in the semantic space should reflect homology relationships between sequences.</p>
         <p>In order to learn an embedding of protein sequences into a semantic space, we need to define (i) a feature representation for proteins, (ii) a training signal that determines whether a given pair of training sequences are similar and should be pushed together by the algorithm, or dissimilar and should be pulled apart, and (iii) an algorithm that learns an appropriate embedding.</p>
         <p>Let us denote the set of proteins in the database as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e001" xlink:type="simple"/></inline-formula> and a query protein as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e002" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e003" xlink:type="simple"/></inline-formula> is the set of all possible sequences of amino acids. We then choose a feature map <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e004" xlink:type="simple"/></inline-formula> to represent proteins as vectors. This map is necessary so that we can perform geometric operations on proteins. We use the following representation for a protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e005" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e006" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e007" xlink:type="simple"/></inline-formula> is the E-value returned by a surrogate protein alignment algorithm, such as PSI-BLAST, suitably transformed. Following R<sc>ankprop</sc> <xref ref-type="bibr" rid="pcbi.1001047-Weston1">[7]</xref>, we use the following transformation:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e008" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e009" xlink:type="simple"/></inline-formula> is the PSI-BLAST E-value assigned to protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e010" xlink:type="simple"/></inline-formula> given query <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e011" xlink:type="simple"/></inline-formula> and where we set the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e012" xlink:type="simple"/></inline-formula>. This transformation yields a stochastic connectivity matrix; i.e., the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e013" xlink:type="simple"/></inline-formula> can be interpreted as the probability that a random walk on the protein similarity network will choose to move from protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e014" xlink:type="simple"/></inline-formula> to protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e015" xlink:type="simple"/></inline-formula>. Note that, because most protein pairs exhibit no detectable similarity according to an algorithm such as PSI-BLAST, most feature values are zero. (Specifically, PSI-BLAST assigns a large maximal E-value to all database sequences for which no homology to the query is detected, and the exponential transfer function converts these values to zero.) The sparseness of the feature vectors will be important for computational reasons.</p>
         <p>Next, we again use a surrogate protein alignment algorithm, this time as a <italic>teacher</italic> to provide a noisy training signal. We construct a training set of tuples <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e016" xlink:type="simple"/></inline-formula>, where each tuple contains a query <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e017" xlink:type="simple"/></inline-formula>, a related protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e018" xlink:type="simple"/></inline-formula> and an unrelated (or lower ranked) protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e019" xlink:type="simple"/></inline-formula>. The tuples themselves are collected by running PSI-BLAST in an all-versus-all fashion over the database of proteins. Taking any given protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e020" xlink:type="simple"/></inline-formula> as the query, we consider any protein with an E-value lower than 0.1 to be a similar protein (instance of a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e021" xlink:type="simple"/></inline-formula>); in the current implementation, instances of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e022" xlink:type="simple"/></inline-formula> are chosen randomly from all training examples and with high probability will be dissimilar to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e023" xlink:type="simple"/></inline-formula>. We can then, in principle, construct all possible combinations (tuples) from which we sample randomly during online training.</p>
         <p>Given the feature vectors and the training tuples, our aim is to learn a feature embedding that performs well for protein ranking and classification tasks. We will learn an embedding function<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e024" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e025" xlink:type="simple"/></inline-formula> is an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e026" xlink:type="simple"/></inline-formula> matrix, resulting in an embedding <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e027" xlink:type="simple"/></inline-formula>. Typically, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e028" xlink:type="simple"/></inline-formula> is chosen to be low dimensional, e.g. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e029" xlink:type="simple"/></inline-formula>. The learning procedure consists of finding a matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e030" xlink:type="simple"/></inline-formula> such that similar proteins have close proximity in the embedding space. Specifically, we would like to choose <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e031" xlink:type="simple"/></inline-formula> such that, for all tuples <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e032" xlink:type="simple"/></inline-formula>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e033" xlink:type="simple"/></disp-formula>expressing that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e034" xlink:type="simple"/></inline-formula> should be ranked higher than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e035" xlink:type="simple"/></inline-formula>, relative to an appropriate distance measure <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e036" xlink:type="simple"/></inline-formula> in the embedding space. We define this distance measure using the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e037" xlink:type="simple"/></inline-formula>-norm (which is defined as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e038" xlink:type="simple"/></inline-formula>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e039" xlink:type="simple"/></disp-formula></p>
         <p>After training, given a query protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e040" xlink:type="simple"/></inline-formula>, we will rank the database using the ranking score:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e041" xlink:type="simple"/></disp-formula>where we consider smaller values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e042" xlink:type="simple"/></inline-formula> to be more highly ranked.</p>
         <p>The training objective employs the margin ranking loss <xref ref-type="bibr" rid="pcbi.1001047-Herbrich1">[11]</xref>, which has been used successfully in the field of information retrieval to rank documents given a query <xref ref-type="bibr" rid="pcbi.1001047-Joachims1">[12]</xref>–<xref ref-type="bibr" rid="pcbi.1001047-Grangier1">[14]</xref>. That is, we minimize:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e043" xlink:type="simple"/><label>(1)</label></disp-formula>which encourages <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e044" xlink:type="simple"/></inline-formula> to be smaller than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e045" xlink:type="simple"/></inline-formula> until a margin constraint of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e046" xlink:type="simple"/></inline-formula> is satisfied. Intuitively, the algorithm tries to push <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e047" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e048" xlink:type="simple"/></inline-formula> together while pulling <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e049" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e050" xlink:type="simple"/></inline-formula> apart, until the difference in distances achieves a margin of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e051" xlink:type="simple"/></inline-formula>. For an equivalent formulation, we can introduce a slack variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e052" xlink:type="simple"/></inline-formula> for each tuple <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e053" xlink:type="simple"/></inline-formula> and enforce the constraints<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e054" xlink:type="simple"/></disp-formula>for all tuples while minimizing the objective function<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e055" xlink:type="simple"/></disp-formula></p>
         <p>This optimization problem is solved using stochastic gradient descent <xref ref-type="bibr" rid="pcbi.1001047-Burges1">[13]</xref>: iteratively, one picks a random tuple <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e056" xlink:type="simple"/></inline-formula> and, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e057" xlink:type="simple"/></inline-formula>, makes a gradient step for that tuple as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e058" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e059" xlink:type="simple"/></inline-formula> denotes that the sign function is applied componentwise to the vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e060" xlink:type="simple"/></inline-formula> to yield a vector of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e061" xlink:type="simple"/></inline-formula> values. Pseudocode for training the P<sc>rot</sc>E<sc>mbed</sc> embedding is given in Algorithm 1 in <xref ref-type="supplementary-material" rid="pcbi.1001047.s001">Text S1</xref>.</p>
         <p>One can exploit the sparsity of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e062" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e063" xlink:type="simple"/></inline-formula> when calculating these updates to make them computationally cheap. To train our model, we choose the (fixed) learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e064" xlink:type="simple"/></inline-formula> that minimizes the training error, i.e. the loss defined by equation (1). We initialize the matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e065" xlink:type="simple"/></inline-formula> randomly using a normal distribution with mean zero and standard deviation one. Overall, stochastic training is highly scalable and is easy to implement for our model, and learning can scale to millions of proteins.</p>
         <p>After training, we precompute the embedding <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e066" xlink:type="simple"/></inline-formula> for every protein in the database. At test time, given a query protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e067" xlink:type="simple"/></inline-formula>, we compute its linear embedding once. Then we are left with only <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e068" xlink:type="simple"/></inline-formula> operations per protein in the database to perform when retrieving results for that query.</p>
      </sec>
      <sec id="s2b">
         <title>Adding information about protein structure</title>
         <p>In general, recognizing remote homology relationships among protein structures is easier than recognizing remote homologies based only on protein sequences. Although structural information is available for only a subset of the proteins in the database, we would like to ensure that our embedding captures this structural information in addition to the sequence-based information provided by PSI-BLAST. We consider two sources of structural information: (1) category labels for a given protein and (2) similarity scores between pairs of proteins. For the the category labels, we use the Structural Classification of Proteins (SCOP) <xref ref-type="bibr" rid="pcbi.1001047-Murzin1">[10]</xref>. For pairwise similarity scores, we use pairwise structure alignments of known 3D structures using MAMMOTH <xref ref-type="bibr" rid="pcbi.1001047-Ortiz1">[15]</xref>.</p>
         <p>We incorporate this auxiliary information using the framework of multitask learning: in addition to the main embedding task, we simultaneously learn models to solve additional tasks using appropriate subsets of the training data. The tasks share internal representations learned by the algorithm, in this case, the embedding function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e069" xlink:type="simple"/></inline-formula>. In particular, we pose an auxiliary classification task using SCOP categories, and we pose an auxiliary ranking task using either SCOP category relationships or using MAMMOTH similarities. In all cases, the multitask objective function is simply the sum of the original P<sc>rot</sc>E<sc>mbed</sc> objective function and of that of the auxiliary task. We consider these two task types in turn.</p>
         <p><bold>Class-based data.</bold> For auxiliary data in the form of a class label <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e070" xlink:type="simple"/></inline-formula> for protein <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e071" xlink:type="simple"/></inline-formula> we train an auxiliary classification task that is multitasked with the original P<sc>rot</sc>E<sc>mbed</sc> objective, sharing the same embedding space. For each fold and superfamily class we create a vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e072" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e073" xlink:type="simple"/></inline-formula>, which can be thought of as a set of class centroids. We then would like to satisfy the constraints:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e074" xlink:type="simple"/></disp-formula>That is, proteins belonging to some class should be closer to that class centroid than proteins that do not belong to that class. We train this model using the margin ranking loss as before, and multitask this problem with the original objective using the following updates:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e075" xlink:type="simple"/><label>(3)</label></disp-formula>Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e076" xlink:type="simple"/></inline-formula> is a matrix containing the centroid vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e077" xlink:type="simple"/></inline-formula> as columns, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e078" xlink:type="simple"/></inline-formula> (resp. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e079" xlink:type="simple"/></inline-formula>) is the bit vector of length <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e080" xlink:type="simple"/></inline-formula> whose two non-zero entries are placed at indices for the fold and superfamily of the labeled training example <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e081" xlink:type="simple"/></inline-formula> (resp. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e082" xlink:type="simple"/></inline-formula>). Pseudocode for training the P<sc>rot</sc>E<sc>mbed</sc> embedding with class-based auxiliary data is given in Algorithm 2 in <xref ref-type="supplementary-material" rid="pcbi.1001047.s001">Text S1</xref>.</p>
         <p><bold>Ranking-based data.</bold> For auxiliary data in the form of similarity scores between pairs of proteins, we simply add more ranking constraints into the set of tuples <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e083" xlink:type="simple"/></inline-formula>. That is, we consider additional tuples of the form <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e084" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e085" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e086" xlink:type="simple"/></inline-formula> are similar SCOP proteins based on auxiliary data—i.e., a similarity score comparing these proteins is above a cutoff value—while <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e087" xlink:type="simple"/></inline-formula> is chosen at random from all of SCOP and with high probability will be structurally dissimilar to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e088" xlink:type="simple"/></inline-formula>. Then we require these additional tuples to satisfy constraints of the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e089" xlink:type="simple"/></disp-formula>analogous to the constraints in the main optimization problem. Two examples of the use of such auxiliary constraints are given by using SCOP superfamily labels or MAMMOTH. For SCOP labels, if two proteins are in the same superfamily, we say they are similar. For MAMMOTH, we choose a cutoff value of 2.0, and a pair of proteins that has a structural alignment scoring above this cutoff is deemed to be similar. Pseudocode for training the P<sc>rot</sc>E<sc>mbed</sc> embedding with ranking-based auxiliary data is given in Algorithm 3 in <xref ref-type="supplementary-material" rid="pcbi.1001047.s001">Text S1</xref>.</p>
      </sec>
      <sec id="s2c">
         <title>Data sets</title>
         <p>For labeled data—namely, proteins with structural category labels and 3D structures from which to compute pairwise similarity scores—we used proteins from the SCOP v1.59 protein database. We used ASTRAL <xref ref-type="bibr" rid="pcbi.1001047-Brenner1">[16]</xref> to filter these sequences so that no two sequences share greater than 95% identity. This filtering resulted in 7329 sequences. Our test set consists of 97 proteins selected at random from these SCOP sequences. These test sequences were excluded entirely from the training data.</p>
         <p>For unlabeled data, i.e. protein domain sequences without category labels or structural information, we used sequences from the ADDA domain database version 4 <xref ref-type="bibr" rid="pcbi.1001047-Heger1">[17]</xref> (<ext-link ext-link-type="uri" xlink:href="http://ekhidna.biocenter.helsinki.fi/downloads/adda" xlink:type="simple">http://ekhidna.biocenter.helsinki.fi/downloads/adda</ext-link>). This database contains 3,854,803 single-domain sequences. We removed from the database sequences comprised entirely of the ambiguity code “X,” sequences shorter than 6 amino acids and sequences longer than 10,000 amino acids. We then randomly selected sequences from the remaining sequences until we had picked 3% of the original sequences. This left us with an unlabeled single domain database of 115,644 sequences.</p>
         <p>We ran PSI-BLAST version 2.2.8 on the combined SCOP+ADDA database using the default parameters, allowing a maximum of 6 iterations. For a second and more powerful pairwise sequence similarity method based on HMM-HMM comparisons, we also ran HHSearch version 1.5.0, using default parameters. HHPred/HHSearch is considered a leading method for remote homology detection <xref ref-type="bibr" rid="pcbi.1001047-Soding1">[6]</xref>. When searching for homologs to the test set domains, we added the HHSearch options “-realign -mact 0,” which uses local Viterbi search followed by MAC to realign the proteins globally on a local posterior probability matrix. Similarly, MAMMOTH was run with its default settings.</p>
         <p>We first trained embeddings on SCOP+ADDA (with SCOP test sequences held out) using PSI-BLAST or HHSearch as the pairwise sequence comparison method to serve as “teacher” for producing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e090" xlink:type="simple"/></inline-formula> tuples. In this setting, we did not make use of the category labels or structural information for the SCOP training examples. We then trained embeddings using ADDA as unlabeled data and SCOP as labeled data, where the labeled data was used in (i) an auxiliary classification task based on SCOP category labels or (ii) an auxiliary ranking task based either on SCOP category relationships or on MAMMOTH similarity scores.</p>
      </sec>
   </sec>
   <sec id="s3">
      <title>Results</title>
      <sec id="s3a">
         <title>A two-dimensional embedding of proteins</title>
         <p>As an initial proof-of-concept test of the P<sc>rot</sc>E<sc>mbed</sc> algorithm, we created an embedding of protein domains into a two-dimensional space. This embedding is necessarily underfit, because two dimensions does not provide very much capacity to learn a good embedding. However, a two-dimensional space has the advantage of being easy to visualize. We trained the embedding using the 7329 SCOP proteins from the training set, and then calculated the locations of the all SCOP proteins from all superfamilies with 25 or more members. <xref ref-type="fig" rid="pcbi-1001047-g001">Figure 1</xref> shows these locations. Proteins are colored and labeled according to their SCOP superfamilies. The embedding generally places members of the same superfamily near one another.</p>
         <fig id="pcbi-1001047-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001047.g001</object-id><label>Figure 1</label>
            <caption>
               <title>Visualization of the protein embedding.</title>
               <p>Visualization based on training P<sc>rot</sc>E<sc>mbed</sc> with dimension <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e091" xlink:type="simple"/></inline-formula> and viewing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e092" xlink:type="simple"/></inline-formula> for SCOP proteins from all superfamilies with 25 or more members.</p>
            </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.g001" xlink:type="simple"/></fig>
      </sec>
      <sec id="s3b">
         <title>ProtEmbed provides accurate rankings</title>
         <p>To investigate the ability of P<sc>rot</sc>E<sc>mbed</sc> to rank homologous proteins above non-homologs, we used a gold standard derived from the SCOP database of protein domain structures. We then used PSI-BLAST, Rankprop, HHSearch and P<sc>rot</sc>E<sc>mbed</sc> to rank a collection of 7329 SCOP domain sequences with respect to each of 97 test domains. To provide a rich database in which to perform the search, we augmented the SCOP data set with 115,644 single-domain sequences from the ADDA domain database. In our evaluation, protein domains that reside in the same SCOP superfamily as a query domain are labeled positive, and domains in different folds than that of the query are labeled negative. The remaining sequences—from the same fold but different superfamilies—are ignored, because their homology to the query is uncertain. For each query, traversing the ranked list of labeled sequences induces a receiver operating characteristic (ROC) curve, which plots the percentage of positives as a function of the percentage of negatives observed thus far in the ranked list. We measured the area under this curve up to the first false positive (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e093" xlink:type="simple"/></inline-formula>) or the 50th false positive (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e094" xlink:type="simple"/></inline-formula>). Both scores are normalized such that perfect performance corresponds to a score of 1.0.</p>
         <p>Before training our embedding, we ran a series of cross-validation experiments within the training set to select <italic>hyperparameters</italic>; i.e., parameters that are not subject to optimization. Based on these experiments, we used, for PSI-BLAST, a learning rate of 0.05 and an embedding dimension of 250; and for HHSearch, a learning rate of 0.02 and an embedding dimension of 100. In each case, the training was run for 150 epochs, where one epoch corresponds to 20,000 tuples. We used the same hyperparameters when training with or without the auxiliary, structural information.</p>
         <p><xref ref-type="fig" rid="pcbi-1001047-g002">Figure 2</xref> compares the performance of PSI-BLAST, RankProp, HHSearch and various versions of the P<sc>rot</sc>E<sc>mbed</sc> algorithm. The performance of each algorithm is summarized by the mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e095" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e096" xlink:type="simple"/></inline-formula> score. To establish the statistical significance of the observed differences, we used a Wilcoxon signed-rank test with a 0.05 significance threshold. For both of the performance metrics that we considered, the ranking of the three previously described methods is the same: HHSearch outperforms Rankprop, which outperforms PSI-BLAST. Also, the standard P<sc>rot</sc>E<sc>mbed</sc> algorithm, with no auxiliary data, outperforms PSI-BLAST when it is trained using PSI-BLAST and outperforms HHSearch when it is trained using HHSearch, although for the latter comparison, the difference is only significant for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e097" xlink:type="simple"/></inline-formula> performance metric. <xref ref-type="fig" rid="pcbi-1001047-g002">Figure 2</xref> in <xref ref-type="supplementary-material" rid="pcbi.1001047.s001">Text S1</xref>, which plots the number of queries for which the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e098" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e099" xlink:type="simple"/></inline-formula> score exceeds a given threshold, shows that the differences among methods are not traceable to queries with particularly high or low ROC values; on the contrary, the improvements from one method to the next span the entire range of ROC values.</p>
         <fig id="pcbi-1001047-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001047.g002</object-id><label>Figure 2</label>
            <caption>
               <title>Comparison of mean ROC scores.</title>
               <p>Each node corresponds to a homology detection algorithm, and the value associated with each node is the mean ROC<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e100" xlink:type="simple"/></inline-formula> (A) or ROC<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e101" xlink:type="simple"/></inline-formula> (B) score achieved with respect to 97 test queries. An edge between nodes X and Y indicates that method X performs better than method Y, according to a Wilcoxon signed-rank test with a 0.05 significance threshold.</p>
            </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.g002" xlink:type="simple"/></fig>
         <p><xref ref-type="fig" rid="pcbi-1001047-g002">Figure 2</xref> shows that adding auxiliary, structural information during P<sc>rot</sc>E<sc>mbed</sc> training significantly improves the quality of the resulting rankings. Adding structural information to P<sc>rot</sc>E<sc>mbed</sc> improves the mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e102" xlink:type="simple"/></inline-formula> score by 0.038–0.170 and improves the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e103" xlink:type="simple"/></inline-formula> by 0.083–0.180. Perhaps most strikingly, if we consider P<sc>rot</sc>E<sc>mbed</sc> trained from HHSearch, the initial embedding is 0.154 away from a perfect <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e104" xlink:type="simple"/></inline-formula> score, whereas the embedding learned using SCOP rankings is only 0.025 away from a perfect <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e105" xlink:type="simple"/></inline-formula> score. Thus, in this case, structural information removes 83.7% of the residual error. In general, using SCOP information leads to better rankings than using MAMMOTH. This is not surprising, because we are using a gold standard based on SCOP. Between the two modes of representation, the SCOP ranking appears to give better results than using SCOP class-based structural information. This result is somewhat surprising, because our gold standard is based explicitly on SCOP classes and perhaps suggests that the ranking representation is more resistant to overfitting.</p>
         <p>In evaluations of remote homology detection algorithms, some researchers prefer to ignore members of the same family as the query, since these family members are presumably easy to identify <xref ref-type="bibr" rid="pcbi.1001047-Jaakkola1">[18]</xref>. To ensure that our results are not dependent on family-level information, we repeated the ROC calculations above, but we skipped target proteins that fall into the same family as the query. <xref ref-type="fig" rid="pcbi-1001047-g003">Figure 3</xref> in <xref ref-type="supplementary-material" rid="pcbi.1001047.s001">Text S1</xref> shows that the conclusions above remain unchanged in this setting: P<sc>rot</sc>E<sc>mbed</sc> outperforms HHSearch, RankProp and PSI-BLAST, and using structural information significantly improves ProtEmbed's performance.</p>
         <fig id="pcbi-1001047-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001047.g003</object-id><label>Figure 3</label>
            <caption>
               <title>Combined evaluation across multiple queries.</title>
               <p>Each panel shows a collection of ROC curves, produced by sorting into a single ranked list the results from all 97 test queries. Each series corresponds to a different algorithm. The panel on top (A) includes algorithms based on PSI-BLAST; the panel on the bottom (B) includes algorithms based on HHSearch.</p>
            </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.g003" xlink:type="simple"/></fig>
      </sec>
      <sec id="s3c">
         <title>Calibration of ProtEmbed scores</title>
         <p>Next, we evaluated how well P<sc>rot</sc>E<sc>mbed</sc> scores are calibrated between queries. We say that our scores are well calibrated if pairs of query and target sequences at similar distances from each other in embedding space also have similar degrees of homology, regardless of where the query embeds. If this property holds, then the scores generated by ranking database sequences relative to different queries can be compared to each other and modeled to assign statistical significance.</p>
         <p>The experiment reported in <xref ref-type="fig" rid="pcbi-1001047-g002">Figure 2</xref>, in which ROC scores are computed separately for each query and then averaged, only measures how well the target sequences in the database are ranked relative to each query sequence. To measure the calibration of the scores among queries, we sorted all of the scores from all 97 test queries into a single list. The resulting ROC curves are shown in <xref ref-type="fig" rid="pcbi-1001047-g003">Figure 3</xref>. The overall ranking of methods is the same as in <xref ref-type="fig" rid="pcbi-1001047-g002">Figure 2</xref>, in order of improving performance: PSI-BLAST, Rankprop, HHSearch, ProtEmbed. To obtain calibrated scores, PSI-BLAST, Rankprop and HHSearch include specific calibration procedures—calculation of E-values for PSI-BLAST and HHSearch, and calculation of superfamily probabilities for Rankprop. ProtEmbed, in contrast, requires no explicit calibration procedure; instead, the scores are naturally calibrated because they all correspond to distances in a single embedding space.</p>
         <p>To be useful, a homology detection algorithm must provide scores with well defined semantics. For example, PSI-BLAST reports an expectation value, or E-value, that corresponds to the number of scores as good or better than the observed score that are expected to occur in a random database of the given size <xref ref-type="bibr" rid="pcbi.1001047-Altschul2">[3]</xref>. Rankprop reports for each query-target pair the probability that they belong to the same SCOP superfamily <xref ref-type="bibr" rid="pcbi.1001047-Melvin1">[19]</xref>. To convert P<sc>rot</sc>E<sc>mbed</sc> distances to an interpretable score, we employed a simple empirical null model in which protein sequences are generated by a third-order Markov chain, with parameters derived from the SCOP+ADDA database. We randomly generated decoy protein sequences according to this null model, and we embedded these proteins into the PSI-BLAST P<sc>rot</sc>E<sc>mbed</sc> space. Empirical analysis of the resulting sets of scores (<xref ref-type="fig" rid="pcbi-1001047-g001">Figure 1</xref> in <xref ref-type="supplementary-material" rid="pcbi.1001047.s001">Text S1</xref>) shows that the left tail of the null distribution is well approximated by a Weibull distribution. To compute a <italic>p</italic>-value, we select the null distribution based on the length of the given query sequence. Further details are given in <xref ref-type="supplementary-material" rid="pcbi.1001047.s001">Text S1</xref>.</p>
         <p>We cannot use these <italic>p</italic>-values directly, because we must correct for the large number of tests involved in searching a large sequence database. To do so, we employ standard false discovery rate-based multiple testing correction procedures. In particular, for a given query, we first estimate the percentage <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e106" xlink:type="simple"/></inline-formula> of the observed scores that are drawn according to the null distribution <xref ref-type="bibr" rid="pcbi.1001047-Storey1">[20]</xref>. We then use the Benjamin-Hochberg procedure <xref ref-type="bibr" rid="pcbi.1001047-Benjamini1">[21]</xref> to estimate false discovery rates, including the multiplicative factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e107" xlink:type="simple"/></inline-formula>. Finally, we convert the estimated false discovery rate into a <italic>q</italic>-value <xref ref-type="bibr" rid="pcbi.1001047-Storey1">[20]</xref>, which is defined as the minimum FDR threshold at which an observed score is deemed significant.</p>
      </sec>
      <sec id="s3d">
         <title>Visualizing the results of a query</title>
         <p>For many users of alignment tools such as PSI-BLAST, the multiple alignment produced with respect to a given query is as useful as the rankings and accompanying E-values, because the multiple alignment provides an explanation of the ranking. However, a method like P<sc>rot</sc>E<sc>mbed</sc> does not rely solely on multiple alignments. Therefore, although it would certainly be feasible to create, in a <italic>post hoc</italic> fashion, an alignment of the ranked proteins up to, e.g., a specified P<sc>rot</sc>E<sc>mbed</sc> <italic>q</italic>-value threshold, such a multiple alignment is not likely to accurately reflect the semantics of the P<sc>rot</sc>E<sc>mbed</sc> embedding space. Instead, we propose to use a multidimensional scaling approach to project the top-ranked protein domains into an easy-to-visualize 2D representation.</p>
         <p>To illustrate how effective such a visualization can be, we systematically generated 2D maps of the neighborhood for all 97 test set domains, using a <italic>q</italic>-value threshold of 0.01. Thumbnail versions of all 97 neighborhoods are provided in the supplement.</p>
         <p>Here, we focus on a single example. <xref ref-type="fig" rid="pcbi-1001047-g004">Figure 4</xref> shows the structure learned by the embedding near a particular query, the C-terminal domain of Staphylococcal enterotoxin B (PDB ID 3seb). <xref ref-type="fig" rid="pcbi-1001047-g004">Figure 4(A)</xref> shows the neighborhood of the query relative to the initial PSI-BLAST based feature embedding of the domain sequences, projected into 2D for easier visualization. This mapping corresponds to the initialization of the embedding algorithm, before any training. We see that the other members of the query's family—the superantigen toxins, C-terminal domain (SCOP 1.75 ID d.15.6.1), shown in green—are generally near the query in the initial embedding, but these true positives are intermingled with members of a functionally related but structurally distinct superfamily, the bacterial enterotoxins (SCOP 1.75 ID b.40.2, shown in blue) as well as several members of unrelated superfamilies. When we map the query sequence into the final embedding space (<xref ref-type="fig" rid="pcbi-1001047-g004">Figure 4(B)</xref>), we now find that it lands in a tight cluster of its family members, which is near but separated from the cluster of related bacterial enterotoxins. Meanwhile, unrelated superfamilies are appropriately separated into distinct clusters distant from the query. In this example, the homology detection performance improves from an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e108" xlink:type="simple"/></inline-formula> score of 0.091 (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e109" xlink:type="simple"/></inline-formula> of 0.716) relative to the initial embedding to a perfect <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e110" xlink:type="simple"/></inline-formula> (and perfect <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001047.e111" xlink:type="simple"/></inline-formula>) of 1.0 after training.</p>
         <fig id="pcbi-1001047-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001047.g004</object-id><label>Figure 4</label>
            <caption>
               <title>Neighborhood of a query in the embedding space.</title>
               <p>(A) To visualize the effect of the embedding, we first show a query, the C-terminal domain of Staphylococcal enterotoxin B (PDB ID 3seb), mapped into a metric space according to the PSI-BLAST based feature representation used to initialize the embedding algorithm. (B) The query is now mapped into the final embedding space. In both panels, the query is labeled and indicated with a black circle. All members of the same SCOP family (superantigen toxins, C-terminal domain; SCOP 1.75 ID d.15.6.1), indicated with green triangles, are now in a tight cluster around the query and disambiguated from a distinct but functionally related SCOP superfamily (bacterial enterotoxins; SCOP 1.75 ID b.40.2), indicated with blue squares. Unrelated superfamilies are well separated from the query in the embedding space; members of unrelated SCOP superfamilies are indicated by various colored shapes, as labeled in the right panel.</p>
            </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.g004" xlink:type="simple"/></fig>
      </sec>
   </sec>
   <sec id="s4">
      <title>Discussion</title>
      <p>We have shown that P<sc>rot</sc>E<sc>mbed</sc> <italic>learns</italic> an embedding of protein domain sequences such that proximity in the embedding space reflects homology relationships. Due to efficient stochastic gradient descent methods, the training algorithm can scale to millions of sequences. A flexible multitask framework also enables the use of additional label or ranking information, e.g. protein structural classes or pairwise structural similarity scores, where known, to improve the embedding. Given a test query sequence, its embedding can be computed in the same time that it takes to run the underlying pairwise sequence alignment method. The query's homologs can then be efficiently retrieved by determining the nearby database proteins based on their precomputed embedding coordinates. Moreover, using a faster but less accurate pairwise alignment method, such as PSI-BLAST, together with ProtEmbed, when supplied with labeled data through an auxiliary task, leads to better performance than state-of-the-art but slower pairwise alignments methods, such as HHSearch, used on their own. Moreover, use of more sensitive PSI-BLAST parameters rather than the default choices could potentially further improve the performance of the embedding.</p>
      <p>While alignment-based pairwise sequence similarity scores are used as features for calculating the embedding, P<sc>rot</sc>E<sc>mbed</sc> does not produce multiple sequence alignments for query sequences as an output of its computation. Instead, the embedding neighborhood of the query can be visualized for insight into the relationship between the query and its homologs. For further sequence-based analysis of query-homolog similarities, hits from the P<sc>rot</sc>E<sc>mbed</sc> neighborhood could be used to compute an alignment using standard methods <xref ref-type="bibr" rid="pcbi.1001047-Kemena1">[22]</xref> or newer graph algorithm approaches <xref ref-type="bibr" rid="pcbi.1001047-Heger2">[23]</xref>.</p>
      <p>The P<sc>rot</sc>E<sc>mbed</sc> algorithm learns its embedding on domain sequences rather than full-length protein sequences, because the embedding only makes sense when transitivity relationships hold. For example, a multidomain sequence will have sequence similarity to its constituent domains, which will typically also be represented as entries in the database; if these domains are dissimilar from each other, then the set of pairwise relationships lead to conflicting constraints during training. Nonetheless, it is possible to process a multidomain query sequences using P<sc>rot</sc>E<sc>mbed</sc> by first applying an existing domain decomposition algorithm <xref ref-type="bibr" rid="pcbi.1001047-Yeats1">[24]</xref> and then embedding each domain separately. Alternatively, one could potentially use the embedding to help resolve the domain structure: first, one could run a pairwise alignment method such as PSI-BLAST to determine the start and end positions of all the hits, and then these subsequences could be embedded separately as candidate domain sequences. The <italic>p</italic>-value for the score between the embedded candidate sequence and its nearest neighbor in the database should generally favor candidates with boundaries similar to those of the true domains.</p>
      <p>Protein sequence analysis is one of the oldest subfields of computational biology, with mature and specialized tools designed to describe the <italic>local</italic> structure of protein sequence space. By adapting new techniques from massive data domains such as natural language processing and web search, we have demonstrated that the <italic>global</italic> structural of protein sequence space can be exploited for classical problems like homology detection.</p>
   </sec>
   <sec id="s5">
      <title>Supporting Information</title>
<supplementary-material id="pcbi.1001047.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001047.s001" xlink:type="simple">
<label>Text S1</label>
<caption><p>Supplementary methods and results.</p>
      <p>(1.69 MB PDF)</p></caption></supplementary-material>
   </sec>
</body>
<back>
   <ref-list>
      <title>References</title>
      <ref id="pcbi.1001047-Altschul1">
         <label>1</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Altschul</surname><given-names>SF</given-names></name>
               <name name-style="western"><surname>Gish</surname><given-names>W</given-names></name>
               <name name-style="western"><surname>Miller</surname><given-names>W</given-names></name>
               <name name-style="western"><surname>Myers</surname><given-names>EW</given-names></name>
               <name name-style="western"><surname>Lipman</surname><given-names>DJ</given-names></name>
            </person-group>
            <year>1990</year>
            <article-title>A basic local alignment search tool.</article-title>
            <source>J Mol Biol</source>
            <volume>215</volume>
            <fpage>403</fpage>
            <lpage>410</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Smith1">
         <label>2</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Smith</surname><given-names>T</given-names></name>
               <name name-style="western"><surname>Waterman</surname><given-names>M</given-names></name>
            </person-group>
            <year>1981</year>
            <article-title>Identification of common molecular subsequences.</article-title>
            <source>J Mol Biol</source>
            <volume>147</volume>
            <fpage>195</fpage>
            <lpage>197</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Altschul2">
         <label>3</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Altschul</surname><given-names>SF</given-names></name>
               <name name-style="western"><surname>Madden</surname><given-names>TL</given-names></name>
               <name name-style="western"><surname>Schaffer</surname><given-names>AA</given-names></name>
               <name name-style="western"><surname>Zhang</surname><given-names>J</given-names></name>
               <name name-style="western"><surname>Zhang</surname><given-names>Z</given-names></name>
               <etal/>
            </person-group>
            <year>1997</year>
            <article-title>Gapped BLAST and PSI-BLAST: A new generation of protein database search programs.</article-title>
            <source>Nucleic Acids Res</source>
            <volume>25</volume>
            <fpage>3389</fpage>
            <lpage>3402</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Eddy1">
         <label>4</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Eddy</surname><given-names>SR</given-names></name>
            </person-group>
            <year>1995</year>
            <article-title>Multiple alignment using hidden Markov models.</article-title>
            <person-group person-group-type="editor">
               <name name-style="western"><surname>Rawlings</surname><given-names>C</given-names></name>
            </person-group>
            <source>Proceedings of the Third International Conference on Intelligent Systems for Molecular Biology</source>
            <source>AAAI Press</source>
            <fpage>114</fpage>
            <lpage>120</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Rychlewski1">
         <label>5</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Rychlewski</surname><given-names>L</given-names></name>
               <name name-style="western"><surname>Jaroszewski</surname><given-names>L</given-names></name>
               <name name-style="western"><surname>Li</surname><given-names>W</given-names></name>
               <name name-style="western"><surname>Godzik</surname><given-names>A</given-names></name>
            </person-group>
            <year>2000</year>
            <article-title>Comparison of sequence profiles: Strategies for structural predictions using sequence information.</article-title>
            <source>Protein Sci</source>
            <volume>9</volume>
            <fpage>232</fpage>
            <lpage>241</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Soding1">
         <label>6</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Soding</surname><given-names>J</given-names></name>
               <name name-style="western"><surname>Biegert</surname><given-names>A</given-names></name>
               <name name-style="western"><surname>Lupas</surname><given-names>AN</given-names></name>
            </person-group>
            <year>2005</year>
            <article-title>The HHpred interactive server for protein homology detection and structure prediction.</article-title>
            <source>Nucleic Acids Res</source>
            <volume>33</volume>
            <fpage>W244</fpage>
            <lpage>248</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Weston1">
         <label>7</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Weston</surname><given-names>J</given-names></name>
               <name name-style="western"><surname>Elisseeff</surname><given-names>A</given-names></name>
               <name name-style="western"><surname>Zhou</surname><given-names>D</given-names></name>
               <name name-style="western"><surname>Leslie</surname><given-names>C</given-names></name>
               <name name-style="western"><surname>Noble</surname><given-names>WS</given-names></name>
            </person-group>
            <year>2004</year>
            <article-title>Protein ranking: From local to global structure in the protein similarity network.</article-title>
            <source>Proc Natl Acad Sci U S A</source>
            <volume>101</volume>
            <fpage>6559</fpage>
            <lpage>63</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Bai1">
         <label>8</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Bai</surname><given-names>B</given-names></name>
               <name name-style="western"><surname>Weston</surname><given-names>J</given-names></name>
               <name name-style="western"><surname>Grangier</surname><given-names>D</given-names></name>
               <name name-style="western"><surname>Collobert</surname><given-names>R</given-names></name>
               <name name-style="western"><surname>Sadamasa</surname><given-names>K</given-names></name>
               <etal/>
            </person-group>
            <year>2009</year>
            <article-title>Polynomial semantic indexing.</article-title>
            <person-group person-group-type="editor">
               <name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name>
               <name name-style="western"><surname>Schuurmans</surname><given-names>D</given-names></name>
               <name name-style="western"><surname>Lafferty</surname><given-names>J</given-names></name>
               <name name-style="western"><surname>Williams</surname><given-names>CKI</given-names></name>
               <name name-style="western"><surname>Culotta</surname><given-names>A</given-names></name>
            </person-group>
            <source>Advances in Neural Information Processing Systems 22</source>
            <publisher-loc>Red Hook, NY</publisher-loc>
            <publisher-name>Curran Associates, NIPS 2009</publisher-name>
            <fpage>64</fpage>
            <lpage>72</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Collobert1">
         <label>9</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Collobert</surname><given-names>R</given-names></name>
               <name name-style="western"><surname>Weston</surname><given-names>J</given-names></name>
            </person-group>
            <year>2008</year>
            <article-title>A unified architecture for natural language processing: deep neural networks with multitask learning.</article-title>
            <source>Proceedings of the 25th International Conference on Machine Learning</source>
            <publisher-loc>New York, NY</publisher-loc>
            <publisher-name>ACM, ICML 2008</publisher-name>
            <fpage>160</fpage>
            <lpage>167</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Murzin1">
         <label>10</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Murzin</surname><given-names>AG</given-names></name>
               <name name-style="western"><surname>Brenner</surname><given-names>SE</given-names></name>
               <name name-style="western"><surname>Hubbard</surname><given-names>T</given-names></name>
               <name name-style="western"><surname>Chothia</surname><given-names>C</given-names></name>
            </person-group>
            <year>1995</year>
            <article-title>SCOP: A structural classification of proteins database for the investigation of sequences and structures.</article-title>
            <source>J Mol Biol</source>
            <volume>247</volume>
            <fpage>536</fpage>
            <lpage>540</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Herbrich1">
         <label>11</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Herbrich</surname><given-names>R</given-names></name>
               <name name-style="western"><surname>Graepel</surname><given-names>T</given-names></name>
               <name name-style="western"><surname>Obermayer</surname><given-names>K</given-names></name>
            </person-group>
            <year>2000</year>
            <article-title>Large margin rank boundaries for ordinal regression.</article-title>
            <person-group person-group-type="editor">
               <name name-style="western"><surname>Smola</surname></name>
               <name name-style="western"><surname>Bartlett</surname></name>
               <name name-style="western"><surname>Schoelkopf</surname></name>
               <name name-style="western"><surname>Schuurmans</surname></name>
            </person-group>
            <source>Advances in Large Margin Classifiers</source>
            <publisher-loc>Cambridge, MA</publisher-loc>
            <publisher-name>MIT Press</publisher-name>
            <fpage>115</fpage>
            <lpage>132</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Joachims1">
         <label>12</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Joachims</surname><given-names>T</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>Optimizing search engines using clickthrough data.</article-title>
            <source>Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</source>
            <publisher-loc>New York, NY</publisher-loc>
            <publisher-name>ACM, KDD 2002</publisher-name>
            <fpage>133</fpage>
            <lpage>142</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Burges1">
         <label>13</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Burges</surname><given-names>C</given-names></name>
               <name name-style="western"><surname>Shaked</surname><given-names>T</given-names></name>
               <name name-style="western"><surname>Renshaw</surname><given-names>E</given-names></name>
               <name name-style="western"><surname>Lazier</surname><given-names>A</given-names></name>
               <name name-style="western"><surname>Deeds</surname><given-names>M</given-names></name>
               <etal/>
            </person-group>
            <year>2005</year>
            <article-title>Learning to rank using gradient descent.</article-title>
            <source>Proceedings of the 22nd International Conference on Machine Learning</source>
            <publisher-loc>New York, NY</publisher-loc>
            <publisher-name>ACM, ICML 2005</publisher-name>
            <fpage>89</fpage>
            <lpage>96</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Grangier1">
         <label>14</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Grangier</surname><given-names>D</given-names></name>
               <name name-style="western"><surname>Bengio</surname><given-names>S</given-names></name>
            </person-group>
            <year>2005</year>
            <article-title>Inferring document similarity from hyperlinks.</article-title>
            <source>Proceedings of the 14th ACM International Conference on Information and Knowledge Management</source>
            <publisher-loc>New York, NY</publisher-loc>
            <publisher-name>ACM, CIKM 2005</publisher-name>
            <fpage>359</fpage>
            <lpage>360</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Ortiz1">
         <label>15</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Ortiz</surname><given-names>AR</given-names></name>
               <name name-style="western"><surname>Strauss</surname><given-names>CEM</given-names></name>
               <name name-style="western"><surname>Olmea</surname><given-names>O</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>MAMMOTH (Matching molecular models obtained from theory): An automated method for model comparison.</article-title>
            <source>Protein Sci</source>
            <volume>11</volume>
            <fpage>2606</fpage>
            <lpage>2621</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Brenner1">
         <label>16</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Brenner</surname><given-names>SE</given-names></name>
               <name name-style="western"><surname>Koehl</surname><given-names>P</given-names></name>
               <name name-style="western"><surname>Levitt</surname><given-names>M</given-names></name>
            </person-group>
            <year>2000</year>
            <article-title>The ASTRAL compendium for sequence and structure analysis.</article-title>
            <source>Nucleic Acids Res</source>
            <volume>28</volume>
            <fpage>254</fpage>
            <lpage>256</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Heger1">
         <label>17</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Heger</surname><given-names>A</given-names></name>
               <name name-style="western"><surname>Wilton</surname><given-names>CA</given-names></name>
               <name name-style="western"><surname>Sivakumar</surname><given-names>A</given-names></name>
               <name name-style="western"><surname>Holm</surname><given-names>L</given-names></name>
            </person-group>
            <year>2005</year>
            <article-title>ADDA: a domain database with global coverage of the protein universe.</article-title>
            <source>Nucleic Acids Res</source>
            <volume>33</volume>
            <fpage>188</fpage>
            <lpage>191</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Jaakkola1">
         <label>18</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Jaakkola</surname><given-names>T</given-names></name>
               <name name-style="western"><surname>Diekhans</surname><given-names>M</given-names></name>
               <name name-style="western"><surname>Haussler</surname><given-names>D</given-names></name>
            </person-group>
            <year>1999</year>
            <article-title>Using the Fisher kernel method to detect remote protein homologies.</article-title>
            <source>Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology</source>
            <publisher-loc>Menlo Park, CA</publisher-loc>
            <publisher-name>AAAI Press</publisher-name>
            <fpage>149</fpage>
            <lpage>158</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Melvin1">
         <label>19</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Melvin</surname><given-names>I</given-names></name>
               <name name-style="western"><surname>Weston</surname><given-names>J</given-names></name>
               <name name-style="western"><surname>Leslie</surname><given-names>CS</given-names></name>
               <name name-style="western"><surname>Noble</surname><given-names>WS</given-names></name>
            </person-group>
            <year>2009</year>
            <article-title>RANKPROP: a web server for protein remote homology detection.</article-title>
            <source>Bioinformatics</source>
            <volume>25</volume>
            <fpage>121</fpage>
            <lpage>122</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Storey1">
         <label>20</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Storey</surname><given-names>JD</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>A direct approach to false discovery rates.</article-title>
            <source>J R Stat Soc Series B</source>
            <volume>64</volume>
            <fpage>479</fpage>
            <lpage>498</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Benjamini1">
         <label>21</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Benjamini</surname><given-names>Y</given-names></name>
               <name name-style="western"><surname>Hochberg</surname><given-names>Y</given-names></name>
            </person-group>
            <year>1995</year>
            <article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing.</article-title>
            <source>J R Stat Soc Series B</source>
            <volume>57</volume>
            <fpage>289</fpage>
            <lpage>300</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Kemena1">
         <label>22</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Kemena</surname><given-names>C</given-names></name>
               <name name-style="western"><surname>Notredame</surname><given-names>C</given-names></name>
            </person-group>
            <year>2009</year>
            <article-title>Upcoming challenges for multiple sequence alignment methods in the high-throughput era.</article-title>
            <source>Bioinformatics</source>
            <volume>25</volume>
            <fpage>2455</fpage>
            <lpage>2465</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Heger2">
         <label>23</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Heger</surname><given-names>A</given-names></name>
               <name name-style="western"><surname>Mallick</surname><given-names>S</given-names></name>
               <name name-style="western"><surname>Wilton</surname><given-names>CA</given-names></name>
               <name name-style="western"><surname>Holm</surname><given-names>L</given-names></name>
            </person-group>
            <year>2007</year>
            <article-title>The global trace graph, a novel paradigm for searching protein sequence databases.</article-title>
            <source>Bioinformatics</source>
            <volume>23</volume>
            <fpage>2361</fpage>
            <lpage>2367</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1001047-Yeats1">
         <label>24</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Yeats</surname><given-names>C</given-names></name>
               <name name-style="western"><surname>Redfern</surname><given-names>O</given-names></name>
               <name name-style="western"><surname>Orengo</surname><given-names>CA</given-names></name>
            </person-group>
            <year>2010</year>
            <article-title>A fast and automated solution for accurately resolving protein domain architectures.</article-title>
            <source>Bioinformatics</source>
            <volume>26</volume>
            <fpage>745</fpage>
            <lpage>751</lpage>
         </element-citation>
      </ref>
   </ref-list>
   
</back></article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN"><front><journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pcbi</journal-id><journal-id journal-id-type="flc">plcb</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1371/journal.pcbi.0020152</article-id><article-id pub-id-type="publisher-id">06-PLCB-RA-0207R2</article-id><article-id pub-id-type="sici">plcb-02-11-04</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience</subject><subject>Mental Health/Psychology</subject></subj-group><subj-group subj-group-type="System Taxonomy"><subject>Homo (human)</subject></subj-group></article-categories><title-group><article-title>Humans Can Adopt Optimal Discounting Strategy under Real-Time Constraints</article-title><alt-title alt-title-type="running-head">Optimal Discounting Strategy</alt-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Schweighofer</surname><given-names>N</given-names></name><xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref><xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Shishida</surname><given-names>K</given-names></name><xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Han</surname><given-names>C. E</given-names></name><xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Okamoto</surname><given-names>Y</given-names></name><xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Tanaka</surname><given-names>S. C</given-names></name><xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref><xref ref-type="aff" rid="aff5">
            <sup>5</sup>
          </xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Yamawaki</surname><given-names>S</given-names></name><xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name><xref ref-type="aff" rid="aff5">
            <sup>5</sup>
          </xref><xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref></contrib></contrib-group><aff id="aff1">
				<label>1</label><addr-line> Biokinesiology and Physical Therapy, University of Southern California, Los Angeles, United States of America
			</addr-line></aff><aff id="aff2">
				<label>2</label><addr-line> Department of Psychiatry and Neurosciences, Hiroshima University, Hiroshima, Japan
			</addr-line></aff><aff id="aff3">
				<label>3</label><addr-line> Computer Science, University of Southern California, Los Angeles, United States of America
			</addr-line></aff><aff id="aff4">
				<label>4</label><addr-line> Bioinformatics and Genomics, Nara Institute of Science and Technology, Nara, Japan
			</addr-line></aff><aff id="aff5">
				<label>5</label><addr-line> Department of Computational Neurobiology, Advanced Telecommunications Research Institute International Computational Neuroscience Labs, Kyoto, Japan
			</addr-line></aff><aff id="aff6">
				<label>6</label><addr-line> Initial Research Project, Okinawa Institute of Science and Technology, Okinawa, Japan
			</addr-line></aff><contrib-group><contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes><fn fn-type="con" id="ack1"><p>NS, KS, YO, SCT, SY, and KD conceived and designed the experiments. KS, YO, and SCT performed the experiments. NS and CEH analyzed the data. NS wrote the paper.</p></fn><corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">schweigh@usc.edu</email></corresp><fn fn-type="conflict" id="ack3"><p> The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="ppub"><month>11</month><year>2006</year></pub-date><pub-date pub-type="epub"><day>10</day><month>11</month><year>2006</year></pub-date><pub-date pub-type="epreprint"><day>4</day><month>10</month><year>2006</year></pub-date><volume>2</volume><issue>11</issue><elocation-id>e152</elocation-id><history><date date-type="received"><day>31</day><month>5</month><year>2006</year></date><date date-type="accepted"><day>4</day><month>10</month><year>2006</year></date></history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2006</copyright-year><copyright-holder>Schweighofer et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>Critical to our many daily choices between larger delayed rewards, and smaller more immediate rewards, are the shape and the steepness of the function that discounts rewards with time. Although research in artificial intelligence favors exponential discounting in uncertain environments, studies with humans and animals have consistently shown hyperbolic discounting. We investigated how humans perform in a reward decision task with temporal constraints, in which each choice affects the time remaining for later trials, and in which the delays vary at each trial. We demonstrated that most of our subjects adopted exponential discounting in this experiment. Further, we confirmed analytically that exponential discounting, with a decay rate comparable to that used by our subjects, maximized the total reward gain in our task. Our results suggest that the particular shape and steepness of temporal discounting is determined by the task that the subject is facing, and question the notion of hyperbolic reward discounting as a universal principle.</p></abstract><abstract abstract-type="synopsis"><title>Synopsis</title><p>When we make a choice between two options, we compare the values of their outcomes and select the option with a larger value. However, what if one option leads to a larger delayed reward and the other leads to a smaller more immediate reward? Naturally, we assign a larger value for a larger reward, but it is “discounted” if the reward is to be delivered later. Thus, the value is a monotonically decreasing function of the delays. Previous behavioral studies have repeatedly demonstrated that humans and animals discount delayed rewards hyperbolically. This has practical importance, as hyperbolic discounting can sometimes lead to “irrational” preference reversal: for instance, an individual may prefer two apples in 51 days to one apple in 50 days, but if the days come closer, he prefers one apple today to two apples tomorrow. On the contrary, exponential discounting is always “rational,” as it predicts constant preference. Here, in a new task that mimics animal foraging, and that uses delayed monetary rewards, Schweighofer and colleagues showed that humans can also discount reward exponentially. Furthermore, it is remarkable that by adopting exponential discounting, their subjects maximized their total gain. Thus, depending on the task at hand, the authors' study suggests that humans can flexibly choose the type of reward discounting, and can exhibit rational behavior that maximizes long-term gains.</p></abstract><funding-group><funding-statement>This study was supported in part by CREST (Core Research for Evolutional Science and Technology, Japan Science and Technology Agency), and by US National Institutes of Health (NIH) P20 RR020700–02 and US National Science Foundation (NSF) IIS 0535282 grants to NS.</funding-statement></funding-group><counts><page-count count="8"/></counts><!--===== Restructure custom-meta-wrap to custom-meta-group =====--><custom-meta-group><custom-meta><meta-name>citation</meta-name><meta-value>Schweighofer N, Shishida K, Han CE, Okamoto Y, Tanaka SC, et al. (2006) Humans can adopt optimal discounting strategy under real-time constraints. PLoS Comput Biol 2(11): e152. doi:<ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.0020152" xlink:type="simple">10.1371/journal.pcbi.0020152</ext-link></meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><title>Introduction</title><p>In the limited amount of time available before nighttime, winter, or retirement, we need to make a large number of choices to maximize our total reward gain. In particular, when choosing between a larger, but delayed, reward, and a smaller, but more immediate reward, we compare the values associated with each reward, and choose the reward associated with the larger value [<xref ref-type="bibr" rid="pcbi-0020152-b001">1</xref>]. Critical to these choices are the <italic>shape</italic> and the <italic>steepness</italic> of the reward values, which monotonically decrease as a function of the delay: the rewards are said to be discounted as a function of the delays (<xref ref-type="fig" rid="pcbi-0020152-g001">Figure 1</xref>A).</p><fig id="pcbi-0020152-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020152.g001</object-id><label>Figure 1</label><caption><title>Hyperbolic and Exponential Reward Discounting Models</title><p>(A) Hyperbolic versus exponential reward discounting models as a function of the delay to the reward for two different sets of steepness parameters. The hyperbolic model has an initial steep decay followed by a flatter “tail”; thus, delayed rewards are less discounted with hyperbolic models than with exponential models.</p><p>(B) Preference reversal, which is commonly observed in humans and animals, is predicted by the hyperbolic model and is due to a decrease in the decay rate as the delay increases. Initially (at time 0), the large reward has a higher value than the small reward, and is therefore preferred. As the small reward draws near, the preference shifts to the small reward. The exponential model, which has a constant decay rate, does not predict preference reversal.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020152.g001" xlink:type="simple"/></fig><p>Two main classes of models that characterize the <italic>shape</italic> of reward discounting have been proposed: exponential [<xref ref-type="bibr" rid="pcbi-0020152-b002">2</xref>–<xref ref-type="bibr" rid="pcbi-0020152-b004">4</xref>] and hyperbolic [<xref ref-type="bibr" rid="pcbi-0020152-b005">5</xref>–<xref ref-type="bibr" rid="pcbi-0020152-b013">13</xref>]. Although researchers in artificial intelligence favor exponential discounting in uncertain environments, e.g., [<xref ref-type="bibr" rid="pcbi-0020152-b004">4</xref>,<xref ref-type="bibr" rid="pcbi-0020152-b014">14</xref>,<xref ref-type="bibr" rid="pcbi-0020152-b015">15</xref>], all behavioral studies that have directly compared the two types of discounting in animals or humans have concluded that hyperbolic discounting better fits delayed reward choice data than does exponential discounting, e.g., [<xref ref-type="bibr" rid="pcbi-0020152-b006">6</xref>–<xref ref-type="bibr" rid="pcbi-0020152-b008">8</xref>,<xref ref-type="bibr" rid="pcbi-0020152-b016">16</xref>–<xref ref-type="bibr" rid="pcbi-0020152-b018">18</xref>].</p><p>In exponential discounting, the reward value <italic>V</italic> is given by:
				<disp-formula id="pcbi-0020152-e001"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e001" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>V</mml:mi><mml:mo>&equals;</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mi>R</mml:mi><mml:mtext>&thinsp;</mml:mtext><mml:mtext>&thinsp;</mml:mtext><mml:mtext>&thinsp;</mml:mtext><mml:mi>exp</mml:mi><mml:mo></mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mtext>&thinsp;</mml:mtext><mml:mo stretchy='false'>(</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mo>&minus;</mml:mo><mml:mi>k</mml:mi><mml:mtext>&thinsp;</mml:mtext><mml:mtext>&thinsp;</mml:mtext><mml:mi>D</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mtext>&thinsp;</mml:mtext></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where <italic>R</italic> is the reward magnitude, <italic>D</italic> the delay, and <italic>k</italic> ≥ 0 the decay rate. This equation is equivalently given by:
				<disp-formula id="pcbi-0020152-e002"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e002" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>V</mml:mi><mml:mo>&equals;</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mi>R</mml:mi><mml:mtext>&thinsp;</mml:mtext><mml:msup><mml:mi>&gamma;</mml:mi><mml:mi>D</mml:mi></mml:msup><mml:mtext>&thinsp;</mml:mtext></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where <italic>γ</italic> is the discount factor (0 ≤ <italic>γ</italic> &lt; 1), and <italic>γ</italic> = exp(−<italic>k</italic>); we note here that a large decay rate corresponds to a small discount factor and vice versa. Because of constant decay rate, exponential discounting is “rational,” as it predicts constant preference.
			</p><p>Typical human studies are questionnaire-based: subjects are asked to make a number of choices between small immediate rewards and larger rewards weeks, months, or years in the future, after thinking about the consequences of each alternative [<xref ref-type="bibr" rid="pcbi-0020152-b019">19</xref>] (but see [<xref ref-type="bibr" rid="pcbi-0020152-b020">20</xref>]). In these studies, the hyperbolic discounted reward value is given by:
				<disp-formula id="pcbi-0020152-e003"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e003" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>V</mml:mi><mml:mo>&equals; </mml:mo><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mi>K</mml:mi><mml:mi>D</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mtext>with </mml:mtext><mml:mi>k</mml:mi><mml:mspace width="2pt"/><mml:mo>&gt;</mml:mo><mml:mspace width="2pt"/><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>
			</p><p>In animal studies, animals are trained to make repeated reward choices, and experience both delays (on the order of a few dozen seconds) and rewards. Assuming a constant inter-trial interval <italic>(ITI),</italic> if the animal consistently makes a choice that gives the same reward <italic>R</italic> after the same delay <italic>D,</italic> the average reward rate is the hyperbolic function of the delay [<xref ref-type="bibr" rid="pcbi-0020152-b021">21</xref>]:
				<disp-formula id="pcbi-0020152-e004"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e004" xlink:type="simple"/><!-- <mml:math display='block'><mml:mi>V</mml:mi><mml:mo>&equals;</mml:mo><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>&plus;</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mtext>with&thinsp;</mml:mtext><mml:mi>T</mml:mi><mml:mspace width="2pt"/><mml:mo>&gt;</mml:mo><mml:mspace width="2pt"/><mml:mn>0</mml:mn><mml:mtext>,</mml:mtext></mml:math> --></disp-formula>where <italic>T</italic> is the sum of all times except the delay in each trial (<italic>T</italic> is often equal to the <italic>ITI</italic>), and <italic>V</italic> the reward value. Because of the decreasing decay rate as a function of delay [<xref ref-type="bibr" rid="pcbi-0020152-b022">22</xref>], hyperbolic discounting has been termed “irrational,” as it predicts preference reversal and impulsive choice (<xref ref-type="fig" rid="pcbi-0020152-g001">Figure 1</xref>B). For instance, an individual may prefer one apple today to two apples tomorrow, but at the same time prefer two apples in 51 days to one apple in 50 days [<xref ref-type="bibr" rid="pcbi-0020152-b023">23</xref>]. Hyperbolic discounting is often presented as a struggle between oneself and one's alter ego in the future, or similarly, between a myopic doer and a farsighted planner—see [<xref ref-type="bibr" rid="pcbi-0020152-b023">23</xref>,<xref ref-type="bibr" rid="pcbi-0020152-b024">24</xref>].
			</p><p>In what situations is it theoretically advantageous to make delayed reward choices based on exponential or hyperbolic discounting? Exponential discounting maximizes total gain in situations of constant probability of reward loss per unit time, and exact estimate of the time of the future reward delivery—see [<xref ref-type="bibr" rid="pcbi-0020152-b021">21</xref>,<xref ref-type="bibr" rid="pcbi-0020152-b025">25</xref>]. Because hyperbolic discounted value, as given by <xref ref-type="disp-formula" rid="pcbi-0020152-e004">Equation 4</xref>, is the reward rate, it maximizes the total gain in situations of constant delays at each trial (with no reward loss and with an exact estimate of the time of future reward delivery).</p><p>But does hyperbolic discounting maximize the total gain in foraging-like situations, that is, in situations of repeated forced choices with varying delays to the rewards, constant <italic>ITI,</italic> and limited total time? In these situations, the hyperbolic discounting model maximizes the instantaneous reward rate. But, as the trials are not independent from each other, hyperbolic discounting may not maximize the average reward rate, and thus the total gain. For instance, in a relatively unfavorable trial with long delays to both rewards, although hyperbolic discounting may favor the large reward, pursuing the small more immediate reward may result in a smaller overall decrease of the average reward rate. By choosing the small but less-delayed reward, the subject can quickly move to the next (hopefully) more favorable trials. Thus, we hypothesize that, in these situations, a discounting strategy that values rewards with longer delays less than hyperbolic discounting, as exponential discounting does (see <xref ref-type="fig" rid="pcbi-0020152-g001">Figure 1</xref>A), would maximize total gain.</p><p>The <italic>steepness</italic> of discounting specifies how far in the future delayed rewards should be considered. A large decay rate biases individuals to acquire small and more immediate rewards. Individuals with impulse-control disorders, as well as heroin-, alcohol-, cigarette-, and cocaine-addicted individuals, have steeper discounting functions than controls [<xref ref-type="bibr" rid="pcbi-0020152-b010">10</xref>,<xref ref-type="bibr" rid="pcbi-0020152-b026">26</xref>–<xref ref-type="bibr" rid="pcbi-0020152-b029">29</xref>]. A small decay rate promotes the acquisition of large and more delayed rewards. Yet, individuals must obtain some rewards in time; for instance, an animal must find food before it starves, or before it is exhausted, or before winter arrives. Thus, the discount rate should be carefully adjusted to maximize total gain in task situations of repeated forced choices with varying delays to the rewards and limited total time [<xref ref-type="bibr" rid="pcbi-0020152-b014">14</xref>,<xref ref-type="bibr" rid="pcbi-0020152-b015">15</xref>].</p><p>Here, we designed a task that mimics animal foraging to study whether humans could adopt a discounting function whose shape and steepness maximize total gain. At each trial, subjects had to choose between a smaller more immediate reward (5 Japanese yen, about US$.05) and a larger delayed reward (20 Japanese yen, about US$.20), with varying experienced delays to the rewards, and fixed <italic>ITI.</italic> To avoid subjects trying to compute explicit reward ratios, or other objective measures of reward discounting, we did not provide direct access to the delay. Instead, subjects had to select, at each trial, between one of two squares made of 100 small patches (<xref ref-type="fig" rid="pcbi-0020152-g002">Figure 2</xref>). The stimulus color (white- or yellow-) coded for the monetary reward amount (5 Japanese yen and 20 Japanese yen). At each trial, the initial number of black patches in the white stimulus indicated the small delay <italic>D<sub>S</sub>,</italic> and the initial number of black patches in the yellow stimulus indicated large delay <italic>D<sub>L</sub></italic>. The subject was then prompted to choose one of the two stimuli: the stimulus that had been selected in the previous step showed more filled patches, and the other stimulus was identical to that of the previous step. The stimuli were always displayed for one time step (1.5 s). This chain of events was repeated until either square was completely filled. Then a display of the acquired reward was shown during <italic>ITI</italic> = 1.5 s (see <xref ref-type="fig" rid="pcbi-0020152-g002">Figure 2</xref>).</p><fig id="pcbi-0020152-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020152.g002</object-id><label>Figure 2</label><caption><title>Experimental Task</title><p>At each trial the subject must select either a white or a yellow mosaic after the fixation cross turns red (“Go” signal). Each button press (green disk) adds a number of colored patches to the selected mosaic. In the example shown here, if the white mosaic is selected, the subject receives 5 yen in two steps of 1.5 s each. If the yellow mosaic is selected, the subject receives 20 yen in four steps. The position of the squares (left or right) was changed randomly at each step. For each trial, the initial numbers of black patches for both mosaics were randomly drawn from uniform distributions, and indicated different delays. The <italic>ITI,</italic> which corresponds to the reward display, was fixed (one time step). Thus, just after the reward display, a new trial began. The subjects had a total of 700 time steps to maximize their total gain.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020152.g002" xlink:type="simple"/></fig><p>In the experiment, total time was limited to five sessions of 210 s each, separated by 15 s to give the subject some rest time. Thus, each subject had 700 steps (210 s * 5 sessions / 1.5 s) available to maximize the total reward. Because the subjects performed a minimum of one training session of equal duration before the experiment, they were highly familiar with the task. Subjects were compensated by the total reward earned at the end of the experiment.</p></sec><sec id="s2"><title>Results</title><p>With data from all trials, we first constructed <italic>D<sub>S</sub></italic> versus <italic>D<sub>L</sub></italic> scatter plots for each subject (<xref ref-type="fig" rid="pcbi-0020152-g003">Figure 3</xref>A). We first classified subjects' choices with a logistic regression model (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). All models were significant (<italic>p</italic> &lt; 0.05), and gave a good fit to the data: <italic>R2_logit</italic> = 0.55 ± 0.11 SD. An “indifference line,” for which there is equal probability to take either reward, divides the rectangular delay space into two trapezoids (see <xref ref-type="fig" rid="pcbi-0020152-g003">Figure 3</xref>): in the area above the indifference line, the delays <italic>D<sub>L</sub></italic> are long, and subjects tend to select small rewards. Conversely, in the area below the indifference line, subjects tend to select large rewards. The average slope of the indifference line for all subjects was 1.1 ± 0.51 SD. Thus, on average, subjects made choices with an indifference line that is much closer to that of an exponential model—the theoretical slope is equal to 1 and independent of the rewards—than that of a hyperbolic model—the theoretical slope is equal to the ratio of the large reward to the small reward, i.e., <inline-formula id="pcbi-0020152-ex001"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0020152.ex001" xlink:type="simple"/></inline-formula>
				 = 4 in our experiment (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>).
			</p><fig id="pcbi-0020152-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020152.g003</object-id><label>Figure 3</label><caption><title>Reward Choice as a Function of Delays</title><p>(A) Example of a subject's reward choice as a function of delays. At each trial, the subject had the choice between a large reward <italic>R<sub>L</sub></italic> and a small reward <italic>R<sub>S</sub></italic>. The indifference line (solid line) was obtained with a logistic regression model (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>).</p><p>(B) Comparison of average indifference lines derived from the experiment with the theoretical indifference line that maximizes total gain in the experiment. Black solid line: average indifference line for all subjects obtained with the logistic regression model. Dotted blue line: average indifference line for all subjects obtained by fitting an exponential discounting model (the slope of the indifference line is 1). Dash-dotted red line: average indifference line for all subjects obtained by fitting a hyperbolic model (the slope of the indifference line is 4). Dashed green line: theoretical indifference line that maximizes the total gain in the experiment (the slope of the indifference line is 1).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020152.g003" xlink:type="simple"/></fig><p>Then, we directly fit the exponential model (<xref ref-type="disp-formula" rid="pcbi-0020152-e002">Equation 2</xref>) and the hyperbolic model (<xref ref-type="disp-formula" rid="pcbi-0020152-e003">Equations 3</xref> and <xref ref-type="disp-formula" rid="pcbi-0020152-e004">4</xref>) to the choice data (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). In each case, two parameters were estimated: <italic>γ</italic> and <italic>β,</italic> which controls the variability of reward choice, for the exponential model, <italic>K</italic> and <italic>β</italic> for the first hyperbolic model (<xref ref-type="disp-formula" rid="pcbi-0020152-e003">Equation 3</xref>), and <italic>T</italic> and <italic>β</italic> for the second hyperbolic model (<xref ref-type="disp-formula" rid="pcbi-0020152-e004">Equation 4</xref>). The exponential model fit gave: <italic>γ</italic> = 0.77 ± 0.035 SD and <italic>β</italic> = 7.3 ± 2.4 SD. Hyperbolic model fits gave <italic>K</italic> = 2.6 ± 0.94 SD and <italic>β</italic> = 13.8 ± 3.6 SD, and <italic>T</italic> = 0.30 ± 0.34 SD and <italic>β</italic> = 7.3 ± 3.0 SD. As can be seen in <xref ref-type="fig" rid="pcbi-0020152-g003">Figure 3</xref>B, the average indifference line obtained with the exponential model (i.e., with <italic>γ</italic> = 0.77, which corresponds to a decay rate <italic>k</italic> = 0.26) is close to that obtained with the logistic regression model above (compare with the line obtained with the hyperbolic model of <xref ref-type="disp-formula" rid="pcbi-0020152-e004">Equation 4</xref>).</p><p>To evaluate the goodness of fit between the different two-parameter models, we computed the negative logarithm of the likelihood (<italic>E</italic>), also called the cross entropy error function, which is smaller for better-fitting models. Results from all subjects gave <italic>E</italic> = 94.6 ± 24 SD for the logistic regression model, <italic>E</italic> = 107 ± 25 SD for the exponential model, <italic>E</italic> = 161 ± 32 SD for the first hyperbolic model (<xref ref-type="disp-formula" rid="pcbi-0020152-e003">Equation 3</xref>), and <italic>E</italic> = 155 ± 31 SD for the second hyperbolic model (<xref ref-type="disp-formula" rid="pcbi-0020152-e004">Equation 4</xref>). A two-tail t-test showed that <italic>E</italic> for the two hyperbolic models were not significantly different (<italic>p</italic> = 0.47), indicating that both models fit the data equally well (this gives validity to our optimization method, as rescaling of one equation leads to the other equation). A two-tail t-test showed that <italic>E</italic> for the exponential model was significantly smaller than that for the hyperbolic models (<italic>p</italic> &lt; 0.005 for both hyperbolic models), indicating that the exponential model better fits the data.</p><p>The generalized hyperbolic model has been proposed to be a better model of delayed reward discounting than simple hyperbolic discounting [<xref ref-type="bibr" rid="pcbi-0020152-b030">30</xref>]. The generalized hyperbolic discounting model is given by:
				<disp-formula id="pcbi-0020152-e005"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e005" xlink:type="simple"/><!-- <mml:math display='block'><mml:mi>V</mml:mi><mml:mo>&equals;</mml:mo><mml:mi>R</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mi>&lambda;</mml:mi><mml:mi>D</mml:mi><mml:msup><mml:mo>)</mml:mo><mml:mrow><mml:mo>&minus;</mml:mo><mml:mi>v</mml:mi><mml:mo>/</mml:mo><mml:mi>&lambda;</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext>with&thinsp;</mml:mtext><mml:mi>&lambda;</mml:mi><mml:mtext>,&thinsp;</mml:mtext><mml:mi>v</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mtext>,</mml:mtext></mml:math> --></disp-formula>where the λ coefficient determines how much the function departs from exponential discounting. In the limit, as λ goes to zero the function becomes the exponential discounting model <italic>V = R</italic> exp(<italic>−vD</italic>). Fitting this model to the data gave: λ = 0.28 ± 0.73 SD, <italic>v</italic> = 0.54 ± 0.74 SD, <italic>β</italic> = 12.9 ± 14.2 SD, and <italic>E</italic> = 101 ± 23.1 SD. Despite the increase in the number of parameters from two to three, and although <italic>E</italic> appears to be slightly lower for the generalized hyperbolic model than for the exponential model, a two-tail t-test shows that the difference is not significant (<italic>p</italic> = 0.46). The slope of the indifference line for this model was 1.42 ± 0.79 SD. Interestingly, for 14 subjects, the coefficient λ was very close to zero, and the slope of the indifference line was between 1 and &lt;1.0001, indicating pure exponential discounting for most subjects. The slope of the indifference line for four subjects was less than 2.5 (S10: 1.8, S14: 2.4, S17: 2.0, and S20 1.4), indicating near exponential discounting for these subjects. The slope for the last two subjects (S3: 3.5, and S16: 3.2) was close to the ratio of the large to the small reward, that is, 4, indicating discounting closer to hyperbolic discounting for these subjects.
			</p><p>Next, we estimated the coefficients of a semiparametric value model with exponential basis functions (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Because integrating the exponential discounting function with respect to the decay rate <italic>k</italic> from 0 to infinity yields a hyperbolic function of the delay <italic>D,</italic> a sum of several exponentials with different decay rates approximates a hyperbola [<xref ref-type="bibr" rid="pcbi-0020152-b031">31</xref>]. Thus, if a number of coefficients in the semiparametric model are positive, subjects would discount reward approximately hyperbolically. In contrast, if only one or a few nearby coefficients are positive, then subjects would discount reward exponentially. <xref ref-type="fig" rid="pcbi-0020152-g004">Figure 4</xref> shows that the distribution of coefficients was sparse: all subjects exhibited a single narrow first peak (peak width: 0.050 ± 0.008 SD sec<sup>−1</sup>). Further, the average decay rate was 0.25 ± 0.06 SD sec<sup>−1</sup> (a very similar average decay rate was obtained with the direct exponential fit method—see above), with a sharp distribution ranging between 0.13 and 0.35 sec<sup>−1</sup>. For 13 subjects, this peak was the only peak, indicating pure exponential discounting. For seven subjects the first peak was followed by a prominent second peak; two of these subjects had a secondary isolated peak (near <italic>k</italic> = 0.75 sec<sup>−1</sup>), and for five of these subjects, a higher frequency component appeared at <italic>k</italic> = 1 sec<sup>−1</sup> (e.g., subject 3). This method confirmed the results of the generalized hyperbolic model fit, as 13 subjects were identified as pure exponential discounters by both methods.</p><fig id="pcbi-0020152-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020152.g004</object-id><label>Figure 4</label><caption><title>Coefficients of the Exponential Basis Functions Normalized to Unity for Each of the 20 Subjects (S1 to S20)</title><p>Note the sparseness of the coefficient distribution: all subjects exhibit a single peak for decay rates in the range 0.125 and 0.35 sec<sup>−1</sup>.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020152.g004" xlink:type="simple"/></fig><p>In our experiment, the subjects gained an average of 1840 ± 71 SD yen. Could the subjects have earned more if they had adopted different decision lines? In other words, were the subjects' choices optimal with regard to maximizing their total gain? To answer this question, we estimated the indifference line that yields the maximum theoretical total reward in our experimental setting, independently of any particular model (hyperbolic or exponential). We first computed the expected reward rate—the “value” <italic>V</italic> (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Then, we computed the maximum expected reward rate <italic>Vmax,</italic> by computing the two partial derivatives of the expected reward rate with respect to the slope <italic>a</italic> and the intercept <italic>b</italic> of the indifference line <italic>D<sub>L</sub></italic> = <italic>aD<sub>s</sub></italic> + <italic>b</italic>. A maximum of <italic>V</italic> is obtained when both partial derivatives are equal to zero.</p><p>We found only one (real number) solution with respect to the slope <italic>a</italic> of the indifference line<italic>, a</italic> = 1, and one (real number) solution for the intercept that maximizes <italic>V, b</italic> = 6.93. Furthermore, taking into account the <italic>ITI,</italic> the intercept corresponds to an exponential decay rate of <italic>k</italic> = 0.25 (discount rate 0.77), very close to the average decay rate of our subjects (average decay rate found with the exponential model: <italic>k</italic> = 0.26). Thus, our analytical analysis shows that the theoretical indifference line is very close to the lines obtained with the logistic regression model fit and with the exponential model fit (see <xref ref-type="fig" rid="pcbi-0020152-g003">Figure 3</xref>B). It is also noteworthy that the slope <italic>a</italic> = 1 that maximizes <italic>V</italic> was independent of the maximum and minimum of the boundaries of the (<italic>D<sub>S</sub>, D<sub>L</sub></italic>) space <italic>(α, β, η,</italic> and <italic>μ</italic>), and independent of the <italic>ITI</italic> as well.</p><p>Finally, using an optimization method (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>), we then confirmed that we did not find such an indifference line “by chance”: any experiment similar to ours, but with different boundaries of the (<italic>D<sub>S</sub>, D<sub>L</sub></italic>) space, different rewards, and/or different <italic>ITI,</italic> would also yield an indifference line of slope 1. <xref ref-type="table" rid="pcbi-0020152-t001">Table 1</xref> shows that the optimization method gives the same results as the exact analytical method for the experimental parameters (“original parameters”). Further, although the intersect value <italic>b</italic> and the maximum reward rate <italic>Vmax</italic> depended on the various experimental parameters, the slope <italic>a</italic> stayed exactly equal to 1 as we varied the experimental parameters.</p><table-wrap id="pcbi-0020152-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020152.t001</object-id><label>Table 1</label><caption><p>Parameter Sensitivity Analysis</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020152.t001" xlink:type="simple"/><!-- <table frame="hsides" rules="none"><colgroup><col id="tb1col1" align="left" charoff="0" char=""/><col id="tb1col2" align="left" charoff="0" char=""/><col id="tb1col3" align="left" charoff="0" char=""/><col id="tb1col4" align="left" charoff="0" char=""/><col id="tb1col5" align="left" charoff="0" char=""/><col id="tb1col6" align="left" charoff="0" char=""/><col id="tb1col7" align="left" charoff="0" char=""/><col id="tb1col8" align="left" charoff="0" char=""/></colgroup><thead><tr><td align="left"><hr/>Parameter</td><td><hr/>Original Parameters</td><td><hr/><italic>R<sub>L</sub></italic>/2</td><td><hr/><italic>R<sub>S</sub></italic>*2</td><td><hr/><italic>&alpha;</italic>*2</td><td><hr/><italic>&beta;*</italic>2, <italic>&eta;*</italic>2</td><td><hr/><italic>&mu;/</italic>2</td><td><hr/><italic>ITI</italic>*2</td></tr></thead><tbody><tr><td><italic>a</italic></td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr><tr><td><italic>b</italic></td><td>6.93</td><td>3.52</td><td>3.52</td><td>7.14</td><td>9.00</td><td>5.11</td><td>8.54</td></tr><tr><td><italic>Vmax</italic></td><td>2.16</td><td>1.42</td><td>2.84</td><td>2.10</td><td>1.67</td><td>2.93</td><td>1.75</td></tr></tbody></table> --><!-- <table-wrap-foot><fn id="nt101"><p>Values of the slope <italic>a</italic> and the intersect <italic>b</italic> of the indifference line that maximizes the reward rate <italic>Vmax</italic> (in yen/s) for the original parameters of our experiment, and for a number of other parameters, as found using an optimization parameter. <italic>R<sub>L</sub></italic> and <italic>R<sub>S</sub></italic> are the magnitude of the large and small rewards, respectively, <italic>&alpha;</italic> and <italic>&beta;</italic> are the lower and upper bound of the range of the small delays, and <italic>&eta;</italic> and <italic>&mu;</italic> are the lower and upper bounds of the range of large delays.</p></fn><fn id="nt102"><p>doi:10.1371/journal.pcbi.0020152.t001</p></fn></table-wrap-foot> --></table-wrap></sec><sec id="s3"><title>Discussion</title><p>In our experiment, most of our subjects adopted a discounting function with a <italic>shape</italic> (exponential) and <italic>steepness</italic> (the decay rate) appropriate to maximize the total reward in the experiment. Using a logistic regression model, we found that the average indifference line had a slope near 1, as predicted by exponential discounting. Then, a direct fit of the data with exponential and hyperbolic models indicated that the exponential model better fitted the data overall. A fit with the generalized hyperbolic model [<xref ref-type="bibr" rid="pcbi-0020152-b030">30</xref>] showed pure exponential discounting for 14 out of 20 subjects, and near exponential discounting for three more subjects. Next, using a semiparametric method to approximate the value function with exponential bases, we found a sparse distribution of positive basis coefficients, with a single isolated peak for most subjects, further supporting exponential discounting. Finally, we showed both analytically and with an optimization technique that the theoretical indifference line that maximizes the total gain in our experiment had a slope of exactly 1. Importantly, this result was not affected by the magnitude of the reward ratio; thus, we predict that this result would hold for different reward magnitudes. However, as it has been suggested that the value of a positive reinforcer increases as a hyperbolic function of its size [<xref ref-type="bibr" rid="pcbi-0020152-b011">11</xref>], this prediction needs to be further tested.</p><p>The use of exponential discounting by our subjects appears to be a farsighted strategy that allows an optimal tradeoff between (the relatively short) delays at each trial and (the relatively long) total time remaining in the experiment. The use of hyperbolic discounting, in contrast, would be a greedy, but myopic strategy, which would maximize the instantaneous reward rate at each trial, not the total reward gain. Thus, our results suggest that humans can overcome their hyperbolic discounting when it is suboptimal, and discount time exponentially instead to maximize total gain.</p><p>Not all our subjects exhibited pure exponential discounting, however. Our direct-fit method using the generalized hyperbolic model notably showed that two subjects exhibited discounting closer to hyperbolic discounting, and four subjects exhibited intermediate discounting closer to exponential discounting. Our semiparametric method mostly yielded similar results, with the addition of one other near-exponential discounter. These subjects had a discount function with two decay rates: one similar to the other subjects, around 0.25 sec<sup>−1</sup>, and a second higher decay rate above 0.67 sec<sup>−1</sup>. Because the time step in the experiment was 1.5 s, we can interpret any decay rate beyond 0.67 sec<sup>−1</sup> as the bias for a small reward choice available within one step (see <xref ref-type="fig" rid="pcbi-0020152-g004">Figure 4</xref>). Thus, for these subjects, the discounting functions are qualitatively similar to that proposed by the quasi-hyperbolic model [<xref ref-type="bibr" rid="pcbi-0020152-b032">32</xref>,<xref ref-type="bibr" rid="pcbi-0020152-b033">33</xref>], for which initial discounting after the first time step is steeper than subsequent discounting, which is exponential.</p><p>The decay rates used by our subjects were in good agreement with the theoretical discount rate that maximizes the total gain. These decay rates were close to that observed in animal studies [<xref ref-type="bibr" rid="pcbi-0020152-b034">34</xref>], and similar to that reported in a related human experiment [<xref ref-type="bibr" rid="pcbi-0020152-b020">20</xref>], but several order of magnitudes larger than that observed in other questionnaire-based human studies [<xref ref-type="bibr" rid="pcbi-0020152-b019">19</xref>], suggesting that humans can select decay rates based on the task at hand. Note that our optimization methods give us an overall estimate of the discount factor, that is, it does not allow us to tract variations, if any, of the discount factor within the session. However, since the subjects had one training session before the experiment, it is probable that most meta-learning of the discount parameter occurred previous to the experiment.</p><p>Although, to our knowledge, exponential discounting had not been previously demonstrated in human reward discounting, a number of investigators have suggested that, in some circumstances, humans can be less impulsive than predicted by hyperbolic discounting, and behave in a more rational manner. Forzano and Logue [<xref ref-type="bibr" rid="pcbi-0020152-b035">35</xref>] showed that subjects are more impulsive in conditions when juice is given during the experiment (after each choice), compared with conditions when subjects are given money or points exchangeable for a total (juice) reward at the end of the experiment (as in the present experiment). Loewenstein [<xref ref-type="bibr" rid="pcbi-0020152-b036">36</xref>] pointed out that people are impulsive as a result of the effect of visceral factors, such as hunger, thirst, and sexual desire, on the desirability of immediate consumption. When no immediate visceral factors are involved, people tend to be less impulsive. Montague and Berns [<xref ref-type="bibr" rid="pcbi-0020152-b025">25</xref>] proposed that because of uncertainty in reward estimation, reward values should be more steeply discounted than exponential discounting. However, according to their model, if there is no uncertainty of reward estimation, then discounting is exponential. Finally, Read [<xref ref-type="bibr" rid="pcbi-0020152-b037">37</xref>] showed that humans do not discount rewards hyperbolically but subadditively, that is, they tend to discount rewards more if the delay is divided into subintervals than when it is left undivided. Subadditivity is then explained by a modified exponential function, where the delay <italic>D</italic> is taken to the power of a parameter <italic>s,</italic> 0 &lt; <italic>s</italic> &lt; 1 reflecting nonlinear time perception. As this parameter approaches 1, discounting becomes exponential.</p><p>What may be the possible neural correlates of exponential or hyperbolic discounting? We have previously found that parallel cortico–basal ganglia loops are involved in reward prediction with different discounting factors [<xref ref-type="bibr" rid="pcbi-0020152-b038">38</xref>]. Because summation of several exponential discounting can yield hyperbolic discounting [<xref ref-type="bibr" rid="pcbi-0020152-b031">31</xref>], simultaneous activation of a number of exponential parallel cortico–basal ganglia loops could generate hyperbolic discounting. If reward prediction at a larger time scale is required, as in questionnaire-based human experiments, the frontal cortex would be additionally recruited [<xref ref-type="bibr" rid="pcbi-0020152-b039">39</xref>]. If, however, exponential discounting of rewards at relatively short delays is required, as in the present experiment, a particular cortico–striatial loop with the appropriate discount rate would be selected, possibly via serotonin modulation (Tanaka SC, Schweighofer N, Asahi S, Okamoto Y, Yamawaki S, et al. (2006) Serotonin regulates striatal activities in delay discounting, unpublished data).</p></sec><sec id="s4"><title>Materials and Methods</title><sec id="s4a"><title>Subjects.</title><p>Twenty-two healthy, right-handed male volunteers, with no history of psychiatric or neurological disorders, gave written informed consent after the nature and possible consequences of the study were explained. The study was approved by the ethics and safety committees of the Advanced Telecommunications Research Institute International and of Hiroshima University. We recruited only male subjects to avoid estrogen-level fluctuation during the menstrual cycle in women, which affects central serotonin levels. The results reported here are part of an experiment to study the role of serotonin in reward choice and learning. In this within-subject experiment, six hours before the beginning of the behavioral task, the subject consumed one of three amino acid drinks: one containing a standard amount of tryptophan (2.3 g per 100 g amino acid mixture), one containing excess tryptophan (10.3 g), and one without tryptophan (0g )—more experimental details of serotonergic manipulation are described elsewhere (Tanaka SC, Schweighofer N, Asahi S, Okamoto Y, Yamawaki S, et al. (2006) Serotonin regulates striatal activities in delay discounting, unpublished data). Here, we present the results for twenty subjects in the control condition, who drank the solution containing the standard amount of tryptophan. The mean plasma-free tryptophan concentrations at the time of the experiment in the control condition was 2.42 ± 0.98 SD mg/ml. These levels are slightly higher than normal physiological levels, about 1.3–1.5 mg/ml [<xref ref-type="bibr" rid="pcbi-0020152-b040">40</xref>–<xref ref-type="bibr" rid="pcbi-0020152-b042">42</xref>], but much lower than those in the high-tryptophan condition (61.2 ± 34 SD mg/ml).</p><p>Two subjects were excluded from the study. The first subject was excluded because no change in plasma-free tryptophan measurements between the control-tryptophan and the high-tryptophan conditions could be detected. This can be explained by either an error in the procedure, or by digestive problems, as all other subjects exhibited a dramatic increase in plasma-free tryptophan measurements in the high-tryptophan condition (close to a 40-fold increase compared with preingestion measurements). The second subject was excluded because of a technical problem that prevented us from recording the choice data in the low-tryptophan condition.</p></sec><sec id="s4b"><title>Task.</title><p>Two stimuli (one white-coded for the small reward, and one yellow-coded for the large reward) were presented during a time selected from a uniform distribution ranging from 0.4 to 0.7 s from the onset of the presentation of the stimuli. Then, a change of color in the fixation cross from white to red acted as a “Go” signal; then the subject had to decide to pursue either the large or the small reward. The subject then clicked on the mouse button associated with the position of the chosen stimulus (i.e., left button to choose the left stimulus, for instance). After 1.5 s from the beginning of the step, two new stimuli were presented, and a new step started—the stimulus that was chosen showed more filled patches and the stimulus that was not chosen was identical to that of the previous step. A trial ended when either square was completely filled (100 patches were filled). The corresponding monetary reward then appeared on the screen for 1.5 sec (corresponding to an <italic>ITI</italic> of 1.5 s). To maintain the subjects' attention, the position of the squares (left or right) was changed randomly at each step.</p><p>At each trial, the delays to the small and large rewards <italic>D<sub>S</sub></italic> and <italic>D<sub>L</sub></italic> are theoretically given by:
					<disp-formula id="pcbi-0020152-e006"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e006" xlink:type="simple"/><!-- <mml:math display='block'><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mo>(</mml:mo><mml:mi>100</mml:mi><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>t</mml:mi><mml:mi>s</mml:mi><mml:mtext>&thinsp;&thinsp;and&thinsp;&thinsp;</mml:mtext><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mo>(</mml:mo><mml:mn>100</mml:mn><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msub><mml:mtext>S</mml:mtext><mml:mi>L</mml:mi></mml:msub><mml:mo>*</mml:mo><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:math> --></disp-formula>where <italic>ts</italic> is the time step (1.5 s), <italic>N<sub>S</sub></italic> and <italic>N<sub>L</sub></italic> are the initial number of white and yellow patches, and <italic>S<sub>S</sub></italic> and <italic>S<sub>L</sub></italic> are the number of patches added per step (10 ± 2 patches/step). At the onset of each trial, the white and yellow patches were drawn from random uniform distributions: white patches were in the range 85 ± 10 and initial yellow patches in the range 40 ± 35. Thus, the white square always appeared brighter than the yellow square on the first step of each trial, and the average delay needed to get a large reward was 4× that to get a small reward (excluding the <italic>ITI</italic>). For the average value of <italic>S<sub>S</sub></italic> and <italic>S<sub>L</sub>,</italic> the range of theoretical delays for the small rewards was 0.75 to 3.75 s, and for the large rewards 3.75 to 14.25 s. Because the experimental step was 1.5 s, however, the actual delays were the delays above rounded to the next 1.5-s increment; further, every trial also contained an additional step due to <italic>ITI</italic> = 1.5 s.
				</p></sec><sec id="s4c"><title>Data analysis.</title><p>We first approximated the choices with a two-parameter logistic regression model:
					<disp-formula id="pcbi-0020152-e007"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e007" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mi>exp</mml:mi><mml:mo></mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mo>&minus;</mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where <italic>P</italic>(<italic>L</italic>) is the probability to choose the large reward, <italic>a<sub>L</sub>,</italic> and <italic>a<sub>c</sub></italic> are parameters that were determined using the Matllab function <italic>glmfit</italic> with a maximum likelihood loss function. Note that for the logistic regression model of <xref ref-type="disp-formula" rid="pcbi-0020152-e007">Equation 7</xref>, −1<italic>/a<sub>L</sub></italic> gives the slope of the indifference line (for which <italic>P</italic>(<italic>L</italic>) = 0.5).
				</p><p>Then, we directly fit different discounting models to the data. For this, we used the following equation, which gives the probability of choosing the large reward:
					<disp-formula id="pcbi-0020152-e008"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e008" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mi>exp</mml:mi><mml:mo></mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mo>&minus;</mml:mo><mml:mi>&beta;</mml:mi><mml:mtext>&thinsp;</mml:mtext><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where <italic>V<sub>L</sub></italic> and <italic>V<sub>S</sub>,</italic> are the large and small reward values, and <italic>β</italic> the “inverse temperature,” which controls the randomness of the reward choice. <italic>V</italic> was replaced by <xref ref-type="disp-formula" rid="pcbi-0020152-e002">Equation 2</xref> (exponential model), <xref ref-type="disp-formula" rid="pcbi-0020152-e003">Equations 3</xref> and <xref ref-type="disp-formula" rid="pcbi-0020152-e004">4</xref> (hyperbolic models), and <xref ref-type="disp-formula" rid="pcbi-0020152-e005">Equation 5</xref> (generalized hyperbolic model).
				</p><p>By taking <italic>V<sub>L</sub></italic> = <italic>V<sub>S</sub>,</italic> it can be easily shown that the indifference line's equation for the exponential discounting model is:
					<disp-formula id="pcbi-0020152-e009"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e009" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mtext>&thinsp;</mml:mtext><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>log</mml:mi><mml:mo></mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mi>&gamma;</mml:mi><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>&times;</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mi>log</mml:mi><mml:mo></mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:math> --></disp-formula>
				</p><p>The slope of the indifference of line is 1, independent of the reward amounts. For the hyperbolic model, the indifference line is:
					<disp-formula id="pcbi-0020152-e010"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e010" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mtext>&thinsp;</mml:mtext><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>&times;</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mi>T</mml:mi><mml:mo>&times;</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> --></disp-formula>The slope of this line is the ratio of the rewards <inline-formula id="pcbi-0020152-ex002"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0020152.ex002" xlink:type="simple"/></inline-formula>
					 ; thus, in our specific case, the slope is 40/10 = 4 (Note: for the other form of the hyperbolic model, it can easily be shown that the slope is also the ratio of the rewards). For the generalized hyperbolic model, the indifference line is given by:
					<disp-formula id="pcbi-0020152-e011"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e011" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&lambda;</mml:mi><mml:mo>/</mml:mo><mml:mi>&upsi;</mml:mi></mml:mrow></mml:msup><mml:mtext>&thinsp;</mml:mtext><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>&lambda;</mml:mi><mml:mo>/</mml:mo><mml:mi>&nu;</mml:mi></mml:mrow></mml:msup><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>&lambda;</mml:mi></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math> --></disp-formula>
				</p><p>The parameters for these three models (<italic>k</italic> and <italic>β</italic> for the exponential model, <italic>K,</italic> or <italic>T</italic> and <italic>β</italic> for the hyperbolic models, and <italic>λ, v,</italic> and <italic>β</italic> for the generalized hyperbolic model) were constrained the be positive (≥0), and were found by fitting the models to the subjects' choices with a maximum likelihood loss function. Such optimization can be performed using sequential dynamic programming, which is available in Matlab using the optimization function <italic>fmincon</italic>. This function estimates the Hessian of the Lagrangian through the BFGS formula at each iteration. Then, the line search method is used with this estimation to find the parameters that minimize the maximum likelihood loss function.</p><p>Next, we estimated the discounting function directly with a semiparametric model. Specifically, each value function was computed as a weighted sum of exponential basis functions:
					<disp-formula id="pcbi-0020152-e012"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e012" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>V</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:munder><mml:mo>&sum;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:mi>R</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>t</mml:mi><mml:mo>&plus;</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mtext>&thinsp;</mml:mtext><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where the basis functions were given by
					<disp-formula id="pcbi-0020152-e013"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e013" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>exp</mml:mi><mml:mo></mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi>D</mml:mi><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>Where 0 ≤ <italic>k</italic> ≤ <italic>k</italic><sub>max</sub> and <italic>c<sub>i</sub></italic> are the basis coefficients. We replaced the two value functions in <xref ref-type="disp-formula" rid="pcbi-0020152-e008">Equation 8</xref> by their semiparametric expression, which gives:
					<disp-formula id="pcbi-0020152-e014"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e014" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>L</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mi>exp</mml:mi><mml:mo></mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mo>&minus;</mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mstyle displaystyle='true'><mml:munder><mml:mo>&sum;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>exp</mml:mi><mml:mo></mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mi>exp</mml:mi><mml:mo></mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math> --></disp-formula>
				</p><p>The basis coefficients <italic>c<sub>i</sub></italic> were constrained to be positive, and were found by fitting subjects' choices with a maximum likelihood loss function. The optimization was performed with the function <italic>fmincon,</italic> as above. We estimated the coefficients for decay rates <italic>k</italic> between 0 and 1 sec<sup>−1</sup> with increments of 0.05 sec<sup>−1</sup>.</p></sec><sec id="s4d"><title>Mathematical analysis.</title><p>To estimate the indifference line that gives the maximum theoretical total reward, we computed the expected reward rate (in yen/s), given by:
					<disp-formula id="pcbi-0020152-e015"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e015" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>V</mml:mi><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy='false'>&lsqb;</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo stretchy='false'>&rsqb;</mml:mo></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy='false'>&lsqb;</mml:mo><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy='false'>&rsqb;</mml:mo></mml:mrow></mml:mfrac><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mrow><mml:mstyle displaystyle='true'><mml:mrow><mml:munder><mml:mo>&int;</mml:mo><mml:mi>&Omega;</mml:mi></mml:munder><mml:mrow><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mstyle displaystyle='true'><mml:mrow><mml:munder><mml:mo>&int;</mml:mo><mml:mi>&Omega;</mml:mi></mml:munder><mml:mrow><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where Ω is the <italic>D<sub>L</sub></italic>,<italic>D<sub>S</sub></italic> space, modified by rounding the space boundary to the next time step and by adding the <italic>ITI,</italic> and <italic>P<sub>L</sub></italic>(<italic>D<sub>S</sub>, D<sub>L</sub></italic>) is the probability of choosing the large reward for the delays <italic>D<sub>S</sub></italic> and <italic>D<sub>L</sub></italic>. The total reward is then the reward rate times the total time in the experiment. We parameterized the expected reward rate with a family of indifference line modeled with
					<disp-formula id="pcbi-0020152-e016"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e016" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mi>a</mml:mi><mml:mtext>&thinsp;</mml:mtext><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math> --></disp-formula>
				</p><p>To find the parameters <italic>a</italic> and <italic>b</italic> that maximize the value given by <xref ref-type="disp-formula" rid="pcbi-0020152-e015">Equation 15</xref>, we simplified the problem by assuming that subjects made deterministic decisions. If in a one-trial, <italic>D<sub>L</sub></italic> ≤ <italic>aD<sub>S</sub></italic> + <italic>b,</italic> then the large reward is chosen; the small reward is chosen otherwise. We then noted that the value function equation can be evaluated with two separated trapezoids, one above and the other below the indifference line. Thus, <italic>E[reward]</italic> consists of two terms.
					<disp-formula id="pcbi-0020152-e017"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e017" xlink:type="simple"/><!-- <mml:math display='block'><mml:mtable><mml:mtr><mml:mtd><mml:mi>E</mml:mi><mml:mo stretchy='false'>&lsqb;</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo stretchy='false'>&rsqb;</mml:mo><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:munder><mml:mo>&int;</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:munder><mml:mo>&int;</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&equals;</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mstyle displaystyle='true'><mml:mrow><mml:msubsup><mml:mo>&int;</mml:mo><mml:mi>&alpha;</mml:mi><mml:mi>&beta;</mml:mi></mml:msubsup><mml:mrow><mml:mstyle displaystyle='true'><mml:mrow><mml:msubsup><mml:mo>&int;</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mi>&mu;</mml:mi></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mstyle displaystyle='true'><mml:mrow><mml:msubsup><mml:mo>&int;</mml:mo><mml:mi>&alpha;</mml:mi><mml:mi>&beta;</mml:mi></mml:msubsup><mml:mrow><mml:mstyle displaystyle='true'><mml:mrow><mml:msubsup><mml:mo>&int;</mml:mo><mml:mi>&eta;</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where <italic>α</italic>, <italic>β</italic>, <italic>η</italic>, and <italic>μ</italic> are the lower and upper bounds of the <italic>D<sub>L</sub></italic>,<italic>D<sub>S</sub></italic> space. Similarly
					<disp-formula id="pcbi-0020152-e018"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e018" xlink:type="simple"/><!-- <mml:math display='block'><mml:mtable><mml:mtr><mml:mtd><mml:mi>E</mml:mi><mml:mo stretchy='false'>&lsqb;</mml:mo><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy='false'>&rsqb;</mml:mo><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:munder><mml:mo>&int;</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:munder><mml:mo>&int;</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:msubsup><mml:mo>&int;</mml:mo><mml:mi>&alpha;</mml:mi><mml:mi>&beta;</mml:mi></mml:msubsup><mml:mrow><mml:mstyle displaystyle='true'><mml:mrow><mml:msubsup><mml:mo>&int;</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mi>&mu;</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle><mml:mo>&plus;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:msubsup><mml:mo>&int;</mml:mo><mml:mi>&alpha;</mml:mi><mml:mi>&beta;</mml:mi></mml:msubsup><mml:mrow><mml:mstyle displaystyle='true'><mml:mrow><mml:msubsup><mml:mo>&int;</mml:mo><mml:mi>&eta;</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>&plus;</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>L</mml:mi></mml:msub><mml:mi>d</mml:mi><mml:msub><mml:mi>D</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math> --></disp-formula>
				</p><p>We then computed the partial derivative of <italic>V</italic> with respect to the parameters,<italic>a</italic> and <italic>b:</italic>
					<disp-formula id="pcbi-0020152-e019"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0020152.e019" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&part;</mml:mo><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mo>&part;</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:mfrac><mml:mo>&equals;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mrow><mml:mo>&part;</mml:mo><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mo>&part;</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mfrac><mml:mo>&equals;</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>and solved these equations analytically using Mathematica software.
				</p></sec><sec id="s4e"><title>Sensitivity analysis.</title><p>We used an optimization method (1) to verify our analytical results and (2) to perform a sensitivity analysis to examine how variations in experimental parameters affected the values of <italic>a</italic> and <italic>b</italic> that maximized the expected reward rate <italic>V</italic>. We computed the maximum of <italic>V</italic> using the Matlab function <italic>fminunc,</italic> which is similar to the function <italic>fmincon,</italic> but without any constraints on the parameters.</p></sec></sec></body><back><ack><p>The authors thank Peter Bossaerts, Nina Bradley, Mathieu Bertin, Yoshiro Tsutsui, Stefan Schaal, and Younggeun Choi for their helpful suggestions on the manuscript.</p></ack><glossary><title>Abbreviation</title><def-list><def-item><term>
            <italic>ITI</italic>
            <italic/>
          </term><def><p>inter-trial interval</p></def></def-item></def-list></glossary><ref-list><title>References</title><ref id="pcbi-0020152-b001"><label>1</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Platt</surname><given-names>ML</given-names></name></person-group>
					<year>2002</year>
					<article-title>Neural correlates of decisions.</article-title>
					<source>Curr Opin Neurobiol</source>
					<volume>12</volume>
					<fpage>141</fpage>
					<lpage>148</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b002"><label>2</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Samuelson</surname><given-names>PA</given-names></name></person-group>
					<year>1937</year>
					<article-title>A note on measurement of utility.</article-title>
					<source>Rev Econ Stud</source>
					<volume>4</volume>
					<fpage>155</fpage>
					<lpage>161</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b003"><label>3</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kagel</surname><given-names>JH</given-names></name><name name-style="western"><surname>Green</surname><given-names>L</given-names></name><name name-style="western"><surname>Caraco</surname><given-names>T</given-names></name></person-group>
					<year>1986</year>
					<article-title>When foragers discount the future: Constraints or adaptation?</article-title>
					<source>Anim Behav</source>
					<volume>34</volume>
					<fpage>271</fpage>
					<lpage>283</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b004"><label>4</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>RS</given-names></name><name name-style="western"><surname>Barto</surname><given-names>AG</given-names></name></person-group>
					<year>1998</year>
					<source>Reinforcement learning</source>
					<publisher-loc>Cambridge (Massachusetts)</publisher-loc>
					<publisher-name>The MIT press</publisher-name>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">322</size>
				</element-citation></ref><ref id="pcbi-0020152-b005"><label>5</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Ainslie</surname><given-names>G</given-names></name></person-group>
					<year>1975</year>
					<article-title>Specious reward: A behavioral theory of impulsiveness and impulse control.</article-title>
					<source>Psychol Bull</source>
					<volume>82</volume>
					<fpage>463</fpage>
					<lpage>496</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b006"><label>6</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Mazur</surname><given-names>JE</given-names></name></person-group>
					<year>1987</year>
					<article-title>An adjusting procedure for studying delayed reinforcement.</article-title>
					<comment>In:</comment>
					<person-group person-group-type="editor"><name name-style="western"><surname>Commons</surname><given-names>ML</given-names></name><name name-style="western"><surname>Mazur</surname><given-names>JE</given-names></name><name name-style="western"><surname>Nevin</surname><given-names>JA</given-names></name><name name-style="western"><surname>Rachlin</surname><given-names>H</given-names></name></person-group>
					<source>Quantitative analysis of behavior. Volume V: The effect of delay and intervening events</source>
					<publisher-loc>London</publisher-loc>
					<publisher-name>Erlbaum</publisher-name>
					<fpage>55</fpage>
					<lpage>73</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b007"><label>7</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Rodriguez</surname><given-names>ML</given-names></name><name name-style="western"><surname>Logue</surname><given-names>AW</given-names></name></person-group>
					<year>1988</year>
					<article-title>Adjusting delay to reinforcement: Comparing choice in pigeons and humans.</article-title>
					<source>J Exp Psychol Anim Behav Process</source>
					<volume>14</volume>
					<fpage>105</fpage>
					<lpage>117</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b008"><label>8</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Rachlin</surname><given-names>H</given-names></name><name name-style="western"><surname>Raineri</surname><given-names>A</given-names></name><name name-style="western"><surname>Cross</surname><given-names>D</given-names></name></person-group>
					<year>1991</year>
					<article-title>Subjective probability and delay.</article-title>
					<source>J Exp Anal Behav</source>
					<volume>55</volume>
					<fpage>233</fpage>
					<lpage>244</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b009"><label>9</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bateson</surname><given-names>M</given-names></name><name name-style="western"><surname>Kacelnik</surname><given-names>A</given-names></name></person-group>
					<year>1996</year>
					<article-title>Rate currencies and the foraging starling: The fallacy of the averages revisited.</article-title>
					<source>Behav Ecol</source>
					<volume>7</volume>
					<fpage>341</fpage>
					<lpage>352</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b010"><label>10</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bickel</surname><given-names>WK</given-names></name><name name-style="western"><surname>Odum</surname><given-names>AL</given-names></name><name name-style="western"><surname>Madden</surname><given-names>GJ</given-names></name></person-group>
					<year>1999</year>
					<article-title>Impulsivity and cigarette smoking: Delay discounting in current, never, and ex-smokers.</article-title>
					<source>Psychopharmacology (Berl)</source>
					<volume>146</volume>
					<fpage>447</fpage>
					<lpage>454</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b011"><label>11</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Ho</surname><given-names>MY</given-names></name><name name-style="western"><surname>Mobini</surname><given-names>S</given-names></name><name name-style="western"><surname>Chiang</surname><given-names>TJ</given-names></name><name name-style="western"><surname>Bradshaw</surname><given-names>CM</given-names></name><name name-style="western"><surname>Szabadi</surname><given-names>E</given-names></name></person-group>
					<year>1999</year>
					<article-title>Theory and method in the quantitative analysis of “impulsive choice” behaviour: Implications for psychopharmacology.</article-title>
					<source>Psychopharmacology (Berl)</source>
					<volume>146</volume>
					<fpage>362</fpage>
					<lpage>372</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b012"><label>12</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kirby</surname><given-names>KN</given-names></name><name name-style="western"><surname>Petry</surname><given-names>NM</given-names></name><name name-style="western"><surname>Bickel</surname><given-names>WK</given-names></name></person-group>
					<year>1999</year>
					<article-title>Heroin addicts have higher discount rates for delayed rewards than nondrug-using controls.</article-title>
					<source>J Exp Psychol Gen</source>
					<volume>128</volume>
					<fpage>78</fpage>
					<lpage>87</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b013"><label>13</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Petry</surname><given-names>NM</given-names></name></person-group>
					<year>2001</year>
					<article-title>Pathological gamblers, with and without substance use disorders, discount delayed rewards at high rates.</article-title>
					<source>J Abnorm Psychol</source>
					<volume>110</volume>
					<fpage>482</fpage>
					<lpage>487</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b014"><label>14</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name></person-group>
					<year>2000</year>
					<article-title>Metalearning and neuromodulation.</article-title>
					<source>Math Sci</source>
					<volume>38</volume>
					<fpage>19</fpage>
					<lpage>24</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b015"><label>15</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schweighofer</surname><given-names>N</given-names></name><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name></person-group>
					<year>2003</year>
					<article-title>Meta-learning in reinforcement learning.</article-title>
					<source>Neural Netw</source>
					<volume>16</volume>
					<fpage>5</fpage>
					<lpage>9</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b016"><label>16</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kirby</surname><given-names>KN</given-names></name><name name-style="western"><surname>Marakovic</surname><given-names>NN</given-names></name></person-group>
					<year>1995</year>
					<article-title>Modeling myopic decisions: Evidence for hyperbolic delay-discounting within subjects and amounts.</article-title>
					<source>Organ Behav Hum Dec</source>
					<volume>64</volume>
					<fpage>22</fpage>
					<lpage>30</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b017"><label>17</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Myerson</surname><given-names>J</given-names></name><name name-style="western"><surname>Green</surname><given-names>L</given-names></name></person-group>
					<year>1995</year>
					<article-title>Discounting of delayed rewards: Models of individual choice.</article-title>
					<source>J Exp Anal Behav</source>
					<volume>64</volume>
					<fpage>263</fpage>
					<lpage>276</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b018"><label>18</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Angeletos</surname><given-names>GM</given-names></name><name name-style="western"><surname>Laibson</surname><given-names>DI</given-names></name><name name-style="western"><surname>Repetto</surname><given-names>A</given-names></name><name name-style="western"><surname>Tobacman</surname><given-names>J</given-names></name><name name-style="western"><surname>Weinberg</surname><given-names>S</given-names></name></person-group>
					<year>2001</year>
					<article-title>The hyperbolic consumption model: Calibration, simulation, and empirical evaluation.</article-title>
					<source>J Econ Prospect</source>
					<volume>15</volume>
					<fpage>47</fpage>
					<lpage>68</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b019"><label>19</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Frederick</surname><given-names>S</given-names></name><name name-style="western"><surname>Loewenstein</surname><given-names>G</given-names></name><name name-style="western"><surname>O'Donoghue</surname><given-names>T</given-names></name></person-group>
					<year>2002</year>
					<article-title>Time discounting and time preference: A critical review.</article-title>
					<source>J Econ Lit</source>
					<volume>40</volume>
					<fpage>351</fpage>
					<lpage>401</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b020"><label>20</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Reynolds</surname><given-names>B</given-names></name><name name-style="western"><surname>Schiffbauer</surname><given-names>R</given-names></name></person-group>
					<year>2004</year>
					<article-title>Measuring state changes in human delay discounting: An experiential discounting task.</article-title>
					<source>Behav Process</source>
					<volume>67</volume>
					<fpage>343</fpage>
					<lpage>356</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b021"><label>21</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kacelnik</surname><given-names>A</given-names></name></person-group>
					<year>1997</year>
					<source>Normative and descriptive models of decision making: Time discounting and risk sensitivity. Characterizing human psychological adaptations</source>
					<publisher-loc>Chichester</publisher-loc>
					<publisher-name>Wiley</publisher-name>
					<fpage>51</fpage>
					<lpage>70</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b022"><label>22</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Laibson</surname><given-names>DI</given-names></name></person-group>
					<year>2003</year>
					<article-title>Intertemporal decision making.</article-title>
					<comment>In:</comment>
					<person-group person-group-type="editor"><name name-style="western"><surname>Nadel</surname><given-names>L</given-names></name></person-group>
					<source>Encyclopedia of cognitive science</source>
					<publisher-loc>London</publisher-loc>
					<publisher-name>Nature Publishing Group/Wiley Interscience</publisher-name>
				</element-citation></ref><ref id="pcbi-0020152-b023"><label>23</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Thaler</surname><given-names>RH</given-names></name><name name-style="western"><surname>Shefrin</surname><given-names>HM</given-names></name></person-group>
					<year>1981</year>
					<article-title>An economic theory of self-control.</article-title>
					<source>J Polit Economy</source>
					<volume>89</volume>
					<fpage>392</fpage>
					<lpage>410</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b024"><label>24</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Ainslie</surname><given-names>G</given-names></name></person-group>
					<year>2005</year>
					<article-title>Precis of breakdown of will.</article-title>
					<source>Behav Brain Sci</source>
					<volume>28</volume>
					<fpage>635</fpage>
					<lpage>650</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b025"><label>25</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Montague</surname><given-names>PR</given-names></name><name name-style="western"><surname>Berns</surname><given-names>GS</given-names></name></person-group>
					<year>2002</year>
					<article-title>Neural economics and the biological substrates of valuation.</article-title>
					<source>Neuron</source>
					<volume>36</volume>
					<fpage>265</fpage>
					<lpage>284</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b026"><label>26</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Crean</surname><given-names>JP</given-names></name><name name-style="western"><surname>de Wit</surname><given-names>H</given-names></name><name name-style="western"><surname>Richards</surname><given-names>JB</given-names></name></person-group>
					<year>2000</year>
					<article-title>Reward discounting as a measure of impulsive behavior in a psychiatric outpatient population.</article-title>
					<source>Exp Clin Psychopharmacol</source>
					<volume>8</volume>
					<fpage>155</fpage>
					<lpage>162</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b027"><label>27</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Madden</surname><given-names>GJ</given-names></name><name name-style="western"><surname>Petry</surname><given-names>NM</given-names></name><name name-style="western"><surname>Badger</surname><given-names>GJ</given-names></name><name name-style="western"><surname>Bickel</surname><given-names>WK</given-names></name></person-group>
					<year>1997</year>
					<article-title>Impulsive and self-control choices in opioid-dependent patients and nondrug-using control participants: Drug and monetary rewards.</article-title>
					<source>Exp Clin Psychopharmacol</source>
					<volume>5</volume>
					<fpage>256</fpage>
					<lpage>262</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b028"><label>28</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Vuchinich</surname><given-names>RE</given-names></name><name name-style="western"><surname>Simpson</surname><given-names>CA</given-names></name></person-group>
					<year>1998</year>
					<article-title>Hyperbolic temporal discounting in social drinkers and problem drinkers.</article-title>
					<source>Exp Clin Psychopharmacol</source>
					<volume>6</volume>
					<fpage>292</fpage>
					<lpage>305</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b029"><label>29</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Coffey</surname><given-names>SF</given-names></name><name name-style="western"><surname>Gudleski</surname><given-names>GD</given-names></name><name name-style="western"><surname>Saladin</surname><given-names>ME</given-names></name><name name-style="western"><surname>Brady</surname><given-names>KT</given-names></name></person-group>
					<year>2003</year>
					<article-title>Impulsivity and rapid discounting of delayed hypothetical rewards in cocaine-dependent individuals.</article-title>
					<source>Exp Clin Psychopharmacol</source>
					<volume>11</volume>
					<fpage>18</fpage>
					<lpage>25</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b030"><label>30</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Loewenstein</surname><given-names>G</given-names></name><name name-style="western"><surname>Prelec</surname><given-names>D</given-names></name></person-group>
					<year>1992</year>
					<article-title>Anomalies in intertemporal choice: Evidence and and interpretation.</article-title>
					<source>Quart J Econ</source>
					<volume>107</volume>
					<fpage>573</fpage>
					<lpage>597</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b031"><label>31</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Redish</surname><given-names>AD</given-names></name></person-group>
					<year>2004</year>
					<article-title>Addiction as a computational process gone awry.</article-title>
					<source>Science</source>
					<volume>306</volume>
					<fpage>1944</fpage>
					<lpage>1947</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b032"><label>32</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Phelps</surname><given-names>ES</given-names></name><name name-style="western"><surname>Pollack</surname><given-names>RA</given-names></name></person-group>
					<year>1968</year>
					<article-title>On second-best national saving and game-equilibrium growth.</article-title>
					<source>Rev Econ Stud</source>
					<volume>35</volume>
					<fpage>185</fpage>
					<lpage>199</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b033"><label>33</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Laibson</surname><given-names>D</given-names></name></person-group>
					<year>1997</year>
					<article-title>Golden eggs and hyperbolic discounting.</article-title>
					<source>Quart J Econ</source>
					<fpage>443</fpage>
					<lpage>477</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b034"><label>34</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Stevens</surname><given-names>JR</given-names></name><name name-style="western"><surname>Rosati</surname><given-names>AG</given-names></name><name name-style="western"><surname>Ross</surname><given-names>KR</given-names></name><name name-style="western"><surname>Hauser</surname><given-names>MD</given-names></name></person-group>
					<year>2005</year>
					<article-title>Will travel for food: Spatial discounting in two New World monkeys.</article-title>
					<source>Curr Biol</source>
					<volume>15</volume>
					<fpage>1855</fpage>
					<lpage>1860</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b035"><label>35</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Forzano</surname><given-names>LB</given-names></name><name name-style="western"><surname>Logue</surname><given-names>AW</given-names></name></person-group>
					<year>1992</year>
					<article-title>Predictors of adult humans' self-control and impulsiveness for food reinforcers.</article-title>
					<source>Appetite</source>
					<volume>19</volume>
					<fpage>33</fpage>
					<lpage>47</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b036"><label>36</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Loewenstein</surname><given-names>G</given-names></name></person-group>
					<year>1996</year>
					<article-title>Out of control: Visceral influences on behavior.</article-title>
					<source>Organ Behav Hum Dec</source>
					<volume>65</volume>
					<fpage>272</fpage>
					<lpage>292</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b037"><label>37</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Read</surname><given-names>D</given-names></name></person-group>
					<year>2001</year>
					<article-title>Is time-discounting hyperbolic or subadditive?</article-title>
					<source>J Risk Uncertainty</source>
					<volume>23</volume>
					<fpage>5</fpage>
					<lpage>32</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b038"><label>38</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Tanaka</surname><given-names>SC</given-names></name><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name><name name-style="western"><surname>Okada</surname><given-names>G</given-names></name><name name-style="western"><surname>Ueda</surname><given-names>K</given-names></name><name name-style="western"><surname>Okamoto</surname><given-names>Y</given-names></name><etal/></person-group>
					<year>2004</year>
					<article-title>Prediction of immediate and future rewards differentially recruits cortico–basal ganglia loops.</article-title>
					<source>Nat Neurosci</source>
					<volume>7</volume>
					<fpage>887</fpage>
					<lpage>893</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b039"><label>39</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>McClure</surname><given-names>SM</given-names></name><name name-style="western"><surname>Laibson</surname><given-names>DI</given-names></name><name name-style="western"><surname>Loewenstein</surname><given-names>G</given-names></name><name name-style="western"><surname>Cohen</surname><given-names>JD</given-names></name></person-group>
					<year>2004</year>
					<article-title>Separate neural systems value immediate and delayed monetary rewards.</article-title>
					<source>Science</source>
					<volume>306</volume>
					<fpage>503</fpage>
					<lpage>507</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b040"><label>40</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Coppen</surname><given-names>A</given-names></name><name name-style="western"><surname>Eccleston</surname><given-names>EG</given-names></name><name name-style="western"><surname>Peet</surname><given-names>M</given-names></name></person-group>
					<year>1972</year>
					<article-title>Total and free tryptophan concentration in the plasma of depressive patients.</article-title>
					<source>Lancet</source>
					<volume>2</volume>
					<fpage>1415</fpage>
					<lpage>1416</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b041"><label>41</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Coppen</surname><given-names>A</given-names></name><name name-style="western"><surname>Eccleston</surname><given-names>EG</given-names></name><name name-style="western"><surname>Peet</surname><given-names>M</given-names></name></person-group>
					<year>1973</year>
					<article-title>Total and free tryptophan concentration in the plasma of depressive patients.</article-title>
					<source>Lancet</source>
					<volume>2</volume>
					<fpage>60</fpage>
					<lpage>63</lpage>
				</element-citation></ref><ref id="pcbi-0020152-b042"><label>42</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hoshino</surname><given-names>Y</given-names></name><name name-style="western"><surname>Yamamoto</surname><given-names>T</given-names></name><name name-style="western"><surname>Kaneko</surname><given-names>M</given-names></name><name name-style="western"><surname>Kumashiro</surname><given-names>H</given-names></name></person-group>
					<year>1986</year>
					<article-title>Plasma free tryptophan concentration in autistic children.</article-title>
					<source>Brain Dev</source>
					<volume>8</volume>
					<fpage>424</fpage>
					<lpage>427</lpage>
				</element-citation></ref></ref-list></back></article>
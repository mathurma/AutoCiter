<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-01369</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003994</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurogenesis</subject><subj-group><subject>Cortical neurogenesis</subject></subj-group></subj-group><subj-group><subject>Synaptic plasticity</subject></subj-group></subj-group><subj-group><subject>Developmental neuroscience</subject><subj-group><subject>Neural circuit formation</subject></subj-group></subj-group><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and information sciences</subject><subj-group><subject>Computerized simulations</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Developmental Self-Construction and -Configuration of Functional Neocortical Neuronal Networks</article-title>
<alt-title alt-title-type="running-head">Simulation of Neuronal Network Development</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bauer</surname><given-names>Roman</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Zubler</surname><given-names>Frédéric</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Pfister</surname><given-names>Sabina</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Hauri</surname><given-names>Andreas</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Pfeiffer</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Muir</surname><given-names>Dylan R.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Douglas</surname><given-names>Rodney J.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Institute of Neuroinformatics, University/ETH Zürich, Zürich, Switzerland</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>School of Computing Science, Newcastle University, Newcastle upon Tyne, United Kingdom</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Department of Neurology, Inselspital Bern, Bern University Hospital, University of Bern, Bern, Switzerland</addr-line></aff>
<aff id="aff4"><label>4</label><addr-line>Biozentrum, University of Basel, Basel, Switzerland</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">roman.bauer@newcastle.ac.uk</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: RB SP RJD. Performed the experiments: RB SP. Analyzed the data: RB SP. Contributed reagents/materials/analysis tools: RB FZ SP AH. Wrote the paper: RB FZ SP MP DRM RJD.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>12</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>4</day><month>12</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>12</issue>
<elocation-id>e1003994</elocation-id>
<history>
<date date-type="received"><day>24</day><month>7</month><year>2014</year></date>
<date date-type="accepted"><day>9</day><month>10</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Bauer et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>The prenatal development of neural circuits must provide sufficient configuration to support at least a set of core postnatal behaviors. Although knowledge of various genetic and cellular aspects of development is accumulating rapidly, there is less systematic understanding of how these various processes play together in order to construct such functional networks. Here we make some steps toward such understanding by demonstrating through detailed simulations how a competitive co-operative (‘winner-take-all’, WTA) network architecture can arise by development from a single precursor cell. This precursor is granted a simplified gene regulatory network that directs cell mitosis, differentiation, migration, neurite outgrowth and synaptogenesis. Once initial axonal connection patterns are established, their synaptic weights undergo homeostatic unsupervised learning that is shaped by wave-like input patterns. We demonstrate how this autonomous genetically directed developmental sequence can give rise to self-calibrated WTA networks, and compare our simulation results with biological data.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>Models of learning in artificial neural networks generally assume that the neurons and approximate network are given, and then learning tunes the synaptic weights. By contrast, we address the question of how an entire functional neuronal network containing many differentiated neurons and connections can develop from only a single progenitor cell. We chose a winner-take-all network as the developmental target, because it is a computationally powerful circuit, and a candidate motif of neocortical networks. The key aspect of this challenge is that the developmental mechanisms must be locally autonomous as in Biology: They cannot depend on global knowledge or supervision. We have explored this developmental process by simulating in physical detail the fundamental biological behaviors, such as cell proliferation, neurite growth and synapse formation that give rise to the structural connectivity observed in the superficial layers of the neocortex. These differentiated, approximately connected neurons then adapt their synaptic weights homeostatically to obtain a uniform electrical signaling activity before going on to organize themselves according to the fundamental correlations embedded in a noisy wave-like input signal. In this way the precursor expands itself through development and unsupervised learning into winner-take-all functionality and orientation selectivity in a biologically plausible manner.</p>
</abstract>
<funding-group><funding-statement>This work was supported by the EU grant 216593 SECO (<ext-link ext-link-type="uri" xlink:href="http://www.seco-project.eu" xlink:type="simple">http://www.seco-project.eu</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="18"/></counts><custom-meta-group><custom-meta id="data-availability" xlink:type="simple"><meta-name>Data Availability</meta-name><meta-value>The authors confirm that all data underlying the findings are fully available without restriction. All relevant data are within the paper and its Supporting Information files.</meta-value></custom-meta></custom-meta-group></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>In this paper we address the question of how progenitor cells of the neocortical subplate can give rise to large functional neuronal sub-networks in the developed cortex. We choose winner-take-all (WTA) <xref ref-type="bibr" rid="pcbi.1003994-Yuille1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Yuille2">[2]</xref> connectivity as the target of this self-construction and -configuration process because these sub-networks are consistent with the observed physiology <xref ref-type="bibr" rid="pcbi.1003994-Douglas1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Douglas2">[4]</xref> and connectivity <xref ref-type="bibr" rid="pcbi.1003994-Binzegger1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Douglas3">[6]</xref> of neurons in the superficial layers of neocortex, and because they are powerful elements of computation <xref ref-type="bibr" rid="pcbi.1003994-Maass1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Rutishauser1">[8]</xref>. WTA networks actively select the strongest of multiple input signals, while suppressing the weaker ones. This fundamental characteristic is applicable in various contexts, and so many studies modeling cortical function are based on WTA modules <xref ref-type="bibr" rid="pcbi.1003994-Rutishauser1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Pfeiffer1">[15]</xref>.</p>
<p>The idealized WTA network architecture is shown in <xref ref-type="fig" rid="pcbi-1003994-g001">Fig. 1A</xref>. Excitatory neurons are recurrently connected to each other and also with one or more inhibitory neurons, which project back to the excitatory neurons. This architecture does not in itself guarantee WTA functionality. The degree of recurrent excitation, excitation of inhibitory neurons, and inhibition of excitatory neurons need all to lie within preferred ranges <xref ref-type="bibr" rid="pcbi.1003994-Rutishauser1">[8]</xref> in order for the network to exhibit effective WTA behavior. The appropriate neural architecture must be grown, and then the weights of the many synapses must be tuned to fall within the necessary ranges. Such neuronal growth and synapse formation are subject to variability (1B,C), for which the homeostatic learning mechanisms must compensate.</p>
<fig id="pcbi-1003994-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g001</object-id><label>Figure 1</label><caption>
<title>Winner-take-all architecture.</title>
<p>(<bold>A</bold>) Architecture of an idealised winner-take-all-network. Several excitatory neurons (red) excite a single shared inhibitory neuron, or a shared population of inhibitory neurons (blue). Each excitatory neuron receives inhibitory feedback in proportion to the average activity of the excitatory population. (<bold>B</bold>) The WTA architecture is embedded in the field of recurrent connections between a population of excitatory and inhibitory neurons. (<bold>C</bold>) Once the WTA architecture has formed, coarsely structured synaptic input drives synaptic refinement of the recurrent connections within the network.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g001" position="float" xlink:type="simple"/></fig>
<p>The behavior of a WTA network depends on the ratios of the effects of its various excitatory and inhibitory connection paths. In its high excitatory gain regime a WTA network will report only the strongest of its feed-forward inputs, and suppress the remainder of the excitatory neurons, which are weakly activated. In a more relaxed regime (soft-WTA, sWTA) the network will return a pattern of winners that best conforms to its input. In this sense the sWTA performs a pattern based signal restoration, which is a crucial mechanism for resisting degradation of processing in neural systems across their many computational steps. In this paper we choose to have the developmental process grow and tune these sWTA networks.</p>
<p>Our goal is to demonstrate how plausible genetic developmental mechanisms can combine with homeostatic synaptic tuning to bring networks of neurons into sWTA functionality (<xref ref-type="fig" rid="pcbi-1003994-g001">Fig. 1</xref>). Our demonstration is based on simulations of the development and growth of neural tissue in 3D physical space using <italic>Cx3D</italic> <xref ref-type="bibr" rid="pcbi.1003994-Zubler1">[16]</xref>. The simulation begins with a single precursor cell. This cell encodes gene-like instructions that are sequentially and conditionally expressed through a gene regulatory network (GRN). By controlling the expression of different genes, this GRN gives rise to pools of differentiated excitatory and inhibitory neurons. These neurons, which are placed randomly in 3D space, extend axons and dendrites and make synapses according to a proximity rule. This process results in a synaptically connected network that matches well experimentally obtained connectivity statistics. During this neurite outgrowth, the synaptic weights calibrate themselves homeostatically using experimentally established synaptic scaling <xref ref-type="bibr" rid="pcbi.1003994-Turrigiano1">[17]</xref> and BCM learning rules <xref ref-type="bibr" rid="pcbi.1003994-Bienenstock1">[18]</xref>. This synaptic learning is conditioned by coarsely patterned neuronal activity similar to that of retinal waves or cortico-thalamic loops <xref ref-type="bibr" rid="pcbi.1003994-Wong1">[19]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Kirkby1">[23]</xref>.</p>
<p>We compare these grown networks with biological data, and demonstrate WTA functionality. This comparison is done also in the context of cortical functionality, such as orientation selectivity. Importantly, the overall behavior stems solely from local processes, which are instantiated from internally encoded and developmental primitives <xref ref-type="bibr" rid="pcbi.1003994-Zubler2">[24]</xref>. Hence, we provide a model that explains the developmental self-construction and -configuration of a neocortical WTA network in a biologically plausible way.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Development of Differentiated Neurons Based on a Gene-Regulatory-Network</title>
<p>Cell proliferation and differentiation into different cell types is specified implicitly in the genetic code of a single precursor cell. This code determines how a given number of excitatory and inhibitory neurons is produced. During the unfolding process of this code, each cell contains the same genetic code, but because of its local environment can follow different developmental trajectories.</p>
<p>We model the molecular mechanisms that regulate cell differentiation by a dynamical gene regulatory network (GRN). This GRN is defined by a set of 5 variables (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e001" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e002" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e003" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e004" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e005" xlink:type="simple"/></inline-formula>) that represent substance concentrations, where each substance is the expression of a gene. Importantly, all cells have their own instantiations of these variables. The secretion, interaction, and decay of substances, is regulated by the laws of kinetics. The differential equations specifying these dynamics are shown in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<p>During the evolution of the substance concentrations, also cell growth and division is simulated. The cell cycle time and model parameters of the differential equations are fixed and independent of the substance dynamics.</p>
<p>Initially, all concentrations are set to zero. At this stage, only the “starter” substance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e006" xlink:type="simple"/></inline-formula> is produced, which reaches high concentration levels in the first time step, and triggers the production of a second gene <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e007" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e008" xlink:type="simple"/></inline-formula> is produced according to a prespecified intrinsic production constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e009" xlink:type="simple"/></inline-formula>. This value determines how many cell divisions will occur until the concentration of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e010" xlink:type="simple"/></inline-formula> reaches a value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e011" xlink:type="simple"/></inline-formula>. When this threshold is reached, a probabilistic decision is induced: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e012" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e013" xlink:type="simple"/></inline-formula>, responsible for activating the excitatory and inhibitory cell phenotypes, are triggered with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e014" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e015" xlink:type="simple"/></inline-formula>, respectively.</p>
<p>Such a GRN network configuration would enable us to generate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e016" xlink:type="simple"/></inline-formula> cells, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e017" xlink:type="simple"/></inline-formula> is the number of symmetric divisions. However, the target number of cells might not be an exponential of 2. Therefore, we have introduced a second gene <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e018" xlink:type="simple"/></inline-formula> that is (probabilistically) activated by high concentrations of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e019" xlink:type="simple"/></inline-formula>, and that leads to a second round of symmetric division. As for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e020" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e021" xlink:type="simple"/></inline-formula> activates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e022" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e023" xlink:type="simple"/></inline-formula> in a probabilistic manner. The probability to enter into this secondary cell cycle is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e024" xlink:type="simple"/></inline-formula>, which is computed based on the target number of cells. The evolution of the GRN across cell types is depicted in <xref ref-type="fig" rid="pcbi-1003994-g002">Fig. 2</xref>.</p>
<fig id="pcbi-1003994-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g002</object-id><label>Figure 2</label><caption>
<title>Gene Regulatory Network.</title>
<p>(<bold>A</bold>) Schematic representation of the GRN, composed of five interacting genes that give rise to excitatory and inhibitory neurons. The identity of a neuron is determined by the genes GE and GI for excitatory or inhibitory neurons, respectively. Arrows indicate a positive effect on gene expression. (<bold>B</bold>) Lineage tree. Nodes indicate cells; boxes indicate gene expression patterns. G0 triggers the expression of G1, which characterizes the undifferentiated state of progenitor cells. After a series of symmetric divisions, G1 reaches a concentration threshold. According to fixed probabilities, G1 can then activate the differentiation toward excitatory (red) or inhibitory (blue) neurons. Alternatively, a small proportion of cells probabilistically undergoes a second round of cell division and activates gene G2, which again promotes the differentiation toward excitatory or inhibitory neurons by the expression of GE or GI. The probabilistic activation of inhibitory or excitatory genes is a simplification, but guarantees the production of a homogeneously mixed population of neurons.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g002" position="float" xlink:type="simple"/></fig>
<p>By setting the production rate constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e025" xlink:type="simple"/></inline-formula> of gene <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e026" xlink:type="simple"/></inline-formula> and the probabilistic activation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e027" xlink:type="simple"/></inline-formula>, we can control the final number of cells produced. The equations for computing the probabilities for either differentiating into neurons by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e028" xlink:type="simple"/></inline-formula> induction (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e029" xlink:type="simple"/></inline-formula>) or by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e030" xlink:type="simple"/></inline-formula> induction (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e031" xlink:type="simple"/></inline-formula>), depending on the target number of cells, are shown in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<p>Overall, the GRN is designed so that a desired total number of cells is reached, and that the distribution of excitatory <italic>vs.</italic> inhibitory cells follows the approximate 4∶1 ratio observed in cortex <xref ref-type="bibr" rid="pcbi.1003994-Gabbott1">[25]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Li1">[27]</xref> (<xref ref-type="supplementary-material" rid="pcbi.1003994.s001">S1 Figure</xref>). <xref ref-type="fig" rid="pcbi-1003994-g003">Fig. 3(A-D)</xref> shows the evolution of an initial cell giving rise to a number of cells which eventually grow out neurites based solely on their genetic encoding.</p>
<fig id="pcbi-1003994-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g003</object-id><label>Figure 3</label><caption>
<title>Developmental process for building a competitive network.</title>
<p>A single precursor cell (<bold>A</bold>) contains the genetic code specifying the entire developmental process. (<bold>B</bold>) The precursor cell first undergoes repeated division to increase the pool of neuronal precursors (black). (<bold>C</bold>) Precursor neurons then differentiate into excitatory and inhibitory cell classes. (<bold>D</bold>) Neurite outgrowth begins to provide a scaffold for synaptic connections. (<bold>E</bold>) A network of differentiated neurons (grey) after neurite outgrowth has finished. For better visualization, examples of excitatory and inhibitory neurons are colored in red and blue, respectively. (<bold>F</bold>) Synapses (black rectangles) can form at appositions between axons and dendrites.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g003" position="float" xlink:type="simple"/></fig></sec><sec id="s2b">
<title>Neurite Growth and Synapse Formation</title>
<p>Neurite growth and arborization is caused by growth cone traction and bifurcation. The growth cone is able to sense the presence and gradient of morphogens and other signal molecules, and also able to actively explore the local extracellular space. Importantly, neurite growth is steered via a growth cone model instantiated at the tip of the axon or dendrite, and so is a local process.</p>
<p>Diffusable signal molecules are secreted by the cell somata. In these simulations excitatory and inhibitory neurons secrete two characteristic signals, that enable excitatory and inhibitory axons to find inhibitory and excitatory neurons, respectively. The axonal growth cones initially grow out of the somata in random directions. However, they retract whenever the concentration they sense falls below a threshold. The retraction stops and growth recommences when a second higher threshold is exceeded. In this way the axons remain close to substance secreting sources. Retraction is an efficient strategy for establishing connections because axons grow only into regions containing a potential target, and is commonly observed in developing neurons <xref ref-type="bibr" rid="pcbi.1003994-LaMantia1">[28]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-PorteraCailliau1">[31]</xref>. A video of a developing neural network with axonal retraction (simulated in Cx3D) is included in the Supporting Information (<xref ref-type="supplementary-material" rid="pcbi.1003994.s004">S1 Video</xref>) and on Youtube (<ext-link ext-link-type="uri" xlink:href="http://www.youtube.com/watch?v=il2uc-ZUZQ4" xlink:type="simple">http://www.youtube.com/watch?v=il2uc-ZUZQ4</ext-link>).</p>
<p>Axons deploy boutons. Whenever these boutons are sufficiently close to a potential post-synaptic site on a dendrite a synapse is created between them. Consequently, the final synaptic network connectivity depends on the nearly stochastic arrangement of regions of spatial proximity of the outgrowing axons and dendrites.</p>
<p>We adapted the parameters of the neurite outgrowth (see <xref ref-type="table" rid="pcbi-1003994-t001">Table 1</xref>) so that the connectivity of the simulated neuronal growth matched our experimental observations in layers II/III of cat visual cortex <xref ref-type="bibr" rid="pcbi.1003994-Binzegger1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Binzegger2">[32]</xref> (see <xref ref-type="fig" rid="pcbi-1003994-g004">Fig. 4A</xref>). Overall, we found that connectivity was robust to reasonable variation of the growth parameters and the random location of somata. The absolute numbers of synapses simulated here are smaller than observed in biology, due to constraints on computational resources. However, there is no inherent restriction on scalability using our methods, and so we expect that realistic numbers of cells and synapses could if necessary be simulated using supercomputers.</p>
<fig id="pcbi-1003994-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g004</object-id><label>Figure 4</label><caption>
<title>Connectivity after simulated neurite outgrowth.</title>
<p>(<bold>A</bold>) Comparison of connectivity statistics from Cx3D simulations (blue) with experimental data (red) from <xref ref-type="bibr" rid="pcbi.1003994-Binzegger1">[5]</xref>. Indicated on the vertical axis are the numbers (normalized with respect to the first bar) of synapses onto a single neuron. The individual bars show the values for the different pre- and postsynaptic neuron pairs (excitatory or inhibitory synapses onto an excitatory or inhibitory postsynaptic neuron). The numbers match in proportion, while the absolute quantities are higher in the biological data (approximately 155 <italic>vs.</italic> 3500 excitatory synapses onto a single excitatory neuron in the simulated and biological connectivity, respectively). This particular simulation consists of 250 neurons (200 excitatory and 50 inhibitory), which are randomly arranged in 3D space. (<bold>B</bold>) Histogram of the percentage of excitatory input synapses across the simulated network from (A). Each bar indicates the number of neurons that have a particular percentage of excitatory input synapses (after neurite growth and synapse formation have ended). The final distribution has a mean of 84%, which is in line with experimental assessments <xref ref-type="bibr" rid="pcbi.1003994-Binzegger1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Beaulieu1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-DeFelipe1">[35]</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g004" position="float" xlink:type="simple"/></fig><table-wrap id="pcbi-1003994-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.t001</object-id><label>Table 1</label><caption>
<title>Parameters for simulating axonal and dendritic growth.</title>
</caption><alternatives><graphic id="pcbi-1003994-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Parameter</td>
<td align="left" rowspan="1" colspan="1">Value (Ex. Axon/Inh. Axon/Ex. Dendrite/Inh. Dendrite)</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e032" xlink:type="simple"/></inline-formula> (minimal diameter)</td>
<td align="left" rowspan="1" colspan="1">0.2/0.2/0.3/0.3</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e033" xlink:type="simple"/></inline-formula> (diameter reduction when moving)</td>
<td align="left" rowspan="1" colspan="1">0.004/0.012/0.02/0.042</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e034" xlink:type="simple"/></inline-formula> (diameter reduction when bifurcating)</td>
<td align="left" rowspan="1" colspan="1">0.12/0.105/0.14/0.12</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e035" xlink:type="simple"/></inline-formula> (baseline probability for bifurcation)</td>
<td align="left" rowspan="1" colspan="1">0.05/0.08/0.04/0.05</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e036" xlink:type="simple"/></inline-formula> (substance dependent probability for bifurcation)</td>
<td align="left" rowspan="1" colspan="1">0.005/0.05/0.0/0.0</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">speed of growth</td>
<td align="left" rowspan="1" colspan="1">100/100/100/100</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">speed of retraction</td>
<td align="left" rowspan="1" colspan="1">5/5/(no retraction)/(no retraction)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e037" xlink:type="simple"/></inline-formula> (concentration threshold triggering retraction)</td>
<td align="left" rowspan="1" colspan="1">1e-8/1e-8/(no retraction)/(no retraction)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e038" xlink:type="simple"/></inline-formula> (concentration threshold stopping retraction)</td>
<td align="left" rowspan="1" colspan="1">0.036/0.036/(no retraction)/(no retraction)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e039" xlink:type="simple"/></inline-formula> (weight of previous growth direction)</td>
<td align="left" rowspan="1" colspan="1">0.75/0.75/0.75/0.75</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e040" xlink:type="simple"/></inline-formula> (weight of random direction)</td>
<td align="left" rowspan="1" colspan="1">0.25/0.25/0.25/0.25</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e041" xlink:type="simple"/></inline-formula> (neurite discretization size)</td>
<td align="left" rowspan="1" colspan="1">7/7/7/7</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>Growth parameters are dependent on the type of the neurite, as well as the neuron type. In order to qualitatively match biological observations, we modeled axons to be longer than dendrites and inhibitory (basket) cells to have smaller spatial extent than excitatory neurons <xref ref-type="bibr" rid="pcbi.1003994-Markram1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Fiala1">[132]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Stepanyants1">[134]</xref>. In our model, axons direct their growth based on extracellular substance concentrations.</p></fn></table-wrap-foot></table-wrap>
<p><xref ref-type="fig" rid="pcbi-1003994-g004">Fig. 4B</xref> shows the distribution of the percentage of excitatory input synapses to the neurons, across the whole population. The average percentage of excitatory inputs to a neuron in this network is 84%, which is in good agreement with the experimental data. This result is consistent with observations across species and cortical areas that some 15% of all the synapses are GABAergic <xref ref-type="bibr" rid="pcbi.1003994-Binzegger1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Beaulieu1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-DeFelipe1">[35]</xref>, irrespective of neuronal densities. Importantly, this good agreement arises naturally out of the growth model, and did not require extensive tuning of the model parameters.</p>
</sec><sec id="s2c">
<title>Electrophysiology</title>
<p>The self-configuration of electrophysiological processing depends on the tuning of network synaptic weights and neuronal activity. In order to simulate this aspect of the developing networks, we must model also the electrical activity of neurons. However, the time scales of morphological growth and electrophysiological dynamics are many orders of magnitude different, and this difference makes for substantial technical problems in simulation.</p>
<p>For simplicity, and for minimizing computational demands we have used a rate-based approach to modeling neuronal activity. We approximate the neuronal activation by a linear-threshold function <xref ref-type="bibr" rid="pcbi.1003994-Dayan1">[36]</xref> that describes the output action potential discharge rate of the neuron as a function of its input. This type of neuronal activation function is a good approximation to experimental observations of the adapted current discharge relation of neurons <xref ref-type="bibr" rid="pcbi.1003994-Azouz1">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Ahmed1">[38]</xref> and has been used in a wide range of modeling works <xref ref-type="bibr" rid="pcbi.1003994-Rutishauser1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-BenYishai1">[39]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Hahnloser2">[41]</xref>.</p>
<p>The linear-threshold activation function is:<disp-formula id="pcbi.1003994.e042"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e042" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e043" xlink:type="simple"/></inline-formula> denotes the firing rate of a neuron with index i, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e044" xlink:type="simple"/></inline-formula> is the neuronal time constant, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e045" xlink:type="simple"/></inline-formula> is the spontaneous activity, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e046" xlink:type="simple"/></inline-formula> is the feed-forward input to neuron i, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e047" xlink:type="simple"/></inline-formula> is the weight of the connection from neuron j to neuron i (can be positive or negative, depending on the presynaptic neuron's type), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e048" xlink:type="simple"/></inline-formula> is the neuron's threshold. For simplicity, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e049" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e050" xlink:type="simple"/></inline-formula> are set to 1 and 0. Exploratory simulations where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e051" xlink:type="simple"/></inline-formula> yielded very similar results.</p>
<p>For computational efficiency, the electrophysiology simulator is implemented as a global process that acts on the total weight matrix of the neuronal network, rather than performing these frequent computations locally. We chose this global methodology because it leads to a significant speed-up compared with a local version that had been used initially. The total weight matrix is obtained by summation of the weights of all synapses in the Cx3D simulation. Using these connection weights, neuronal activity is computed as described in <xref ref-type="disp-formula" rid="pcbi.1003994.e042">Eq. 1</xref>. Connection weight changes resulting from the learning and adaptation (explained below) are computed based on this summed weight matrix and the activities of the two respective connected neurons, which are saved at each electrophysiology time step. The same connection weights (and neuronal activities) would be computed if only local processes at the synapses were simulated, because the synaptic learning and adaptation dynamics (<xref ref-type="disp-formula" rid="pcbi.1003994.e052">Eq. 2</xref> and <xref ref-type="disp-formula" rid="pcbi.1003994.e059">3</xref>) are dependent on the (locally available) neuronal activities, and linearly dependent on the synaptic weight. Hence, the dynamics of the summed synaptic weights match the sum of the individual synapse weight changes.</p>
<p>For reasons of biological plausibility, the electrophysiology simulator incorporates a maximum connection weight. This maximum weight for the functional connection strength between two neurons is determined by counting the number of synapses involved. This number, multiplied by the maximal weight of a single synapse, is defined as the maximum of the total connection weight. Hence, neurons that are connected by few synapses can not establish a strong functional link.</p>
<p>In our model, self-configuration of the weights towards sWTA functionality occurs during sequential developmental phases. Sequential phases of electrical adaptation and learning during development have been observed experimentally <xref ref-type="bibr" rid="pcbi.1003994-Hensch1">[42]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Espinosa1">[43]</xref>, and have also been applied in previous models <xref ref-type="bibr" rid="pcbi.1003994-Bednar1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Srinivasa1">[45]</xref>.</p>
<p>During the first, homeostatic phase neurons adapt the synaptic weights of their own input in order to maintain a target output activity. The effect of this phase is to bring the neuronal firing rates into a balanced regime, and so allow for a reliable synaptic learning without interference by unresponsive neurons or run-away excitation. During the second, specification phase the neurons structure their individual responses by correlation-based learning on their inputs.</p>
<sec id="s2c1">
<title>Homeostatic phase</title>
<p>During this first phase of activity-dependent adaptation, neurite outgrowth, synapse formation and homeostatic adaptation of neuronal activity occur simultaneously. Neurons implement the synaptic scaling rule <xref ref-type="bibr" rid="pcbi.1003994-Turrigiano1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Turrigiano2">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Turrigiano3">[47]</xref>, whereby they scale their synaptic input weights to achieve a preferred average output firing rate. Thus, when their average output activity exceeds a given target, neurons scale their excitatory and inhibitory inputs down and up respectively. The opposite effect occurs when the average activity has fallen below the target. Since there is no correlation-based learning during this phase the population of neurons can converge towards stable average levels of activity, but there is no input learning.</p>
<p>The equations for synaptic scaling are given by <xref ref-type="bibr" rid="pcbi.1003994-VanRossum1">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Liu1">[49]</xref>:<disp-formula id="pcbi.1003994.e052"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e052" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e053" xlink:type="simple"/></inline-formula> is the connection strength from neuron j to neuron i, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e054" xlink:type="simple"/></inline-formula> is the time constant of the learning rule (usually hours or days), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e055" xlink:type="simple"/></inline-formula> is desired average activity of postsynaptic neuron i, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e056" xlink:type="simple"/></inline-formula> is the actual average activity of neuron i. <xref ref-type="fig" rid="pcbi-1003994-g005">Fig. 5</xref> shows that this synaptic scaling permits the simulated network to reach a stable state with robust excitatory and inhibitory firing rates.</p>
<fig id="pcbi-1003994-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g005</object-id><label>Figure 5</label><caption>
<title>Homeostatic adaptation of neuronal firing rates during establishment of synaptic connectivity.</title>
<p>(<bold>A</bold>) Synaptic scaling during neurite outgrowth leads to robust average activities of both excitatory (red) and inhibitory (blue) neurons. The network consists of 250 neurons that are randomly arranged in 3D space. The horizontal axis indicates the estimated real-time when taking into account that the time constant of synaptic scaling is in the order of several hours <xref ref-type="bibr" rid="pcbi.1003994-Turrigiano1">[17]</xref>. At <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e057" xlink:type="simple"/></inline-formula> (dashed line), the neurite outgrowth begins. Average firing rates of layer II/III pyramidal neurons have been shown to be smaller than 1 Hz <italic>in-vivo</italic> <xref ref-type="bibr" rid="pcbi.1003994-Greenberg1">[128]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-DeKock1">[129]</xref>. Experimental data indicates that inhibitory neurons have higher activities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e058" xlink:type="simple"/></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1003994.e052">Eq. 2</xref>) than excitatory neurons <xref ref-type="bibr" rid="pcbi.1003994-Mruczek1">[68]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Liu2">[100]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Swadlow1">[130]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Povysheva1">[131]</xref>. In this simulation there are not yet any input projections, so the activity originates solely from internally generated and random activity. (<bold>B</bold>) Total (excitatory and inhibitory) number of synapses in the network during development. New synapses are formed also after the neurons reach the target average activities, without disrupting the homeostatic adaptation process or bringing the network out of balance. These simulation results demonstrate the robustness of the synaptic scaling process during network growth.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g005" position="float" xlink:type="simple"/></fig>
<p>Post-synaptic scaling is not the only mechanism that can be used for neuronal activity homeostasis. For example, <xref ref-type="bibr" rid="pcbi.1003994-Liu1">[49]</xref> has described an extended version of synaptic scaling: The presynaptic-dependent synaptic scaling (PSD) rule. We also implemented that PSD rule, but obtained results which differed only slightly from traditional synaptic scaling.</p>
<p>In the later stages of this first phase, input neurons (that are not part of the growing network) are added to the model (see <xref ref-type="fig" rid="pcbi-1003994-g001">Fig. 1C</xref>). These input neurons could correspond, for example, to thalamic or cortical layer IV neurons. They are initially fully connected to neurons of the grown network, and their projection efficacies are randomly drawn from a uniform distribution. Importantly, there is a neighborhood relationship amongst the input neurons: Input populations can be topologically close to, or distant from one another. The input neurons provide coarsely patterned input activity to the grown network. We chose hill-shaped patterns of activity centered on a given population, and decaying with topological distance from its center. The centers of these patterns move periodically in a noisy wave-like fashion (see <xref ref-type="sec" rid="s4">Methods</xref>). This patterning of the electrical activity in the input layer can be interpreted as, for example, the retinal waves in early development <xref ref-type="bibr" rid="pcbi.1003994-Wong1">[19]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Kirkby1">[23]</xref>, that can induce correlations within the activities of downstream neural subpopulation.</p>
<p>By the end of this homeostatic phase, neurons and synapses have reached their final structural configuration. Overall, this phase prepares the network for the next phase of correlation-based learning of input stimuli.</p>
</sec><sec id="s2c2">
<title>Specification phase</title>
<p>In this phase synapses onto excitatory postsynaptic neurons obey the Bienenstock-Cooper-Munro (BCM) learning rule <xref ref-type="bibr" rid="pcbi.1003994-Bienenstock1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Cooper1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Cooper2">[51]</xref>, rather than synaptic scaling. The BCM rule is composed of a Hebbian term, and a homeostatic term which determines whether the Hebbian synapse grows stronger or weaker.</p>
<p>The BCM learning rule is:<disp-formula id="pcbi.1003994.e059"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e059" xlink:type="simple"/><label>(3)</label></disp-formula></p>
<p>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e060" xlink:type="simple"/></inline-formula> denote the discharge rates of post- and pre-synaptic neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e061" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e062" xlink:type="simple"/></inline-formula> is the averaged square of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e063" xlink:type="simple"/></inline-formula>'s firing rate, multiplied by a constant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e064" xlink:type="simple"/></inline-formula>). The constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e065" xlink:type="simple"/></inline-formula> determines the average firing rate that the neuron converges towards in the stationary state; the condition <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e066" xlink:type="simple"/></inline-formula> is met in the non-trivial case where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e067" xlink:type="simple"/></inline-formula>. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e068" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e069" xlink:type="simple"/></inline-formula> denote the target average firing rates of excitatory and inhibitory neurons, respectively. Then in order for the neurons to converge to these firing rates, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e070" xlink:type="simple"/></inline-formula> is set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e071" xlink:type="simple"/></inline-formula> if neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e072" xlink:type="simple"/></inline-formula> is excitatory, or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e073" xlink:type="simple"/></inline-formula> if it is inhibitory.</p>
<p>All synapses (excitatory and inhibitory) made onto excitatory neurons follow the BCM learning rule, while those onto inhibitory neurons follow the synaptic scaling (<xref ref-type="disp-formula" rid="pcbi.1003994.e052">Eq. 2</xref>) rule. While learning is commonly attributed to excitatory synapses, inhibitory synapses can also undergo long-term potentiation (LTP) as well as long-term depression (LTD) <xref ref-type="bibr" rid="pcbi.1003994-Haas1">[52]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Vogels1">[55]</xref>.</p>
<p>The lack of a correlative term for synapses onto inhibitory postsynaptic neurons is, as shown below, necessary to match experimental data on orientation selectivity of excitatory and inhibitory neurons in mouse visual cortex. We therefore hypothesize that basket cells in the superficial layers of cortex homeostatically adapt their input synapses, in contrast to pyramidal neurons, which also use correlational information.</p>
<p>We have also explored the case in which the same learning rule is used by all synapses. This case also yields WTA functionality (see below). Given that there are many different classes of inhibitory neurons <xref ref-type="bibr" rid="pcbi.1003994-Markram1">[56]</xref>, which differ also in their developmental characteristics <xref ref-type="bibr" rid="pcbi.1003994-BatistaBrito1">[57]</xref>, it is possible that different interneuron types follow different learning rules.</p>
</sec></sec><sec id="s2d">
<title>Functional Properties</title>
<sec id="s2d1">
<title>Self-organization of WTA functionality</title>
<p>As a consequence of the synaptic learning in the second developmental phase, the network learns the topology of its inputs. Those neurons which are excited by a common input, become more strongly connected with one another. Because of the competition that is inherent to the BCM learning rule, excitatory neurons become progressively more connected to only particular input neurons (those which evoke their strongest response), while decreasing their affinity to the others. <xref ref-type="fig" rid="pcbi-1003994-g006">Fig. 6A</xref> shows that the final functional connectivity of excitatory neurons indeed exhibits a strong neighborhood relationship: The connection weights are stronger around the diagonal, so that the neurons are close to or distant from one another in weight space. This connection topology reflects the (1-dimensional) topology of the input patterns.</p>
<fig id="pcbi-1003994-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g006</object-id><label>Figure 6</label><caption>
<title>Winner-take-all functionality.</title>
<p>(<bold>A</bold>) Weight matrix of 117 excitatory neurons in a WTA network. After learning the network exhibits a 1-dimensional neighborhood topology, as shown by the predominantly strong weights around the diagonal. This topology mirrors the neighborhood relationship of the input stimuli, which are continuously and periodically moving hills of activity. Only the excitatory connections are shown here, because the inhibitory neurons do not integrate into the neighborhood topology (see text). (<bold>B</bold>) Demonstration of WTA functionality on the network connectivity shown in (A). Neurons are ordered here such that adjacent neurons connect most strongly. The input to the network (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e074" xlink:type="simple"/></inline-formula>; top row) has a hill shape, with added noise. The network response (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e075" xlink:type="simple"/></inline-formula>; middle row) is a de-noised version of the input with the bump in the same location. The neuronal gain (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e076" xlink:type="simple"/></inline-formula>; bottom row) is high for neurons receiving the strongest input, and low (or zero) for neurons distant from the main input to the network. The dashed horizontal line indicates a gain of 1. (<bold>C</bold>) Activity of a winning neuron (blue, solid), during presentation of its feedforward input (blue, dashed) in the same simulation as shown in (B). Recurrent connectivity amplifies the response of the neuron for the duration of the stimulus (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e077" xlink:type="simple"/></inline-formula>). In contrast, a losing neuron (green, solid) receives non-zero feedforward input (green, dashed), but is suppressed due to the WTA functionality of the network. (<bold>D</bold>) Response of the same network to a different feedforward input. The recovery of a bump shaped activity can occur anywhere in the network topology.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g006" position="float" xlink:type="simple"/></fig>
<p>The inhibitory neurons do not integrate into this topology because the synapses onto inhibitory neurons follow the non-Hebbian synaptic scaling rule, and so their input correlations can not be learned. <xref ref-type="fig" rid="pcbi-1003994-g006">Fig. 6B,D</xref> show examples of the final soft-WTA functionality, after the network has learned the input topology. The excitatory neurons receiving the largest input are predominantly enhanced due to recurrent excitation with one another. The inhibitory neurons reflect the overall activity, and reduce the losing neurons' activity, more than they are enhanced by excitatory inputs. From a functional point of view, this active selection of the winning population improves the signal to noise ratio, and confirms their sWTA properties.</p>
</sec><sec id="s2d2">
<title>Unsupervised clustering</title>
<p>WTA networks are able to perform pattern recognition and classification, i.e. that neurons cluster functionally and respond to patterns in a discriminative and classifying manner. We explored whether this property can arise in a biological setting, as captured by our developmental model. To do this, the processes of connectivity establishment and synaptic homeostasis were simulated as described before. However, during the learning phase input patterns consisting of discrete bars of different position and orientation (<xref ref-type="fig" rid="pcbi-1003994-g007">Fig. 7A</xref>) were presented to the network. In this input regime there are no continuous orderings between individual patterns (which is the case for the retinal-wave like activation patterns).</p>
<fig id="pcbi-1003994-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g007</object-id><label>Figure 7</label><caption>
<title>Clustering and decorrelation of representations.</title>
<p>(<bold>A–C</bold>) Discrete input patterns give rise to clusters in the functional connectivity of the WTA network. (<bold>A</bold>) Input stimuli used in the learning process. Filled and empty spheres indicate strongly and weakly active populations, respectively. (<bold>B,C</bold>) Visualization of the network structure before and after learning. Strongly-coupled neurons are drawn close together; excitatory synaptic connections are indicated by grey links. Excitatory neurons are coloured according to their preferred input pattern (colours in A); inhibitory neurons (square) are drawn in yellow. (<bold>B</bold>) Before learning, no clustering of synaptic connections is present. (<bold>C</bold>) After learning, neurons with the same preferred stimulus are strongly interconnected. See <xref ref-type="supplementary-material" rid="pcbi.1003994.s005">S2 Video</xref>. (<bold>D</bold>) Before learning, the response of the network is similar across all stimuli. Shown is the scalar product between the vectors of neuronal responses to pairs of stimuli <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e078" xlink:type="simple"/></inline-formula>. The noise was added in order to assess the sensitivity of the network's activity to a perturbation of the input signal (see text). The high values and uniformity of scalar products in (D) indicates that network responses poorly distinguish between stimuli. (<bold>E</bold>) After learning, responses to noisy stimulus presentations are highly similar (high values of scalar product; black diagonal), whereas responses to different stimuli are decorrelated (low values of scalar product; light shading).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g007" position="float" xlink:type="simple"/></fig>
<p>Learning the discrete input stimuli causes the population to partition into sub-populations, or assemblies, as shown in <xref ref-type="fig" rid="pcbi-1003994-g007">Fig. 7C</xref>. We demonstrated the generality of this learning by simulating the clustering in response to presentation of only 4 input stimuli, using the same network and simulation parameters as in the case with a full range of stimuli (<xref ref-type="supplementary-material" rid="pcbi.1003994.s002">S2A Figure</xref>). We also examined the scenario in which all synapses (including those onto inhibitory neurons) follow the same BCM learning rule. As anticipated, this case yielded networks in which inhibitory neurons cluster along with the excitatory populations (compare <xref ref-type="supplementary-material" rid="pcbi.1003994.s002">S2B Figure</xref> with <xref ref-type="fig" rid="pcbi-1003994-g007">Fig. 7C</xref>).</p>
<p>The clustered functional connectivity allows the network to decorrelate its inputs, so that even noisy signals can be reliably differentiated. We quantified this ability by testing the network response to a particular pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e079" xlink:type="simple"/></inline-formula>, by comparison with pattern <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e080" xlink:type="simple"/></inline-formula>. This comparison was measured using the scalar product between the activities in the network after presentation of the different input patterns. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e081" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e082" xlink:type="simple"/></inline-formula> be the n-dimensional vectors of the neuronal activities in a network of n neurons, in response to the stimuli <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e083" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e084" xlink:type="simple"/></inline-formula>, respectively. The scalar product <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e085" xlink:type="simple"/></inline-formula> then quantifies whether the responses to the two stimuli <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e086" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e087" xlink:type="simple"/></inline-formula> are very different (s close to 0) or correlated (s close to 1). To demonstrate that the results are valid under more biologically plausible conditions, noisy stimuli were used. A noisy input stimulus is defined as:<disp-formula id="pcbi.1003994.e088"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e088" xlink:type="simple"/><label>(4)</label></disp-formula></p>
<p>where k is the index of the input population and U is the stimulus identifier. M is the amplitude of the active populations in the input (which we set to 10 Hz in this case), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e089" xlink:type="simple"/></inline-formula> is uniformly distributed noise in the range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e090" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1003994-g006">Fig. 6D, E</xref> shows the correlations of the network's responses for 8 different input stimuli before (D) and after (E) learning under noisy <italic>vs.</italic> not noisy (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e091" xlink:type="simple"/></inline-formula>) conditions. The off-diagonal elements in the correlation matrix are much lower after learning than before. These results demonstrate the decorrelation of the network's activity, and the robustness to input noise.</p>
</sec><sec id="s2d3">
<title>Competition between states</title>
<p>In addition to the decorrelation of responses, clustering provides competition between inputs. This property is computationally interesting because it forces the network to make a decision based on its input (<xref ref-type="fig" rid="pcbi-1003994-g008">Fig. 8A</xref>). We demonstrated this competition by presenting simultaneously two competing patterns (after the network had learned 4 different patterns). The relative proportion of these patterns in the input was gradually varied between the first and second pattern.</p>
<fig id="pcbi-1003994-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g008</object-id><label>Figure 8</label><caption>
<title>Stimuli are represented by competing subpopulations.</title>
<p>(<bold>A</bold>) Competition for representation of a mixture of 2 concurrent stimuli. Shown is the normalized average activity of two sub-populations, in response to mixtures of the preferred stimuli of the two populations. For mixtures containing predominately one stimulus (mixture proportions close to 0 and 1), the populations are strongly in competition, and the network represents exclusively the stronger of the two stimuli (responses near 0 and 1). For intermediate mixture proportions, competition causes a rapid shift between representations of the two stimuli (deviation from diagonal reference line). (<bold>B</bold>) Increasing the gain of the network <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e092" xlink:type="simple"/></inline-formula> (black line: 1.3, blue: 1.5, red: 1.8) increases the stability of representations, and increases the rate of switching between representations due to stronger competition.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g008" position="float" xlink:type="simple"/></fig>
<p>The results show that the stronger stimulus non-linearly dominates responses in the WTA network, so that the masked stimulus evokes an activity pattern that resembles that evoked by the strong stimulus alone. These results are in accord with experimental studies in visual cortex <xref ref-type="bibr" rid="pcbi.1003994-Busse1">[58]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Tsai1">[60]</xref> and auditory cortex <xref ref-type="bibr" rid="pcbi.1003994-Bathellier1">[61]</xref>.</p>
<p>The nature of the competition between the states is dependent on the functional connectivity. Strong recurrent excitation (i.e. a high gain) yields strong inhibition, which results in a marked switching behavior between the different populations. This is because the competition is strong, and so the switch from one state to the other is more evident. A high slope of the transition reflects a functionality similar to a bistable switch. More specifically, the slope of the transition (middle part of the interpolation in <xref ref-type="fig" rid="pcbi-1003994-g008">Fig. 8A</xref>) increases with the gain of the WTA network. This gain can be adjusted via the homeostatic average activities: Higher target activities lead to more recurrent excitation, which increases the gain. Such differently graded competition is seen in <xref ref-type="fig" rid="pcbi-1003994-g008">Fig. 8B</xref>. Bistability is also interesting from a computational point of view, because discrete states can be represented reliably. This kind of reliability is useful for performing computation with states based on analog elements <xref ref-type="bibr" rid="pcbi.1003994-Rutishauser1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-VonNeumann1">[62]</xref>. Competition also develops when synapses onto excitatory as well as inhibitory neurons follow the BCM learning rule, as shown in <xref ref-type="supplementary-material" rid="pcbi.1003994.s003">S3 Figure</xref>.</p>
</sec></sec><sec id="s2e">
<title>Correspondence with Orientation Selectivity of Excitatory and Inhibitory Neurons</title>
<p>We investigated whether our developmental model can account for experimental findings on orientation selectivity in visual cortex; for example, differences in tuning between excitatory and inhibitory neurons. In order to address this question, we assumed that the hills of activity in the input layer correspond to oriented stimuli (e.g. bars), which are smoothly and periodically rotating between 0 and 180 degrees. As anticipated from the previous results, excitatory neurons become highly orientation selective (<xref ref-type="fig" rid="pcbi-1003994-g009">Fig. 9</xref>), in contrast to inhibitory neurons. These results are in line with biological data. For example, <xref ref-type="bibr" rid="pcbi.1003994-Kerlin1">[63]</xref> have analyzed orientation selectivity of excitatory and inhibitory neurons in mouse visual cortex. They report inhibitory neurons to be more broadly tuned and hence less selective than excitatory, pyramidal neurons. Similar findings were reported by <xref ref-type="bibr" rid="pcbi.1003994-Niell1">[64]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Mruczek1">[68]</xref>.</p>
<fig id="pcbi-1003994-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g009</object-id><label>Figure 9</label><caption>
<title>Excitatory neurons are strongly tuned; inhibitory neurons are poorly tuned.</title>
<p>Tuning properties of excitatory and inhibitory neurons. (<bold>A</bold>) Representative tuning curves for 3 excitatory (red, 1-3) and 3 inhibitory (blue, 4-6) neurons in a WTA network after the learning process. Excitatory neurons exhibit strong and narrowly tuned preference for certain inputs, in contrast to inhibitory neurons. (<bold>B</bold>) Distribution of the orientation selectivity index (OSI) across all excitatory and inhibitory neurons in a WTA network, demonstrating the discrepancy of tuning on a population level. (<bold>C</bold>) Simulation of the same learning rule for synapses onto excitatory as well as inhibitory neurons yields orientation-tuned neurons in both populations.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g009" position="float" xlink:type="simple"/></fig>
<p>We also quantified the orientation tuning based on the orientation selectivity index (OSI), which specifies the degree to which a neuron is selective for orientation. The value of this index lies between 0 (non-selective) and 1 (selective to a single, specific orientation). <xref ref-type="fig" rid="pcbi-1003994-g009">Fig. 9B</xref> shows the distribution of the OSI for excitatory and inhibitory neurons in a WTA network, demonstrating the discrepancy of orientation selectivity also on a population level. We conducted additional simulations, which demonstrated that when inhibitory neurons follow the same learning rule as excitatory neurons, they exhibit more narrowly tuned orientation selectivity (<xref ref-type="fig" rid="pcbi-1003994-g009">Fig. 9C</xref>). Hence, experimental findings of orientation selective inhibitory neurons in cat visual cortex <xref ref-type="bibr" rid="pcbi.1003994-Azouz2">[69]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Nowak1">[72]</xref> can also be accounted for by our model.</p>
</sec><sec id="s2f">
<title>Inhibition of Excitatory Neurons</title>
<p>We have analyzed the consequences of our model on the nature of the inhibition of excitatory neurons. As mentioned above, inhibitory synapses onto excitatory neurons are subject to the BCM learning rule (<xref ref-type="disp-formula" rid="pcbi.1003994.e059">Eq. 3</xref>).</p>
<p>The competition between excitatory neurons depends on the common input that they all receive from inhibitory neurons. This common input must reflect the overall activity of the network, so that the competition is suitably normalized. However, the inhibition of the excitatory neurons stems from multiple inhibitory neurons, which should partition their common inhibitory task amongst each other in a self-organizing way. We investigated this partitioning, and how an excitatory neuron is inhibited during stimulation.</p>
<p>In order to quantify the impact of a neuron j on another neuron i for a given stimulus, we calculate a value that we will call the recursively effective exertion (REE). It is obtained by multiplying the activity of neuron j (under a given stimulus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e093" xlink:type="simple"/></inline-formula>) with the total connection weight <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e094" xlink:type="simple"/></inline-formula> from neuron j to i:<disp-formula id="pcbi.1003994.e095"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e095" xlink:type="simple"/><label>(5)</label></disp-formula></p>
<p>The REE value is therefore stimulus-dependent, and dependent on the recurrent network connectivity. <xref ref-type="fig" rid="pcbi-1003994-g010">Fig. 10</xref> shows that inhibition is distributed non-uniformly: A few inhibitory neurons dominate the suppression of an excitatory neuron. This dominance is due to the BCM learning by inhibitory synapses: Strongly and weakly correlated inhibitory connections to excitatory neurons are strengthened or weakened, respectively. These inhibitory connection strengths converge because of the homeostatic activity regulation, which is part of the BCM learning rule.</p>
<fig id="pcbi-1003994-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003994.g010</object-id><label>Figure 10</label><caption>
<title>Inhibition of excitatory neurons.</title>
<p>Excitatory neurons are predominantly inhibited by subsets of the inhibitory neurons that project to them. (<bold>A</bold>) Representative examples of the inhibition to excitatory neurons in a learned WTA network, during presentation of a stimulus. The vertical axis indicates the percentage of the total inhibitory REE (see definition of REE in text) that an individual inhibitory neuron delivers to this particular excitatory neuron. Few (usually 2 or 3) inhibitory neurons provide the major part of the inhibition. (<bold>B</bold>) Histogram of all the REE contributions (in %) from inhibitory neurons, across all excitatory neurons in the WTA network. The distribution shows that few inhibitory neurons provide the major part of the inhibitory REE on an excitatory neuron. This specialization is a result of the BCM learning rule, which is followed also by inhibitory synapses onto excitatory neurons.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003994.g010" position="float" xlink:type="simple"/></fig>
<p>The nature of inhibition of excitatory neurons is interesting in the context of the anatomy of inhibitory basket cells. These neurons predominantly target locations close to the soma or the proximal dendrites, where they can strongly influence the excitatory neuron <xref ref-type="bibr" rid="pcbi.1003994-Somogyi2">[73]</xref>. Therefore, it is plausible that the recruitment of a small number of inhibitory neurons is sufficient to inhibit an excitatory neuron. Electrophysiological experiments could in principle validate this hypothesis by showing that only a small proportion of the inhibitory neurons projecting to a pyramidal neuron are predominantly responsible for its suppression.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>In this paper we have demonstrated by simulation of physical development in a 3D space, how an autonomous gene regulatory network can orchestrate the self-construction and -calibration of a field of soft-WTA neural networks, able to perform pattern restoration and classification on their input signals. The importance of this result is that it demonstrates in a systematic and principled way how genetic information contained in a single precursor cell can unfold into a functional network of neurons with highly organized connections and synaptic weights.</p>
<p>The principles of morphological and functional development captured in our model are necessarily simplified with respect to the boundless detail of biology. Nevertheless, these principles are both strongly supported by experimental data, and sufficiently rich in their collective expression to explain coherently the complex process of expansion of a genotype to a functional phenotypic neuronal circuit. In this way our work offers a significant advance over previous biological and modeling studies which have focused either on elements of neuronal development, or on learning in networks whose initial connectivity is given. Therefore we expect that methods and results of the kind reported here will be of interest both to developmental biologists seeking a modeling approach to exploring system level processes, as well as to neuronal learning theorists who usually neglect the genetic-developmental and homeostatic aspects of detailed learning in favor of an initial network that serves as a basic scaffold for subsequent learning <xref ref-type="bibr" rid="pcbi.1003994-GrabskaBarwiska1">[74]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Bednar2">[76]</xref>.</p>
<p>It is relatively easy to express a well-characterized biological process through an explicit simulation. That is, one in which the simulation simply recapitulates the process by expanding some data through a simple model, without regard for physical and mechanistic constraints. By contrast, the simulation methods <xref ref-type="bibr" rid="pcbi.1003994-Zubler1">[16]</xref> that we have used here are strictly committed to physical realities such as 3D space, forces, diffusion, gene-expression networks, cellular growth mechanisms, etc. Our methods are also committed to local agency: All active processes are localized to cells, can only have local actions, and have access to only local signals. There is no global controller with global knowledge, able simply to paint the developmental picture into a 3D space. Instead, the ability of a precursor cell to expand to a functional network is the result of collective interaction between localized cellular processes. And overall, the developmental process is the expression of an organization that is encoded only implicitly, rather than explicity, in the GRN of the precursor cell. Thus, our GRN encodes constraints and methods rather than explicit behaviors.</p>
<p>In previous work <xref ref-type="bibr" rid="pcbi.1003994-Zubler3">[77]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Bauer1">[78]</xref> we have shown how this approach can be used to explain the development of neocortical lamination and connectivity. In that case we did not consider also the electrophysiological signaling between cells and so the self-configuration of their computational roles, as we have done here. However, the incorporation of electrophysiological signaling into the growth model brings substantial technical difficulties, such as those arising out of the large differences in spatio-temporal scales between cellular developmental and electrophysiological signaling processes, as well as the supply and management of sufficient computational resources. Therefore we have chosen to keep these problems tractable in this first functional study, by restricting our question to a sub-domain of cortical development: How could neuronal precursors expand into functional circuits, at all. Even then, we must be satisfied for the moment with a rate based model of neuronal activity, rather than a fully spiking one.</p>
<p>The emphasis of this paper is on the process whereby a precursor expands to some useful network function. The particular function is less relevant, and in any case the functional/computational details of cortical circuits are as yet not fully understood. We have chosen to induce WTA-like function because our previous work has been focused on the likely similarity between the WTA motif and the neuronal types and their inter-connectivity in the superficial layers of cortex <xref ref-type="bibr" rid="pcbi.1003994-Douglas3">[6]</xref>. Moreover these WTA networks are intriguing from both the biological, and computational perspective <xref ref-type="bibr" rid="pcbi.1003994-Douglas1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Douglas3">[6]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Pfeiffer1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Hahnloser2">[41]</xref>. The strong recurrent excitation available in the superficial layers of cortex, and their critical dependence on feedback inhibition has been clearly demonstrated by intracellular recordings in the presence of ionophoretic manipulation of GABA agonists and antagonists <xref ref-type="bibr" rid="pcbi.1003994-Douglas2">[4]</xref>. These relationships are crucial for WTA-like processing, because they offer the network induced gain that is crucial for providing the signal restoration, signal selection, and process control that support systematic computation. Recent optogenetic studies appear to confirm the presence of circuit induced gain, in the input layers of mouse visual cortex <xref ref-type="bibr" rid="pcbi.1003994-Li2">[79]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Lien1">[80]</xref>. Taken together these experimental and theoretical results support the hypothesis that at least some fundamental WTA functionality is embedded in the processing architecture of superficial neuronal circuits, and so makes the WTA motif a worth target of the developmental process that we have described here.</p>
<p>Our model predicts that neurons form specific subgroups, or cell assemblies <xref ref-type="bibr" rid="pcbi.1003994-Hebb1">[81]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Harris1">[82]</xref>. There is indeed strong evidence from biological data for this clustered connectivity <xref ref-type="bibr" rid="pcbi.1003994-Song1">[83]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Perin1">[85]</xref>, which (as in our simulations), appears to be grounded in the similarity of functional selectivity <xref ref-type="bibr" rid="pcbi.1003994-Ko1">[86]</xref>.</p>
<p>We did not allow dynamic rearrangement of synapses in these first simulations. However, it is plausible that weak synapses are pruned away, freeing synaptic resource to explore for more correlated partners.</p>
<p>Peters' rule <xref ref-type="bibr" rid="pcbi.1003994-Peters1">[87]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Peters2">[89]</xref> proposes that connectivity can be estimated by the product of the random overlap of pre- and postsynaptic sites. This rule may be true for average connectivity, but specific functionality obviously calls for more specific low level connectivity within the average. One opinion is that such specificity is explicitly genetic, and so accounts for example for the diversity of cortical interneurons <xref ref-type="bibr" rid="pcbi.1003994-Monyer1">[90]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Wonders1">[91]</xref>. Instead, our result speaks for an implicit rather than explicit genetic specificity. That is, the apparently specific wiring of the WTA network arises by neurons collectively satisfying genetically expressed constraints. This concept is in stark contrast to the view that network functionality emerges from individual processes that do not coordinate with potential interaction partners. In our simulations, a neuron's morphology and the functional strengths of its synapses depend on the collective behavior of the other neurons. Hence, the structure and function of a neuron grown in isolation is different from a neuron with the same genetic code, but that interacts and coordinates with its environment during development.</p>
<p>Our learning rule requires that input projections are ordered in such a way that their collective input patterns provide at least a coarsely structured signal against which the presumptive WTA layer of neurons can successfully deploy a BCM-like learning mechanism. This ordering is not a stringent requirement. For example, provided that there is some degree of coherent axonal mapping of axons from input neurons of the subplate or thalamus into the target WTA layer, then even metabolically induced travelling waves of activity across the developing input population could provide a sufficiently structured signal for learning.</p>
<p>Traditionally, many modeling studies have been based on the assumption that the limited lateral extent of the neuronal axonal and dendritic tree naturally leads to a properly configured 2D neighborhood topology <xref ref-type="bibr" rid="pcbi.1003994-Beurle1">[92]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Griffith2">[94]</xref>. However, it is unclear how more realistic anatomical properties (anisotropy, variation of neurite extent, irregular locations of somata etc.) affect these topologies. Our work addresses this problem by demonstrating how neurons can self-calibrate in a stimulus-induced way, within a non-uniform and irregular neuronal setting. Hence, our work provides a better understanding of how developmental mechanisms can generate a neighborhood topology, and so is complementary to the classical approach.</p>
<p>As development of input neurons proceeds, the degree of structuring is likely to improve also, so that input neurons projecting to the same targets share similar features (for example, their ON- and OFF-subfields). This is in line with studies on thalamo-cortical projections <xref ref-type="bibr" rid="pcbi.1003994-Alonso1">[95]</xref>, as well as cortico-cortical projections from layer IV to II/III <xref ref-type="bibr" rid="pcbi.1003994-Yoshimura2">[96]</xref>. However, it should be noted that this input specificity does not play onto inhibitory targets, which is in accordance with our work. Since the input to the neurons shapes the functional connectivity in the network, it follows from our model that neurons which receive common input are more likely to connect with each other (assuming that structural connectivity is adjusting to functional connectivity). The studies of <xref ref-type="bibr" rid="pcbi.1003994-Yoshimura2">[96]</xref> and <xref ref-type="bibr" rid="pcbi.1003994-Wang1">[97]</xref> provide evidence for this input-dependent intra-network specificity.</p>
<p>Our results predict that only a few inhibitory neurons provide the major part of WTA-relevant inhibition, i.e. a relatively small subset of all the inhibitory basket cells projecting to a single pyramidal cell is responsible for its WTA suppression. These results suggest that WTA inhibition might not be very redundant, so that de-activation of only a few inhibitory neurons could result in very different electrophysiological behavior of pyramidal cells.</p>
<p>Our networks employ Hebbian-type learning for both excitatory and inhibitory synapses onto excitatory postsynaptic neurons. It is known that inhibitory synapses can undergo long-term potentiation (LTP) as well as long-term depression (LTD) <xref ref-type="bibr" rid="pcbi.1003994-Haas1">[52]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Saar1">[54]</xref>, and learning by inhibitory synapses has been used in previous modeling studies <xref ref-type="bibr" rid="pcbi.1003994-Srinivasa1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Vogels2">[98]</xref>.</p>
<p>Non-Hebbian synaptic scaling of synapses onto inhibitory neurons results in orientation-nonselective inhibitory neurons. This distinction with respect to pyramidal neurons has been observed in mouse visual cortex, where the tuning of inhibitory neurons is broader than that of excitatory neurons <xref ref-type="bibr" rid="pcbi.1003994-Kerlin1">[63]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Kuhlman1">[67]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Sohya1">[99]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Bock1">[101]</xref>. There is evidence for broadly tuned thalamo-cortical input to inhibitory neurons <xref ref-type="bibr" rid="pcbi.1003994-Alonso1">[95]</xref>, as well as cortico-cortical input to those of layer II/III of mouse cortex <xref ref-type="bibr" rid="pcbi.1003994-Liu2">[100]</xref>. Therefore we propose that at least some types of inhibitory neurons (e.g. fast-spiking (FS), PV-expressing interneurons) do not selectively adjust their inputs, but uniformly adapt the electrophysiological properties of their inputs for homeostasis.</p>
<p>Orientation-selective inhibitory neurons are found in cat visual cortex <xref ref-type="bibr" rid="pcbi.1003994-Azouz2">[69]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Nowak1">[72]</xref>. Since we do not model orientation maps, our findings are not directly applicable to the cat. However, we argue that it is the spatial location in the orientation map that determines the tuning curve of inhibitory neurons. Most cortical interneurons have a small horizontal dendritic extent <xref ref-type="bibr" rid="pcbi.1003994-Markram1">[56]</xref>, and so they likely receive inputs from similarly tuned excitatory neurons within an orientation map. Inhibitory neurons located close to orientation pinwheels are expected to have relatively broad orientation tuning, as reported in the above studies. The unbiased pooling of surrounding activity by inhibitory neurons is also supported by experimental results across species and sensory modalities <xref ref-type="bibr" rid="pcbi.1003994-Kerlin1">[63]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Bock1">[101]</xref>. By contrast, we have shown that inhibitory neurons become orientation-selective when they follow the same (BCM) learning rule as excitatory neurons.</p>
<p>Our learning model provides a computational explanation for why most interneurons are smooth, i.e. have very few dendritic spines. It is believed that spines, by compartmentalizing biochemical signals, provide the molecular isolation required for independent synaptic learning <xref ref-type="bibr" rid="pcbi.1003994-Bloodgood1">[102]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Chiu1">[104]</xref>. The nonspecific and homogeneous adaptation of inhibitory neurons, which in our model are homogeneously scaling the input efficacies, is therefore well in line with this suggested function of dendritic spines. This model also provides an explanation for the finding that inhibitory, but not excitatory neurons exhibit structural remodeling of dendrites in the adult rat <xref ref-type="bibr" rid="pcbi.1003994-Lee1">[105]</xref>. Changes in excitatory morphology at the level of dendritic branches (rather then spines) could have detrimental effects on already consolidated memories. Inhibitory neurons may retain their potential for dendritic restructuring, because their homeostatic adaptation does not interfere with learning of sensory experience.</p>
<p>We believe our findings to be robust also with respect to models incorporating spikes, because the main features of the adaptation and learning behavior have been demonstrated also on this more detailed level of electrophysiology. Along these lines, the studies of <xref ref-type="bibr" rid="pcbi.1003994-Oster1">[106]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Chen1">[107]</xref> have explored spike-based WTA network functionality. Spike-dependent plasticity (STDP) is a Hebbian learning rule <xref ref-type="bibr" rid="pcbi.1003994-Caporale1">[108]</xref> and can yield synaptic homeostasis <xref ref-type="bibr" rid="pcbi.1003994-Clopath1">[109]</xref>. In particular, the BCM learning rule has been related to STDP mechanisms <xref ref-type="bibr" rid="pcbi.1003994-Clopath1">[109]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Gjorgjieva1">[112]</xref>.</p>
<p>The robust self-organization of the WTA network is remarkable in that it arises out a single precursor cell, by simple genetically encoded rules. In future, this genetic developmental approach to functional circuit construction could be extended to larger networks composed of multiple WTA networks. For example, it has been hypothesized that by cooperation of multiple WTA circuits, the superficial layers of cortex could perform context-dependent processing <xref ref-type="bibr" rid="pcbi.1003994-Rutishauser1">[8]</xref>. Along these lines, <xref ref-type="bibr" rid="pcbi.1003994-Bauer1">[78]</xref> provide a model for the development of long-range projections connecting multiple columns, arranged on an hexagonal grid, as is observed in the superficial patch system <xref ref-type="bibr" rid="pcbi.1003994-Rockland1">[113]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Muir1">[116]</xref>. It also remains to integrate these computational aspects into the context of a laminated cortical structure, which has already been simulated in Cx3D <xref ref-type="bibr" rid="pcbi.1003994-Zubler2">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Zubler3">[77]</xref>.</p>
</sec><sec id="s4" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="s4a">
<title>Simulation</title>
<sec id="s4a1">
<title>Cx3Dp</title>
<p>The growth simulations were conducted with the open-source package Cx3Dp, the parallelized version of Cx3D <xref ref-type="bibr" rid="pcbi.1003994-Zubler1">[16]</xref> (available at <ext-link ext-link-type="uri" xlink:href="http://www.ini.uzh.ch/projects/cx3d/" xlink:type="simple">http://www.ini.uzh.ch/projects/cx3d/</ext-link>). As in the non-parallel version, neurons in Cx3Dp are decomposed into discrete spherical or cylindrical <italic>physical elements</italic> emulating the physical properties of developing tissues, whereas the biological properties derive from <italic>modules</italic>, that is, smaller programs expressed within specific physical elements. This local instantiation forces simulations to be based only on local interactions, without any global control of the developmental processes.</p>
<p>The default parameters for physical objects in Cx3D were initially chosen so that (1) density of cells/neurites can not be infinite, (2) objects do have a minimal adhesive property ensuring tissue integrity and (3) viscosity and not mass opposes to movement (see <xref ref-type="bibr" rid="pcbi.1003994-Zubler1">[16]</xref>). For the present study, we did not have to modify these default parameters.</p>
</sec><sec id="s4a2">
<title>Computer specifications</title>
<p>We used a rack computer with two 12-core AMD Opteron 6168 processors (1.9 GHz, 64 GB of RAM), running under Ubuntu 12.04 LTS.</p>
</sec></sec><sec id="s4b">
<title>Gene Regulatory Network (GRN)</title>
<p>The GRN is defined by a set of variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e096" xlink:type="simple"/></inline-formula> that represent genes and the corresponding substance concentrations. Changes in substance concentration are described by the rate equation:<disp-formula id="pcbi.1003994.e097"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e097" xlink:type="simple"/><label>(6)</label></disp-formula></p>
<p>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e098" xlink:type="simple"/></inline-formula> is the concentration of a protein encoded by the gene <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e099" xlink:type="simple"/></inline-formula> (i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e100" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e101" xlink:type="simple"/></inline-formula>), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e102" xlink:type="simple"/></inline-formula> the corresponding concentration vector. The function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e103" xlink:type="simple"/></inline-formula> expresses how the synthesis rate of the protein encoded by gene <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e104" xlink:type="simple"/></inline-formula> depends on the cooperative binding of all the substances, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e105" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e106" xlink:type="simple"/></inline-formula> represent the production and degradation rates (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e107" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e108" xlink:type="simple"/></inline-formula>). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e109" xlink:type="simple"/></inline-formula> is a vector of Hill functions, which compute the binding probability of a substance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e110" xlink:type="simple"/></inline-formula> to a regulatory region given the affinity constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e111" xlink:type="simple"/></inline-formula>, cooperativity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e112" xlink:type="simple"/></inline-formula> and binding bias <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e113" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003994.e114"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e114" xlink:type="simple"/><label>(7)</label></disp-formula></p>
<p>Gene substances can regulate gene expression by binding to specific sites in the genomic cis-regulatory regions. Substances that regulate each others' transcription are called transcription factors. Many genes are controlled by a number of different transcription factors and different arrangements of binding sites can compute logic operations on multiple inputs. Here, the function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e115" xlink:type="simple"/></inline-formula> takes the form of a logical combination of interacting substances and is defined by the elementary operations:<disp-formula id="pcbi.1003994.e116"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e116" xlink:type="simple"/><label>(8)</label></disp-formula><disp-formula id="pcbi.1003994.e117"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e117" xlink:type="simple"/><label>(9)</label></disp-formula><disp-formula id="pcbi.1003994.e118"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e118" xlink:type="simple"/><label>(10)</label></disp-formula>More information on this description of GRN dynamics can be found in <xref ref-type="bibr" rid="pcbi.1003994-Alon1">[117]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Pfister2">[118]</xref>. Although abstract, this formalism can be directly translated into the corresponding mechanistic, kinetic differential equations. For our computational model based on 5 genes, we have used the following equations:<disp-formula id="pcbi.1003994.e119"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e119" xlink:type="simple"/><label>(11)</label></disp-formula><disp-formula id="pcbi.1003994.e120"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e120" xlink:type="simple"/><label>(12)</label></disp-formula><disp-formula id="pcbi.1003994.e121"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e121" xlink:type="simple"/><label>(13)</label></disp-formula><disp-formula id="pcbi.1003994.e122"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e122" xlink:type="simple"/><label>(14)</label></disp-formula><disp-formula id="pcbi.1003994.e123"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e123" xlink:type="simple"/><label>(15)</label></disp-formula></p>
<p>with:<disp-formula id="pcbi.1003994.e124"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e124" xlink:type="simple"/><label>(16)</label></disp-formula></p>
<p>The probabilities of either differentiating into neurons by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e125" xlink:type="simple"/></inline-formula> induction (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e126" xlink:type="simple"/></inline-formula>) or by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e127" xlink:type="simple"/></inline-formula> induction (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e128" xlink:type="simple"/></inline-formula>) are computed as follows:<disp-formula id="pcbi.1003994.e129"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e129" xlink:type="simple"/><label>(17)</label></disp-formula><disp-formula id="pcbi.1003994.e130"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e130" xlink:type="simple"/><label>(18)</label></disp-formula><disp-formula id="pcbi.1003994.e131"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e131" xlink:type="simple"/><label>(19)</label></disp-formula><disp-formula id="pcbi.1003994.e132"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003994.e132" xlink:type="simple"/><label>(20)</label></disp-formula></p>
<p>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e133" xlink:type="simple"/></inline-formula> is the number of divisions in the first division cycle, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e134" xlink:type="simple"/></inline-formula> is the difference between the target number of neurons (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e135" xlink:type="simple"/></inline-formula>) and the number of neurons resulting from the first division cycle, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e136" xlink:type="simple"/></inline-formula> denotes the floor function for rounding to integers.</p>
<p>The intrinsic production constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e137" xlink:type="simple"/></inline-formula> determines the number of cell divisions until differentiation into excitatory and inhibitory neurons can occur. The higher it is, the faster the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e138" xlink:type="simple"/></inline-formula> gene reaches the threshold of 0.99. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e139" xlink:type="simple"/></inline-formula> was adjusted manually in order for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e140" xlink:type="simple"/></inline-formula> divisions to occur in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e141" xlink:type="simple"/></inline-formula> cycle.</p>
</sec><sec id="s4c">
<title>Development of Neuronal Morphology</title>
<p>Initially, neuronal cell bodies are assigned uniformly random positions in 3D unprepared space. In Cx3D, these cell bodies are modeled as physical spheres. The neuronal cell density was in agreement with values derived from experimental data, i.e. in the range of 40'000 to 86'900 per mm<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e142" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003994-Warren1">[119]</xref>–<xref ref-type="bibr" rid="pcbi.1003994-Miki1">[121]</xref>. We found 250 neurons (200 excitatory and 50 inhibitory) to be appropriate for the available computer resources. For the establishment of neuronal connectivity, the somata were placed randomly in a cube with side length 160 <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e143" xlink:type="simple"/></inline-formula>m. A smaller network of 150 neurons in a cube with side length 140 <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e144" xlink:type="simple"/></inline-formula>m was used for simulations where the second developmental phase was simulated, in order to decrease simulation time. 3 of these 150 neurons did not get inhibitory inputs after the initial outgrowth and were not included for the simulation of learning, such that the analyzed network consisted of 117 excitatory and 30 inhibitory neurons. Standard Cx3D parameters for the physical properties of the cells (e.g. mass or adherence) were used <xref ref-type="bibr" rid="pcbi.1003994-Zubler1">[16]</xref>. The somatic diameters were set to 8 <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e145" xlink:type="simple"/></inline-formula>m. Variation of these parameters had only minimal effects on the simulation results.</p>
<p>Axonal and dendritic growth were encoded with the instruction language G-code <xref ref-type="bibr" rid="pcbi.1003994-Zubler2">[24]</xref>. We used the following mechanisms, which are executed by such G-code “modules” located in the growth cone, for axonal and dendritic growth, as well as synapse formation:</p>
<sec id="s4c1">
<title>Axonal growth</title>
<p>The axon is initially extended from the cell body in a random direction, and is dependent on the concentration of an extracellular substance that is secreted by the somata of the neurons participating in the WTA network. The growth cones of excitatory and inhibitory neurons sense the substance secreted by inhibitory and excitatory neurons, respectively. As long as the concentration of this substance is higher than a given threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e146" xlink:type="simple"/></inline-formula>, the axonal growth continues (see below). If the growth cone enters a zone where the concentration is below the threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e147" xlink:type="simple"/></inline-formula>, then the axon retracts until the concentration is above another threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e148" xlink:type="simple"/></inline-formula> (with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e149" xlink:type="simple"/></inline-formula>), before resuming elongation. During elongation, the direction at each time step is a weighted sum of the direction from the previous time step, and of a random perturbation (i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e150" xlink:type="simple"/></inline-formula>). At each time step, the axon bifurcates with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e151" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e152" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e153" xlink:type="simple"/></inline-formula> are constants and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e154" xlink:type="simple"/></inline-formula> is the substance concentration at the current location of the growth cone. When the axon elongates or branches, its diameter is reduced by a factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e155" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e156" xlink:type="simple"/></inline-formula>, respectively. The outgrowth stops when the axonal diameter falls below <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e157" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4c2">
<title>Dendritic growth</title>
<p>Each soma produces three dendrites. As for the axon, the initial sprouting direction for dendrites is random. The subsequent elongation direction is also chosen as a weighted sum of the previous direction and a random perturbation. The major difference is that dendrites are not sensitive to extracellular cues (and do not retract). Branching and stopping mechanisms are implemented as in the axonal case. As a result, the overall dendritic morphology develops isotropically.</p>
</sec><sec id="s4c3">
<title>Synapse formation</title>
<p>In Cx3D, synapses are modeled as connections between excrescences on neurite elements of axons (boutons) and dendrites (spines). For simplification, spines represent potential postsynaptic densities in general, such that we do not model the absence of spines in most classes of inhibitory neurons <xref ref-type="bibr" rid="pcbi.1003994-Markram1">[56]</xref>. During elongation of the neurite, an excrescence is instantiated in the middle of the discretized element. Whenever the excrescence of the tip of a growing axon or dendrite is close to another excrescence, it can check whether they are of complementary types. This local process of synapse formation is done by means of a module that is instantiated in the most distal neurite element, which corresponds to the growth cone's location. If this condition of complementarity is fulfilled and the excrescences are close enough (i.e. the distance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e158" xlink:type="simple"/></inline-formula> 2 <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e159" xlink:type="simple"/></inline-formula>m, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e160" xlink:type="simple"/></inline-formula> denotes the location where the excrescence is attached to the segment of the axon or dendrite), a synapse is formed. Synapse formation between neurites belonging to the same neuron (i.e. autapses) is prohibited, because their number has been reported to be relatively small <xref ref-type="bibr" rid="pcbi.1003994-Lbke1">[122]</xref>, <xref ref-type="bibr" rid="pcbi.1003994-Hellwig1">[123]</xref>, and their electrophysiological significance is unclear.</p>
<p>In our Cx3D implementation, synapse formation also implies the establishment of a physical bond between the two excrescences on the axon and dendrite. This bond is approximated as a spring which reacts linearly to the force to which it is subject to. Therefore, connected neurite segments are kept close to each other, except when a certain repulsive force is exceeded. Once a bond is overstretched, it is released and the synapse destroyed. This ensures that synapses do not over-restrict the neuronal morphology.</p>
<p>The synaptic weights are assigned at synapse formation: Excitatory and inhibitory synapses are initialized with weights 0.001 and 0.01 respectively, in qualitative accordance with the estimate of <xref ref-type="bibr" rid="pcbi.1003994-Binzegger3">[124]</xref>. The overall behavior of the simulations was not sensitive to these initial weights, because of the homeostatic adaptation processes.</p>
</sec></sec><sec id="s4d">
<title>Electrophysiology</title>
<p>The computation of the electrical activity was implemented in Java, to allow a direct interfacing with Cx3D. All the synaptic weights in the Cx3D simulation are summed up, which yields a weight matrix. Based on this weight matrix, the input activity and the spontaneous activity, the firing rate of a neuron is computed according to <xref ref-type="disp-formula" rid="pcbi.1003994.e042">Eq. 1</xref>. The numerical solution of the differential equations was computed using the explicit Euler integration method. The network's activity is computed with 3000 iterations and integration step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e161" xlink:type="simple"/></inline-formula>. The maximal firing rate is set to 250 Hz.</p>
<sec id="s4d1">
<title>Learning</title>
<p>In all the simulations of WTA learning, two different scenarios of input stimulation were conducted. In one case, the input neurons were activated in the form of a hill of activity. This hill was centered around an individual input population, and decayed with the distance from this center. The center population of the hill of activity was active with a rate of 1.4 Hz, the immediate neighboring populations at 0.5<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e162" xlink:type="simple"/></inline-formula>1.4 Hz, the second at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e163" xlink:type="simple"/></inline-formula>1.4 Hz, and the third at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e164" xlink:type="simple"/></inline-formula>1.4 Hz. If the distance of the input population to the center population was bigger than 3, the activity of the input population was chosen to be a random number between 0 and 0.06. The hill of activity in the input layer moved in a periodic fashion (i.e. the peak restarts in the first input population of the input layer after having reached the last). This first scenario represents retinal waves, or orientation stimuli between 0 and 180 degrees. In the second case, discrete input patterns (<xref ref-type="fig" rid="pcbi-1003994-g007">Fig. 7A</xref>) are presented to the network. The stimulated input populations are active at a rate of 2.1 Hz, while the unstimulated ones are (as in the first scenario) active with a rate drawn uniformly from the interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e165" xlink:type="simple"/></inline-formula> Hz. In both scenarios, the target average activity for excitatory neurons (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e166" xlink:type="simple"/></inline-formula>) was identical for all excitatory neurons, and chosen between 0.14 Hz and 0.68 Hz. The inhibitory target activity was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e167" xlink:type="simple"/></inline-formula>. For the simulations shown in <xref ref-type="fig" rid="pcbi-1003994-g008">Fig. 8</xref>, target average activities of excitatory neurons were 0.4, 0.55 and 0.68 for the gains 1.3, 1.5 and 1.8, respectively. During learning, the input populations were active or not active in an alternating fashion. In the non-active case, only spontaneous and random activity generated electrical activity. This non-active input mode was introduced to demonstrate that correlated, instructive input can be intermittent in time. The neurons in the network have a random spontaneous activity that is drawn uniformly from the interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e168" xlink:type="simple"/></inline-formula> Hz.</p>
<p>Usually, the simulations took around 1 day to develop networks that exhibit WTA behaviour. The main computational bottleneck is the computation of the average activity, which relies on a large number of samples of neuronal activity. During an entire simulation, electrical activity in response to the input is computed around 1'000'000 times, and in the order of 100'000 learning steps (synaptic scaling and BCM learning) are performed.</p>
<p>The average activities used for the BCM learning (<xref ref-type="disp-formula" rid="pcbi.1003994.e059">Eq. 3</xref>) are computed as the arithmetic mean of the neuronal activities from the last N inputs. N is set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e169" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e170" xlink:type="simple"/></inline-formula> being the number of input populations. The factor 2 comes from the fact that the inputs are alternating between two different modi: active and non-active input neurons (as described before). In order for the WTA neurons to keep track of their activities, N has to be long enough to allow averaging the activities evoked by all possible inputs. Analogously, for the learning of the clustering based on discrete input patterns (second scenario), N was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e171" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e172" xlink:type="simple"/></inline-formula> being the number of different input stimuli presented to the network. The time constant of the average activity is long compared to the time constant of the instantaneous firing rate, and assumed to be in the range of several hours to days. Based on this assumption, we assessed the real time of learning, and so some figures in this work indicate the estimated real-time of the learning process.</p>
<p>As a standard, we chose 20 input populations (or neurons) in the case of learning continuous input patterns, and the input strengths were initialized randomly and uniformly distributed between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e173" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e174" xlink:type="simple"/></inline-formula>. In the case of discrete input stimuli, we used 3 <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e175" xlink:type="simple"/></inline-formula> 3 input populations. The initial connection strengths (from each of these input populations to each of the neurons in the grown network) were distributed in the range of [<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e176" xlink:type="simple"/></inline-formula>]. We found little change of behavior when varying these numbers. During unsupervised learning, retinal-wave like activity or discrete input patterns are presented to the network in a periodic fashion. After every period, the new values of average activities are obtained and learning is simulated. The same synaptic learning time constants are used for input, excitatory and inhibitory lateral synapses. In the case of retinal waves, learning is simulated only after the hill of activity has passed every input population. In the case of learning discrete input patterns, learning is simulated each time a pattern is presented. The time duration for synaptic scaling after a retinal wave was chosen equal to the duration of learning one pass of all input patterns. Because of the 8 input patterns, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e177" xlink:type="simple"/></inline-formula> was set 8 times larger in the scenario of discrete patterns (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e178" xlink:type="simple"/></inline-formula> for retinal waves and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e179" xlink:type="simple"/></inline-formula> for discrete input patterns). The same time constants for the BCM learning rule were chosen, but exploratory simulations showed that this is not a necessary condition. In order to demonstrate that the WTA learning is not sensitive to changes in these time constants, simulations of WTA networks learning 4 stimuli were conducted with the same time constants as with 8 stimuli (<xref ref-type="supplementary-material" rid="pcbi.1003994.s002">S2A Figure</xref>). The weight change per learning step is constrained to maximally 3 <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e180" xlink:type="simple"/></inline-formula> of the current value, in order to prevent large or destabilizing disruptions at the initial stages of development. The weight of an individual synapse between two neurons is approximated by dividing the total connection weight by the number of synapses involved in this particular connection. This absolute synaptic weight is constrained to a maximal value of 0.1 <xref ref-type="bibr" rid="pcbi.1003994-Trappenberg1">[125]</xref>. Overall, variation of the learning parameters do not have a strong effect on our results.</p>
</sec></sec><sec id="s4e">
<title>Network Analysis and Visualization</title>
<p>Analyses of the simulated networks were performed with MATLAB (Mathworks Inc.). In order to assess WTA functionality, electrical activity was computed in the same way as in the Java implementation of the Cx3Dp simulation, namely using the rate-based model (<xref ref-type="disp-formula" rid="pcbi.1003994.e042">Eq. 1</xref>) and the explicit Euler method. The integration step was decreased to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e181" xlink:type="simple"/></inline-formula> for minimizing integration errors.</p>
<p>The ordering of neurons for visualization, such as for <xref ref-type="fig" rid="pcbi-1003994-g006">Fig. 6A</xref>, was done using the genetic algorithm “ga.m” from the Global Optimization Toolbox of MATLAB. The energy to be minimized was defined as the sum of weighted topological distances between neurons, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e182" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e183" xlink:type="simple"/></inline-formula> are the summed synaptic weights from neuron j to neuron i. The topological distances <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e184" xlink:type="simple"/></inline-formula> are inferred from a discrete 1-dimensional position vector of the neurons, which is initialized randomly and optimized. The ordering for the matrix visualization is then given by the locations of the neurons in this vector (i.e. neighbors in this vector are also neighbors in the matrix ordering). Note that the topological position is unrelated to the physical position of the neurons, and is only used for the optimization process. The visualization of the clustering was done with CytoScape <xref ref-type="bibr" rid="pcbi.1003994-Smoot1">[126]</xref>, an open-source framework that is downloadable from <ext-link ext-link-type="uri" xlink:href="http://www.cytoscape.org/" xlink:type="simple">http://www.cytoscape.org/</ext-link>. We used the “dynnetwork” plugin implemented by Sabina Pfister, which clusters weighted networks based on the Kamada-Kawai algorithm <xref ref-type="bibr" rid="pcbi.1003994-Kamada1">[127]</xref>.</p>
</sec><sec id="s4f">
<title>Neurite Outgrowth Parameters</title>
<p>The neurite outgrowth has several parameters, which depend on the neuronal type (excitatory/inhibitory) and also on the neurite type (axon or dendrite). <xref ref-type="table" rid="pcbi-1003994-t001">Table 1</xref> lists all these parameters. The 2 substances which are secreted by the cell bodies and used by the axons as guidance cues both have a diffusion coefficient of 50 and a degradation constant of 5.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003994.s001" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003994.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p><bold>Histograms of resulting numbers of neurons after simulation of the GRN.</bold> The intrinsic instructions of the precursor cell in an unprepared environment lead to multiple neurons of two types (excitatory and inhibitory, other types like for example glia cells could facultatively be added). We conducted 100 trials of a GRN, that was set to give rise to 100 neurons, of which 80 are excitatory and 20 inhibitory. These results demonstrate that the (probabilistic) GRN produces approximately the desired number and proportion of neurons.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003994.s002" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003994.s002" position="float" xlink:type="simple"><label>Figure S2</label><caption>
<p><bold>Visualization of network connectivity in weight space, after learning 4 input patterns.</bold> (<bold>A</bold>) The locations of the neurons are determined using a clustering algorithm, such that strongly connected neurons are close to each other. Different colors indicate different preferred patterns of the neurons. The preferred pattern of a neuron was assessed by determining the pattern that evokes the largest electrical response. Inhibitory neurons are colored yellow and rectangular-shaped. The same network as in <xref ref-type="fig" rid="pcbi-1003994-g007">Fig. 7B and 7C</xref> is simulated, but after learning 4 input stimuli (horizontal, vertical and both diagonally oriented bars) instead of 8. The 4 clusters defined by the spatially proximal assemblies of neurons are visible. Importantly, the same parameters (time constants of synaptic scaling and BCM learning) were used, demonstrating the robustness of the learning scheme. (<bold>B</bold>) Network connectivity after using the same BCM learning rule both for excitatory and inhibitory neurons. As in (A), the locations of the neurons are determined using a clustering algorithm, such that strongly connected neurons are close to each other. Different colors indicate different selectivities of the neurons. In contrast to the simulations where synapses onto inhibitory neurons were following the synaptic scaling rule, here we used exactly the same learning dynamics for both types of neurons. This influences the clustering, such that also the inhibitory neurons become selective for the learning input stimuli.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003994.s003" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003994.s003" position="float" xlink:type="simple"><label>Figure S3</label><caption>
<p><bold>WTA competition between two populations after correlation-based BCM learning of excitatory and inhibitory neurons.</bold> WTA populations compete for representation of a mixture of 2 concurrent stimuli. In contrast to the simulations for <xref ref-type="fig" rid="pcbi-1003994-g008">Fig. 8</xref>, synapses onto excitatory as well as inhibitory neurons followed the BCM rule during learning. Also in this case, the populations with different preferred stimuli compete and mutually suppress each other. The blue crosses indicate samples of the relative activity of a WTA population selective for one of the two concurrent stimuli. The continuous blue line is the interpolation of these samples. The dashed blue line indicates the relative activity of the competing population. The green line is the angle bisector given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003994.e185" xlink:type="simple"/></inline-formula>. The horizontal and vertical axes show the relative contribution of two concurrent stimuli (two orthogonal orientations) and the corresponding populations (see legend of <xref ref-type="fig" rid="pcbi-1003994-g008">Fig. 8</xref> for a detailed description). If there was no competition between the populations, simulation samples would lie on the green line, because then the network simply mirrors its input.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003994.s004" mimetype="video/x-ms-wmv" xlink:href="info:doi/10.1371/journal.pcbi.1003994.s004" position="float" xlink:type="simple"><label>Video S1</label><caption>
<p><bold>Neurite outgrowth in the 2-dimensional plane, with concentration-dependent axonal retraction.</bold> Excitatory and inhibitory neurons (colored red and purple, respectively) are initially randomly positioned on a 2-dimensional unprepared environment. The somata of both types secrete different substances, which are sensed by the growth cones at the tip of the axons. Whenever the sensed concentration falls below a predefined threshold, axons retract until they reach a high enough concentration (this retraction is indicated in green). This behavior is iteratively instantiated, allowing the network to project more efficiently, because axons do not grow into regions where no potential targets are located.</p>
<p>(WMV)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003994.s005" mimetype="video/quicktime" xlink:href="info:doi/10.1371/journal.pcbi.1003994.s005" position="float" xlink:type="simple"><label>Video S2</label><caption>
<p><bold>Clustering of functional connectivity in a WTA network.</bold> The presence of functional connections among excitatory and inhibitory neurons (red and blue respectively) are indicated with arrows. For clearer visualization, the strength is not shown. A clustering algorithm was applied to move the nodes such that strong connections are more probable to be close to each other. Therefore, the video does not show any physical movement, but only the arrangements performed by the clustering algorithm in weight space. 4 input stimuli referring to horizontal, vertical and both diagonal orientations are presented to the network. In the first part of the video (until 0:07 min), all neurons do synaptic scaling. Subsequently, synapses onto excitatory neurons become subject to the BCM learning rule, which has impact on the clustering of the functional connectivity: 4 clusters emerge for excitatory neurons, in contrast to the inhibitory neurons. This discrepancy is because of the different learning rule simulated after the first part, which is BCM learning for synapses onto excitatory and synaptic scaling for synapses onto inhibitory postsynaptic neurons.</p>
<p>(MOV)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>The authors wish to thank Matthew Cook, Nuno da Costa, Arko Ghosh, Dennis Goehlsdorf, Kevan Martin, Gabriela Michel, Emre Neftci, Ueli Rutishauser, Andreas Steimer, Christoph von der Malsburg and Adrian Whatley for stimulating discussions and useful comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003994-Yuille1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yuille</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Grzywacz</surname><given-names>N</given-names></name> (<year>1989</year>) <article-title>A winner-take-all mechanism based on presynaptic inhibition feedback</article-title>. <source>Neural Comput</source> <volume>1</volume>: <fpage>334</fpage>–<lpage>347</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Yuille2"><label>2</label>
<mixed-citation publication-type="other" xlink:type="simple">Yuille A, Geiger D (2003) Winner-take-all networks. The handbook of brain theory and neural networks: 1228–1231.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Douglas1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Whitteridge</surname><given-names>D</given-names></name> (<year>1989</year>) <article-title>A canonical microcircuit for neocortex</article-title>. <source>Neural Comput</source> <volume>1</volume>: <fpage>480</fpage>–<lpage>488</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Douglas2"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Douglas</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>K</given-names></name> (<year>1991</year>) <article-title>A functional microcircuit for cat visual cortex</article-title>. <source>J Physiol</source> <volume>440</volume>: <fpage>735</fpage>–<lpage>769</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Binzegger1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Binzegger</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>K</given-names></name> (<year>2004</year>) <article-title>A quantitative map of the circuit of cat primary visual cortex</article-title>. <source>J Neurosci</source> <volume>24</volume>: <fpage>8441</fpage>–<lpage>8453</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Douglas3"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>K</given-names></name> (<year>2004</year>) <article-title>Neuronal circuits of the neocortex</article-title>. <source>Annu Rev Neurosci</source> <volume>27</volume>: <fpage>419</fpage>–<lpage>451</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Maass1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2000</year>) <article-title>On the computational power of winner-take-all</article-title>. <source>Neural Comput</source> <volume>12</volume>: <fpage>2519</fpage>–<lpage>2535</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Rutishauser1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rutishauser</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name> (<year>2009</year>) <article-title>State-dependent computation using coupled recurrent networks</article-title>. <source>Neural Comput</source> <volume>21</volume>: <fpage>478</fpage>–<lpage>509</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Indiveri1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Indiveri</surname><given-names>G</given-names></name> (<year>2000</year>) <article-title>Modeling selective attention using a neuromorphic analog VLSI device</article-title>. <source>Neural Comput</source> <volume>12</volume>: <fpage>2857</fpage>–<lpage>2880</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Hahnloser1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hahnloser</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hepp</surname><given-names>K</given-names></name> (<year>2002</year>) <article-title>Attentional recruitment of inter-areal recurrent networks for selective gain control</article-title>. <source>Neural Comput</source> <volume>14</volume>: <fpage>1669</fpage>–<lpage>1689</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Johansson1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johansson</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rehn</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Lansner</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Attractor neural networks with patchy connectivity</article-title>. <source>Neurocomputing</source> <volume>69</volume>: <fpage>627</fpage>–<lpage>633</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Johansson2"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Johansson</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Lansner</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>Towards cortex sized artificial neural systems</article-title>. <source>Neural Networks</source> <volume>20</volume>: <fpage>48</fpage>–<lpage>61</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Jitsev1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jitsev</surname><given-names>J</given-names></name>, <name name-style="western"><surname>von der Malsburg</surname><given-names>C</given-names></name> (<year>2009</year>) <article-title>Experience-driven formation of parts-based representations in a model of layered visual memory</article-title>. <source>Front Comput Neurosci</source> <volume>3</volume>: <fpage>15</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Nessler1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nessler</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Pfeiffer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Buesing</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2013</year>) <article-title>Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>: <fpage>e1003037</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Pfeiffer1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pfeiffer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nessler</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2010</year>) <article-title>Reward-modulated hebbian learning of decision making</article-title>. <source>Neural Comput</source> <volume>22</volume>: <fpage>1399</fpage>–<lpage>1444</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Zubler1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zubler</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name> (<year>2009</year>) <article-title>A framework for modeling the growth and development of neurons and networks</article-title>. <source>Front Comput Neurosci</source> <volume>3</volume>: <fpage>25</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Turrigiano1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Turrigiano</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Leslie</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Desai</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Rutherford</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>S</given-names></name> (<year>1998</year>) <article-title>Activity-dependent scaling of quantal amplitude in neocortical neurons</article-title>. <source>Nature</source> <volume>391</volume>: <fpage>892</fpage>–<lpage>896</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Bienenstock1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bienenstock</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Cooper</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Munro</surname><given-names>P</given-names></name> (<year>1982</year>) <article-title>Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex</article-title>. <source>J Neurosci</source> <volume>2</volume>: <fpage>32</fpage>–<lpage>48</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Wong1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wong</surname><given-names>R</given-names></name> (<year>1999</year>) <article-title>Retinal waves and visual system development</article-title>. <source>Annu Rev Neurosci</source> <volume>22</volume>: <fpage>29</fpage>–<lpage>47</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Weliky1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weliky</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hall</surname><given-names>M</given-names></name> (<year>2000</year>) <article-title>Correlated neuronal activity minireview and visual cortical development</article-title>. <source>Neuron</source> <volume>27</volume>: <fpage>427</fpage>–<lpage>430</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Butts1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Butts</surname><given-names>D</given-names></name> (<year>2002</year>) <article-title>Retinal waves: implications for synaptic learning rules during development</article-title>. <source>Neuroscientist</source> <volume>8</volume>: <fpage>243</fpage>–<lpage>253</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Huberman1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huberman</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Feller</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Chapman</surname><given-names>B</given-names></name> (<year>2008</year>) <article-title>Mechanisms underlying development of visual maps and receptive fields</article-title>. <source>Annu Rev Neurosci</source> <volume>31</volume>: <fpage>479</fpage>–<lpage>509</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Kirkby1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kirkby</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Sack</surname><given-names>GS</given-names></name>, <name name-style="western"><surname>Firl</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Feller</surname><given-names>MB</given-names></name> (<year>2013</year>) <article-title>A role for correlated spontaneous activity in the assembly of neural circuits</article-title>. <source>Neuron</source> <volume>80</volume>: <fpage>1129</fpage>–<lpage>1144</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Zubler2"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zubler</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hauri</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Pfister</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Whatley</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Cook</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>An instruction language for self-construction in the context of neural networks</article-title>. <source>Front Comput Neurosci</source> <volume>5</volume>: <fpage>57</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Gabbott1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gabbott</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Somogyi</surname><given-names>P</given-names></name> (<year>1986</year>) <article-title>Quantitative distribution of GABA-immunoreactive neurons in the visual cortex (area 17) of the cat</article-title>. <source>Exp Brain Res</source> <volume>61</volume>: <fpage>323</fpage>–<lpage>331</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Somogyi1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Somogyi</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Tamas</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Lujan</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Buhl</surname><given-names>E</given-names></name> (<year>1998</year>) <article-title>Salient features of synaptic organisation in the cerebral cortex</article-title>. <source>Brain Res Rev</source> <volume>26</volume>: <fpage>113</fpage>–<lpage>135</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Li1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Schwark</surname><given-names>H</given-names></name> (<year>1994</year>) <article-title>Distribution and proportions of GABA-Immunoreactive neurons in cat primary somatosensory cortex</article-title>. <source>J Comp Neurol</source> <volume>343</volume>: <fpage>353</fpage>–<lpage>361</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-LaMantia1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>LaMantia</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rakic</surname><given-names>P</given-names></name> (<year>1990</year>) <article-title>Axon overproduction and elimination in the corpus callosum of the developing rhesus monkey</article-title>. <source>J Neurosci</source> <volume>10</volume>: <fpage>2156</fpage>–<lpage>2175</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Godement1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Godement</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Mason</surname><given-names>C</given-names></name> (<year>1994</year>) <article-title>Retinal axon divergence in the optic chiasm: dynamics of growth cone behavior at the midline</article-title>. <source>J Neurosci</source> <volume>14</volume>: <fpage>7024</fpage>–<lpage>7039</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Luo1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Luo</surname><given-names>L</given-names></name>, <name name-style="western"><surname>O'Leary</surname><given-names>D</given-names></name> (<year>2005</year>) <article-title>Axon retraction and degeneration in development and disease</article-title>. <source>Annu Rev Neurosci</source> <volume>28</volume>: <fpage>127</fpage>–<lpage>156</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-PorteraCailliau1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Portera-Cailliau</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Weimer</surname><given-names>R</given-names></name>, <name name-style="western"><surname>De Paola</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Caroni</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Svoboda</surname><given-names>K</given-names></name> (<year>2005</year>) <article-title>Diverse modes of axon elaboration in the developing neocortex</article-title>. <source>PLoS Biol</source> <volume>3</volume>: <fpage>e272</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Binzegger2"><label>32</label>
<mixed-citation publication-type="book" xlink:type="simple">Binzegger T, Douglas R, Martin K (2010) An axonal perspective on cortical circuits. In: Feldmeyer, D. and Lübke, JHR. New aspects of axonal structure and function. New York (NY): Springer, 117–139 pp.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Beaulieu1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beaulieu</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Kisvarday</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Somogyi</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Cynader</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Cowey</surname><given-names>A</given-names></name> (<year>1992</year>) <article-title>Quantitative distribution of GABA-immunopositive and-immunonegative neurons and synapses in the monkey striate cortex (area 17)</article-title>. <source>Cereb Cortex</source> <volume>2</volume>: <fpage>295</fpage>–<lpage>309</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Beaulieu2"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beaulieu</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Campistron</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Crevier</surname><given-names>C</given-names></name> (<year>1994</year>) <article-title>Quantitative aspects of the GABA circuitry in the primary visual cortex of the adult rat</article-title>. <source>J Comp Neurol</source> <volume>339</volume>: <fpage>559</fpage>–<lpage>572</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-DeFelipe1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Felipe</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Marco</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Fairen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>E</given-names></name> (<year>1997</year>) <article-title>Inhibitory synaptogenesis in mouse somatosensory cortex</article-title>. <source>Cereb Cortex</source> <volume>7</volume>: <fpage>619</fpage>–<lpage>634</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Dayan1"><label>36</label>
<mixed-citation publication-type="book" xlink:type="simple">Dayan P, Abbott L (2001) Theoretical neuroscience, volume 31. MIT press Cambridge, MA.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Azouz1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Azouz</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Gray</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Nowak</surname><given-names>L</given-names></name>, <name name-style="western"><surname>McCormick</surname><given-names>D</given-names></name> (<year>1997</year>) <article-title>Physiological properties of inhibitory interneurons in cat striate cortex</article-title>. <source>Cereb Cortex</source> <volume>7</volume>: <fpage>534</fpage>–<lpage>545</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Ahmed1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ahmed</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Whitteridge</surname><given-names>D</given-names></name> (<year>1998</year>) <article-title>Estimates of the net excitatory currents evoked by visual stimulation of identified neurons in cat visual cortex</article-title>. <source>Cereb Cortex</source> <volume>8</volume>: <fpage>462</fpage>–<lpage>476</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-BenYishai1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ben-Yishai</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bar-Or</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name> (<year>1995</year>) <article-title>Theory of orientation tuning in visual cortex</article-title>. <source>Proc Natl Acad Sci</source> <volume>92</volume>: <fpage>3844</fpage>–<lpage>3848</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Carandini1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ringach</surname><given-names>D</given-names></name> (<year>1997</year>) <article-title>Predictions of a recurrent model of orientation selectivity</article-title>. <source>Vision Res</source> <volume>37</volume>: <fpage>3061</fpage>–<lpage>3071</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Hahnloser2"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hahnloser</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Seung</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Slotine</surname><given-names>J</given-names></name> (<year>2003</year>) <article-title>Permitted and forbidden sets in symmetric threshold-linear networks</article-title>. <source>Neural Comput</source> <volume>15</volume>: <fpage>621</fpage>–<lpage>638</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Hensch1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hensch</surname><given-names>TK</given-names></name> (<year>2005</year>) <article-title>Critical period plasticity in local cortical circuits</article-title>. <source>Nature Rev Neurosci</source> <volume>6</volume>: <fpage>877</fpage>–<lpage>888</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Espinosa1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Espinosa</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Stryker</surname><given-names>MP</given-names></name> (<year>2012</year>) <article-title>Development and plasticity of the primary visual cortex</article-title>. <source>Neuron</source> <volume>75</volume>: <fpage>230</fpage>–<lpage>249</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Bednar1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bednar</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Miikkulainen</surname><given-names>R</given-names></name> (<year>2004</year>) <article-title>Prenatal and postnatal development of laterally connected orientation maps</article-title>. <source>Neurocomputing</source> <volume>58</volume>: <fpage>985</fpage>–<lpage>992</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Srinivasa1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Srinivasa</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Jiang</surname><given-names>Q</given-names></name> (<year>2013</year>) <article-title>Stable learning of functional maps in self-organizing spiking neural networks with continuous synaptic plasticity</article-title>. <source>Front Comput Neurosci</source> <volume>7</volume>: <fpage>10</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Turrigiano2"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Turrigiano</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>S</given-names></name> (<year>2004</year>) <article-title>Homeostatic plasticity in the developing nervous system</article-title>. <source>Nature Rev Neurosci</source> <volume>5</volume>: <fpage>97</fpage>–<lpage>107</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Turrigiano3"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Turrigiano</surname><given-names>G</given-names></name> (<year>2011</year>) <article-title>Too many cooks? Intrinsic and synaptic homeostatic mechanisms in cortical circuit refinement</article-title>. <source>Annu Rev Neurosci</source> <volume>34</volume>: <fpage>89</fpage>–<lpage>103</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-VanRossum1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Rossum</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Bi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Turrigiano</surname><given-names>G</given-names></name> (<year>2000</year>) <article-title>Stable hebbian learning from spike timing-dependent plasticity</article-title>. <source>J Neurosci</source> <volume>20</volume>: <fpage>8812</fpage>–<lpage>8821</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Liu1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Learning rule of homeostatic synaptic scaling: Presynaptic dependent or not</article-title>. <source>Neural Comput</source> <volume>23</volume>: <fpage>3145</fpage>–<lpage>3161</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Cooper1"><label>50</label>
<mixed-citation publication-type="other" xlink:type="simple">Cooper LN, Intrator N, Blais BS, Shouval HZ (2004) Theory of cortical plasticity. World Scientific.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Cooper2"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cooper</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Bear</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>The BCM theory of synapse modification at 30: interaction of theory with experiment</article-title>. <source>Nature Rev Neurosci</source> <volume>13</volume>: <fpage>798</fpage>–<lpage>810</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Haas1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haas</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Nowotny</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Abarbanel</surname><given-names>H</given-names></name> (<year>2006</year>) <article-title>Spike-timing-dependent plasticity of inhibitory synapses in the entorhinal cortex</article-title>. <source>J Neurophysiol</source> <volume>96</volume>: <fpage>3305</fpage>–<lpage>3313</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Ivenshitz1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ivenshitz</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Segal</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Simultaneous NMDA-dependent long-term potentiation of EPSCs and long-term depression of IPSCs in cultured rat hippocampal neurons</article-title>. <source>J Neurosci</source> <volume>26</volume>: <fpage>1199</fpage>–<lpage>1210</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Saar1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saar</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Reuveni</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Barkai</surname><given-names>E</given-names></name> (<year>2012</year>) <article-title>Mechanisms underlying rule learning-induced enhancement of excitatory and inhibitory synaptic transmission</article-title>. <source>J Neurophysiol</source> <volume>107</volume>: <fpage>1222</fpage>–<lpage>1229</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Vogels1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vogels</surname><given-names>TP</given-names></name>, <name name-style="western"><surname>Froemke</surname><given-names>RC</given-names></name>, <name name-style="western"><surname>Doyon</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Gilson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Haas</surname><given-names>JS</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Inhibitory synaptic plasticity: spike timing-dependence and putative network function</article-title>. <source>Front Neural Circuits</source> <volume>7</volume>: <fpage>119</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Markram1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Toledo-Rodriguez</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Gupta</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Silberberg</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>Interneurons of the neocortical inhibitory system</article-title>. <source>Nature Rev Neurosci</source> <volume>5</volume>: <fpage>793</fpage>–<lpage>807</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-BatistaBrito1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Batista-Brito</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Fishell</surname><given-names>G</given-names></name> (<year>2009</year>) <article-title>The developmental integration of cortical interneurons into a functional network</article-title>. <source>Curr Top Dev Biol</source> <volume>87</volume>: <fpage>81</fpage>–<lpage>118</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Busse1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Busse</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Wade</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Representation of concurrent stimuli by population activity in visual cortex</article-title>. <source>Neuron</source> <volume>64</volume>: <fpage>931</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Brouwer1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brouwer</surname><given-names>GJ</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>2011</year>) <article-title>Cross-orientation suppression in human visual cortex</article-title>. <source>J Neurophysiol</source> <volume>106</volume>: <fpage>2108</fpage>–<lpage>2119</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Tsai1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tsai</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Wade</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Norcia</surname><given-names>AM</given-names></name> (<year>2012</year>) <article-title>Dynamics of normalization underlying masking in human visual cortex</article-title>. <source>J Neurosci</source> <volume>32</volume>: <fpage>2783</fpage>–<lpage>2789</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Bathellier1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bathellier</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Ushakova</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Rumpel</surname><given-names>S</given-names></name> (<year>2012</year>) <article-title>Discrete neocortical dynamics predict behavioral categorization of sounds</article-title>. <source>Neuron</source> <volume>76</volume>: <fpage>435</fpage>–<lpage>449</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-VonNeumann1"><label>62</label>
<mixed-citation publication-type="book" xlink:type="simple">Von Neumann J (1958) The computer and the brain. Yale Univer. Press.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Kerlin1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kerlin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Andermann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Berezovskii</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Reid</surname><given-names>R</given-names></name> (<year>2010</year>) <article-title>Broadly tuned response properties of diverse inhibitory neuron subtypes in mouse visual cortex</article-title>. <source>Neuron</source> <volume>67</volume>: <fpage>858</fpage>–<lpage>871</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Niell1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niell</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Stryker</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Highly selective receptive fields in mouse visual cortex</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>7520</fpage>–<lpage>7536</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Hofer1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hofer</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Ko</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Pichler</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Vogelstein</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ros</surname><given-names>H</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Differential connectivity and response dynamics of excitatory and inhibitory neurons in visual cortex</article-title>. <source>Nat Neurosci</source> <volume>14</volume>: <fpage>1045</fpage>–<lpage>1052</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Zariwala1"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zariwala</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Madisen</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Ahrens</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Bernard</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lein</surname><given-names>E</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Visual tuning properties of genetically identified layer 2/3 neuronal types in the primary visual cortex of cre-transgenic mice</article-title>. <source>Front Syst Neurosci</source> <volume>4</volume>: <fpage>162</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Kuhlman1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kuhlman</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Tring</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Trachtenberg</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Fast-spiking interneurons have an initial orientation bias that is lost with vision</article-title>. <source>Nat Neurosci</source> <volume>14</volume>: <fpage>1121</fpage>–<lpage>1123</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Mruczek1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mruczek</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Sheinberg</surname><given-names>D</given-names></name> (<year>2012</year>) <article-title>Stimulus selectivity and response latency in putative inhibitory and excitatory neurons of the primate inferior temporal cortex</article-title>. <source>J Neurophysiol</source> <volume>108</volume>: <fpage>2725</fpage>–<lpage>2736</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Azouz2"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Azouz</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Gray</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Nowak</surname><given-names>L</given-names></name>, <name name-style="western"><surname>McCormick</surname><given-names>D</given-names></name> (<year>1997</year>) <article-title>Physiological properties of inhibitory interneurons in cat striate cortex</article-title>. <source>Cereb Cortex</source> <volume>7</volume>: <fpage>534</fpage>–<lpage>545</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Hirsch1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hirsch</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Martinez</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Pillai</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Alonso</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Q</given-names></name>, <etal>et al</etal>. (<year>2003</year>) <article-title>Functionally distinct inhibitory neurons at the first stage of visual cortical processing</article-title>. <source>Nat Neurosci</source> <volume>6</volume>: <fpage>1300</fpage>–<lpage>1308</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Cardin1"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cardin</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Palmer</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Contreras</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>Stimulus feature selectivity in excitatory and inhibitory neurons in primary visual cortex</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>10333</fpage>–<lpage>10344</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Nowak1"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nowak</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Sanchez-Vives</surname><given-names>M</given-names></name>, <name name-style="western"><surname>McCormick</surname><given-names>D</given-names></name> (<year>2008</year>) <article-title>Lack of orientation and direction selectivity in a subgroup of fast-spiking inhibitory interneurons: cellular and synaptic mechanisms and comparison with other electrophysiological cell types</article-title>. <source>Cereb Cortex</source> <volume>18</volume>: <fpage>1058</fpage>–<lpage>1078</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Somogyi2"><label>73</label>
<mixed-citation publication-type="other" xlink:type="simple">Somogyi P, Martin K (1985) Cortical circuitry underlying inhibitory processes in cat area 17. Models of the Visual Cortex: 514–523.</mixed-citation>
</ref>
<ref id="pcbi.1003994-GrabskaBarwiska1"><label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grabska-Barwińska</surname><given-names>A</given-names></name>, <name name-style="western"><surname>von der Malsburg</surname><given-names>C</given-names></name> (<year>2008</year>) <article-title>Establishment of a scaffold for orientation maps in primary visual cortex of higher mammals</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>249</fpage>–<lpage>257</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Lazar1"><label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lazar</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Pipa</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Triesch</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>SORN: a self-organizing recurrent neural network</article-title>. <source>Front Comput Neurosci</source> <volume>3</volume>: <fpage>23</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Bednar2"><label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bednar</surname><given-names>JA</given-names></name> (<year>2012</year>) <article-title>Building a mechanistic model of the development and function of the primary visual cortex</article-title>. <source>J Physiol Paris</source> <volume>106</volume>: <fpage>194</fpage>–<lpage>211</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Zubler3"><label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zubler</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hauri</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Pfister</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Bauer</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>JC</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Simulating cortical development as a self constructing process: A novel multi-scale approach combining molecular and physical aspects</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>: <fpage>e1003173</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Bauer1"><label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bauer</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Zubler</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Hauri</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Muir</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name> (<year>2014</year>) <article-title>Developmental origin of patchy axonal connectivity in the neocortex: A computational model</article-title>. <source>Cereb Cortex</source> <volume>24</volume>: <fpage>487</fpage>–<lpage>500</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Li2"><label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>Yt</given-names></name>, <name name-style="western"><surname>Ibrahim</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>Bh</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>LI</given-names></name>, <name name-style="western"><surname>Tao</surname><given-names>HW</given-names></name> (<year>2013</year>) <article-title>Linear transformation of thalamocortical input by intracortical excitation</article-title>. <source>Nat Neurosci</source> <volume>16</volume>: <fpage>1324</fpage>–<lpage>1330</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Lien1"><label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lien</surname><given-names>AD</given-names></name>, <name name-style="western"><surname>Scanziani</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Tuned thalamic excitation is amplified by visual cortical circuits</article-title>. <source>Nat Neurosci</source> <volume>16</volume>: <fpage>1315</fpage>–<lpage>1323</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Hebb1"><label>81</label>
<mixed-citation publication-type="book" xlink:type="simple">Hebb D (1949) The organization of behavior, volume 70. Wiley, New York, 71–72 pp.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Harris1"><label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harris</surname><given-names>KD</given-names></name> (<year>2012</year>) <article-title>Cell assemblies of the superficial cortex</article-title>. <source>Neuron</source> <volume>76</volume>: <fpage>263</fpage>–<lpage>265</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Song1"><label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Song</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sjöström</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Reigl</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Chklovskii</surname><given-names>D</given-names></name> (<year>2005</year>) <article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title>. <source>PLoS Biol</source> <volume>3</volume>: <fpage>e68</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Yoshimura1"><label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yoshimura</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Callaway</surname><given-names>E</given-names></name> (<year>2005</year>) <article-title>Fine-scale specificity of cortical networks depends on inhibitory cell type and connectivity</article-title>. <source>Nat Neurosci</source> <volume>8</volume>: <fpage>1552</fpage>–<lpage>1559</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Perin1"><label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perin</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Berger</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Markram</surname><given-names>H</given-names></name> (<year>2011</year>) <article-title>A synaptic organizing principle for cortical neuronal groups</article-title>. <source>Proc Natl Acad Sci</source> <volume>108</volume>: <fpage>5419</fpage>–<lpage>5424</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Ko1"><label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ko</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Hofer</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Pichler</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Buchanan</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Sjöström</surname><given-names>P</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Functional specificity of local synaptic connections in neocortical networks</article-title>. <source>Nature</source> <volume>473</volume>: <fpage>87</fpage>–<lpage>91</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Peters1"><label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peters</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Feldman</surname><given-names>M</given-names></name> (<year>1976</year>) <article-title>The projection of the lateral geniculate nucleus to area 17 of the rat cerebral cortex. I. general description</article-title>. <source>J neurocytol</source> <volume>5</volume>: <fpage>63</fpage>–<lpage>84</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Braitenberg1"><label>88</label>
<mixed-citation publication-type="book" xlink:type="simple">Braitenberg V, Schüz A (1991) Anatomy of the cortex: Statistics and geometry. Springer-Verlag Publishing, 109–112 pp.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Peters2"><label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peters</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Payne</surname><given-names>B</given-names></name> (<year>1993</year>) <article-title>Numerical relationships between geniculocortical afferents and pyramidal cell modules in cat primary visual cortex</article-title>. <source>Cereb Cortex</source> <volume>3</volume>: <fpage>69</fpage>–<lpage>78</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Monyer1"><label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Monyer</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Markram</surname><given-names>H</given-names></name> (<year>2004</year>) <article-title><italic>Interneuron Diversity series</italic>: Molecular and genetic tools to study GABAergic interneuron diversity and function</article-title>. <source>Trends Neurosci</source> <volume>27</volume>: <fpage>90</fpage>–<lpage>97</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Wonders1"><label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wonders</surname><given-names>CP</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>SA</given-names></name> (<year>2006</year>) <article-title>The origin and specification of cortical interneurons</article-title>. <source>Nature Rev Neurosci</source> <volume>7</volume>: <fpage>687</fpage>–<lpage>696</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Beurle1"><label>92</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beurle</surname><given-names>RL</given-names></name> (<year>1956</year>) <article-title>Properties of a mass of cells capable of regenerating pulses</article-title>. <source>Philos T Roy Soc B</source> <volume>240</volume>: <fpage>55</fpage>–<lpage>94</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Griffith1"><label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Griffith</surname><given-names>J</given-names></name> (<year>1963</year>) <article-title>A field theory of neural nets: I: Derivation of field equations</article-title>. <source>B Math Biophys</source> <volume>25</volume>: <fpage>111</fpage>–<lpage>120</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Griffith2"><label>94</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Griffith</surname><given-names>JS</given-names></name> (<year>1965</year>) <article-title>A field theory of neural nets: Ii. properties of the field equations</article-title>. <source>B Math Biophys</source> <volume>27</volume>: <fpage>187</fpage>–<lpage>195</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Alonso1"><label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alonso</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Swadlow</surname><given-names>H</given-names></name> (<year>2005</year>) <article-title>Thalamocortical specificity and the synthesis of sensory cortical receptive fields</article-title>. <source>J Neurophysiol</source> <volume>94</volume>: <fpage>26</fpage>–<lpage>32</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Yoshimura2"><label>96</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yoshimura</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Dantzker</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Callaway</surname><given-names>E</given-names></name> (<year>2005</year>) <article-title>Excitatory cortical neurons form fine-scale functional networks</article-title>. <source>Nature</source> <volume>433</volume>: <fpage>868</fpage>–<lpage>873</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Wang1"><label>97</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Kloc</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Gu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Ge</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Maffei</surname><given-names>A</given-names></name> (<year>2013</year>) <article-title>Layer-specific experience-dependent rewiring of thalamocortical circuits</article-title>. <source>J Neurosci</source> <volume>33</volume>: <fpage>4181</fpage>–<lpage>4191</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Vogels2"><label>98</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vogels</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Sprekeler</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Zenke</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Clopath</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name> (<year>2011</year>) <article-title>Inhibitory plasticity balances excitation and inhibition in sensory pathways and memory networks</article-title>. <source>Science</source> <volume>334</volume>: <fpage>1569</fpage>–<lpage>1573</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Sohya1"><label>99</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sohya</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Kameyama</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Yanagawa</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Obata</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Tsumoto</surname><given-names>T</given-names></name> (<year>2007</year>) <article-title>GABAergic neurons are less selective to stimulus orientation than excitatory neurons in layer II/III of visual cortex, as revealed by in vivo functional Ca2+ imaging in transgenic mice</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>2145</fpage>–<lpage>2149</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Liu2"><label>100</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Yanagawa</surname><given-names>Y</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Visual receptive field structure of cortical inhibitory neurons revealed by two-photon imaging guided recording</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>10520</fpage>–<lpage>10532</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Bock1"><label>101</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bock</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Kerlin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Andermann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hood</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Network anatomy and in vivo physiology of visual cortical neurons</article-title>. <source>Nature</source> <volume>471</volume>: <fpage>177</fpage>–<lpage>182</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Bloodgood1"><label>102</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bloodgood</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Giessel</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sabatini</surname><given-names>B</given-names></name> (<year>2009</year>) <article-title>Biphasic synaptic ca influx arising from compartmentalized electrical signals in dendritic spines</article-title>. <source>PLoS Biol</source> <volume>7</volume>: <fpage>e1000190</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Kasai1"><label>103</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kasai</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Hayama</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Ishikawa</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Watanabe</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Yagishita</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Learning rules and persistence of dendritic spines</article-title>. <source>Eur J Neurosci</source> <volume>32</volume>: <fpage>241</fpage>–<lpage>249</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Chiu1"><label>104</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chiu</surname><given-names>CQ</given-names></name>, <name name-style="western"><surname>Lur</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Morse</surname><given-names>TM</given-names></name>, <name name-style="western"><surname>Carnevale</surname><given-names>NT</given-names></name>, <name name-style="western"><surname>Ellis-Davies</surname><given-names>GC</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Compartmentalization of gabaergic inhibition by dendritic spines</article-title>. <source>Science</source> <volume>340</volume>: <fpage>759</fpage>–<lpage>762</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Lee1"><label>105</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>WCA</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Feng</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Sanes</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Brown</surname><given-names>EN</given-names></name>, <etal>et al</etal>. (<year>2005</year>) <article-title>Dynamic remodeling of dendritic arbors in GABAergic interneurons of adult visual cortex</article-title>. <source>PLoS Biol</source> <volume>4</volume>: <fpage>e29</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Oster1"><label>106</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oster</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>SC</given-names></name> (<year>2009</year>) <article-title>Computation with spikes in a winner-take-all network</article-title>. <source>Neural Comput</source> <volume>21</volume>: <fpage>2437</fpage>–<lpage>2465</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Chen1"><label>107</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>McKinstry</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name> (<year>2013</year>) <article-title>Versatile networks of simulated spiking neurons displaying winner-take-all behavior</article-title>. <source>Front Comput Neurosci</source> <volume>7</volume>: <fpage>16</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Caporale1"><label>108</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Caporale</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name> (<year>2008</year>) <article-title>Spike timing-dependent plasticity: a hebbian learning rule</article-title>. <source>Annu Rev Neurosci</source> <volume>31</volume>: <fpage>25</fpage>–<lpage>46</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Clopath1"><label>109</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Clopath</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Büsing</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Vasilaki</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name> (<year>2010</year>) <article-title>Connectivity reflects coding: a model of voltage-based stdp with homeostasis</article-title>. <source>Nature Neurosci</source> <volume>13</volume>: <fpage>344</fpage>–<lpage>352</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Pfister1"><label>110</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pfister</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name> (<year>2006</year>) <article-title>Triplets of spikes in a model of spike timing-dependent plasticity</article-title>. <source>J Neurosci</source> <volume>26</volume>: <fpage>9673</fpage>–<lpage>9682</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Bush1"><label>111</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bush</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Philippides</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Husbands</surname><given-names>P</given-names></name>, <name name-style="western"><surname>O'Shea</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Reconciling the stdp and bcm models of synaptic plasticity in a spiking recurrent neural network</article-title>. <source>Neural Comput</source> <volume>22</volume>: <fpage>2059</fpage>–<lpage>2085</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Gjorgjieva1"><label>112</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gjorgjieva</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Clopath</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Audet</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Pfister</surname><given-names>JP</given-names></name> (<year>2011</year>) <article-title>A triplet spike-timing–dependent plasticity model generalizes the bienenstock–cooper–munro rule to higher-order spatiotemporal correlations</article-title>. <source>Proc Natl Acad Sci</source> <volume>108</volume>: <fpage>19383</fpage>–<lpage>19388</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Rockland1"><label>113</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rockland</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Lund</surname><given-names>J</given-names></name> (<year>1982</year>) <article-title>Widespread periodic intrinsic connections in the tree shrew visual cortex</article-title>. <source>Science</source> <volume>215</volume>: <fpage>1532</fpage>–<lpage>1534</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Rockland2"><label>114</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rockland</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Lund</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Humphrey</surname><given-names>A</given-names></name> (<year>1982</year>) <article-title>Anatomical banding of intrinsic connections in striate cortex of tree shrews (Tupaia glis)</article-title>. <source>J Comp Neurol</source> <volume>209</volume>: <fpage>41</fpage>–<lpage>58</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Lund1"><label>115</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lund</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Angelucci</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Bressloff</surname><given-names>P</given-names></name> (<year>2003</year>) <article-title>Anatomical substrates for functional columns in macaque monkey primary visual cortex</article-title>. <source>Cereb Cortex</source> <volume>13</volume>: <fpage>15</fpage>–<lpage>24</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Muir1"><label>116</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Muir</surname><given-names>DR</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>RJ</given-names></name> (<year>2011</year>) <article-title>From neural arbors to daisies</article-title>. <source>Cereb Cortex</source> <volume>21</volume>: <fpage>1118</fpage>–<lpage>33</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Alon1"><label>117</label>
<mixed-citation publication-type="book" xlink:type="simple">Alon U (2006) An introduction to systems biology: design principles of biological circuits. CRC Press.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Pfister2"><label>118</label>
<mixed-citation publication-type="other" xlink:type="simple">Pfister S (2013) Inference of developmental motifs in the developing mouse cerebral cortex. Ph.D. thesis, ETH Zuerich.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Warren1"><label>119</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Warren</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bedi</surname><given-names>K</given-names></name> (<year>1984</year>) <article-title>A quantitative assessment of the development of synapses and neurons in the visual cortex of control and undernourished rats</article-title>. <source>J Comp Neurol</source> <volume>227</volume>: <fpage>104</fpage>–<lpage>108</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Leuba1"><label>120</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Leuba</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Garey</surname><given-names>L</given-names></name> (<year>1989</year>) <article-title>Comparison of neuronal and glial numerical density in primary and secondary visual cortex of man</article-title>. <source>Exp Brain Res</source> <volume>77</volume>: <fpage>31</fpage>–<lpage>38</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Miki1"><label>121</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miki</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Fukui</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Itoh</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hisano</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>Q</given-names></name>, <etal>et al</etal>. (<year>1997</year>) <article-title>Estimation of the numerical densities of neurons and synapses in cerebral cortex</article-title>. <source>Brain Res Prot</source> <volume>2</volume>: <fpage>9</fpage>–<lpage>16</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Lbke1"><label>122</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lübke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Markram</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Frotscher</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sakmann</surname><given-names>B</given-names></name> (<year>1996</year>) <article-title>Frequency and dendritic distribution of autapses established by layer 5 pyramidal neurons in the developing rat neocortex: comparison with synaptic innervation of adjacent neurons of the same class</article-title>. <source>J Neurosci</source> <volume>16</volume>: <fpage>3209</fpage>–<lpage>3218</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Hellwig1"><label>123</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hellwig</surname><given-names>B</given-names></name> (<year>2000</year>) <article-title>A quantitative analysis of the local connectivity between pyramidal neurons in layers 2/3 of the rat visual cortex</article-title>. <source>Biol Cybern</source> <volume>82</volume>: <fpage>111</fpage>–<lpage>121</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Binzegger3"><label>124</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Binzegger</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>K</given-names></name> (<year>2009</year>) <article-title>Topology and dynamics of the canonical circuit of cat V1</article-title>. <source>Neural Networks</source> <volume>22</volume>: <fpage>1071</fpage>–<lpage>1078</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Trappenberg1"><label>125</label>
<mixed-citation publication-type="book" xlink:type="simple">Trappenberg TP (2010) Fundamentals of computational neuroscience. Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Smoot1"><label>126</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smoot</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ono</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Ruscheinski</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Ideker</surname><given-names>T</given-names></name> (<year>2011</year>) <article-title>Cytoscape 2.8: new features for data integration and network visualization</article-title>. <source>Bioinformatics</source> <volume>27</volume>: <fpage>431</fpage>–<lpage>432</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Kamada1"><label>127</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kamada</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kawai</surname><given-names>S</given-names></name> (<year>1989</year>) <article-title>An algorithm for drawing general undirected graphs</article-title>. <source>Inform Process Lett</source> <volume>31</volume>: <fpage>7</fpage>–<lpage>15</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Greenberg1"><label>128</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greenberg</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Houweling</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kerr</surname><given-names>J</given-names></name> (<year>2008</year>) <article-title>Population imaging of ongoing neuronal activity in the visual cortex of awake rats</article-title>. <source>Nat Neurosci</source> <volume>11</volume>: <fpage>749</fpage>–<lpage>751</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-DeKock1"><label>129</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Kock</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Sakmann</surname><given-names>B</given-names></name> (<year>2009</year>) <article-title>Spiking in primary somatosensory cortex during natural whisking in awake head-restrained rats is cell-type specific</article-title>. <source>Proc Natl Acad Sci</source> <volume>106</volume>: <fpage>16446</fpage>–<lpage>16450</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Swadlow1"><label>130</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Swadlow</surname><given-names>HA</given-names></name> (<year>1989</year>) <article-title>Efferent neurons and suspected interneurons in S-1 vibrissa cortex of the awake rabbit: receptive fields and axonal properties</article-title>. <source>J Neurophysiol</source> <volume>62</volume>: <fpage>288</fpage>–<lpage>308</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Povysheva1"><label>131</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Povysheva</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Zaitsev</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rotaru</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Gonzalez-Burgos</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Lewis</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Parvalbumin-positive basket interneurons in monkey and rat prefrontal cortex</article-title>. <source>J Neurophysiol</source> <volume>100</volume>: <fpage>2348</fpage>–<lpage>2360</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Fiala1"><label>132</label>
<mixed-citation publication-type="other" xlink:type="simple">Fiala JC, Harris KM (1999) Dendrite structure. Dendrites: 1–34.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Binzegger4"><label>133</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Binzegger</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>KA</given-names></name> (<year>2005</year>) <article-title>Axons in cat visual cortex are topologically self-similar</article-title>. <source>Cereb Cortex</source> <volume>15</volume>: <fpage>152</fpage>–<lpage>165</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003994-Stepanyants1"><label>134</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stepanyants</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Martinez</surname><given-names>LM</given-names></name>, <name name-style="western"><surname>Ferecskó</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Kisvárday</surname><given-names>ZF</given-names></name> (<year>2009</year>) <article-title>The fractions of short-and long-range connections in the visual cortex</article-title>. <source>Proc Natl Acad Sci</source> <volume>106</volume>: <fpage>3555</fpage>–<lpage>3560</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN"><front><journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">08-PLCB-RA-0066R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000119</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Biophysics/Theory and Simulation</subject><subject>Neuroscience/Sensory Systems</subject><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>Intrinsic Gain Modulation and Adaptive Neural Coding</article-title><alt-title alt-title-type="running-head">Intrinsic Gain Modulation and Neural Adaptation</alt-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Hong</surname><given-names>Sungho</given-names></name><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref><xref ref-type="fn" rid="fn1"><sup>¤</sup></xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Lundstrom</surname><given-names>Brian Nils</given-names></name><xref ref-type="aff" rid="aff1"/></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Fairhall</surname><given-names>Adrienne L.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib></contrib-group><aff id="aff1"><addr-line>Physiology and Biophysics Department, University of Washington, Seattle, Washington, United States of America</addr-line>       </aff><contrib-group><contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes><corresp id="cor1">* E-mail: <email xlink:type="simple">shhong@oist.jp</email></corresp><fn fn-type="current-aff" id="fn1"><label>¤</label><p>Current address: Computational Neuroscience Unit, Okinawa Institute of Science and Technology, Onna-son, Okinawa, Japan</p></fn><fn fn-type="con"><p>Conceived and designed the experiments: SH. Analyzed the data: SH. Contributed reagents/materials/analysis tools: BL. Wrote the paper: SH BL AF. Derived the equations: SH.</p></fn><fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>7</month><year>2008</year></pub-date><pub-date pub-type="epub"><day>18</day><month>7</month><year>2008</year></pub-date><volume>4</volume><issue>7</issue><elocation-id>e1000119</elocation-id><history><date date-type="received"><day>30</day><month>1</month><year>2008</year></date><date date-type="accepted"><day>9</day><month>6</month><year>2008</year></date></history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2008</copyright-year><copyright-holder>Hong et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>In many cases, the computation of a neural system can be reduced to a receptive field, or a set of linear filters, and a thresholding function, or gain curve, which determines the firing probability; this is known as a linear/nonlinear model. In some forms of sensory adaptation, these linear filters and gain curve adjust very rapidly to changes in the variance of a randomly varying driving input. An apparently similar but previously unrelated issue is the observation of gain control by background noise in cortical neurons: the slope of the firing rate versus current (<italic>f-I</italic>) curve changes with the variance of background random input. Here, we show a direct correspondence between these two observations by relating variance-dependent changes in the gain of <italic>f-I</italic> curves to characteristics of the changing empirical linear/nonlinear model obtained by sampling. In the case that the underlying system is fixed, we derive relationships relating the change of the gain with respect to both mean and variance with the receptive fields derived from reverse correlation on a white noise stimulus. Using two conductance-based model neurons that display distinct gain modulation properties through a simple change in parameters, we show that coding properties of both these models quantitatively satisfy the predicted relationships. Our results describe how both variance-dependent gain modulation and adaptive neural computation result from intrinsic nonlinearity.</p></abstract><abstract abstract-type="summary"><title>Author Summary</title><p>Many neurons are known to achieve a wide dynamic range by adaptively changing their computational input/output function according to the input statistics. These adaptive changes can be very rapid, and it has been suggested that a component of this adaptation could be purely input-driven: even a fixed neural system can show apparent adaptive behavior since inputs with different statistics interact with the nonlinearity of the system in different ways. In this paper, we show how a single neuron's intrinsic computational function can dictate such input-driven changes in its response to varying input statistics, which begets a relationship between two different characterizations of neural function—in terms of mean firing rate and in terms of generating precise spike timing. We then apply our results to two biophysically defined model neurons, which have significantly different response patterns to inputs with various statistics. Our model of intrinsic adaptation explains their behaviors well. Contrary to the picture that neurons carry out a stereotyped computation on their inputs, our results show that even in the simplest cases they have simple yet effective mechanisms by which they can adapt to their input. Adaptation to stimulus statistics, therefore, is built into the most basic single neuron computations.</p></abstract><funding-group><funding-statement>This work was supported by a Burroughs-Wellcome Careers at the Scientific Interface grant, a Sloan Research Fellowship, and a McKnight Scholar Award to ALF. BNL was supported by grant number F30NS055650 from the National Institute of Neurological Disorders and Stroke, the Medical Scientist Training Program at the University of Washington supported by the National Institute of General Sciences, and an Achievement Rewards for College Scientists fellowship.</funding-statement></funding-group><counts><page-count count="11"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>An <italic>f-I</italic> curve, defined as the mean firing rate in response to a stationary mean current input, is one of the simplest ways to characterize how a neuron transforms a stimulus into a spike train output as a function of the magnitude of a single stimulus parameter. Recently, the dependence of <italic>f-I</italic> curves on other input statistics such as the variance has been examined: the slope of the <italic>f-I</italic> curve, or gain, is modulated in diverse ways in response to different intensities of added noise <xref ref-type="bibr" rid="pcbi.1000119-Chance1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Arsiero1">[4]</xref>. This enables multiplicative control of the neuronal gain by the level of background synaptic activity <xref ref-type="bibr" rid="pcbi.1000119-Chance1">[1]</xref>: changing the level of the background synaptic activity is equivalent to changing the variance of the noisy balanced excitatory and inhibitory input current to the soma, which modulates the gain of the <italic>f-I</italic> curve. It has been demonstrated that such somatic gain modulation, combined with saturation in the dendrites, can lead to multiplicative gain control in a single neuron by background inputs <xref ref-type="bibr" rid="pcbi.1000119-Prescott1">[5]</xref>. From a computational perspective, the sensitivity of the firing rate to mean or variance can be thought of as distinguishing the neuron's function as either an integrator (greater sensitivity to the mean) or a differentiator/coincidence detector (greater sensitivity to fluctuations, as quantified by the variance) <xref ref-type="bibr" rid="pcbi.1000119-Higgs1">[3]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Prescott2">[6]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Lundstrom1">[7]</xref>.</p><p>An alternative method of characterizing a neuron's input-to-output transformation is through a linear/nonlinear (LN) cascade model <xref ref-type="bibr" rid="pcbi.1000119-Victor1">[8]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Meister1">[9]</xref>. These models comprise a set of linear filters or receptive field that selects particular features from the input; the filter output is transformed by a nonlinear threshold stage into a time-varying firing rate. Spike-triggered covariance analysis <xref ref-type="bibr" rid="pcbi.1000119-Brenner1">[10]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Simoncelli1">[11]</xref> reconstructs a model with multiple features from a neuron's input/output data. It has been widely employed to characterize both neural systems <xref ref-type="bibr" rid="pcbi.1000119-Rust1">[12]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Maravall1">[15]</xref> and single neurons or neuron models subject to current or conductance inputs <xref ref-type="bibr" rid="pcbi.1000119-AgerayArcas1">[16]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Hong1">[19]</xref>.</p><p>Generally, results of reverse correlation analysis may depend on the statistics of the stimulus used to sample the model <xref ref-type="bibr" rid="pcbi.1000119-Maravall1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Hong1">[19]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Gaudry1">[25]</xref>. While some of the dependence on stimulus statistics in the response of a neuron or neural system may reflect underlying plasticity, in some cases, the rapid timescale of the changes suggests the action of intrinsic nonlinearities in systems with <italic>fixed</italic> parameters <xref ref-type="bibr" rid="pcbi.1000119-AgerayArcas1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Hong1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Gaudry1">[25]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Borst1">[29]</xref>, which changes the <italic>effective</italic> computation of a neuron.</p><p>Our goal here is to unify the <italic>f-I</italic> curve description of variance-dependent adaptive computation with that given by the LN model: we present analytical results showing that the variance-dependent modulation of the firing rate is closely related to adaptive changes in the <italic>recovered</italic> LN model if a fixed underlying model is assumed. When the model relies only on a single feature, we find that such a system can show only a single type of gain modulation, which accompanies an interesting asymptotic scaling behavior. With multiple features, the model can show more diverse adaptive behaviors, exemplified by two conductance-based models that we will study.</p></sec><sec id="s2"><title>Results</title><sec id="s2a"><title>Diverse Variance-Dependent Gain Modulations without Spike Rate Adaptation</title><p>Recently, Higgs et al. <xref ref-type="bibr" rid="pcbi.1000119-Higgs1">[3]</xref> and Arsiero et al. <xref ref-type="bibr" rid="pcbi.1000119-Arsiero1">[4]</xref> identified different forms of variance-dependent change in the <italic>f-I</italic> curves of various neuron types in avian brainstem and in cortex. Depending on the type, neurons can have either increasing or decreasing gain in the <italic>f-I</italic> curve with increasing variance. These papers linked the phenomenon to mechanisms underlying spike rate adaptation, such as slow afterhyperpolarization (sAHP) currents and slow sodium channel inactivation. We recently showed <xref ref-type="bibr" rid="pcbi.1000119-Lundstrom1">[7]</xref> that a standard Hodgkin–Huxley (HH) neuron model, lacking spike rate adaptation, can show two different types of variance-dependent gain modulation simply by tuning the maximal conductance parameters of the model. These differences in gain modulation correspond to two different regimes in the space of conductance parameters. In one regime, which includes the standard parameters, a neuron periodically fires to a sufficiently large constant input current. In the other regime, a neuron never fires to a constant input regardless of its magnitude, but responds only to rapid fluctuations. This rarely discussed property has been termed <italic>class 3 excitability</italic> <xref ref-type="bibr" rid="pcbi.1000119-Hodgkin1">[30]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Izhikevich1">[31]</xref>. Higgs et al. <xref ref-type="bibr" rid="pcbi.1000119-Higgs1">[3]</xref> proposed that the type of gain modulation classifies the neuron as an integrator or differentiator.</p><p>Here, we examine two models that show these different forms of variance-dependent gain modulation without spike rate adaptation, and study the resulting LN models sampled with different stimulus statistics. We show that these <italic>fixed</italic> models generate variance-dependent gain modulation, and that this gain modulation is well predicted by aspects of the LN models derived from white noise stimulation. The two models are both based on the HH <xref ref-type="bibr" rid="pcbi.1000119-Hodgkin2">[32]</xref> active currents; one model is the standard HH model, and the other (HHLS) has lower Na<sup>+</sup> and higher K<sup>+</sup> conductances. The HHLS model is a class 3 neuron and responds only to a rapidly changing input. For this reason, the HHLS model can be thought of as behaving more like a differentiator than an integrator <xref ref-type="bibr" rid="pcbi.1000119-Higgs1">[3]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Lundstrom1">[7]</xref>.</p><p><xref ref-type="fig" rid="pcbi-1000119-g001">Figure 1</xref> shows the different gain modulation behaviors of the HH and HHLS conductance-based models. For the HH model, <xref ref-type="fig" rid="pcbi-1000119-g001">Figure 1A</xref>, the <italic>f-I</italic> curves in the presence of noise are similar to the noiseless case except that they are increasingly smoothed at the threshold. In contrast, <xref ref-type="fig" rid="pcbi-1000119-g001">Figure 1C</xref> shows that the <italic>f-I</italic> curves of the HHLS model never converge toward each other as the noise level increases. This case resembles that of layer 5 pyramidal neurons in rat medial prefrontal cortex <xref ref-type="bibr" rid="pcbi.1000119-Arsiero1">[4]</xref>, as well as nucleus laminaris (NL) neurons in the chick auditory brainstem and some pyramidal neurons in layer 2/3 of rat neocortex <xref ref-type="bibr" rid="pcbi.1000119-Higgs1">[3]</xref>. While for these layer 2/3 neurons, there is evidence that this change in <italic>f-I</italic> curve slope may be related to the sAHP current <xref ref-type="bibr" rid="pcbi.1000119-Higgs1">[3]</xref>, at steady state this effect can be obtained in general by tuning the maximal conductances without introducing any mechanism for spike rate adaptation <xref ref-type="bibr" rid="pcbi.1000119-Lundstrom1">[7]</xref>.</p><fig id="pcbi-1000119-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000119.g001</object-id><label>Figure 1</label><caption><title>Variance-Dependent Gain Modulation of the HH and HHLS Model.</title><p>Each model is simulated as described in the <xref ref-type="sec" rid="s4">Materials and Methods</xref> section. (A) <italic>f-I</italic> curves of a standard HH model for differing 10 variances (σ<sup>2</sup>) from 0 to 45 nA<sup>2</sup>. The topmost trace is the response to the highest variance. Each curve is obtained with 31 mean values (<italic>I</italic><sub>0</sub>) ranging from −5 to 20 nA. (B) The same data as (A) plotted in the (mean, variance) plane. Lighter shades represent higher firing rates. We used cubic spline interpolation for points not included in the simulated data. (C,D) <italic>f-I</italic> curves of the HHLS model as in (A) and (B). 10 means from −10 to 50 nA and 21 variances from 0 to 100 nA<sup>2</sup> are used.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.g001" xlink:type="simple"/></fig></sec><sec id="s2b"><title>Gain Modulation and Adaptation of Fixed Models</title><p>For a system described by an LN model with a single feature, we derive an equation relating the slopes of the firing rate with respect to stimulus mean and variance. We then consider gain modulation in a system with multiple relevant features and derive a series of equations relating gain change to properties of the spike-triggered average and spike-triggered covariance. Throughout, we assume that the underlying system is fixed, and that its parameter settings do not depend on stimulus statistics. For example, if the model has a single exponential filter with a time constant τ, we assume that τ does not change with the stimulus mean (<italic>I</italic><sub>0</sub>) or variance (σ<sup>2</sup>). However, this does not mean that the model shows a single response pattern regardless of the statistical structure of stimuli. The sampled LN description of a nonlinear system with fixed parameters—even when the underlying model is an LN model <xref ref-type="bibr" rid="pcbi.1000119-Gaudry1">[25]</xref>—can show interaction with the input statistics, leading to different LN model descriptions for different input parameters <xref ref-type="bibr" rid="pcbi.1000119-Hong1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Gaudry1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Paninski1">[27]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Borst1">[29]</xref>. We refer to this as <italic>intrinsic adaptation</italic>.</p></sec><sec id="s2c"><title>One-Dimensional Model</title><p>An LN model is composed of its relevant features {ε<sub>μ</sub>(<italic>t</italic>)} (μ  =  1,2,…,<italic>n</italic>)), which act as linear filters on an incoming stimulus, and a probability to spike given the filtered stimulus, <italic>P</italic>(spike|filtered stimulus). For a Gaussian white noise stimulus with mean <italic>I</italic><sub>0</sub> and variance σ<sup>2</sup>, the firing rate is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e001" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e002" xlink:type="simple"/></inline-formula> is the time-integrated filter and <bold>x</bold> is the mean-subtracted noise stimulus filtered by the <italic>n</italic> relevant features. <italic>p</italic>(<bold>x</bold>) is an <italic>n</italic>-dimensional Gaussian distribution with variance σ<sup>2</sup>. We refer to the <xref ref-type="sec" rid="s4">Materials and Methods</xref> section for a more detailed account of the model.</p><p>For a one-dimensional model <italic>n</italic>  =  1, Equation 1 can be rewritten with change of variables<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e003" xlink:type="simple"/><label>(2)</label></disp-formula>Since <italic>p</italic>(<italic>x</italic>) is Gaussian, it is also the kernel or Green's function of a diffusion equation in terms of (<italic>x</italic>,σ<sup>2</sup>) and therefore so is <italic>p</italic>(<italic>x</italic>−<italic>I</italic><sub>0</sub>ε̅) in terms of (<italic>I</italic><sub>0</sub>,σ<sup>2</sup>). In other words, we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e004" xlink:type="simple"/></disp-formula>Now operating with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e005" xlink:type="simple"/></inline-formula> on both sides of the equation, <italic>p</italic>(<italic>x</italic>−<italic>I</italic><sub>0</sub>ε̅) is the only term on the left hand side of Equation 2 that depends on (<italic>I</italic><sub>0</sub>,σ<sup>2</sup>) and therefore the right hand side of Equation 2 vanishes. Thus one finds<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e006" xlink:type="simple"/><label>(3)</label></disp-formula>The boundary condition is given by evaluating Equation 2 as σ<sup>2</sup>→0; here the Gaussian distribution becomes a delta function<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e007" xlink:type="simple"/></disp-formula>and the boundary condition is given by the zero-noise <italic>f-I</italic> curve. Thus, when a model depends only on a single feature, ε(<italic>t</italic>), the <italic>f-I</italic> curve with a noisy input is given by a simple diffusion-like equation, Equation 3, with a single parameter, the time integrated filter, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e008" xlink:type="simple"/></inline-formula>, determining the diffusion constant 1/2ε̅<sup>2</sup>.</p><p>Equation 3 states that the variance-dependent change in the firing rate is simply determined by the curvature of the <italic>f-I</italic> curve. Thus, a one-dimensional system displays only a single type of noise-induced gain modulation: as in diffusion, an <italic>f-I</italic> curve is gradually smoothed and flattened as the variance increases. Given a boundary condition, such as an <italic>f-I</italic> curve for a particular variance, the family of <italic>f-I</italic> relations can be reconstructed up to a scale factor by solving Equation 3. For example, one can predict how the neuron would respond to a noise stimulus based on its output in the absence of noise. Note that the solution of Equation 3 generalizes a classical result <xref ref-type="bibr" rid="pcbi.1000119-Spekreijse1">[33]</xref> based on a binary nonlinearity to a simple closed form which applies to any type of nonlinearity.</p><p><xref ref-type="fig" rid="pcbi-1000119-g002">Figure 2A and 2B</xref> show a solution of Equation 3. While this one-dimensional model is based on the simplest and most general assumptions, it provides insights into the structure of variance-dependent gain modulation. The boundary condition is an <italic>f-I</italic> curve with no noise, <italic>f</italic>  =  (<italic>I</italic>+0.1)<sup>1/2</sup> for <italic>I</italic>&gt;0 and <italic>f</italic>  =  0 for <italic>I</italic>≤0, which imitates the general behavior of many dynamical neuron models around rheobase <xref ref-type="bibr" rid="pcbi.1000119-Ermentrout1">[34]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Hoppensteadt1">[36]</xref>. Compared with the HH conductance-based model, Equation 3 captures qualitative characteristics of the HH <italic>f-I</italic> curve despite differences due to the increased complexity of the HH model over a 1D LN model: in <xref ref-type="fig" rid="pcbi-1000119-g002">Figure 2A and 2B</xref>, there is a positive curvature (second derivative of firing rate with respect to current) of the <italic>f-I</italic> curve below rheobase related to the increase of the firing rate with increasing variance. In contrast, the behavior of the HHLS model cannot be described by Equation 3. Even though the <italic>f-I</italic> curves in <xref ref-type="fig" rid="pcbi-1000119-g001">Figure 1C</xref> mostly have negative curvature, the firing rate keeps increasing with variance, implying that the HHLS model cannot be described by a one-dimensional LN model.</p><fig id="pcbi-1000119-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000119.g002</object-id><label>Figure 2</label><caption><title>Variance-Dependent Gain Modulation of One-Dimensional Models.</title><p>(A) Variance-dependent <italic>f-I</italic> curves of a one-dimensional model from the solution of Equation 3 with the boundary condition, <italic>f</italic> = (<italic>I</italic>+0.1)<sup>1/2</sup> for <italic>I</italic>&gt;0 and <italic>f</italic> = 0 for <italic>I</italic>≤0 at zero noise. (B) The firing rates of A in the (mean, variance) plane. (C) <italic>f-I</italic> curves of an LIF model. (D) <italic>f-I</italic> curves of a QIF model. The model parameters for the LIF and QIF are in the <xref ref-type="sec" rid="s4">Materials and Methods</xref> section. We used 50 mean (<italic>I</italic><sub>0</sub>) values from 0 to 4 (LIF) and from −2 to 2 (QIF), and 8 variances (σ<sup>2</sup>) from 0 to 8 for both models.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.g002" xlink:type="simple"/></fig><p>We also compared Equation 3 with the <italic>f-I</italic> curves from two commonly used simple neuron models, the leaky integrate-and-fire (LIF) model (<xref ref-type="fig" rid="pcbi-1000119-g002">Figure 2C</xref>), and a similar model with minimal nonlinearity, the quadratic integrate-and-fire (QIF) model <xref ref-type="bibr" rid="pcbi.1000119-Ermentrout2">[37]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Ermentrout3">[38]</xref> (<xref ref-type="fig" rid="pcbi-1000119-g002">Figure 2D</xref>). The <italic>f-I</italic> curves of the two models are similar but have subtle differences: in the LIF model, firing rate never decreases with noise, even though parameters were chosen to induce a large negative curvature, as shown analytically in <xref ref-type="supplementary-material" rid="pcbi.1000119.s001">Text S1</xref>. The QIF model behavior is much more similar to the 1D LN model, marked by a slight decrease in firing rate at large <italic>I</italic><sub>0</sub>. From this perspective, the QIF is a <italic>simpler</italic> model in terms of the LN description despite the dynamical nonlinearity.</p><p>It is interesting to note that for one-dimensional models, the gain modulation given by Equation 3 depends only on the boundary condition, which implicitly describes how an input with a given mean samples the nonlinearity, but not explicitly on the details of filters or nonlinearity. An ideal differentiator, where firing rate is independent of the stimulus mean, is realized only when the filter has zero integral, ε̅  =  0. This is also the criterion that would be satisfied if the filter itself were ideally differentiating. We will return to the relationship between the LN model functional description and that of the <italic>f-I</italic> curves in the Discussion.</p></sec><sec id="s2d"><title>Multidimensional Models</title><p>Here we examine gain modulation in the case of a system with multiple relevant features. In this case, one cannot derive a single simple equation such as Equation 3. Instead, we derive relationships between the characteristics of <italic>f</italic>(<italic>I</italic><sub>0</sub>,σ) curves and quantities calculated using white noise analysis.</p><p>Fixed multidimensional models can display far more complex response patterns to different stimulus statistics than one-dimensional models, because linear components in the model can now interact nonlinearly <xref ref-type="bibr" rid="pcbi.1000119-Borst1">[29]</xref>. For example, in white noise analysis, as the stimulus variance increases, the distribution of the filtered stimuli also expands and probes different regions of the nonlinear threshold structure of the model. This induces a variance-dependent rotation among the filters recovered through sampling by white noise analysis, and the corresponding changes in the spike-triggered average, spike-triggered covariance, and the sampled nonlinearity <xref ref-type="bibr" rid="pcbi.1000119-Hong1">[19]</xref>.</p><p>Here, we relate parameters of the changing spike-triggered average and spike-triggered covariance description to the form of the <italic>f-I</italic> curves. The relationships are derived by taking derivatives of each side of Equation 1 with respect to <italic>I</italic><sub>0</sub> and σ<sup>2</sup> (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> section). The first order in <italic>I</italic><sub>0</sub> establishes the relationship between the STA and the gain of the <italic>f-I</italic> curve with respect to the mean<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e009" xlink:type="simple"/><label>(4)</label></disp-formula>The second order leads to a relationship between the second derivative of the <italic>f-I</italic> curve and the covariance matrix<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e010" xlink:type="simple"/><label>(5)</label></disp-formula>The gain with respect to the variance is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e011" xlink:type="simple"/><label>(6)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e012" xlink:type="simple"/></disp-formula></p><p>Equations 4–6 show how the nonlinear gain of an <italic>f-I</italic> curve with respect to input mean and variance is related to intrinsic adaptation as observed through changes in the STA and STC. Note that Equations 4–6 apply to one-dimensional LN models as well. In that case, the STA has the same shape as the feature in the model, and only its magnitude varies according to the overlap integral, Equation 1, between the nonlinearity of the model and the prior stimulus. This is the same for the STC, and thus Equations 4–6 are not independent. This leads to a single form of variance gain modulation, given by Equation 3. However, in a multidimensional model, changing the stimulus mean shifts the nonlinearity in a single direction, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e013" xlink:type="simple"/></inline-formula>, while increasing the variance expands the prior in every direction in the stimulus space. Therefore, the overlap integral can show more diverse behaviors.</p></sec><sec id="s2e"><title>Conductance-Based Models</title><p>We now examine whether the gain modulation behaviors we have described can be captured by a multi-dimensional LN model. We tested this by computing <italic>f-I</italic> curves, spike-triggered averages and the spike-triggered covariance matrices for the noise-driven HH and HHLS models for a range of input statistics. <xref ref-type="fig" rid="pcbi-1000119-g003">Figure 3A, B, and C</xref> show the result of fitting simulation data from the HH (left) and HHLS (right) model to Equations 4, 5, and 6, respectively. The linear relationships are quite clear in <xref ref-type="fig" rid="pcbi-1000119-g003">Figure 3A and 3C</xref> which show the gains with respect to mean and variance. <xref ref-type="fig" rid="pcbi-1000119-g003">Figure 3B</xref> involves the curvature of <italic>f-I</italic> curves, which is more difficult to calculate accurately, and shows larger errors. In every case, goodness of fit is <italic>p</italic>&lt;1.3×10<sup>−6</sup> and <italic>p</italic>&lt;5.8×10<sup>−6</sup> for the HH and HHLS where the upper bounds of <italic>p</italic>-values are given by the case of Equation 5, corresponding to <xref ref-type="fig" rid="pcbi-1000119-g003">Figure 3B</xref>. These results show that intrinsic adaptation of the LN model predicts the form of noise-induced gain modulation for these models.</p><fig id="pcbi-1000119-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000119.g003</object-id><label>Figure 3</label><caption><title>Derivatives of the Firing Rate Curves with Respect to Mean and Variance Related to Quantities Obtained by White Noise Analysis for the Standard HH (Left) and HHLS (Right) Models.</title><p>Each point is calculated from the simulated data with a selected (mean, variance) input parameter pair, as described in the <xref ref-type="sec" rid="s4">Materials and Methods</xref> section, and the gray lines represent our theoretical predictions, Equations 4–6, which hold when the variance dependent change in <italic>f-I</italic> curves is only due to intrinsic adaptation. (A) Gain versus the norm of the STA, as in Equation 4. (B) Gain change versus the spike-triggered covariance term of Equation 5. (C) Change of firing rate with respect to variance versus the function of the STA and spike-triggered covariance given in Equation 6.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.g003" xlink:type="simple"/></fig></sec><sec id="s2f"><title>Gain Rescaling of One-Dimensional Models</title><p>Here we discuss a consequence of intrinsic adaptation for neuronal encoding of mean and variance information for a one-dimensional model. In this case, Equation 3 completely specifies intrinsic adaptation, and therefore we will focus on this case.</p><p>Our first observation is that Equation 3 is invariant under the simultaneous rescaling of the mean and standard deviation, <italic>I</italic><sub>0</sub>→α<italic>I</italic><sub>0</sub>, σ→ασ, where α is an arbitrary positive number. This invariance is preserved if the solution is also a function of only a dimensionless variable <italic>I</italic><sub>0</sub>/σ, which would represent a signal-to-noise ratio if we describe the neuron's input/output function in terms of an <italic>f-I</italic> curve at a fixed noise level σ. Note that this situation is analogous to the Weber–Fechner <xref ref-type="bibr" rid="pcbi.1000119-Weber1">[39]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Fechner1">[40]</xref> and Fitts' law <xref ref-type="bibr" rid="pcbi.1000119-Fitts1">[41]</xref>, which states that perception tends to depend on only dimensionless variables that are invariant under scaling of the absolute magnitude of stimulus <xref ref-type="bibr" rid="pcbi.1000119-Stevens1">[42]</xref>. However, the invariance of Equation 3 under the scaling of a stimulus does not necessarily lead to the invariance of a firing rate solution. By rewriting Equation 2 in terms of the “rescaled” variables, <italic>y</italic> = <italic>x</italic>/σ and μ = <italic>I</italic><sub>0</sub>/σ, we get<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e014" xlink:type="simple"/><label>(7)</label></disp-formula>where <italic>f</italic><sub>0</sub>(<italic>I</italic>) = <italic>P</italic>(spike|<italic>I</italic>ε̅) is an <italic>f-I</italic> curve with no noise. Thus, the scaling of <italic>f</italic>(<italic>I</italic><sub>0</sub>,σ<sup>2</sup>) with standard deviation depends on the boundary condition, <italic>f</italic><sub>0</sub>(<italic>I</italic>), which in principle can be any arbitrary function.</p><p>Nevertheless, in practice, the <italic>f-I</italic> curves of many dynamical neurons are not completely arbitrary but can share a simple scaling property, at least asymptotically. For example, in the QIF and many other neuron models, the <italic>f-I</italic> curve with no noise asymptotically follows a power law <italic>f</italic><sub>0</sub>∼(<italic>I</italic><sub>0</sub>−<italic>I</italic><sub>c</sub>)<sup>1/2</sup> around the rheobase <italic>I</italic><sub>c</sub> <xref ref-type="bibr" rid="pcbi.1000119-Ermentrout1">[34]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Hoppensteadt1">[36]</xref>. In general, if <italic>f</italic><sub>0</sub>(<italic>I</italic>)∝<italic>I</italic><sup>α</sup> asymptotically in such a regime, from Equation 7, the firing rate is asymptotically factorized into a σ dependent and μ = <italic>I</italic><sub>0</sub>/σ dependent part as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e015" xlink:type="simple"/><label>(8)</label></disp-formula>In other words, <italic>I</italic><sub>0</sub>/σ becomes an <italic>intermediate asymptotic</italic> of the <italic>f-I</italic> curves <xref ref-type="bibr" rid="pcbi.1000119-Barenblatt1">[43]</xref>.</p><p>To test to what extent this scaling relationship holds in the models we have considered, we calculated the <italic>rescaled relative gain</italic> of the <italic>f-I</italic> curves, which we define as (σ/<italic>f</italic>) ∂<italic>f</italic>/∂<italic>I</italic><sub>0</sub> = σ ∂ log <italic>f</italic>/∂<italic>I</italic><sub>0</sub>; the rescaled relative gain of Equation 8 depends only on μ = <italic>I</italic><sub>0</sub>/σ, not on σ. Thus, if the rescaling strictly holds, this becomes a single-valued function of the signal-to-noise ratio, <italic>I</italic><sub>0</sub>/σ, regardless of the noise level σ.</p><p>We find evidence for this form of variance rescaling in the QIF, LIF, and HH models. <xref ref-type="fig" rid="pcbi-1000119-g004">Figure 4</xref> shows the rescaled gains evaluated from the simulated data. The QIF and HH case, <xref ref-type="fig" rid="pcbi-1000119-g004">Figure 4B and 4D</xref>, match well with the solution of Equation 3, <xref ref-type="fig" rid="pcbi-1000119-g004">Figure 4A</xref>. In the LIF case, <xref ref-type="fig" rid="pcbi-1000119-g004">Figure 4C</xref>, the relative gain shows deviations at low variance, but it approaches a variance-independent limit at large σ. We also present an analytic account in <xref ref-type="supplementary-material" rid="pcbi.1000119.s001">Text S1</xref>. On the other hand, in <xref ref-type="fig" rid="pcbi-1000119-g004">Figure 4E</xref>, the HHLS model does not exhibit this form of asymptotic scaling at all. The role of the signal-to-noise ratio, <italic>I</italic><sub>0</sub>/σ, in the HHLS model appears to be quite distinct from the other models. In summary, Equation 3 predicts that one-dimensional LN models will have the tendency to decrease gain with increasing noise level. However, if the <italic>f-I</italic> curve of a neuron is power-law-like, the resulting gain modulation will be such that the neuron's sensitivity to mean stimulus change at various noise levels is governed only by the signal-to-noise ratio.</p><fig id="pcbi-1000119-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000119.g004</object-id><label>Figure 4</label><caption><title>Rescaled Relative Gains of Variance-Dependent <italic>f-I</italic> Curves.</title><p>(A) The one-dimensional LN, (B) QIF, and (C) LIF models. The same data as <xref ref-type="fig" rid="pcbi-1000119-g002">Figure 2</xref> are used. (D) The standard HH model from <xref ref-type="fig" rid="pcbi-1000119-g001">Figure 1A and 1B</xref>. (E) The HHLS model from <xref ref-type="fig" rid="pcbi-1000119-g001">Figure 1C and 1D</xref>. Since the HHLS does not have a rheobase, we instead used <italic>I</italic><sub>center</sub> = 20 nA at which the variance-dependent firing rate increase is maximal.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.g004" xlink:type="simple"/></fig></sec></sec><sec id="s3"><title>Discussion</title><p>In this paper, we have obtained analytical relationships between noise-dependent gain modulation of <italic>f-I</italic> curves and properties of the sampled linear/nonlinear model. We have shown that gain control arises as a simple consequence of the nonlinearity of the LN model, even with no changes in any underlying parameters.</p><p>For a system described by an LN model with only one relevant feature, a simple single-parameter diffusion relationship relates the <italic>f-I</italic> curves at different variances, where the role of the diffusion coefficient is taken by the integral of the STA. This form strictly limits the possible forms of gain modulation that may be manifested by such a system. The result qualitatively describes the variance dependent gain modulation of different neuron models such as the LIF, QIF, and standard HH neuron models. Models based on dynamical spike generation, such as QIF, showed better agreement with this result than the LIF model. The QIF model case is a good example of how a nonlinear dynamical system can be mapped onto an LN model description <xref ref-type="bibr" rid="pcbi.1000119-Hong1">[19]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Gerstner1">[44]</xref>. The QIF model has a single dynamical equation whose subthreshold dynamics are captured approximately by a linear kernel, which takes the role of the feature; one can then determine a threshold which acts as a binary decision boundary for spiking. Thus, it is reasonable that the QIF model and the one-dimensional LN model show a similar response pattern to a noisy input. When the system has multiple relevant features, we obtain equations relating the gain with respect to the input mean and the input variance to parameters of the STA and STC. We verified these results using HH neurons displaying two different forms of noise-induced gain control.</p><p>Previous work has related different gain control behaviors to a neuron's function as an integrator or a differentiator <xref ref-type="bibr" rid="pcbi.1000119-Higgs1">[3]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Lundstrom1">[7]</xref>. From an LN model perspective, the neuron's function is defined by specific properties of the filter or filters ε(<italic>t</italic>). An integrating filter would consist of entirely positive weights; for leaky integrators these weights will decay at large negative times. A differentiating filter implements a local subtraction of the stimulus, and so should consist of a bimodal form where the positive weights approximately cancel the negative weights.</p><p>In general, characterizations of neural function by LN model and by <italic>f-I</italic> curves are quite distinct. The <italic>f-I</italic> approach we have discussed here describes the encoding of stationary statistical properties of the stimulus by time-averaged firing rate, while the LN model describes the encoding of specific input fluctuations by single spikes, generally under a particular choice of stimulus statistics. Indeed, the LN characterization can change with the driving stimulus distribution, even, in principle, from an integrator to a differentiator. Thus, a model may, for example, act as a differentiator on short timescales but as an integrator on longer timescales. For systems whose LN approximation varies with mean and variance, the neuron's effective computation changes with stimulus statistics, and so does the information that is represented. One might then ask how the system can decode the represented information. It has been proposed that statistics of the spike train might provide the information required to decode slower-varying stimulus parameters <xref ref-type="bibr" rid="pcbi.1000119-Fairhall2">[22]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Lundstrom2">[45]</xref>. The possibility of distinguishing between responses to different stimulus statistics using the firing rate alone depends on the properties of the <italic>f-I</italic> curves.</p><p>The primary focus of this work is the restricted problem of single neurons responding to driving currents, where the integrated synaptic current in an in vivo-like condition is approximated to be a (filtered) Gaussian white noise <xref ref-type="bibr" rid="pcbi.1000119-Gerstein1">[46]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Rudolph1">[50]</xref>. However, our derivations can apply to arbitrary neural systems driven by white noise inputs, if <italic>f-I</italic> curves are interpreted as tuning functions with respect to the mean stimulus parameter. Given the generality of our results for neural systems, it would be interesting to test our results in cases where firing is driven by an external stimulus. A good candidate would be retinal ganglion cells, which are well-described by LN-type models <xref ref-type="bibr" rid="pcbi.1000119-Meister1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Fairhall1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Keat1">[51]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Pillow1">[53]</xref>, show adaptation to stimulus statistics on multiple timescales <xref ref-type="bibr" rid="pcbi.1000119-Baccus1">[23]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Smirnakis1">[54]</xref> and display a variety of dimensionalities in their feature space <xref ref-type="bibr" rid="pcbi.1000119-Fairhall1">[14]</xref>.</p><p>A limitation of the tests we have performed here is a restriction to the low firing rate regime where spike-triggered reverse correlation captures most of the dependence of firing probability on the stimulus. The effects of interspike interaction can be significant <xref ref-type="bibr" rid="pcbi.1000119-AgerayArcas1">[16]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-AgerayArcas2">[17]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Pillow2">[55]</xref> and models with spike history feedback have been developed to account for this <xref ref-type="bibr" rid="pcbi.1000119-Gerstner1">[44]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Keat1">[51]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Truccolo1">[56]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Paninski2">[57]</xref>. We have not investigated how spike history effects would impact our results.</p><p>Although evidence suggests that gain modulation by noise may be enhanced by slow afterhyperpolarization currents underlying spike frequency adaptation <xref ref-type="bibr" rid="pcbi.1000119-Higgs1">[3]</xref>, these slow currents are not required to generate gain enhancement in simple neuron models <xref ref-type="bibr" rid="pcbi.1000119-Lundstrom1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Hong1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Gaudry1">[25]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Borst1">[29]</xref>. While one may generate diverse types of noise-induced gain modulation only by modifying the mechanism of generating a spike independent of spike history <xref ref-type="bibr" rid="pcbi.1000119-Lundstrom1">[7]</xref>, in realistic situations, slow adaptation currents are present and will affect neural responses over many timescales <xref ref-type="bibr" rid="pcbi.1000119-Schwindt1">[58]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-LaCamera1">[60]</xref>. In principle, it is possible to extend our result to include these effects: <italic>f-I</italic> curves under conditions of spike frequency adaptation have been already discussed <xref ref-type="bibr" rid="pcbi.1000119-Ermentrout4">[61]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-LaCamera2">[63]</xref> and can be compared to LN models with spike history feedback. However, our goal here was to demonstrate the effects that can occur independent of slow adaptation currents and before such currents have acted to shift neuronal coding properties.</p><p>The suggestive form of our result for one-dimensional LN models led us to look for a representation of neuronal output that is invariant under change in the input noise level. Our motivation is based on a simple principle of dimensional analysis: the gains of the <italic>f-I</italic> curves with noise may be asymptotically described by a signal-to-noise ratio, a dimensionless variable depending only on the stimulus itself. We showed that this may occur if the <italic>f-I</italic> curve with no noise obeys asymptotic power-law properties. Such a property has been determined to arise both from the bifurcation patterns of spike generation <xref ref-type="bibr" rid="pcbi.1000119-Izhikevich1">[31]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Ermentrout1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Rinzel1">[35]</xref> and due to spike rate adaptation <xref ref-type="bibr" rid="pcbi.1000119-Ermentrout4">[61]</xref>. This relationship implies that the gain of the firing rate as a function of the mean should scale inversely with the standard deviation. Scaling of the gain of the nonlinear decision function with the stimulus standard deviation has been observed to some degree in a number of neural systems <xref ref-type="bibr" rid="pcbi.1000119-Brenner1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Maravall1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Fairhall2">[22]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Gaudry1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Borst1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1000119-Kim1">[64]</xref>–<xref ref-type="bibr" rid="pcbi.1000119-Ringach1">[67]</xref>. Such scaling guarantees maximal transmission of information <xref ref-type="bibr" rid="pcbi.1000119-Brenner1">[10]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Fairhall2">[22]</xref>. As we and others have proposed, a static model might suffice to explain this phenomenon <xref ref-type="bibr" rid="pcbi.1000119-Gaudry1">[25]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Paninski1">[27]</xref>, although in some cases slow adaptation currents are known to contribute <xref ref-type="bibr" rid="pcbi.1000119-Arganda1">[65]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-DiazQuesada1">[66]</xref>.</p><p>In summary, we have presented theoretically derived relationships between the variance-dependent gain modulation of <italic>f-I</italic> curves and intrinsic adaptation in neural coding. In real neural systems, any type of gain modulation likely results from many different mechanisms, possibly involving long-time scale dynamics. Our results show that observed forms of gain modulation may be a result of a pre-existing static nonlinearity that reacts to changes in the stimulus statistics robustly and almost instantaneously.</p></sec><sec id="s4"><title>Materials and Methods</title><sec id="s4a"><title>Biophysical Models</title><p>We used two single compartmental models with Hodgkin–Huxley (HH) active currents. The first one is an HH model with standard parameters while the second model (HHLS) has a lower Na<sup>+</sup> and higher K<sup>+</sup> maximal conductance. The voltage changes are described by <xref ref-type="bibr" rid="pcbi.1000119-Hodgkin2">[32]</xref><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e016" xlink:type="simple"/></disp-formula>and the activation variables <italic>m</italic>, <italic>n</italic>, and <italic>h</italic> behave according to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e017" xlink:type="simple"/></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e018" xlink:type="simple"/></disp-formula>The voltage <italic>V</italic> is in millivolts (mV).</p><p>For the HH model, the conductance parameters are <italic>g̅</italic><italic><sub>K</sub></italic> = 36 mS/cm<sup>2</sup> and <italic>g̅</italic><italic><sub>Na</sub></italic> = 120 mS/cm<sup>2</sup>. The HHLS model has <italic>g̅</italic><italic><sub>K</sub></italic> = 41 mS/cm<sup>2</sup> and <italic>g̅</italic><italic><sub>Na</sub></italic> = 79 mS/cm<sup>2</sup>. All other parameters are common to both models. The leak conductance is <italic>g̅</italic><italic><sub>L</sub></italic> = 0.3 mS/cm<sup>2</sup> and the membrane capacitance per area <italic>C</italic> is 1 μF/cm<sup>2</sup>. The reversal potentials are <italic>E<sub>L</sub></italic> = −54.3 mV, <italic>E<sub>Na</sub></italic> = 50 mV, and <italic>E<sub>K</sub></italic> = −77 mV. The membrane area is 10<sup>−3</sup> cm<sup>2</sup>, so that a current density of 1 μA/cm<sup>2</sup> corresponds to a current of 1 nA.</p><p>All simulations of these models were done with the NEURON simulation environment <xref ref-type="bibr" rid="pcbi.1000119-Hines1">[68]</xref>. Gaussian white noise currents with various means and variances are generated with an update rate of 5 kHz (d<italic>t</italic> = 0.2 ms) and delivered into the model via current clamp. For the <italic>f-I</italic> curves, we simulated 4 min of input for each mean and variance pair. The whole procedure was repeated five times to estimate the variance of the <italic>f-I</italic> relationship, σ<sub>repeat</sub>.</p><p>We ran another set of simulations for reverse correlation analysis and collected about 100,000 spikes for each stimulus condition. The means and variances of the Gaussian noisy stimuli were chosen such that the mean firing rate did not exceed 10 Hz, and we selected eight means and seven variances for the HH model, and nine means and four variances for the HHLS model.</p></sec><sec id="s4b"><title>Integrate-and-Fire-Type Models</title><p>In addition to the conductance-based model, we investigated the behavior of two heuristic model neurons driven by a noisy current input. Each model consists of a single dynamical equation describing voltage fluctuations of the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e019" xlink:type="simple"/></disp-formula></p><p>The first model is a leaky integrate-and-fire (LIF) model <xref ref-type="bibr" rid="pcbi.1000119-Knight1">[69]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Tuckwell1">[70]</xref>, for which <italic>L</italic>(<italic>V</italic>) = −<italic>g<sub>L</sub></italic>(<italic>V</italic>−<italic>E<sub>L</sub></italic>). We used the parameters <italic>g<sub>L</sub></italic> = 2, <italic>E<sub>L</sub></italic> = 0, and <italic>C</italic> = 1. Since this choice of <italic>L</italic>(<italic>V</italic>) cannot generate a spike, we additionally imposed a spiking threshold <italic>V<sub>th</sub></italic> = 1 and reset voltage <italic>V</italic><sub>reset</sub> = −3.</p><p>The second is a quadratic integrate-and-fire (QIF) model <xref ref-type="bibr" rid="pcbi.1000119-Izhikevich1">[31]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Ermentrout2">[37]</xref>,<xref ref-type="bibr" rid="pcbi.1000119-Ermentrout3">[38]</xref>, for which <italic>L</italic>(<italic>V</italic>) = <italic>g<sub>L</sub></italic>(<italic>V</italic>−<italic>E<sub>L</sub></italic>)(<italic>V</italic>−<italic>V<sub>th</sub></italic>)/Δ<italic>V</italic> where Δ<italic>V</italic> = <italic>V<sub>th</sub></italic>−<italic>E<sub>L</sub></italic>&gt;0. We used <italic>g<sub>L</sub></italic> = 0.5, <italic>E<sub>L</sub></italic> = 0, <italic>V<sub>th</sub></italic> = 0.1, and <italic>C</italic> = 1. In this model, the voltage <italic>V</italic> can increase without bound; such a trajectory is defined to be a spike if it crosses <italic>V</italic><sub>spike</sub> = 5. After spiking, the system is reset to <italic>V</italic><sub>reset</sub> = 0.</p><p>These two models are simulated using a fourth-order Runge–Kutta integration method with an integration time step of d<italic>t</italic> = 0.01. The input current <italic>I</italic>(<italic>t</italic>) was Gaussian white noise, updated at each time step, with a range of means and variances. The <italic>f-I</italic> curves were obtained from 1,000 s of stimulation for each (mean,variance) condition. We then compared the <italic>f-I</italic> curves from these models with the relationship derived in the Results section, Equation 5. A numerical solution of the partial differential equation was obtained using a PDE solver in Mathematica (Wolfram Research, Inc.).</p></sec><sec id="s4c"><title>Linear/Nonlinear Model</title><p>We use the linear/nonlinear (LN) cascade model framework to describe a neuron's input/output relation. We will focus on the dependence of the firing rate of a fixed LN model on the mean and variance of a Gaussian white noise input.</p><p>We will take the driving input to be <italic>I</italic>(<italic>t</italic>) = <italic>I</italic><sub>0</sub>+ξ(<italic>t</italic>) where <italic>I</italic><sub>0</sub> is the mean and ξ(<italic>t</italic>) is a Gaussian white noise with variance σ<sup>2</sup> and zero mean. The linear part of the model selects, by linear filtering, a subset of the possible stimuli probed by <italic>I</italic>(<italic>t</italic>). That subset is expressed as <italic>n</italic> relevant features {ε<sub>μ</sub>(<italic>t</italic>)}, (μ = 1,2,…,<italic>n</italic>). Interpreted as vectors, the components of any stimulus that are relevant to changing the firing rate can be expressed in terms of projections onto these features. The firing rate of the model for a given temporal sequence <italic>I</italic>(<italic>t</italic>) depends only on <bold>s</bold>, the input filtered by the <italic>n</italic> relevant features. Thus the firing rate from the given stimulus depends on the convolution of the input with all <italic>n</italic> features and can be written as <italic>P</italic>(spike|<bold>s</bold> = <italic>I</italic><sub>0</sub><bold>ε̅</bold>+<bold>x</bold>) where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e020" xlink:type="simple"/></disp-formula>Since <italic>I</italic>(<italic>t</italic>) is white noise with stationary statistics, the projections <italic>x</italic><sub>μ</sub> can be taken to be stationary random variables chosen from a Gaussian distribution at each <italic>t</italic>.</p><p>Given the filtered stimulus, a nonlinear decision function <italic>P</italic>(spike|<italic>I</italic><sub>0</sub><bold>ε̅</bold>+<bold>x</bold>) generates the instantaneous time-varying firing rate. For a specified model and stimulus statistics, the mean firing rate <italic>f</italic>(<italic>I</italic><sub>0</sub>,σ<sup>2</sup>) = <italic>P</italic>(spike) is simply<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e021" xlink:type="simple"/><label>(9)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e022" xlink:type="simple"/></disp-formula></p><p>Equation 9 describes an <italic>f-I</italic> curve of the model in the presence of added noise with variance σ<sup>2</sup>. The slope or <italic>gain</italic> of the firing rate with respect to mean or variance can be computed if <italic>P</italic>(spike|<italic>I</italic><sub>0</sub><bold>ε̅</bold>+<bold>x</bold>) is known. However, the gains can be also obtained in terms of the first and second moments of <italic>P</italic>(spike|<italic>I</italic><sub>0</sub><bold>ε̅</bold>+<bold>x</bold>), which can be measured <italic>directly</italic> by reverse correlation analysis.</p></sec><sec id="s4d"><title>Reverse Correlation Analysis</title><p>We used spike-triggered reverse correlation to probe the computation of the model neurons through an LN model. We collected about 100,000 spikes and corresponding ensembles of spike triggered stimulus histories in a 30 ms long time window preceding each spike.</p><p>From the spike-triggered input ensembles, we calculated spike-triggered averages (STAs) and spike-triggered covariances (STCs). The STA is simply the average of the set of stimuli that led to spikes subtracted from the mean of the “prior” stimulus distribution, the distribution of all stimuli independent of spiking output<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e023" xlink:type="simple"/><label>(10)</label></disp-formula>Therefore, one may consider only the noise part of the zero mean stimulus.</p><p>When computing the STC, the prior's covariance is subtracted<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e024" xlink:type="simple"/><label>(11)</label></disp-formula></p></sec><sec id="s4e"><title>Statistical Analysis</title><p>In calculating the slope and curvature of the <italic>f-I</italic> curves, we used 6–10 degree polynomial fitting of the <italic>f-I</italic> curves, where in any single case, the lowest degree was used which provided both a good fit and smoothness. From the fitting procedure, we obtained the standard deviation of the residuals, σ<sub>fit</sub>. This was repeated five times for <italic>f-I</italic> curves computed using different noise samples, and from this we computed σ<sub>repeat</sub>, the standard deviation of each computed slope and curvature. We estimated the total error of our calculation as σ<sub>total</sub> = (σ<sub>repeat</sub><sup>2</sup>+σ<sub>fit</sub><sup>2</sup>)<sup>1/2</sup>. In practice, σ<sub>repeat</sub> was always greater than σ<sub>fit</sub> by an order of magnitude. This σ<sub>total</sub> was used for the error bars in <xref ref-type="fig" rid="pcbi-1000119-g003">Figure 3</xref>.</p><p>To evaluate the goodness of fit in <xref ref-type="fig" rid="pcbi-1000119-g003">Figure 3</xref>, we used the Pearson χ<sup>2</sup> test by using the reduced χ<sup>2</sup> statistic<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e025" xlink:type="simple"/></disp-formula>where <italic>O</italic> and <italic>E</italic> represent the right and left hand sides of Equations 4–6, respectively. From this, the <italic>p</italic>-values are estimated from the cumulative density function of the χ<sup>2</sup> distribution, <italic>Q</italic>(χ<sup>2</sup>/<italic>k</italic>,<italic>k</italic>). The degree of freedom is <italic>k</italic> = 54 and <italic>k</italic> = 34 for the HH and HHLS, respectively.</p></sec><sec id="s4f"><title>Derivation of Equations 4–6</title><p>We first present two key identities: the first one, which depends on the form of <bold>s</bold> having additive mean and noise components, is a change of variables for the gradient of <italic>P</italic>(spike|<bold>x</bold>+<italic>I</italic><sub>0</sub><bold>ε̅</bold>)<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e026" xlink:type="simple"/><label>(12)</label></disp-formula>Secondly, when <italic>x</italic> is a Gaussian random variable with zero mean and variance σ<sup>2</sup>, by using integration by parts in can be seen that any function <italic>F</italic>(<italic>x</italic>) satisfies<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e027" xlink:type="simple"/><label>(13)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e028" xlink:type="simple"/></disp-formula></p><p>Then, we first take derivatives of both sides of Equation 9 (or equivalently Equation 1), by <italic>I</italic><sub>0</sub> and σ<sup>2</sup>, and apply Equations 12 and 13. The first order in <italic>I</italic><sub>0</sub> is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e029" xlink:type="simple"/><label>(14)</label></disp-formula>The second order is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e030" xlink:type="simple"/><label>(15)</label></disp-formula>where δ<sub>μν</sub> is a Kronecker delta symbol. The gain with respect to variance is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e031" xlink:type="simple"/><label>(16)</label></disp-formula></p><p>Now, we show how the right hand sides of Equations 14–16 correspond to the STA and the STC. Given a Gaussian white noise signal ξ(<italic>t</italic>), we can split it as ξ = ξ<sub>∥</sub>+ξ<sub>⊥</sub>, where ξ<sub>∥</sub> belongs to the space spanned by our basis features {ε<sub>μ</sub>}, and therefore relevant to spiking. ξ<sub>⊥</sub> is the orthogonal or irrelevant part. ξ<sub>∥</sub> can be written as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e032" xlink:type="simple"/></disp-formula>Again, <bold>x</bold> is a Gaussian variable from a distribution Equation 9.</p><p>The STA is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e033" xlink:type="simple"/></disp-formula>since ξ<sub>⊥</sub> is irrelevant and does not make any contribution. Here we use Bayes theorem<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e034" xlink:type="simple"/></disp-formula>As in Equation 9, <italic>P</italic>(<bold>s</bold> = <bold>x</bold>+<italic>I</italic><sub>0</sub><bold>ε̅</bold>) = <italic>p</italic>(<bold>x</bold>), and therefore the STA becomes<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e035" xlink:type="simple"/></disp-formula>Comparing this result with Equation 14, we obtain Equation 4.</p><p>A similar calculation for the second order <xref ref-type="bibr" rid="pcbi.1000119-Hong1">[19]</xref> shows<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.e036" xlink:type="simple"/></disp-formula>This result, combined with Equations 15 and 16, leads to Equations 5 and 6, respectively.</p></sec></sec><sec id="s5"><title>Supporting Information</title><supplementary-material id="pcbi.1000119.s001" mimetype="application/msword" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000119.s001" xlink:type="simple"><label>Text S1</label><caption><p>Firing Rate of the LIF Model with Noisy Stimuli.</p><p>(0.09 MB DOC)</p></caption></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="pcbi.1000119-Chance1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chance</surname><given-names>FS</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name><name name-style="western"><surname>Reyes</surname><given-names>AD</given-names></name></person-group>             <year>2002</year>             <article-title>Gain modulation from background synaptic input.</article-title>             <source>Neuron</source>             <volume>35</volume>             <fpage>773</fpage>             <lpage>782</lpage>          </element-citation></ref><ref id="pcbi.1000119-Fellous1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fellous</surname><given-names>JM</given-names></name><name name-style="western"><surname>Rudolph</surname><given-names>M</given-names></name><name name-style="western"><surname>Destexhe</surname><given-names>A</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>2003</year>             <article-title>Synaptic background noise controls the input/output characteristics of single cells in an in vitro model of in vivo activity.</article-title>             <source>Neuroscience</source>             <volume>122</volume>             <fpage>811</fpage>             <lpage>829</lpage>          </element-citation></ref><ref id="pcbi.1000119-Higgs1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Higgs</surname><given-names>MH</given-names></name><name name-style="western"><surname>Slee</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Spain</surname><given-names>WJ</given-names></name></person-group>             <year>2006</year>             <article-title>Diversity of gain modulation by noise in neocortical neurons: regulation by the slow afterhyperpolarization conductance.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>8787</fpage>             <lpage>8799</lpage>          </element-citation></ref><ref id="pcbi.1000119-Arsiero1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Arsiero</surname><given-names>M</given-names></name><name name-style="western"><surname>Lüscher</surname><given-names>HR</given-names></name><name name-style="western"><surname>Lundstrom</surname><given-names>BN</given-names></name><name name-style="western"><surname>Giugliano</surname><given-names>M</given-names></name></person-group>             <year>2007</year>             <article-title>The impact of input fluctuations on the frequency–current relationships of layer 5 pyramidal neurons in the rat medial prefrontal cortex.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>3274</fpage>             <lpage>3284</lpage>          </element-citation></ref><ref id="pcbi.1000119-Prescott1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Prescott</surname><given-names>SA</given-names></name><name name-style="western"><surname>Koninck</surname><given-names>YD</given-names></name></person-group>             <year>2003</year>             <article-title>Gain control of firing rate by shunting inhibition: roles of synaptic noise and dendritic saturation.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>100</volume>             <fpage>2076</fpage>             <lpage>2081</lpage>          </element-citation></ref><ref id="pcbi.1000119-Prescott2"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Prescott</surname><given-names>SA</given-names></name><name name-style="western"><surname>Ratté</surname><given-names>S</given-names></name><name name-style="western"><surname>De Koninck</surname><given-names>Y</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>2006</year>             <article-title>Nonlinear interaction between shunting and adaptation controls a switch between integration and coincidence detection in pyramidal neurons.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>9084</fpage>             <lpage>9097</lpage>          </element-citation></ref><ref id="pcbi.1000119-Lundstrom1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lundstrom</surname><given-names>BN</given-names></name><name name-style="western"><surname>Hong</surname><given-names>S</given-names></name><name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name></person-group>             <year>2008</year>             <article-title>Two computational regimes of a single-compartment neuron separated by a planar boundary in conductance space.</article-title>             <source>Neural Comput</source>             <volume>20</volume>             <fpage>1239</fpage>             <lpage>1260</lpage>          </element-citation></ref><ref id="pcbi.1000119-Victor1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Victor</surname><given-names>J</given-names></name><name name-style="western"><surname>Shapley</surname><given-names>R</given-names></name></person-group>             <year>1980</year>             <article-title>A method of nonlinear analysis in the frequency domain.</article-title>             <source>Biophys J</source>             <volume>29</volume>             <fpage>459</fpage>             <lpage>483</lpage>          </element-citation></ref><ref id="pcbi.1000119-Meister1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Meister</surname><given-names>M</given-names></name><name name-style="western"><surname>Berry</surname><given-names>MJ</given-names><suffix>II</suffix></name></person-group>             <year>1999</year>             <article-title>The neural code of the retina.</article-title>             <source>Neuron</source>             <volume>22</volume>             <fpage>435</fpage>             <lpage>450</lpage>          </element-citation></ref><ref id="pcbi.1000119-Brenner1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brenner</surname><given-names>N</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name><name name-style="western"><surname>de Ruyter van Steveninck</surname><given-names>R</given-names></name></person-group>             <year>2000</year>             <article-title>Adaptive rescaling maximizes information transmission.</article-title>             <source>Neuron</source>             <volume>26</volume>             <fpage>695</fpage>             <lpage>702</lpage>          </element-citation></ref><ref id="pcbi.1000119-Simoncelli1"><label>11</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name><name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name><name name-style="western"><surname>Pillow</surname><given-names>J</given-names></name><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name></person-group>             <year>2004</year>             <article-title>Characterization of neural responses with stochastic stimuli.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Gazzaniga</surname><given-names>M</given-names></name></person-group>             <source>The Cognitive Neurosciences. 3rd edition</source>             <publisher-loc>Cambridge (Massachusetts)</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref><ref id="pcbi.1000119-Rust1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rust</surname><given-names>NC</given-names></name><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name><name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group>             <year>2005</year>             <article-title>Spatiotemporal elements of macaque V1 receptive fields.</article-title>             <source>Neuron</source>             <volume>46</volume>             <fpage>945</fpage>             <lpage>956</lpage>          </element-citation></ref><ref id="pcbi.1000119-Stanley1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stanley</surname><given-names>GB</given-names></name><name name-style="western"><surname>Lei</surname><given-names>FF</given-names></name><name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name></person-group>             <year>1999</year>             <article-title>Reconstruction of natural scenes from ensemble responses in the lateral geniculate nucleus.</article-title>             <source>J Neurosci</source>             <volume>19</volume>             <fpage>8036</fpage>             <lpage>8042</lpage>          </element-citation></ref><ref id="pcbi.1000119-Fairhall1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name><name name-style="western"><surname>Burlingame</surname><given-names>CA</given-names></name><name name-style="western"><surname>Narasimhan</surname><given-names>R</given-names></name><name name-style="western"><surname>Harris</surname><given-names>RA</given-names></name><name name-style="western"><surname>Puchalla</surname><given-names>JL</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>Selectivity for multiple stimulus features in retinal ganglion cells.</article-title>             <source>J Neurophysiol</source>             <volume>96</volume>             <fpage>2724</fpage>             <lpage>2738</lpage>          </element-citation></ref><ref id="pcbi.1000119-Maravall1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Maravall</surname><given-names>M</given-names></name><name name-style="western"><surname>Petersen</surname><given-names>RS</given-names></name><name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name><name name-style="western"><surname>Arabzadeh</surname><given-names>E</given-names></name><name name-style="western"><surname>Diamond</surname><given-names>ME</given-names></name></person-group>             <year>2007</year>             <article-title>Shifts in coding properties and maintenance of information transmission during adaptation in barrel cortex.</article-title>             <source>PLoS Biol</source>             <volume>5</volume>             <fpage>e19</fpage>             <comment>doi:10.1371/journal.pbio.0050019</comment>          </element-citation></ref><ref id="pcbi.1000119-AgerayArcas1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Agüera y Arcas</surname><given-names>B</given-names></name><name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name></person-group>             <year>2003</year>             <article-title>What causes a neuron to spike?</article-title>             <source>Neural Comput</source>             <volume>15</volume>             <fpage>1715</fpage>             <lpage>1749</lpage>          </element-citation></ref><ref id="pcbi.1000119-AgerayArcas2"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Agüera y Arcas</surname><given-names>B</given-names></name><name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name></person-group>             <year>2003</year>             <article-title>Computation in a single neuron: Hodgkin and Huxley revisited.</article-title>             <source>Neural Comput</source>             <volume>15</volume>             <fpage>1789</fpage>             <lpage>1807</lpage>          </element-citation></ref><ref id="pcbi.1000119-Slee1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Slee</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Higgs</surname><given-names>MH</given-names></name><name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name><name name-style="western"><surname>Spain</surname><given-names>WJ</given-names></name></person-group>             <year>2005</year>             <article-title>Two-dimensional time coding in the auditory brainstem.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>9978</fpage>             <lpage>9988</lpage>          </element-citation></ref><ref id="pcbi.1000119-Hong1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hong</surname><given-names>S</given-names></name><name name-style="western"><surname>Agüera y Arcas</surname><given-names>B</given-names></name><name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name></person-group>             <year>2007</year>             <article-title>Single neuron computation: from dynamical system to feature detector.</article-title>             <source>Neural Comput</source>             <volume>19</volume>             <fpage>3133</fpage>             <lpage>3172</lpage>          </element-citation></ref><ref id="pcbi.1000119-Atick1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name></person-group>             <year>1992</year>             <article-title>Could information theory provide an ecological theory of sensory processing?</article-title>             <source>Network (Bristol, England)</source>             <volume>3</volume>             <fpage>213</fpage>             <lpage>251</lpage>          </element-citation></ref><ref id="pcbi.1000119-Theunissen1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name><name name-style="western"><surname>Doupe</surname><given-names>AJ</given-names></name></person-group>             <year>2000</year>             <article-title>Spectral-temporal receptive fields of nonlinear auditory neurons obtained using natural sounds.</article-title>             <source>J Neurosci</source>             <volume>20</volume>             <fpage>2315</fpage>             <lpage>2331</lpage>          </element-citation></ref><ref id="pcbi.1000119-Fairhall2"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fairhall</surname><given-names>A</given-names></name><name name-style="western"><surname>Lewen</surname><given-names>G</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name><name name-style="western"><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name></person-group>             <year>2001</year>             <article-title>Efficiency and ambiguity in an adaptive neural code.</article-title>             <source>Nature</source>             <volume>412</volume>             <fpage>787</fpage>             <lpage>792</lpage>          </element-citation></ref><ref id="pcbi.1000119-Baccus1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Baccus</surname><given-names>SA</given-names></name><name name-style="western"><surname>Meister</surname><given-names>M</given-names></name></person-group>             <year>2002</year>             <article-title>Fast and slow contrast adaptation in retinal circuitry.</article-title>             <source>Neuron</source>             <volume>36</volume>             <fpage>909</fpage>             <lpage>919</lpage>          </element-citation></ref><ref id="pcbi.1000119-Nagel1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nagel</surname><given-names>KI</given-names></name><name name-style="western"><surname>Doupe</surname><given-names>AJ</given-names></name></person-group>             <year>2006</year>             <article-title>Temporal processing and adaptation in the songbird auditory forebrain.</article-title>             <source>Neuron</source>             <volume>51</volume>             <fpage>845</fpage>             <lpage>859</lpage>          </element-citation></ref><ref id="pcbi.1000119-Gaudry1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gaudry</surname><given-names>KS</given-names></name><name name-style="western"><surname>Reinagel</surname><given-names>P</given-names></name></person-group>             <year>2007</year>             <article-title>Benefits of contrast normalization demonstrated in neurons and model cells.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>8071</fpage>             <lpage>8079</lpage>          </element-citation></ref><ref id="pcbi.1000119-Rudd1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rudd</surname><given-names>ME</given-names></name><name name-style="western"><surname>Brown</surname><given-names>LG</given-names></name></person-group>             <year>1997</year>             <article-title>Noise adaptation in integrate-and-fire neurons.</article-title>             <source>Neural Comput</source>             <volume>9</volume>             <fpage>1047</fpage>             <lpage>1069</lpage>          </element-citation></ref><ref id="pcbi.1000119-Paninski1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name><name name-style="western"><surname>Lau</surname><given-names>B</given-names></name><name name-style="western"><surname>Reyes</surname><given-names>AD</given-names></name></person-group>             <year>2003</year>             <article-title>Noise-driven adaptation: in vitro and mathematical analysis.</article-title>             <source>Neurocomputing</source>             <volume>52</volume>             <fpage>877</fpage>             <lpage>883</lpage>          </element-citation></ref><ref id="pcbi.1000119-Yu1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Lee</surname><given-names>TS</given-names></name></person-group>             <year>2003</year>             <article-title>Dynamical mechanisms underlying contrast gain control in single neurons.</article-title>             <source>Phys Rev E</source>             <volume>68</volume>             <fpage>011901</fpage>          </element-citation></ref><ref id="pcbi.1000119-Borst1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Borst</surname><given-names>A</given-names></name><name name-style="western"><surname>Flanagin</surname><given-names>VL</given-names></name><name name-style="western"><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group>             <year>2005</year>             <article-title>Adaptation without parameter change: dynamic gain control in motion detection.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>102</volume>             <fpage>6172</fpage>             <lpage>6176</lpage>          </element-citation></ref><ref id="pcbi.1000119-Hodgkin1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hodgkin</surname><given-names>AL</given-names></name></person-group>             <year>1948</year>             <article-title>The local electric changes associated with repetitive action in a non-medullated axon.</article-title>             <source>J Physiol</source>             <volume>107</volume>             <fpage>165</fpage>             <lpage>181</lpage>          </element-citation></ref><ref id="pcbi.1000119-Izhikevich1"><label>31</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Izhikevich</surname><given-names>EM</given-names></name></person-group>             <year>2006</year>             <source>Dynamical Systems in Neuroscience: The Geometry of Excitability and Bursting</source>             <publisher-loc>Cambridge (Massachusetts)</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref><ref id="pcbi.1000119-Hodgkin2"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hodgkin</surname><given-names>AL</given-names></name><name name-style="western"><surname>Huxley</surname><given-names>AF</given-names></name></person-group>             <year>1952</year>             <article-title>A quantitative description of membrane current and its application to conduction and excitation in nerve.</article-title>             <source>J Physiol</source>             <volume>463</volume>             <fpage>391</fpage>             <lpage>407</lpage>          </element-citation></ref><ref id="pcbi.1000119-Spekreijse1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Spekreijse</surname><given-names>H</given-names></name><name name-style="western"><surname>Reits</surname><given-names>D</given-names></name></person-group>             <year>1982</year>             <article-title>Sequential analysis of the visual evoked potential system in man: nonlinear analysis of a sandwich system.</article-title>             <source>Ann N Y Acad Sci</source>             <volume>388</volume>             <fpage>72</fpage>             <lpage>97</lpage>          </element-citation></ref><ref id="pcbi.1000119-Ermentrout1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ermentrout</surname><given-names>GB</given-names></name></person-group>             <year>1994</year>             <article-title>Reduction of conductance-based models with slow synapses to neural nets.</article-title>             <source>Neural Comput</source>             <volume>6</volume>             <fpage>679</fpage>             <lpage>695</lpage>          </element-citation></ref><ref id="pcbi.1000119-Rinzel1"><label>35</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rinzel</surname><given-names>JM</given-names></name><name name-style="western"><surname>Ermentrout</surname><given-names>GB</given-names></name></person-group>             <year>1989</year>             <article-title>Analysis of neuronal excitability.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Koch</surname><given-names>C</given-names></name><name name-style="western"><surname>Segev</surname><given-names>I</given-names></name></person-group>             <source>Methods in Neuronal Modeling: From Synapses to Networks</source>             <publisher-loc>Cambridge (Massachusetts)</publisher-loc>             <publisher-name>MIT Press</publisher-name>             <fpage>135</fpage>             <lpage>170</lpage>          </element-citation></ref><ref id="pcbi.1000119-Hoppensteadt1"><label>36</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hoppensteadt</surname><given-names>F</given-names></name><name name-style="western"><surname>Izhikevich</surname><given-names>EM</given-names></name></person-group>             <year>1997</year>             <source>Weakly Connected Neural Nets</source>             <publisher-loc>Berlin</publisher-loc>             <publisher-name>Springer-Verlag</publisher-name>          </element-citation></ref><ref id="pcbi.1000119-Ermentrout2"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ermentrout</surname><given-names>GB</given-names></name><name name-style="western"><surname>Kopell</surname><given-names>N</given-names></name></person-group>             <year>1986</year>             <article-title>Parabolic bursting in an excitable system coupled with a slow oscillation.</article-title>             <source>SIAM J Appl Math</source>             <volume>4</volume>             <fpage>233</fpage>             <lpage>253</lpage>          </element-citation></ref><ref id="pcbi.1000119-Ermentrout3"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ermentrout</surname><given-names>B</given-names></name></person-group>             <year>1996</year>             <article-title>Type I membranes, phase resetting curves, and synchrony.</article-title>             <source>Neural Comput</source>             <volume>8</volume>             <fpage>979</fpage>             <lpage>1001</lpage>          </element-citation></ref><ref id="pcbi.1000119-Weber1"><label>39</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Weber</surname><given-names>EH</given-names></name></person-group>             <year>1834</year>             <source>De Pulsu, Resorptione, Auditu et Tactu. Annotiones Anatomicae et Physiologicae</source>             <publisher-loc>Lipsiae</publisher-loc>             <publisher-name>Koehler</publisher-name>          </element-citation></ref><ref id="pcbi.1000119-Fechner1"><label>40</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fechner</surname><given-names>G</given-names></name></person-group>             <year>1966</year>             <source>Elements of Psychophysics</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Holt, Rinehart and Winston</publisher-name>          </element-citation></ref><ref id="pcbi.1000119-Fitts1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fitts</surname><given-names>PM</given-names></name></person-group>             <year>1954</year>             <article-title>The information capacity of the human motor system in controlling the amplitude of movement.</article-title>             <source>J Exp Psychol</source>             <volume>47</volume>             <fpage>381</fpage>             <lpage>391</lpage>          </element-citation></ref><ref id="pcbi.1000119-Stevens1"><label>42</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stevens</surname><given-names>SS</given-names></name></person-group>             <year>1986</year>             <source>Psychophysics: Introduction to Its Perceptual, Neural, and Social Prospects</source>             <publisher-loc>Piscataway (New Jersey)</publisher-loc>             <publisher-name>Transaction Publishers</publisher-name>          </element-citation></ref><ref id="pcbi.1000119-Barenblatt1"><label>43</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barenblatt</surname><given-names>GI</given-names></name></person-group>             <year>2003</year>             <source>Scaling</source>             <publisher-loc>Cambridge, UK</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref><ref id="pcbi.1000119-Gerstner1"><label>44</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name><name name-style="western"><surname>Kistler</surname><given-names>W</given-names></name></person-group>             <year>2002</year>             <source>Spiking Neuron Models: Single Neurons, Populations, Plasticity</source>             <publisher-loc>Cambridge, UK</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref><ref id="pcbi.1000119-Lundstrom2"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lundstrom</surname><given-names>BN</given-names></name><name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name></person-group>             <year>2006</year>             <article-title>Decoding stimulus variance from a distributional neural code of interspike intervals.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>9030</fpage>             <lpage>9037</lpage>          </element-citation></ref><ref id="pcbi.1000119-Gerstein1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gerstein</surname><given-names>GL</given-names></name><name name-style="western"><surname>Mandelbrot</surname><given-names>B</given-names></name></person-group>             <year>1964</year>             <article-title>Random walk models for the spike activity of a single neuron.</article-title>             <source>Biophys J</source>             <volume>4</volume>             <fpage>41</fpage>             <lpage>68</lpage>          </element-citation></ref><ref id="pcbi.1000119-Bryant1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bryant</surname><given-names>HL</given-names></name><name name-style="western"><surname>Segundo</surname><given-names>JP</given-names></name></person-group>             <year>1976</year>             <article-title>Spike initiation by transmembrane current: a white-noise analysis.</article-title>             <source>J Physiol</source>             <volume>260</volume>             <fpage>279</fpage>             <lpage>314</lpage>          </element-citation></ref><ref id="pcbi.1000119-Mainen1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mainen</surname><given-names>ZF</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group>             <year>1995</year>             <article-title>Reliability of spike timing in neocortical neurons.</article-title>             <source>Science</source>             <volume>268</volume>             <fpage>1503</fpage>             <lpage>1506</lpage>          </element-citation></ref><ref id="pcbi.1000119-Destexhe1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Destexhe</surname><given-names>A</given-names></name><name name-style="western"><surname>Paré</surname><given-names>D</given-names></name></person-group>             <year>1999</year>             <article-title>Impact of network activity on the integrative properties of neocortical pyramidal neurons in vivo.</article-title>             <source>J Neurophysiol</source>             <volume>81</volume>             <fpage>1531</fpage>             <lpage>1547</lpage>          </element-citation></ref><ref id="pcbi.1000119-Rudolph1"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rudolph</surname><given-names>M</given-names></name><name name-style="western"><surname>Destexhe</surname><given-names>A</given-names></name></person-group>             <year>2003</year>             <article-title>Characterization of subthreshold voltage fluctuations in neuronal membranes.</article-title>             <source>Neural Comput</source>             <volume>15</volume>             <fpage>2577</fpage>             <lpage>2618</lpage>          </element-citation></ref><ref id="pcbi.1000119-Keat1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Keat</surname><given-names>J</given-names></name><name name-style="western"><surname>Reinagel</surname><given-names>P</given-names></name><name name-style="western"><surname>Reid</surname><given-names>RC</given-names></name><name name-style="western"><surname>Meister</surname><given-names>M</given-names></name></person-group>             <year>2001</year>             <article-title>Predicting every spike: a model for the responses of visual neurons.</article-title>             <source>Neuron</source>             <volume>30</volume>             <fpage>803</fpage>             <lpage>817</lpage>          </element-citation></ref><ref id="pcbi.1000119-Chichilnisky1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group>             <year>2001</year>             <article-title>A simple white noise analysis of neuronal light responses.</article-title>             <source>Network (Bristol, England)</source>             <volume>12</volume>             <fpage>199</fpage>             <lpage>213</lpage>          </element-citation></ref><ref id="pcbi.1000119-Pillow1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pillow</surname><given-names>JW</given-names></name><name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name><name name-style="western"><surname>Uzzell</surname><given-names>VJ</given-names></name><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name><name name-style="western"><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group>             <year>2005</year>             <article-title>Prediction and decoding of retinal ganglion cell responses with a probabilistic spiking model.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>11003</fpage>             <lpage>11013</lpage>          </element-citation></ref><ref id="pcbi.1000119-Smirnakis1"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smirnakis</surname><given-names>SM</given-names></name><name name-style="western"><surname>Berry</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Warland</surname><given-names>DK</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name><name name-style="western"><surname>Meister</surname><given-names>M</given-names></name></person-group>             <year>1997</year>             <article-title>Adaptation of retinal processing to image contrast and spatial scale.</article-title>             <source>Nature</source>             <volume>386</volume>             <fpage>69</fpage>             <lpage>73</lpage>          </element-citation></ref><ref id="pcbi.1000119-Pillow2"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pillow</surname><given-names>JW</given-names></name><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group>             <year>2003</year>             <article-title>Biases in white noise analysis due to non-Poisson spike generation.</article-title>             <source>Neurocomputing</source>             <volume>52–54</volume>             <fpage>109</fpage>             <lpage>115</lpage>          </element-citation></ref><ref id="pcbi.1000119-Truccolo1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Truccolo</surname><given-names>W</given-names></name><name name-style="western"><surname>Eden</surname><given-names>UT</given-names></name><name name-style="western"><surname>Fellows</surname><given-names>MR</given-names></name><name name-style="western"><surname>Donoghue</surname><given-names>JP</given-names></name><name name-style="western"><surname>Brown</surname><given-names>EN</given-names></name></person-group>             <year>2005</year>             <article-title>A point process framework for relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects.</article-title>             <source>J Neurophysiol</source>             <volume>93</volume>             <fpage>1074</fpage>             <lpage>1089</lpage>          </element-citation></ref><ref id="pcbi.1000119-Paninski2"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name><name name-style="western"><surname>Pillow</surname><given-names>J</given-names></name><name name-style="western"><surname>Lewi</surname><given-names>J</given-names></name></person-group>             <year>2006</year>             <article-title>Statistical models for neural encoding, decoding, and optimal stimulus design.</article-title>             <source>Prog Brain Res</source>             <volume>165</volume>             <fpage>493</fpage>             <lpage>507</lpage>          </element-citation></ref><ref id="pcbi.1000119-Schwindt1"><label>58</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schwindt</surname><given-names>PC</given-names></name><name name-style="western"><surname>Spain</surname><given-names>WJ</given-names></name><name name-style="western"><surname>Foehring</surname><given-names>RC</given-names></name><name name-style="western"><surname>Stafstrom</surname><given-names>CE</given-names></name><name name-style="western"><surname>Chubb</surname><given-names>MC</given-names></name><etal/></person-group>             <year>1988</year>             <article-title>Multiple potassium conductances and their functions in neurons from cat sensorimotor cortex in vitro.</article-title>             <source>J Neurophysiol</source>             <volume>59</volume>             <fpage>424</fpage>             <lpage>449</lpage>          </element-citation></ref><ref id="pcbi.1000119-Spain1"><label>59</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Spain</surname><given-names>WJ</given-names></name><name name-style="western"><surname>Schwindt</surname><given-names>PC</given-names></name><name name-style="western"><surname>Crill</surname><given-names>WE</given-names></name></person-group>             <year>1991</year>             <article-title>Two transient potassium currents in layer V pyramidal neurones from cat sensorimotor cortex.</article-title>             <source>J Physiol</source>             <volume>434</volume>             <fpage>591</fpage>             <lpage>607</lpage>          </element-citation></ref><ref id="pcbi.1000119-LaCamera1"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>La Camera</surname><given-names>G</given-names></name><name name-style="western"><surname>Rauch</surname><given-names>A</given-names></name><name name-style="western"><surname>Thurbon</surname><given-names>D</given-names></name><name name-style="western"><surname>Lüscher</surname><given-names>HR</given-names></name><name name-style="western"><surname>Senn</surname><given-names>W</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>Multiple time scales of temporal response in pyramidal and fast spiking cortical neurons.</article-title>             <source>J Neurophysiol</source>             <volume>96</volume>             <fpage>3448</fpage>             <lpage>3464</lpage>          </element-citation></ref><ref id="pcbi.1000119-Ermentrout4"><label>61</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ermentrout</surname><given-names>B</given-names></name></person-group>             <year>1998</year>             <article-title>Linearization of F-I curves by adaptation.</article-title>             <source>Neural Comput</source>             <volume>10</volume>             <fpage>1721</fpage>             <lpage>1729</lpage>          </element-citation></ref><ref id="pcbi.1000119-Benda1"><label>62</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Benda</surname><given-names>J</given-names></name><name name-style="western"><surname>Herz</surname><given-names>AVM</given-names></name></person-group>             <year>2003</year>             <article-title>A universal model for spike-frequency adaptation.</article-title>             <source>Neural Comput</source>             <volume>15</volume>             <fpage>2523</fpage>             <lpage>2564</lpage>          </element-citation></ref><ref id="pcbi.1000119-LaCamera2"><label>63</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>La Camera</surname><given-names>G</given-names></name><name name-style="western"><surname>Rauch</surname><given-names>A</given-names></name><name name-style="western"><surname>Lüscher</surname><given-names>HR</given-names></name><name name-style="western"><surname>Senn</surname><given-names>W</given-names></name><name name-style="western"><surname>Fusi</surname><given-names>S</given-names></name></person-group>             <year>2004</year>             <article-title>Minimal models of adapted neuronal response to in vivo-like input currents.</article-title>             <source>Neural Comput</source>             <volume>16</volume>             <fpage>2101</fpage>             <lpage>2124</lpage>          </element-citation></ref><ref id="pcbi.1000119-Kim1"><label>64</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kim</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name></person-group>             <year>2001</year>             <article-title>Temporal contrast adaptation in the input and output signals of salamander retinal ganglion cells.</article-title>             <source>J Neurosci</source>             <volume>21</volume>             <fpage>287</fpage>             <lpage>299</lpage>          </element-citation></ref><ref id="pcbi.1000119-Arganda1"><label>65</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Arganda</surname><given-names>S</given-names></name><name name-style="western"><surname>Guantes</surname><given-names>R</given-names></name><name name-style="western"><surname>de Polavieja</surname><given-names>GG</given-names></name></person-group>             <year>2007</year>             <article-title>Sodium pumps adapt spike bursting to stimulus statistics.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>1467</fpage>             <lpage>1473</lpage>          </element-citation></ref><ref id="pcbi.1000119-DiazQuesada1"><label>66</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Diaz-Quesada</surname><given-names>M</given-names></name><name name-style="western"><surname>Maravall</surname><given-names>M</given-names></name></person-group>             <year>2008</year>             <article-title>Intrinsic mechanisms for adaptive gain rescaling in barrel cortex.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>696</fpage>             <lpage>710</lpage>          </element-citation></ref><ref id="pcbi.1000119-Ringach1"><label>67</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ringach</surname><given-names>DL</given-names></name><name name-style="western"><surname>Malone</surname><given-names>BJ</given-names></name></person-group>             <year>2007</year>             <article-title>The operating point of the cortex: neurons as large deviation detectors.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>7673</fpage>             <lpage>7683</lpage>          </element-citation></ref><ref id="pcbi.1000119-Hines1"><label>68</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hines</surname><given-names>ML</given-names></name><name name-style="western"><surname>Carnevale</surname><given-names>NT</given-names></name></person-group>             <year>1997</year>             <article-title>The NEURON simulation environment.</article-title>             <source>Neural Comput</source>             <volume>9</volume>             <fpage>1179</fpage>             <lpage>1209</lpage>          </element-citation></ref><ref id="pcbi.1000119-Knight1"><label>69</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Knight</surname><given-names>BW</given-names></name></person-group>             <year>1972</year>             <article-title>Dynamics of encoding in a population of neurons.</article-title>             <source>J Gen Physiol</source>             <volume>59</volume>             <fpage>734</fpage>          </element-citation></ref><ref id="pcbi.1000119-Tuckwell1"><label>70</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tuckwell</surname><given-names>HC</given-names></name></person-group>             <year>1988</year>             <source>Introduction to Theoretical Neurobiology</source>             <publisher-loc>Cambridge, UK</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref></ref-list></back></article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PBIOLOGY-D-12-00836</article-id><article-id pub-id-type="doi">10.1371/journal.pbio.1001372</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Essay</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
        </subj-group>
      </article-categories><title-group><article-title>Musical Melody and Speech Intonation: Singing a Different Tune</article-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Zatorre</surname>
            <given-names>Robert J.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Baum</surname>
            <given-names>Shari R.</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1">
        <label>1</label>
        <addr-line>Montreal Neurological Institute, McGill University, Montreal, Quebec, Canada</addr-line>
      </aff><aff id="aff2">
        <label>2</label>
        <addr-line>Centre for Research on Brain, Language &amp; Music, McGill University, Montreal, Quebec, Canada</addr-line>
      </aff><aff id="aff3">
        <label>3</label>
        <addr-line>School of Communication Sciences and Disorders, McGill University, Montreal, Quebec, Canada</addr-line>
      </aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">robert.zatorre@mcgill.ca</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
      </author-notes><pub-date pub-type="collection">
        <month>7</month>
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>31</day>
        <month>7</month>
        <year>2012</year>
      </pub-date><volume>10</volume><issue>7</issue><elocation-id>e1001372</elocation-id><permissions>
        
        <copyright-holder>Zatorre, Baum</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions><abstract>
        <p>Music and speech are often cited as characteristically human forms of communication. Both share the features of hierarchical structure, complex sound systems, and sensorimotor sequencing demands, and both are used to convey and influence emotions, among other functions <xref ref-type="bibr" rid="pbio.1001372-Patel1">[1]</xref>. Both music and speech also prominently use acoustical frequency modulations, perceived as variations in pitch, as part of their communicative repertoire. Given these similarities, and the fact that pitch perception and production involve the same peripheral transduction system (cochlea) and the same production mechanism (vocal tract), it might be natural to assume that pitch processing in speech and music would also depend on the same underlying cognitive and neural mechanisms. In this essay we argue that the processing of pitch information differs significantly for speech and music; specifically, we suggest that there are two pitch-related processing systems, one for more coarse-grained, approximate analysis and one for more fine-grained accurate representation, and that the latter is unique to music. More broadly, this dissociation offers clues about the interface between sensory and motor systems, and highlights the idea that multiple processing streams are a ubiquitous feature of neuro-cognitive architectures.</p>
      </abstract><abstract abstract-type="toc">
        <p>Pitch changes are an integral part of both spoken language and song. Despite sharing some of the same psychological and neural mechanisms, the authors conclude there are fundamental differences between them.</p>
      </abstract><funding-group>
        <funding-statement>The authors received no specific funding for this work.</funding-statement>
      </funding-group><counts>
        <page-count count="6"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title/>
      <p>Whether you speak or sing, your vocal tract modulates the pitch of your voice. But to what extent do the mechanisms for producing and perceiving pitch in speech differ from those enlisted in musical contexts? Here we discuss the relevant evidence from psychology and neuroscience. We propose that although speaking and singing involve a substantial sharing of resources, musical pitch requires more accurate encoding and reproduction of pitch relationships than does speech.</p>
    </sec>
    <sec id="s2">
      <title>Similarities in the Use of Pitch in Music and Speech</title>
      <p>The importance of pitch for melodic processing needs little justification; it is hard to imagine a musical system that does not include more than a single pitch (Antonio Carlos Jobim's “One-Note Samba” notwithstanding). Things are more complicated in the case of speech, where pitch variation forms part of a more complex set of modulations known as prosody. Prosody refers to the set of speech parameters that generally apply across individual speech sounds (i.e., at the level of the syllable, phrase, or sentence), including intonation (fundamental frequency, corresponding to pitch variations across a sentence), stress, and rhythm. Prosody is particularly useful in various communicative functions of language, including distinguishing word meanings in tone languages (e.g., Mandarin and Thai), disambiguating sentence structures (e.g., distinguishing questions from statements), highlighting or emphasizing elements in a sentence, and signaling emotion (including irony and sarcasm). Whereas all of the prosodic parameters contribute in varying ways to these functions, for the purpose of the present discussion, we will concentrate on the most evident parallel in music and speech—the processing of melody and sentence-level intonation, or pitch.</p>
      <p>Both speech and music production rely on the ability to control the tension on the vocal cords, which (in combination with transglottal air pressure) results in modulations of the vocal fundamental frequency (<xref ref-type="fig" rid="pbio-1001372-g001">Figure 1</xref>). Recent acoustical analyses suggest that the probability distribution of the amplitudes of harmonics present in human speech can be used to predict the structure of musical scales, in terms of the pitch intervals that are most commonly used across cultures <xref ref-type="bibr" rid="pbio.1001372-Ross1">[2]</xref>. These data can also lead to predictions about consonance judgments of pitches drawn from these scales <xref ref-type="bibr" rid="pbio.1001372-Schwartz1">[3]</xref>. There may therefore be a close connection between vocalizations and the tonal structure of musical scales, at least in terms of origins, which in turn implies a close connection between production and perception of both music and speech.</p>
      <fig id="pbio-1001372-g001" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.1001372.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Acoustical representations of speech and song.</title>
          <p>The top panels show the waveforms (amplitude as a function of time) of 2-s excerpts of samples of spoken and sung speech, respectively. The bottom panels show spectrograms (frequency as a function of time) of the same sound samples; intensity is coded by a color scale in this representation. Note the prominent fundamental frequency and harmonics (horizontal lines) present in the sung speech.</p>
        </caption>
        <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.g001" xlink:type="simple"/>
      </fig>
    </sec>
    <sec id="s3">
      <title>Differences in the Use of Pitch between Music and Speech</title>
      <p>Despite these fundamental similarities between the use of pitch in speech and in music, closer inspection reveals some critical differences between the two domains. Although under some unusual conditions spoken speech may be perceived as sung <xref ref-type="bibr" rid="pbio.1001372-Deutsch1">[4]</xref>, the two are rarely confused. One reason that song and speech are clearly different is that pitch variations in melodies are mostly discrete, compared to those in speech, which are continuous (<xref ref-type="fig" rid="pbio-1001372-g002">Figure 2</xref>). Music from a wide array of different cultures throughout the world most often uses pitches drawn from a limited set of tones (commonly five or seven) within an octave, creating scales that have specific musical interval values <xref ref-type="bibr" rid="pbio.1001372-Ross1">[2]</xref>; there is no counterpart of this phenomenon in speech intonation. Furthermore, the various tones within a scale are hierarchically organized and play different roles in most musical systems, leading to a wide array of perceptual phenomena (such as key structures, harmonic relationships, etc.) that may be subsumed under the term tonality <xref ref-type="bibr" rid="pbio.1001372-Krumhansl1">[5]</xref>; again, there is no truly analogous feature in speech intonation.</p>
      <fig id="pbio-1001372-g002" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.1001372.g002</object-id>
        <label>Figure 2</label>
        <caption>
          <title>Each panel represents the fundamental frequency (F0) contour of a spoken utterance (left side of figure) or of sung speech (right side of figure).</title>
          <p>Note the more continuous F0 contours for speech compared to the more discrete contours for song. The blue traces are the original contours, while the red ones represent distortions in which the F0 was either compressed by 50% (top panels) or exaggerated by 50% (bottom panels). The associated sound files illustrate that the manipulation of F0 on the speech sample (Sounds S1, S2, S3) has little perceptual effect, since it continues to sound natural (in fact, the change is hardly detectable). In contrast, the same degree of F0 distortion on the music (Sounds S4, S5, S6) is readily noticeable, as the familiar melody sounds obviously out of tune.</p>
        </caption>
        <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.g002" xlink:type="simple"/>
      </fig>
      <p>Most importantly, pitch within music depends on a much greater degree of accuracy, both in production and perception, as compared to speech. Many musical systems, including the Western tonal one, depend on specific, fixed musical intervals (frequency ratios). Under most circumstances, even fairly small deviations from these prescribed intervals are readily perceived as errors by listeners <xref ref-type="bibr" rid="pbio.1001372-Warrier1">[6]</xref>. In contrast, only rough frequency relationships are important for speech intonation: deviations of a similar magnitude as those that sound wrong in a melody are not perceived as violations in a speech contour. Behavioral studies show that removing all fundamental frequency modulation does not affect speech comprehension, even for tonal languages <xref ref-type="bibr" rid="pbio.1001372-Patel2">[7]</xref> unless the content is ambiguous <xref ref-type="bibr" rid="pbio.1001372-Binns1">[8]</xref> or the signal-to-noise ratio is poor <xref ref-type="bibr" rid="pbio.1001372-Miller1">[9]</xref>. The sound examples (<xref ref-type="fig" rid="pbio-1001372-g002">Figure 2</xref>) illustrate that accurate pitch relationships are more important for music than for speech: compare a 50% change in the magnitude of the pitch intervals (expansion or contraction) applied to a natural speech sample with the identical manipulation applied to a song. The speech sounds fairly natural under all conditions, whereas the song is clearly out of tune when the pitch is altered; indeed, the concept of “out of tune” does not even really apply to speech. Thus, there is a profound difference in how pitch is used in speech and music.</p>
    </sec>
    <sec id="s4">
      <title>Fine Versus Coarse Pitch Representations</title>
      <p>One way to think about the different uses of pitch variation in music and speech is to distinguish between the fine-grained, accurate encoding required for processing musical interval relationships used in scales, as compared to the more coarse-grained processing associated with contours. Contour in both music and speech is defined by the direction of pitch changes, but not by specific pitch relationships. Contour is especially relevant for speech, since direction of intonation can change linguistic meaning (e.g., question versus statement, or rising versus falling tones in Mandarin). But contour also plays a fundamental role in music perception: cognitive studies have shown that contour information is more perceptually salient (<xref ref-type="fig" rid="pbio-1001372-g003">Figure 3</xref>) and more easily remembered, whereas specific intervals take more time to encode <xref ref-type="bibr" rid="pbio.1001372-Dowling1">[10]</xref>. Infants detect contour but not interval information <xref ref-type="bibr" rid="pbio.1001372-Trainor1">[11]</xref>, implying that it is a more basic process that develops early or is innate. The neural correlates of contour and scale processing also appear to differ <xref ref-type="bibr" rid="pbio.1001372-Stewart1">[12]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Lee1">[13]</xref>. Taken together, these findings suggest that perhaps the coarse pitch processing related to contour might represent one mechanism used for both speech and music, whereas the precise encoding and production required for musical scale information might be a separate mechanism, perhaps even one that emerged later in phylogeny.</p>
      <fig id="pbio-1001372-g003" orientation="portrait" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.1001372.g003</object-id>
        <label>Figure 3</label>
        <caption>
          <title>Three melodies in musical notation (left) and their corresponding fundamental frequency contours (right).</title>
          <p>Melodies B and C are identical to Melody A, except for one changed tone (indicated by red arrows in both the musical notation and the pitch traces). Melodies A and B have the same contour (up, down, up, down, down, down), whereas Melody C has a different contour (up, down, up, up, down, down). The associated sound files illustrate that Melody C (Sound S9) is generally more easily distinguished from Melody A (Sound S7) because of this contour change, whereas Melody B (Sound S8) sounds more similar to Melody A because it has the same contour.</p>
        </caption>
        <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.g003" xlink:type="simple"/>
      </fig>
    </sec>
    <sec id="s5">
      <title>Dual Processing in the Brain for Music Versus Speech</title>
      <p>Consistent with this proposal, there is a large amount of human lesion evidence indicating that the processing of speech prosody and the processing of melody in music may be partially dissociated. Numerous investigations of individuals who have suffered focal brain damage (particularly within the right cerebral hemisphere) have demonstrated impairments in the ability to convey and/or perceive or comprehend speech intonation and its functional significance <xref ref-type="bibr" rid="pbio.1001372-Ross2">[14]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Pell1">[15]</xref>. In fact, although lesions in the left hemisphere (LH) have long been associated with impaired comprehension of linguistic meanings conveyed by prosody, rarely have isolated LH lesions been reported to lead to major disorders of melody perception <xref ref-type="bibr" rid="pbio.1001372-Peretz1">[16]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Peretz2">[17]</xref>. In contrast, however, evidence also exists supporting the notion of a shared neural substrate for the processing of melody in speech and music. For example, there have been a number of studies of patients with documented lesions that result in music processing deficits that have reported parallel difficulties in the perception of speech prosody <xref ref-type="bibr" rid="pbio.1001372-Patel3">[18]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Nicholson1">[19]</xref>. Such patterns of partially shared but dissociable processing mechanisms fit well with our hypothesis of dual processing mechanisms for pitch perception.</p>
      <p>Functional imaging studies show evidence both for segregation and overlap in the recruitment of cortical circuits for perception of speech and of tonal patterns <xref ref-type="bibr" rid="pbio.1001372-Koelsch1">[20]</xref>–<xref ref-type="bibr" rid="pbio.1001372-Tillmann1">[23]</xref>, but the commonalities may be more apparent than real. Sharing is likely due either to common task demands (for example, working memory) or to common input or output systems, with distinct neural resources at other levels <xref ref-type="bibr" rid="pbio.1001372-Patel4">[24]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Rogalsky1">[25]</xref>. Moreover, there is consistent evidence for a relative advantage of right auditory cortical structures compared to left for fine-grained spectral processing <xref ref-type="bibr" rid="pbio.1001372-Hyde1">[26]</xref>–<xref ref-type="bibr" rid="pbio.1001372-Zatorre1">[28]</xref>. Similarly, when contrasting vocal pitch production in linguistic and musical contexts, there seems to be overlap, but greater reliance on right-hemisphere structures during singing compared to speaking <xref ref-type="bibr" rid="pbio.1001372-Ozdemir1">[29]</xref>. Imaging studies of trained singers <xref ref-type="bibr" rid="pbio.1001372-Zarate1">[30]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Kleber1">[31]</xref> indicate that singing involves specialized contributions of auditory cortical regions, along with somatosensory and motor-related structures, suggesting that singing makes particular demands on auditory-vocal integration mechanisms related to the high level of pitch accuracy required for singing in tune, which is less relevant for speech.</p>
      <p>The distinction between two pitch mechanisms finds additional support from amusia, because a dissociation can be seen between preserved contour but impaired fine-pitch processing. People with congenital amusia, also known as tone-deafness, have little difficulty perceiving large changes in pitch contours typical of speech <xref ref-type="bibr" rid="pbio.1001372-Ayotte1">[32]</xref>. When measured with stimuli that have small pitch deviations, however, these individuals show impairments, whether the stimuli are speech or not <xref ref-type="bibr" rid="pbio.1001372-Hutchins1">[33]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Tillmann2">[34]</xref>, indicating a selective deficit at the level of fine-grained pitch distinctions <xref ref-type="bibr" rid="pbio.1001372-Hyde2">[35]</xref>, which are not as critical for speech as they are for music, as we have seen. These behavioral data fit with evidence of anatomical <xref ref-type="bibr" rid="pbio.1001372-Hyde3">[36]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Loui1">[37]</xref> and functional <xref ref-type="bibr" rid="pbio.1001372-Hyde4">[38]</xref> disruption in right auditory-frontal cortical circuitry, consistent with the functional neuroimaging evidence cited above suggesting that this circuitry plays a role in fine-grained pitch processing.</p>
    </sec>
    <sec id="s6">
      <title>Potential Subcortical Mechanisms for Processing Music and Speech</title>
      <p>If pitch processing for speech and music are dissociable at the cortical level, it is fair to ask if the dissociation originates there or at subcortical levels. Auditory brainstem activity can be studied using an electrical evoked potential measure, the frequency-following response, which most likely originates in the inferior colliculus. As its name implies, it encodes the frequency information contained in the acoustic stimulus in terms of changes in voltage that follow the fundamental frequency of the stimulus. Several studies have shown that the fidelity of the brainstem response in relation to the frequency content of the stimulus is enhanced both in tone-language speakers <xref ref-type="bibr" rid="pbio.1001372-Krishnan1">[39]</xref> and in trained musicians <xref ref-type="bibr" rid="pbio.1001372-Musacchia1">[40]</xref>. Moreover, training in one domain results in generalization of the brainstem enhancement in the other domain, such that musicians show better encoding of linguistic tone while tone-language speakers show enhancement for musical tones <xref ref-type="bibr" rid="pbio.1001372-Wong1">[41]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Bidelman1">[42]</xref>. This reciprocity suggests that the distinctions seen at cortical levels have not yet emerged at the subcortical processing stage. Yet the origins of this experience-dependent modulation are not fully understood. Differences as a function of training in very early latencies of brainstem onset responses, before activity in auditory cortex <xref ref-type="bibr" rid="pbio.1001372-Musacchia1">[40]</xref>, suggest that part of the enhancement is intrinsic to the brainstem. However, it could also be the case that cortical efferent mechanisms are also at play in the frequency following response.</p>
    </sec>
    <sec id="s7">
      <title>Conclusion</title>
      <p>In summary, the evidence indicates that despite some shared cognitive processes and neural substrates, the way pitch information is handled in speech and in music differs: there seem to be two mechanisms, one focused on contour, which may overlap across domains, and another, perhaps specific to music, involving more accurate pitch encoding and production. This distinction is reminiscent of parallel processing in other neural domains, such as vision, memory, or the motor system, where multiple types of analysis are needed to solve distinct problems. The dissociation we have discussed for pitch may therefore be seen as one more example of this more general biological principle.</p>
      <p>One implication of this model is that it should be possible to identify distinct neural substrates for the two mechanisms. Although some of the evidence points in this direction, there is no firm identification of the underlying neural circuitry that may give rise to the two processes. How the two hypothesized mechanisms emerge from interactions between cortical and subcortical pitch-processing mechanisms also remains to be understood. It might also be valuable to consider the distinction we have drawn in evaluating comparative analyses of how different animal species make use of pitch for communicative purposes <xref ref-type="bibr" rid="pbio.1001372-Hauser1">[43]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Fitch1">[44]</xref>. A greater understanding of the neural circuitry involved in the perception and production of pitch across cognitive domains will permit us to develop a more advanced model of the sensorimotor control of communicative systems, from basic processing to integration with higher order linguistic and cognitive processes beyond auditory and motor cortices <xref ref-type="bibr" rid="pbio.1001372-Hickok1">[45]</xref>,<xref ref-type="bibr" rid="pbio.1001372-Rauschecker1">[46]</xref>. We believe that substantial advances will emerge from such interdisciplinary ventures, with potential for future applications in fields as diverse as computer voice recognition to the rehabilitation of individuals who have suffered brain damage.</p>
    </sec>
    <sec id="s8">
      <title>Supporting Information</title>
      <supplementary-material id="pbio.1001372.s001" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s001" xlink:type="simple">
        <label>Sound S1</label>
        <caption>
          <p>Original speech.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001372.s002" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s002" xlink:type="simple">
        <label>Sound S2</label>
        <caption>
          <p>Pitch-compressed speech.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001372.s003" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s003" xlink:type="simple">
        <label>Sound S3</label>
        <caption>
          <p>Pitch-expanded speech.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001372.s004" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s004" xlink:type="simple">
        <label>Sound S4</label>
        <caption>
          <p>Original song.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001372.s005" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s005" xlink:type="simple">
        <label>Sound S5</label>
        <caption>
          <p>Pitch-compressed song.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001372.s006" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s006" xlink:type="simple">
        <label>Sound S6</label>
        <caption>
          <p>Pitch-expanded song.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001372.s007" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s007" xlink:type="simple">
        <label>Sound S7</label>
        <caption>
          <p>Melody A.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001372.s008" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s008" xlink:type="simple">
        <label>Sound S8</label>
        <caption>
          <p>Melody B.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001372.s009" mimetype="audio/x-wav" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001372.s009" xlink:type="simple">
        <label>Sound S9</label>
        <caption>
          <p>Melody C.</p>
          <p>(WAV)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Andrea Halpern and Marc Bouffard for assistance in construction of the figures and sound examples. The authors' research is funded via the Canadian Institutes of Health Research, the Natural Sciences and Engineering Research Council of Canada, and the Canada Fund for Innovation. The Centre is funded by the Government of Québec via the Fonds de Recherche Nature et Technologies and Société et Culture.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pbio.1001372-Patel1">
        <label>1</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patel</surname><given-names>AD</given-names></name> (<year>2008</year>) <source>Music, language, and the brain</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Ross1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ross</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Choi</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Purves</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>Musical intervals in speech</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>104</volume>: <fpage>9852</fpage>–<lpage>9857</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Schwartz1">
        <label>3</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwartz</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Howe</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Purves</surname><given-names>D</given-names></name> (<year>2003</year>) <article-title>The statistical structure of human speech sounds predicts musical universals</article-title>. <source>Journal of Neuroscience</source> <volume>23</volume>: <fpage>7160</fpage>–<lpage>7168</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Deutsch1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deutsch</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Henthorn</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Lapidis</surname><given-names>R</given-names></name> (<year>2011</year>) <article-title>Illusory transformation from speech to song</article-title>. <source>Journal of the Acoustical Society of America</source> <volume>129</volume>: <fpage>2245</fpage>–<lpage>2252</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Krumhansl1">
        <label>5</label>
        <mixed-citation publication-type="other" xlink:type="simple"><name name-style="western"><surname>Krumhansl</surname><given-names>CL</given-names></name> (<year>1990</year>) <source>Cognitive foundations of musical pitch</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Warrier1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Warrier</surname><given-names>CM</given-names></name>, <name name-style="western"><surname>Zatorre</surname><given-names>RJ</given-names></name> (<year>2002</year>) <article-title>Influence of tonal context and timbral variation on perception of pitch</article-title>. <source>Perception and Psychophysics</source> <volume>64</volume>: <fpage>198</fpage>–<lpage>207</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Patel2">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patel</surname><given-names>AD</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>B</given-names></name> (<year>2010</year>) <article-title>The role of F0 variation in the intelligibility of Mandarin sentences</article-title>. Proceedings of Speech Prosody, May 11–14 Chicago.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Binns1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Binns</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Culling</surname><given-names>JF</given-names></name> (<year>2007</year>) <article-title>The role of fundamental frequency contours in the perception of speech against interfering speech</article-title>. <source>Journal of the Acoustical Society of America</source> <volume>122</volume>: <fpage>1765</fpage>–<lpage>1776</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Miller1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname><given-names>SE</given-names></name>, <name name-style="western"><surname>Schlauch</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Watson</surname><given-names>PJ</given-names></name> (<year>2010</year>) <article-title>The effects of fundamental frequency contour manipulations on speech intelligibility in background noise</article-title>. <source>Journal of the Acoustical Society of America</source> <volume>128</volume>: <fpage>435</fpage>–<lpage>443</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Dowling1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dowling</surname><given-names>WJ</given-names></name> (<year>1978</year>) <article-title>Scale and contour: two components of a theory of memory for melodies</article-title>. <source>Psychological Review</source> <volume>85</volume>: <fpage>341</fpage>–<lpage>354</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Trainor1">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Trainor</surname><given-names>LJ</given-names></name>, <name name-style="western"><surname>Trehub</surname><given-names>SE</given-names></name> (<year>1992</year>) <article-title>A comparison of infants' and adults' sensitivity to Western musical structure</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source> <volume>18</volume>: <fpage>394</fpage>–<lpage>402</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Stewart1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stewart</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Overath</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Warren</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Foxton</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Griffiths</surname><given-names>TD</given-names></name> (<year>2002</year>) <article-title>fMRI evidence for a cortical hierarchy of pitch pattern processing</article-title>. <source>PLoS ONE</source> <volume>3</volume>: <fpage>e1470</fpage> doi:10.1371/journal.pone.0001470.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Lee1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>Y-S</given-names></name>, <name name-style="western"><surname>Janata</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Frost</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Hanke</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Granger</surname><given-names>R</given-names></name> (<year>2011</year>) <article-title>Investigation of melodic contour processing in the brain using multivariate pattern-based fMRI</article-title>. <source>NeuroImage</source> <volume>57</volume>: <fpage>293</fpage>–<lpage>300</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Ross2">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ross</surname><given-names>ED</given-names></name> (<year>1981</year>) <article-title>The aprosodias: functional-anatomic organization of the affective components of language in the right hemisphere</article-title>. <source>Archives of Neurology</source> <volume>38</volume>: <fpage>561</fpage>–<lpage>569</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Pell1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pell</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Cerebral mechanisms for understanding emotional prosody in speech</article-title>. <source>Brain and Language</source> <volume>96</volume>: <fpage>221</fpage>–<lpage>234</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Peretz1">
        <label>16</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Gagnon</surname><given-names>L</given-names></name> (<year>1999</year>) <article-title>Dissociation between recognition and emotional judgements for melodies</article-title>. <source>Neurocase</source> <volume>5</volume>: <fpage>21</fpage>–<lpage>30</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Peretz2">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Kolinsky</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Tramo</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Labrecque</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hublet</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>1994</year>) <article-title>Functional dissociations following bilateral lesions of auditory cortex</article-title>. <source>Brain</source> <volume>117</volume>: <fpage>1283</fpage>–<lpage>1301</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Patel3">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patel</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Tramo</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Labreque</surname><given-names>R</given-names></name> (<year>1998</year>) <article-title>Processing prosodic and musical patterns: a neuropsychological investigation</article-title>. <source>Brain and Language</source> <volume>61</volume>: <fpage>123</fpage>–<lpage>144</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Nicholson1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nicholson</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Baum</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Cuddy</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Munhall</surname><given-names>K</given-names></name> (<year>2002</year>) <article-title>A case of impaired auditory and visual speech prosody perception after right hemisphere damage</article-title>. <source>Neurocase</source> <volume>8</volume>: <fpage>314</fpage>–<lpage>322</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Koelsch1">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koelsch</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gunter</surname><given-names>TC</given-names></name>, <name name-style="western"><surname>von Cramon</surname><given-names>DY</given-names></name>, <name name-style="western"><surname>Zysset</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Lohmann</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Bach speaks: a cortical “language-network” serves the processing of music</article-title>. <source>NeuroImage</source> <volume>17</volume>: <fpage>956</fpage>–<lpage>966</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Maess1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maess</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Koelsch</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gunter</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Friederici</surname><given-names>AD</given-names></name> (<year>2001</year>) <article-title>“Musical syntax” is processed in the area of Broca: an MEG-study</article-title>. <source>Nature Neuroscience</source> <volume>4</volume>: <fpage>540</fpage>–<lpage>545</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Schn1">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schön</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Gordon</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Campagne</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Magne</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Astesano</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Similar cerebral networks in language, music and song perception</article-title>. <source>NeuroImage</source> <volume>51</volume>: <fpage>450</fpage>–<lpage>461</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Tillmann1">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tillmann</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Janata</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Bharucha</surname><given-names>JJ</given-names></name> (<year>2003</year>) <article-title>Activation of the inferior frontal cortex in musical priming</article-title>. <source>Cognitive Brain Research</source> <volume>16</volume>: <fpage>145</fpage>–<lpage>161</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Patel4">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patel</surname><given-names>AD</given-names></name> (<year>2011</year>) <article-title>Why would musical training benefit the neural encoding of speech? The OPERA hypothesis</article-title>. <source>Frontiers in Psychology</source> <volume>2</volume>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Rogalsky1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rogalsky</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Rong</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Saberi</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Hickok</surname><given-names>G</given-names></name> (<year>2011</year>) <article-title>Functional anatomy of language and music perception: temporal and structural factors investigated using functional magnetic resonance imaging</article-title>. <source>Journal of Neuroscience</source> <volume>31</volume>: <fpage>3843</fpage>–<lpage>3852</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Hyde1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyde</surname><given-names>KL</given-names></name>, <name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Zatorre</surname><given-names>RJ</given-names></name> (<year>2008</year>) <article-title>Evidence for the role of the right auditory cortex in fine pitch resolution</article-title>. <source>Neuropsychologia</source> <volume>46</volume>: <fpage>632</fpage>–<lpage>639</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Schnwiesner1">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schönwiesner</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Rubsamen</surname><given-names>R</given-names></name>, <name name-style="western"><surname>von Cramon</surname><given-names>DY</given-names></name> (<year>2005</year>) <article-title>Hemispheric asymmetry for spectral and temporal processing in the human antero-lateral auditory belt cortex</article-title>. <source>European Journal of Neuroscience</source> <volume>22</volume>: <fpage>1521</fpage>–<lpage>1528</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Zatorre1">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zatorre</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Belin</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Penhune</surname><given-names>VB</given-names></name> (<year>2002</year>) <article-title>Structure and function of auditory cortex: music and speech</article-title>. <source>Trends in Cognitive Science</source> <volume>6</volume>: <fpage>37</fpage>–<lpage>46</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Ozdemir1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ozdemir</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Norton</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Schlaug</surname><given-names>G</given-names></name> (<year>2006</year>) <article-title>Shared and distinct neural correlates of singing and speaking</article-title>. <source>NeuroImage</source> <volume>33</volume>: <fpage>628</fpage>–<lpage>635</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Zarate1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zarate</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Zatorre</surname><given-names>RJ</given-names></name> (<year>2008</year>) <article-title>Experience-dependent neural substrates involved in vocal pitch regulation during singing</article-title>. <source>NeuroImage</source> <volume>40</volume>: <fpage>1871</fpage>–<lpage>1887</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Kleber1">
        <label>31</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kleber</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Veit</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Birbaumer</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Gruzelier</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Lotze</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>The brain of opera singers: experience-dependent changes in functional activation</article-title>. <source>Cerebral Cortex</source> <volume>20</volume>: <fpage>1144</fpage>–<lpage>1152</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Ayotte1">
        <label>32</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ayotte</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Hyde</surname><given-names>K</given-names></name> (<year>2002</year>) <article-title>Congenital amusia: a group study of adults afflicted with a music-specific disorder</article-title>. <source>Brain</source> <volume>125</volume>: <fpage>238</fpage>–<lpage>251</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Hutchins1">
        <label>33</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hutchins</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gosselin</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name> (<year>2010</year>) <article-title>Identification of changes along a continuum of speech intonation is impaired in congenital amusia</article-title>. <source>Frontiers in Psychology</source> <volume>1</volume>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Tillmann2">
        <label>34</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tillmann</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Rusconi</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Traube</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Butterworth</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Umilta</surname><given-names>C</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Fine-grained pitch processing of music and speech in congenital amusia</article-title>. <source>The Journal of the Acoustical Society of America</source> <volume>130</volume>: <fpage>4089</fpage>–<lpage>4096</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Hyde2">
        <label>35</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyde</surname><given-names>KL</given-names></name>, <name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name> (<year>2004</year>) <article-title>Brains that are out of tune but in time</article-title>. <source>Psychological Science</source> <volume>15</volume>: <fpage>356</fpage>–<lpage>360</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Hyde3">
        <label>36</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyde</surname><given-names>KL</given-names></name>, <name name-style="western"><surname>Lerch</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Zatorre</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Griffiths</surname><given-names>TD</given-names></name>, <name name-style="western"><surname>Evans</surname><given-names>AC</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Cortical thickness in congenital amusia: when less is better than more</article-title>. <source>J Neurosci</source> <volume>27</volume>: <fpage>13028</fpage>–<lpage>13032</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Loui1">
        <label>37</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Loui</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Alsop</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Schlaug</surname><given-names>G</given-names></name> (<year>2009</year>) <article-title>Tone deafness: a new disconnection syndrome</article-title>? <source>J Neurosci</source> <volume>29</volume>: <fpage>10215</fpage>–<lpage>10220</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Hyde4">
        <label>38</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyde</surname><given-names>KL</given-names></name>, <name name-style="western"><surname>Zatorre</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Peretz</surname><given-names>I</given-names></name> (<year>2011</year>) <article-title>Functional MRI evidence of an abnormal neural network for pitch processing in congenital amusia</article-title>. <source>Cerebral Cortex</source> <volume>21</volume>: <fpage>292</fpage>–<lpage>299</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Krishnan1">
        <label>39</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Krishnan</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Xu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Gandour</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Cariani</surname><given-names>P</given-names></name> (<year>2005</year>) <article-title>Encoding of pitch in the human brainstem is sensitive to language experience</article-title>. <source>Brain Research, Cognitive Brain Research</source> <volume>25</volume>: <fpage>161</fpage>–<lpage>168</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Musacchia1">
        <label>40</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Musacchia</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Sams</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Skoe</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Kraus</surname><given-names>N</given-names></name> (<year>2007</year>) <article-title>Musicians have enhanced subcortical auditory and audiovisual processing of speech and music</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>104</volume>: <fpage>15894</fpage>–<lpage>15898</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Wong1">
        <label>41</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wong</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Skoe</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Russo</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Dees</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Kraus</surname><given-names>N</given-names></name> (<year>2007</year>) <article-title>Musical experience shapes human brainstem encoding of linguistic pitch patterns</article-title>. <source>Nature Neuroscience</source> <volume>10</volume>: <fpage>420</fpage>–<lpage>422</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Bidelman1">
        <label>42</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bidelman</surname><given-names>GM</given-names></name>, <name name-style="western"><surname>Gandour</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Krishnan</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Cross-domain effects of music and language experience on the representation of pitch in the human auditory brainstem</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>23</volume>: <fpage>425</fpage>–<lpage>434</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Hauser1">
        <label>43</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hauser</surname><given-names>MD</given-names></name>, <name name-style="western"><surname>McDermott</surname><given-names>J</given-names></name> (<year>2003</year>) <article-title>The evolution of the music faculty: a comparative perspective</article-title>. <source>Nat Neurosci</source> <volume>6</volume>: <fpage>663</fpage>–<lpage>668</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Fitch1">
        <label>44</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fitch</surname><given-names>WT</given-names></name> (<year>2005</year>) <article-title>The evolution of music in comparative perspective</article-title>. <source>Annals New York Academy of Sciences</source> <volume>1060</volume>: <fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Hickok1">
        <label>45</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hickok</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Poeppel</surname><given-names>D</given-names></name> (<year>2004</year>) <article-title>Dorsal and ventral streams: a framework for understanding aspects of the functional anatomy of language</article-title>. <source>Cognition</source> <volume>92</volume>: <fpage>67</fpage>–<lpage>99</lpage>.</mixed-citation>
      </ref>
      <ref id="pbio.1001372-Rauschecker1">
        <label>46</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rauschecker</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Scott</surname><given-names>SK</given-names></name> (<year>2009</year>) <article-title>Maps and streams in the auditory cortex: nonhuman primates illuminate human speech processing</article-title>. <source>Nat Neurosci</source> <volume>12</volume>: <fpage>718</fpage>–<lpage>724</lpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
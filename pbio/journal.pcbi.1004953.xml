<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="research-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004953</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-01775</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>People and places</subject><subj-group><subject>Population groupings</subject><subj-group><subject>Age groups</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>People and places</subject><subj-group><subject>Population groupings</subject><subj-group><subject>Age groups</subject><subj-group><subject>Adolescents</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Optimization</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>People and places</subject><subj-group><subject>Population groupings</subject><subj-group><subject>Age groups</subject><subj-group><subject>Adults</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>The Computational Development of Reinforcement Learning during Adolescence</article-title>
<alt-title alt-title-type="running-head">Computational Development of Learning</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Palminteri</surname>
<given-names>Stefano</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0360-3769</contrib-id>
<name name-style="western">
<surname>Kilford</surname>
<given-names>Emma J.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Coricelli</surname>
<given-names>Giorgio</given-names>
</name>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Blakemore</surname>
<given-names>Sarah-Jayne</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Institute of Cognitive Neuroscience, University College London, London, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Laboratoire de Neurosciences Cognitive, École Normale Supérieure, Paris, France</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Interdepartmental Centre for Mind/Brain Sciences, Università degli Studi di Trento, Trento, Italy</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department of Economics, University of Southern California, Los Angeles, California, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>O'Reilly</surname>
<given-names>Jill X</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Oxford University, UNITED KINGDOM</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: SP SJB. Performed the experiments: SP EJK. Analyzed the data: SP. Contributed reagents/materials/analysis tools: SJB GC. Wrote the paper: SP EJK GC SJB.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">stefano.palminteri@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>20</day>
<month>6</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>6</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>6</issue>
<elocation-id>e1004953</elocation-id>
<history>
<date date-type="received">
<day>19</day>
<month>10</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>29</day>
<month>4</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Palminteri et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004953"/>
<abstract>
<p>Adolescence is a period of life characterised by changes in learning and decision-making. Learning and decision-making do not rely on a unitary system, but instead require the coordination of different cognitive processes that can be mathematically formalised as dissociable computational modules. Here, we aimed to trace the developmental time-course of the computational modules responsible for learning from reward or punishment, and learning from counterfactual feedback. Adolescents and adults carried out a novel reinforcement learning paradigm in which participants learned the association between cues and probabilistic outcomes, where the outcomes differed in valence (reward versus punishment) and feedback was either partial or complete (either the outcome of the chosen option only, or the outcomes of both the chosen and unchosen option, were displayed). Computational strategies changed during development: whereas adolescents’ behaviour was better explained by a basic reinforcement learning algorithm, adults’ behaviour integrated increasingly complex computational features, namely a counterfactual learning module (enabling enhanced performance in the presence of complete feedback) and a value contextualisation module (enabling symmetrical reward and punishment learning). Unlike adults, adolescent performance did not benefit from counterfactual (complete) feedback. In addition, while adults learned symmetrically from both reward and punishment, adolescents learned from reward but were less likely to learn from punishment. This tendency to rely on rewards and not to consider alternative consequences of actions might contribute to our understanding of decision-making in adolescence.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>We employed a novel learning task to investigate how adolescents and adults learn from reward versus punishment, and to counterfactual feedback about decisions. Computational analyses revealed that adults and adolescents did not implement the same algorithm to solve the learning task. In contrast to adults, adolescents’ performance did not take into account counterfactual information; adolescents also learned preferentially to seek rewards rather than to avoid punishments, whereas adults learned to seek and avoid both equally. Increasing our understanding of computational changes in reinforcement learning during adolescence may provide insights into adolescent value-based decision-making. Our results might also have implications for education, since they suggest that adolescents benefit more from positive feedback than from negative feedback in learning tasks.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Marie Sklodowska-Curie Individual European Fellowship</institution>
</funding-source>
<award-id>PIEF-GA-2012 Grant 328822</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Palminteri</surname>
<given-names>Stefano</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000781</institution-id>
<institution>European Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>ERC Consolidator Grant 617629</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Coricelli</surname>
<given-names>Giorgio</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution>Medical Research Council studentship</institution>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0360-3769</contrib-id>
<name name-style="western">
<surname>Kilford</surname>
<given-names>Emma J</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution>Royal Society University Research Fellowship</institution>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Blakemore</surname>
<given-names>Sarah-Jayne</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>SP is supported by a Marie Sklodowska-Curie Individual European Fellowship (PIEF-GA-2012 Grant 328822). EJK is supported by a Medical Research Council studentship. GC is funded by the European Research Council (ERC Consolidator Grant 617629). SJB is funded by a Royal Society University Research Fellowship, the Jacobs Foundation and the Wellcome Trust. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="4"/>
<page-count count="25"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data are available online at <ext-link ext-link-type="uri" xlink:href="https://dx.doi.org/10.6084/m9.figshare.3398056.v1" xlink:type="simple">https://dx.doi.org/10.6084/m9.figshare.3398056.v1</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Adolescence is defined as the period of life that starts with the biological changes of puberty and ends with the individual attainment of a stable, independent role in society[<xref ref-type="bibr" rid="pcbi.1004953.ref001">1</xref>]. During this period, significant changes in value-based decision-making are observed[<xref ref-type="bibr" rid="pcbi.1004953.ref002">2</xref>]. Adolescents are often characterised as prone to engage in suboptimal decision-making, which although probably adaptive in many circumstances[<xref ref-type="bibr" rid="pcbi.1004953.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref006">6</xref>], can sometimes result in negative real life outcomes[<xref ref-type="bibr" rid="pcbi.1004953.ref007">7</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref008">8</xref>].</p>
<p>The computational framework of reinforcement learning formally captures value-based decision-making[<xref ref-type="bibr" rid="pcbi.1004953.ref009">9</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref010">10</xref>]. Reinforcement learning (RL) refers to the ability to learn to improve one’s future choices in order to maximise the expected value. The simplest RL algorithm (Q-learning) learns action-outcome associations directly from experienced rewards on a trial and error basis[<xref ref-type="bibr" rid="pcbi.1004953.ref011">11</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref012">12</xref>]. However, more complex behaviours, such as counterfactual learning and punishment- avoidance learning cannot be explained using the basic RL algorithm, due to its computational simplicity. Counterfactual learning refers to the ability to learn not only from direct experience, but also from hypothetical outcomes (the outcomes of the option(s) that were not chosen)[<xref ref-type="bibr" rid="pcbi.1004953.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref014">14</xref>]. Punishment avoidance, compared to reward seeking, requires an additional computational step in which outcomes are considered relative to a reference point (i.e. outcome valuation is contextualised)[<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref016">16</xref>]. Thus, compared to simple reward seeking, counterfactual and avoidance learning are more computationally demanding. Accordingly, whereas simple reward learning has been largely and robustly associated with the striatum[<xref ref-type="bibr" rid="pcbi.1004953.ref017">17</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref019">19</xref>], punishment and counterfactual processing have been consistently associated with the dorsal prefrontal system and the insula, areas that are classically associated with cognitive control[<xref ref-type="bibr" rid="pcbi.1004953.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref023">23</xref>]. Theories of adolescent brain development have pointed to differential functional and anatomical development of limbic regions, such as the striatum, and cognitive control regions and there is some evidence to support this notion [<xref ref-type="bibr" rid="pcbi.1004953.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref002">2</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref026">26</xref>]. We hypothesise that this asymmetrical development might be translated into a difference in the computational strategies used by adolescents compared with adults. Differences in reinforcement learning strategies may in turn contribute to an explanation of features of adolescent value-directed behaviour.</p>
<p>More precisely, we hypothesise that, while the basic RL algorithm successfully encapsulates value-based decision-making in adolescence, adults integrate more sophisticated computations, such as counterfactual learning and value contextualisation. To test this hypothesis, adults and adolescents performed an instrumental probabilistic learning task in which they had to learn which stimuli had the greatest likelihood of resulting in an advantageous outcome through trial and error. Both outcome valence (Reward vs. Punishment) and feedback type (Partial vs. Complete) were manipulated using a within-subjects factorial design (<xref ref-type="fig" rid="pcbi.1004953.g001">Fig 1A</xref>). This allowed us to investigate both punishment avoidance learning and counterfactual learning within the same paradigm. In a previous study, model comparison showed that adult behaviour in this task is best explained by a computational model in which basic RL is augmented by a counterfactual learning module (to account for learning from outcomes of unchosen options) and a value contextualisation module (to account for learning efficiently to avoid punishments) (<xref ref-type="fig" rid="pcbi.1004953.g002">Fig 2A</xref>)[<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>]. Our computational and behavioural results are consistent with our hypothesis and show that adolescents utilise a different, simpler computational strategy to perform the task.</p>
<fig id="pcbi.1004953.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Task design.</title>
<p><bold>(A)</bold> The learning task 2x2 factorial design. Different symbols were used as cues in each context, and symbol to context attribution was randomised across participants. The coloured frames are purely illustrative and represent each of the four context conditions throughout all figures. “Reward” = gain maximisation context; “Punishment” = loss minimisation context; “Partial”: counterfactual feedback was not provided; “Complete”: counterfactual feedback was provided; P<sub>Gain</sub> = probability of gaining 1 point; P<sub>Loss</sub> = probability of losing 1 point. <bold>(B)</bold> Time course of example trials in the Reward/Partial (top) and Reward/Complete (bottom) conditions. Durations are given in seconds. Fig 1 was adapted by the authors from a figure originally published in [<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>], licensed under CC BY 4.0.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.g001" xlink:type="simple"/>
</fig>
<fig id="pcbi.1004953.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Computational models and ex-ante model simulations.</title>
<p><bold>(A)</bold> The schematic illustrates the computational architecture of the model space. For each context (or state, ‘s’), the agent tracks option values (Q(s,:)), which are used to decide amongst alternative courses of action. In all contexts, the agent is informed about the outcome corresponding to the chosen option (R(c)), which is used to update the chosen option value (Q(s,c)) via a prediction error (δ(c)). This computational module (“factual module”) requires a learning rate (α<sub>1</sub>). In the presence of complete feedback, the agent is also informed about the outcome of the unchosen option (R(u)), which is used to update the unchosen option value (Q(s,u)) via a prediction error (δ(u)). This computational module (“counterfactual module”) requires a specific learning rate (α<sub>2</sub>). In addition to tracking option value, the agent also tracks the value of the context (V(s)), which is also updated via a prediction error (δ(v)), integrating over all available feedback information (R(c) and, where applicable, R(u)). This computational module (“contextual module”) requires a specific learning rate (α<sub>3</sub>). The full model (Model 3) can be reduced to Model 2 by suppressing the contextual module (i.e. assuming α<sub>3</sub> = 0). Model 2 can be reduced to Model 1 (basic Q-learning) by suppressing the counterfactual module (i.e. assuming α<sub>2</sub> = α<sub>3</sub> = 0). (<bold>B</bold>). Bars represent the model estimates of option values (top row) and decision values (bottom row), plotted as a function of the computational models and task contexts. G75 and G25: options associated with 75% and 25% chance of gaining a point, respectively; L75 and L25: options associated with 75% and 25% chance of losing a point, respectively. “Decision value” represents the difference in value between the correct and incorrect options (G75 minus G25 in Reward contexts; L25 minus L75 in Punishment contexts). Fig 2A was adapted by the authors from a figure originally published in [<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>], licensed under CC BY 4.0.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Computational models</title>
<p>During the learning task, participants made choices between two options, presented within different choice contexts (<xref ref-type="fig" rid="pcbi.1004953.g001">Fig 1</xref>). In each context, one option had a higher probability of resulting in an advantageous outcome (the ‘correct’ option; gaining a point or not losing a point) than the other. We submitted participants’ correct choice rate to computational analyses, based on an algorithm that has been shown to provide a good account for both behavioural and neural data within the same task in adults (<xref ref-type="fig" rid="pcbi.1004953.g002">Fig 2A</xref>)[<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>]. In short, the model includes a factual learning module (Q-learning), which updates the value of the chosen option (governed by a first free parameter: α<sub>1</sub>), a counterfactual learning module, which updates the value of the unchosen option (governed by a second free parameter: α<sub>2</sub>) and, finally, a contextual learning module, which learns the average value of the choice context and uses this to move from an absolute to a relative encoding of option value (governed by a third free parameter: α<sub>3</sub>). The counterfactual learning module has been shown to underlie the enhanced learning induced by the presence of complete feedback information, whereas the contextual learning model has been proposed to underpin the ability to perform similarly in both punishment and reward contexts. Thus, our model space included three nested and increasingly sophisticated models. Model 1 was a simple, option-value learning model (Q-learning), with no counterfactual or contextual learning modules (α<sub>2</sub> = α<sub>3</sub> = 0). Model 2 also included counterfactual, but no contextual learning (α<sub>3</sub> = 0). Finally, Model 3 was the “complete” model. Model 3 can be seen as the most parsimonious translation into the reinforcement-learning framework of the fictive learning models and relative value-based decision-making models proposed in economics[<xref ref-type="bibr" rid="pcbi.1004953.ref027">27</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref028">28</xref>].</p>
</sec>
<sec id="sec004">
<title>Ex-ante model simulations: Learning test</title>
<p>To describe the properties of the three models and illustrate how their performances differ across the different choice contexts (states, ‘s’), we ran ex-ante model simulations and analysed the model estimates of option values (Q(s,:)) and decision values (ΔQ(s)) (<xref ref-type="fig" rid="pcbi.1004953.g002">Fig 2B</xref>). Decision value is defined for each context as the difference in value between the correct and incorrect option. Decision values ultimately determine the percentage of correct choices during the learning task. Model 1 (basic Q-learning) predicts higher performance in the Reward compared to the Punishment contexts, a learning asymmetry predicted by the punishment avoidance learning paradox[<xref ref-type="bibr" rid="pcbi.1004953.ref029">29</xref>], and similar performance in the Partial and Complete feedback contexts. Model 2 (Model 1 plus the counterfactual learning module) permits an improvement in performance in the Punishment/Complete context, however still predicts a learning asymmetry in the Partial feedback contexts. Finally, Model 3 (Model 2 plus the value contextualisation module) predicts similar performance in the Reward and Punishment contexts and increased performance in the Complete compared to the Partial feedback contexts: this is the behavioural pattern that we expected for the adult group, based on our previous study[<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>].</p>
</sec>
<sec id="sec005">
<title>Model fitting: Baseline quality of fit does not differ between adolescents and adults</title>
<p>We fitted the three models to individual histories of choices and outcomes, in order to obtain, for each participant and each model, the parameters that maximised the negative log-likelihood of participants’ choices during the learning task (see <xref ref-type="supplementary-material" rid="pcbi.1004953.s004">S1 Table</xref>). To assess whether baseline model fitting differed between adolescents and adults, we submitted the negative log-likelihood and the inverse temperature parameter (β) to mixed-design ANOVA with group (Adolescents vs. Adults) as the between-subjects factor and model as the within-subjects factor. For negative log-likelihood (a measure of model quality of fit), there was no main effect of group (F(1,36) = 1.3, P&gt;0.2) and the group x model interaction did not reach significance (F(2,72) = 2.7, P&lt;0.08). Note that the main effect of model cannot be tested since the models are nested and therefore the negative log-likelihood can only decrease. Analysis of the inverse temperature (β) parameter supported these results. This parameter can be taken as a measure of how well choices are predicted by the model and strongly correlates with the model likelihood (for all models: R&gt;0.93; P&lt;0.001). There was no main effect of group (F(1,36) = 2.3, P&gt;0.1) but there was a significant group x model interaction (F(2,72) = 5.0, P&lt;0.01) (<xref ref-type="fig" rid="pcbi.1004953.g003">Fig 3A</xref>). Post-hoc comparisons showed that this interaction was driven by adults showing increases in inverse temperature when comparing Model 1 to Model 2 (T(19) = 3.2, P&lt;0.01) and Model 2 to Model 3 (T(19) = 2.2, P&lt;0.05). Baseline (Model 1) inverse temperature did not differ between adults and adolescents (T(36) = 0.4, P&gt;0.70). The absence of main effects of group indicates that baseline quality of fit was not different between age groups, thus allowing further model comparison analyses.</p>
<fig id="pcbi.1004953.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Baseline model fitting and model comparison.</title>
<p><bold>(A)</bold> Choice inverse temperature (β) of each model for adults (dark grey) and adolescents (light grey). (<bold>B</bold>). Posterior probability (PP) of each model for adults (dark grey) and adolescents (light grey). The dotted line indicates chance level (0.33). <sup>#</sup>P&lt;0.05; 2-sided, one-sample, t-tests; *P&lt;0.001; 2-sided, independent samples, t-tests. Error bars represent s.e.m.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec006">
<title>Model comparison: Different computational models explain learning in adolescents compared to adults</title>
<p>Posterior probability (PP) was calculated for each of the models, using the log of the Laplace approximation of the model evidence. Similar to other model comparison criteria, quality of fit is penalised by the model complexity[<xref ref-type="bibr" rid="pcbi.1004953.ref030">30</xref>]. As above, we submitted the PP of the models to a mixed-design ANOVA with group as the between-subjects factor and model as the within-subjects factor (<xref ref-type="fig" rid="pcbi.1004953.g003">Fig 3B</xref>). This analysis indicated a significant group x model interaction (F(2,72) = 38.9, P&lt;0.001). The effect of model was not quite significant (F(2,72) = 3.0, P&lt;0.06). Note that the main effect of group cannot be tested, since the model posterior probabilities by definition must sum to one, thus creating equal group means. Post-hoc comparisons showed that in the adolescent group, the posterior probability of Model 1 was significantly greater than chance level (T(17) = 3.0, P&lt;0.01; exceedance probability = 0.77) and greater than that of the adult group (T(36) = 8.0, P&lt;0.001). Conversely, in adults, the posterior probability of Model 3 was significantly greater than chance level (T(19) = 5.2, P&lt;0.001; exceedance probability = 0.80) and greater than that of the adolescents (T(36) = 7.8, P&lt;0.001) (see also Tables <xref ref-type="table" rid="pcbi.1004953.t001">1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1004953.s004">S1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1004953.s005">S2</xref> and <xref ref-type="supplementary-material" rid="pcbi.1004953.s006">S3</xref>). This result indicates that different computational models explain learning behaviour in the two groups. More precisely, a simple RL model better describes adolescents’ behaviour, whereas a more complex model, which integrates counterfactual and contextual learning processes, better accounts for adults’ behaviour.</p>
<table-wrap id="pcbi.1004953.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.t001</object-id>
<label>Table 1</label> <caption><title>Bayesian Model comparison.</title></caption>
<alternatives>
<graphic id="pcbi.1004953.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="center" colspan="2">Model 1</th>
<th align="center" colspan="2">Model 2</th>
<th align="center" colspan="2">Model 3</th>
</tr>
<tr>
<th align="left"/>
<th align="center">PP</th>
<th align="center">XP</th>
<th align="center">PP</th>
<th align="center">XP</th>
<th align="center">PP</th>
<th align="center">XP</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><bold>Subject -level</bold></td>
<td align="center"/>
<td align="center"/>
<td align="center"/>
<td align="center"/>
<td align="center"/>
<td align="center"/>
</tr>
<tr>
<td align="left"> <bold>Adoles.</bold></td>
<td align="center">0.51±0.06</td>
<td align="char" char=".">0.77</td>
<td align="center">0.33±0.05</td>
<td align="char" char=".">0.20</td>
<td align="center">0.16±0.02</td>
<td align="char" char=".">0.02</td>
</tr>
<tr>
<td align="left"> <bold>Adults</bold></td>
<td align="center">0.04±0.01</td>
<td align="char" char=".">0.00</td>
<td align="center">0.38±0.04</td>
<td align="char" char=".">0.20</td>
<td align="center">0.57±0.05</td>
<td align="char" char=".">0.79</td>
</tr>
<tr>
<td align="left"><bold>Group-level</bold></td>
<td align="center"/>
<td align="center"/>
<td align="center"/>
<td align="center"/>
<td align="center"/>
<td align="center"/>
</tr>
<tr>
<td align="left"> <bold>Adoles.</bold></td>
<td align="center">0.70</td>
<td align="char" char=".">0.48</td>
<td align="center">0.21</td>
<td align="char" char=".">0.28</td>
<td align="center">0.08</td>
<td align="char" char=".">0.24</td>
</tr>
<tr>
<td align="left"> <bold>Adults</bold></td>
<td align="center">0.00</td>
<td align="char" char=".">0.21</td>
<td align="center">0.31</td>
<td align="char" char=".">0.32</td>
<td align="center">0.68</td>
<td align="char" char=".">0.47</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>PP: posterior probability. XP: exceedance probability. Subject-level: parameters optimization assuming a set of free parameters per subject. Group-level: parameters optimization assuming a single set of free parameters per age group. PPs are reported as mean±s.e.m.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec007">
<title>Behavioural analyses: Correct choice rate</title>
<p>Our model comparison analyses suggest that adults and adolescents do not use the same computational strategy (<xref ref-type="fig" rid="pcbi.1004953.g003">Fig 3B</xref>). If this is the case, this computational result should be reflected in behavioural differences between the two groups. To verify this, we analysed the correct choice rate learning curves using a mixed-design ANOVA with group (Adolescents vs. Adults) as the between-subjects factor and trial (1:20), valence (Reward vs. Punishment) and feedback information (Partial vs. Complete) as within-subjects factors (<xref ref-type="fig" rid="pcbi.1004953.g004">Fig 4A</xref>). There was a significant main effect of trial on correct choice rate (F(19,684) = 26.8, P&lt;0.001), in which the rate of correct choices increased over the course of the learning task. There was also a significant interaction between group and trial (F(19,684) = 5.7 P&lt;0.001), which was further moderated by valence (F(19,684) = 2.0, P&lt;0.01). This suggests that adults and adolescents differed in the way their correct choice rate evolved during learning and that this difference interacted with outcome valence (Reward vs. Punishment). Post-hoc comparisons performed on the correct choice rate improvement (the difference between the first and last trials) indicated that, compared to adults, adolescents showed lower correct choice rate improvement in the Punishment/Partial context (T(36) = -2.9, P&lt;0.01) (<xref ref-type="fig" rid="pcbi.1004953.g004">Fig 4B</xref>). Post-hoc comparisons performed on the correct choice rate in the final trial (trial 20) indicated that, compared to adults, adolescents had lower rates of correct choice in the Punishment/Complete context (T(36) = -2.1, P&lt;0.05) (<xref ref-type="fig" rid="pcbi.1004953.g004">Fig 4B</xref>). Finally, while there was no significant interaction between feedback information and group, exploratory analyses indicated that whereas adults performed better in Complete feedback contexts (final correct choice rate: T(19) = 2.7, P&lt;0.05), adolescents showed no such positive effect of counterfactual information on correct choice rate (T(17) = 0.9, P&gt;0.4). To summarise, adolescents displayed reduced punishment learning compared to adults. Also consistent with our computational analyses, adolescent performance did not benefit from counterfactual feedback, although the interaction with group did not reach statistical significance (see <xref ref-type="table" rid="pcbi.1004953.t002">Table 2</xref>).</p>
<fig id="pcbi.1004953.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Correct choice rate.</title>
<p><bold>(A)</bold> Learning curves in adolescents (left) and adults (right). The bold lines within the shaded areas represent the actual behavioural data (bold lines represent mean correct choice rate; shaded areas represent s.e.m). The behavioural data are superimposed with the ex-post model-simulated learning curves, estimated using parameters from each age group’s best fitting model (Model 1 for adolescents; Model 3 for adults). The dots represent the model-simulated mean correct choice probabilities. (<bold>B</bold>) Bars represent the correct choice rate improvement (difference in correct choice rate between last and first trials) and the final correct choice rate (last trial) in Reward (leftmost panel) and Punishment (rightmost panel) contexts. Chance level (i.e. no learning) is 0.0 for correct choice rate improvement, and 0.5 for final correct choice rate. Error bars represent s.e.m. *P&lt;0.05: independent samples t-test (2-sided).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.g004" xlink:type="simple"/>
</fig>
<table-wrap id="pcbi.1004953.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.t002</object-id>
<label>Table 2</label> <caption><title>Behavioural data as function of choice context.</title></caption>
<alternatives>
<graphic id="pcbi.1004953.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="justify">Dependent variables</th>
<th align="justify">Adolescents (N = 18)</th>
<th align="justify">Adults (N = 20)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="justify"><bold>Correct choice rate (% correct)</bold></td>
<td align="justify"/>
<td align="justify"/>
</tr>
<tr>
<td align="justify">Overall</td>
<td align="justify">64.1±5.0<sup>#</sup></td>
<td align="justify">71.4±2.9<sup>###</sup></td>
</tr>
<tr>
<td align="justify">Reward/Partial</td>
<td align="justify">67.4±6.2</td>
<td align="justify">65.3±6.8</td>
</tr>
<tr>
<td align="justify">Punishment/Partial</td>
<td align="justify">56.8±4.5</td>
<td align="justify">63.8±4.6</td>
</tr>
<tr>
<td align="justify">Reward/Complete</td>
<td align="justify">68.2±7.7</td>
<td align="justify">78.1±4.9</td>
</tr>
<tr>
<td align="justify">Punishment/Complete</td>
<td align="justify">63.8±5.6</td>
<td align="justify">78.6±4.3</td>
</tr>
<tr>
<td align="justify"><bold>Reaction time (seconds)</bold></td>
<td align="justify"/>
<td align="justify"/>
</tr>
<tr>
<td align="justify">Overall</td>
<td align="justify">0.79±0.03</td>
<td align="justify">0.83±0.03</td>
</tr>
<tr>
<td align="justify">Reward/Partial</td>
<td align="justify">0.78±0.03</td>
<td align="justify">0.78±0.03</td>
</tr>
<tr>
<td align="justify">Punishment/Partial</td>
<td align="justify">0.84±0.03</td>
<td align="justify">0.87±0.03</td>
</tr>
<tr>
<td align="justify">Reward/Complete</td>
<td align="justify">0.71±0.03</td>
<td align="justify">0.81±0.03</td>
</tr>
<tr>
<td align="justify">Punishment/Complete</td>
<td align="justify">0.82±0.03</td>
<td align="justify">0.85±0.03</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>Overall refers to average performance collapsed across contexts.</p></fn>
<fn id="t002fn002"><p><sup>#</sup>P&lt;0.05 and <sup>###</sup>P&lt;0.001 (2-sided, one-sample, t-test), when comparing to chance level—random—performance (i.e. 50% of correct responses).</p></fn>
<fn id="t002fn003"><p>Note that neither overall correct choice rate (T(36) = 1.3, P&gt;0.1) nor overall reaction time (T(36) = 1.3, P&gt;0.3) differed between groups (T(36) = 1.3, P&gt;0.3).</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec008">
<title>Ex-post model simulations: Learning task</title>
<p>The behavioural analyses support the model comparison analyses, suggesting that adolescents implement a simpler computational model than adults (<xref ref-type="fig" rid="pcbi.1004953.g004">Fig 4A and 4B</xref>). To further verify the ability of the models to reproduce the observed behaviour, we used the optimised model parameter values to simulate correct choice rate (ex-post model simulations; see <xref ref-type="sec" rid="sec018">Methods</xref>). Trial-by-trial model estimates of the probability of choosing the correct response in the learning task were generated for each participant using the best fitting model for their age group (i.e. Model 1 for adolescents; Model 3 for adults). Model-simulated data were submitted to the same analyses as the behavioural data, which indicated significant group x valence x trial (F(19,684) = 2.8, P&lt;0.001), and group x feedback information x trial (F(19,684) = 8.7, P&lt;0.001) interactions, consistent with the reduced capacity to learn from counterfactual information and to efficiently avoid punishments observed in adolescents (<xref ref-type="fig" rid="pcbi.1004953.g004">Fig 4A</xref>).</p>
</sec>
<sec id="sec009">
<title>Behavioural analyses: Reaction times</title>
<p>Although reinforcement learning models and paradigms are primarily concerned with choice data, RTs are also supposed to carry relevant information concerning both option and decision values[<xref ref-type="bibr" rid="pcbi.1004953.ref031">31</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref032">32</xref>]. RTs were analysed in the same way as correct choice rate. We analysed the RT curves with a mixed-design ANOVA with group (Adolescents vs. Adults) as between-subjects factor and trial (1:20), valence (Reward vs. Punishment) and feedback information (Partial vs. Complete) as within-subject factors (<xref ref-type="fig" rid="pcbi.1004953.g005">Fig 5</xref>). There was a significant main effect of trial on RT (F(19,684) = 12.1, P&lt;0.001), reflecting a learning-induced RT reduction. There was also a significant main effect of valence (F(1,36) = 9.6, P&lt;0.01), and a significant interaction between valence and trial (F(19,684) = 5.9, P&lt;0.001), which reflected shorter RTs in the Reward compared to the Punishment contexts.</p>
<fig id="pcbi.1004953.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Reaction times.</title>
<p><bold>(A)</bold> Reaction time (RT) curves in adolescents (left) and adults (right). The bold lines within the shaded areas represent the mean RT. The shaded areas represent the s.e.m. (<bold>B</bold>) Bars represent the RT reduction (difference in RT between last and first trials) and the final RT (last trial) in the Partial (leftmost panel) and the Complete (rightmost panel) feedback contexts. Error bars represent the s.e.m. *P&lt;0.05: independent-samples t-test (2-sided).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.g005" xlink:type="simple"/>
</fig>
<p>Post-hoc comparisons performed on the final RT reduction (RTs at trial 20) indicated that both adults and adolescents showed higher RT (i.e. slower responses) in the Punishment compared to the Reward contexts (adults: T(19) = 2.1, P&lt;0.05; adolescents: T(17) = 2.9, P&lt;0.05). We also found a significant interaction between feedback information and trial, indicating that RT reduction differed in Partial and Complete feedback contexts (F(19,684) = 2.3, P&lt;0.001). There was no main effect of group on RT (F(1,36) = 1.6, P&gt;0.2), however there was a significant interaction between group and feedback information (F(1,36) = 12.2, P&lt;0.01), which was further moderated by trial (F(19,684) = 4.1, P&lt;0.001), indicating that RT reduction in the two groups was differentially influenced by the presence of counterfactual information. Post-hoc comparisons performed on the RT reduction (i.e. RTs at trial 1 minus RTs at trial 20) indicated that, compared to adults, adolescents showed less of a reduction in RT in the Reward/Complete context, which was not quite significant (T(36) = 1.9, P&lt;0.06) and the Punishment/Complete context, which was significant (T(36) = 2.2, P&lt;0.05) (T(36) = 2.4, P&lt;0.05; when collapsed across the two Complete contexts) (<xref ref-type="fig" rid="pcbi.1004953.g005">Fig 5B</xref>). Accordingly, whereas adult RT was reduced in the Complete compared to the Partial context (-89.8ms: T(19) = 2.4, P&lt;0.05), adolescents increased their speed (+10.7ms; T(17) = 1.8, P&lt;0.09). To summarise, in both age groups RTs are slower in the Punishment compared to the Reward contexts, which is consistent with an implicit Pavlovian inhibition effect[<xref ref-type="bibr" rid="pcbi.1004953.ref032">32</xref>]. Consistent with the model comparison analyses and choice, the influence of counterfactual information on RT over the course of the learning task was reduced in adolescents compared to adults (see <xref ref-type="table" rid="pcbi.1004953.t002">Table 2</xref>).</p>
</sec>
<sec id="sec010">
<title>Behavioural analyses: Post-learning test</title>
<p>The post-learning test measured the ability to retrieve and transfer the value of the cues, as learnt by trial and error during the learning task. Post-learning choice rate was extracted for each of the eight cues and analysed using a mixed-design ANOVA with group (Adolescents vs. Adults) as a between-subjects factor, and cue valence (Reward vs. Punishment), feedback information (Partial vs. Complete), and cue correctness (Correct vs. Incorrect) as within-subject factors. There was a significant effect of valence (F(1,36) = 92.2, P&lt;0.001) on post-learning choice rate, indicating that cues associated with Reward (G75 and G25) were preferred over those associated with Punishment (L25 and L75). Similarly, Correct cues (G75 and L25) were preferred over Incorrect ones (G25 and L75; F(1,36) = 38.1, P&lt;0.001) (<xref ref-type="fig" rid="pcbi.1004953.g006">Fig 6</xref>). These effects indicate that, overall, participants were able to retrieve the value of the cues during the post-learning test. Crucially, the analysis also revealed a significant interaction between feedback information and cue correctness (F(1,36 = 11.6, P&lt;0.01), which was further moderated by group (F(1,36 = 6.0, P&lt;0.05). Post-hoc between-groups comparisons of these difference scores (<xref ref-type="fig" rid="pcbi.1004953.g006">Fig 6</xref> and <xref ref-type="table" rid="pcbi.1004953.t003">Table 3</xref>) indicated that cue discrimination was significantly lower in the adolescents than in the adults in both the Complete contexts (Reward/Complete: T(36) = -2.4, P&lt;0.05; Punishment/Complete: T(36) = -2.6, P&lt;0.05). While adults showed improved cue discrimination in Complete contexts compared to Partial contexts (T(19) = 4.1, P&lt;0.001), adolescents did not (T(17) = 0.6, P&gt;0.5). To summarise, in adults, cue value retrieval in the post-learning test was enhanced for cues associated with counterfactual feedback during the learning task. Adolescents did not show this effect.</p>
<fig id="pcbi.1004953.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Post-learning test.</title>
<p><bold>(A)</bold> Bars represent the choice rate observed in the post-learning test, in adolescents (left) and adults (right). G75 and G25: options associated with 75% and 25% chance of gaining a point, respectively; L75 and L25: options associated with 75% and 25% chance of losing a point, respectively. The behavioural data are superimposed with coloured dots representing the model-simulated post-learning choices, estimated using parameters from each age group’s best fitting model (Model 1 for adolescents; Model 3 for adults). <bold>(B)</bold> Bars represent cue discrimination, the difference between post-learning choice-rates for Correct vs. Incorrect cues (G75 minus G25 in Reward contexts; L25 minus L75 in Punishment contexts), in Partial (leftmost panel) and Complete (rightmost panel) contexts. Chance level (i.e. no cue discrimination) is 0.0. Error bars represent s.e.m. *P&lt;0.05: independent samples t-test (2-sided).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.g006" xlink:type="simple"/>
</fig>
<table-wrap id="pcbi.1004953.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.t003</object-id>
<label>Table 3</label> <caption><title>Post-learning test behavioural data as a function of cue type.</title></caption>
<alternatives>
<graphic id="pcbi.1004953.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.t003" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Post-learning choice rate</th>
<th align="left">Adoles.</th>
<th align="left">Adults</th>
</tr>
</thead>
<tbody>
<tr>
<td align="justify">G<sub>75</sub> Reward/Partial (% choices)</td>
<td align="justify">65.3±6.8</td>
<td align="justify">75.0±5.1</td>
</tr>
<tr>
<td align="justify">G<sub>25</sub> Reward/Partial (% choices)</td>
<td align="justify">48.8±5.0</td>
<td align="justify">50.7±5.8</td>
</tr>
<tr>
<td align="justify">L<sub>25</sub> Punishment/Partial (% choices)</td>
<td align="justify">46.0±5.0</td>
<td align="justify">39.5±4.7</td>
</tr>
<tr>
<td align="justify">L<sub>75</sub> Punishment/Partial (% choices)</td>
<td align="justify">34.7±6.1</td>
<td align="justify">27.7±3.0</td>
</tr>
<tr>
<td align="justify">G<sub>75</sub> Reward/Complete (% choices)</td>
<td align="justify">73.6±5.2</td>
<td align="justify">84.6±3.3</td>
</tr>
<tr>
<td align="justify">G<sub>25</sub> Reward/Complete (% choices)</td>
<td align="justify">60.7±6.7</td>
<td align="justify">43.9±5.1</td>
</tr>
<tr>
<td align="left">L<sub>25</sub> Punishment/Complete (% choices)</td>
<td align="justify">45.8±4.3</td>
<td align="justify">58.0±3.8</td>
</tr>
<tr>
<td align="left">L<sub>75</sub> Punishment/Complete (% choices)</td>
<td align="justify">25.0±3.6</td>
<td align="justify">20.5±3.5</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001"><p>G75 and G25: options associated with 75% and 25% chance of gaining a point, respectively; L75 and L25: options associated with 75% and 25% chance of losing a point, respectively. Post-learning choice rates are reported as mean+-s.e.m.</p></fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec011">
<title>Ex-post model simulations: Post-learning test</title>
<p>We also tested the model’s ability to account for choices made in the post-learning test. Under the assumptions that choices in the post-learning test were dependent on the final option values in the learning task, and that there was no significant memory decay between the two tasks, the post-learning test, as in previous studies, can be used as an out-of-sample measure to compare the predictions of the different models[<xref ref-type="bibr" rid="pcbi.1004953.ref033">33</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref034">34</xref>] We calculated the probability of choice in the post-learning test using a softmax function, using the same individual choice inverse temperature optimized during the learning task (note that similar results have been obtained by optimising a beta specific to the post-learning test). Again, we submitted the model-simulated post-learning choice rates to the same statistical analyses as the behavioural data (<xref ref-type="fig" rid="pcbi.1004953.g006">Fig 6</xref>). Analysis of the model-simulated choices in the post-learning test also showed a significant group x feedback information x correctness interaction (F(1,36) = 13.0, P&lt;0.001), consistent with the behavioural finding of enhanced cue value retrieval in adults for cues associated with counterfactual information that was not observed in adolescents, and the model comparison analyses. As indicated by the ex-ante model-simulated option values, higher cue discrimination in both the Reward/Complete and Punishment/Complete contexts and inverted preferences for intermediate value cues (i.e. small gains and small losses) requires both counterfactual learning and value contextualisation (<xref ref-type="fig" rid="pcbi.1004953.g002">Fig 2B</xref>).</p>
</sec>
</sec>
<sec id="sec012" sec-type="conclusions">
<title>Discussion</title>
<p>Adolescents and adults performed an instrumental probabilistic learning task that involved learning to seek rewards or to avoid punishments. Feedback information was also manipulated: in some contexts, participants could only learn from the outcome of their choice, whereas in other contexts they could learn from both the outcome of the chosen and the unchosen option (counterfactual learning). Bayesian model selection indicated that a sophisticated model, incorporating a counterfactual learning module (necessary to learn from the unchosen option outcome) and a value contextualisation module (necessary to learn equally well from rewards and punishments) best accounted for adult behaviour, replicating previous findings[<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>]. Behavioural analyses showed that adults learnt equally well to seek rewards and avoid punishments and also efficiently integrated counterfactual information in instrumental learning. However, adolescent behaviour displayed a different pattern. In adolescents, Bayesian model selection significantly favoured the simplest action-value algorithm (Q-learning). This computational observation was supported by behavioural analyses of the learning task, in which the adolescents displayed reduced punishment avoidance learning, and in which RT reduction differed between adolescents and adults in the Reward/Complete context. Post-learning test analysis further corroborated the computational and behavioural findings of the learning test. Our findings support the hypothesis that adolescents and adults do not implement the same computational strategies.</p>
<sec id="sec013">
<title>Reward learning</title>
<p>Within the factorial design of our task, the Reward/Partial context represented a “baseline” learning context. From a computational perspective, this context is the simplest as participants can efficiently maximise rewards by directly tracking outcome values using a basic model of reinforcement learning (RL). Neuroimaging and pharmacological studies have demonstrated the importance of subcortical structures, particularly the ventral striatum, in this basic reward-value learning[<xref ref-type="bibr" rid="pcbi.1004953.ref010">10</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref035">35</xref>]. The striatum shows earlier anatomical maturation compared with the more protracted development of the prefrontal cortex[<xref ref-type="bibr" rid="pcbi.1004953.ref024">24</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref026">26</xref>]. Basic reward seeking has also been associated with the dopaminergic modulation of the striatum[<xref ref-type="bibr" rid="pcbi.1004953.ref033">33</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref036">36</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref037">37</xref>], and animal studies show that striatal dopamine peaks during adolescence[<xref ref-type="bibr" rid="pcbi.1004953.ref038">38</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref039">39</xref>]. A previous task using a simple reward maximisation task, comparable to our Reward/Partial condition, showed stronger encoding of reward learning signals in the striatum in adolescents compared to adults, with no negative behavioural consequences [<xref ref-type="bibr" rid="pcbi.1004953.ref002">2</xref>]. Consistent with these data, we observed no differences between age groups in basic reward learning in the Reward/Partial context. The similar performance between groups in the Reward/Partial context provides evidence that the group differences we observed concerning punishment and reward learning cannot be explained by a generalised lack of motivation or attention, but rather are likely to be associated with specific computational differences.</p>
</sec>
<sec id="sec014">
<title>Counterfactual learning</title>
<p>While less extensively studied than simple action-value learning, previous neuroimaging and computational studies of counterfactual learning suggest that learning from the outcome of the unchosen option recruits dorsolateral and polar prefrontal structures[<xref ref-type="bibr" rid="pcbi.1004953.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref014">14</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref021">21</xref>]. We hypothesised that, since these regions are still developing in adolescence [<xref ref-type="bibr" rid="pcbi.1004953.ref040">40</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref043">43</xref>], adolescents would display a reduced ability to learn from counterfactual feedback. Both our computational and behavioural analyses (specifically the reaction times and post-learning test) supported this prediction. This reduced integration of counterfactual outcomes in adolescent behaviour is also consistent with a previous study showing limited feedback use as a possible source of higher risky decision-making during adolescents[<xref ref-type="bibr" rid="pcbi.1004953.ref044">44</xref>]. Counterfactual learning can also be understood within the framework of “model-based” (as opposite to “model-free”) RL[<xref ref-type="bibr" rid="pcbi.1004953.ref045">45</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref046">46</xref>]. Algorithms that operate without using a representation (model) of the environment, such as basic Q-learning, are termed model-free. Conversely, algorithms that build option values by simulating different possible courses of action (i.e. planning), based on an explicit model of the environment (the task), are termed model-based. Counterfactual learning can be conceptualised as a “model-based” process, as it involves the updating of option values according to mental simulations of what the outcome could have been if we had chosen an alternative course of action[<xref ref-type="bibr" rid="pcbi.1004953.ref021">21</xref>]. Like counterfactual learning, model-based learning has been theoretically and experimentally associated with prefrontal systems[<xref ref-type="bibr" rid="pcbi.1004953.ref047">47</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref049">49</xref>]. A key area for future research will be to examine whether or not the developmental changes in counterfactual learning observed here generalise to and interact with other forms of computation implicated in model-based learning, such as state transition learning.</p>
</sec>
<sec id="sec015">
<title>Punishment learning</title>
<p>In our task, symmetrical performance in the reward seeking and punishment avoidance learning conditions depends on the ability to contextualise outcome values. Value contextualisation consists of updating option value as a function of the difference between the experienced outcome and an approximation of the average value of the two options (i.e. the context value). Thus, in punishment contexts, where the overall context value is negative, an intrinsically neutral outcome (neither gaining nor losing points: 0pt; Figs <xref ref-type="fig" rid="pcbi.1004953.g002">2A</xref> and <xref ref-type="fig" rid="pcbi.1004953.g004">4</xref>) acquires a positive value and can therefore reinforce selection of the options that lead to successful avoidance of punishment. In the absence of value contextualisation, the neutral outcome, which represents the best possible outcome in the punishment contexts will inevitably be considered as less attractive than a positive outcome (the best possible outcome in the reward contexts: +1pt), and consequently the participant will perform less optimally in punishment contexts.</p>
<p>Previous studies of punishment avoidance learning, using the same or similar tasks as ours, have implicated the dorsomedial prefrontal cortex and dorsal anterior cingulate cortex in the representation of negative values and negative prediction errors[<xref ref-type="bibr" rid="pcbi.1004953.ref020">20</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref022">22</xref>]. Similarly to counterfactual learning, we predicted that adolescents would show reduced punishment avoidance learning based on the continuing development of prefrontal “control” regions. Indeed, our results demonstrated that adolescents were less likely to engage in value contextualisation computation and thus showed less effective punishment avoidance learning and different cue evaluation in the post-learning test. Thus, our results provide a computational substrate to neurobiological theories pointing to a reward/punishment imbalance as a driving force of adolescent risk- and novelty-seeking behaviour[<xref ref-type="bibr" rid="pcbi.1004953.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref024">24</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref026">26</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref050">50</xref>].</p>
<p>Previous studies of punishment avoidance learning in adolescents have elicited somewhat inconsistent results. While some studies showed a reduction of punishment learning in adolescents[<xref ref-type="bibr" rid="pcbi.1004953.ref051">51</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref053">53</xref>], others reported no effect of valence[<xref ref-type="bibr" rid="pcbi.1004953.ref054">54</xref>], or even higher performance in punishment than reward contexts[<xref ref-type="bibr" rid="pcbi.1004953.ref055">55</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref056">56</xref>]. One possible way to reconcile these discrepancies is to consider the modular nature of computational RL. In addition to value contextualisation, at least one other learning process, the Pavlovian inhibitory system, has been implicated in punishment avoidance learning[<xref ref-type="bibr" rid="pcbi.1004953.ref032">32</xref>]. According to this theory, and supported by experimental findings, Pavlovian expectations may influence choice behaviour via Pavlovian-Instrumental Transfer (PIT)[<xref ref-type="bibr" rid="pcbi.1004953.ref057">57</xref>]. In instrumental tasks, PIT is observed in the form of increased motor inertia for actions leading to potential harm (losses). Since Pavlovian learning has been shown to be underpinned by subcortical structures, such as the amygdala, which mature relatively early in adolescence [<xref ref-type="bibr" rid="pcbi.1004953.ref040">40</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref058">58</xref>], it is possible that PIT occurs similarly in adolescents and adults. We would predict that, for avoidance tasks that rely only on PIT, adolescents and adults would display similar performance, whereas in tasks that require value contextualisation (such as multi-armed bandit tasks, with probabilistic outcomes), adolescents and adults would not behave similarly. To investigate the Pavlovian inhibitory system in adolescent we considered the reaction time from stimulus onset to the decision point. We found that in both adolescents and adults, RTs were longer in Punishment than in Reward contexts. Interpreted within the framework of Pavlovian-Instrumental Transfer learning, this effect may reflect an increase in motor inertia of actions associated with potential losses. In other words, punishment avoidance actions require more time to be performed, compared to reward seeking actions, because avoidance is more naturally linked to “nogo” responses. It is possible that in adolescents the Pavlovian inhibitory system is fully responsive and can mediate successful punishment avoidance in tasks that do not require value contextualisation[<xref ref-type="bibr" rid="pcbi.1004953.ref055">55</xref>]. Finally, RT profiles differed between adolescents and adults in the Reward/Complete context, which may provide supplementary evidence of reduced counterfactual learning in adolescents. This “multiple systems” account of avoidance learning is also consistent with the proposal that reward/punishment imbalance in pathology, development and aging, could be underpinned by different neurophysiological mechanisms[<xref ref-type="bibr" rid="pcbi.1004953.ref059">59</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref060">60</xref>].</p>
</sec>
<sec id="sec016">
<title>Methodological implications</title>
<p>From a methodological perspective our study underlines the importance of using computational approaches to study the development of learning and decision-making[<xref ref-type="bibr" rid="pcbi.1004953.ref061">61</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref062">62</xref>]. Few studies have used computational models to interpret adolescent behaviour[<xref ref-type="bibr" rid="pcbi.1004953.ref063">63</xref>–<xref ref-type="bibr" rid="pcbi.1004953.ref065">65</xref>], and fewer still have implemented model comparison techniques[<xref ref-type="bibr" rid="pcbi.1004953.ref051">51</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref054">54</xref>]. Behavioural measures provide a relatively rough measure of performance in learning tasks for the following reasons. First, in probabilistic learning tasks an incorrect response, as defined by the experimenter with knowledge of the task design, may locally be a “correct” response, according to the actual history of choices and outcomes experienced by the participant, as a function of misleading trials. Second, the final estimation of learning performance may be affected by differences in initial choice rate. For example, a participant who starts choosing the correct option by chance is favoured compared to a participant who would need to “explore” the options in order to find out the correct option. Third, aggregate model-free analyses are not able to formally tease apart the possible computational processes underlying performance differences, which could be characterised either by differences in free parameter values within the same model, or by differences in the computational architecture itself. By incorporating into the analysis the individual history of choices and outcomes, and formalising different learning mechanisms in discrete algorithmic modules, computational model-based analyses offer an elegant solution to these issues<strike>.</strike> As such, our study, together with others, has be seen as part of a broader agenda aiming at moving from an “heuristic” to an “mechanistic” modelisation of human cognitive development[<xref ref-type="bibr" rid="pcbi.1004953.ref066">66</xref>].</p>
</sec>
<sec id="sec017">
<title>Conclusions and implications</title>
<p>Our results suggest that adolescents show heightened reward seeking compared to punishment avoidance learning and a reduced ability to take into account the outcomes of alternative courses of action. Together, these processes may contribute to the adolescent propensity to engage in value-based decision-making. Atypical value processing and learning are also implicated in multiple mental health disorders, at both the behavioural and neural level[<xref ref-type="bibr" rid="pcbi.1004953.ref067">67</xref>]. Increasing our understanding of normative changes in learning and decision-making during adolescence may thus provide insight into why adolescence is a period of increased risk for risky behaviours and mental health difficulties such as substance abuse and depression[<xref ref-type="bibr" rid="pcbi.1004953.ref068">68</xref>]. Finally, our results might also have implications for education, since they suggest that adolescents might benefit more from positive than from negative feedback when improving behavioural performance[<xref ref-type="bibr" rid="pcbi.1004953.ref069">69</xref>].</p>
</sec>
</sec>
<sec id="sec018" sec-type="materials|methods">
<title>Materials and Methods</title>
<sec id="sec019">
<title>Participants</title>
<p>We recruited 50 volunteers aged between 12 and 32 years. Adolescents (N = 26; 12–17 years) were recruited from a local Community Theatre and UCL volunteer databases; adults (N = 24; 18–32 years) were recruited from UCL volunteer databases. The study was approved by the UCL Research Ethics Committee, and participants, or their legal guardians (adolescents), gave written informed consent. All participants were native English speakers and non-verbal IQ was assessed using the matrix reasoning subset of the Wechsler’s Abbreviated Scale of Intelligence (WASI)[<xref ref-type="bibr" rid="pcbi.1004953.ref070">70</xref>]. Due to group differences in non-verbal IQ scores (T(48) = 4.59, P&lt;0.001), we restricted our analysis to those participants with scores falling within the range shared by both groups. The lower level of the range was determined by the lower IQ of the initial adult group, the higher IQ level of the range was determined by the higher IQ of the initial adolescent group. This gave a final sample of 38 participants, in which age groups (20 adults; 18 adolescents) were matched in non-verbal IQ and gender composition (see <xref ref-type="table" rid="pcbi.1004953.t004">Table 4</xref>).</p>
<table-wrap id="pcbi.1004953.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004953.t004</object-id>
<label>Table 4</label> <caption><title>Sample demographics.</title></caption>
<alternatives>
<graphic id="pcbi.1004953.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.t004" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Group</th>
<th align="left">N</th>
<th align="left">Age (years)</th>
<th align="left">Gender</th>
<th align="left">IQ (T-scores)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Adolescents</td>
<td align="left">18</td>
<td align="left">14.27 ± 0.30 (12–16)</td>
<td align="left">8 male, 10 female</td>
<td align="left">98.5 ± 1.1 (46–61)</td>
</tr>
<tr>
<td align="left">Adults</td>
<td align="left">20</td>
<td align="left">22.35 ± 0.83 (18–32)</td>
<td align="left">8 male, 12 female</td>
<td align="left">101.4 ± 1.0 (43–61)</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t004fn001"><p>IQ: on-verbal IQ assessed using the matrix reasoning subset of WASI. Age and IQ are reported as mean+-s.e.m. IQ did not significantly differ ns between age groups: T(36) = 2.01, P&gt;0.05.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>All participants received a fixed amount of £5 for taking part, plus an additional amount (£0-£10) that varied according to their task performance (i.e. the average correct response rate). For “correct choice rate ≤ 0.50” participants received no bonus, for “0.50 &gt; correct choice rate ≥ 0.75” participants received a £5 bonus, and for “correct choice rate &gt; 0.75” participants received a £10 bonus. As a result of this payoff scheme, on average adults received £11.75±0.9 and adolescents £9.72±0.9 (payoff did not significantly differ between age groups: T(36) = 1.8, P&gt;0.08).</p>
<p>Our group definition has, of course, limitations. We chose to define the adolescent group as individuals under the age of 18, and adults over the age of 18. This fits with societal definition of adulthood, but it is an inevitably arbitrary cut-off, and as such, it is possible that there might be developmental changes in task performance during in early adulthood that we cannot detect. The age range of the adolescent group is relatively large and, again, it is possible that developmental changes within this age range could be found.</p>
</sec>
<sec id="sec020">
<title>Behavioural task</title>
<p>Participants performed a probabilistic instrumental learning task adapted from a previous neuroimaging study [<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>]. The task had two phases, a learning task and a post-learning test. The learning task was designed to manipulate both outcome valence (Reward vs. Punishment) and feedback type (Partial vs. Complete; <xref ref-type="fig" rid="pcbi.1004953.g001">Fig 1</xref>) using a 2x2 factorial design. In the learning task, participants viewed pairs of abstract symbol cues (characters from the Agathodaimon alphabet) on a computer screen and had to choose one of the two. There were eight different cues, divided into four fixed pairs so that a given cue was always presented with the same counterpart. As such, the cue pairs represented stable choice contexts. Each of the four pairs corresponded to one of four context conditions (Reward/Partial, Reward/Complete, Punishment/Partial and Punishment/Complete). In Reward contexts, the ‘good’ outcome was gaining a point and a ‘bad’ outcome was not gaining a point, whereas in Punishment contexts, a ‘good’ outcome was not losing a point, while a ‘bad’ outcome was the loss of a point. Within each pair, one cue had a higher probability of resulting in a ‘good’ outcome (75%; the “correct” option; G75 and L25 cues) than the other (25%; the “incorrect” option; G25 and L75 cues). Depending on the pair of cues (i.e. choice context), participants were presented with only the outcome of the chosen cue (Partial feedback) or the outcomes of both the chosen and unchosen cues (Complete feedback). Each cue pair was presented 20 times in a pseudo-randomised order, giving a total of 80 trials. Cue pairs were presented either side of a central fixation cross, with side of presentation pseudo-randomised so that each cue was presented an equal number of times on each side.</p>
<p>Participants were instructed to acquire as many points as possible, as this would determine their final payment. We explained to participants that only their chosen outcome counted toward their points score, even if sometimes both outcomes were presented, and that both winning points and avoiding losing points were equally important to maximise payoff. After hearing the task instructions, participants performed a training session, before starting the learning task. Each trial started with a fixation cross (1 seconds), followed by presentation of the cue pairs (2 seconds), during which participants had to select either the left or right cue by pressing the corresponding button. After the choice window, a red arrow indicated the chosen option (0.5 seconds), before the cues disappeared and the chosen cue was replaced by the outcome (2 seconds; “+1pt” and a happy smiley, “0pt” and no image, or “-1pt” and unhappy smiley; <xref ref-type="fig" rid="pcbi.1004953.g001">Fig 1B</xref>). In Complete feedback contexts, the outcome corresponding to the unchosen option (counterfactual feedback) was also displayed. Note that while, on average, outcomes for each cue pair were anti-correlated on an individual trial, the outcomes of each cue were independent from one another. Thus, for example, in Complete feedback contexts participants could observe the same outcome for each cue (37.5% of trials).</p>
<p>After the learning task, participants completed a post-learning test of cue value. Here, the eight cues from the learning task were presented as unfixed pairs of all 28 possible pair-wise combinations[<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref033">33</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref034">34</xref>]. Each pair was presented 4 times in a pseudo-random order, giving a total of 112 trials. For each cue pair, participants had to indicate the option with the highest value during the preceding learning session (i.e. the cue with the highest likelihood of resulting in a ‘good’ outcome). Unlike the learning task, choice was self-paced and no feedback was presented. Instructions for this task were given after the learning task, to prevent participants from explicitly memorising cue values. We informed participants that cues would not necessarily be shown in pairings that had been presented previously during the learning task. While participants could not earn points in this assessment, we encouraged participants to respond as if points were at stake.</p>
</sec>
<sec id="sec021">
<title>Behavioural analyses</title>
<p>From the learning task we extracted the correct choice rate and RT as the dependent variables. A correct response was defined as a choice directed toward the “good” stimulus (i.e., the most rewarding or the least punishing cue of the pair). Learning curves were computed from the trial-by-trial cumulative average of correct responses during the learning session. The cumulative average in a given trial “t” is calculated by averaging the correct choice rate from trial 1 to trial “t”. Statistical analyses were performed on the learning curves, using mixed-design ANOVA, with group (Adolescents vs. Adults) as the between-subjects factor, and trial (1:20), valence (Reward or Punishment) and feedback information (Partial or Complete), as within-subjects factors, and group (Adolescents or Adults) as the between-subjects factor. The “trial” factor is important to assess whether or not the effect are “learning-dependent”[<xref ref-type="bibr" rid="pcbi.1004953.ref071">71</xref>]. Between-group post-hoc comparisons were performed on final correct choice rate (which is directly proportional to the final number of points earned) and on the correct choice rate improvement (i.e. final minus initial correct choice rate at trial 20 minus correct choice rate at trial 1) using independent-samples t-tests. Examining both the final and the improvement in correct choice rate are important, if one is to draw conclusions regarding differences in learning. Reaction times were also extracted from the learning task, smoothed with a three trial sliding window and submitted to the same statistical model used for the correct choice rate. For RT, between-group post-hoc comparisons were performed on the RT reduction (i.e. RTs at trial 1 minus RTs at trial 20) and the final RT (RTs at trial 20).</p>
<p>Post-learning choice rate (i.e. the number of time a cues was chosen in the post-learning test divided by the number of trials the cue was presented in) indirectly reflects instrumental learning and should be higher for the more advantageous (“Correct”) cues of the learning task. Post-learning choice rate was extracted for each of the eight cues and analysed using a mixed-design ANOVA with group (Adolescents vs. Adults) as a between-subjects factor, and cue valence (Reward vs. Punishment), feedback information (Partial vs. Complete), and cue correctness (Correct vs. Incorrect) as within-subject factors. Between-group post-hoc comparisons were performed on the difference between Correct and Incorrect cues (i.e. G75 minus G25, in Reward contexts; L25 minus L75 in Punishment contexts) using independent samples t-tests (2-sided). This difference is a measure of cue discrimination: a significant and positive value indexes the participant’s tendency to prefer the optimal option during the preceding learning task.</p>
<p>Statistical analyses were performed using Matlab (<ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com" xlink:type="simple">www.mathworks.com</ext-link>) and R (<ext-link ext-link-type="uri" xlink:href="http://www.r-project.org" xlink:type="simple">www.r-project.org</ext-link>).</p>
</sec>
<sec id="sec022">
<title>Computational models</title>
<p>We analysed participants’ with reinforcement learning models [<xref ref-type="bibr" rid="pcbi.1004953.ref072">72</xref>]. 68 The goal of all models was to find the option that maximises the cumulative future reward (R) in each choice context (state: s). Our model space included three nested and increasingly sophisticated models (<xref ref-type="fig" rid="pcbi.1004953.g002">Fig 2A</xref>). Model 1 was a standard Q-learning model, which instantiates learning from direct experience by updating the value of the chosen option according to the outcome of each trial. Counterfactual information and the context in which choices are presented are not taken into account. In Model 2, the standard Q-learning model was augmented by a computational module enabling learning from counterfactual information[<xref ref-type="bibr" rid="pcbi.1004953.ref014">14</xref>]. Finally, in Model 3, Model 2 was further augmented by a contextual learning module, enabling the updating of option values relative to the choice context in which they were presented[<xref ref-type="bibr" rid="pcbi.1004953.ref073">73</xref>]. 69 Model 3, has recently been proposed to account for: i) the ability to perform similarity in both punishment and reward contexts; ii) counterfactual learning; and iii) inverted preferences for intermediate value cues (i.e. small gains and small losses) when assessed post-learning[<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>]. Model 3 updates option values in relation to the choice context in which they are presented. Since Model 1 and Model 2 can be considered as special cases of Model 3, we will describe only Model 3. We made a deliberate effort to keep these models as simple and parsimonious as possible. Model 3 tracks the mean of the distribution of values of the choice context and uses it to centre option values. Notably, this model represents a minimal departure from standard reinforcement learning algorithms that imply context or option values are updated with a delta rule, such as Q-learning and actor–critic algorithms[<xref ref-type="bibr" rid="pcbi.1004953.ref072">72</xref>]. Given our prior interest in the computational (dynamic) processes of learning, and also given that in our task we did not independently modulate outcome variance and valence, our model space did not include descriptive and aggregate economic models, such as cumulative prospect theory (CPT; [<xref ref-type="bibr" rid="pcbi.1004953.ref074">74</xref>]). Note, exploratory simulations showed that models with different learning rates for positive and negative prediction errors were not capable of discriminating between our task factors and predictions and were therefore not included (see <xref ref-type="supplementary-material" rid="pcbi.1004953.s001">S1 Text</xref> and <xref ref-type="supplementary-material" rid="pcbi.1004953.s009">S2 Fig</xref>).</p>
<p>At trial t the chosen (c) and the unchosen (u) option values of the current context (s) are updated with the Rescorla-Wagner rule (also called delta-rule)[<xref ref-type="bibr" rid="pcbi.1004953.ref012">12</xref>]:
<disp-formula id="pcbi.1004953.e001">
<alternatives>
<graphic id="pcbi.1004953.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
and
<disp-formula id="pcbi.1004953.e002">
<alternatives>
<graphic id="pcbi.1004953.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>The key idea behind Model 3 is that it separately learns and tracks the choice context value V(s). Crucially, the state value (V(s)) is not merely the sum of the option values, but rather it actively affects (controls) them. In fact V(s) is used to centre option prediction errors δ<sub>C</sub> and δ<sub>U</sub> as follows:
<disp-formula id="pcbi.1004953.e003">
<alternatives>
<graphic id="pcbi.1004953.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>–</mml:mo><mml:mtext> </mml:mtext><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>–</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
and
<disp-formula id="pcbi.1004953.e004">
<alternatives>
<graphic id="pcbi.1004953.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>–</mml:mo><mml:mtext> </mml:mtext><mml:mi>V</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>–</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
(in the Complete feedback contexts only, in the Partial feedback condition no counterfactual prediction error is calculated: <italic>δ</italic><sub><italic>U</italic>,<italic>t</italic></sub> <italic>= 0</italic>).</p>
<p>Consequently, the option values are no longer calculated on an absolute scale, but are relative to their choice context value <italic>V(s)</italic>. <italic>V(s)</italic> itself is learnt with a delta rule:
<disp-formula id="pcbi.1004953.e005">
<alternatives>
<graphic id="pcbi.1004953.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow/></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>α</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>α</italic><sub><italic>3</italic></sub> is the context value learning rate and δ<sub>V,t</sub> the context value prediction error, which is calculated as follows:
<disp-formula id="pcbi.1004953.e006">
<alternatives>
<graphic id="pcbi.1004953.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>V</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>–</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>R</italic><sub><italic>Tot</italic></sub>. is the average outcome of a trial and is calculated in the Complete feedback contexts as the average of the factual and the counterfactual outcomes as follows:
<disp-formula id="pcbi.1004953.e007">
<alternatives>
<graphic id="pcbi.1004953.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>U</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>/</mml:mo><mml:mtext> </mml:mtext><mml:mn>2</mml:mn><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Given that <italic>R</italic><sub><italic>Tot</italic></sub> is designed to be a measure that encompasses the value of both chosen and unchosen options, in order to incorporate the unchosen option in the Partial feedback trials we calculate <italic>R</italic><sub><italic>Tot</italic>,<italic>t</italic></sub> as follows:
<disp-formula id="pcbi.1004953.e008">
<alternatives>
<graphic id="pcbi.1004953.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>T</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>/</mml:mo><mml:mtext> </mml:mtext><mml:mn>2</mml:mn><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Model 2 can be derived from Model 3 by assuming no context value learning (<italic>α</italic><sub><italic>3</italic></sub> = 0). Model 1 can be derived from Model 2 by assuming no counterfactual learning (<italic>α</italic><sub><italic>2</italic></sub> = <italic>α</italic><sub><italic>3</italic></sub> = 0).</p>
<p>In all models decision-making relies on a softmax function. The probability of choosing the option ‘a’ over the option ‘b’ is given by:
<disp-formula id="pcbi.1004953.e009">
<alternatives>
<graphic id="pcbi.1004953.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>*</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>–</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>,</mml:mo><mml:mi>a</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>β</italic> is the inverse temperature parameter.</p>
</sec>
<sec id="sec023">
<title>Parameter optimisation and model selection procedure</title>
<p>In a first analysis, we optimised model parameters by minimising the negative log-likelihood of the data, given different parameter settings, using Matlab’s fmincon function initialised at different starting points, as described in [<xref ref-type="bibr" rid="pcbi.1004953.ref015">15</xref>] (ranges: 0&lt;<italic>β</italic>&lt;Infinite, and 0&lt; <italic>α</italic><sub><italic>n</italic></sub>&lt;1). Note that model fitting and parameter optimisation involved the learning (and not the post-learning) data. Negative log-likelihoods and inverse temperature parameters (β) were used to compare the between-group baseline quality of fit (without taking into account the model complexity) (<xref ref-type="supplementary-material" rid="pcbi.1004953.s004">S1 Table</xref>). In a second analysis, we optimised model parameters by minimising the Laplace approximation to the model evidence (LPP):
<disp-formula id="pcbi.1004953.e010">
<alternatives>
<graphic id="pcbi.1004953.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004953.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mrow><mml:mi>L</mml:mi><mml:mi>P</mml:mi><mml:mi>P</mml:mi><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Σ</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>|</mml:mo><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where D, M and θ represent the data, model and model parameters, respectively (<xref ref-type="supplementary-material" rid="pcbi.1004953.s005">S2 Table</xref>). The LPP increases with the likelihood (a measure of quality of fit) and is penalised by the size of the parameter space (a measure of model complexity). Thus, the LPP represents a trade-off between accuracy and complexity and can guide model selection. In addition, LPP maximisation, by including priors over the parameters, avoids degenerate parameter estimates, due to the small number of trials and the noisiness of the data. To avoid bias in model selection the same priors were used for the adolescent and adult group. Individual LPPs were fed into the mbb-vb-toolbox (<ext-link ext-link-type="uri" xlink:href="https://code.google.com/p/mbb-vb-toolbox/" xlink:type="simple">https://code.google.com/p/mbb-vb-toolbox/</ext-link>)[<xref ref-type="bibr" rid="pcbi.1004953.ref030">30</xref>], a procedure that estimates the expected frequencies and the exceedance probability for each model within a set of models, given the data gathered from all participants. Expected frequency is a quantification of the posterior probability of the model (denoted PP), i.e. the probability of the model generating the data obtained from any randomly selected participant. Exceedance probability (denoted XP) is the probability that a given model fits the data better than all other models in the set, i.e. has the highest PP. PP has an advantage over likelihood ratios as it can be directly compared between subjects (log likelihood ratios are calculated within subjects), which was necessary as our aim was to compare model fitting between age groups. Moreover, we validated the superior sensitivity of our model comparison procedure compared to the BIC using model simulation (see <xref ref-type="supplementary-material" rid="pcbi.1004953.s002">S2 Text</xref>). We submitted the negative log-likelihoods, the inverse temperature parameters (β) and the PP to a mixed-design ANOVA with group (Adolescents vs Adults) as the between-subjects factor and model (Models 1–3) as the within-subjects factor. Post-hoc comparisons (2-sided) were conducted using independent samples t-tests when comparing between groups, and one-sample t-tests when comparing within group and against chance-level. In a control analysis, we fitted the model to maximise the negative log-likelihood and the LPP, assuming a single set of parameters for each level (group-level optimisation) (see Tables <xref ref-type="table" rid="pcbi.1004953.t001">1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1004953.s004">S1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1004953.s005">S2</xref> and <xref ref-type="supplementary-material" rid="pcbi.1004953.s006">S3</xref>).</p>
</sec>
<sec id="sec024">
<title>Model simulations</title>
<p>We performed both ex-ante and ex-post model simulations. Ex-ante model simulations, in which we simulated data from 1000 virtual participants, were used to illustrate the properties of each model. The parameter values used in these simulation were <italic>β</italic> = 5.0, <italic>α</italic><sub><italic>n</italic></sub> = 0.3, similar to values observed in previous studies [<xref ref-type="bibr" rid="pcbi.1004953.ref075">75</xref>,<xref ref-type="bibr" rid="pcbi.1004953.ref076">76</xref>]. Note that using different parameter values led to very similar results. For each model, we analysed the model estimates of the option values (Q(state, action)) and decision values (ΔQ(state) <xref ref-type="fig" rid="pcbi.1004953.g002">Fig 2B</xref>), both of which are associated with different aspects of task performance. In the learning task, performance is a function of the learned difference in Q-values (ΔQ(state)) between the correct and incorrect option (decision value); in contrast, preference in the post-learning test allows inferences to be made about the value of individual options, which cannot be directly inferred from learning performance. Ex-ante model simulations were not submitted to statistical testing because the “N” is arbitrary.</p>
<p>Once we had optimised the model parameters, we used ex-post model simulations of the data to assess their generative performance by analysing the model simulation of the data[<xref ref-type="bibr" rid="pcbi.1004953.ref077">77</xref>] (“ex-post” model simulations). Model estimates of choice probability were generated on a trial-by-trial basis using the individual history of choices and outcomes. For each participant, we used their best fitting set of model parameters from their age group’s best fitting model (i.e. Model 1 for adolescents; Model 3 for adults). Model-simulated correct choice probability was then submitted to the same statistical analysis that was used to assess the actual choices made by participants in the learning task. Note that qualitative discrepancies between actual and simulated data at the beginning of the learning curve should be interpreted with caution. In fact, in the behavioural data the variance is higher in the early trials and then progressively decreases due to integrating over the past trials, whereas in model simulations the variance follows a different trajectory. By definition, the variance is zero in the first trial, in which the probability of a correct response is 0.5 for all virtual participants/contexts and then progressively increases following individual histories of choice and outcomes, as well as individual differences in free parameters.</p>
</sec>
</sec>
<sec id="sec025">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004953.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Supplementary model comparison: Value contextualisation without counterfactual learning.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004953.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Supplementary model simulations (I): Validation of the model comparison procedure.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004953.s003" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s003" xlink:type="simple">
<label>S3 Text</label>
<caption>
<title>Supplementary model simulations (II): Different learning rates for positive and negative prediction errors.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004953.s004" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s004" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Negative log-likelihood maximisation.</title>
<p>Random: random model that assumes chance performance for all trials; p(correct choice) = 0.5. Subject-level: parameter optimization assumes a set of free parameters per subject. Group-level: parameter optimisation assumes a single set of free parameters per age group.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004953.s005" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s005" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>Model parameters.</title>
<p>Parameters were optimised by minimising the Laplace approximation to the model evidence (LPP). Note that the group-level, adolescents were systematically fitted with α2 = α3 = 0 (basic Q-learning), whereas adults were fitted with α2&gt;0 and α3&gt;0 whenever the model allowed the parameter to be different from zero. Data are reported as mean±s.e.m. β: inverse temperature; α1: factual learning rate; α2: counterfactual learning rate; α3: contextual learning rate. Subject-level: parameter optimisation assumes a set of free parameters per subject. Group-level: parameter optimisation assumes a single set of free parameters per age group.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004953.s006" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s006" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>Log-likelihood differences.</title>
<p>For each pair of models we calculated the log likelihood difference multiplied by 2, which is a log-scale analogue of the likelihood ratio. M1 to M3: Model 1 to 3. M0: the random model. Subject-level: parameter optimisation assumes a set of free parameters per subject. Group-level: parameter optimisation assumes a single set of free parameters per age group. “Adoles. % of Adults”: indicates the percentage of likelihood difference improvement observed in the Adolescent group compared to the Adult group (when accounting for the different number of subjects).</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004953.s007" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s007" xlink:type="simple">
<label>S4 Table</label>
<caption>
<title>Supplementary model comparison.</title>
<p>PP: posterior probability. XP: exceedance probability. Model 1: α<sub>2</sub> = α<sub>3</sub> = 0; Model 2: α<sub>3</sub> = 0; Model 4: α<sub>2</sub> = 0. PP are reported as mean±s.e.m.</p>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004953.s008" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s008" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Validation of the model comparison procedure.</title>
<p><bold>(A</bold>) Virtual groups’ parameters and simulated data, plotted as a function of task context. <bold>(B)</bold> Possible and obtained model comparison results for Group 1 (light grey) and Group 2 (dark grey): better fit is indicated by a higher PP and lower BIC, respectively.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004953.s009" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004953.s009" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Model simulation involving different learning rates for positive and negative prediction errors.</title>
<p>The value of the β was 5.0 as in the other ex-ante model simulations. The number of virtual participants was N = 1000.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Ashok Sakhardande, Delia Fuhrmann and Emily Garrett for helping with behavioural testing.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004953.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Steinberg</surname> <given-names>L</given-names></name>. <article-title>Cognitive and affective development in adolescence</article-title>. <source>Trends Cogn Sci</source>. <year>2005</year>;<volume>9</volume>: <fpage>69</fpage>–<lpage>74</lpage>. <object-id pub-id-type="pmid">15668099</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blakemore</surname> <given-names>S-J</given-names></name>, <name name-style="western"><surname>Robbins</surname> <given-names>TW</given-names></name>. <article-title>Decision-making in the adolescent brain</article-title>. <source>Nat Neurosci. Nature Publishing Group</source>; <year>2012</year>;<volume>15</volume>: <fpage>1184</fpage>–<lpage>91</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sercombe</surname> <given-names>H</given-names></name>. <article-title>Risk, adaptation and the functional teenage brain</article-title>. <source>Brain Cogn</source>. <year>2014</year>;<volume>89</volume>: <fpage>61</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.bandc.2014.01.001" xlink:type="simple">10.1016/j.bandc.2014.01.001</ext-link></comment> <object-id pub-id-type="pmid">24468052</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willoughby</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Good</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Adachi</surname> <given-names>PJC</given-names></name>, <name name-style="western"><surname>Hamza</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Tavernier</surname> <given-names>R</given-names></name>. <article-title>Brain and Cognition Examining the link between adolescent brain development and risk taking from a social—developmental perspective</article-title>. <source>Brain Cogn. Elsevier Inc</source>.; <year>2013</year>;<volume>83</volume>: <fpage>315</fpage>–<lpage>323</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blakemore</surname> <given-names>S-J</given-names></name>, <name name-style="western"><surname>Mills</surname> <given-names>KL</given-names></name>. <article-title>Is adolescence a sensitive period for sociocultural processing?</article-title> <source>Annu Rev Psychol</source>. <year>2014</year>;<volume>65</volume>: <fpage>187</fpage>–<lpage>207</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev-psych-010213-115202" xlink:type="simple">10.1146/annurev-psych-010213-115202</ext-link></comment> <object-id pub-id-type="pmid">24016274</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Casey</surname> <given-names>BJ</given-names></name>. <article-title>Beyond Simple Models of Self-Control to Circuit-Based Accounts of Adolescent Behavior</article-title>. <source>Annu Rev Psychol</source>. <year>2014</year>; <fpage>1</fpage>–<lpage>25</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Viner</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Coffey</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Mathers</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bloem</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Costello</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Santelli</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>50-year mortality trends in children and young people: A study of 50 low-income, middle-income, and high-income countries</article-title>. <source>Lancet</source>. <year>2011</year>;<volume>377</volume>: <fpage>1162</fpage>–<lpage>1174</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0140-6736(11)60106-2" xlink:type="simple">10.1016/S0140-6736(11)60106-2</ext-link></comment> <object-id pub-id-type="pmid">21450338</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Viner</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Ozer</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Denny</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Marmot</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Resnick</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fatusi</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Adolescent Health 2 Adolescence and the social determinants of health</article-title>. <source>Lancet. Elsevier Ltd</source>; <volume>379</volume>: <fpage>1641</fpage>–<lpage>1652</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rangel</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Camerer</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A framework for studying the neurobiology of value-based decision making</article-title>. <source>Nat Rev Neurosci</source>. <year>2008</year>;<volume>9</volume>: <fpage>545</fpage>–<lpage>556</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2357" xlink:type="simple">10.1038/nrn2357</ext-link></comment> <object-id pub-id-type="pmid">18545266</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref010"><label>10</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <chapter-title>Advanced Reinforcement Learning</chapter-title>. <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Fehr</surname> <given-names>E</given-names></name>, editors. <source>Neuroeconomics Decis Mak Brain Second Ed. Neuroecono</source>. <publisher-name>Academic Press</publisher-name>, <publisher-loc>London, UK</publisher-loc>; <year>2013</year>; <fpage>299</fpage>–<lpage>320</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watkins</surname> <given-names>CJCH</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Q-learning</article-title>. <source>Mach Learn</source>. <year>1992</year>;<volume>8</volume>: <fpage>279</fpage>–<lpage>292</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref012"><label>12</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Rescorla</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AR</given-names></name>. <chapter-title>A Theory of Pavlovian Conditioning: Variations in the Effectiveness of Reinforcement and Nonreinforcement</chapter-title>. In: <name name-style="western"><surname>Black</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Prokasy</surname> <given-names>WF</given-names></name>, editors. <source>Classical conditioning II: current research and theory</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Applenton-Century-Crofts</publisher-name>; <year>1972</year>. pp. <fpage>64</fpage>–<lpage>99</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boorman</surname> <given-names>ED</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MF</given-names></name>. <article-title>Counterfactual Choice and Learning in a Neural Network Centered on Human Lateral Frontopolar Cortex</article-title>. <source>PLoS Biol</source>. <year>2011</year>;<volume>9</volume>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fischer</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Ullsperger</surname> <given-names>M</given-names></name>. <article-title>Real and fictive outcomes are processed differently but converge on a common adaptive mechanism</article-title>. <source>Neuron. Elsevier Inc.</source>; <year>2013</year>;<volume>79</volume>: <fpage>1243</fpage>–<lpage>55</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Khamassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Joffily</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Coricelli</surname> <given-names>G</given-names></name>. <article-title>Contextual modulation of value signals in reward and punishment learning</article-title>. <source>Nat Commun</source>. <collab>Nature Publishing Group</collab>; <year>2015</year>;<volume>6</volume>: <fpage>8096</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/ncomms9096" xlink:type="simple">10.1038/ncomms9096</ext-link></comment> <object-id pub-id-type="pmid">26302782</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maia</surname> <given-names>T V</given-names></name>. <article-title>Two-factor theory, the actor-critic model, and conditioned avoidance</article-title>. <source>Learn Behav a Psychon Soc Publ</source>. <year>2010</year>;<volume>38</volume>: <fpage>50</fpage>–<lpage>67</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Serra</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Buot</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Welter</surname> <given-names>M-L</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>. <article-title>Hemispheric dissociation of reward processing in humans: Insights from deep brain stimulation</article-title>. <source>Cortex. Elsevier Ltd</source>; <year>2013</year>;</mixed-citation></ref>
<ref id="pcbi.1004953.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Deichmann</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title>. <source>Science</source>. <year>2004</year>;<volume>304</volume>: <fpage>452</fpage>–<lpage>454</lpage>. <object-id pub-id-type="pmid">15087550</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kahnt</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Heinzle</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Park</surname> <given-names>SQ</given-names></name>, <name name-style="western"><surname>Haynes</surname> <given-names>J-D</given-names></name>. <article-title>Decoding the formation of reward predictions across learning</article-title>. <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>: <fpage>14624</fpage>–<lpage>30</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3412-11.2011" xlink:type="simple">10.1523/JNEUROSCI.3412-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21994378</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ullsperger</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fischer</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Nigbur</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Endrass</surname> <given-names>T</given-names></name>. <article-title>Neural mechanisms and temporal dynamics of performance monitoring</article-title>. <source>Trends Cogn Sci. Elsevier Ltd</source>; <year>2014</year>; <fpage>1</fpage>–<lpage>9</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>An evolutionary computational theory of prefrontal executive function in decision-making An evolutionary computational theory of prefrontal executive function in decision-making</article-title>. <source>Phil Trans R Soc B</source>. <year>2014</year>;<volume>369</volume>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Justo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Jauffret</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Pavlicek</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dauta</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Delmaire</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Critical Roles for Anterior Insula and Dorsal Striatum in Punishment-Based Avoidance Learning</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>76</volume>: <fpage>998</fpage>–<lpage>1009</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.10.017" xlink:type="simple">10.1016/j.neuron.2012.10.017</ext-link></comment> <object-id pub-id-type="pmid">23217747</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Casey</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Galvan</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hare</surname> <given-names>TA</given-names></name>. <article-title>Changes in cerebral functional organization during cognitive development</article-title>. <source>Curr Opin Neurobiol</source>. <year>2005</year>;<volume>15</volume>: <fpage>239</fpage>–<lpage>44</lpage>. <object-id pub-id-type="pmid">15831409</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ernst</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fudge</surname> <given-names>JL</given-names></name>. <article-title>A developmental neurobiological model of motivated behavior: Anatomy, connectivity and ontogeny of the triadic nodes</article-title>. <source>Neurosci Biobehav Rev</source>. <year>2009</year>;<volume>33</volume>: <fpage>367</fpage>–<lpage>382</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neubiorev.2008.10.009" xlink:type="simple">10.1016/j.neubiorev.2008.10.009</ext-link></comment> <object-id pub-id-type="pmid">19028521</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Casey</surname> <given-names>BJ</given-names></name>. <article-title>Beyond simple models of self-control to circuit-based accounts of adolescent behavior</article-title>. <source>Annu Rev Psychol. Annual Reviews</source>; <year>2015</year>;<volume>66</volume>: <fpage>295</fpage>–<lpage>319</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shulman</surname> <given-names>EP</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Silva</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Icenogle</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Duell</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Chein</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>The Dual Systems Model: Review, Reappraisal, and Reaffirmation</article-title>. <source>Dev Cogn Neurosci</source>. <year>2015</year>;<volume>17</volume>: <fpage>103</fpage>–<lpage>117</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.dcn.2015.12.010" xlink:type="simple">10.1016/j.dcn.2015.12.010</ext-link></comment> <object-id pub-id-type="pmid">26774291</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Camerer</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Ho</surname> <given-names>T-H</given-names></name>, <name name-style="western"><surname>Chong</surname> <given-names>J-K</given-names></name>. <article-title>A cognitive hierarchy model of games</article-title>. <source>Q J Econ</source>. <year>2004</year>;<volume>119</volume>: <fpage>861</fpage>–<lpage>898</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vlaev</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Stewart</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>GD</given-names></name> a. <article-title>Does the brain calculate value?</article-title> <source>Trends Cogn Sci. Elsevier Ltd</source>; <year>2011</year>;<volume>15</volume>: <fpage>546</fpage>–<lpage>554</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Maruyama</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>De Martino</surname> <given-names>B</given-names></name>. <article-title>When is a loss a loss? Excitatory and inhibitory processes in loss-related decision-making</article-title>. <source>Curr Opin Behav Sci</source>. <year>2015</year>;<volume>5</volume>: <fpage>122</fpage>–<lpage>127</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Adam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Rigoux</surname> <given-names>L</given-names></name>. <article-title>VBA: A Probabilistic Treatment of Nonlinear Models for Neurobiological and Behavioural Data</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>: <fpage>e1003441</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003441" xlink:type="simple">10.1371/journal.pcbi.1003441</ext-link></comment> <object-id pub-id-type="pmid">24465198</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shenhav</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Straccia</surname> <given-names>M a</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>MM</given-names></name>. <article-title>Anterior cingulate engagement in a foraging context reflects choice difficulty, not foraging value</article-title>. <source>Nat Neurosci. Nature Publishing Group</source>; <year>2014</year>;<volume>17</volume>: <fpage>1249</fpage>–<lpage>1254</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guitart-Masip</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Duzel</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Action versus valence in decision making</article-title>. <source>Trends Cogn Sci. Elsevier Ltd</source>; <year>2014</year>;<volume>18</volume>: <fpage>194</fpage>–<lpage>202</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Seeberger</surname> <given-names>LC</given-names></name>, <name name-style="western"><surname>Reilly</surname> <given-names>RCO</given-names></name>, <name name-style="western"><surname>O’Reilly</surname> <given-names>RC</given-names></name>. <article-title>By carrot or by stick: cognitive reinforcement learning in parkinsonism</article-title>. <source>Science</source>. <year>2004</year>;<volume>306</volume>: <fpage>1940</fpage>–<lpage>3</lpage>. <object-id pub-id-type="pmid">15528409</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wimmer</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Shohamy</surname> <given-names>D</given-names></name>. <article-title>Preference by Association: How Memory Mechanisms in the Hippocampus Bias Decisions</article-title>. <source>Science (80-)</source>. <year>2012</year>;<volume>338</volume>: <fpage>270</fpage>–<lpage>273</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Twenty-five lessons from computational neuromodulation</article-title>. <source>Neuron. Elsevier Inc.</source>; <year>2012</year>;<volume>76</volume>: <fpage>240</fpage>–<lpage>56</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lebreton</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Worbe</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Grabli</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hartmann</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>. <article-title>Pharmacological modulation of subliminal learning in Parkinson’s and Tourette's syndromes</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2009</year>;<volume>106</volume>: <fpage>19179</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0904035106" xlink:type="simple">10.1073/pnas.0904035106</ext-link></comment> <object-id pub-id-type="pmid">19850878</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Flandin</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Frith</surname> <given-names>CD</given-names></name>. <article-title>Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title>. <source>Nature</source>. <year>2006</year>;<volume>442</volume>: <fpage>1042</fpage>–<lpage>5</lpage>. <object-id pub-id-type="pmid">16929307</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Benes</surname> <given-names>FM</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>MC</given-names></name>. <article-title>Convergence and plasticity of monoaminergic systems in the medial prefrontal cortex during the postnatal period: implications for the development of psychopathology</article-title>. <source>Cereb Cortex</source>. <year>2000</year>;<volume>10</volume>: <fpage>1014</fpage>–<lpage>27</lpage>. Available: <ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/11007552" xlink:type="simple">http://www.ncbi.nlm.nih.gov/pubmed/11007552</ext-link> <object-id pub-id-type="pmid">11007552</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brenhouse</surname> <given-names>HC</given-names></name>, <name name-style="western"><surname>Sonntag</surname> <given-names>KC</given-names></name>, <name name-style="western"><surname>Andersen</surname> <given-names>SL</given-names></name>. <article-title>Transient D1 dopamine receptor expression on prefrontal cortex projection neurons: relationship to enhanced motivational salience of drug cues in adolescence</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>: <fpage>2375</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5064-07.2008" xlink:type="simple">10.1523/JNEUROSCI.5064-07.2008</ext-link></comment> <object-id pub-id-type="pmid">18322084</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mills</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Goddings</surname> <given-names>A-L</given-names></name>, <name name-style="western"><surname>Clasen</surname> <given-names>LS</given-names></name>, <name name-style="western"><surname>Giedd</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Blakemore</surname> <given-names>S-J</given-names></name>. <article-title>The developmental mismatch in structural brain maturation during adolescence</article-title>. <source>Dev Neurosci. Karger Publishers</source>; <year>2014</year>;<volume>36</volume>: <fpage>147</fpage>–<lpage>60</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Giedd</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Blumenthal</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Jeffries</surname> <given-names>NO</given-names></name>, <name name-style="western"><surname>Castellanos</surname> <given-names>FX</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Zijdenbos</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Brain development during childhood and adolescence: a longitudinal MRI study</article-title>. <source>Nat Neurosci</source>. <year>1999</year>;<volume>2</volume>: <fpage>861</fpage>–<lpage>3</lpage>. <object-id pub-id-type="pmid">10491603</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Somerville</surname> <given-names>LH</given-names></name>, <name name-style="western"><surname>Hare</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Casey</surname> <given-names>BJ</given-names></name>. <article-title>Frontostriatal maturation predicts cognitive control failure to appetitive cues in adolescents</article-title>. <source>J Cogn Neurosci</source>. <year>2011</year>;<volume>23</volume>: <fpage>2123</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.2010.21572" xlink:type="simple">10.1162/jocn.2010.21572</ext-link></comment> <object-id pub-id-type="pmid">20809855</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gogtay</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Giedd</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Lusk</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Hayashi</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Greenstein</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Vaituzis</surname> <given-names>aC</given-names></name>, <etal>et al</etal>. <article-title>Dynamic mapping of human cortical development during childhood through early adulthood</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2004</year>;<volume>101</volume>: <fpage>8174</fpage>–<lpage>9</lpage>. <object-id pub-id-type="pmid">15148381</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Figner</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Mackinlay</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Wilkening</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Weber</surname> <given-names>EU</given-names></name>. <article-title>Affective and deliberative processes in risky choice: Age differences in risk taking in the Columbia Card Task</article-title>. <source>J Exp Psychol Learn Mem Cogn</source>. <year>2009</year>;<volume>35</volume>: <fpage>709</fpage>–<lpage>730</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0014983" xlink:type="simple">10.1037/a0014983</ext-link></comment> <object-id pub-id-type="pmid">19379045</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doll</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Simon</surname> <given-names>D a.</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>The ubiquity of model-based reinforcement learning</article-title>. <source>Curr Opin Neurobiol. Elsevier Ltd</source>; <year>2012</year>;<volume>22</volume>: <fpage>1075</fpage>–<lpage>81</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>McNamee</surname> <given-names>D</given-names></name>. <article-title>The structure of reinforcement-learning mechanisms in the human brain</article-title>. <source>Curr Opin Behav Sci. Elsevier Ltd</source>; <year>2015</year>;<volume>1</volume>: <fpage>94</fpage>–<lpage>100</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gläscher</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>. <article-title>States versus rewards: Dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</article-title>. <source>Neuron. Elsevier Ltd</source>; <year>2010</year>;<volume>66</volume>: <fpage>585</fpage>–<lpage>595</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smittenaar</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>FitzGerald</surname> <given-names>THB</given-names></name>, <name name-style="western"><surname>Romei</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Wright</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Disruption of Dorsolateral Prefrontal Cortex Decreases Model-Based in Favor of Model-free Control in Humans</article-title>. <source>Neuron. The Authors</source>; <year>2013</year>;<volume>80</volume>: <fpage>914</fpage>–<lpage>919</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>: <fpage>1704</fpage>–<lpage>1711</lpage>. <object-id pub-id-type="pmid">16286932</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Casey</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Galván</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Somerville</surname> <given-names>LH</given-names></name>. <article-title>Beyond simple models of adolescence to an integrated circuit-based account: A commentary</article-title>. <source>Dev Cogn Neurosci</source>. <year>2015</year>;<volume>17</volume>: <fpage>128</fpage>–<lpage>130</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.dcn.2015.12.006" xlink:type="simple">10.1016/j.dcn.2015.12.006</ext-link></comment> <object-id pub-id-type="pmid">26739434</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Christakou</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Simmons</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Brammer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rubia</surname> <given-names>K</given-names></name>. <article-title>Neural and psychological maturation of decision-making in adolescence and young adulthood</article-title>. <source>J Cogn Neurosci</source>. <year>2013</year>;<volume>25</volume>: <fpage>1807</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn_a_00447" xlink:type="simple">10.1162/jocn_a_00447</ext-link></comment> <object-id pub-id-type="pmid">23859647</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Javadi</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>DHK</given-names></name>, <name name-style="western"><surname>Smolka</surname> <given-names>MN</given-names></name>. <article-title>Adolescents adapt more slowly than adults to varying reward contingencies</article-title>. <source>J Cogn Neurosci</source>. <year>2014</year>;<volume>26</volume>: <fpage>2670</fpage>–<lpage>81</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn_a_00677" xlink:type="simple">10.1162/jocn_a_00677</ext-link></comment> <object-id pub-id-type="pmid">24960048</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Duijvenvoorde</surname> <given-names>ACK</given-names></name>, <name name-style="western"><surname>Zanolie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Rombouts</surname> <given-names>SARB</given-names></name>, <name name-style="western"><surname>Raijmakers</surname> <given-names>MEJ</given-names></name>, <name name-style="western"><surname>Crone</surname> <given-names>EA</given-names></name>. <article-title>Evaluating the negative or valuing the positive? Neural mechanisms supporting feedback-based learning across development</article-title>. <source>J Neurosci. Society for Neuroscience</source>; <year>2008</year>;<volume>28</volume>: <fpage>9495</fpage>–<lpage>503</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Den Bos</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Gürog</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Van Den Bulk</surname> <given-names>BG</given-names></name>, <name name-style="western"><surname>Rombouts</surname> <given-names>SARB</given-names></name>, <name name-style="western"><surname>Crone</surname> <given-names>EA</given-names></name>. <article-title>Better than expected or as bad as you thought? The neurocognitive development of probabilistic feedback processing</article-title>. <source>Front Hum Neurosci</source>. <year>2009</year>;<volume>3</volume>: <fpage>52</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.09.052.2009" xlink:type="simple">10.3389/neuro.09.052.2009</ext-link></comment> <object-id pub-id-type="pmid">20140268</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Der Schaaf</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Warmerdam</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Crone</surname> <given-names>E a.</given-names></name>, <name name-style="western"><surname>Cools</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Van Der Schaaf</surname> <given-names>ME</given-names></name>. <article-title>Distinct linear and non-linear trajectories of reward and punishment reversal learning during development: Relevance for dopamine’s role in adolescent decision making</article-title>. <source>Dev Cogn Neurosci. Elsevier Ltd</source>; <year>2011</year>;<volume>1</volume>: <fpage>578</fpage>–<lpage>590</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hämmerer</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>S-C</given-names></name>, <name name-style="western"><surname>Müller</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Lindenberger</surname> <given-names>U</given-names></name>. <article-title>Life span differences in electrophysiological correlates of monitoring gains and losses during probabilistic reinforcement learning</article-title>. <source>J Cogn Neurosci</source>. <year>2011</year>;<volume>23</volume>: <fpage>579</fpage>–<lpage>592</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.2010.21475" xlink:type="simple">10.1162/jocn.2010.21475</ext-link></comment> <object-id pub-id-type="pmid">20377358</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guitart-Masip</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Huys</surname> <given-names>QJM</given-names></name>, <name name-style="western"><surname>Fuentemilla</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Duzel</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Go and no-go learning in reward and punishment: interactions between affect and effect</article-title>. <source>Neuroimage. Elsevier Inc</source>.; <year>2012</year>;<volume>62</volume>: <fpage>154</fpage>–<lpage>66</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olsson</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Phelps</surname> <given-names>EA</given-names></name>. <article-title>Social learning of fear</article-title>. <source>Nat Neurosci. Nature Publishing Group</source>; <year>2007</year>;<volume>10</volume>: <fpage>1095</fpage>–<lpage>1102</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref059"><label>59</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>. <chapter-title>Opponent brain systems for reward and punishment learning: causal evidence from drug and lesion studies in humans</chapter-title>. In: <name name-style="western"><surname>Tremblay</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Dreher</surname> <given-names>J-C</given-names></name>, editors. <source>Decision Neuroscience</source>. <publisher-name>Academic Press</publisher-name>, <publisher-loc>London, UK</publisher-loc>;</mixed-citation></ref>
<ref id="pcbi.1004953.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hämmerer</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Eppinger</surname> <given-names>B</given-names></name>. <article-title>Dopaminergic and prefrontal contributions to reward-based learning and outcome monitoring during child development and aging</article-title>. <source>Dev Psychol</source>. <year>2012</year>;<volume>48</volume>: <fpage>862</fpage>–<lpage>874</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0027342" xlink:type="simple">10.1037/a0027342</ext-link></comment> <object-id pub-id-type="pmid">22390655</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>X-J</given-names></name>, <name name-style="western"><surname>Krystal</surname> <given-names>JH</given-names></name>. <article-title>Computational Psychiatry</article-title>. <source>Neuron. Elsevier Inc.</source>; <year>2014</year>;<volume>84</volume>: <fpage>638</fpage>–<lpage>654</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Hampton</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>H</given-names></name>. <article-title>Model-based fMRI and its application to reward learning and decision making</article-title>. <source>Ann N Y Acad Sci</source>. <year>2007</year>;<volume>1104</volume>: <fpage>35</fpage>–<lpage>53</lpage>. <object-id pub-id-type="pmid">17416921</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Asarnow</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Sabb</surname> <given-names>FW</given-names></name>, <name name-style="western"><surname>Bilder</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Bookheimer</surname> <given-names>SY</given-names></name>, <name name-style="western"><surname>Knowlton</surname> <given-names>BJ</given-names></name>, <etal>et al</etal>. <article-title>A unique adolescent response to reward prediction errors</article-title>. <source>Nat Neurosci. Nature Publishing Group</source>; <year>2010</year>;<volume>13</volume>: <fpage>669</fpage>–<lpage>671</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Bos</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>MX</given-names></name>, <name name-style="western"><surname>Kahnt</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Crone</surname> <given-names>E a</given-names></name>. <article-title>Striatum-medial prefrontal cortex connectivity predicts developmental changes in reinforcement learning</article-title>. <source>Cereb Cortex. Oxford University Press</source>; <year>2012</year>;<volume>22</volume>: <fpage>1247</fpage>–<lpage>55</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Javadi</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>DHK</given-names></name>, <name name-style="western"><surname>Smolka</surname> <given-names>MN</given-names></name>. <article-title>Adolescents Adapt More Slowly than Adults to Varying Reward Contingencies</article-title>. <source>J Cogn Neurosci</source>. <year>2010</year>; <fpage>2670</fpage>–<lpage>2681</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van den Bos</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Eppinger</surname> <given-names>B</given-names></name>. <article-title>Developing developmental cognitive neuroscience: From agenda setting to hypothesis testing</article-title>. <source>Dev Cogn Neurosci. Elsevier Ltd</source>; <year>2015</year>;<volume>17</volume>: <fpage>138</fpage>–<lpage>144</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maia T</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>From reinforcement learning models to psychiatric and neurological disorders</article-title>. <source>Nat Neurosci. Nature Publishing Group</source>; <year>2011</year>;<volume>14</volume>: <fpage>154</fpage>–<lpage>62</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paus</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Keshavan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Giedd</surname> <given-names>JN</given-names></name>. <article-title>Why do many psychiatric disorders emerge during adolescence?</article-title> <source>Nat Rev Neurosci</source>. <year>2008</year>;<volume>9</volume>: <fpage>947</fpage>–<lpage>957</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2513" xlink:type="simple">10.1038/nrn2513</ext-link></comment> <object-id pub-id-type="pmid">19002191</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sigman</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Peña</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Goldin</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Ribeiro</surname> <given-names>S</given-names></name>. <article-title>Neuroscience and education: prime time to build the bridge</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>: <fpage>497</fpage>–<lpage>502</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3672" xlink:type="simple">10.1038/nn.3672</ext-link></comment> <object-id pub-id-type="pmid">24671066</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref070"><label>70</label><mixed-citation publication-type="other" xlink:type="simple">Wechsler D. Wechsler abbreviated scale of intelligence. 1999; Available: <ext-link ext-link-type="uri" xlink:href="https://scholar.google.com/scholar_lookup?title=Wechslerabbreviatedscaleofintelligence&amp;author=Wechsler&amp;publication_year=1999#0" xlink:type="simple">https://scholar.google.com/scholar_lookup?title=Wechslerabbreviatedscaleofintelligence&amp;author=Wechsler&amp;publication_year=1999#0</ext-link></mixed-citation></ref>
<ref id="pcbi.1004953.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lebreton</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Worbe</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hartmann</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lehéricy</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Vidailhet</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Dopamine-dependent reinforcement of motor skill learning: evidence from Gilles de la Tourette syndrome</article-title>. <source>Brain</source>. <year>2011</year>;<volume>134</volume>: <fpage>2287</fpage>–<lpage>301</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/brain/awr147" xlink:type="simple">10.1093/brain/awr147</ext-link></comment> <object-id pub-id-type="pmid">21727098</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref072"><label>72</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>. <source>Reinforcement Learning: An Introduction</source>. <publisher-loc>Cambridge</publisher-loc>. <publisher-name>MIT Press</publisher-name>; <year>1998</year>.</mixed-citation></ref>
<ref id="pcbi.1004953.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Louie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Efficient coding and the neural representation of value</article-title>. <source>Ann N Y Acad Sci</source>. <year>2012</year>;<volume>1251</volume>: <fpage>13</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1749-6632.2012.06496.x" xlink:type="simple">10.1111/j.1749-6632.2012.06496.x</ext-link></comment> <object-id pub-id-type="pmid">22694213</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref074"><label>74</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsu</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Krajbich</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Camerer</surname> <given-names>CF</given-names></name>. <article-title>Neural response to reward anticipation under risk is nonlinear in probabilities</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>: <fpage>2231</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5296-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5296-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19228976</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Palminteri</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Justo</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Jauffret</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Pavlicek</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dauta</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Delmaire</surname> <given-names>C</given-names></name>, <etal>et al</etal>. <article-title>Critical Roles for Anterior Insula and Dorsal Striatum in Punishment-Based Avoidance Learning</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>76</volume>: <fpage>998</fpage>–<lpage>1009</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.10.017" xlink:type="simple">10.1016/j.neuron.2012.10.017</ext-link></comment> <object-id pub-id-type="pmid">23217747</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Signals in Human Striatum Are Appropriate for Policy Update Rather than Value Prediction</article-title>. <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>: <fpage>5504</fpage>–<lpage>5511</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.6316-10.2011" xlink:type="simple">10.1523/JNEUROSCI.6316-10.2011</ext-link></comment> <object-id pub-id-type="pmid">21471387</object-id></mixed-citation></ref>
<ref id="pcbi.1004953.ref077"><label>77</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Corrado</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Sugrue</surname> <given-names>LP</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>. <chapter-title>The Trouble with Choice : Studying Decision Variables in the Brain</chapter-title>. In: <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Fehr</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Camerer</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Poldrack</surname> <given-names>R a</given-names></name>, editors. <source>Neuroeconomics: Decision Making and the Brain</source>. <edition>2009th ed</edition>. <publisher-name>Academic Press</publisher-name>, <publisher-loc>London, UK</publisher-loc>; <year>2009</year>. pp. <fpage>463</fpage>–<lpage>480</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-00696</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003859</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Ensembles of Spiking Neurons with Noise Support Optimal Probabilistic Inference in a Dynamically Changing Environment</article-title>
<alt-title alt-title-type="running-head">Ensembles of Spiking Neurons Support Probabilistic Inference</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Legenstein</surname><given-names>Robert</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Maass</surname><given-names>Wolfgang</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
</contrib-group>
<aff id="aff1"><addr-line>Institute for Theoretical Computer Science, Graz University of Technology, Graz, Austria</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">robert.legenstein@igi.tugraz.at</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: RL WM. Performed the experiments: RL. Analyzed the data: RL WM. Wrote the paper: RL WM.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>10</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>23</day><month>10</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>10</issue>
<elocation-id>e1003859</elocation-id>
<history>
<date date-type="received"><day>22</day><month>4</month><year>2014</year></date>
<date date-type="accepted"><day>16</day><month>8</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Legenstein, Maass</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>It has recently been shown that networks of spiking neurons with noise can emulate simple forms of probabilistic inference through “neural sampling”, i.e., by treating spikes as samples from a probability distribution of network states that is encoded in the network. Deficiencies of the existing model are its reliance on single neurons for sampling from each random variable, and the resulting limitation in representing quickly varying probabilistic information. We show that both deficiencies can be overcome by moving to a biologically more realistic encoding of each salient random variable through the stochastic firing activity of an ensemble of neurons. The resulting model demonstrates that networks of spiking neurons with noise can easily track and carry out basic computational operations on rapidly varying probability distributions, such as the odds of getting rewarded for a specific behavior. We demonstrate the viability of this new approach towards neural coding and computation, which makes use of the inherent parallelism of generic neural circuits, by showing that this model can explain experimentally observed firing activity of cortical neurons for a variety of tasks that require rapid temporal integration of sensory information.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>The Markov Chain Monte Carlo (MCMC) approach to probabilistic inference for a distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e001" xlink:type="simple"/></inline-formula> is to draw a sequence of samples from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e002" xlink:type="simple"/></inline-formula> and to carry out computational operations via simple online computations on such a sequence. But such a sequential computational process takes time, and therefore this simple version of the MCMC approach runs into problems when one needs to carry out probabilistic inference for rapidly varying distributions. This difficulty also affects all currently existing models for emulating MCMC sampling by networks of stochastically firing neurons. We show here that by moving to a space-rate approach where salient probabilities are encoded through the spiking activity of ensembles of neurons, rather than by single neurons, this problem can be solved. In this way even theoretically optimal models for dealing with time varying distributions through sequential Monte Carlo sampling, so called particle filters, can be emulated by networks of spiking neurons. Each spike of a neuron in an ensemble represents in this approach a “particle” (or vote) for a particular value of a time-varying random variable. In other words, neural circuits can speed up computations based on Monte Carlo sampling through their inherent parallelism.</p>
</abstract>
<funding-group><funding-statement>Written under partial support by the European Union project #604102 (HBP) and the Austrian Science Fund FWF #I753-N23 (PNEUMA). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="27"/></counts><custom-meta-group><custom-meta id="data-availability" xlink:type="simple"><meta-name>Data Availability</meta-name><meta-value>The authors confirm that all data underlying the findings are fully available without restriction. All relevant data are within the paper and its Supporting Information files.</meta-value></custom-meta></custom-meta-group></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Humans and animals are confronted with various situations where the state of some behaviorally relevant time-varying random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e003" xlink:type="simple"/></inline-formula> is only accessible through noisy observations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e004" xlink:type="simple"/></inline-formula>. It is then essential to estimate the current value of that random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e005" xlink:type="simple"/></inline-formula>, and to update this belief on the basis of further evidence. Over the last three decades we have learned from various experiments that monkeys are able to perform such operations. In the classical random-dot motion task, monkeys are confronted with dots on a screen moving in random directions, where a random subset of dots moves coherently. Monkeys are able to determine the direction of coherent motion even for low coherency levels <xref ref-type="bibr" rid="pcbi.1003859-Gold1">[1]</xref>. A more recent study has shown that the firing rate of neurons in parietal cortex are proportional to the momentary log-likelihood ratio of a rewarded action for the given sensory evidence <xref ref-type="bibr" rid="pcbi.1003859-Yang1">[2]</xref>, suggesting that cortical circuits perform some form of probabilistic inference to determine the value of the hidden variable that represents rewarded actions. In yet another experiment, Cisek and Kalaska <xref ref-type="bibr" rid="pcbi.1003859-Cisek1">[3]</xref> studied macaque monkeys in an ambiguous target task. A visual spatial cue and a color cue, which were separated by a memory epoch, determined the rewarded direction of an arm movement, see <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1A</xref>. Ambiguity about the rewarded action after the first cue was reflected in the firing activity of dorsal premotor cortex (PMd) neurons, see <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1B</xref>. When the second cue determined the single rewarded action, only neurons tuned to the rewarded movement direction remained active. This finding suggests that estimates for the value of a salient time-varying random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e006" xlink:type="simple"/></inline-formula> (getting rewarded for carrying out a specific action) are represented and updated through the current firing activity of different ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e007" xlink:type="simple"/></inline-formula> of neurons, one for each possible value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e008" xlink:type="simple"/></inline-formula> of the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e009" xlink:type="simple"/></inline-formula>.</p>
<fig id="pcbi-1003859-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g001</object-id><label>Figure 1</label><caption>
<title>Representation of a belief in dorsal premotor cortex (PMd) in the ambiguous target task.</title>
<p><bold>A)</bold> Task structure. After an initial fixation (center-hold time; CHT), the spatial cue (SC) is shown in the form of two color markers at one of eight possible locations and displaced from each other by 180 degrees. They mark two potentially rewarded movement directions. After a memory epoch (MEM), the color cue (CC) is shown at the fixation cross. The rewarded movement direction is defined by the direction of matching color in the color cue (time periods of simulation indicated). <bold>B)</bold> Firing activity of neurons in dorsal premotor cortex during the task. Before the spatial cue is shown, neurons are diffusely active. As the spatial cue is shown, neurons with preferred directions consistent with the spatial cue increase the firing rate and others are silenced. This circuit behavior is retained during the memory epoch. As the color cue is presented, neurons with consistent preferred directions increase their firing rates. <bold>C)</bold> Simulation result for a circuit that performs evidence integration in ENS coding (activity smoothed; horizontal axis: time). Neurons are ordered by their preferred direction. Panel B modified with permission from <xref ref-type="bibr" rid="pcbi.1003859-Cisek2">[52]</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g001" position="float" xlink:type="simple"/></fig>
<p>We show that despite of their diversity, all these tasks can be viewed as probabilistic inference tasks, where some internal belief about the current value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e010" xlink:type="simple"/></inline-formula> of a hidden random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e011" xlink:type="simple"/></inline-formula> (e.g., which action is most likely to be rewarded at the end of a trial) needs to be updated based on often ambiguous sensory evidence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e012" xlink:type="simple"/></inline-formula> (moving dots, visual cues, etc.). We will distinguish 5 different classes of such tasks (labeled A - E in <xref ref-type="sec" rid="s2">Results</xref>) that differ for example with regard to the time scale on which the hidden variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e013" xlink:type="simple"/></inline-formula> changes, or prior knowledge about the expected change of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e014" xlink:type="simple"/></inline-formula>. These tasks can not be solved adequately through a Hidden Markov Model (HMM). The reason is that a HMM generates at each moment in time just a single guess for the current value of an unknown variable. It is therefore not able to work with more complex temporary guesses, say that an unknown variable has probably value 1 or 2, but definitely not value 3. Obviously such advanced representations are necessary in order to make decisions that depend on the integration of numerous temporally dispersed cues.</p>
<p>For all these classes of computational tasks there exist theoretically optimal solutions that can be derived within a probabilistic inference framework. If one assumes that the hidden random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e015" xlink:type="simple"/></inline-formula> is static (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e016" xlink:type="simple"/></inline-formula> for some <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e017" xlink:type="simple"/></inline-formula> and all times <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e018" xlink:type="simple"/></inline-formula>), evidence provided by the temporal stream of observations has to be integrated in order to infer the internal belief about the value of the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e019" xlink:type="simple"/></inline-formula>. In such <italic>evidence integration</italic>, an initial prior belief formalized as a probability distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e020" xlink:type="simple"/></inline-formula> is updated over time in order to infer the time-varying posterior distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e021" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e022" xlink:type="simple"/></inline-formula> denotes all evidence up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e023" xlink:type="simple"/></inline-formula>. For example, an observation at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e024" xlink:type="simple"/></inline-formula> that is likely for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e025" xlink:type="simple"/></inline-formula> will increase the probability of state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e026" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e027" xlink:type="simple"/></inline-formula>, while the probability of values under which the observation is unlikely will be decreased. <italic>Bayesian filtering</italic> generalizes evidence integration to time-varying random variables. It is often assumed that the dynamics of the random variable is time-independent. Bayesian filtering then infers the posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e028" xlink:type="simple"/></inline-formula> by taking the assumed dynamics of the time-varying random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e029" xlink:type="simple"/></inline-formula> into account. For example, if value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e030" xlink:type="simple"/></inline-formula> is currently likely, and state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e031" xlink:type="simple"/></inline-formula> is likely to transition to state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e032" xlink:type="simple"/></inline-formula>, then the probability for state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e033" xlink:type="simple"/></inline-formula> will gradually increase over time. For many important tasks, the dynamics of the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e034" xlink:type="simple"/></inline-formula> is not identical at all times but rather depends on context. For example, the change of body position in space (formalized as a hidden random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e035" xlink:type="simple"/></inline-formula>) depends on motor actions. We refer to Bayesian filtering with context dependent dynamics as <italic>context-dependent Bayesian filtering</italic>. It infers <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e036" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e037" xlink:type="simple"/></inline-formula> denotes all context information received up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e038" xlink:type="simple"/></inline-formula>.</p>
<p>In previous work, it was shown that networks of spiking neurons can embody a probability distribution through their stochastic spiking activity. This enables a neural system to carry out probabilistic inference through sampling (e.g., estimate of a marginal probability by observing the firing rate of a corresponding neuron) <xref ref-type="bibr" rid="pcbi.1003859-Buesing1">[4]</xref>. This model for probabilistic inference in networks of spiking neurons was termed neural sampling. However, neural sampling does not provide a suitable model for the representation and updating of quickly-varying distributions as it is needed for the tasks discussed above, since a good estimate of the current value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e039" xlink:type="simple"/></inline-formula> can only be read out after several samples have been observed. Another deficit of the aforementioned simple form of the neural sampling model is, that each salient random variable is represented through the firing activity of just a single neuron. This is unsatisfactory because it does not provide a network computation that is robust against the failures of single neurons. In fact, the representation of random variables through single neurons is not consistent with experimental data, see <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1B</xref>. In addition it requires unbiologically strong synaptic connections in order to ensure that the random variable that is represented by such single neuron has an impact on other random variables, or on downstream readouts. Furthermore, downstream readout neurons are required to integrate (count) spikes of such neuron over intervals of several hundred ms or larger, in order to get a reasonable estimate of the probability that is represented through the firing rate of the neuron (i.e., in order to estimate a posterior marginal, which is an important form of probabilistic inference).</p>
<p>We examine in this article therefore an extension of the neural sampling model, where random variables (e.g. internal beliefs) are represented through a space-rate code of neuronal ensembles. In other words, we are making stronger use of the inherent parallelism of neural systems. In this <italic>ensemble based neural sampling (ENS) code</italic>, the percentage of neurons in an ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e040" xlink:type="simple"/></inline-formula> that fire within some short (e.g. 20 ms) time interval encodes the internal belief (or estimated probability) that a random variable currently has a specific value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e041" xlink:type="simple"/></inline-formula>.</p>
<p>This variation of the neural sampling model is nontrivial, since one tends to lose the link to the theory of sampling/probabilistic inference if one simply replaces a single neuron by an ensemble of neurons. We show however that ensemble based neural sampling is nevertheless possible, and is supported by a rigorous theory. In this new framework downstream neurons can read out current internal estimates in the ENS code just through their standard integration of postsynaptic potentials. We prove rigorously that this generates unbiased estimates, and we also show on what parameters the variance of this estimate depends. Furthermore we explore first steps of a theory of neural computation with the ENS code. We show that nonlinear computation steps that are needed for optimal integration of time-varying evidence can be carried out within this spike-based setting through disinhibition of neurons. Hence networks of spiking neurons with noise are in principle able to approximate theoretically optimal filtering operations – such as evidence integration and context-dependent Bayesian filtering – for updating internal estimates for possible causes of external stimuli. We show in particular, that networks of spiking neurons with noise are able to emulate state-of-the-art probabilistic methods that enable robots to estimate their current position on the basis of multiple ambiguous sensory cues and path integration. This provides a first paradigm for the organization of brain computations that are able to solve generic self-localization tasks. The resulting model is especially suited as “computational engine” for an intention-based neural coding framework, as proposed in <xref ref-type="bibr" rid="pcbi.1003859-Shadlen1">[5]</xref>. Intention-based neural coding is commonly observed in lateral intraparietal cortex (area LIP) of monkeys, where neurons encode a preference for a particular target of a saccade within the visual field <xref ref-type="bibr" rid="pcbi.1003859-Gold1">[1]</xref>.</p>
<p>The remainder of this paper is structured as follows. First we introduce ENS coding. We then discuss basic properties of the ENS code. In <italic>Computational operations through ensemble-based neural sampling</italic>, we show how basic computations on time-varying internal beliefs can be realized by neural circuits in ENS coding. This section is structured along 5 classes of computational tasks of increasing complexity (<italic>Task class A</italic> to <italic>Task class E</italic>). Within these task classes, we present computer simulations where the characteristics of these neural circuits are analyzed and compared to experimental results. A discussion of the main findings of this paper and related work can be found in <italic><xref ref-type="sec" rid="s3">Discussion</xref></italic>. Detailed derivations and descriptions of computer simulations are provided in <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Ensemble-based neural sampling</title>
<p>In neural sampling <xref ref-type="bibr" rid="pcbi.1003859-Buesing1">[4]</xref>, each neuron in a network represents a binary random variable. Spike generation is stochastic, with a probability that depends on the current membrane potential. At each time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e042" xlink:type="simple"/></inline-formula>, the activity of each neuron is mapped to a sample for the value of the corresponding variable by setting the value to 1 if the neuron has spiked in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e043" xlink:type="simple"/></inline-formula> for some small <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e044" xlink:type="simple"/></inline-formula> (e.g. 20 ms). It was shown that under certain conditions on the membrane potentials of the neurons, the network converges to a stationary distribution that corresponds to the posterior distribution of the represented random variables for the given evidence. Evidence is provided to the circuit by clamping the activities of a subset of neurons during inference. The marginal distribution for a given variable can be read out by observing the firing activity of the corresponding neuron in the stationary distribution.</p>
<p>Neural sampling is an implementation of the Markov Chain Monte Carlo (MCMC) sampling approach (see e.g. <xref ref-type="bibr" rid="pcbi.1003859-Murphy1">[6]</xref>) in networks of spiking neurons. By definition, it does not provide a suitable model for the representation of time-varying distributions, since samples are generated in a sequential manner. Convergence to the stationary distribution in MCMC sampling can take substantial time, the readout of marginal distributions demands spike counts of neurons over extended periods of time, and MCMC sampling is only defined for the fictional case of stationary external inputs. But also time-varying distributions can theoretically be handled through Monte Carlo sampling if one has a sufficiently parallelized stochastic system that can generate at each time point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e045" xlink:type="simple"/></inline-formula> simultaneously several samples <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e046" xlink:type="simple"/></inline-formula> from the time varying distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e047" xlink:type="simple"/></inline-formula>, and by carrying out simple computational operations on this batch of samples in parallel. The resulting computational model is usually referred to as <italic>particle filter</italic>, a special case of sequential Monte Carlo sampling <xref ref-type="bibr" rid="pcbi.1003859-Murphy1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Doucet1">[7]</xref>. Here each sample <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e048" xlink:type="simple"/></inline-formula> from a batch <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e049" xlink:type="simple"/></inline-formula> that is generated at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e050" xlink:type="simple"/></inline-formula> is referred to as a <italic>particle</italic>.</p>
<p>To port the idea of neural sampling to the representation of time-varying distributions through neuronal ensembles, we therefore consider <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e051" xlink:type="simple"/></inline-formula> ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e052" xlink:type="simple"/></inline-formula> that collectively encode the belief about the value of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e053" xlink:type="simple"/></inline-formula> with range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e054" xlink:type="simple"/></inline-formula> in terms of a probability distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e055" xlink:type="simple"/></inline-formula>. We refer to the value of a random variable also as the hidden state, or simply the state of the variable. We will in the following omit the subscript <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e056" xlink:type="simple"/></inline-formula> in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e057" xlink:type="simple"/></inline-formula> for notational convenience (formally, we consider a family of variables, indexed by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e058" xlink:type="simple"/></inline-formula>, that defines a random process, see <xref ref-type="bibr" rid="pcbi.1003859-Grimmett1">[8]</xref>; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e059" xlink:type="simple"/></inline-formula> is then the distribution over the member <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e060" xlink:type="simple"/></inline-formula> of this family). Each ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e061" xlink:type="simple"/></inline-formula> consists of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e062" xlink:type="simple"/></inline-formula> neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e063" xlink:type="simple"/></inline-formula>, where we refer to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e064" xlink:type="simple"/></inline-formula> as the <italic>ensemble size</italic>. We interpret a spike in the circuit as one sample from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e065" xlink:type="simple"/></inline-formula>, i.e., one concrete value for the represented variable drawn according to the distribution <xref ref-type="bibr" rid="pcbi.1003859-Buesing1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Pecevski1">[9]</xref>. In particular, if a spike is elicited by some neuron in ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e066" xlink:type="simple"/></inline-formula>, then this value is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e067" xlink:type="simple"/></inline-formula>. See <xref ref-type="fig" rid="pcbi-1003859-g002">Figure 2A</xref> for an illustration of sample-based representations.</p>
<fig id="pcbi-1003859-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g002</object-id><label>Figure 2</label><caption>
<title>Spikes as samples from probability distributions.</title>
<p><bold>A</bold>) Sample-based representations of probability distributions. True distribution of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e068" xlink:type="simple"/></inline-formula> (green) and approximated distribution (yellow) based on 20 samples (top) and 200 samples (bottom) <bold>B</bold>) Interpretation of the spiking activity of two neuronal ensembles as samples from a probability distribution over a temporally changing random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e069" xlink:type="simple"/></inline-formula>. Shown is an example for a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e070" xlink:type="simple"/></inline-formula> with two possible states. Black lines in the top traces indicate action potentials in two ensembles (5 neurons per state shown). Traces above spikes show EPSP-filtered versions of these spikes (red: state 1; blue: state 2). Bottom plot: Estimated probabilities for state 1 (red) and state 2 (blue) according to eq. (1) based on the spiking activity of 10 neurons per state.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g002" position="float" xlink:type="simple"/></fig>
<p>A downstream neuron can evaluate how many spikes it received from each ensemble within its membrane time constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e071" xlink:type="simple"/></inline-formula> through summation of excitatory postsynaptic potentials (EPSPs) caused by spikes from ensemble neurons. We denote the EPSP-filtered spike train of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e072" xlink:type="simple"/></inline-formula> by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e073" xlink:type="simple"/></inline-formula> (see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for a precise definition) and adopt rectangular EPSP shapes of length <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e074" xlink:type="simple"/></inline-formula> in the following, similar to those recorded at the soma of pyramidal neurons for dendrite-targeting synaptic inputs (see <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1</xref> in <xref ref-type="bibr" rid="pcbi.1003859-Williams1">[10]</xref>). The sum of all EPSPs from an ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e075" xlink:type="simple"/></inline-formula>, denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e076" xlink:type="simple"/></inline-formula>, is then the number of samples for hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e077" xlink:type="simple"/></inline-formula> in the time window from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e078" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e079" xlink:type="simple"/></inline-formula>. The number of samples <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e080" xlink:type="simple"/></inline-formula> is thus directly accessible to downstream neurons. We refer to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e081" xlink:type="simple"/></inline-formula> as the (non-normalized) probability mass for hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e082" xlink:type="simple"/></inline-formula>. The use of plateau-like EPSP shapes is motivated from the need to count spikes in some predefined time interval. An alternative motivation that is based on the idea that the EPSP weights a spike by the probability that it belongs to the most recent samples is given in <italic><xref ref-type="supplementary-material" rid="pcbi.1003859.s002">Text S1</xref></italic>.</p>
<p>The represented distribution can be estimated by the relative portion of spikes from the ensembles<disp-formula id="pcbi.1003859.e083"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e083" xlink:type="simple"/><label>(1)</label></disp-formula>where we assume that at least one sample is available. See <xref ref-type="fig" rid="pcbi-1003859-g002">Figure 2B</xref> for an intuitive illustration of ENS coding. In this representation, probabilities are temporally filtered by the EPSPs. Hence, the ability of the code to capture fast dynamics of distributions depends on the length of EPSPs, where shorter time constants give rise to faster tracking. Due to the stochasticity of the sampling process, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e084" xlink:type="simple"/></inline-formula> is a random variable that assumes different values each time the distribution is represented. We demand in ENS coding that the expected value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e085" xlink:type="simple"/></inline-formula> is equal to the temporally filtered represented probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e086" xlink:type="simple"/></inline-formula> for all states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e087" xlink:type="simple"/></inline-formula>, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for details.</p>
<p>We will see in the construction of computational operations in ENS coding that downstream neurons do not have to carry out the division of eq. (1). Instead, for these operations, they can compute with the non-normalized probability masses <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e088" xlink:type="simple"/></inline-formula> that they obtain through summation of EPSPs from ensemble neurons. The reason is that normalization is not necessary in the representation of a distribution in ENS coding. It is rather the relative portion of spikes for each value of the random variable that defines the represented distribution. Of course, activity needs to be kept in some reasonable range, but this can be done in a rather relaxed manner.</p>
</sec><sec id="s2b">
<title>Basic properties of the ENS code</title>
<p>Assume that samples (spikes) for state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e089" xlink:type="simple"/></inline-formula> are produced by a Poisson process with rate proportional to the represented probability, i.e., the rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e090" xlink:type="simple"/></inline-formula> of neurons in ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e091" xlink:type="simple"/></inline-formula> are given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e092" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e093" xlink:type="simple"/></inline-formula> is a constant that defines the maximal instantaneous rate of each neuron. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e094" xlink:type="simple"/></inline-formula> is then a random variable distributed according to a Poisson distribution with intensity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e095" xlink:type="simple"/></inline-formula>, where the <italic>estimation sample size</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e096" xlink:type="simple"/></inline-formula> is the average number of spikes produced by all ensembles within a time span of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e097" xlink:type="simple"/></inline-formula>.</p>
<p>We show in <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> that in this case, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e098" xlink:type="simple"/></inline-formula> is an unbiased estimator of the probability of state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e099" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e100" xlink:type="simple"/></inline-formula> filtered by the EPSPs, hence, an ENS code is established. An important question is how parameters of a circuit influence the fidelity of the encoding. To answer this question, we investigated the variance of the estimator. It is inversely proportional to the ensemble size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e101" xlink:type="simple"/></inline-formula>, the maximal firing rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e102" xlink:type="simple"/></inline-formula>, and the membrane time constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e103" xlink:type="simple"/></inline-formula> if the number of samples within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e104" xlink:type="simple"/></inline-formula> is large, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>. Hence, the accuracy can be increased by increasing the ensemble size, the firing rate of neurons, and the time constant of neuronal integration. Note however that an increase of the latter will lead to more temporal filtering of the distribution.</p>
<p>We close this discussion by considering the relation between the instantaneous firing rates of ensemble neurons and the mean represented probability mass <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e105" xlink:type="simple"/></inline-formula>. The probability mass is not an instantaneous function of the ensemble firing rate, since at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e106" xlink:type="simple"/></inline-formula> there are still past samples that influence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e107" xlink:type="simple"/></inline-formula> through their EPSPs. A past sample becomes invalid after time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e108" xlink:type="simple"/></inline-formula>, when the associated EPSP vanishes. The instantaneous firing rates <italic>change</italic> the mass through the production of novel samples. Consider given continuous firing rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e109" xlink:type="simple"/></inline-formula>. Under mild assumptions on the firing rates of ensemble neurons (see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>), the change of the expected probability mass <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e110" xlink:type="simple"/></inline-formula> is then given by<disp-formula id="pcbi.1003859.e111"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e111" xlink:type="simple"/><label>(2)</label></disp-formula>where the expectation is taken over realizations of spike trains for the given instantaneous rates. Here, the first term is due to the production of novel samples and the second term due to old samples that become invalid. In summary, the membrane potentials of the neurons determine – through the firing rate – the rate of change of the represented probability mass in ENS-coding.</p>
</sec><sec id="s2c">
<title>Computational operations through ensemble-based neural sampling</title>
<p>We address now the question how basic computations on time-varying internal beliefs can be realized by neural circuits in ENS coding. Spiking activity of excitatory neurons is modeled according to the stochastic Spike Response model <xref ref-type="bibr" rid="pcbi.1003859-Jolivet1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Mensi1">[12]</xref>. In this model, each neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e112" xlink:type="simple"/></inline-formula> emits a Poisson spike train with instantaneous firing rate<disp-formula id="pcbi.1003859.e113"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e113" xlink:type="simple"/><label>(3)</label></disp-formula></p>
<p>Here, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e114" xlink:type="simple"/></inline-formula> denotes a link function that links the somatic membrane potential <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e115" xlink:type="simple"/></inline-formula> to the instantaneous firing rate. Typically, the link function is either an exponential function or a non-negative linear function. We consider in this article a non-negative linear link function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e116" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003859-Mensi1">[12]</xref>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e117" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e118" xlink:type="simple"/></inline-formula> for non-negative <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e119" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e120" xlink:type="simple"/></inline-formula> otherwise.</p>
<p>We discuss five classes of computational tasks.</p>
<sec id="s2c1">
<title>Tasks class A</title>
<p>In these tasks, the state of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e121" xlink:type="simple"/></inline-formula> has to be inferred in ENS coding given the belief about a variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e122" xlink:type="simple"/></inline-formula> in ENS coding, where the distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e123" xlink:type="simple"/></inline-formula> depends solely on the current state of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e124" xlink:type="simple"/></inline-formula>. The computational operation needed to solve such problems is simpler than the other ones considered here in the sense that the distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e125" xlink:type="simple"/></inline-formula> can be directly inferred from recent samples for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e126" xlink:type="simple"/></inline-formula>. We will use this operation several times to read out the belief about a rewarded motor action (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e127" xlink:type="simple"/></inline-formula>) from the internal belief about some random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e128" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s2c2">
<title>Tasks class B</title>
<p>This class consists of tasks that can be solved through evidence integration. In other words, the state of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e129" xlink:type="simple"/></inline-formula> has to be estimated based on evidence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e130" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e131" xlink:type="simple"/></inline-formula> is assumed to be static during each trial. Examples for such tasks are the ambiguous target task, the random-dot motion task, and the probabilistic inference task from <xref ref-type="bibr" rid="pcbi.1003859-Yang1">[2]</xref>. We will exhibit a spiking neural network architecture that approximates optimal solutions for these tasks in ENS coding and compare its behavior to experimental results.</p>
</sec><sec id="s2c3">
<title>Tasks class C</title>
<p>Also in these tasks, evidence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e132" xlink:type="simple"/></inline-formula> has to be integrated to estimate the state of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e133" xlink:type="simple"/></inline-formula>. However, the state of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e134" xlink:type="simple"/></inline-formula> may change over time according to known time-independent stochastic dynamics. Bayesian filtering provides an optimal solution for such tasks. We will extend the circuit architecture from task class B to approximate Bayesian filtering in ENS coding and test its performance in a generic task setup.</p>
</sec><sec id="s2c4">
<title>Tasks class D</title>
<p>In this class of tasks, the dynamics of the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e135" xlink:type="simple"/></inline-formula> may change during the task, and changes are indicated by some context-variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e136" xlink:type="simple"/></inline-formula>. Note that task classes B and C are special cases of this task class. We refer to the optimal solution as context-dependent Bayesian filtering. An approximation based on sequential Monte Carlo sampling is particle filtering. We will extend our circuit architecture to perform full particle filtering in ENS coding. We will show how the important problem of self-localization can be solved by this architecture.</p>
</sec><sec id="s2c5">
<title>Tasks class E</title>
<p>Finally, we will discuss tasks where the context variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e137" xlink:type="simple"/></inline-formula> is not explicitly given but has to be estimated from noisy evidence. Hence, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e138" xlink:type="simple"/></inline-formula> – which determines the dynamics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e139" xlink:type="simple"/></inline-formula> – has also to be considered a random variable. We will treat such tasks by combining two particle filters. One particle filter estimates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e140" xlink:type="simple"/></inline-formula> and provides context for another particle filter that estimates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e141" xlink:type="simple"/></inline-formula>. As an example, we will reconsider the ambiguous target task. We show that a belief about the current stage within a series of trials can be generated in order to decide whether evidence should be further integrated for the belief about the rewarded action or whether a new trial has started and the belief should be reset to some prior distribution.</p>
</sec></sec><sec id="s2d">
<title>Task class A: Simple probabilistic dependencies</title>
<p>We first discuss how the belief for a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e142" xlink:type="simple"/></inline-formula> can be inferred in ENS coding given the belief over a variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e143" xlink:type="simple"/></inline-formula>. Consider a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e144" xlink:type="simple"/></inline-formula> for which the distribution depends solely on the current state of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e145" xlink:type="simple"/></inline-formula>. The task is to infer the distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e146" xlink:type="simple"/></inline-formula> for the current distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e147" xlink:type="simple"/></inline-formula>. This operation is needed for example in typical decision making tasks where inference about a rewarded action has to be performed according to the belief about some hidden variable that is based on sensory information. For example, the rewarded movement direction has to be guessed, based on the belief about the perceived cue combination in the ambiguous target task.</p>
<p>Assume that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e148" xlink:type="simple"/></inline-formula> is constant and represented by neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e149" xlink:type="simple"/></inline-formula> through ENS coding with estimation sample size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e150" xlink:type="simple"/></inline-formula>. We are looking for a neural circuit that represents the posterior belief<disp-formula id="pcbi.1003859.e151"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e151" xlink:type="simple"/><label>(4)</label></disp-formula>in ENS coding. Here, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e152" xlink:type="simple"/></inline-formula> are the known conditional probabilities that determine the dependencies between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e153" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e154" xlink:type="simple"/></inline-formula>.</p>
<p>We consider a layer of ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e155" xlink:type="simple"/></inline-formula> that receive feed-forward synaptic input from ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e156" xlink:type="simple"/></inline-formula> representing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e157" xlink:type="simple"/></inline-formula>, see <xref ref-type="fig" rid="pcbi-1003859-g003">Figure 3</xref>. The membrane potentials of neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e158" xlink:type="simple"/></inline-formula> are given by<disp-formula id="pcbi.1003859.e159"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e159" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e160" xlink:type="simple"/></inline-formula> denotes the efficacy of the synapse connecting presynaptic neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e161" xlink:type="simple"/></inline-formula> to postsynaptic neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e162" xlink:type="simple"/></inline-formula> (we assume for simplicity of notation that all weights between two ensembles are identical). Consider the estimator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e163" xlink:type="simple"/></inline-formula> for synaptic efficacies<disp-formula id="pcbi.1003859.e164"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e164" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e165" xlink:type="simple"/></inline-formula> is the ensemble size of the ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e166" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e167" xlink:type="simple"/></inline-formula> is some constant. Due to the stochastic nature of neurons, this estimator is a random variable. Its expected value (with respect to realizations of spikes trains in all ensembles) is equal to the posterior probability and the estimation sample size is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e168" xlink:type="simple"/></inline-formula> (see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>). Thus, the layer represents the posterior distribution in ENS coding. The estimate at some specific time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e169" xlink:type="simple"/></inline-formula> is however variable due to variability in spike counts of both the representation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e170" xlink:type="simple"/></inline-formula> and the representation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e171" xlink:type="simple"/></inline-formula>. An analysis of the variance of the posterior representation is given in <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>.</p>
<fig id="pcbi-1003859-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g003</object-id><label>Figure 3</label><caption>
<title>Computations in ENS coding in a feed forward circuit architecture.</title>
<p>A binary random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e172" xlink:type="simple"/></inline-formula> is represented in ENS coding through neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e173" xlink:type="simple"/></inline-formula>. The posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e174" xlink:type="simple"/></inline-formula> for a binary variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e175" xlink:type="simple"/></inline-formula> is represented by neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e176" xlink:type="simple"/></inline-formula>. Each variable is represented by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e177" xlink:type="simple"/></inline-formula> ensembles, one for each possible state (indicated by neuron color), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e178" xlink:type="simple"/></inline-formula> neurons per ensemble. The two layers are connected in an all-to-all manner. Arrows indicate efferent connections (i.e., outputs in ENS coding). The architecture is summarized in the inset.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g003" position="float" xlink:type="simple"/></fig>
<p>We will use such a layer with feed-forward input several times in our simulations to infer a belief about rewarded actions for a given belief about the state of a random variable and thus refer to it as an <italic>action readout layer</italic>.</p>
<p>We will also need a special case of this operation where the distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e179" xlink:type="simple"/></inline-formula> is simply copied, i.e., the state of the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e180" xlink:type="simple"/></inline-formula> is assumed to be identical to the state of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e181" xlink:type="simple"/></inline-formula>. In other words, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e182" xlink:type="simple"/></inline-formula> is 1 for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e183" xlink:type="simple"/></inline-formula> and 0 for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e184" xlink:type="simple"/></inline-formula>. The copy operation is thus performed for weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e185" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e186" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e187" xlink:type="simple"/></inline-formula> (where we used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e188" xlink:type="simple"/></inline-formula>).</p>
</sec><sec id="s2e">
<title>Task class B: Evidence integration</title>
<p>In pure evidence integration, the value of the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e189" xlink:type="simple"/></inline-formula> is assumed to be constant and only indirectly observable via stochastic point-event observations. Point-event observations are assumed to arise according to Poisson processes with instantaneous rates that depend on the current hidden state. In the context of neuronal circuits, observations are reported through spikes of afferent neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e190" xlink:type="simple"/></inline-formula>. In particular, afferent neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e191" xlink:type="simple"/></inline-formula> is assumed to spike in a Poissonian manner with rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e192" xlink:type="simple"/></inline-formula> if the hidden variable assumes state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e193" xlink:type="simple"/></inline-formula>. For a prior distribution over states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e194" xlink:type="simple"/></inline-formula>, the task is to infer the posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e195" xlink:type="simple"/></inline-formula>, that is, the distribution over states at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e196" xlink:type="simple"/></inline-formula>, given the spike trains of all afferent neurons up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e197" xlink:type="simple"/></inline-formula>, denoted here by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e198" xlink:type="simple"/></inline-formula>. Many laboratory tasks can be formalized as evidence integration task, including the random-dot motion task, the probabilistic inference task considered in <xref ref-type="bibr" rid="pcbi.1003859-Yang1">[2]</xref> and the ambiguous target task discussed in the <xref ref-type="sec" rid="s1">introduction</xref>. We construct in the following a circuit of spiking neurons that approximates optimal evidence integration by performing particle filtering in ENS coding under the assumption that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e199" xlink:type="simple"/></inline-formula> is constant. The will then evaluate its behavior against experimental data in computer simulations. This circuit will be extended in the subsequent sections to perform particle filtering for tasks classes C and D.</p>
<p>It is well-known that the evidence integration problem can be solved efficiently through a set of coupled differential equations<disp-formula id="pcbi.1003859.e200"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e200" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e201" xlink:type="simple"/></inline-formula> is the spike train of afferent neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e202" xlink:type="simple"/></inline-formula> formalized as a sum of Dirac delta pulses at spike times (see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e203" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003859-Brmaud1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Bobrowski1">[14]</xref>. The inferred probabilities can be obtained by normalization <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e204" xlink:type="simple"/></inline-formula> (for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e205" xlink:type="simple"/></inline-formula>). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e206" xlink:type="simple"/></inline-formula> induces a constant decrease of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e207" xlink:type="simple"/></inline-formula> such that hidden states that give rise to many observations are punished if no observations are encountered. Is the dynamics (7) compatible with ENS coding, assuming that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e208" xlink:type="simple"/></inline-formula> is estimated from the spiking activity of an ensemble? Four potential difficulties arise. First, the afferent neurons impact eq. (7) via point events and not via EPSPs (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e209" xlink:type="simple"/></inline-formula> instead of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e210" xlink:type="simple"/></inline-formula>). Second, the deterministic dynamics (7) need to be implemented via particles in the ENS code. Third, the summed evidence needs to be multiplied with the current value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e211" xlink:type="simple"/></inline-formula>. And finally, to avoid an exponential blow-up of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e212" xlink:type="simple"/></inline-formula>'s, their values need to be normalized. We discuss these four issues in the following.</p>
<sec id="s2e1">
<title>Evidence can be provided through EPSPs</title>
<p>It turns out that the first difficulty can be resolved in a convenient manner. The set of differential <xref ref-type="disp-formula" rid="pcbi.1003859.e200">equations (7</xref>) can be transformed to<disp-formula id="pcbi.1003859.e213"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e213" xlink:type="simple"/><label>(8)</label></disp-formula>with weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e214" xlink:type="simple"/></inline-formula> for an arbitrary constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e215" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e216" xlink:type="simple"/></inline-formula>, and an arbitrary function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e217" xlink:type="simple"/></inline-formula>. Integration of EPSPs weighted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e218" xlink:type="simple"/></inline-formula> leads to exactly the same result as integration of eq. (7) after the EPSPs have fully been integrated, even if they are temporally overlapping, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>. The constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e219" xlink:type="simple"/></inline-formula> can be used to shift <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e220" xlink:type="simple"/></inline-formula> to positive values. This constant, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e221" xlink:type="simple"/></inline-formula>, and the function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e222" xlink:type="simple"/></inline-formula> are integrated by all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e223" xlink:type="simple"/></inline-formula>'s giving rise to a scaling that cancels in the normalization.</p>
</sec><sec id="s2e2">
<title>Particle-based implementation of the filtering equations</title>
<p>We now discuss how eq. (8) is approximated in ENS coding. While eq. (8) is a deterministic differential equation, the dynamics of the circuit is stochastic due to sampling noise. We construct a circuit that approximates the desired changes in its expected probability masses. The validity of this approach will later be ascertained through various computer simulations. The belief about the hidden state of the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e224" xlink:type="simple"/></inline-formula> is in general shaped by two components. First, the assumed internal dynamics of the random variable, and second by novel evidence about the state. Consider a circuit that consists of two layers <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e225" xlink:type="simple"/></inline-formula> (the dynamics layer) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e226" xlink:type="simple"/></inline-formula> (the evidence layer) with neural ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e227" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e228" xlink:type="simple"/></inline-formula> respectively, see <xref ref-type="fig" rid="pcbi-1003859-g004">Figure 4A</xref>. The dynamics layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e229" xlink:type="simple"/></inline-formula> implements changes of the represented distribution due to the internal dynamics of the random variable. The evidence layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e230" xlink:type="simple"/></inline-formula> implements changes due to incoming evidence. Since in task class B, the random variable is assumed to be static, no temporal changes of the random variable are expected, and hence the excitatory weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e231" xlink:type="simple"/></inline-formula> from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e232" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e233" xlink:type="simple"/></inline-formula> are set such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e234" xlink:type="simple"/></inline-formula> copies the distribution represented by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e235" xlink:type="simple"/></inline-formula>, as discussed in <italic>Task class A</italic>. For task classes C and D, different weights will be used such that layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e236" xlink:type="simple"/></inline-formula> predicts dynamics changes of the hidden variable.</p>
<fig id="pcbi-1003859-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g004</object-id><label>Figure 4</label><caption>
<title>Particle filter circuit architecture for task classes B and C.</title>
<p><bold>A</bold>) Circuit with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e237" xlink:type="simple"/></inline-formula> ensembles (indicated by red and blue neurons respectively) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e238" xlink:type="simple"/></inline-formula> neurons per ensemble. Neurons in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e239" xlink:type="simple"/></inline-formula> receive synaptic connections from neurons in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e240" xlink:type="simple"/></inline-formula> and update the represented distribution according to evidence input from afferent neurons (green). Lateral inhibition (magenta; see panel C) stabilizes activity in this layer. Neurons project back to layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e241" xlink:type="simple"/></inline-formula>. For task class B (evidence integration; static random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e242" xlink:type="simple"/></inline-formula>), only connections between neurons that code for the same hidden state are necessary and layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e243" xlink:type="simple"/></inline-formula> simply copies the distribution represented by layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e244" xlink:type="simple"/></inline-formula>, see <italic>Task class A</italic> and <xref ref-type="fig" rid="pcbi-1003859-g003">Figure 3</xref> (in contrast to <xref ref-type="fig" rid="pcbi-1003859-g003">Figure 3</xref>, the copying ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e245" xlink:type="simple"/></inline-formula> are plotted above ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e246" xlink:type="simple"/></inline-formula> in order to avoid a cluttered diagram). For task class C (Bayesian filtering; random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e247" xlink:type="simple"/></inline-formula> with time-independent dynamics), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e248" xlink:type="simple"/></inline-formula> implements changes of the represented distribution due to the dynamics of the random variable and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e249" xlink:type="simple"/></inline-formula> is potentially fully connected to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e250" xlink:type="simple"/></inline-formula>. Neurons in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e251" xlink:type="simple"/></inline-formula> disinhibit neurons in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e252" xlink:type="simple"/></inline-formula> (double-dot connections; see panel B). Disinhbition and lateral inhibition is indicated by shortcuts as defined in B, C. Arrows indicate efferent connections. A schematic overview of the circuit is shown in the inset. <bold>B</bold>) Disinhibition <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e253" xlink:type="simple"/></inline-formula>: neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e254" xlink:type="simple"/></inline-formula> excite an interneuron (purple) which inhibits the inhibitory drive to some neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e255" xlink:type="simple"/></inline-formula>. As a graphical shortcut, we draw such disinhibitory influence as a connection with two circles (inset) <bold>C</bold>) Lateral inhibition: Pyramidal cells (blue) excite a pool of inhibitory neurons (magenta) which feed back common inhibition <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e256" xlink:type="simple"/></inline-formula>. The graphical shortcut for lateral inhibition is shown in the inset.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g004" position="float" xlink:type="simple"/></fig>
<p>The evidence layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e257" xlink:type="simple"/></inline-formula> receives input from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e258" xlink:type="simple"/></inline-formula> and evidence from afferent neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e259" xlink:type="simple"/></inline-formula>. Our goal is that its probability masses integrate evidence in the representation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e260" xlink:type="simple"/></inline-formula> in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e261" xlink:type="simple"/></inline-formula>, such that<disp-formula id="pcbi.1003859.e262"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e262" xlink:type="simple"/><label>(9)</label></disp-formula>where the latter approximation applies due to the copy operation of layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e263" xlink:type="simple"/></inline-formula>. This equation resembles eq. (8) where the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e264" xlink:type="simple"/></inline-formula>'s represent the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e265" xlink:type="simple"/></inline-formula>'s. We show in <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> that such changes are obtained if the membrane potentials of the neurons in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e266" xlink:type="simple"/></inline-formula> are set to<disp-formula id="pcbi.1003859.e267"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e267" xlink:type="simple"/><label>(10)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e268" xlink:type="simple"/></inline-formula> are positive biases.</p>
</sec><sec id="s2e3">
<title>Multiplication through gating of activity</title>
<p>We see that neurons need to compute a multiplication between the current probability mass for state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e269" xlink:type="simple"/></inline-formula> and the summed evidence. In order to implement similar equations in a neuronal-like manner, logarithmic dendritic nonlinearities or multiplicative synaptic interactions have been postulated in a number of studies, see e.g. <xref ref-type="bibr" rid="pcbi.1003859-Bobrowski1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Rao1">[15]</xref>. In ENS coding however, the population response in the evidence layer is the sum of the responses of individual neurons. This linearity allows us to base the membrane potential of an individual neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e270" xlink:type="simple"/></inline-formula> on a small number of particles rather than on the whole set of particles summarized in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e271" xlink:type="simple"/></inline-formula>, as long as each particle is used exactly once in the computation. Hence, the same behavior is obtained on the population level if instead of membrane potentials (10), membrane potentials are given by<disp-formula id="pcbi.1003859.e272"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e272" xlink:type="simple"/><label>(11)</label></disp-formula>see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for a detailed derivation. If spiking of individual neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e273" xlink:type="simple"/></inline-formula> is sparse, i.e., if the ensemble size is large compared to the estimation sample size, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e274" xlink:type="simple"/></inline-formula> nearly always takes on the values 0 or 1. In this case, it suffices that the activity of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e275" xlink:type="simple"/></inline-formula> is <italic>gated</italic> by neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e276" xlink:type="simple"/></inline-formula>, i.e., the neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e277" xlink:type="simple"/></inline-formula> is able to produce spikes only if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e278" xlink:type="simple"/></inline-formula> was recently active. In summary, under the assumption of sparse activity (which can always be accomplished by a suitable choice of parameters), one can replace the multiplication of two analog variables by gating of activity in ENS coding. This multiplication strategy generalizes the one proposed in the context of stochastic computation to ensemble representations <xref ref-type="bibr" rid="pcbi.1003859-Gaines1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Srinivasan1">[17]</xref>.</p>
<p>Such gating could be accomplished in cortical networks in various ways. One possibility is synaptic gating <xref ref-type="bibr" rid="pcbi.1003859-Katz1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Gisiger1">[19]</xref> where inputs can be gated by either suppression or facilitation of specific synaptic activity. Another possibility is disinhibition. Disinhibitory circuits provide pyramidal cells with the ability to release other neurons from strong inhibitory currents <xref ref-type="bibr" rid="pcbi.1003859-Letzkus1">[20]</xref>. We choose in this article disinhibition as the gating mechanism, although no specific mechanism can be favored on the basis of the experimental literature. A small circuit with disinhibition <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e279" xlink:type="simple"/></inline-formula> is shown in <xref ref-type="fig" rid="pcbi-1003859-g004">Figure 4B</xref>. Here, two pyramidal cells excite an interneuron which inhibits the inhibitory drive to some neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e280" xlink:type="simple"/></inline-formula>. Functionally, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e281" xlink:type="simple"/></inline-formula> is released from strong baseline inhibition if one of the neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e282" xlink:type="simple"/></inline-formula> was recently active (see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for a formal definition). Using disinhibition, the membrane potential of the neuron can be written as<disp-formula id="pcbi.1003859.e283"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e283" xlink:type="simple"/><label>(12)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e284" xlink:type="simple"/></inline-formula> ensures that the firing rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e285" xlink:type="simple"/></inline-formula> is nonzero only if neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e286" xlink:type="simple"/></inline-formula> did spike within the last 20 ms.</p>
</sec><sec id="s2e4">
<title>Stabilization of firing rates through lateral inhibition</title>
<p>Lateral inhibition is generally assumed to stabilize the activity of excitatory populations <xref ref-type="bibr" rid="pcbi.1003859-Douglas1">[21]</xref>–<xref ref-type="bibr" rid="pcbi.1003859-Fino1">[23]</xref>. A group of pyramidal cells inhibit each other laterally by projecting to a group of inhibitory neurons which in turn inhibit that ensemble, see <xref ref-type="fig" rid="pcbi-1003859-g004">Figure 4C</xref>. The key observation that enables us to use lateral inhibition to stabilize circuit activity is that one has freedom to choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e287" xlink:type="simple"/></inline-formula> in eq. (12) as long as it is identical in all ensembles. We model lateral inhibition <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e288" xlink:type="simple"/></inline-formula> that depends on the recent firing activity in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e289" xlink:type="simple"/></inline-formula> such that inhibitory activity increases if the estimation sample size is above the desired value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e290" xlink:type="simple"/></inline-formula> and choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e291" xlink:type="simple"/></inline-formula>, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for details and a brief discussion. This concludes the construction of a particle filtering circuit in ENS coding for task class B. The circuit architecture is depicted in <xref ref-type="fig" rid="pcbi-1003859-g004">Figure 4A</xref>. A summary of circuit equations can be found in <xref ref-type="table" rid="pcbi-1003859-t001">Table 1</xref>.</p>
<table-wrap id="pcbi-1003859-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.t001</object-id><label>Table 1</label><caption>
<title>Particle filter circuit equations for task classes B and C.</title>
</caption><alternatives><graphic id="pcbi-1003859-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.t001" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Layer</td>
<td align="left" rowspan="1" colspan="1">Ensembles</td>
<td align="left" rowspan="1" colspan="1">Neurons</td>
<td align="left" rowspan="1" colspan="1">Membrane voltage and parameters</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e292" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e293" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e294" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e295" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e296" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e297" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e298" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e299" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e300" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e301" xlink:type="simple"/></inline-formula> for all <italic>i</italic>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e302" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e303" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e304" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e305" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e306" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e307" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e308" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e309" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e310" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt101"><label/><p>Here we have defined <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e311" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e312" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e313" xlink:type="simple"/></inline-formula> denotes lateral inhibition and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e314" xlink:type="simple"/></inline-formula> disinhibition. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e315" xlink:type="simple"/></inline-formula> is an arbitrary constant. In task class B (evidence integration), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e316" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e317" xlink:type="simple"/></inline-formula>, leading to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e318" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e319" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e320" xlink:type="simple"/></inline-formula>.</p></fn></table-wrap-foot></table-wrap>
<p>We tested how well a circuit consisting of 2000 neurons per state and an estimation sample size of 400 can approximate the true posterior in a simple evidence integration setup. The task was to compute the posterior distribution for a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e321" xlink:type="simple"/></inline-formula> with two hidden states and two observable variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e322" xlink:type="simple"/></inline-formula>, see <xref ref-type="fig" rid="pcbi-1003859-g005">Figure 5A</xref>. The schematic circuit diagram is shown in panel B. The two evidence neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e323" xlink:type="simple"/></inline-formula> spiked at times 20 ms and 25 ms respectively, see panel C. <xref ref-type="fig" rid="pcbi-1003859-g005">Figure 5D</xref> depicts the rate dynamics in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e324" xlink:type="simple"/></inline-formula> for one example trial. Novel evidence transiently increases the firing rate in the layer, which is in turn restored by lateral inhibition. The response of ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e325" xlink:type="simple"/></inline-formula> that represents state 1 undergoes a transient increase that is counteracted by inhibition until it stabilizes at an enhanced sustained level. This behavior is reminiscent of the typical response of cortical pyramidal cells to sensory input. <xref ref-type="fig" rid="pcbi-1003859-g005">Figure 5E</xref> shows the temporal evolution of the encoded posterior probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e326" xlink:type="simple"/></inline-formula> in comparison to the true posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e327" xlink:type="simple"/></inline-formula>. The true posterior is approximated very well after a delay of about 20 ms, which is the time needed to integrate the EPSPs from evidence neurons. We simulated 100 trials where in each trial, prior probabilities for the states and observation likelihoods were drawn randomly such that the posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e328" xlink:type="simple"/></inline-formula> at time <italic>t</italic> = 45 ms assumed values between 0 and 1 (see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>). The estimate of the circuit at the end of the second EPSP (i.e., at time <italic>t</italic> = 45 ms) is shown in comparison to the true posterior in <xref ref-type="fig" rid="pcbi-1003859-g005">Figure 5F</xref>.</p>
<fig id="pcbi-1003859-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g005</object-id><label>Figure 5</label><caption>
<title>Evidence integration through particle filtering in ENS coding.</title>
<p><bold>A</bold>) The state of a binary random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e329" xlink:type="simple"/></inline-formula> that gives rise to two possible observations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e330" xlink:type="simple"/></inline-formula> is estimated. Both observations occur more frequently in state 1 (indicated by sharpness of arrows). <bold>B</bold>) Estimation is performed by a particle filtering circuit with evidence input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e331" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e332" xlink:type="simple"/></inline-formula>: dynamics layer ensembles; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e333" xlink:type="simple"/></inline-formula>: evidence layer ensembles). <bold>C</bold>) An evidence spike is observed at times 20 ms and 25 ms in evidence neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e334" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e335" xlink:type="simple"/></inline-formula> respectively. <bold>D</bold>) Example for the rate dynamics in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e336" xlink:type="simple"/></inline-formula>. Ensemble rate for ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e337" xlink:type="simple"/></inline-formula> (black) and whole layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e338" xlink:type="simple"/></inline-formula> (gray). The input leads to a transient increase in the ensemble rate. Inhibition recovers baseline activity. The ensemble rate for state 1 undergoes a transient and a sustained activity increase. <bold>E</bold>) Temporal evolution of estimated posterior probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e339" xlink:type="simple"/></inline-formula> for state 1 (black) in comparison to true posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e340" xlink:type="simple"/></inline-formula> (gray) for this example run. <bold>F</bold>) Posterior probability at <italic>t</italic> = 45 ms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e341" xlink:type="simple"/></inline-formula>) for state 1 of the circuit in comparison to true posterior at this time (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e342" xlink:type="simple"/></inline-formula>). Each dot represents one out of 100 runs with prior probabilities and observation likelihoods drawn independently in each run (see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>). The results of the example run from panels A–E is indicated by a cross.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g005" position="float" xlink:type="simple"/></fig>
<p>Gating of activity for multiplication can be used for many types of multiplicative operations on probability distributions. In <italic><xref ref-type="supplementary-material" rid="pcbi.1003859.s003">Text S2</xref></italic>, we discuss its application to cue combination, an operation that has been considered for example in <xref ref-type="bibr" rid="pcbi.1003859-Ma1">[24]</xref>.</p>
</sec></sec><sec id="s2f">
<title>Comparison to experimental results</title>
<p>We performed computer simulations in order to compare the behavior of the model to various experimental studies on tasks that are examples for task class B.</p>
<sec id="s2f1">
<title>The ambiguous target task</title>
<p>The ambiguous target task studied in <xref ref-type="bibr" rid="pcbi.1003859-Cisek1">[3]</xref> was already discussed above, see also <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1A</xref>. In our model of the decision making process, the hidden state of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e343" xlink:type="simple"/></inline-formula> was estimated through evidence integration. Each of the 16 hidden states corresponded to a tuple <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e344" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e345" xlink:type="simple"/></inline-formula> denotes one of eight possible directions of movement, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e346" xlink:type="simple"/></inline-formula> denotes the color of the color cue. In other words, such a state represented the color of the color cue and the movement direction that leads to reward, see <xref ref-type="fig" rid="pcbi-1003859-g006">Figure 6A</xref>a. Possible observations were the fixation cross, the spatial cues at 8 positions in two colors, and the two color cues. Each of the 19 possible stimuli was coded by 20 afferent neuron that fired at a baseline rate of 0.1 Hz. When a stimulus was present, the corresponding neurons spiked in a Poissonian manner with a rate of 5 Hz.</p>
<fig id="pcbi-1003859-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g006</object-id><label>Figure 6</label><caption>
<title>Particle filtering in ENS coding for the ambiguous target task.</title>
<p><bold>A</bold>) Represented random variables. <bold>Aa</bold>) Evidence integration is performed for a random variable with 16 hidden states corresponding to direction-color pairs. Values of the random variable are depicted as circles. Observations accessible to the monkey in one example state are shown as boxes. <bold>Ab</bold>) The action readout layer infers a color-independent random variable by marginalization over color in each direction. <bold>B</bold>) Circuit structure. The circuit on the top approximates evidence integration through particle filtering (top gray box; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e347" xlink:type="simple"/></inline-formula>: dynamics layer ensembles; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e348" xlink:type="simple"/></inline-formula>: evidence layer ensembles)) on the random variable indicated in panel (Aa). An action readout layer (bottom gray box; ensembles <italic>X</italic>) receives feed-forward projections from the particle filter circuit. <bold>C</bold>) Spike rasters from simulations for afferent neurons (Ca) and neurons in the action readout layer (Cb). Each line corresponds to the output of one neuron. Afferent neurons are ordered by feature selectivity (e.g., top neurons code the presence of the fixation cross). Action readout neurons are ordered by preferred movement direction. See also <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g006" position="float" xlink:type="simple"/></fig>
<p>We simulated a particle filter circuit to compute the belief about the state of the random variable with 1000 neurons per hidden state and an estimation sample size of 400. An action readout layer as described in <italic>Task class A</italic> was added that received connections from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e349" xlink:type="simple"/></inline-formula> in a feedforward manner, see <xref ref-type="fig" rid="pcbi-1003859-g006">Figure 6B</xref>. This layer computed the current belief over rewarded actions independently from the color of the color cue (i.e., it marginalized over color), see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for details.</p>
<p>The spiking activity of afferent neurons that provided evidence for one example simulation run is shown in <xref ref-type="fig" rid="pcbi-1003859-g006">Figure 6C</xref>a. Simulated neural activities from the readout layer are shown in <xref ref-type="fig" rid="pcbi-1003859-g006">Figure 6C</xref>b, see also <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1C</xref>. After the spatial cue was presented, the two consistent ensembles increased their activity. Due to competition between these ensembles, neurons fired at a medium rate. After the color cue was shown, only the ensemble consistent with both the spatial and the color cue remained active. These neurons increased their firing rate since the competing action became improbable and the winning ensemble was uncompeted. This behavior has been observed in PMd <xref ref-type="bibr" rid="pcbi.1003859-Cisek1">[3]</xref>, see <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1B</xref>. The action readout layer is not needed to reproduce this behavior, since neurons in the particle filter circuit exhibit similar behavior. However, it was reported that most neurons in PMd were not color selective <xref ref-type="bibr" rid="pcbi.1003859-Cisek1">[3]</xref>. In our model, neurons of the particle filter circuit are color selective since states are defined according to direction-color pairs. It is clear that color-related information has to be integrated with movement-related information and memorized during the memory epoch in order to solve the task. The experimental results suggest that this integration is not implemented in PMd but rather in upstream circuits. PMd could then act as a motor readout.</p>
<p>Applications of the model to various other experimental tasks can be found in supporting texts. Action-predictive activity in macaque motor cortex is also modulated by the expected value of the action. This was demonstrated for example in <xref ref-type="bibr" rid="pcbi.1003859-PastorBernier1">[25]</xref>. An application of our model to this scenario is described in <italic><xref ref-type="supplementary-material" rid="pcbi.1003859.s004">Text S3</xref></italic>. Furthermore, we show in <italic><xref ref-type="supplementary-material" rid="pcbi.1003859.s005">Text S4</xref></italic> that the model is consistent with features of neuronal activity during random-dot motion tasks <xref ref-type="bibr" rid="pcbi.1003859-Gold1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Shadlen2">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Churchland1">[27]</xref>. In <italic><xref ref-type="supplementary-material" rid="pcbi.1003859.s006">Text S5</xref></italic> it is shown that the model can also explain neuronal activitiy in area LIP during a probabilistic reasoning task <xref ref-type="bibr" rid="pcbi.1003859-Yang1">[2]</xref>.</p>
</sec></sec><sec id="s2g">
<title>Task class C: Bayesian filtering</title>
<p>Evidence integration cannot take temporal changes of the hidden variable into account. Knowledge about temporal changes can be exploited by Bayesian filtering, which is an extension of evidence integration. Here, we assume that the dynamics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e350" xlink:type="simple"/></inline-formula> are constant during the filtering process. The more general case when the dynamics may change is discussed below in <italic>Task class D</italic>. Formally, the Bayesian filtering problem considered here is to estimate the posterior distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e351" xlink:type="simple"/></inline-formula> over the states of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e352" xlink:type="simple"/></inline-formula> that represents the hidden state of a random process which is only indirectly observable via stochastic point-event observations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e353" xlink:type="simple"/></inline-formula>. In particular, state changes are assumed to be Markovian with <italic>transition rates</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e354" xlink:type="simple"/></inline-formula> for each pair of distinct states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e355" xlink:type="simple"/></inline-formula>. Transition rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e356" xlink:type="simple"/></inline-formula> defines the rate of transition from state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e357" xlink:type="simple"/></inline-formula> to state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e358" xlink:type="simple"/></inline-formula>, i.e., the probability that a transition occurs to state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e359" xlink:type="simple"/></inline-formula> in some small time interval if the current state is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e360" xlink:type="simple"/></inline-formula>, thus defining a continuous time Markov chain, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for a more formal description.</p>
<p>Note that evidence integration is a special case of Bayesian filtering with the assumption of no state transitions, i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e361" xlink:type="simple"/></inline-formula> for all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e362" xlink:type="simple"/></inline-formula>. In the following, we show that the particle filtering circuit for task class B constructed above can easily be extended to this generalization. The Bayesian filtering problem can be solved efficiently through a set of coupled differential equations<disp-formula id="pcbi.1003859.e363"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e363" xlink:type="simple"/><label>(13)</label></disp-formula>where again the inferred probabilities are obtained by normalization <xref ref-type="bibr" rid="pcbi.1003859-Brmaud1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Bobrowski1">[14]</xref>. Note that the first term in eq. (13) is identical to eq. (7), since the optimal solution for evidence integration, eq. (7), is the special case of eq. (13) for vanishing transition rates. This term is taken care of in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e364" xlink:type="simple"/></inline-formula> of the particle filtering circuit for task class B. In this circuit, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e365" xlink:type="simple"/></inline-formula> simply copies the distribution given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e366" xlink:type="simple"/></inline-formula>. We modify the connections from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e367" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e368" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e369" xlink:type="simple"/></inline-formula> instead provides the changes in probability masses needed for the second and third term, i.e., it predicts changes based on the assumed dynamics of the random variable. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e370" xlink:type="simple"/></inline-formula> approximates the desired changes of probability masses if the membrane potentials are given by<disp-formula id="pcbi.1003859.e371"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e371" xlink:type="simple"/><label>(14)</label></disp-formula>with synaptic efficacies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e372" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e373" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e374" xlink:type="simple"/></inline-formula> for all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e375" xlink:type="simple"/></inline-formula>, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>. An overview of the circuit equations and parameters is given in <xref ref-type="table" rid="pcbi-1003859-t001">Table 1</xref>, see also <xref ref-type="fig" rid="pcbi-1003859-g004">Figure 4A</xref>.</p>
<p>We tested the ability of a particle filter circuit consisting of 2000 neurons per state and an estimation sample size of 400 to track the temporal evolution of a binary random variable where state 1 transitions to state 2 with some transition rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e376" xlink:type="simple"/></inline-formula>, see <xref ref-type="fig" rid="pcbi-1003859-g007">Figure 7A</xref>. The dynamics of the circuit and the estimated probability for an example simulation run are shown in panels C,D. We simulated 100 trials, where in each trial the transition rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e377" xlink:type="simple"/></inline-formula> was drawn uniformly in [0, 30]Hz and initial probabilities were drawn uniformly in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e378" xlink:type="simple"/></inline-formula>. The estimate of the posterior at time <italic>t</italic> = 50 ms is shown in comparison to the true posterior in <xref ref-type="fig" rid="pcbi-1003859-g007">Figure 7E</xref>. See <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for details on this simulation.</p>
<fig id="pcbi-1003859-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g007</object-id><label>Figure 7</label><caption>
<title>Tracking of dynamics in ENS coding.</title>
<p><bold>A</bold>) The state of a binary random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e379" xlink:type="simple"/></inline-formula> is estimated where state 1 transitions to state 2 with some transition rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e380" xlink:type="simple"/></inline-formula>. <bold>B</bold>) Estimation is performed by a particle filter circuit without evidence input (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e381" xlink:type="simple"/></inline-formula>: dynamics layer ensembles; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e382" xlink:type="simple"/></inline-formula>: evidence layer ensembles). <bold>C</bold>) Example for the rate dynamics in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e383" xlink:type="simple"/></inline-formula>. Ensemble rate for ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e384" xlink:type="simple"/></inline-formula> (black) and whole layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e385" xlink:type="simple"/></inline-formula> (gray). While rates in ensembles change due to the prediction of a transition, inhibition keeps the overall firing rate in the layer approximately constant. <bold>D</bold>) Temporal evolution of estimated posterior probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e386" xlink:type="simple"/></inline-formula> for state 2 (black) and true posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e387" xlink:type="simple"/></inline-formula> (gray) for this example run. <bold>E</bold>) Circuit estimates of posterior probabilities at time <italic>t</italic> = 50 ms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e388" xlink:type="simple"/></inline-formula>) in comparison to true posteriors at this time (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e389" xlink:type="simple"/></inline-formula>). Shown are 100 runs (dots) with prior probability for state 1 and transition rate drawn from uniform distributions in [0.1, 0.9] and [0, 30]Hz respectively in each run. The result of the example run from panels C-D is indicated by a cross.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g007" position="float" xlink:type="simple"/></fig><sec id="s2g1">
<title>Particle filtering in a generic setup for task class C</title>
<p>We performed further computer simulations in order to test the performance of the model in a generic setup. In this setup, a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e390" xlink:type="simple"/></inline-formula> evolved according to a continuous time Markov chain with five states. In this Markov chain, state 1 transitions to states 2 or 3 which themselves transition to states 4 and 5 respectively. From states 4 and 5, a transition to state 1 is possible, see <xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8A</xref>a (bottom). Transition rates for all possible transitions were set to 1Hz. Information about the actual state was conveyed by 35 afferent neurons with state-dependent rates defined by Gaussians as shown in <xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8A</xref>a (top). Note that states 2 and 3 gave rise to very similar observations. Thus, many observations have to be integrated before these states can be distinguished. This makes inference over the current state hard if the full distribution over state probabilities is not communicated over time.</p>
<fig id="pcbi-1003859-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g008</object-id><label>Figure 8</label><caption>
<title>Particle filtering for task class C (A) and task class D (B) in the ENS code.</title>
<p><bold>Aa</bold>) State diagram of the Markov chain for the dynamics of the hidden random variable (bottom) and state-dependent firing rates of afferent neurons (top). Colors indicate the value of the hidden state. <bold>Ab</bold>) Actual hidden state over time is indicated by color in correspondence with colors in panel Aa. <bold>Ac</bold>) Spike trains of afferent neurons. Each line corresponds to the output of one afferent neuron ordered according to panel Aa. <bold>Ad</bold>) Network response to the input in panel Ac. Neurons are ordered according to their preferred state from state 1 (top neurons) to 5 (bottom neurons). <bold>Ae</bold>) Network belief (estimated posterior state probability) derived from network activity. Rows ordered by state as neurons in panel Ad. Hot color indicates high probability of the state. Note the uncertainty when state 2 or 3 is entered. <bold>Af</bold>) Summary of network performance (“model”; fraction of incorrect state estimates) in comparison with the optimal Bayesian filter (“opt”), a network with jittered synaptic efficacies (“jit”), and the optimal decision based on the most recent observation only (“inp”). Bars are means and errorbars STDs over 20 state and observation sequences (12 seconds each). <bold>B</bold>) Particle filtering for task class D. <bold>Ba</bold>) As panel Aa but with context. Dark gray arrows in the state diagram indicate transitions in context A. In context B, the transitions from states 2 to 4 and 3 to 5 are interchanged (light gray arrows). <bold>Bb</bold>) As panel Ab. Background shading indicates context (context A: white; context B: gray). <bold>Bc–Be</bold>) Actual hidden state, input spikes, networks spikes, and network belief; see panels Ac–Ae. <bold>Bf</bold>) Summary of network performance. “opt” shows performance of the optimal context-dependent Bayesian filter and “mix” a Bayesian filter where the transition rates are the mean rates over contexts A and B. The spiking network performs significantly better than the mixed Bayesian filter (paired t-test, <italic>p</italic>&lt;0.001).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g008" position="float" xlink:type="simple"/></fig>
<p>Results from simulations of a particle filter circuit with 2000 neurons per state and an estimation sample size of 400 are shown in <xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8A</xref>c–Af, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic> for details. <xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8A</xref>f shows a comparison of the model performance (“model”) with the optimal Bayesian filtering (“opt”) and the optimal model that does not take temporal information into account (the Bayes estimate based on the latest observation; “inp”). The performance of the model was very close to optimal and much better than the non-temporal Bayes estimate. We furthermore tested the robustness of the network to variations of synaptic efficacies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e391" xlink:type="simple"/></inline-formula> that determine the assumed transition rates of the random variable. In a control experiment, each individual synaptic weight from ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e392" xlink:type="simple"/></inline-formula> to ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e393" xlink:type="simple"/></inline-formula> was drawn from a log-normal distribution with mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e394" xlink:type="simple"/></inline-formula> and standard deviation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e395" xlink:type="simple"/></inline-formula>. The resulting weights assumed values that were up to 10 times larger than the mean. Network performance with jittered efficacies was indistinguishable from the performance of the homogeneous network (<xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8A</xref>f; “jit”). This robustness stems from two features of ENS-coding. First, as network belief is represented by ensemble rates, it is invariant to firing rate variations of individual neurons as long as the ensemble rate is preserved. Second, network computations are generally based on averages over ensemble activities, see eq. (14). Therefore variations in synaptic efficacies do not influence the result as long as the mean ensemble-to-ensemble weights are preserved. Note that this even holds for nonlinear link-functions, eq. (3).</p>
</sec></sec><sec id="s2h">
<title>Task class D: Context-dependent Bayesian filtering</title>
<p>In many important situations, the dynamics of a random variable changes in different contexts. Context cannot simply be formulated as a type of observation since observations just influence the probabilities of states for the given transition rates and not the dynamics themselves. Consider for example the estimation of the current body position in space. Here, an action such as forward movement can be considered as context since it increases the transition rates from any position to positions ahead. Thus, it changes the transition rates and not just the probability of a particular position. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e396" xlink:type="simple"/></inline-formula> possible contexts, consider a function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e397" xlink:type="simple"/></inline-formula> with range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e398" xlink:type="simple"/></inline-formula> that indicates the context at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e399" xlink:type="simple"/></inline-formula>. We define a context-dependent Markov chain as a Markov chain with state transition rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e400" xlink:type="simple"/></inline-formula> for each pair of distinct states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e401" xlink:type="simple"/></inline-formula>. At each time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e402" xlink:type="simple"/></inline-formula>, the chain evolves according to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e403" xlink:type="simple"/></inline-formula>. Context-dependent Bayesian filtering determines the distribution over the current state for the given observations and context. Note that Bayesian filtering used in task class C is a special case with just a single context. Also note that we use the term <italic>context</italic> here with the specific meaning of additional information about the dynamics of the random variable.</p>
<p>We encode the current context by ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e404" xlink:type="simple"/></inline-formula> that provide contextual feedback to the circuit. Each context ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e405" xlink:type="simple"/></inline-formula> consists of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e406" xlink:type="simple"/></inline-formula> context neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e407" xlink:type="simple"/></inline-formula>. At time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e408" xlink:type="simple"/></inline-formula>, only the context ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e409" xlink:type="simple"/></inline-formula> is active. The circuit architecture for particle filtering (<xref ref-type="fig" rid="pcbi-1003859-g004">Figure 4A</xref>) is extended as shown in <xref ref-type="fig" rid="pcbi-1003859-g009">Figure 9</xref> to perform particle filtering for a hidden random variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e410" xlink:type="simple"/></inline-formula> with context-dependent dynamics. Layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e411" xlink:type="simple"/></inline-formula> consists of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e412" xlink:type="simple"/></inline-formula> representations of the random variable, one for each context. Hence, for each context <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e413" xlink:type="simple"/></inline-formula> there are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e414" xlink:type="simple"/></inline-formula> ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e415" xlink:type="simple"/></inline-formula> in this layer. In addition to excitatory synaptic connections originating from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e416" xlink:type="simple"/></inline-formula>, these neurons are disinhibited by context neurons from the corresponding context ensembles. The disinhibitory effect of context is consistent with experimental data about neocortical circuits. There, context information from other cortical areas is believed to be provided through feedback connections. Those connections have abundant terminals in neocortical layer 1 where they recruit disinhibitory circuits <xref ref-type="bibr" rid="pcbi.1003859-Jiang1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Pi1">[29]</xref>. Formally, the membrane potential of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e417" xlink:type="simple"/></inline-formula>, the <italic>m</italic>-th neuron in ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e418" xlink:type="simple"/></inline-formula>, is given by<disp-formula id="pcbi.1003859.e419"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e419" xlink:type="simple"/><label>(15)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e420" xlink:type="simple"/></inline-formula> denotes the EPSP-filtered spike train of a neuron in ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e421" xlink:type="simple"/></inline-formula> of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e422" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e423" xlink:type="simple"/></inline-formula> denotes the efficacy of the connecting synapse. These efficacies are set proportionally to the transition rates in the corresponding context, see <xref ref-type="table" rid="pcbi-1003859-t002">Table 2</xref>. The membrane potential of a neuron in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e424" xlink:type="simple"/></inline-formula> is similar to the non-contextual case with the difference that each neuron is disinhibited by neurons that code for the same state in various contexts<disp-formula id="pcbi.1003859.e425"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e425" xlink:type="simple"/><label>(16)</label></disp-formula></p>
<fig id="pcbi-1003859-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g009</object-id><label>Figure 9</label><caption>
<title>Particle filter circuit architecture for task class D.</title>
<p>Extended circuit with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e426" xlink:type="simple"/></inline-formula> ensembles (indicated by red and blue neurons respectively) and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e427" xlink:type="simple"/></inline-formula> neurons per ensemble and two possible contexts. Ensembles in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e428" xlink:type="simple"/></inline-formula> are duplicated for each context. These neurons receive context information via disinhibition from context neurons (yellow; only connections from context 1 shown for clarity). Disinhbition and lateral inhibition indicated by shortcuts as defined in <xref ref-type="fig" rid="pcbi-1003859-g004">Figure 4B, C</xref>. Arrows indicate efferent connections. A schematic overview of the circuit is shown in the inset.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g009" position="float" xlink:type="simple"/></fig><table-wrap id="pcbi-1003859-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.t002</object-id><label>Table 2</label><caption>
<title>Particle filter circuit equations for task class D.</title>
</caption><alternatives><graphic id="pcbi-1003859-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.t002" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Layer</td>
<td align="left" rowspan="1" colspan="1">Neurons</td>
<td align="left" rowspan="1" colspan="1">Membrane voltage and parameters</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e429" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e430" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e431" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e432" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e433" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e434" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e435" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e436" xlink:type="simple"/></inline-formula> for all <italic>i</italic>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e437" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e438" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e439" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e440" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e441" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e442" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e443" xlink:type="simple"/></inline-formula></td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt102"><label/><p>Here we have defined <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e444" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e445" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e446" xlink:type="simple"/></inline-formula> denotes lateral inhibition and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e447" xlink:type="simple"/></inline-formula> disinhibition. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e448" xlink:type="simple"/></inline-formula> is an arbitrary constant.</p></fn></table-wrap-foot></table-wrap>
<p>Due to disinhibition of layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e449" xlink:type="simple"/></inline-formula> by context ensembles, only those ensembles in the layer which correspond to the current context are active. The active neurons in this layer disinhibit neurons in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e450" xlink:type="simple"/></inline-formula> in the same way as in the non-contextual case. Thus, in each individual context, a subcircuit is recruited that consists of the whole layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e451" xlink:type="simple"/></inline-formula> and the ensembles for the current context in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e452" xlink:type="simple"/></inline-formula>. Since the weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e453" xlink:type="simple"/></inline-formula> from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e454" xlink:type="simple"/></inline-formula> to ensembles for context <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e455" xlink:type="simple"/></inline-formula> in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e456" xlink:type="simple"/></inline-formula> implement the dynamics of the random variable in that context, the circuit approximates the correct transition dynamics of the random variable in each context. The resulting membrane potential equations are summarized together with parameters in <xref ref-type="table" rid="pcbi-1003859-t002">Table 2</xref>.</p>
<sec id="s2h1">
<title>Particle filtering in a generic setup for task class D</title>
<p>In order to test the ability of the model to perform context-dependent Bayesian filtering, we considered a random variable with context-dependent dynamics. Two possible contexts A and B were indicated by 20 context neurons. The underlying Markov chain with context-dependent transition rates is shown in <xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8B</xref>a (bottom). The dynamics in context A was equivalent to the one considered in the generic test for task class C (dark gray arrows). However in context B, state 2 exclusively transitioned to state 5 and state 3 exclusively to 4 (light gray arrows). Additionally, we considered a more complex observation model in this example (panel Ba, top). State-dependent firing rates were either Gaussians with varying variances, bimodal, or uniform. Note that states 4 and 5 gave rise to quite similar observations. Hence, it is hard to distinguish these states without context. Panels Bc-Be show that the model makes good use of this context information (context indicated by gray shading in panel Bc). At time <italic>t</italic> = 2 s, there was a transition from state 2 to state 4 in context A, and at time <italic>t</italic> = 4.25 s, there was a transition from state 2 to state 5 in context B. In both cases, the network estimate followed immediately since the expected transitions were modulated by context information. We also tested the performance of an optimal context-dependent Bayesian filter and a Bayesian filter without context information. This filter was based on a dynamics model with mean transition rates over both contexts, which resulted in suboptimal performance, see <xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8B</xref>f. Implementation details are given in <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>.</p>
</sec><sec id="s2h2">
<title>Particle filtering in ENS coding for self-localization</title>
<p>Estimation of the body position in space (self-localization) is an essential ingredient of autonomous agents. In robotics, particle filtering is one of the most successful techniques for self localization <xref ref-type="bibr" rid="pcbi.1003859-Murphy1">[6]</xref>. Here, we demonstrate that particle filtering in ENS coding can be used for self-localization in environments with ambiguous evidence.</p>
<p>Every state of the considered hidden random variable corresponded to some position in the environment and transitions were possible between spatially adjacent states. The movement of the agent provided context for the particle filter such that movement in a particular direction enhanced transitions that point to that direction (<xref ref-type="fig" rid="pcbi-1003859-g010">Figure 10A</xref>). Sensory cues provided partial information about the current position. We simulated a two-chamber maze with a small opening that connects these chambers. The southern parts of the chambers gave rise to exactly the same observations, making it impossible to distinguish them without prior information (colored circles in <xref ref-type="fig" rid="pcbi-1003859-g010">Figure 10A</xref>). Observations in more northern parts were different and in the very north, no observations were experienced (corresponding for example to a dark corridor). <xref ref-type="fig" rid="pcbi-1003859-g010">Figure 10B</xref> shows the estimate of the network for a single trajectory. The model was started with a uniform prior distribution over all positions. In the southern terrain, the left and the right chamber cannot be distinguished, and accordingly, ensembles in both areas were active, indicating possible positions (<italic>t</italic> = 300 ms). In the more northern parts, observations disambiguate the current position, and activity in the right chamber ensembles ceased (<italic>t</italic> = 600, 900 ms). As the upper northern region was reached, no more evidence was provided from the environment (<italic>t</italic> = 1500, 2400 ms). Still, the network predicted movement to the right correctly thus utilizing movement information provided via context ensembles. As the right chamber was entered, the posterior was sharpened due to unambiguous sensory input. It remained single peaked even in southern parts of the chamber although these terrains produced ambiguous sensory input (<italic>t</italic> = 3300, 3800 ms).</p>
<fig id="pcbi-1003859-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g010</object-id><label>Figure 10</label><caption>
<title>Self-localization through particle filtering in ENS coding.</title>
<p><bold>A</bold>) Two-chamber maze (black lines) and transitions between states in various contexts. States are arranged on a 10×10 grid in the maze (crossing points of gray lines). Light gray lines indicate bidirectional state transitions with low transition rates (0.1 Hz). Dark gray arrows indicate transitions with high transition rates (3.5 Hz). Context is defined by movement direction (right, down, left, up). Colored circles indicate sensory evidence. Each color stands for one afferent neuron with a Gaussian spatial receptive field. The circle indicates the STD of the Gaussian. Note that the southern chambers give rise to identical observations. Observations are truncated at the height of the opening between the chambers such that no observations are experienced in the most northern parts. <bold>B</bold>) Network estimate of posterior probability (see color bar on the right for color code) for one trajectory through the maze (white trace; dot denotes current position) at different times. Spatial layout as in A. Various phases of the trajectory are shown: Uninformative prior knowledge (<italic>t</italic> = 10 ms), ambiguous estimates (<italic>t</italic> = 300 ms); disambiguation (<italic>t</italic> = 600, 900 ms); states without evidence (<italic>t</italic> = 1500, 2400 ms); unambiguous state estimation based on ambiguous evidence (<italic>t</italic> = 3300, 3800 ms).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g010" position="float" xlink:type="simple"/></fig></sec></sec><sec id="s2i">
<title>Task class E: Internal beliefs as context</title>
<p>In many tasks, the context variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e457" xlink:type="simple"/></inline-formula> is not explicitly available to the animal but rather has to be estimated from noisy evidence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e458" xlink:type="simple"/></inline-formula> as well. For example, in many sequential tasks the current stage within the task can provide valuable context information which can be used to time actions or to decide when beliefs should be reset. In the computational framework considered here, this can be achieved by treating the context variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e459" xlink:type="simple"/></inline-formula> as a random variable that is estimated by a particle filter circuit from the given evidence <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e460" xlink:type="simple"/></inline-formula>. Estimated context is then utilized for the estimation of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e461" xlink:type="simple"/></inline-formula> in a particle filter circuit with context.</p>
<p>In the tasks considered in task class D, the context was unambiguously given and all neurons of exactly one context ensemble had a firing rate larger than zero. This is not the case in task class E, since here context neurons encode a belief about the current context. The context-dependent particle filter should therefore deal with context in a graded manner. This is accomplished by a simple modification of how neurons in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e462" xlink:type="simple"/></inline-formula> integrate context, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>. In the modified circuit, effective transition rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e463" xlink:type="simple"/></inline-formula> of the context-dependent filtering circuit are given as a linear mixture of the context-dependent transition rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e464" xlink:type="simple"/></inline-formula>, where each contributes approximately proportionally to the current belief <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e465" xlink:type="simple"/></inline-formula> in this context<disp-formula id="pcbi.1003859.e466"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e466" xlink:type="simple"/><label>(17)</label></disp-formula></p>
<p>To demonstrate the viability of this approach, we reconsidered the ambiguous target task.</p>
<sec id="s2i1">
<title>The ambiguous target task revisited</title>
<p>The ambiguous target task has a clear sequential structure (initial fixation, spatial cue, memory epoch, color cue), see <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1A</xref>. The corresponding hidden variable <italic>c</italic>(<italic>t</italic>) – for which the current value is given by the momentary stage of the experimental trial – is shown in <xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11A</xref>a.</p>
<fig id="pcbi-1003859-g011" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.g011</object-id><label>Figure 11</label><caption>
<title>Context-dependent Bayesian filtering in two successive trials of the ambiguous target task.</title>
<p><bold>A</bold>) Represented random variables. <bold>Aa</bold>) Dynamics of a random variable that codes the current phase in a trial of the ambiguous target task (CHT: fixation; SC: spatial cue; MEM: memory cue; CC: color cue). Possible observations in each phase are indicated in boxes. <bold>Ab</bold>) Context-dependent Bayesian filtering is performed for a random variable with 16 hidden states corresponding to direction-color pairs as in <xref ref-type="fig" rid="pcbi-1003859-g006">Figure 6A</xref>a. Gray lines indicate context-dependent transitions. All-to-all transitions are possible in the fixation phase (CHT). There are no transitions in other phases of a trial. <bold>Ac</bold>) The action readout layer infers a color-independent random variable by marginalization over color in each direction. <bold>B</bold>) Circuit structure. The circuit on the top (ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e473" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e474" xlink:type="simple"/></inline-formula>) performs Bayesian filtering on the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e475" xlink:type="simple"/></inline-formula> indicated in panel (Aa). It provides context for another particle filter circuit (middle gray box; ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e476" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e477" xlink:type="simple"/></inline-formula>) that generates a belief about the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e478" xlink:type="simple"/></inline-formula> indicated in Ab. An action readout layer is added (bottom gray box; ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e479" xlink:type="simple"/></inline-formula>). <bold>C</bold>) Spike rasters from a simulation of two successive trials for afferent neurons (Ca), neurons in the particle filter circuit for the phase in the trial (Cb), and neurons in the action readout layer (Cc). Neurons in Cb are coding for the current phase of the trial (ordered from bottom to top: CHT, SC, MEM, and CC). Neuron ordering in Ca and Cc as in <xref ref-type="fig" rid="pcbi-1003859-g006">Figure 6</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.g011" position="float" xlink:type="simple"/></fig>
<p>The modeled task is similar to the ambiguous target task considered above with the difference that several trials of the task are performed sequentially, i.e., a sequence of epochs (fixation, spatial cue, memory, color cue) is directly followed by the fixation epoch, indicating the start of a new trial, again followed by the spatial cue and so on. The difficulty of this task is that in the fixation epoch, the internal belief about the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e467" xlink:type="simple"/></inline-formula> that encodes the current color-direction pair is highly biased by the last trial. This bias is problematic since an optimal prior would assign equal probability to all color-direction pairs. In other words, during the fixation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e468" xlink:type="simple"/></inline-formula> should be reset. A reset can be accomplished by assuming that during fixation the dynamics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e469" xlink:type="simple"/></inline-formula> are such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e470" xlink:type="simple"/></inline-formula> can quickly change its state from any state to any other state (i.e., transition rates are high between all pairs of states, see <xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11A</xref>b). In other epochs however, the assumption is that the value of the random variable is fixed and does not change (transition rates are zero between all pairs of distinct states). We arrive at a context-dependent Bayesian filtering problem where the dynamics of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e471" xlink:type="simple"/></inline-formula> depend on the current estimate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e472" xlink:type="simple"/></inline-formula>, the epoch in the trial.</p>
<p>We modeled the context-dependent reset of the internal belief by extending the circuit for the ambiguous target task in the following manner. The internal belief about the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e480" xlink:type="simple"/></inline-formula> that encodes the current color-direction pair (<xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11A</xref>b) is generated by a particle filter circuit. Context is provided to this circuit by an estimate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e481" xlink:type="simple"/></inline-formula>, the current epoch in the trial (<xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11B</xref>). This estimate is performed by a particle filter circuit that receives the same sensory evidence but no context (task class C). In the context of the fixation-epoch, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e482" xlink:type="simple"/></inline-formula> is believed to change its state rapidly (all-to-all transitions in the dynamics of the random variable, gray connections in <xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11A</xref>b). In the context of other epochs, the random variable is believed to be constant (no transitions between states, i.e., pure evidence integration). Finally, an action readout layer derives the belief over the rewarded action. In <xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11C</xref>, a simulation for two successive trials of the ambiguous target task is shown. The epoch <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e483" xlink:type="simple"/></inline-formula> is correctly inferred by the particle filter circuit that provides the epoch-context (<xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11C</xref>b). This context influences information processing in the subsequent circuit for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e484" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11C</xref>c). While information is retained during the memory epochs, the belief about the rewarded movement direction returns to an uninformative prior during the memory epoch at 1 s to 1.25 s. This example demonstrates that internally generated beliefs about random variables can act as valuable context in ENS coding.</p>
</sec></sec></sec><sec id="s3">
<title>Discussion</title>
<p>It has recently been demonstrated that the dynamics of recurrent networks of spiking neurons can perform MCMC sampling on a distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e485" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003859-Buesing1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Pecevski1">[9]</xref>. The distribution can be approximately recovered by observing the evolution of the network state trajectory for some time. Such a temporal representation is less suitable for distributions that have to be updated rapidly since each estimate of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e486" xlink:type="simple"/></inline-formula> needs several hundreds of milliseconds. We have therefore proposed and analyzed in this article ENS coding, where ensembles of neurons code for each state of a random variable. In this coding scheme, adaptations of internal beliefs can be established on the time-scale of EPSPs, see <xref ref-type="fig" rid="pcbi-1003859-g005">Figures 5E</xref> and <xref ref-type="fig" rid="pcbi-1003859-g008">8</xref>. Similarly, downstream readout neurons can rapidly estimate ENS coded probability values according to eq. (1) from neural ensembles, while such readout operation from neural sampling networks demands the integration of spikes over intervals of several hundred milliseconds. Another deficiency of the neural sampling approach is the need for unbiologically strong synaptic connections. This results from the principle that random variables are encoded by single neurons in neural sampling, which necessitates strong connections in order to ensure sufficient impact on postsynaptic targets. Unbiologically strong synaptic connections are not necessary in ENS coding, since targets can be activated in a cooperative manner by neuronal ensembles. This is for example apparent in the inverse scaling of weights with ensemble size in eq. (6).</p>
<p>We have shown that particle filtering <xref ref-type="bibr" rid="pcbi.1003859-Murphy1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Doucet1">[7]</xref> can be performed by circuits of spiking neurons in ENS coding. Numerous engineering applications of particle filtering to tasks belonging to task class D exist. In such tasks, particles are evolved according to a dynamics-model that depends on context, such as the movement direction in a self-localization task. This particle filtering with context cannot be emulated by approximate Bayesian filtering as described in task class C. To the best of our knowledge, this article provides the first proof that this powerful operation is in principle accessible to spiking neural circuits. We have demonstrated in computer simulations that ENS coding enables neuronal circuits to perform these essential operations with high fidelity, thus making them suitable for higher-level decision-related processing. Lee and Mumford <xref ref-type="bibr" rid="pcbi.1003859-Lee1">[30]</xref> proposed that particle filtering could be the basic computational operation in hierarchical cortical processing. We have demonstrated a first step in that direction in a spiking model with ENS coding by showing that the belief about a random variable can provide context information for the temporal processing related to other variables, see <italic>The ambiguous target task revisited</italic>.</p>
<sec id="s3a">
<title>Model simplifications and possible extensions</title>
<p>For consistency with the neural sampling approach, we used in this article rectangular shaped EPSPs. To test how deviations from rectangular EPSPs effect circuit performance, we performed simulations where all EPSPs were modeled as exponentially decaying EPSPs with decay time constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e487" xlink:type="simple"/></inline-formula>ms such that the integral over the EPSP is unchanged. The particle filter circuit was tested in the generic setup for task class C (see <xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8A</xref>). Despite of its strong deviation from the rectangular shape, exponential EPSPs caused only a slight decrease of circuit performance (the percentage of incorrect state estimates was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e488" xlink:type="simple"/></inline-formula>% as compared to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e489" xlink:type="simple"/></inline-formula>% for rectangular EPSPs).</p>
<p>The model also uses particular forms of instantaneous lateral inhibition and disinhibition. Although both forms of inhibition have been reported to play crucial roles in cortical information processing <xref ref-type="bibr" rid="pcbi.1003859-Letzkus1">[20]</xref>–<xref ref-type="bibr" rid="pcbi.1003859-Fino1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Jiang1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Pi1">[29]</xref>, the exact circuitry and function of those inhibitory circuits is still unknown. The lateral inhibition used in our circuit model is however consistent with a recent study which showed that inhibition has a broader spatial selectivity than excitation in visual cortex of awake mice <xref ref-type="bibr" rid="pcbi.1003859-Haider1">[31]</xref>. Such broader selectivity is expected in our model since lateral inhibition is common to all ensembles for a random variable. Apart from that, the assumption that inhibition follows excitation instantaneously is clearly a model simplification. A recent experimental study <xref ref-type="bibr" rid="pcbi.1003859-Okun1">[32]</xref> revealed that cortical inhibition lags excitation by about 3 ms in anesthetized rats (the lag is possibly smaller in awake animals, see <xref ref-type="bibr" rid="pcbi.1003859-Haider1">[31]</xref>). In order to test whether the circuit is tolerant to delayed inhibition, we performed control simulations where in addition to the use of exponential EPSP shapes, both lateral inhibition and disinhibition was delayed by 3 ms in the generic setup for task class C (see <xref ref-type="fig" rid="pcbi-1003859-g008">Figure 8A</xref>). We found that delayed lateral inhibition can lead to activity peaks as excitation arising from incoming evidence cannot be compensated rapidly. This can lead to unstable circuit activity when lateral inhibition tries to compensate these peaks in the delayed negative feedback loop. Instabilities can be avoided by reduction of the inhibitory drive, i.e., by reducing the lateral inhibition scaling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e490" xlink:type="simple"/></inline-formula> in eq. (33). Simulations showed that with reduced inhibition scaling, the network tolerates delayed inhibition with a slight decrease of performance (the percentage of incorrect state estimates was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e491" xlink:type="simple"/></inline-formula>% as compared to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e492" xlink:type="simple"/></inline-formula>% without delay; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e493" xlink:type="simple"/></inline-formula>).</p>
<p>In ENS coding, each neuron is tuned to one value of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e494" xlink:type="simple"/></inline-formula>. The encoded random variable may represent a specific feature relevant for some task. Many experiments show that such tunings exist in various cortical areas, such as the tuning of PMd neurons to potentially rewarded movement direction <xref ref-type="bibr" rid="pcbi.1003859-Cisek1">[3]</xref>. However, the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e495" xlink:type="simple"/></inline-formula> does not necessarily correspond to a single task-relevant feature. For example, the random variable encoded in the particle filter circuit for the ambiguous target task represents direction-color pairs (see <xref ref-type="fig" rid="pcbi-1003859-g006">Figure 6A</xref>a). Therefore, neurons in this circuit are selective for both the spatial cue and the color cue. This mixed tuning helps to integrate the temporally separated cues. Mixed selectivity of neurons has been found in higher cortical areas such as prefrontal cortex, and its computational benefits have been highlighted in <xref ref-type="bibr" rid="pcbi.1003859-Rigotti1">[33]</xref>. Hence, ENS coding is consistent with these findings. We note however that in the pure formulation of ENS coding, mixed selectivity to many task aspects is problematic since the number of ensembles necessary to encode all possible states over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e496" xlink:type="simple"/></inline-formula> task dimensions grows exponentially with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e497" xlink:type="simple"/></inline-formula>. One possibility to overcome exponential growth for large <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e498" xlink:type="simple"/></inline-formula> is to consider approximations schemes such as neglecting mixed configurations that are highly unlikely.</p>
<p>The important question how the parameters of the network could be attained by learning from experience is outside of the scope of this paper. However, some possible solutions to the learning problem can be sketched. For the particle filtering circuit, two classes of synaptic connections could be adapted through learning processes. First, synaptic efficacies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e499" xlink:type="simple"/></inline-formula> from evidence neurons to neurons in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e500" xlink:type="simple"/></inline-formula>. These efficacies encode the log-firing rates of evidence neurons for the given hidden state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e501" xlink:type="simple"/></inline-formula>. It has been shown that hidden-cause representations that require such synaptic efficacies can be learned in spiking neural networks with lateral inhibition through spike-timing-dependent (STDP)-like synaptic plasticity rules <xref ref-type="bibr" rid="pcbi.1003859-Habenschuss1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Nessler1">[35]</xref>. Hence, it seems quite feasible that the efficacies <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e502" xlink:type="simple"/></inline-formula> can be attained in an self-organized manner through STDP. The second type of connections, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e503" xlink:type="simple"/></inline-formula> from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e504" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e505" xlink:type="simple"/></inline-formula> encode the dynamics of the random variable in terms of the rate of change <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e506" xlink:type="simple"/></inline-formula> from state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e507" xlink:type="simple"/></inline-formula> to state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e508" xlink:type="simple"/></inline-formula>. In other words, the synapse needs to track how often neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e509" xlink:type="simple"/></inline-formula> is active after neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e510" xlink:type="simple"/></inline-formula> (the synaptic efficacies needed for task class A are of a similar nature). Again, this tracking can be done by a temporal Hebbian learning rule. In particular, it has recently been shown in <xref ref-type="bibr" rid="pcbi.1003859-Kappel1">[36]</xref> that such temporal relationships can be learned through STDP-like learning rules in networks of spiking neurons that implement hidden Markov models. A more sophisticated learning approach that requires additional circuitry was outlined in <xref ref-type="bibr" rid="pcbi.1003859-Rezende1">[37]</xref>. Of course, these results do not immediately generalize to the architecture proposed in this article, and further studies are needed to prove the viability of such a learning approach. Finally, we note that the feature of the particle filter circuit (and ENS coding in general) that individual synaptic efficacies do not need to be adjusted to exact values as long as the mean efficacy between ensembles is correct (see <italic>Particle filtering in a generic setup for task class C</italic>) may prove advantageous for learning processes.</p>
</sec><sec id="s3b">
<title>Experimentally testable predictions</title>
<p>We investigated the behavior of the model and compared it to experimental results. Our results so far indicate that ENS coding is consistent with a number of experimental studies. It is noteworthy that the lateral inhibition that is needed to stabilize network firing rates leads to the typical transient ensemble rate increases at stimulus-onset (see transient responses in <xref ref-type="fig" rid="pcbi-1003859-g005">Figure 5D</xref> and <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1C</xref> in <italic><xref ref-type="supplementary-material" rid="pcbi.1003859.s006">Text S5</xref></italic>).</p>
<p>While many laboratory tasks implement a variant of evidence integration (task class B), there is a lack of studies in the experimental literature for task classes D and E. We hypothesized in <italic>Task class E: Internal beliefs as context</italic> that the current values of important context variables are estimated in higher brain areas. Hence, one prediction of the model is that neural activities in such areas should not only be related to variables of primary interest, but also to context such as the current phase in a task with sequential structure, see <xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11B,C</xref>. Evidence for such representations in monkey dorsolateral prefrontal cortex has been reported <xref ref-type="bibr" rid="pcbi.1003859-Jin1">[38]</xref>. Our model also predicts that activity in neuronal ensembles that represent context should modulate the activity of decision-related ensembles in a manner that is fundamentally different from the impact of direct evidence. In particular, according to our circuit models in task classes D and E, context gates or modulates activity in such neurons. Task context has been shown to modulate neuronal activity in primate prefrontal cortex <xref ref-type="bibr" rid="pcbi.1003859-Asaad1">[39]</xref> as well as in various lower level visual areas including area MT <xref ref-type="bibr" rid="pcbi.1003859-Maunsell1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Saalmann1">[41]</xref>. These findings are contrasted by studies that showed that task-context influenced noise-correlations but not firing rates in MT in a variant of the random-dot motion task <xref ref-type="bibr" rid="pcbi.1003859-Cohen1">[42]</xref>. The general term context of course subsumes many different types of contextual information in various quite different task settings, which may explain the discrepancies between the different studies. In this work, context is defined specifically as additional information about the dynamics of the random variable. Experimental setups where context information is indicative of the dynamics of task-relevant variables would help to elucidate how such information alters temporal processing in cortical circuits.</p>
<p>We proposed disinhibition as one possibility for context-dependent modulation, consistent with the experimental findings that disinhibitory circuits are recruited by feedback connections in neocortical layer 1 <xref ref-type="bibr" rid="pcbi.1003859-Jiang1">[28]</xref>. We note however that such effects could be implemented in cortical circuits by a number of mechanisms <xref ref-type="bibr" rid="pcbi.1003859-Katz1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Gisiger1">[19]</xref>.</p>
<p>We applied particle filtering – one of the most successful techniques for self localization in autonomous robots – in ENS coding to self-localization, a particularly important task for many animals. Whether self-localization in animals is solved in a similar manner is of course still unknown. There have however been studies which show that ambiguous sensory information can be resolved on the neuronal level in rodents <xref ref-type="bibr" rid="pcbi.1003859-Skaggs1">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Chen1">[44]</xref>. This indicates that the algorithm employed by the brain is in fact quite powerful. The particular implementation proposed here also implies that the spatial structure of the environment (i.e., possible transitions between locations in space) should be encoded in the synaptic weight matrix of particular neural circuits (edges and arrows in <xref ref-type="fig" rid="pcbi-1003859-g010">Figure 10A</xref>). Furthermore, our model predicts that information about motor events (movement) is treated by such circuits as context. Hence, these signals impact circuit activity quite differently from sensory evidence, see the <xref ref-type="sec" rid="s3">discussion</xref> above. Evidence for nonlinear interaction of visual information and movement information in self-localization of mice has been reported recently <xref ref-type="bibr" rid="pcbi.1003859-Chen1">[44]</xref>.</p>
</sec><sec id="s3c">
<title>Related work</title>
<p>Probabilistic population codes (PPC; <xref ref-type="bibr" rid="pcbi.1003859-Ma1">[24]</xref>) have been suggested as one hypothesis how probability distributions could be coded in the spiking activity of neurons. In the PPC concept, one assumes that each neuron is (at least implicitly) linked to a stimulus via a tuning function. A hypothetical decoder would then apply Bayes rule to decode the stimulus distribution, making use of the tuning functions of the neurons. In ENS coding considered here, the neural ensembles produce samples from a distribution and a hypothetical decoder would just count spikes. Accumulation of evidence in LIP in a random-dot motion task has been modeled in the PPC framework <xref ref-type="bibr" rid="pcbi.1003859-Beck1">[45]</xref>. In general, information can be accumulated in PPC simply by adding up activity from afferent neurons, given that this activity follows Poisson-like statistics. The model however assumes that the hidden variable is static. In fact, tracking of dynamic variables, such as those considered in task classes C–E, is hard to implement in the PPC framework <xref ref-type="bibr" rid="pcbi.1003859-Lochmann1">[46]</xref>.</p>
<p>Several spiking neural network models for Bayesian filtering have been proposed in the literature with very similar basic ideas to solve the problem <xref ref-type="bibr" rid="pcbi.1003859-Rao1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Denve1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Boerlin1">[48]</xref>. Denève <xref ref-type="bibr" rid="pcbi.1003859-Denve1">[47]</xref> proposed a model where a single integrate-and-fire neuron estimates the hidden state of a binary random variable with temporal dynamics. The model can only deal with binary variables, whereas our proposed model is not restricted in this respect. A similar model was proposed in <xref ref-type="bibr" rid="pcbi.1003859-Boerlin1">[48]</xref>. There the assumption was that the continuous-valued random variable evolves according to a drift-diffusion process. Our implementation of Bayesian filtering in ENS coding complements this work by considering discrete-valued random variables with the assumption that the dynamics can be approximated by a continuous-time Markov chain.</p>
<p>Rao <xref ref-type="bibr" rid="pcbi.1003859-Rao1">[15]</xref> considered Bayesian filtering in discrete time through a network of spiking neurons. This model was however not based on a rigorous coding scheme with respect to information transfer through spikes. The instantaneous firing rate of individual neurons was regarded as the distribution-encoding quantity and it was implicitly assumed that spikes can communicate this quantity in sufficient quality. In the current article, we base representations of beliefs on the spiking activity in the first place and propose ENS coding as a solution where the fidelity of representation is provided through ensemble activity. Our analysis identified how network properties such as the ensemble size, the maximal firing rate, and the membrane time constant influence the quality of the representation. In any case, the noise introduced by stochastic spiking cannot be neglected in general. We have demonstrated in computer simulations that still, temporal information processing on demanding tasks is possible in ENS coding.</p>
<p>We have argued that particle filtering with context is an important operation that is needed for example for self-localization. The current work shows that this extension of Bayesian filtering, that has not been considered in previous models, can easily be implemented in the ENS code.</p>
<p>Several non-spiking models for Bayesian filtering have been proposed previously <xref ref-type="bibr" rid="pcbi.1003859-Bobrowski1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Rao2">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Beck2">[50]</xref>. We have based our circuit model for task classes B and C on well-known filtering equations <xref ref-type="bibr" rid="pcbi.1003859-Brmaud1">[13]</xref> that also provided the basis for the rate-based model considered in <xref ref-type="bibr" rid="pcbi.1003859-Bobrowski1">[14]</xref>. Several conclusions can be drawn when comparing the model based on ENS coding considered here with the non-spiking model from <xref ref-type="bibr" rid="pcbi.1003859-Bobrowski1">[14]</xref>. First, we confirmed through computer simulations that quite demanding information processing tasks are possible with spiking neurons using ENS coding, despite of substantial noise introduced by stochastic spiking. Second, ensemble coding is clearly necessary for the tasks considered in this article if neuronal responses are stochastic. We used on the order of 1000 neurons per ensemble in the simulations. This number was not optimized, but ensemble sizes below 100 are not sufficient, for example in the ambiguous target task (see <italic><xref ref-type="supplementary-material" rid="pcbi.1003859.s001">Dataset S1</xref></italic>). Third, besides the complications that stochastic spike codes introduce, we have shown that ENS coding also has some positive effects. We found that multiplicative operations can be replaced by gating of neuronal activity in ENS coding, for example through synaptic gating or through disinhibition. This property of ENS coding provides an attractive alternative to previously proposed solutions for the unavoidable demand of nonlinear processing in Bayesian filtering, such as multiplicative interaction of synaptic inputs <xref ref-type="bibr" rid="pcbi.1003859-Bobrowski1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Beck2">[50]</xref>, or the use of precise dendritic nonlinearities <xref ref-type="bibr" rid="pcbi.1003859-Rao1">[15]</xref>. Finally, the use of a spiking model enabled us to directly compare model characteristics to experimental data. We found that the model is consistent with quite diverse experimental results <xref ref-type="bibr" rid="pcbi.1003859-Gold1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1003859-Cisek1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-PastorBernier1">[25]</xref>.</p>
</sec><sec id="s3d">
<title>Conclusions</title>
<p>Sample-based representations of probability distributions provide an attractive framework for modeling probabilistic inference on static evidence in cortical networks. We have shown that ensemble-based neural sampling enables cortical networks to perform also powerful context-dependent temporal inference. Hence, our model provides a new and theoretically founded basis for understanding temporal probabilistic computations in various higher-level cortical areas.</p>
</sec></sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<p>For easy reference, <xref ref-type="table" rid="pcbi-1003859-t003">Table 3</xref> summarizes the notational conventions used in this article.</p>
<table-wrap id="pcbi-1003859-t003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003859.t003</object-id><label>Table 3</label><caption>
<title>Notation.</title>
</caption><alternatives><graphic id="pcbi-1003859-t003-3" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003859.t003" xlink:type="simple"/>
<table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" rowspan="1" colspan="1">Variable name</td>
<td align="left" rowspan="1" colspan="1">Description</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e511" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Random variable with range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e512" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e513" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Number of states of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e514" xlink:type="simple"/></inline-formula> and number of ensembles that represent <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e515" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e516" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Ensemble <italic>i</italic> represents the belief that a random variable is in state <italic>i</italic>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e517" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Number of neurons per ensemble.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e518" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1"><italic>m</italic>-th neuron in ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e519" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e520" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Spike train of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e521" xlink:type="simple"/></inline-formula> at time <italic>t</italic>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e522" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">EPSP-filtered spike train of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e523" xlink:type="simple"/></inline-formula> at time <italic>t</italic>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e524" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Summed activity (probability mass) for state <italic>i</italic> at time <italic>t</italic>: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e525" xlink:type="simple"/></inline-formula>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e526" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Membrane potential of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e527" xlink:type="simple"/></inline-formula> at time <italic>t</italic>.</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e528" xlink:type="simple"/></inline-formula></td>
<td align="left" rowspan="1" colspan="1">Instantaneous firing rate of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e529" xlink:type="simple"/></inline-formula> at time <italic>t</italic>.</td>
</tr>
</tbody>
</table>
</alternatives><table-wrap-foot><fn id="nt103"><label/><p>Description of frequently used variables for easy reference. In general, capital letters refer to ensembles and lower case letters to neurons in these ensembles.</p></fn></table-wrap-foot></table-wrap><sec id="s4a">
<title>Spike trains, EPSP shapes, and EPSP-filtered spike trains</title>
<p>Here, we define EPSP-filtered spike trains and the shape of EPSPs used throughout the article. We denote the spike-train <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e530" xlink:type="simple"/></inline-formula> of a neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e531" xlink:type="simple"/></inline-formula> as the sum of Dirac delta functions<disp-formula id="pcbi.1003859.e532"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e532" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e533" xlink:type="simple"/></inline-formula> denotes the <italic>j</italic>-th spike-time of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e534" xlink:type="simple"/></inline-formula>. We define the EPSP-filtered spike train <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e535" xlink:type="simple"/></inline-formula> as</p>
<p><disp-formula id="pcbi.1003859.e536"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e536" xlink:type="simple"/><label>(18)</label></disp-formula>Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e537" xlink:type="simple"/></inline-formula> denotes the EPSP shape produced by a spike of a presynaptic neuron. We use in this article rectangular EPSP shapes of the form<disp-formula id="pcbi.1003859.e538"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e538" xlink:type="simple"/><label>(19)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e539" xlink:type="simple"/></inline-formula> denotes the Heaviside step function and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e540" xlink:type="simple"/></inline-formula> is the length of the EPSP. For some control simulations, we use exponentially decaying EPSP shapes</p>
<disp-formula id="pcbi.1003859.e541"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e541" xlink:type="simple"/><label>(20)</label></disp-formula></sec><sec id="s4b">
<title>ENS code and filtered probability distributions</title>
<p>Assuming rectangular EPSP shapes of length <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e542" xlink:type="simple"/></inline-formula>, the filtered probability denoted as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e543" xlink:type="simple"/></inline-formula> is the average probability for state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e544" xlink:type="simple"/></inline-formula> in time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e545" xlink:type="simple"/></inline-formula>, that is<disp-formula id="pcbi.1003859.e546"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e546" xlink:type="simple"/><label>(21)</label></disp-formula></p>
<p>We denote the ensemble average of a random variable by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e547" xlink:type="simple"/></inline-formula>. Consider a given fixed temporal evolution of the probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e548" xlink:type="simple"/></inline-formula>. In ENS coding, we demand that neural activities are such that the mean of the estimator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e549" xlink:type="simple"/></inline-formula> is equal to the temporally filtered probability of that state at time <italic>t</italic>, that is<disp-formula id="pcbi.1003859.e550"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e550" xlink:type="simple"/><label>(22)</label></disp-formula></p>
</sec><sec id="s4c">
<title>Mean and variance of the estimator</title>
<p>Here we show that eq. (1) is an unbiased estimator of the probability of state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e551" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e552" xlink:type="simple"/></inline-formula> filtered by the EPSP, given that there is at least one spike in the integration window. Additionally we compute the variance of the estimator.</p>
<p>Consider a given fixed temporal evolution of the probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e553" xlink:type="simple"/></inline-formula>. We first consider the mean of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e554" xlink:type="simple"/></inline-formula> for a given number of spikes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e555" xlink:type="simple"/></inline-formula>, written as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e556" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003859.e557"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e557" xlink:type="simple"/></disp-formula></p>
<p>Given a spike at time <italic>t</italic>, the probability that it was elicited in ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e558" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e559" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e560" xlink:type="simple"/></inline-formula> denotes the total network rate. Since the total network rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e561" xlink:type="simple"/></inline-formula> is constant and each spike is drawn independently, to count the spikes in different ensembles in a time window <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e562" xlink:type="simple"/></inline-formula>, we can replace each inhomogeneous Poisson process by a homogeneous process in that time window with rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e563" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e564" xlink:type="simple"/></inline-formula> denotes the temporally filtered probability of the state, see eq. (21). Each individual spike in the time window originates from ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e565" xlink:type="simple"/></inline-formula> with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e566" xlink:type="simple"/></inline-formula>. Hence, for a given <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e567" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e568" xlink:type="simple"/></inline-formula> is drawn from a binomial distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e569" xlink:type="simple"/></inline-formula>. It follows that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e570" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e571" xlink:type="simple"/></inline-formula>. Hence, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e572" xlink:type="simple"/></inline-formula>, and the estimator is unbiased.</p>
<p>We now turn to the variance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e573" xlink:type="simple"/></inline-formula>. We define <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e574" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e575" xlink:type="simple"/></inline-formula> for notational convenience. From <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e576" xlink:type="simple"/></inline-formula>, we obtain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e577" xlink:type="simple"/></inline-formula>. By the law of total variance, we have<disp-formula id="pcbi.1003859.e578"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e578" xlink:type="simple"/></disp-formula></p>
<p>The second summand is 0 since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e579" xlink:type="simple"/></inline-formula> is independent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e580" xlink:type="simple"/></inline-formula>. We thus obtain<disp-formula id="pcbi.1003859.e581"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e581" xlink:type="simple"/></disp-formula></p>
<p>Here, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e582" xlink:type="simple"/></inline-formula> is Poissonian with intensity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e583" xlink:type="simple"/></inline-formula>. Inserting the Poisson density, we obtain<disp-formula id="pcbi.1003859.e584"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e584" xlink:type="simple"/></disp-formula></p>
<p>The approximation is excellent if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e585" xlink:type="simple"/></inline-formula> is large, i.e., a small number of spikes over all ensembles within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e586" xlink:type="simple"/></inline-formula> is very unlikely.</p>
</sec><sec id="s4d">
<title>Influence of the firing rate on the represented distribution</title>
<p>We provide here the proof for eq. (2). We assume that an antiderivative <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e587" xlink:type="simple"/></inline-formula> exists for all rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e588" xlink:type="simple"/></inline-formula> (which is satisfied for example if the rates are continuous or sums of Heaviside step functions). The probability mass of a population <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e589" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pcbi.1003859.e590"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e590" xlink:type="simple"/><label>(23)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e591" xlink:type="simple"/></inline-formula> is the spike train of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e592" xlink:type="simple"/></inline-formula> as defined above. The neurons spike in a Poissonian manner with continuous rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e593" xlink:type="simple"/></inline-formula>. Hence we obtain for the mean over realizations of spike trains<disp-formula id="pcbi.1003859.e594"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e594" xlink:type="simple"/><label>(24)</label></disp-formula>It follows<disp-formula id="pcbi.1003859.e595"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e595" xlink:type="simple"/><label>(25)</label></disp-formula></p>
</sec><sec id="s4e">
<title>Task class A: Simple probabilistic dependencies</title>
<p>We first show that the expected value of the estimator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e596" xlink:type="simple"/></inline-formula> is equal to the posterior distribution (4) for membrane potentials (5) and weights (6). We will then derive the variance of an alternative estimator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e597" xlink:type="simple"/></inline-formula> of the posterior distribution.</p>
<p>Consider two distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e598" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e599" xlink:type="simple"/></inline-formula> over random variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e600" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e601" xlink:type="simple"/></inline-formula> respectively such that the desired posterior is given by eq. (4). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e602" xlink:type="simple"/></inline-formula> is coded by neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e603" xlink:type="simple"/></inline-formula> through ENS coding. We denote the estimation sample size of the ensembles for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e604" xlink:type="simple"/></inline-formula> by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e605" xlink:type="simple"/></inline-formula> for clarity. Consider a circuit with neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e606" xlink:type="simple"/></inline-formula> and ensemble size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e607" xlink:type="simple"/></inline-formula> that should represent the posterior. The membrane potentials are given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e608" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e609" xlink:type="simple"/></inline-formula>. For given EPSP-filtered spike trains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e610" xlink:type="simple"/></inline-formula>, this leads to the firing rate for neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e611" xlink:type="simple"/></inline-formula><disp-formula id="pcbi.1003859.e612"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e612" xlink:type="simple"/><label>(26)</label></disp-formula></p>
<p>Averaging over realizations of spike trains in the posterior population, we obtain<disp-formula id="pcbi.1003859.e613"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e613" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e614" xlink:type="simple"/></inline-formula> denotes the average for given activities in ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e615" xlink:type="simple"/></inline-formula>. Taking also the average over realizations of spike trains in ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e616" xlink:type="simple"/></inline-formula>, this evaluates to</p>
<p><disp-formula id="pcbi.1003859.e617"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e617" xlink:type="simple"/></disp-formula></p>
<p>We assume for simplicity that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e618" xlink:type="simple"/></inline-formula> is constant over time, and obtain<disp-formula id="pcbi.1003859.e619"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e619" xlink:type="simple"/></disp-formula>where we defined <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e620" xlink:type="simple"/></inline-formula>. This shows that the represented probability of the circuit is the posterior probability in the mean with an estimation sample size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e621" xlink:type="simple"/></inline-formula>.</p>
<sec id="s4e1">
<title>Variance of the posterior representation</title>
<p>The estimate of the posterior distribution at some specific time <italic>t</italic> is however variable due to variability in spike counts of both the representation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e622" xlink:type="simple"/></inline-formula> and the representation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e623" xlink:type="simple"/></inline-formula>. Due to this doubly stochastic nature, the variance of the estimator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e624" xlink:type="simple"/></inline-formula> is hard to evaluate. We derive in here the variance of an alternative estimator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e625" xlink:type="simple"/></inline-formula> which is also unbiased but has higher variance. We show that the variance of this estimator for conditional probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e626" xlink:type="simple"/></inline-formula> that maximize the variance of the firing rates in the posterior circuit is at most twice the variance of the estimator <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e627" xlink:type="simple"/></inline-formula>. The firing rate of a neuron in the posterior representation has a variance of<disp-formula id="pcbi.1003859.e628"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e628" xlink:type="simple"/></disp-formula>where the maximum is achieved when one <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e629" xlink:type="simple"/></inline-formula> for some <italic>j</italic>. We derive the variance of the spike count in a window of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e630" xlink:type="simple"/></inline-formula> in the posterior circuit in this case. This variance is not straight forward to compute since it is the variance in spike count of a Poisson process with a rate that is itself a random variable. For the case of maximum variance of the firing rate, the firing rate is given by<disp-formula id="pcbi.1003859.e631"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e631" xlink:type="simple"/></disp-formula>for some <italic>j</italic>. For the spike count in a window of duration <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e632" xlink:type="simple"/></inline-formula> over the whole ensemble for state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e633" xlink:type="simple"/></inline-formula>, that is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e634" xlink:type="simple"/></inline-formula>, we consider thus a Poisson-distributed random variable with intensity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e635" xlink:type="simple"/></inline-formula> which is itself a random variable. Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e636" xlink:type="simple"/></inline-formula> is Poisson distributed, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e637" xlink:type="simple"/></inline-formula> can be expressed as a compound Poisson distribution in the following way. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e638" xlink:type="simple"/></inline-formula> is the sum of random variables <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e639" xlink:type="simple"/></inline-formula> which are i.i.d. Poisson with intensity 1 and scaled by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e640" xlink:type="simple"/></inline-formula>. The number of random variables that are summed is Poisson distributed with intensity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e641" xlink:type="simple"/></inline-formula>. Hence, the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e642" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pcbi.1003859.e643"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e643" xlink:type="simple"/></disp-formula>It is easy to see that this leads to the correct distribution over intensities for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e644" xlink:type="simple"/></inline-formula>. It is known from the theory of compound Poisson processes <xref ref-type="bibr" rid="pcbi.1003859-Bean1">[51]</xref> that the variance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e645" xlink:type="simple"/></inline-formula> is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e646" xlink:type="simple"/></inline-formula> which is in our case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e647" xlink:type="simple"/></inline-formula>. Since the estimated probability for state <italic>i</italic> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e648" xlink:type="simple"/></inline-formula>, we obtain <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e649" xlink:type="simple"/></inline-formula>. In comparison with the variance of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e650" xlink:type="simple"/></inline-formula>, which is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e651" xlink:type="simple"/></inline-formula>, the variance doubles.</p>
</sec></sec><sec id="s4f">
<title>Task class B: Evidence integration</title>
<sec id="s4f1">
<title>Evidence can be provided through EPSPs</title>
<p>We first prove that in a rate-model, integration of evidence signaled via point-events can be performed with finite-length EPSPs. We denote the spike-train <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e652" xlink:type="simple"/></inline-formula> of afferent neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e653" xlink:type="simple"/></inline-formula> as the sum of Dirac delta functions<disp-formula id="pcbi.1003859.e654"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e654" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e655" xlink:type="simple"/></inline-formula> denotes the <italic>j</italic>-th spike-time of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e656" xlink:type="simple"/></inline-formula>. Consider a set of non-normalized and non-negative functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e657" xlink:type="simple"/></inline-formula> from which the probabilities <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e658" xlink:type="simple"/></inline-formula> follow after normalization. The change of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e659" xlink:type="simple"/></inline-formula> is given by <xref ref-type="bibr" rid="pcbi.1003859-Brmaud1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Bobrowski1">[14]</xref></p>
<p><disp-formula id="pcbi.1003859.e660"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e660" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e661" xlink:type="simple"/></inline-formula> is the firing rate of afferent neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e662" xlink:type="simple"/></inline-formula> if the current state is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e663" xlink:type="simple"/></inline-formula>. Starting at some time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e664" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e665" xlink:type="simple"/></inline-formula> and integrating up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e666" xlink:type="simple"/></inline-formula>, we obtain<disp-formula id="pcbi.1003859.e667"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e667" xlink:type="simple"/><label>(27)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e668" xlink:type="simple"/></inline-formula> denotes the number of spikes of afferent neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e669" xlink:type="simple"/></inline-formula> in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e670" xlink:type="simple"/></inline-formula>.</p>
<p>Now assume finite-size EPSPs of length <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e671" xlink:type="simple"/></inline-formula> and integral <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e672" xlink:type="simple"/></inline-formula>, giving rise to the EPSP-filtered spike-trains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e673" xlink:type="simple"/></inline-formula>. Furthermore, assume that the rate-based network evolves due to eq. (8) with weights given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e674" xlink:type="simple"/></inline-formula> for some constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e675" xlink:type="simple"/></inline-formula>. Integrating up to time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e676" xlink:type="simple"/></inline-formula> and assuming no evidence spike in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e677" xlink:type="simple"/></inline-formula>, we obtain<disp-formula id="pcbi.1003859.e678"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e678" xlink:type="simple"/></disp-formula>for a constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e679" xlink:type="simple"/></inline-formula> that only scales the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e680" xlink:type="simple"/></inline-formula>'s. We thus obtained the desired result, compare to eq. (27). Note that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e681" xlink:type="simple"/></inline-formula> can be used to shift weights to positive values for low firing rates. Since the EPSPs are scaled by the weight, we can assume that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e682" xlink:type="simple"/></inline-formula>. Then the optimal weights are <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e683" xlink:type="simple"/></inline-formula>, as considered in the main text.</p>
</sec><sec id="s4f2">
<title>Particle-based implementation of the filtering equations</title>
<p>We now analyze the changes of expected probability masses for membrane voltages given by eq. (10) with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e684" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e685" xlink:type="simple"/></inline-formula>. We show that they are approximately equal to the changes in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e686" xlink:type="simple"/></inline-formula>'s in eq. (8). For a given pattern of spikes in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e687" xlink:type="simple"/></inline-formula>, the firing rates in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e688" xlink:type="simple"/></inline-formula> evaluate to<disp-formula id="pcbi.1003859.e689"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e689" xlink:type="simple"/><label>(28)</label></disp-formula></p>
<p>For positive weights, the only term that can make the argument of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e690" xlink:type="simple"/></inline-formula> operator negative is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e691" xlink:type="simple"/></inline-formula> which will be equated with normalizing inhibition. We will discuss the influence of this effect below. For now, we assume that the membrane potential does not become negative, which enables us to skip the rectification <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e692" xlink:type="simple"/></inline-formula>. We use the shortcut <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e693" xlink:type="simple"/></inline-formula> for the summed firing rate of ensemble <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e694" xlink:type="simple"/></inline-formula> to obtain<disp-formula id="pcbi.1003859.e695"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e695" xlink:type="simple"/><label>(29)</label></disp-formula></p>
<p>The change of the expected probability masses in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e696" xlink:type="simple"/></inline-formula> is given by eq. (2)<disp-formula id="pcbi.1003859.e697"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e697" xlink:type="simple"/></disp-formula></p>
<p>Since layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e698" xlink:type="simple"/></inline-formula> copies the distribution represented by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e699" xlink:type="simple"/></inline-formula>, we have <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e700" xlink:type="simple"/></inline-formula> which yields<disp-formula id="pcbi.1003859.e701"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e701" xlink:type="simple"/></disp-formula></p>
<p>The first term in this equation is equivalent to the change of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e702" xlink:type="simple"/></inline-formula>'s in eq. (8). The last term is due to EPSPs that end at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e703" xlink:type="simple"/></inline-formula> and has to be compensated. It is approximately compensated by the second to last term since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e704" xlink:type="simple"/></inline-formula> under the assumption that the expected firing rate (i.e., the represented probability distribution) changes slowly on the time scale of the EPSP. Hence, we have<disp-formula id="pcbi.1003859.e705"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e705" xlink:type="simple"/></disp-formula></p>
<p>Comparing this result to eq. (8), we can see that the dynamics of the mean probability masses in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e706" xlink:type="simple"/></inline-formula> approximate those needed for evidence integration.</p>
</sec><sec id="s4f3">
<title>Multiplication through gating of activity</title>
<p>We now show that the multiplication can be approximated by gating of activity. The membrane potentials of neurons in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e707" xlink:type="simple"/></inline-formula> given in eq. (10) gives rise to the ensemble firing rates given in eq. (29), which approximate the optimal changes in probability masses as shown above. In a first step, we show that membrane potentials (11) give rise to identical ensemble firing rates. This can easily be seen since for non-negative membrane potentials we have<disp-formula id="pcbi.1003859.e708"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e708" xlink:type="simple"/></disp-formula></p>
<p>The matching of superscripts <italic>m</italic> in eq. (11) is chosen for notational simplicity. Of course, any permutation of superscripts on the right hand side is valid as well. If the firing rate of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e709" xlink:type="simple"/></inline-formula> is low, the probability of two spikes in a time window of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e710" xlink:type="simple"/></inline-formula> is small and we can approximate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e711" xlink:type="simple"/></inline-formula> by a binary variable taking on the values 0 or 1. In this case, the multiplication is accomplished by gating of the activity of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e712" xlink:type="simple"/></inline-formula> by neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e713" xlink:type="simple"/></inline-formula>.</p>
<p>In a second step, we discuss how this gating can be accomplished through disinhibition. Our general model for disinhibition is discussed below. Here we use the special case of a single disinhibiting neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e714" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e715" xlink:type="simple"/></inline-formula> and 0 otherwise. For membrane potentials given by eq. (12), and binary <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e716" xlink:type="simple"/></inline-formula>, we have<disp-formula id="pcbi.1003859.e717"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e717" xlink:type="simple"/><label>(30)</label></disp-formula>if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e718" xlink:type="simple"/></inline-formula> is strong, such that the membrane potential becomes negative if neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e719" xlink:type="simple"/></inline-formula> was not active recently. The ensemble rates<disp-formula id="pcbi.1003859.e720"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e720" xlink:type="simple"/><label>(31)</label></disp-formula>are equivalent to the ensemble firing rates of eq. (29) and therefore approximate the optimal changes of probability masses.</p>
</sec></sec><sec id="s4g">
<title>Disinhibition</title>
<p>We formally define the influence of disinhibition arising from neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e721" xlink:type="simple"/></inline-formula> on the membrane potential of a neuron as<disp-formula id="pcbi.1003859.e722"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e722" xlink:type="simple"/><label>(32)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e723" xlink:type="simple"/></inline-formula> is some baseline inhibition and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e724" xlink:type="simple"/></inline-formula> is some threshold. In other words, the disinhibited neuron is released from baseline inhibition if the neurons were recently active enough to overcome the threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e725" xlink:type="simple"/></inline-formula>. We used in this article a threshold of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e726" xlink:type="simple"/></inline-formula>. For rectangular EPSPs, this results in disinhibition whenever <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e727" xlink:type="simple"/></inline-formula>. In our circuit model, the baseline inhibition is strong enough to suppress any activity when inhibited.</p>
</sec><sec id="s4h">
<title>Lateral inhibition</title>
<p>Lateral inhibition in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e728" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pcbi.1003859.e729"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e729" xlink:type="simple"/><label>(33)</label></disp-formula></p>
<p>It corrects for excessive spiking activity, i.e., when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e730" xlink:type="simple"/></inline-formula>. The constant <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e731" xlink:type="simple"/></inline-formula> determines how strongly this correction influences the membrane potential. We included the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e732" xlink:type="simple"/></inline-formula> operator to model a purely inhibitory population. This means that too low firing rates are not compensated by this mechanism. This is possible, since all other contributions to the membrane potential are non-negative if weights are shifted to non-negative values. In particular, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e733" xlink:type="simple"/></inline-formula> term in the biases <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e734" xlink:type="simple"/></inline-formula> (see <xref ref-type="table" rid="pcbi-1003859-t001">Table 1</xref>) leads to a quick recovery of the ensemble firing rate.</p>
<p>Strong lateral inhibition at low potentials could be cut off by the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e735" xlink:type="simple"/></inline-formula>-operator in <xref ref-type="disp-formula" rid="pcbi.1003859.e689">equation (28</xref>). That would result in unequal inhibition values for different ensembles. This can be avoided by bounding inhibition to a maximum of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e736" xlink:type="simple"/></inline-formula> (note that inhibition is bounded due to the finite size of the network). But our simulations indicate that even with larger values, the circuit performs very well.</p>
</sec><sec id="s4i">
<title>General details on computer simulations</title>
<p>All simulations were performed in discretized time with a time step of 0.5 ms. The duration of EPSPs was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e737" xlink:type="simple"/></inline-formula>ms in all simulations. The delay for lateral inhibition <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e738" xlink:type="simple"/></inline-formula> was set to 0.5 ms. The initialization of network activity for the particle filter circuits was performed as follows. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e739" xlink:type="simple"/></inline-formula> denote the distribution that the network should represent at the beginning of a simulation. Spikes were drawn in both layers and distributed in the time interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e740" xlink:type="simple"/></inline-formula> such that at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e741" xlink:type="simple"/></inline-formula>, the represented probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e742" xlink:type="simple"/></inline-formula> represented <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e743" xlink:type="simple"/></inline-formula> in the mean. More precisely, a spike of neuron <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e744" xlink:type="simple"/></inline-formula> in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e745" xlink:type="simple"/></inline-formula> was assumed with probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e746" xlink:type="simple"/></inline-formula>. If there was a spike for this neuron, its exact timing was drawn from a uniform distribution in the interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e747" xlink:type="simple"/></inline-formula>. Simulation of the network began at <italic>t</italic> = 0 ms where the EPSPs of theses spikes were taken into account when computing the membrane potentials of neurons during the initial phase of the simulation. The initially represented distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e748" xlink:type="simple"/></inline-formula> was assumed uniform over all states if not otherwise noted.</p>
<p>All simulation code is available online as <italic><xref ref-type="supplementary-material" rid="pcbi.1003859.s001">Dataset S1</xref></italic>. Details of individual simulations are discussed in the following.</p>
</sec><sec id="s4j">
<title>Computer Simulations for task class B: Evidence integration</title>
<sec id="s4j1">
<title><xref ref-type="fig" rid="pcbi-1003859-g005">Figure 5</xref></title>
<p>For panel F, the prior probability for state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e749" xlink:type="simple"/></inline-formula> was chosen in each run randomly from a uniform distribution over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e750" xlink:type="simple"/></inline-formula>. The two afferent neurons <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e751" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e752" xlink:type="simple"/></inline-formula> spiked at time 20 ms and 25 ms respectively. Each <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e753" xlink:type="simple"/></inline-formula> was drawn from a uniform distribution over <xref ref-type="bibr" rid="pcbi.1003859-Shadlen1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1003859-Letzkus1">[20]</xref>Hz. For panel F, 100 simulation runs were performed and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e754" xlink:type="simple"/></inline-formula> as well as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e755" xlink:type="simple"/></inline-formula> is shown, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e756" xlink:type="simple"/></inline-formula>ms (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e757" xlink:type="simple"/></inline-formula>). The true posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e758" xlink:type="simple"/></inline-formula> was computed according to eq. (27). Panels C–E show an example run with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e759" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e760" xlink:type="simple"/></inline-formula>Hz, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e761" xlink:type="simple"/></inline-formula>Hz, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e762" xlink:type="simple"/></inline-formula>Hz, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e763" xlink:type="simple"/></inline-formula>Hz.</p>
<p>Circuit parameters: Number of neurons per state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e764" xlink:type="simple"/></inline-formula>; target estimation sample size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e765" xlink:type="simple"/></inline-formula>; lateral inhibition scaling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e766" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s4k">
<title>Action readouts from state variables</title>
<p>We provide here details on the readout layer used to model the ambiguous target task and the random-dot motion task. An application of the feedforward circuit discussed in <italic>Simple probabilistic dependencies</italic> is inference over rewarded actions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e767" xlink:type="simple"/></inline-formula> based on the current belief about the state of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e768" xlink:type="simple"/></inline-formula>. In the context of reward-based action selection, one wants to estimate the probability that a given action leads to reward (we consider here binary rewards <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e769" xlink:type="simple"/></inline-formula> for simplicity). If the probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e770" xlink:type="simple"/></inline-formula> of reward for action <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e771" xlink:type="simple"/></inline-formula> in state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e772" xlink:type="simple"/></inline-formula> is known, then the posterior distribution over actions for the current state distribution can be inferred as<disp-formula id="pcbi.1003859.e773"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e773" xlink:type="simple"/><label>(34)</label></disp-formula>see below. In the ambiguous target task, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e774" xlink:type="simple"/></inline-formula> is 1 if the action (movement direction) matches the direction of the spatial cue in the color of the color cue, and 0 otherwise. Eq. (34) defines a direct probabilistic relation between the action and the state. Hence, a layer of neurons as described in <italic>Task class A</italic> computes the posterior distribution. We refer to such a layer as an <italic>action readout layer</italic>.</p>
<p>We discuss this now more formally. Consider a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e775" xlink:type="simple"/></inline-formula> with range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e776" xlink:type="simple"/></inline-formula>, a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e777" xlink:type="simple"/></inline-formula> over possible actions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e778" xlink:type="simple"/></inline-formula>, and a binary random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e779" xlink:type="simple"/></inline-formula> that indicates whether a reward occurs. Assuming that the joint probability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e780" xlink:type="simple"/></inline-formula> factorizes to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e781" xlink:type="simple"/></inline-formula>, one can infer future actions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e782" xlink:type="simple"/></inline-formula> that will lead to a reward for the given distribution over states by:<disp-formula id="pcbi.1003859.e783"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e783" xlink:type="simple"/><label>(35)</label></disp-formula></p>
<p>We want to infer future actions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e784" xlink:type="simple"/></inline-formula> that will lead to a reward for the current state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e785" xlink:type="simple"/></inline-formula>. Assuming a uniform prior over actions, this simplifies to<disp-formula id="pcbi.1003859.e786"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e786" xlink:type="simple"/><label>(36)</label></disp-formula></p>
<p>Assume that the distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e787" xlink:type="simple"/></inline-formula> is given by ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e788" xlink:type="simple"/></inline-formula> in a sample-based representation with estimation sample size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e789" xlink:type="simple"/></inline-formula>. This defines an operation as discussed above under <italic>Task class A: Simple probabilistic dependencies</italic>. Hence, a circuit consisting of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e790" xlink:type="simple"/></inline-formula> ensembles and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e791" xlink:type="simple"/></inline-formula> neurons per ensemble samples from the posterior distribution (36) with estimation sample size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e792" xlink:type="simple"/></inline-formula> if the membrane voltages of the neurons are given by<disp-formula id="pcbi.1003859.e793"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e793" xlink:type="simple"/></disp-formula>with weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e794" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4l">
<title>The ambiguous target task</title>
<p>Stimuli were coded by 19 ensembles of afferent neurons, where each ensemble consisted of 20 neurons. One ensemble coded for the fixation cross, and two for the two colors of the color cue. Eight ensembles coded for each position of a red spatial cue and eight for each position of a blue color cue. First, the fixation cross-stimulus was presented for 100 ms. The spatial cue followed for 250 ms. Here, two ensembles of afferent neurons were active, one for each color of the spatial cue. In the 250 ms memory epoch, only the fixation cross was present. After the memory epoch, the color cue appeared, and the corresponding ensemble of afferent neurons (for red or blue color cue) was active. Afferent neurons spiked at a baseline rate of 0.1 Hz and at a rate of 5 Hz when they were active.</p>
<p>For synaptic weights from afferent neurons, we used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e795" xlink:type="simple"/></inline-formula> for observations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e796" xlink:type="simple"/></inline-formula> that are possible in state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e797" xlink:type="simple"/></inline-formula>. For example, in a state coding for “movement to 90 degrees with red color cue”, a red spatial cue at 90 degrees, a blue spatial cue at 270 degrees, and a fixation cross are possible. All other <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e798" xlink:type="simple"/></inline-formula> were set to the baseline firing rate of 0.1 Hz. The lateral inhibition scaling was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e799" xlink:type="simple"/></inline-formula>.</p>
<p>The action readout layer consisted of 100 neurons for each of the 8 possible actions (movement to one of eight directions). Considering eq. (4), we identified the random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e800" xlink:type="simple"/></inline-formula> with the random variable estimated in the particle filter circuit. The hidden states of this variable are the direction-color pairs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e801" xlink:type="simple"/></inline-formula> for 8 possible directions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e802" xlink:type="simple"/></inline-formula> and 2 colors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e803" xlink:type="simple"/></inline-formula>. The random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e804" xlink:type="simple"/></inline-formula> has 8 states encoding that movement in direction <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e805" xlink:type="simple"/></inline-formula> leads to a reward. This random variable can be computed through marginalization over color <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e806" xlink:type="simple"/></inline-formula>. Hence, the conditional probabilities were given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e807" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e808" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e809" xlink:type="simple"/></inline-formula> otherwise. With these conditionals, we obtained the synaptic weights through eq. (6) with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e810" xlink:type="simple"/></inline-formula>, leading to an estimation sample size of 80 in the action readout layer.</p>
<p>For <xref ref-type="fig" rid="pcbi-1003859-g001">Figure 1</xref>, spiking activity was averaged over 50 successful trials (87 successful trials out of 100), temporally (10 ms running average) and spatially (mean activity of 10 neighboring neurons for neurons ordered by their preferred direction).</p>
</sec><sec id="s4m">
<title>Continuous time Markov chains</title>
<p>A continuous time Markov chain is characterized by <italic>transition rates</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e811" xlink:type="simple"/></inline-formula> for each pair of distinct states, i.e., for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e812" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e813" xlink:type="simple"/></inline-formula>. Assume that at some time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e814" xlink:type="simple"/></inline-formula> the state is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e815" xlink:type="simple"/></inline-formula>. To sample a sequence of states from the Markov chain starting at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e816" xlink:type="simple"/></inline-formula>, a Poisson process <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e817" xlink:type="simple"/></inline-formula> with rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e818" xlink:type="simple"/></inline-formula> is started for each state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e819" xlink:type="simple"/></inline-formula>. The time of the next state transition is given by the first event in these processes and the next state is given by the index of the process that produced the event. After a transition, the chain starts afresh at the transition time.</p>
</sec><sec id="s4n">
<title>Task class C: Bayesian filtering</title>
<p>We show that the membrane potentials given in <xref ref-type="table" rid="pcbi-1003859-t001">Table 1</xref> approximate the set of differential <xref ref-type="disp-formula" rid="pcbi.1003859.e363">equations (13</xref>). These equations can be formulated as two sets of coupled equations, one for evidence integration and one for prediction of dynamics:<disp-formula id="pcbi.1003859.e820"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e820" xlink:type="simple"/><label>(37)</label></disp-formula><disp-formula id="pcbi.1003859.e821"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e821" xlink:type="simple"/><label>(38)</label></disp-formula>where we assume identical initial conditions for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e822" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e823" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e824" xlink:type="simple"/></inline-formula> is represented by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e825" xlink:type="simple"/></inline-formula> and the change of the expected probability masses corresponds to the changes in eq. (37) as shown above.</p>
<p>We show here that the membrane potentials given in eq. (14) lead to changes in the expected probability masses of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e826" xlink:type="simple"/></inline-formula> that approximate those of eq. (38). Assume that the membrane potentials evolve according to eq. (14) with weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e827" xlink:type="simple"/></inline-formula> where we defined <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e828" xlink:type="simple"/></inline-formula>. For given spikes in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e829" xlink:type="simple"/></inline-formula>, the summed firing rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e830" xlink:type="simple"/></inline-formula> in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e831" xlink:type="simple"/></inline-formula> evaluate to<disp-formula id="pcbi.1003859.e832"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e832" xlink:type="simple"/></disp-formula></p>
<p>The change of the expected probability masses in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e833" xlink:type="simple"/></inline-formula> is<disp-formula id="pcbi.1003859.e834"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e834" xlink:type="simple"/></disp-formula></p>
<p>The last term is due to EPSPs that end at time <italic>t</italic> which needs to be compensated. It is approximately compensated by the second to last term since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e835" xlink:type="simple"/></inline-formula> under the assumption that the expected firing rate (i.e., the represented probability distribution) changes slowly on the time scale of the EPSP. Altogether we obtain<disp-formula id="pcbi.1003859.e836"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e836" xlink:type="simple"/></disp-formula>as needed.</p>
</sec><sec id="s4o">
<title>Computer Simulations for task class C: Bayesian filtering</title>
<sec id="s4o1">
<title><xref ref-type="fig" rid="pcbi-1003859-g007">Figure 7</xref></title>
<p>Parameters for the example run, panels C,D: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e837" xlink:type="simple"/></inline-formula>Hz; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e838" xlink:type="simple"/></inline-formula>. The true posterior was computed analytically as<disp-formula id="pcbi.1003859.e839"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e839" xlink:type="simple"/></disp-formula></p>
<p>Circuit parameters were chosen identical to those for <xref ref-type="fig" rid="pcbi-1003859-g005">Figure 5:</xref> Number of neurons per state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e840" xlink:type="simple"/></inline-formula>; target estimation sample size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e841" xlink:type="simple"/></inline-formula>; lateral inhibition scaling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e842" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4o2">
<title>Particle filtering in a generic setup for task class C</title>
<p>State sequences were generated according to the HMM described in the main text. Once a new state was drawn, it was maintained for at least 60 ms. Point-event observations were produced with rates<disp-formula id="pcbi.1003859.e843"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e843" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e844" xlink:type="simple"/></inline-formula> were set according to Gaussian tuning functions with means <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e845" xlink:type="simple"/></inline-formula> and standard deviation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e846" xlink:type="simple"/></inline-formula> for all <italic>j</italic></p>
<p><disp-formula id="pcbi.1003859.e847"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e847" xlink:type="simple"/><label>(39)</label></disp-formula>The means were set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e848" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e849" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e850" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e851" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e852" xlink:type="simple"/></inline-formula>. Weights from evidence neurons to the evidence layer were set according to these observation rates.</p>
<p>Circuit parameters: Number of neurons per state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e853" xlink:type="simple"/></inline-formula>; target estimation sample size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e854" xlink:type="simple"/></inline-formula>; lateral inhibition scaling <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e855" xlink:type="simple"/></inline-formula>. The circuit was initialized at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e856" xlink:type="simple"/></inline-formula> with the prior distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e857" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e858" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e859" xlink:type="simple"/></inline-formula>.</p>
<p>Panel Af: All simulations were performed in discrete time with a discretization time step of 0.5 ms. The optimal Bayesian filtering was performed by implementing the filtering <xref ref-type="disp-formula" rid="pcbi.1003859.e820">equations (37</xref>) – (38). The optimal estimate based on the most recent observation was computed in the following way: If there was no observation at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e860" xlink:type="simple"/></inline-formula>, the estimate was identical to the estimate at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e861" xlink:type="simple"/></inline-formula>. If there was an observation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e862" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e863" xlink:type="simple"/></inline-formula>, then the distribution over states was given by the posterior <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e864" xlink:type="simple"/></inline-formula>. The errors were computed as follows: At each discrete time step, the maximum over the posterior distribution was taken as the predicted state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e865" xlink:type="simple"/></inline-formula>. The error was then computed as the fraction of incorrect predicted states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e866" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e867" xlink:type="simple"/></inline-formula> is the number of time steps of the simulation run and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e868" xlink:type="simple"/></inline-formula> is the discretization time step.</p>
</sec></sec><sec id="s4p">
<title>Computer Simulations for task class D: Context-dependent Bayesian filtering</title>
<sec id="s4p1">
<title>Particle filtering in a generic setup for task class D</title>
<p>State sequences were generated according to the HMM described in the main text, where state transition rates were chosen according to the current context. The HMM started in context A and context was switched whenever state 1 was entered. Point-event observations were produced as in <italic>Particle filtering in a generic setup for task class C</italic>, but with different tuning functions. The tuning functions for states 1 to 3 were Gaussians with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e869" xlink:type="simple"/></inline-formula> defined as in eq. (39) with means <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e870" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e871" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e872" xlink:type="simple"/></inline-formula> and standard deviations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e873" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e874" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e875" xlink:type="simple"/></inline-formula>. Note that the tuning curves for states 1 and 3 differed only in their standard deviations, but not in their means. The tuning for state 4 was given by a sum of two Gaussians with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e876" xlink:type="simple"/></inline-formula> with an additive offset<disp-formula id="pcbi.1003859.e877"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e877" xlink:type="simple"/></disp-formula></p>
<p>The tuning for state 5 was uniform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e878" xlink:type="simple"/></inline-formula>. Weights from evidence neurons to the evidence layer were set according to these observation rates.</p>
<p>Circuit parameters were identical to those in <italic>Bayesian filtering in a generic setup</italic>. 10 context neurons were used per context. They produced Poisson spike trains with rate 50 Hz when active and no spikes otherwise.</p>
<p>Panel Bf: Simulations were performed and errors were computed as described in <italic>Particle filtering in a generic setup for task class C</italic>. For the optimal context-dependent Bayesian filtering (“opt”), the optimal transition rates were used for the current context. For the optimal filtering without context (“mix”), the weights to layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e879" xlink:type="simple"/></inline-formula> were set according to the mixed transition rates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e880" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e881" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e882" xlink:type="simple"/></inline-formula> are the transition rates for context A and B respectively.</p>
</sec><sec id="s4p2">
<title>Self-localization</title>
<p>For the full maze, we used coordinates between 0 and 1 in each dimension. Locations of variables were uniformly spaced on a 10×10 grid in the maze (see <xref ref-type="fig" rid="pcbi-1003859-g010">Figure 10A</xref>). We simulated an agent that navigated in the continuous space. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e883" xlink:type="simple"/></inline-formula> denote the location of the agent at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e884" xlink:type="simple"/></inline-formula>. All afferent neurons had a baseline firing rate of 0.1 Hz. The firing rate of each afferent neuron was given by a Gaussian with a corresponding center, an STD of 0.1, and a maximum rate of 50 Hz. The lower four afferent neurons in <xref ref-type="fig" rid="pcbi-1003859-g010">Figure 10A</xref>, had identical positional tuning in both chambers. Their firing rate at each time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e885" xlink:type="simple"/></inline-formula> was determined by the Gaussian in the chamber where the agent was currently situated. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e886" xlink:type="simple"/></inline-formula>, all afferent neurons spiked at baseline.</p>
<p>Circuit parameters: The network size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e887" xlink:type="simple"/></inline-formula> and estimation sample size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e888" xlink:type="simple"/></inline-formula> was 250; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e889" xlink:type="simple"/></inline-formula>. 10 context neurons were used per context ensemble, each producing a 50 Hz Poisson spike train in its context and no spikes if the context did not match. The weights from evidence neurons to neurons in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e890" xlink:type="simple"/></inline-formula> were set according to the rates of the afferent neurons when the agent would be exactly at the place of the corresponding state. The weights to neurons in layer <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e891" xlink:type="simple"/></inline-formula> were set according to transition rates as follows. There were four groups of populations in this layer, one for each context. Transition rates were 3.5 Hz for possible movements in the direction that corresponded to the context of the population (dark gray arrows in <xref ref-type="fig" rid="pcbi-1003859-g010">Figure 10A</xref>). Transition rates between other states with adjacent positions (horizontally, vertically, or diagonal; states separated by the chamber wall were considered non-adjacent) were 0.1 Hz (light gray lines in <xref ref-type="fig" rid="pcbi-1003859-g010">Figure 10A</xref>). Transition rates between remaining states were 0 Hz.</p>
</sec></sec><sec id="s4q">
<title>Task class E: Graded integration of uncertain context information</title>
<p>In task class E, it is advantageous to deal with context in a graded manner. This is achieved by a simple modification the context-dependent filtering circuit from task class D. In the modified circuit, the membrane potential of neurons in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e892" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pcbi.1003859.e893"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e893" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e894" xlink:type="simple"/></inline-formula> denotes the EPSP-filtered spike train of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e895" xlink:type="simple"/></inline-formula> neuron in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e896" xlink:type="simple"/></inline-formula> ensemble that represents the distribution over contexts. In comparison to the equation given in <xref ref-type="table" rid="pcbi-1003859-t002">Table 2</xref>, each neuron in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e897" xlink:type="simple"/></inline-formula> is disinhibited by a single context neuron. This leads to an approximate linear mixture of the context-dependent transition rates</p>
<p><disp-formula id="pcbi.1003859.e898"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003859.e898" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e899" xlink:type="simple"/></inline-formula> is the effective transition rate for the context-dependent filtering circuit at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e900" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e901" xlink:type="simple"/></inline-formula> is the estimated posterior for the context variable at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e902" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4r">
<title>Computer simulations for task class E: The ambiguous target task revisited</title>
<p>State sequences and spike trains of evidence neurons were generated as in the simulation for the ambiguous target task, with the exception that the fixation phase lasted for 250 ms. Circuit parameters for the context-dependent filtering of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e903" xlink:type="simple"/></inline-formula> and the action readout layer were identical to those in the simulation for the ambiguous target task (1000 neurons per sate; estimation sample size 400; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e904" xlink:type="simple"/></inline-formula>). In the fixation-context, transition rates between all pairs of states were 1 Hz.</p>
<p>A particle filter circuit (without context) was employed to estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e905" xlink:type="simple"/></inline-formula>, the current phase of the trial. The basic parameters for this circuit were identical to the parameters of the context-dependent filtering circuit (1000 neurons per sate; estimation sample size 400; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e906" xlink:type="simple"/></inline-formula>). Other parameters for this circuit were as follows. Synaptic weights to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003859.e907" xlink:type="simple"/></inline-formula> were set according to transition rates that were assumed to be 5 Hz between states where a transition is possible and 0 Hz between other states. Synaptic weights from evidence neurons to the evidence layer were set according to the following observation rates (see also <xref ref-type="fig" rid="pcbi-1003859-g011">Figure 11</xref>). A fixation cross in the CHT state or in the MEM state: 5 Hz; Any spatial cue in the SC state: 5/16 Hz; Any color cue in the CC state: 2.5 Hz; For other observation rates, a baseline of 0.1 Hz was assumed.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003859.s001" mimetype="application/zip" xlink:href="info:doi/10.1371/journal.pcbi.1003859.s001" position="float" xlink:type="simple"><label>Dataset S1</label><caption>
<p><bold>Matlab source files for all simulations.</bold></p>
<p>(ZIP)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003859.s002" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003859.s002" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p><bold>Interpretation of EPSPs as the validity of a spike as a sample.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003859.s003" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003859.s003" position="float" xlink:type="simple"><label>Text S2</label><caption>
<p><bold>Cue combination in ENS coding.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003859.s004" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003859.s004" position="float" xlink:type="simple"><label>Text S3</label><caption>
<p><bold>Value-related neuronal activity through particle filtering in ENS coding.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003859.s005" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003859.s005" position="float" xlink:type="simple"><label>Text S4</label><caption>
<p><bold>Features of neuronal activity during random-dot motion tasks.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003859.s006" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003859.s006" position="float" xlink:type="simple"><label>Text S5</label><caption>
<p><bold>Probabilistic reasoning in area LIP.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back><ref-list>
<title>References</title>
<ref id="pcbi.1003859-Gold1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gold</surname><given-names>JI</given-names></name>, <name name-style="western"><surname>Shadlen</surname><given-names>MN</given-names></name> (<year>2007</year>) <article-title>The neural basis of decision making</article-title>. <source>Annu Rev Neurosci</source> <volume>30</volume>: <fpage>535</fpage>–<lpage>574</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Yang1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yang</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Shadlen</surname><given-names>MN</given-names></name> (<year>2007</year>) <article-title>Probabilistic reasoning by neurons</article-title>. <source>Nature</source> <volume>447</volume>: <fpage>1075</fpage>–<lpage>1080</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Cisek1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cisek</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Kalaska</surname><given-names>JF</given-names></name> (<year>2005</year>) <article-title>Neural correlates of reaching decisions in dorsal premotor cortex: specification of multiple direction choices and final selection of action</article-title>. <source>Neuron</source> <volume>45</volume>: <fpage>801</fpage>–<lpage>814</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Buesing1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buesing</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Bill</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Nessler</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2011</year>) <article-title>Neural dynamics as sampling: a model for stochastic computation in recurrent networks of spiking neurons</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002211</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Shadlen1"><label>5</label>
<mixed-citation publication-type="other" xlink:type="simple">Shadlen MN, Kiani R, Hanks TD, Churchland AK (2008) Neurobiology of decision making: An intentional framework. In: Better than conscious? Decision-making, the human mind, and implications for institutions, MIT-Press, chapter 4. pp.71–101.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Murphy1"><label>6</label>
<mixed-citation publication-type="other" xlink:type="simple">Murphy KP (2012) Machine learning: a probabilistic perspective. MIT press.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Doucet1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doucet</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Godsill</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Andrieu</surname><given-names>C</given-names></name> (<year>2000</year>) <article-title>On sequential Monte Carlo sampling methods for Bayesian filtering</article-title>. <source>Statistics and computing</source> <volume>10</volume>: <fpage>197</fpage>–<lpage>208</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Grimmett1"><label>8</label>
<mixed-citation publication-type="other" xlink:type="simple">Grimmett G, Stirzaker D (2001) Probability and random processes. Oxford Univ Press, 3rd edition.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Pecevski1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pecevski</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Buesing</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2011</year>) <article-title>Probabilistic inference in general graphical models through sampling in stochastic networks of spiking neurons</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002294</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Williams1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Williams</surname><given-names>SR</given-names></name>, <name name-style="western"><surname>Stuart</surname><given-names>GJ</given-names></name> (<year>2002</year>) <article-title>Dependence of EPSP efficacy on synapse location in neocortical pyramidal neurons</article-title>. <source>Science</source> <volume>295</volume>: <fpage>1907</fpage>–<lpage>1910</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Jolivet1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jolivet</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Rauch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lüscher</surname><given-names>HR</given-names></name>, <name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name> (<year>2006</year>) <article-title>Predicting spike timing of neocortical pyramidal neurons by simple threshold models</article-title>. <source>J Comput Neurosci</source> <volume>21</volume>: <fpage>35</fpage>–<lpage>49</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Mensi1"><label>12</label>
<mixed-citation publication-type="other" xlink:type="simple">Mensi S, Naud R, Gerstner W (2011) From stochastic nonlinear integrate-and-fire to generalized linear models. In: Adv Neural Inf Process Syst. volume 24, pp.1377–1385.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Brmaud1"><label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Brémaud P (1981) Point processes and queues, volume 30. Springer.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Bobrowski1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bobrowski</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Meir</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Eldar</surname><given-names>YC</given-names></name> (<year>2009</year>) <article-title>Bayesian filtering in spiking neural networks: Noise, adaptation, and multisensory integration</article-title>. <source>Neural Comput</source> <volume>21</volume>: <fpage>1277</fpage>–<lpage>1320</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Rao1"><label>15</label>
<mixed-citation publication-type="other" xlink:type="simple">Rao RP (2005) Hierarchical Bayesian inference in networks of spiking neurons. In: Adv Neural Inf Process Syst. MIT Press, volume 17, pp.1113–1120.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Gaines1"><label>16</label>
<mixed-citation publication-type="other" xlink:type="simple">Gaines B (1969) Stochastic computing systems. In: Advances in information systems science, Springer. pp.37–172.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Srinivasan1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>, <name name-style="western"><surname>Bernard</surname><given-names>GD</given-names></name> (<year>1976</year>) <article-title>A proposed mechanism for multiplication of neural signals</article-title>. <source>Biol Cybern</source> <volume>21</volume>: <fpage>227</fpage>–<lpage>236</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Katz1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Katz</surname><given-names>PS</given-names></name> (<year>2003</year>) <article-title>Synaptic gating: the potential to open closed doors</article-title>. <source>Current Biol</source> <volume>13</volume>: <fpage>R554</fpage>–<lpage>R556</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Gisiger1"><label>19</label>
<mixed-citation publication-type="other" xlink:type="simple">Gisiger T, Boukadoum M (2011) Mechanisms gating the flow of information in the cortex: What they might look like and what their uses may be. Front Comput Neurosci 5.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Letzkus1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Letzkus</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Wolff</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Meyer</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Tovote</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Courtin</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>A disinhibitory microcircuit for associative fear learning in the auditory cortex</article-title>. <source>Nature</source> <volume>480</volume>: <fpage>331</fpage>–<lpage>335</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Douglas1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Douglas</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>KA</given-names></name> (<year>2004</year>) <article-title>Neuronal circuits of the neocortex</article-title>. <source>Annu Rev Neurosci</source> <volume>27</volume>: <fpage>419</fpage>–<lpage>451</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Ecker1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ecker</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Berens</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Keliris</surname><given-names>GA</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Decorrelated neuronal firing in cortical microcircuits</article-title>. <source>Science</source> <volume>327</volume>: <fpage>584</fpage>–<lpage>587</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Fino1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fino</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Yuste</surname><given-names>R</given-names></name> (<year>2011</year>) <article-title>Dense inhibitory connectivity in neocortex</article-title>. <source>Neuron</source> <volume>69</volume>: <fpage>1188</fpage>–<lpage>1203</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Ma1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>Beck</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Bayesian inference with probabilistic population codes</article-title>. <source>Nat Neurosci</source> <volume>9</volume>: <fpage>1432</fpage>–<lpage>1438</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-PastorBernier1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pastor-Bernier</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Cisek</surname><given-names>P</given-names></name> (<year>2011</year>) <article-title>Neural correlates of biased competition in premotor cortex</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>7083</fpage>–<lpage>7088</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Shadlen2"><label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Shadlen MN, Gold JI (2005) The neurophysiology of decision-making as a window on cognition. In: The cognitive neurosciences, MIT Press. 3rd edition, pp.1229–1241.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Churchland1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Churchland</surname><given-names>AK</given-names></name>, <name name-style="western"><surname>Kiani</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Chaudhuri</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>XJ</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Variance as a signature of neural computations during decision making</article-title>. <source>Neuron</source> <volume>69</volume>: <fpage>818</fpage>–<lpage>831</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Jiang1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jiang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Stornetta</surname><given-names>RL</given-names></name>, <name name-style="western"><surname>Zhu</surname><given-names>JJ</given-names></name> (<year>2013</year>) <article-title>The organization of two new cortical interneuronal circuits</article-title>. <source>Nat Neurosci</source> <volume>16</volume>: <fpage>210</fpage>–<lpage>218</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Pi1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pi</surname><given-names>HJ</given-names></name>, <name name-style="western"><surname>Hangya</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kvitsiani</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sanders</surname><given-names>JI</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>ZJ</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Cortical interneurons that specialize in disinhibitory control</article-title>. <source>Nature</source> <volume>503</volume>: <fpage>521</fpage>–<lpage>524</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Lee1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>TS</given-names></name>, <name name-style="western"><surname>Mumford</surname><given-names>D</given-names></name> (<year>2003</year>) <article-title>Hierarchical bayesian inference in the visual cortex</article-title>. <source>J Opt Soc Am A Opt Image Sci Vis</source> <volume>20</volume>: <fpage>1434</fpage>–<lpage>1448</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Haider1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haider</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Häusser</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Inhibition dominates sensory responses in the awake cortex</article-title>. <source>Nature</source> <volume>493</volume>: <fpage>97</fpage>–<lpage>100</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Okun1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Okun</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Lampl</surname><given-names>I</given-names></name> (<year>2008</year>) <article-title>Instantaneous correlation of excitation and inhibition during ongoing and sensory-evoked activities</article-title>. <source>Nat Neurosci</source> <volume>11</volume>: <fpage>535</fpage>–<lpage>537</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Rigotti1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rigotti</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Barak</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Warden</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>XJ</given-names></name>, <name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>The importance of mixed selectivity in complex cognitive tasks</article-title>. <source>Nature</source> <volume>497</volume>: <fpage>585</fpage>–<lpage>590</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Habenschuss1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Habenschuss</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Puhr</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2013</year>) <article-title>Emergence of optimal decoding of population codes through STDP</article-title>. <source>Neural Comput</source> <volume>25</volume>: <fpage>1371</fpage>–<lpage>1407</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Nessler1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nessler</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Pfeiffer</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Buesing</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2013</year>) <article-title>Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity</article-title>. <source>PLoS Comp Biol</source> <volume>9</volume>: <fpage>e1003037</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Kappel1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kappel</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Nessler</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2014</year>) <article-title>STDP installs in winner-take-all circuits an online approximation to hidden markov model learning</article-title>. <source>PLoS Comp Biol</source> <volume>10</volume>: <fpage>e1003511</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Rezende1"><label>37</label>
<mixed-citation publication-type="other" xlink:type="simple">Rezende DJ, Gerstner W (2014) Stochastic variational learning in recurrent spiking networks. Front Comput Neurosci 8.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Jin1"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jin</surname><given-names>DZ</given-names></name>, <name name-style="western"><surname>Fujii</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Graybiel</surname><given-names>AM</given-names></name> (<year>2009</year>) <article-title>Neural representation of time in cortico-basal ganglia circuits</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>106</volume>: <fpage>19156</fpage>–<lpage>19161</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Asaad1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Asaad</surname><given-names>WF</given-names></name>, <name name-style="western"><surname>Rainer</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>EK</given-names></name> (<year>2000</year>) <article-title>Task-specific neural activity in the primate prefrontal cortex</article-title>. <source>J Neurophysiol</source> <volume>84</volume>: <fpage>451</fpage>–<lpage>459</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Maunsell1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maunsell</surname><given-names>JH</given-names></name>, <name name-style="western"><surname>Treue</surname><given-names>S</given-names></name> (<year>2006</year>) <article-title>Feature-based attention in visual cortex</article-title>. <source>Trends Neurosci</source> <volume>29</volume>: <fpage>317</fpage>–<lpage>322</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Saalmann1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saalmann</surname><given-names>YB</given-names></name>, <name name-style="western"><surname>Pigarev</surname><given-names>IN</given-names></name>, <name name-style="western"><surname>Vidyasagar</surname><given-names>TR</given-names></name> (<year>2007</year>) <article-title>Neural mechanisms of visual attention: how top-down feedback highlights relevant locations</article-title>. <source>Science</source> <volume>316</volume>: <fpage>1612</fpage>–<lpage>1615</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Cohen1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name> (<year>2008</year>) <article-title>Context-dependent changes in functional circuitry in visual area MT</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>162</fpage>–<lpage>173</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Skaggs1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Skaggs</surname><given-names>WE</given-names></name>, <name name-style="western"><surname>McNaughton</surname><given-names>BL</given-names></name> (<year>1998</year>) <article-title>Spatial firing properties of hippocampal CA1 populations in an environment containing two visually identical regions</article-title>. <source>J Neurosci</source> <volume>18</volume>: <fpage>8455</fpage>–<lpage>8466</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Chen1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chen</surname><given-names>G</given-names></name>, <name name-style="western"><surname>King</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name>, <name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name> (<year>2013</year>) <article-title>How vision and movement combine in the hippocampal place code</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>110</volume>: <fpage>378</fpage>–<lpage>383</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Beck1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beck</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>Kiani</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Hanks</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Churchland</surname><given-names>AK</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Probabilistic population codes for Bayesian decision making</article-title>. <source>Neuron</source> <volume>60</volume>: <fpage>1142</fpage>–<lpage>1152</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Lochmann1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lochmann</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Denève</surname><given-names>S</given-names></name> (<year>2011</year>) <article-title>Neural processing as causal inference</article-title>. <source>Current opinion in neurobiology</source> <volume>21</volume>: <fpage>774</fpage>–<lpage>781</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Denve1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Denéve</surname><given-names>S</given-names></name> (<year>2008</year>) <article-title>Bayesian spiking neurons I: Inference</article-title>. <source>Neural Comput</source> <volume>20</volume>: <fpage>91</fpage>–<lpage>117</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Boerlin1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boerlin</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Denève</surname><given-names>S</given-names></name> (<year>2011</year>) <article-title>Spike-based population coding and working memory</article-title>. <source>PLoS Comp Biol</source> <volume>7</volume>: <fpage>e1001080</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Rao2"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rao</surname><given-names>RP</given-names></name> (<year>2004</year>) <article-title>Bayesian computation in recurrent neural circuits</article-title>. <source>Neural Comput</source> <volume>16</volume>: <fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Beck2"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beck</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>Exact inferences in a neural implementation of a hidden markov model</article-title>. <source>Neural Comput</source> <volume>19</volume>: <fpage>1344</fpage>–<lpage>1361</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Bean1"><label>51</label>
<mixed-citation publication-type="other" xlink:type="simple">Bean MA (2001) Probability: the science of uncertainty with applications to investments, insurance, and engineering, volume 6. American Mathematical Soc.</mixed-citation>
</ref>
<ref id="pcbi.1003859-Cisek2"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cisek</surname><given-names>P</given-names></name> (<year>2006</year>) <article-title>Integrated neural processes for defining potential actions and deciding between them: a computational model</article-title>. <source>J Neurosci</source> <volume>26</volume>: <fpage>9761</fpage>–<lpage>9770</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00017</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006822</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject><subj-group><subject>Recurrent neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject><subj-group><subject>Recurrent neural networks</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine learning algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine learning algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Machine learning</subject><subj-group><subject>Machine learning algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Bayesian method</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Efficient neural decoding of self-location with a deep recurrent network</article-title>
<alt-title alt-title-type="running-head">Efficient neural decoding of self-location with a deep recurrent network</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Tampuu</surname> <given-names>Ardi</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Matiisen</surname> <given-names>Tambet</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Ólafsdóttir</surname> <given-names>H. Freyja</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Barry</surname> <given-names>Caswell</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2497-0007</contrib-id>
<name name-style="western">
<surname>Vicente</surname> <given-names>Raul</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Computational Neuroscience Lab, Institute of Computer Science, University of Tartu, Tartu, Estonia</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Cell and Developmental Biology, University College London, London, United Kingdom</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Battaglia</surname> <given-names>Francesco P.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Radboud Universiteit Nijmegen, NETHERLANDS</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">raul.vicente.zafra@ut.ee</email> (RV); <email xlink:type="simple">caswell.barry@ucl.ac.uk</email> (CB)</corresp>
</author-notes>
<pub-date pub-type="collection">
<month>2</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="epub">
<day>15</day>
<month>2</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>2</issue>
<elocation-id>e1006822</elocation-id>
<history>
<date date-type="received">
<day>4</day>
<month>1</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>28</day>
<month>1</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Tampuu et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006822"/>
<abstract>
<p>Place cells in the mammalian hippocampus signal self-location with sparse spatially stable firing fields. Based on observation of place cell activity it is possible to accurately decode an animal’s location. The precision of this decoding sets a lower bound for the amount of information that the hippocampal population conveys about the location of the animal. In this work we use a novel recurrent neural network (RNN) decoder to infer the location of freely moving rats from single unit hippocampal recordings. RNNs are biologically plausible models of neural circuits that learn to incorporate relevant temporal context without the need to make complicated assumptions about the use of prior information to predict the current state. When decoding animal position from spike counts in 1D and 2D-environments, we show that the RNN consistently outperforms a standard Bayesian approach with either flat priors or with memory. In addition, we also conducted a set of sensitivity analysis on the RNN decoder to determine which neurons and sections of firing fields were the most influential. We found that the application of RNNs to neural data allowed flexible integration of temporal context, yielding improved accuracy relative to the more commonly used Bayesian approaches and opens new avenues for exploration of the neural code.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Being able to accurately self-localize is critical for most motile organisms. In mammals, place cells in the hippocampus appear to be a central component of the brain network responsible for this ability. In this work we recorded the activity of a population of hippocampal neurons from freely moving rodents and carried out neural decoding to determine the animals’ locations. We found that a machine learning approach using <italic>recurrent neural networks</italic> (RNNs) allowed us to predict the rodents’ true positions more accurately than a standard Bayesian method with flat priors (i.e. maximum likelihood estimator, MLE) as well as a Bayesian approach with memory (i.e. with priors informed by past activity). The RNNs are able to take into account past neural activity without making assumptions about the statistics of neuronal firing. Further, by analyzing the representations learned by the network we were able to determine which neurons, and which aspects of their activity, contributed most strongly to the accurate decoding.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100002301</institution-id>
<institution>Eesti Teadusagentuur</institution>
</institution-wrap>
</funding-source>
<award-id>PUT 1476</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2497-0007</contrib-id>
<name name-style="western">
<surname>Vicente</surname> <given-names>Raul</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<name name-style="western">
<surname>Barry</surname> <given-names>Caswell</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>AT, TM, and RV were supported by the Estonian Research Council, project number PUT 1476 (<ext-link ext-link-type="uri" xlink:href="https://www.etis.ee/Portal/Projects/Display/52ed4301-f2ef-4364-9770-397e31936f93?lang=ENG" xlink:type="simple">https://www.etis.ee/Portal/Projects/Display/52ed4301-f2ef-4364-9770-397e31936f93?lang=ENG</ext-link>), and Estonian Centre of Excellence in IT (EXCITE) project number TK148 (<ext-link ext-link-type="uri" xlink:href="https://www.etis.ee/Portal/Projects/Display/fd0aeffa-a7d3-4191-b468-0f44aa2847af?lang=ENG" xlink:type="simple">https://www.etis.ee/Portal/Projects/Display/fd0aeffa-a7d3-4191-b468-0f44aa2847af?lang=ENG</ext-link>). CB was funded by the Royal Society (<ext-link ext-link-type="uri" xlink:href="https://royalsociety.org" xlink:type="simple">https://royalsociety.org</ext-link>) and Wellcome Trust (<ext-link ext-link-type="uri" xlink:href="https://wellcome.ac.uk" xlink:type="simple">https://wellcome.ac.uk</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="1"/>
<page-count count="22"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-03-08</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All data files are available from public repositories. Specifically, the data necessary for Bayesian decoders is available from Zenodo repository (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2540921" xlink:type="simple">https://doi.org/10.5281/zenodo.2540921</ext-link>), while the data for RNN decoders is available from (<ext-link ext-link-type="uri" xlink:href="https://github.com/NeuroCSUT/RatGPS" xlink:type="simple">https://github.com/NeuroCSUT/RatGPS</ext-link>). All code is also available from (<ext-link ext-link-type="uri" xlink:href="https://github.com/NeuroCSUT/RatGPS" xlink:type="simple">https://github.com/NeuroCSUT/RatGPS</ext-link>).</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Place cells, pyramidal neurons found in CA1 and CA3 of the mammalian hippocampus [<xref ref-type="bibr" rid="pcbi.1006822.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006822.ref004">4</xref>], exhibit spatially constrained receptive fields, referred to as place fields. In general, the activity of place cells is considered to be stable [<xref ref-type="bibr" rid="pcbi.1006822.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref006">6</xref>]; place fields are typically robust to the removal of specific environmental cues [<xref ref-type="bibr" rid="pcbi.1006822.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref008">8</xref>], persist between visits to a location [<xref ref-type="bibr" rid="pcbi.1006822.ref009">9</xref>], and in the open field do not strongly depend upon an animal’s behaviour [<xref ref-type="bibr" rid="pcbi.1006822.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref005">5</xref>]. Upon exposure to a novel enclosure the firing correlates of place cells rapidly ‘remap’; place fields change their firing rate and relative position, forming a distinct representation for the new space [<xref ref-type="bibr" rid="pcbi.1006822.ref010">10</xref>–<xref ref-type="bibr" rid="pcbi.1006822.ref012">12</xref>]. For these reasons place cells are widely held to provide the neural basis of self-location, signalling the position of an animal relative to its environment and thus being a necessary element for the control of spatial behaviours, such as navigation, and the retention of spatial memories [<xref ref-type="bibr" rid="pcbi.1006822.ref002">2</xref>]. Unsurprisingly then, given information about the activity of a population of place cells, it is possible to decode the location of an animal with a relatively high degree of accuracy [<xref ref-type="bibr" rid="pcbi.1006822.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>].</p>
<p>However, although place cell activity is strongly modulated by self-location this relationship is non-trivial and not exclusive. For example, during rest and brief pauses, but also during motion, the place code can decouple from an animal’s current location and recapitulate trajectories through the enclosure [<xref ref-type="bibr" rid="pcbi.1006822.ref015">15</xref>]; ‘replaying’ previous experience [<xref ref-type="bibr" rid="pcbi.1006822.ref016">16</xref>] or, perhaps, foreshadowing future actions [<xref ref-type="bibr" rid="pcbi.1006822.ref017">17</xref>]. Similarly, when animals run on linear runways or perform constrained navigational tasks, such as T-maze alternation, place cell activity becomes strongly modulated by behaviour, disambiguating direction of travel [<xref ref-type="bibr" rid="pcbi.1006822.ref018">18</xref>], prospective and retrospective trajectories [<xref ref-type="bibr" rid="pcbi.1006822.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref020">20</xref>], and the degree of engagement with a task [<xref ref-type="bibr" rid="pcbi.1006822.ref021">21</xref>]. Furthermore, although place fields are repeatable they are not static. Even though remapping occurs rapidly in a novel environment, the newly formed firing fields continue to be refined during subsequent experience, a process that appears to persist for several hours [<xref ref-type="bibr" rid="pcbi.1006822.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref023">23</xref>]. Even in familiar environments, that animals have visited many times, the spatial activity of place cells is known to exhibit incremental changes that can result in the generation of distinct spatial codes [<xref ref-type="bibr" rid="pcbi.1006822.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1006822.ref026">26</xref>], which might be important for encoding goal locations [<xref ref-type="bibr" rid="pcbi.1006822.ref027">27</xref>] or other non-spatial variables [<xref ref-type="bibr" rid="pcbi.1006822.ref028">28</xref>]. As such, although hippocampal activity provides considerable information about an animal’s self-location the representation is dynamic: accumulating changes and sometimes encoding other variables both spatial and non-spatial.</p>
<p>A common approach used to interrogate neural representations, such as that of place cells, is decoding; the accuracy with which a variable, such as self-location, can be decoded from the brain, places a useful lower limit on the amount of information present [<xref ref-type="bibr" rid="pcbi.1006822.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>]. In the case of place cells, decoding methodologies typically apply a Bayesian framework to calculate a probability distribution over the the animal’s position, given the observed neural data [<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref029">29</xref>]. Decoding to a specific location is then accomplished via a maximum likelihood estimator applied to the probability distribution. However, the accuracy of Bayesian methods depends on accurate information about the expected activity of neurons. For place cells, activity recorded over the course of tens of minutes is typically used to estimate the firing rate of each cell at different points in the animal’s enclosure, with instantaneous rates assumed to exhibit Poisson dynamics. However, for the reasons outlined above, it is not clear that hippocampal activity can be modelled in this way. Indeed, the variability of place cell firing rates is known to greatly exceed that expected from a Poisson process [<xref ref-type="bibr" rid="pcbi.1006822.ref030">30</xref>]. As such, it is likely that Bayesian methods, as currently applied, do not provide an accurate reflection of the accuracy with which the hippocampus encodes self-location.</p>
<p>To better understand these constraints, we trained a deep recurrent neural network (RNN) [<xref ref-type="bibr" rid="pcbi.1006822.ref031">31</xref>–<xref ref-type="bibr" rid="pcbi.1006822.ref033">33</xref>] to decode rodent location from the firing rates of CA1 neurons. At each time step the network was presented with a vector corresponding to the spike counts of hippocampal cells within a given time window. After accumulating information for 100 time-steps the network was required to predict the animal’s location—supervision being provided in the form of the animal’s true location. We found that decoding with the trained RNN was consistently more accurate than a standard Bayesian approach [<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref029">29</xref>] with flat priors (essentially a MLE) as well as a Bayesian decoder with priors informed by the animals’ historic activity [<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref016">16</xref>]. This demonstrates that RNNs are able to capture the relationship between a temporal sequence of neural activity and an encoded variable without the necessity of explicit assumptions about the underlying noise model or complicated hand-coded priors. Further, inspection of the trained network allowed us to identify both the relative importance of individual neurons for accurate decoding and the locations at which they were most informative. Thus, not only does the accuracy of the RNN set a new limit for the amount of information about self-location encoded by place cells but more generally this work suggests that RNNs provide a useful approach for neural decoding and provide a means to explore the neural code.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<p>In the following Results section we summarize the decoding performance with three decoders. The <italic>simple Bayesian decoder</italic> uses spike counts from a single time window centered around the location measurement. It combines the likelihood of these spike counts occurring in different locations with a flat prior to make a decision, meaning it is essentially a <italic>maximum likelihood estimator (MLE)</italic>. The <italic>Bayesian with memory</italic>[<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>] employs a prior informed from self-location and movement speeds decoded from previous time steps (memory) as well as knowledge about the locations the animal most often visits, and combines it with the likelihood calculated based on the spike counts in the current time window.</p>
<p>The third decoder, <italic>recurrent neural network</italic> (RNN), is a machine learning algorithm that learns from examples via gradient descent [<xref ref-type="bibr" rid="pcbi.1006822.ref031">31</xref>]. In particular, by providing the network with a sequence of spike count vectors from 100 consecutive time windows and the location at the center of the last window, the algorithm learns to predict the latter from the former. As the network has access to neural activity from many preceding time windows, it learns to use this as contextual information to improve decoding accuracy. Learning is achieved by incrementally modifying the connection strengths in the network in order to minimize the mean squared error loss. The direction of change can be found by calculating the gradient of the loss with respect to each parameter.</p>
<p>In this work we used a type of recurrent neural network called long-short term memory (LSTM, [<xref ref-type="bibr" rid="pcbi.1006822.ref034">34</xref>]). All reported results are obtained with a network consisting of two 512-unit LSTM layers followed by a linear output layer (2 values, one for each coordinate). For more detailed description of the network, its inputs and training parameters see the <xref ref-type="sec" rid="sec010">Methods</xref> section and the code in GitHub.</p>
<sec id="sec003">
<title>High accuracy decoding of self-location in 2D environments</title>
<p>To test the RNN’s ability to decode rodent location based on hippocampal activity we first characterized the decoding error for a single animal foraging in a 2D arena (1m x 1m square). Single unit recordings were made using tetrodes from region CA1 of five rats. In all animals less than 10% of the recorded neurons were interneurons, characterized by narrow waveforms and high firing rates. Rat R2192 yielded the greatest number of simultaneously recorded hippocampal neurons (n = 63). Since the number of recorded neurons is expected to correlate with decoding accuracy, we first focused on this particular animal.</p>
<p>Neural data was processed to extract action potentials and these were assigned to individual neurons using the amplitude difference between tetrode channels [<xref ref-type="bibr" rid="pcbi.1006822.ref035">35</xref>] (see <xref ref-type="sec" rid="sec010">Methods</xref>). The input features for the RNN-decoder then consisted of spike counts for each neuron within a set of time windows. The length of time windows was parametrically varied between 200 ms and 4000 ms in 200 ms increments. Each consecutive window started 200 ms later than previous one (this means 0% overlap for 200 ms windows, 50% overlap for 400 ms windows, 80% overlap for 1000 ms windows, etc. See “Feature extraction” in Methods). The network was presented with spike counts from 100 windows before being asked to predict the animal’s location at the center of the latest window.</p>
<p>As the RNN training process is stochastic, 10-fold cross validation (CV) procedure was run multiple times for each window size. For each of these runs we trained 10 models (for each fold of CV) and extracted the mean and median results across the folds. Black dots on <xref ref-type="fig" rid="pcbi.1006822.g001">Fig 1</xref> correspond to these different realizations of the 10-fold CV procedure (notice multiple dots per window size). 10-fold cross validation was also applied to the Bayesian decoders.</p>
<fig id="pcbi.1006822.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006822.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Accurate decoding of position with a RNN.</title>
<p>Location decoding errors based on CA1 neural data recorded from 1m square open field environment as a function of time window size. (a) shows mean error and (b) median error. Blue lines represent errors from the RNN decoder and red lines from Bayesian approaches. Results for the RNN approach are averaged over different independent realizations of the training algorithm. Black dots depict the mean/median error of each individual model. Results shown are for animal R2192.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.g001" xlink:type="simple"/>
</fig>
<p>For both the mean (<xref ref-type="fig" rid="pcbi.1006822.g001">Fig 1a</xref>) and median (<xref ref-type="fig" rid="pcbi.1006822.g001">Fig 1b</xref>) of the validation errors, the error curve was convex with lowest errors obtained at intermediate values. Best median decoding accuracy was achieved with time window of 1200 ms (median error = 10.18±0.23 cm). Best mean decoding was achieved for a time window of 1400 ms (mean error = 12.50±0.39) cm). Using longer or shorter time windows lead to higher errors—likely because spike counts from shorter windows are increasingly noisy, while the animal’s CA1 activity is less specific to a particular location for longer windows. For all time windows, the accuracy of the RNN considerably exceeded that of both the simple Bayesian decoder (dashed red line) and the Bayesian decoder with memory (solid red line). The lowest median decoding error achieved with the simple Bayesian decoder was 12.00 cm (17.9% higher than for the RNN; this accuracy was obtained with multiple different window sizes), lowest mean error was 15.83 cm with a 2800 ms window. The Bayesian decoder with priors informed by the animal’s historic activity was more accurate than the naive Bayes approach but was still considerably less accurate than the RNN (lowest mean decoding error was 15.46 cm with 2000 ms windows, and lowest median 11.31 cm with 1400ms windows).</p>
<p>The RNN has the ability to flexibly use information from all 100 input vectors and thus integrates contextual information over time. This results in lower mean and median errors as compared to the two baseline Bayesian approaches. The naive Bayesian method with flat priors does not have access to information about past activity, resulting in lowest accuracy. Equally, the Bayesian decoder with memory incorporates past activity to form an informed prior, but does this in a predefined manner, being less flexible than the RNN. Notice also that the RNN approach achieves its best results for shorter time windows than the Bayesian approaches (see also <xref ref-type="table" rid="pcbi.1006822.t001">Table 1</xref> for optimal window size results from other animals). We hypothesize that the RNN’s efficient use of contextual information helps it to overcome the stochastic noise in the spike counting obtained for shorter time windows.</p>
<table-wrap id="pcbi.1006822.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006822.t001</object-id>
<label>Table 1</label>
<caption>
<title>Datasets for 2D and 1D decoding tasks.</title>
<p>Number of data points, number of recorded neurons, and the optimal time window for the three decoders for each of the 5 analyzed animals and for both decoding tasks.</p>
</caption>
<alternatives>
<graphic id="pcbi.1006822.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="center">Task</th>
<th align="center">Rat ID</th>
<th align="center">Length of recording</th>
<th align="center">Neurons recorded</th>
<th align="center">Optimal window for RNN</th>
<th align="center">Optimal window for simple Bayes</th>
<th align="center">Optimal window for Bayes with memory</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center" rowspan="5">2D</td>
<td align="center">R2192</td>
<td align="center">1081 s</td>
<td align="center">63</td>
<td align="center">1400 ms</td>
<td align="center">2800 ms</td>
<td align="center">2000 ms</td>
</tr>
<tr>
<td align="center">R2198</td>
<td align="center">1281 s</td>
<td align="center">33</td>
<td align="center">2000 ms</td>
<td align="center">1800 ms</td>
<td align="center">2000 ms</td>
</tr>
<tr>
<td align="center">R2336</td>
<td align="center">1234 s</td>
<td align="center">48</td>
<td align="center">1800 ms</td>
<td align="center">2800 ms</td>
<td align="center">2800 ms</td>
</tr>
<tr>
<td align="center">R2337</td>
<td align="center">1456 s</td>
<td align="center">43</td>
<td align="center">1800 ms</td>
<td align="center">2800 ms</td>
<td align="center">2600 ms</td>
</tr>
<tr>
<td align="center">R2217</td>
<td align="center">1500 s</td>
<td align="center">26</td>
<td align="center">1600 ms</td>
<td align="center">3400 ms</td>
<td align="center">3400 ms</td>
</tr>
<tr>
<td align="center" rowspan="5">1D</td>
<td align="center">R2192</td>
<td align="center">1394 s</td>
<td align="center">72</td>
<td align="center">1400 ms</td>
<td align="center">2800 ms</td>
<td align="center">2200 ms</td>
</tr>
<tr>
<td align="center">R2198</td>
<td align="center">1934 s</td>
<td align="center">49</td>
<td align="center">2200 ms</td>
<td align="center">3400 ms</td>
<td align="center">1800 ms</td>
</tr>
<tr>
<td align="center">R2336</td>
<td align="center">1900 s</td>
<td align="center">71</td>
<td align="center">1400 ms</td>
<td align="center">4400 ms</td>
<td align="center">3600 ms</td>
</tr>
<tr>
<td align="center">R2337</td>
<td align="center">2778 s</td>
<td align="center">71</td>
<td align="center">1600 ms</td>
<td align="center">2000 ms</td>
<td align="center">400 ms</td>
</tr>
<tr>
<td align="center">R2217</td>
<td align="center">1595 s</td>
<td align="center">40</td>
<td align="center">1400 ms</td>
<td align="center">5400 ms</td>
<td align="center">3800 ms</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Beyond the global descriptors of mean and median error, we also inspected the distribution of decoding error sizes (<xref ref-type="fig" rid="pcbi.1006822.g002">Fig 2a</xref>).</p>
<fig id="pcbi.1006822.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006822.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Comparison of RNN and Bayesian decoders.</title>
<p>(a) Histogram of error sizes, generated in each case with the best performing time window (1400 ms for RNN, 2800 ms for flat Bayesian and 2000ms for Bayesian with memory). Both types of Bayesian decoders make more very large errors (0.02% vs 2.7% of errors &gt; 50 cm). Errors are grouped into 2 cm bins, the last bin shows all errors above 50 cm. (b-c) Downsampling analysis demonstrates the RNN decoder is more robust to small dataset sizes. Data from R2192 was downsampled and all three decoders were trained with a random subset of the available neurons. For each sample size, 10 random sets of neurons were selected and independent models trained as before using 10-fold cross validation. Dots represents (b) mean and (c) median error for each downsampled dataset. Lines indicate the (b) mean of means and (c) mean of medians over sets of the same size.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.g002" xlink:type="simple"/>
</fig>
<p>The RNN error distribution followed a unimodal curve with most predictions deviating from the rat’s true position by 6-8 cm and few errors were larger than 35 cm (1.7% of errors &gt; 35 cm, see <xref ref-type="fig" rid="pcbi.1006822.g002">Fig 2a</xref>). The Bayesian classifiers achieve more very low (&lt;2 cm) errors, but also an abundance of very large (&gt;50 cm) errors (≈8% of errors &gt; 35 cm, ≈2.7%&gt; 50 cm; for both Bayesian classifiers).</p>
<p>In many cases single unit recordings yield fewer than the 63 neurons identified from R2192. We hypothesised that the RNN’s ability to use contextual information would be increasingly important in scenarios where neural data was more scarce. To test this prediction we randomly downsampled the dataset available from R2192, repeating the training and decoding procedure for populations of neurons varying in size from 5 to 55 in increments of 5. As expected we saw that decoding accuracy reduced as the size of the dataset reduced. However the RNN was considerably more robust to small sample sizes, decoding with an error of 30.9 cm with only 5 neurons vs. 46.0 cm error for the Bayesian decoder (<xref ref-type="fig" rid="pcbi.1006822.g002">Fig 2b</xref>).</p>
</sec>
<sec id="sec004">
<title>Population-level results in 2D and 1D environments</title>
<p>In total we analyzed recordings from five animals as they foraged in a 2D open field environment (1m x 1m square). For each of these 5 datasets, we determined the best performing time window size (similarly to <xref ref-type="fig" rid="pcbi.1006822.g001">Fig 1</xref>) for the RNN architecture (composed of 2-layers of 512 LSTM units), simple Bayesian decoder (MLE), and Bayesian decoder with memory. The optimal time window sizes for the five 2D foraging datasets are given in top half of <xref ref-type="table" rid="pcbi.1006822.t001">Table 1</xref> along with the length of the recording and the number of identified neurons.</p>
<p>In the 2D decoding task, for different animals, the mean error (mean across cross validation folds) ranged between 12.5-16.3 cm and median between 10.3-13.1 cm (<xref ref-type="fig" rid="pcbi.1006822.g003">Fig 3a and 3b</xref>). Interestingly, despite some recordings yielding as few as 26 or 33 cells, the decoding accuracy using RNNs is roughly similar. In all cases the mean and median decoding results from the RNN decoder outperformed both the standard Bayesian approach and Bayesian with memory.</p>
<fig id="pcbi.1006822.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006822.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Spatial decoding across animals in 2D and 1D environments.</title>
<p>(a-b) Decoding results in a 1m square environment. The RNN consistently outperforms the two Bayesian approaches in all 5 data sets. Mean and median errors across cross validation folds, respectively. (c-d) Decoding errors from a 600 cm long Z-shaped track. RNN consistently yields lower decoding errors than the Bayesian approaches, the difference is more marked when mean (c) as oppose to median (d) errors are considered.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.g003" xlink:type="simple"/>
</fig>
<p>We also performed decoding on 1D datasets recorded while the same 5 animals shuttled back and forwards on a 600 cm long Z-shaped track for reward placed at the corners and ends (<xref ref-type="table" rid="pcbi.1006822.t001">Table 1</xref>) [<xref ref-type="bibr" rid="pcbi.1006822.ref036">36</xref>]. As before we applied RNN and Bayesian decoders to 10-fold cross validated data, selecting in each case the optimal time window size (<xref ref-type="table" rid="pcbi.1006822.t001">Table 1</xref>). The RNN decoder greatly outperformed the two Bayesian decoders in all 5 data sets when comparing mean errors (<xref ref-type="fig" rid="pcbi.1006822.g003">Fig 3c</xref>). In the 2D task the largest possible error was 141.7 cm (if the predicted location is in the corner diagonally opposite to the true location), whereas in 1D task it is 600 cm (if the opposite end of the track is predicted). In the 1D task a small number of extremely large errors will inflate the mean error, whereas the median will be less affected (<xref ref-type="fig" rid="pcbi.1006822.g003">Fig 3c and 3d</xref>). Examining the median errors we found that RNN outperformed the Bayesian decoders in all cases. However for four of the five animals the difference in error was relatively small (<xref ref-type="fig" rid="pcbi.1006822.g003">Fig 3d</xref>). For the fifth rat with the fewest recorded cells (R2117, n = 40), the RNN clearly outperformed the Bayesian approaches, having a median decoding error that was almost half that of what the two types of Bayesian decoders achieved.</p>
</sec>
<sec id="sec005">
<title>Analysis of results obtained with RNN-decoder</title>
<p>Next to understand how behavioural and neural variability influenced decoding accuracy we focused on the results obtained from rat R2192 in the 1m square—the animal with the greatest number of neurons and the lowest decoding error.</p>
<p>First we examined the decoding error as a function of the rat’s location. It is important to note that the animals’ behaviour is non-uniform—the rats visit some parts of the arena more often than others (see <xref ref-type="fig" rid="pcbi.1006822.g004">Fig 4a</xref>). Since more training data is available for frequently visited regions it is expected that any decoding approach would be most accurate in those locations. The spatial distribution of decoding error for R2192 seems to confirm this conjecture—well sampled bins in the center of the enclosure and portions of its borders are more accurately decoded (<xref ref-type="fig" rid="pcbi.1006822.g004">Fig 4b</xref>). To confirm this, we calculated the correlation between the decoding error and the number of training data points located within 10 cm radius of the predicted data point, finding a significant negative correlation (Spearman’s Rank Order, <italic>r</italic> = −0.16, <italic>p</italic><sub><italic>val</italic></sub> ≪ 0.001, <italic>dof</italic> = 4412).</p>
<fig id="pcbi.1006822.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006822.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Analysis of the errors in function of location and neural activity for rat R2192.</title>
<p>(a) The trajectory of the rat during the entire trial. Not all parts of the arena are visited with equal frequently. (b) The average size of errors made in different regions of space. Color of each hexagon depicts the average euclidean error of data points falling into the hexagon. More frequently visited areas (as seen from (a)) tend to have lower mean error. (c) Sum neural activity in different regions of space. For each data point we sum the spike counts of all 63 neurons in a 1400 ms period centered around the moment the location was recorded. The color of the hexagon corresponds to the average over all data points falling into the hexagon. Areas where sum neural activity is high have lower prediction error. (d) Prediction error of a coordinate decreases if the animal is closer to the wall perpendicular to that coordinate.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.g004" xlink:type="simple"/>
</fig>
<p>Another important factor influencing the decoding accuracy is the distribution of neural activity across the 2D enclosure. In particular, place fields of the recorded hippocampal cells do not cover the enclosure uniformly. Clearly it would be difficult for the algorithm to differentiate between locations where no cell is active. As such, it is likely that areas where more neurons are activated are decoded with higher precision. Our results confirm that the sum of spike counts across neurons at a given location is strongly anti-correlated with the prediction error made at that location (<xref ref-type="fig" rid="pcbi.1006822.g004">Fig 4c</xref>, Spearman’s Rank Order, <italic>r</italic> = −0.31, <italic>p</italic><sub><italic>val</italic></sub> ≪ 0.001, <italic>dof</italic> = 4412).</p>
<p>We also inspected the <italic>x</italic> and <italic>y</italic> components of the decoding error separately. Previous work suggests that, in the case of grid cells, contact with an environmental boundary results in a reduction of error in the representation of self-location perpendicular to that wall [<xref ref-type="bibr" rid="pcbi.1006822.ref037">37</xref>]. Such a relationship would be expected if boundaries function as an elongated spatial cue, used by animals to update their representation of self-location relative to its surface. Accordingly, we found that for RNN decoding based on CA1 neurons, the decoding accuracy orthogonal to environmental boundaries increased with proximity to that boundary (<xref ref-type="fig" rid="pcbi.1006822.g004">Fig 4d</xref>, Spearman’s Rank Order between error and distance to wall in the region up to 25cm from the wall, <italic>r</italic> = 0.31, <italic>p</italic> ≪ 0.001, <italic>dof</italic> = 3968). The result also held for <italic>x</italic> (<italic>r</italic> = 0.35, <italic>p</italic> ≪ 0.001, <italic>dof</italic> = 2101) and <italic>y</italic> (<italic>r</italic> = 0.25, <italic>p</italic> ≪ 0.001, <italic>dof</italic> = 1855) coordinates separately. Conversely, decoding error parallel to the boundary was not modulated by proximity.</p>
<p>Furthermore, an additional factor that seemed to influence prediction accuracy was the animal’s motion speed. Predictions were more reliable when the rat was moving as opposed to stationary. The mean prediction error for speeds below 0.5 cm/s being 16.5 cm, higher than the 12.1 cm average error for all speeds above 0.5 cm/s (two-sided Welch’s t-test, <italic>t</italic> = 10.62, <italic>p</italic> ≪ 0.001, median errors 8.68 cm and 7.74 cm accordingly). It seems plausible that the lower prediction accuracy during stationary periods might be due to place cells preferentially replaying non-local trajectories during these periods [<xref ref-type="bibr" rid="pcbi.1006822.ref038">38</xref>]. A second interesting observation is that the prediction error does not increase at higher speeds (two-sided Welch’s t-test between errors in data points where speed is in range from 0.5 cm/s to 10.5cm/s and errors in data points with speed above 10.5cm/s, <italic>t</italic> = 0.31, <italic>p</italic> = 0.76).</p>
</sec>
<sec id="sec006">
<title>Sensitivity analysis</title>
<p>The accuracy of any neural decoder represents a useful lower bound on the information about the decoded state contained by the recorded neurons. Thus, a biologically relevant question is how such information is distributed among the neurons, across space and time. In short we asked which features of the neuronal activity are the most informative at predicting the animal’s position. To this end we conducted two different types of sensitivity analyses to measure robustness to different types of perturbations. For a visualization of the representations learned by the RNN, see the dimensionality reduction analysis (using t-SNE) in <xref ref-type="supplementary-material" rid="pcbi.1006822.s005">S1 Text</xref>, <xref ref-type="supplementary-material" rid="pcbi.1006822.s002">S2</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006822.s003">S3</xref> Figs.</p>
<sec id="sec007">
<title>Knockout approach</title>
<p>A simple way to estimate the relevance of a specific input in a predictive model is to remove it (to <italic>knock out</italic>) and observe how the prediction accuracy changes. If the input is removed before training, the model can learn to compensate for the missing information—knockout with retraining. However, if the input is removed after training—knockout without retraining—the model cannot adapt or compensate.</p>
<p>Here we used knockout without retraining. The RNN was applied, as before, to predict locations based on a validation dataset in which the activity of a single neuron was set to zero. The knock-out procedure was repeated for each input neuron separately and mean prediction error calculated. Thus we were able to rank neurons by sensitivity—the greater the error increase due to the knocking-out the more crucial the neuron was for the model.</p>
<p>The most influential neuron (neuron #55) was visually identified as an inhibitory neuron based on the lack of clear firing fields and high firing rate (<xref ref-type="fig" rid="pcbi.1006822.g005">Fig 5</xref>). In someways it is surprising that this neuron was identified as having the greatest influence on the model—prior work suggests that inhibitory cells do not provide much information about self-location. However, the model’s sensitivity to this neuron is likely due to its high firing rate. Neuron #55 had a firing rate 4 times higher than any other neuron, meaning its removal eliminates the largest number of spikes from the analysis. The other 4 most influential neurons appear to be typical pyramidal place cells characterized by clear place fields [<xref ref-type="bibr" rid="pcbi.1006822.ref002">2</xref>]. The knocking out of these top neurons induced a sizable decrease (&gt; 1<italic>cm</italic>) in the prediction accuracy.</p>
<fig id="pcbi.1006822.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006822.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Results of knockout analysis.</title>
<p>The firing rate maps of the most (a-e) and least (f) influential neurons according to the knockout analysis. Colour bar to the right of each plot indicates the firing rate in Hz. With the complete dataset the mean error was 12.50±0.28 cm. When knocking out neurons 55, 26, 41, 17, 23 (the five most influential) and 9 (the least influential), the mean error increased to 14.72 cm, 13.80 cm, 13.66 cm, 13.50 cm, 13.49 cm and 12.58 cm respectively.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.g005" xlink:type="simple"/>
</fig>
<p>For more than half of the neurons knocking them out decreased the prediction accuracy only slightly (less than the standard deviation of accuracy, calculated over 10 realizations of the complete model). Among those less influential neurons we found both putative inhibitory interneurons and pyramidal cells with no clear place fields and a lower than average firing rate. For example, the rate map of the least influential neuron, was characterized by a low firing rate #9 (<xref ref-type="fig" rid="pcbi.1006822.g005">Fig 5f</xref>). As suggested by the most and least influential neurons, importance according to knock-out analysis correlated strongly with firing rate (Spearman’s Rank Order, <italic>r</italic> = 0.50, <italic>p</italic><sub><italic>val</italic></sub> &lt; 0.001, <italic>dof</italic> = 61).</p>
</sec>
<sec id="sec008">
<title>Gradients with respect to input</title>
<p>A different way to investigate which neurons most strongly influence decoding accuracy is a gradient analysis. In this analysis we calculate the derivatives of the loss function (mean squared prediction error) of the RNN with respect to the inputs (spike counts of neurons) at different time points. By definition these derivatives show how much a small change in a spike count influences the error. This type of sensitivity analysis is quite different from the knock out analysis—knockout sensitivity measures the impact of silencing a neuron, gradient sensitivity measures the impact of a neurons activity deviating from the expected value.</p>
<p>For each predicted location we asked how sensitive the model was to each of the input spike counts. Since our RNN input is a set of 100 spike count vectors (length of time series), each of length 63 (number of neurons), this amounts to 63x100 gradients per sample. Considering that the whole data set contains around 4400 samples we obtain a 4400x63x100 cubic array of gradient values. To reveal different aspects of the sensitivity of the model, we can average this array of gradients across three dimensions—samples, neurons, or position in the input sequence.</p>
<p>Averaging gradients across all samples and all time windows provided one average gradient value per neuron. Similarly to the knock-out analysis this indicated how relevant the neuron is for the prediction. The two sensitivity measures (knock-out and gradient) were strongly correlated (Spearman’s Rank Order, <italic>ρ</italic> = 0.57, <italic>p</italic> ≪ 0.001, <italic>dof</italic> = 61), but not equivalent. The tests ranked some neurons very differently. For example, the high-firing inhibitory neuron #55 which influences the accuracy most strongly according to knock-out analysis is ranked 47th out of 63 neurons by the gradient sensitivity analysis. Thus illustrating, that despite that fact both measures broadly concur, the gradient and knockout analyses capture different notions of robustness with respect to input perturbations. Interestingly, neither of the two sensitivity measures correlated with the spatial information theoretic measure proposed by Skaggs et al.[<xref ref-type="bibr" rid="pcbi.1006822.ref039">39</xref>] (Spearman’s Rank Order, gradient-vs-Skaggs: <italic>ρ</italic> = −0.22, <italic>pval</italic> = 0.08, <italic>dof</italic> = 61; knock-vs-Skaggs: <italic>ρ</italic> = −0.09, <italic>p</italic> = 0.48, <italic>dof</italic> = 61). This suggests that that the Skaggs Information Score captures a specific aspect of each neuron’s influence in the context of a population of place cells. The measures we propose are complementary to the Skaggs Information Score and potentially reveal different notions of sensitivity.</p>
<p>In a second step, we investigate how sensitivity with respect to a neuron’s spike count depends on whether the animal is within its place field or not. Place fields are of variable shape and size and, moreover, a small proportion of the recorded cells have no distinct place fields. Also the firing rates and gradient strengths vary greatly between neurons. Thus, we used firing rate as a proxy to indicate proximity of the animal to a given neuron’s place field—firing rate being maximal when the animal is near the centre of a place field, diminishing the further is moves away from that point. Hence after normalizing both the firing rates and the strength of gradients we averaged over all recorded cells (see the Sensitivity measures subsection in Methods). We saw that sensitivity decreases when the firing rate increases (<xref ref-type="fig" rid="pcbi.1006822.g006">Fig 6</xref>). Hence, indicating that at maximal firing rate—near the center of place field, for example—small changes in firing rate are less influential than they are towards the edges of the firing field. Broadly this accords with theoretical considerations which indicate that, in general, neural responses are most informative in the regions of their coding space where the firing rate changes most rapidly for a given change in the encoded variable [<xref ref-type="bibr" rid="pcbi.1006822.ref040">40</xref>]. In the case of place cells this corresponds to the edges of the place field. Conversely, outside of the place field, where firing rates fall close to 0 Hz, the sensitivity of the RNN to the neuron is again slightly lower (<xref ref-type="fig" rid="pcbi.1006822.g006">Fig 6</xref>).</p>
<fig id="pcbi.1006822.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006822.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Gradient analysis: Sensitivity decreases with activity.</title>
<p>(a) Place field of an example neuron. (b) <italic>Sensitivity field</italic>—absolute values of gradients in different locations for the same neuron. (c) Normalized sensitivity as a function of normalized activity across neurons.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.g006" xlink:type="simple"/>
</fig>
</sec>
</sec>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<p>We have shown that the sequential processing afforded by an artificial recurrent neural network (RNN) provides a flexible methodology able to efficiently decode information from a population of neurons. Moreover, since a RNN decoder is a neural network, it represents a biologically relevant model of how neural information is processed. Specifically, when applied to hippocampal neural data from freely moving rats [<xref ref-type="bibr" rid="pcbi.1006822.ref002">2</xref>], the network made use of the past neural activity to improve the decoding accuracy of the animals’ positions. In a 2D open field arena (1m x 1m), the RNN decoder was able to infer position with a median error of between 10.3 cm to 13.1 cm for 5 different rats. These results represented a marked improvement over both a simple Bayesian decoder using a flat prior [<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref029">29</xref>], which bases its decision solely on spike counts from a single time window centered around the moment of position measurement, as well as a Bayesian decoder incorporating priors informed by the animals’ behaviour and recent spiking history [<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>].</p>
<p>Bayesian methods are known to be optimal decoders when using appropriate priors [<xref ref-type="bibr" rid="pcbi.1006822.ref041">41</xref>]. However, when applied to neural decoding it is difficult to determine these appropriate priors—as a result sub-optimal approximations are commonly used. Hence we propose that RNNs offer a practical methodology to incorporate sequential context without the need to choose or estimate specific priors over high-dimensional spaces. The improvement in 2D position decoding observed for the RNN was mirrored by similar results from a 1D decoding task using hippocampal recordings made while animals ran on a 6 meter track. Here again, the RNN decoder achieved equal or better results than the Bayesian approaches.</p>
<p>Making use of the past neural activity as contextual information, the RNN seems more robust to noise than the two Bayesian classifiers. In particular when using shorter time windows the spike counts become noisier and the Bayesian models’ prediction accuracy degraded rapidly. In contrast the RNN decoder was more resistant to the variability of spike counts, likely due to its ability to combine information over the complete sequence of past inputs. Similarly, in situations where fewer neurons were available and hence the total amount information was reduced, the RNN exhibited a pronounced advantage over the Bayesian decoders. Equally, in the 1D task the benefit of the RNN was most evident for animal R2217, which had the fewest recorded neurons. Nevertheless notice that fewer recorded neurons does not necessarily mean lower accuracy. As described in Section 2.3.1, the error depends strongly on the amount of training data available (length of recording) and the quality of the cells (amount and location of firing). Taken together these results suggest that RNN decoding of neural data may prove to be particularly useful in situations where large populations of neurons are not available or are difficult to stably maintain.</p>
<p>Beyond quality and amount of data available, the size of error the RNN decoder made was also seen to depend on the distance of the animal from the walls and its instantaneous speed. At higher speeds (above 10.5 cm/s) the decoding accuracy does not decrease, but when the animal is immobile (below 0.5 cm/s) the error was significantly higher than when in motion. We hypothesize that while stationary hippocampal activity may reflect non-local activity associated with sharp-wave ripple states [<xref ref-type="bibr" rid="pcbi.1006822.ref038">38</xref>].</p>
<p>Beyond providing more accurate decoding, the neural network approach also provides a new means of conducting sensitivity analyses. While knockout-type sensitivity analyses can be applied to both Bayesian and RNN decoders, the latter approach also supports gradient analyses. The two types of sensitivity—knockout and gradient—are correlated, but not identical. By design knockout analyses answers how the system behaves if an input is completely removed, while gradient analyses investigated how the system behaves in response to small perturbations to that input. Having access to the gradients with respect to each spike count makes is possible to pose new questions about the dynamic variability of the information content of individual neurons.</p>
</sec>
<sec id="sec010" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec011">
<title>Ethics statement</title>
<p>All procedures were approved by the UK Home Office, subject to the restrictions and provisions contained in the Animals Scientific Procedures Act of 1986.</p>
</sec>
<sec id="sec012">
<title>Data collection</title>
<sec id="sec013">
<title>Animals and surgery</title>
<p>Five male Lister Hooded rats were used in this study. All procedures were approved by the UK Home Office, subject to the restrictions and provisions contained in the Animals Scientific Procedures Act of 1986. All rats (330 − 400<italic>g</italic> / 13 − 18 weeks old at implantation) received two microdrives, each carrying eight tetrodes of twisted 17<italic>μm</italic> HM-L coated platinum iridium wire (90% and 10%, respectively; California Fine Wire), targeted to the right CA1 (ML: 2.2<italic>mm</italic>, AP: 3.8<italic>mm</italic> posterior to Bregma) and left medial entorhinal cortex (MEC) (ML = 4.5<italic>mm</italic>, AP = 0.3 − 0.7 anterior to the transverse sinus, angled between 8 − 10°). Wires were platinum plated to reduce impedance to 200 − 300<italic>kΩ</italic> at 1<italic>kHz</italic>. After rats had recovered from surgery they were maintained at 90% of free-feeding weight with <italic>ad libitum</italic> access to water, and were housed individually on a 12 − <italic>hr</italic> light/dark cycle. MEC data was not analysed for this study.</p>
</sec>
<sec id="sec014">
<title>Recording</title>
<p>Screening was performed post-surgically after a 1-week recovery period. An Axona recording system (Axona Ltd., St Albans, UK) was used to acquire the single-units and positional data (for details of the recording system and basic recording protocol see Barry et al(2007). The position and head direction of the animals was inferred using an overhead video camera to record the location of two light-emitting diodes (LEDs) mounted on the animals’ head-stages (50 Hz). Tetrodes were gradually advanced in 62.5<italic>μm</italic> steps across days until place cells (CA1) and grid cells (MEC) were identified.</p>
</sec>
<sec id="sec015">
<title>Experimental apparatus and protocol</title>
<p>The experiment was run during the animals’ light period. First, animals ran on a Z-shaped track, elevated 75<italic>cm</italic> off the ground with 10<italic>cm</italic> wide runways. The two parallel tracks of the Z (190 cm each) were connected by a diagonal section (220<italic>cm</italic>). The entire track was surrounded by plain black curtains with no distal cues. During each track session, animals were required to complete laps on the elevated Z-track. Specifically, the animals were required to run from the start of Arm1 to the end of Arm3, stopping at the track corners and ends in order to receive a food reward. If the animals made a wrong turn at the corners, reward was withheld. Three animals (R2192, R2198, and R2217) were trained to run on the track for 3 days before recording commenced. For the other animals (R2336, R2337), recordings were made from the first day of exposure to the Z-track task. These recordings constitute the dataset we refer to as the 1D decoding task.</p>
<p>Following the track session the same animals completed a 20min random foraging session in a square (1m x 1m) enclosure. Coverage of the enclosure was encouraged by rewarding animals with sweetened rice. These recordings constitute the dataset we refer to as the 2D decoding task. Not all animals’ recordings were used.</p>
</sec>
</sec>
<sec id="sec016">
<title>Decoder based on recurrent neural networks</title>
<p>Deep learning is a class of algorithms that learn a hierarchy of representations or transformations of the data that make the problem of classification or regression easier [<xref ref-type="bibr" rid="pcbi.1006822.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref033">33</xref>]. In particular, deep neural networks, inspired by biological neural circuits, consist of layers of computational units called neurons or nodes. The deepness means that there are multiple “hidden” layers between the input and output. By tuning the connection weights between its layers a neural network can learn to approximate a function from a set of examples, i.e., pairs of related input and output data. In this work we are interested in training a neural network to decode the rat spatial coordinates from the activity recorded from its hippocampal cells.</p>
<p>Whereas feed-forward neural networks learn to predict an output based on a single input, recurrent neural networks (RNNs) can deal with series of inputs and/or outputs [<xref ref-type="bibr" rid="pcbi.1006822.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref033">33</xref>]. In particular, a recurrent network can preserve information from previous inputs by means of feedback connections (loops between its units). Having access to past information can be useful to minimize errors in certain tasks. Such memory of past inputs also means that the order in which the inputs are presented to the network may change the eventual predictions, and thus integrate contextual information over time. A naive implementation of RNNs can only maintain information from a few past inputs, making it possible for the network to detect only immediate trends, but not long timescale dependencies. Advanced realizations of recurrent networks, such as long-short term memory (LSTM) [<xref ref-type="bibr" rid="pcbi.1006822.ref034">34</xref>] and gated recurrent units (GRU)[<xref ref-type="bibr" rid="pcbi.1006822.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref043">43</xref>] have specific architecture and sets of parameters that control to what extent past activity should be remembered or overwritten by a new input [<xref ref-type="bibr" rid="pcbi.1006822.ref043">43</xref>]. This makes them capable of integrating knowledge over a longer sequence. Through using past inputs as contextual information these networks have achieved outstanding performance with noisy sequential data such as text and speech.</p>
<sec id="sec017">
<title>Network architecture</title>
<p>A RNN can be made to predict (i) a series of outputs based on a series of inputs, (ii) a series of outputs given only one input, and (iii) one output given a series of inputs. For our location prediction task we are interested in the latter—given hippocampal activity (spike counts) over a longer period of time, we aim to predict one set of spatial coordinates—the animal location.</p>
<p>The architecture, illustrated in <xref ref-type="fig" rid="pcbi.1006822.g007">Fig 7c</xref>, of the RNN used in this work consists of an input layer (same size as the number of recorded neurons) followed by two 512-node LSTM layers, and an output layer (2 nodes, one for each spatial coordinate <italic>x</italic> and <italic>y</italic>).</p>
<fig id="pcbi.1006822.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006822.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Feature extraction from spiking data and neural network architecture.</title>
<p>(a) Extracting a sequence of spike count vectors from spiking data. Each subsequent input originates from an overlapping time period, shifted 200 ms forward in time. (b) The input data that the RNN decoder will use is a sequence of spike count vectors from these time windows. (c) The network used for decoding consists of an input layer (size equals number of recorded neurons), two hidden layers containing 512 long-short term memory (LSTM) units and an output layer of size 2 (<italic>x</italic> and <italic>y</italic> coordinates). The spike count vectors are inserted to the input layer one by one at each timestep. The network produces a prediction for <italic>x</italic> and <italic>y</italic> coordinates only at the end of the sequence, at <italic>t</italic> = 100.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.g007" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec018">
<title>Feature extraction</title>
<p>The features of neural data used for decoding are the spike counts of all <italic>N</italic> cells recorded (forming a <italic>spike count vector</italic>, as shown in <xref ref-type="fig" rid="pcbi.1006822.g007">Fig 7a and 7b</xref>). In particular, the recurrent neural network is presented with a series of 100 of such spike count vectors, corresponding to activity of all cells in 100 overlapping time windows. The shift between consecutive time windows was fixed to 200 ms for all window sizes (this means 0% overlap in 200 ms windows, 50% overlap in 400 ms windows, 80% overlap in 1000 ms windows). Across the 100 time steps we consider activity from approximately 20 seconds.</p>
<p>Based on this series of 100 spike count vectors the recurrent network was trained to predict the rat’s location in the center of the last (100th) time window. Thus, each sequence of 100 vectors plus the correct location of the rat at the center of the last time window forms one data point for training the RNN.</p>
</sec>
<sec id="sec019">
<title>Training procedure of RNNs</title>
<p>During the training procedure the network aims to minimize an objective function, in our case the mean squared error of the coordinates. The learning is done for 50 epochs (full cycles of training data) using a constant learning rate 0.001 and RMSprop optimizer (a variant of stochastic gradient descent, see [<xref ref-type="bibr" rid="pcbi.1006822.ref044">44</xref>] for detailed description), with a mini-batch size equal to 64. All computations were performed with custom-made scripts using Keras neural network library [<xref ref-type="bibr" rid="pcbi.1006822.ref045">45</xref>]. The training of 10-fold cross validation took approximately 4 hours on GeForce GTX Titan X graphics card.</p>
<p>The code for training the RNN models, can be found in <ext-link ext-link-type="uri" xlink:href="https://github.com/NeuroCSUT/RatGPS" xlink:type="simple">https://github.com/NeuroCSUT/RatGPS</ext-link>. The repository also contains data sets (pre-procesed into spike counts and locations per timewindow) and plotting scripts to generate the figures. All necessary data for RNN approaches is contained in 1D/data and 2D/data subfolders of the repository, for the Z-track and open field respectively.</p>
</sec>
<sec id="sec020">
<title>Model search</title>
<p>When searching for the best recurrent neural network model we scanned a number of architectures. Initially, we experimented with “many-to-many” models that predict a location per timestep, and with bidirectional RNN models [<xref ref-type="bibr" rid="pcbi.1006822.ref046">46</xref>] that also consider future activity. Ultimately we adopted a “many-to-one” approach which provided superior prediction accuracy (compared to “many-to-many”) and relied only on past information (unlike bidirectional). We experimented with both LSTM and GRU [<xref ref-type="bibr" rid="pcbi.1006822.ref043">43</xref>] recurrent units. We scanned the number of recurrent layers in the range (1 to 4) and the number of units per layer in range (128 to 2048). We added Dropout [<xref ref-type="bibr" rid="pcbi.1006822.ref047">47</xref>] with drop probability {0, 0.2 or 0.5} after each LSTM layer.</p>
<p>We tried Adam [<xref ref-type="bibr" rid="pcbi.1006822.ref048">48</xref>] and RMSProp optimizers with different learning rates (10<italic>e</italic><sup>−2</sup> to 10<italic>e</italic><sup>−4</sup>) and batch sizes (5 to 100). Learning rate was multiplied every {1, 5 or 10} epochs with a coefficient {0.1, 0.5 or 1.0}. We trained models for 10, 50 and 100 epochs. We did not use early stopping because we report cross validation performance and hence using a validation set at any stage of the training process might inflate the results.</p>
<p>As the number of possible parameter combinations is huge, we did not run a complete grid search, instead we removed values from consideration if they decreased validation performance or increased computational cost without improving the model.</p>
</sec>
</sec>
<sec id="sec021">
<title>Bayesian decoder</title>
<p>Spatial decoding was also implemented using a Bayesian framework [<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref049">49</xref>] subject to 10-fold cross validation (see also the next subsection). Specifically, for each fold, 90% of the data was used to generate ratemaps for hippocampal neurons—spike and dwell time data were binned into 2 cm square bins, smoothed with a Gaussian kernel (<italic>σ</italic> = 1.5 bins), and rates calculated by dividing spike numbers by dwell time. Note, for the Z-maze only, positional data was linearised before binning.</p>
<p>Next, with the remaining 10% of the data, using temporal windows (200 ms to 4000 ms) each of which overlapped with its neighbours by half, we calculate the probability of the animal’s presence in each spatial bin given the observed spikes—the posterior probability matrix [<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1006822.ref029">29</xref>].</p>
<p>Specifically during a time window (T) the spikes generated by <italic>N</italic> place cells was <italic>K</italic> = (<italic>k</italic><sub>1</sub>,…, <italic>k</italic><sub><italic>i</italic></sub>,…, <italic>k</italic><sub><italic>N</italic></sub>), where <italic>k</italic><sub><italic>i</italic></sub> was the number of spikes fired by the <italic>i</italic>−<italic>th</italic> cell. The probability of observing <italic>K</italic> in time T given position (<italic>x</italic>) was taken as:
<disp-formula id="pcbi.1006822.e001"><alternatives><graphic id="pcbi.1006822.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006822.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">K</mml:mi> <mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∏</mml:mo> <mml:mi>P</mml:mi> <mml:mi>o</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>s</mml:mi> <mml:mi>o</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>k</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>T</mml:mi> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>×</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>k</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msup> <mml:mrow><mml:msub><mml:mi>k</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>!</mml:mo></mml:mrow></mml:mfrac> <mml:mo>×</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>T</mml:mi> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>x</italic> indexes the 2 cm spatial bins defined on the Z-track/foraging environment and <italic>α</italic><sub><italic>i</italic></sub>(<italic>x</italic>) is the firing rate of the <italic>i</italic> − <italic>th</italic> place cell at position <italic>x</italic>, derived from the ratemaps.</p>
<p>In the case of the simple Bayes decoder, to compute the probability of the animal’s position given the observed spikes we applied Bayes’ rule, assuming a flat prior for position (<italic>P</italic>(<italic>x</italic>)), to give:
<disp-formula id="pcbi.1006822.e002"><alternatives><graphic id="pcbi.1006822.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006822.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>R</mml:mi> <mml:mspace width="4pt"/><mml:mo>[</mml:mo> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>k</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msup> <mml:mo>]</mml:mo> <mml:mo>×</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>T</mml:mi> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <italic>R</italic> is a normalizing constant depending on <italic>T</italic> and the number of spikes emitted. Note in this case we do not use the historic position of the animals’ to constrain <italic>P</italic>(<italic>x</italic>|<italic>K</italic>) thus the probability estimate in each <italic>T</italic> is independent of its neighbours. Finally, position was decoded from the posterior probability matrix using a maximum likelihood method—selecting the bin with the highest probability value. Decoding error was then taken as the Euclidean distance between the centre of the decoded bin and the centre of the bin closest to the animal’s true location.</p>
<p>Finally for the Bayes decoder with memory we made two further changes. First for each animal <italic>P</italic>(<italic>x</italic>), the probability of being at position <italic>x</italic>, was calculated directly from the experimental data for the entire trial, giving:
<disp-formula id="pcbi.1006822.e003"><alternatives><graphic id="pcbi.1006822.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006822.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>R</mml:mi> <mml:mspace width="4pt"/><mml:mo>×</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:mo>[</mml:mo> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>k</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msup> <mml:mo>]</mml:mo> <mml:mo>×</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>T</mml:mi> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup> <mml:msub><mml:mi>α</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>Second, following [<xref ref-type="bibr" rid="pcbi.1006822.ref014">14</xref>] we incorporated a continuity constraint such that information about the animal’s decoded position in the previous time step was used to calculate the conditional probability of <italic>P</italic>(<italic>x</italic><sub><italic>t</italic></sub> | <italic>spikes</italic><sub><italic>t</italic></sub>, <italic>x</italic><sub><italic>t</italic>−1</sub>).
<disp-formula id="pcbi.1006822.e004"><alternatives><graphic id="pcbi.1006822.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006822.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mspace width="4pt"/><mml:mo>|</mml:mo> <mml:mspace width="4pt"/><mml:mi>s</mml:mi> <mml:mi>p</mml:mi> <mml:mi>i</mml:mi> <mml:mi>k</mml:mi> <mml:mi>e</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="4pt"/><mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="4pt"/><mml:mo>=</mml:mo> <mml:mspace width="4pt"/><mml:mi>C</mml:mi> <mml:mo>×</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">K</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>×</mml:mo> <mml:mi>n</mml:mi> <mml:mi>o</mml:mi> <mml:mi>r</mml:mi> <mml:mi>m</mml:mi> <mml:mi>D</mml:mi> <mml:mi>i</mml:mi> <mml:mi>s</mml:mi> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mspace width="4pt"/><mml:mi>s</mml:mi> <mml:mi>i</mml:mi> <mml:mi>g</mml:mi> <mml:mi>m</mml:mi> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Where C is a normalising constant and normDist is a normal distribution centred on the animal’s decoded position in the previous time step with sigma equal to the mean distance travelled per time step in the previous 15 time steps multiplied by a scaling factor which was set to 1 for the open field decoding and 5 for linear track.</p>
<p>The implementations of these two approaches can be found in the Bayesian folder of the GitHub repository <ext-link ext-link-type="uri" xlink:href="https://github.com/NeuroCSUT/RatGPS" xlink:type="simple">https://github.com/NeuroCSUT/RatGPS</ext-link>. Please notice that the data for MLE and Bayesian apporaches must be downloaded and added to the Bayesian/Data folder manually, as the files were too large do be added to GitHub. As instructed in the README files in the repository, the data can be found via DOI (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.2540921" xlink:type="simple">https://doi.org/10.5281/zenodo.2540921</ext-link>).</p>
</sec>
<sec id="sec022">
<title>Cross validation and averaging of results</title>
<p>The reported errors for both Bayesian and RNN approach are measured using a 10-fold cross validation method that divides the <italic>D</italic> data points between training and validation sets. Due to the overlap between consecutive time windows a random assignment of data points to training and validation sets would imply that for most of the validation data points a highly correlated neighbouring sample can be found in the training set. This would result in an artificially high validation accuracy that does not actually reflect the model’s ability to generalize to new, unseen data.</p>
<p>Instead, in our analysis the first fold in cross validation simply corresponds to leaving out the first 10% of the recording time and training the model on the last 90% of data. The second fold, accordingly, assigns the second tenth of recordings to the validation set, and so on. For RNNs we need to additionally discard 99 samples at each border between training and validation sets. Remind that the input for RNNs is a series of 100 spike count vectors—to avoid any overlap between training and test data we remove validation data points that have at least one shared spike count vector with any training data point.</p>
<p>For each fold we train a model on the training set and calculate the error on the validation set. All reported errors are the validation errors—errors that the models make on the one tenth of data that was left out of the training procedure. To increase the reliability of the results, we perform 10-fold cross validation procedure multiple times and report the mean and median of the errors. This is done only for the RNN decoder, because the Bayesian decoder is deterministic and repeating cross-validation procedure multiple times is not necessary.</p>
</sec>
<sec id="sec023">
<title>Analysis of decoding results</title>
<sec id="sec024">
<title>Quantifying prediction errors</title>
<p>When decoding rat locations in the 2D arena, prediction errors were quantified by the mean Euclidean distance (MED) between the predicted and true positions:
<disp-formula id="pcbi.1006822.e005"><alternatives><graphic id="pcbi.1006822.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006822.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>M</mml:mi> <mml:mi>E</mml:mi> <mml:mi>D</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover></mml:mstyle> <mml:mrow><mml:mo>(</mml:mo> <mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>^</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>^</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:mspace width="1.em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1006822.e006"><alternatives><graphic id="pcbi.1006822.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006822.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006822.e007"><alternatives><graphic id="pcbi.1006822.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006822.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> are the locations predicted by the decoder, <italic>y</italic> and <italic>x</italic> are the true locations and <italic>N</italic> is the number of data points.</p>
<p>The training procedure for recurrent neural networks is stochastic, potentially resulting in different solutions with the same starting conditions. We repeat the 10-fold cross-validation 10 times, giving us 10 independent predictions for each data point. We report the average of errors over these 10 realizations (and not the error of the averaged prediction).</p>
<p>For evaluating the <italic>x</italic>-coordinate (<italic>y</italic>-coordinate) errors only the <italic>x</italic> (<italic>y</italic>) component of the positions were used in the above formula:
<disp-formula id="pcbi.1006822.e008"><alternatives><graphic id="pcbi.1006822.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006822.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>M</mml:mi> <mml:mi>E</mml:mi> <mml:msub><mml:mi>D</mml:mi> <mml:mi>x</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover></mml:mstyle> <mml:mrow><mml:mo>(</mml:mo> <mml:msqrt><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>^</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:msqrt> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover></mml:mstyle> <mml:mrow><mml:mo>|</mml:mo> <mml:mover accent="true"><mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>^</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mi>N</mml:mi></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>In an additional experiment, we also decode the rat locations on a 600 cm long Z-shaped track. The position of the rat along the track is considered as a 1D coordinate ranging from 0 in one end of the track to 600 in the other end of the Z-shape. To obtain these 1D coordinates the actual locations extracted from camera images are projected to the nearest point on a Z-shaped ideal trajectory. The prediction error of the model is quantified by absolute distance between the predicted and true position along this 1D coordinate.</p>
</sec>
<sec id="sec025">
<title>Sensitivity measures</title>
<p>For knock-out analyses we set the activity of the neuron under consideration to zero in all validation data points and then calculate the validation errors. The activity is not annulled during training of the model, so the system can not learn to compensate or adapt. We repeated this knock-out procedure for each neuron in turn.</p>
<p>The gradient of the loss function with respect to inputs was calculated using back-propagation through time [<xref ref-type="bibr" rid="pcbi.1006822.ref050">50</xref>], similarly to how gradients with respect to weights are found. Indeed, for updating the connection weights of the network at training time, the algorithm needs to calculate the gradients of the loss function with respect to the weights [<xref ref-type="bibr" rid="pcbi.1006822.ref031">31</xref>]. These gradients tell us how a small change in a particular weight would influence the final output error. In here we ask a similar question—how much would a small deviation in a certain input change the final loss. It is important to notice that when talking about sensitivity we disregard the sign of the gradient, in all results we use the absolute values (magnitudes) of gradients. We compute gradient strengths for each validation set data point and separately for each neuron’s spike count for each position in the time series of <italic>T</italic> inputs (<italic>T</italic> = 100). This results in a <italic>D</italic> × <italic>N</italic> × <italic>T</italic> matrix of gradient values. To draw further conclusions from the gradient values, we need to average or manipulate this 3D matrix along different dimensions. For example, when calculating the neurons that the model is most sensitive to, we need to average across all data points and all time steps, so we are left with one value per neuron.</p>
<p>When investigating the relationship between sensitivity and location on the place field (on <xref ref-type="fig" rid="pcbi.1006822.g006">Fig 6c</xref>), we also need to normalize the spike counts and gradient magnitudes of different neurons, so that we could aggregate them. To do this one would usually divide the spike count with the maximum value, resulting in measures between 0 and 1 for all cells. In the case or low-firing neurons, however, the noisiness of the data means that the maximum value can be an outlier (we can have maximum count of 4, whereas no other value is above 2). We therefore choose to divide the spike counts with the 99th percentile of the spike count values instead. A few values end up being above 1, but the normalized value distributions of low and high firing neurons look more similar. We do a similar 99-th percentile normalization on the absolute values of gradients. For each normalized firing rate we have one corresponding normalized gradient size. We can then plot how the normalized gradient size depends on normalized firing rate.</p>
</sec>
</sec>
</sec>
<sec id="sec026">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006822.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Mean prediction error for different instantaneous movement speeds.</title>
<p>Movement speed is based on the distance covered in 200 ms. The first bar is the average over the errors for speeds in range [0, 0.5] cm/s, the second for (0.5, 1.5] cm/s, etc. The error is highest when the rat is not moving or moving very slowly. Notice that speeds in the range of 1-2 cm/s can also be the results of head movements. At higher speeds the exact velocity does not seem to influence accuracy. Note that the bars do not contain the same amount of data points. Apparent changes in the mean error at higher velocities can be attributed to noise as we have less data points there.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006822.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>t-SNE analysis.</title>
<p>Top row: colouring reflects if the data point’s true location is near a wall. Bottom row: points are colored by the X-coordinate of true location of the data point and sized accoring to Y-coordinate. The left column illustrates how the the coloring schemes look on the true XY-coordinates. The right column shows the schemes applied on activations of nodes in the second layer of the RNN model at t = 100, reduced to 2D by t-SNE. Notice that data points with similar true locations are also nearby in activity space.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006822.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>t-SNE analysis.</title>
<p>Top row: data points are colored according to instantaneous speed. Bottow row: data points a colored accoring to instantaneous direction of movement. Left column shows the correspondence between true location and speed and direction. In the right column the colouring schemes are applied to activations of nodes in the second layer of the RNN model at t = 100, reduced to 2D by t-SNE. There is no visible correspondence between RNN activations and neither speed nor direction.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006822.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Gradient analysis.</title>
<p>a-e) Temporal profiles of relative importance for 5 selected neurons among the highest contributing neurons according to gradient analysis. Notice that the profiles peak at different time steps. f) Temporal profile of the least important neuron according to gradient analysis.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006822.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.s005" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>t-SNE analysis of RNN representations of input data.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006822.s006" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006822.s006" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Temporal gradient analysis.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Zurab Bzhalava, Sander Tanni and Jaan Aru for early work and useful discussions. We also thank Jack Kelly for useful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006822.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>O’Keefe</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dostrovsky</surname> <given-names>J</given-names></name>. <article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title>. <source>Brain research</source>. <year>1971</year>;<volume>34</volume>(<issue>1</issue>):<fpage>171</fpage>–<lpage>175</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0006-8993(71)90358-1" xlink:type="simple">10.1016/0006-8993(71)90358-1</ext-link></comment> <object-id pub-id-type="pmid">5124915</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref002">
<label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>O’keefe</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Nadel</surname> <given-names>L</given-names></name>. <source>The hippocampus as a cognitive map</source>. <publisher-loc>Oxford</publisher-loc>: <publisher-name>Clarendon Press</publisher-name>; <year>1978</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ulanovsky</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Moss</surname> <given-names>CF</given-names></name>. <article-title>Hippocampal cellular and network activity in freely moving echolocating bats</article-title>. <source>Nature neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>2</issue>):<fpage>224</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1829" xlink:type="simple">10.1038/nn1829</ext-link></comment> <object-id pub-id-type="pmid">17220886</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ekstrom</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Kahana</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Caplan</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Fields</surname> <given-names>TA</given-names></name>, <etal>et al</etal>. <article-title>Cellular networks underlying human spatial navigation</article-title>. <source>Nature</source>. <year>2003</year>;<volume>425</volume>(<issue>6954</issue>):<fpage>184</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature01964" xlink:type="simple">10.1038/nature01964</ext-link></comment> <object-id pub-id-type="pmid">12968182</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Muller</surname> <given-names>RU</given-names></name>, <name name-style="western"><surname>Kubie</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Ranck</surname> <given-names>JB</given-names></name>. <article-title>Spatial firing patterns of hippocampal complex-spike cells in a fixed environment</article-title>. <source>Journal of Neuroscience</source>. <year>1987</year>;<volume>7</volume>(<issue>7</issue>):<fpage>1935</fpage>–<lpage>1950</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Muller</surname> <given-names>RU</given-names></name>, <name name-style="western"><surname>Kubie</surname> <given-names>JL</given-names></name>. <article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells</article-title>. <source>Journal of Neuroscience</source>. <year>1987</year>;<volume>7</volume>(<issue>7</issue>):<fpage>1951</fpage>–<lpage>1968</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.07-07-01951.1987" xlink:type="simple">10.1523/JNEUROSCI.07-07-01951.1987</ext-link></comment> <object-id pub-id-type="pmid">3612226</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>O’keefe</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Conway</surname> <given-names>D</given-names></name>. <article-title>Hippocampal place units in the freely moving rat: why they fire where they fire</article-title>. <source>Experimental brain research</source>. <year>1978</year>;<volume>31</volume>(<issue>4</issue>):<fpage>573</fpage>–<lpage>590</lpage>. <object-id pub-id-type="pmid">658182</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Quirk</surname> <given-names>GJ</given-names></name>, <name name-style="western"><surname>Muller</surname> <given-names>RU</given-names></name>, <name name-style="western"><surname>Kubie</surname> <given-names>JL</given-names></name>. <article-title>The firing of hippocampal place cells in the dark depends on the rat’s recent experience</article-title>. <source>Journal of Neuroscience</source>. <year>1990</year>;<volume>10</volume>(<issue>6</issue>):<fpage>2008</fpage>–<lpage>2017</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.10-06-02008.1990" xlink:type="simple">10.1523/JNEUROSCI.10-06-02008.1990</ext-link></comment> <object-id pub-id-type="pmid">2355262</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thompson</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Best</surname> <given-names>P</given-names></name>. <article-title>Long-term stability of the place-field activity of single units recorded from the dorsal hippocampus of freely behaving rats</article-title>. <source>Brain research</source>. <year>1990</year>;<volume>509</volume>(<issue>2</issue>):<fpage>299</fpage>–<lpage>308</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0006-8993(90)90555-P" xlink:type="simple">10.1016/0006-8993(90)90555-P</ext-link></comment> <object-id pub-id-type="pmid">2322825</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bostock</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Muller</surname> <given-names>RU</given-names></name>, <name name-style="western"><surname>Kubie</surname> <given-names>JL</given-names></name>. <article-title>Experience-dependent modifications of hippocampal place cell firing</article-title>. <source>Hippocampus</source>. <year>1991</year>;<volume>1</volume>(<issue>2</issue>):<fpage>193</fpage>–<lpage>205</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hipo.450010207" xlink:type="simple">10.1002/hipo.450010207</ext-link></comment> <object-id pub-id-type="pmid">1669293</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Anderson</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Jeffery</surname> <given-names>KJ</given-names></name>. <article-title>Heterogeneous modulation of place cell firing by changes in context</article-title>. <source>Journal of Neuroscience</source>. <year>2003</year>;<volume>23</volume>(<issue>26</issue>):<fpage>8827</fpage>–<lpage>8835</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.23-26-08827.2003" xlink:type="simple">10.1523/JNEUROSCI.23-26-08827.2003</ext-link></comment> <object-id pub-id-type="pmid">14523083</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Leutgeb</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Leutgeb</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Treves</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name>. <article-title>Distinct ensemble codes in hippocampal areas CA3 and CA1</article-title>. <source>Science</source>. <year>2004</year>;<volume>305</volume>(<issue>5688</issue>):<fpage>1295</fpage>–<lpage>1298</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1100265" xlink:type="simple">10.1126/science.1100265</ext-link></comment> <object-id pub-id-type="pmid">15272123</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>. <article-title>Dynamics of the hippocampal ensemble code for space</article-title>. <source>Science</source>. <year>1993</year>;<volume>261</volume>(<issue>5124</issue>):<fpage>1055</fpage>–<lpage>1059</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.8351520" xlink:type="simple">10.1126/science.8351520</ext-link></comment> <object-id pub-id-type="pmid">8351520</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zhang</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ginzburg</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>Interpreting neuronal population activity by reconstruction: unified framework with application to hippocampal place cells</article-title>. <source>Journal of neurophysiology</source>. <year>1998</year>;<volume>79</volume>(<issue>2</issue>):<fpage>1017</fpage>–<lpage>1044</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1998.79.2.1017" xlink:type="simple">10.1152/jn.1998.79.2.1017</ext-link></comment> <object-id pub-id-type="pmid">9463459</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>, <etal>et al</etal>. <article-title>Reactivation of hippocampal ensemble memories during sleep</article-title>. <source>Science</source>. <year>1994</year>;<volume>265</volume>(<issue>5172</issue>):<fpage>676</fpage>–<lpage>679</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.8036517" xlink:type="simple">10.1126/science.8036517</ext-link></comment> <object-id pub-id-type="pmid">8036517</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Davidson</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Kloosterman</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>MA</given-names></name>. <article-title>Hippocampal replay of extended experience</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>63</volume>(<issue>4</issue>):<fpage>497</fpage>–<lpage>507</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.07.027" xlink:type="simple">10.1016/j.neuron.2009.07.027</ext-link></comment> <object-id pub-id-type="pmid">19709631</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pfeiffer</surname> <given-names>BE</given-names></name>, <name name-style="western"><surname>Foster</surname> <given-names>DJ</given-names></name>. <article-title>Hippocampal place cell sequences depict future paths to remembered goals</article-title>. <source>Nature</source>. <year>2013</year>;<volume>497</volume>(<issue>7447</issue>):<fpage>74</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature12112" xlink:type="simple">10.1038/nature12112</ext-link></comment> <object-id pub-id-type="pmid">23594744</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Navratilova</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Hoang</surname> <given-names>LT</given-names></name>, <name name-style="western"><surname>Schwindel</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Tatsuno</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>. <article-title>Experience-dependent firing rate remapping generates directional selectivity in hippocampal place cells</article-title>. <source>Frontiers in neural circuits</source>. <year>2012</year>;<volume>6</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncir.2012.00006" xlink:type="simple">10.3389/fncir.2012.00006</ext-link></comment> <object-id pub-id-type="pmid">22363267</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wood</surname> <given-names>ER</given-names></name>, <name name-style="western"><surname>Dudchenko</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Robitsek</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Eichenbaum</surname> <given-names>H</given-names></name>. <article-title>Hippocampal neurons encode information about different types of memory episodes occurring in the same location</article-title>. <source>Neuron</source>. <year>2000</year>;<volume>27</volume>(<issue>3</issue>):<fpage>623</fpage>–<lpage>633</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0896-6273(00)00071-4" xlink:type="simple">10.1016/S0896-6273(00)00071-4</ext-link></comment> <object-id pub-id-type="pmid">11055443</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ferbinteanu</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shapiro</surname> <given-names>ML</given-names></name>. <article-title>Prospective and retrospective memory coding in the hippocampus</article-title>. <source>Neuron</source>. <year>2003</year>;<volume>40</volume>(<issue>6</issue>):<fpage>1227</fpage>–<lpage>1239</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0896-6273(03)00752-9" xlink:type="simple">10.1016/S0896-6273(03)00752-9</ext-link></comment> <object-id pub-id-type="pmid">14687555</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Markus</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Qin</surname> <given-names>YL</given-names></name>, <name name-style="western"><surname>Leonard</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Skaggs</surname> <given-names>WE</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Barnes</surname> <given-names>CA</given-names></name>. <article-title>Interactions between location and task affect the spatial and directional firing of hippocampal neurons</article-title>. <source>Journal of Neuroscience</source>. <year>1995</year>;<volume>15</volume>(<issue>11</issue>):<fpage>7079</fpage>–<lpage>7094</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.15-11-07079.1995" xlink:type="simple">10.1523/JNEUROSCI.15-11-07079.1995</ext-link></comment> <object-id pub-id-type="pmid">7472463</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Karlsson</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>LM</given-names></name>. <article-title>Network dynamics underlying the formation of sparse, informative representations in the hippocampus</article-title>. <source>Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>52</issue>):<fpage>14271</fpage>–<lpage>14281</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4261-08.2008" xlink:type="simple">10.1523/JNEUROSCI.4261-08.2008</ext-link></comment> <object-id pub-id-type="pmid">19109508</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barry</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Ginzberg</surname> <given-names>LL</given-names></name>, <name name-style="western"><surname>O’Keefe</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Burgess</surname> <given-names>N</given-names></name>. <article-title>Grid cell firing patterns signal environmental novelty by expansion</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2012</year>;<volume>109</volume>(<issue>43</issue>):<fpage>17687</fpage>–<lpage>17692</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1209918109" xlink:type="simple">10.1073/pnas.1209918109</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ziv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Burns</surname> <given-names>LD</given-names></name>, <name name-style="western"><surname>Cocker</surname> <given-names>ED</given-names></name>, <name name-style="western"><surname>Hamel</surname> <given-names>EO</given-names></name>, <name name-style="western"><surname>Ghosh</surname> <given-names>KK</given-names></name>, <name name-style="western"><surname>Kitch</surname> <given-names>LJ</given-names></name>, <etal>et al</etal>. <article-title>Long-term dynamics of CA1 hippocampal place codes</article-title>. <source>Nature neuroscience</source>. <year>2013</year>;<volume>16</volume>(<issue>3</issue>):<fpage>264</fpage>–<lpage>266</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3329" xlink:type="simple">10.1038/nn.3329</ext-link></comment> <object-id pub-id-type="pmid">23396101</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hayman</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Chakraborty</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Jeffery</surname> <given-names>KJ</given-names></name>. <article-title>Context-specific acquisition of location discrimination by hippocampal place cells</article-title>. <source>European Journal of Neuroscience</source>. <year>2003</year>;<volume>18</volume>(<issue>10</issue>):<fpage>2825</fpage>–<lpage>2834</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1460-9568.2003.03035.x" xlink:type="simple">10.1111/j.1460-9568.2003.03035.x</ext-link></comment> <object-id pub-id-type="pmid">14656331</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lever</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Wills</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Cacucci</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Burgess</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>O’keefe</surname> <given-names>J</given-names></name>. <article-title>Long-term plasticity in hippocampal place-cell representation of environmental geometry</article-title>. <source>Nature</source>. <year>2002</year>;<volume>416</volume>(<issue>6876</issue>):<fpage>90</fpage>–<lpage>94</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/416090a" xlink:type="simple">10.1038/416090a</ext-link></comment> <object-id pub-id-type="pmid">11882899</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dupret</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>O’neill</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pleydell-Bouverie</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Csicsvari</surname> <given-names>J</given-names></name>. <article-title>The reorganization and reactivation of hippocampal maps predict spatial memory performance</article-title>. <source>Nature neuroscience</source>. <year>2010</year>;<volume>13</volume>(<issue>8</issue>):<fpage>995</fpage>–<lpage>1002</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2599" xlink:type="simple">10.1038/nn.2599</ext-link></comment> <object-id pub-id-type="pmid">20639874</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eichenbaum</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Dudchenko</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wood</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Shapiro</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tanila</surname> <given-names>H</given-names></name>. <article-title>The hippocampus, memory, and place cells: is it spatial memory or a memory space?</article-title> <source>Neuron</source>. <year>1999</year>;<volume>23</volume>(<issue>2</issue>):<fpage>209</fpage>–<lpage>226</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Towse</surname> <given-names>BW</given-names></name>, <name name-style="western"><surname>Barry</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bush</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Burgess</surname> <given-names>N</given-names></name>. <article-title>Optimal configurations of spatial scale for grid cell firing under noise and uncertainty</article-title>. <source>Philosophical Transactions of the Royal Society of London B: Biological Sciences</source>. <year>2014</year>;<volume>369</volume>(<issue>1635</issue>):<fpage>20130290</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.2013.0290" xlink:type="simple">10.1098/rstb.2013.0290</ext-link></comment> <object-id pub-id-type="pmid">24366144</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fenton</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Muller</surname> <given-names>RU</given-names></name>. <article-title>Place cell discharge is extremely variable during individual passes of the rat through the firing field</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1998</year>;<volume>95</volume>(<issue>6</issue>):<fpage>3182</fpage>–<lpage>3187</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.95.6.3182" xlink:type="simple">10.1073/pnas.95.6.3182</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rumelhart</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>RJ</given-names></name>, <etal>et al</etal>. <article-title>Learning representations by back-propagating errors</article-title>. <source>Cognitive modeling</source>. <year>1988</year>;<volume>5</volume>(<issue>3</issue>):<fpage>1</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Elman</surname> <given-names>JL</given-names></name>. <article-title>Finding structure in time</article-title>. <source>Cognitive science</source>. <year>1990</year>;<volume>14</volume>(<issue>2</issue>):<fpage>179</fpage>–<lpage>211</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1207/s15516709cog1402_1" xlink:type="simple">10.1207/s15516709cog1402_1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref033">
<label>33</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Goodfellow</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Courville</surname> <given-names>A</given-names></name>. <source>Deep Learning</source>. <publisher-name>MIT Press</publisher-name>; <year>2016</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hochreiter</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schmidhuber</surname> <given-names>J</given-names></name>. <article-title>Long short-term memory</article-title>. <source>Neural computation</source>. <year>1997</year>;<volume>9</volume>(<issue>8</issue>):<fpage>1735</fpage>–<lpage>1780</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco.1997.9.8.1735" xlink:type="simple">10.1162/neco.1997.9.8.1735</ext-link></comment> <object-id pub-id-type="pmid">9377276</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barry</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Hayman</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Burgess</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Jeffery</surname> <given-names>KJ</given-names></name>. <article-title>Experience-dependent rescaling of entorhinal grids</article-title>. <source>Nature neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>6</issue>):<fpage>682</fpage>–<lpage>684</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1905" xlink:type="simple">10.1038/nn1905</ext-link></comment> <object-id pub-id-type="pmid">17486102</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ólafsdóttir</surname> <given-names>HF</given-names></name>, <name name-style="western"><surname>Carpenter</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Barry</surname> <given-names>C</given-names></name>. <article-title>Coordinated grid and place cell replay during rest</article-title>. <source>Nature neuroscience</source>. <year>2016</year>;<volume>19</volume>(<issue>6</issue>):<fpage>792</fpage>–<lpage>794</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4291" xlink:type="simple">10.1038/nn.4291</ext-link></comment> <object-id pub-id-type="pmid">27089021</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hardcastle</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ganguli</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Giocomo</surname> <given-names>LM</given-names></name>. <article-title>Environmental boundaries as an error correction mechanism for grid cells</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>86</volume>(<issue>3</issue>):<fpage>827</fpage>–<lpage>839</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.03.039" xlink:type="simple">10.1016/j.neuron.2015.03.039</ext-link></comment> <object-id pub-id-type="pmid">25892299</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ólafsdóttir</surname> <given-names>HF</given-names></name>, <name name-style="western"><surname>Carpenter</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Barry</surname> <given-names>C</given-names></name>. <article-title>Task Demands Predict a Dynamic Switch in the Content of Awake Hippocampal Replay</article-title>. <source>Neuron</source>. <year>2017</year>;<volume>96</volume>(<issue>4</issue>):<fpage>925</fpage>–<lpage>935</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2017.09.035" xlink:type="simple">10.1016/j.neuron.2017.09.035</ext-link></comment> <object-id pub-id-type="pmid">29056296</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref039">
<label>39</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Skaggs</surname> <given-names>WE</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Gothard</surname> <given-names>KM</given-names></name>. <chapter-title>An information-theoretic approach to deciphering the hippocampal code</chapter-title>. In: <source>Advances in neural information processing systems</source>; <year>1993</year>. p. <fpage>1030</fpage>–<lpage>1037</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ducom</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>. <article-title>Narrow versus wide tuning curves: What’s best for a population code?</article-title> <source>Neural computation</source>. <year>1999</year>;<volume>11</volume>(<issue>1</issue>):<fpage>85</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976699300016818" xlink:type="simple">10.1162/089976699300016818</ext-link></comment> <object-id pub-id-type="pmid">9950723</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref041">
<label>41</label>
<mixed-citation publication-type="other" xlink:type="simple">Mitchell TM, et al. Machine learning. WCB; 1997.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref042">
<label>42</label>
<mixed-citation publication-type="other" xlink:type="simple">Cho K, Van Merriënboer B, Bahdanau D, Bengio Y. On the properties of neural machine translation: Encoder-decoder approaches. arXiv preprint arXiv:14091259. 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref043">
<label>43</label>
<mixed-citation publication-type="other" xlink:type="simple">Chung J, Gulcehre C, Cho K, Bengio Y. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:14123555. 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tieleman</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>G</given-names></name>. <article-title>Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude</article-title>. <source>COURSERA: Neural networks for machine learning</source>. <year>2012</year>;<volume>4</volume>(<issue>2</issue>):<fpage>26</fpage>–<lpage>31</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref045">
<label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Chollet F, et al. Keras; 2015. <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras" xlink:type="simple">https://github.com/fchollet/keras</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schuster</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Paliwal</surname> <given-names>KK</given-names></name>. <article-title>Bidirectional recurrent neural networks</article-title>. <source>IEEE Transactions on Signal Processing</source>. <year>1997</year>;<volume>45</volume>(<issue>11</issue>):<fpage>2673</fpage>–<lpage>2681</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/78.650093" xlink:type="simple">10.1109/78.650093</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Srivastava</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Krizhevsky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sutskever</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Salakhutdinov</surname> <given-names>R</given-names></name>. <article-title>Dropout: A simple way to prevent neural networks from overfitting</article-title>. <source>The Journal of Machine Learning Research</source>. <year>2014</year>;<volume>15</volume>(<issue>1</issue>):<fpage>1929</fpage>–<lpage>1958</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref048">
<label>48</label>
<mixed-citation publication-type="other" xlink:type="simple">Kingma DP, Ba J. Adam: A method for stochastic optimization. arXiv preprint arXiv:14126980. 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1006822.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ólafsdóttir</surname> <given-names>HF</given-names></name>, <name name-style="western"><surname>Barry</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Saleem</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Hassabis</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Spiers</surname> <given-names>HJ</given-names></name>. <article-title>Hippocampal place cells construct reward related sequences through unexplored space</article-title>. <source>Elife</source>. <year>2015</year>;<volume>4</volume>:<fpage>e06063</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.06063" xlink:type="simple">10.7554/eLife.06063</ext-link></comment> <object-id pub-id-type="pmid">26112828</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006822.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Werbos</surname> <given-names>PJ</given-names></name>. <article-title>Backpropagation through time: what it does and how to do it</article-title>. <source>Proceedings of the IEEE</source>. <year>1990</year>;<volume>78</volume>(<issue>10</issue>):<fpage>1550</fpage>–<lpage>1560</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/5.58337" xlink:type="simple">10.1109/5.58337</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>
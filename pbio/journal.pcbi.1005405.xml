<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-16-01869</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005405</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject><subj-group><subject>Normal distribution</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Geometry</subject><subj-group><subject>Fractals</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Learning curves</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Learning curves</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Learning curves</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject><subj-group><subject>Learning curves</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Working memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Working memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Working memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Working memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Fidelity of the representation of value in decision-making</article-title>
<alt-title alt-title-type="running-head">Fidelity of the representation of value in decision-making</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4684-4893</contrib-id>
<name name-style="western">
<surname>Bays</surname> <given-names>Paul M.</given-names></name>
<xref ref-type="aff" rid="aff001"/>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dowding</surname> <given-names>Ben A.</given-names></name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>University of Cambridge, Department of Psychology, Cambridge, United Kingdom</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>O’Reilly</surname> <given-names>Jill</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Oxford University, UNITED KINGDOM</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p>
<list list-type="simple">
<list-item>
<p><bold>Conceptualization:</bold> PMB.</p>
</list-item>
<list-item>
<p><bold>Formal analysis:</bold> PMB.</p>
</list-item>
<list-item>
<p><bold>Funding acquisition:</bold> PMB.</p>
</list-item>
<list-item>
<p><bold>Investigation:</bold> PMB BAD.</p>
</list-item>
<list-item>
<p><bold>Methodology:</bold> PMB.</p>
</list-item>
<list-item>
<p><bold>Project administration:</bold> PMB.</p>
</list-item>
<list-item>
<p><bold>Software:</bold> BAD.</p>
</list-item>
<list-item>
<p><bold>Supervision:</bold> PMB.</p>
</list-item>
<list-item>
<p><bold>Visualization:</bold> PMB.</p>
</list-item>
<list-item>
<p><bold>Writing – original draft:</bold> PMB.</p>
</list-item>
</list>
</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">pmb20@cam.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>3</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>1</day>
<month>3</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>3</issue>
<elocation-id>e1005405</elocation-id>
<history>
<date date-type="received">
<day>16</day>
<month>11</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>13</day>
<month>2</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Bays, Dowding</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005405"/>
<abstract>
<p>The ability to make optimal decisions depends on evaluating the expected rewards associated with different potential actions. This process is critically dependent on the fidelity with which reward value information can be maintained in the nervous system. Here we directly probe the fidelity of value representation following a standard reinforcement learning task. The results demonstrate a previously-unrecognized bias in the representation of value: extreme reward values, both low and high, are stored significantly more accurately and precisely than intermediate rewards. The symmetry between low and high rewards pertained despite substantially higher frequency of exposure to high rewards, resulting from preferential exploitation of more rewarding options. The observed variation in fidelity of value representation retrospectively predicted performance on the reinforcement learning task, demonstrating that the bias in representation has an impact on decision-making. A second experiment in which one or other extreme-valued option was omitted from the learning sequence showed that representational fidelity is primarily determined by the relative position of an encoded value on the scale of rewards experienced during learning. Both variability and guessing decreased with the reduction in the number of options, consistent with allocation of a limited representational resource. These findings have implications for existing models of reward-based learning, which typically assume defectless representation of reward value.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Many models of learning and decision-making assume that experienced rewards are stored without error. We examined this assumption experimentally: participants first learned an association between different options and rewards in a simple two-alternative choice task. We then asked them to report what reward they expected to receive for each of the options they had experienced. We checked that the reports we collected matched performance on the choice task, meaning that the values participants reported were the same as those they used to decide between options. The results showed that participants were both less precise (greater variability) and less accurate (greater bias) in their reports of middling reward values compared to either high- or low-valued options. Reports of high and low values were similar in quality even though participants had experienced the rewards associated with high-value options considerably more often. Whether an option’s value was stored well or poorly was not fixed, but instead depended on how the value compared to other options the participant had experienced. These results should lead to better models of how decisions are made based on experiences of reward.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>106926</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-4684-4893</contrib-id>
<name name-style="western">
<surname>Bays</surname> <given-names>Paul M</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This research was supported by the Wellcome Trust (grant number 106926 to PMB). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="0"/>
<page-count count="16"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-03-15</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data are available on the Open Science Framework at <ext-link ext-link-type="uri" xlink:href="https://osf.io/gtswq/" xlink:type="simple">https://osf.io/gtswq/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>In an uncertain and dynamic environment, rational decision-making depends on the ability to learn, store and update the reward values associated with different choices or actions [<xref ref-type="bibr" rid="pcbi.1005405.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005405.ref002">2</xref>]. This ability in turn depends on the coding of reward in neurons of the prefrontal cortex [<xref ref-type="bibr" rid="pcbi.1005405.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref008">8</xref>], supported by teaching signals carried by projections from the basal ganglia [<xref ref-type="bibr" rid="pcbi.1005405.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref013">13</xref>]. Like neurons throughout the brain [<xref ref-type="bibr" rid="pcbi.1005405.ref014">14</xref>], the firing of reward-sensitive neurons is stochastic, i.e. noisy. However, little is known about how this noise is expressed in the representation of reward value.</p>
<p>Classical learning algorithms [<xref ref-type="bibr" rid="pcbi.1005405.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005405.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref017">17</xref>] describe how the values associated with different options are updated, and the decision rules that determine what choices are taken. These models typically assume that values are stored flawlessly: suboptimal decisions are instead a result of noise in reward-generating processes (making experience of past rewards an imprecise guide to the future), incomplete updating of reward estimates by new information (as parameterized by a learning rate), or stochastic decision rules such as <italic>ϵ</italic>-greedy or softmax. While these models can provide good approximations to observed learning patterns, they could be improved by more accurately reflecting what is inevitably an imperfect representation of value in the nervous system.</p>
<p>A second class of decision models, based on noisy accumulation of evidence [<xref ref-type="bibr" rid="pcbi.1005405.ref018">18</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref020">20</xref>], have been shown to account for features of deliberation time as well as a number of violations of rational choice exhibited by human decision-making. In these models, decisions are generated by leaky integration of value information with random variability in each update step. A key assumption of these models is that the noise component is constant across different magnitudes of reward: this assumption has not previously been tested.</p>
<p>Here, we assessed the fidelity of value representation by first running participants on a typical reinforcement learning task in which they were trained to associate different options with particular reward magnitudes. At the end of the learning session, participants were subject to a surprise test in which they were required to directly report the reward they expected to receive on choosing each of the previously-experienced options. Because each participant was able to provide only a single estimate for each learned action-reward pair, a large number of participants were required to obtain interpretable response distributions; for this reason we ran the experiments using a crowdsourcing service.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<p>Participants completed a reinforcement learning task (Exp 1; <xref ref-type="fig" rid="pcbi.1005405.g001">Fig 1a</xref>) in which they selected from pairs of options, represented by fractal image tiles, and received rewards corresponding to the value of the chosen tile plus random noise. Over the course of 100 trials, participants learned associations between the tiles and expected rewards: the frequency with which the option with higher mean value was chosen increased from chance (50%) to reach a plateau at approximately 75% (<xref ref-type="fig" rid="pcbi.1005405.g002">Fig 2a</xref>).</p>
<fig id="pcbi.1005405.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005405.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Experimental task.</title>
<p>(a) During the learning session, participants chose from pairs of options represented by fractal tiles and were presented with rewards represented by coins that varied in size. (b) During an unexpected testing session, participants were instructed to report the expected reward associated with each tile by dragging a slider to change the size of a coin.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005405.g001" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005405.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005405.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Results from the learning session.</title>
<p>(a) Proportion of trials on which the higher-valued tile was chosen, as a function of trial number. Blue dashed line indicates chance performance. Red dashed line indicates the proportion predicted based on reports in the subsequent testing session. (b) Frequency with which tiles of each value were revealed during the learning session (black), and number of trials elapsed since the last presentation of a tile value at the end of the session (blue). (c) Proportion of trials (black symbols) on which the higher-valued tile was chosen, as a function of presented tile value, at the end of the session (final 25 trials). Every trial on which a tile of a specific value was presented as an option is included in each data point, therefore each trial contributes to two datapoints. Red symbols indicate the proportion predicted based on data from the testing session. (d) Proportion of trials on which the higher-valued tile was chosen, for each of the possible pairs of tiles (ordered by increasing value).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005405.g002" xlink:type="simple"/>
</fig>
<p>Because participants observed rewards associated only with tiles they selected, there was substantial variation in the frequency with which different tile values were presented (<xref ref-type="fig" rid="pcbi.1005405.g002">Fig 2b</xref>). The reward associated with the highest-valued tile was presented almost three times as frequently as the lowest-valued (8.2 ± 0.4 vs 21.3 ± 0.5; M ± SE), and at the end of the learning session on average more than seven times as many trials had elapsed since the last selection of the lowest-valued tile compared to the highest-valued (26.2 ± 1.8 vs 3.5 ± 0.3).</p>
<p>Despite these strong differences in the frequency and recency with which rewards were presented, by the end of the learning session the probability of choosing the correct tile varied only weakly between trials involving the highest- and lowest-valued tiles (<xref ref-type="fig" rid="pcbi.1005405.g002">Fig 2c</xref>, black symbols; mean difference between symmetrically-valued pairs of tiles [e.g. 0.875 vs 0.125]: 3.7% ± 1.5%). Instead, we observed that probability correct followed an approximately U-shaped function of value, with trials involving the extreme-valued tiles substantially more likely to be correct than those involving intermediate values (mean difference between extreme- and middle-valued tiles: 9.8% ± 1.7%).</p>
<p>While the superior performance for trials involving extreme-valued options could reflect differences in the representational fidelity of extreme versus intermediate values, it could also be artifactual, arising because trials involving an extreme-valued option on average have a larger disparity in value between the two options presented. To address this, we examined probability correct for pairs of tiles separated by the minimum relative value difference of 0.125. We again found that performance was significantly better for extreme-valued than intermediate-valued tiles (p &lt; 0.03), confirming that these performance differences are not due to differences in value disparity (no significant effects were observed for larger relative value differences, p &gt; 0.16; probability correct for each tile pair is shown in <xref ref-type="fig" rid="pcbi.1005405.g002">Fig 2d</xref>).</p>
<p>The learning session was followed by a surprise testing session (<xref ref-type="fig" rid="pcbi.1005405.g001">Fig 1b</xref>), in which participants were required to report the value they associated with each of the options they had been presented with during learning. <xref ref-type="fig" rid="pcbi.1005405.g003">Fig 3</xref> (grey bars) plots the distributions of response estimates for each mean reward value. Note that, because of the random variability in presented item values, the mean observed value of a tile during the learning session could differ from the tile’s expected value. However, these deviations were very small (mean absolute deviation &lt; 0.01) compared to the observed variability in reproduction (mean absolute error 0.16), indicating that internal noise was by far the dominant factor in determining response variability. We therefore do not consider these deviations further.</p>
<fig id="pcbi.1005405.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005405.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Value estimates.</title>
<p>Bars indicate distributions of value estimates reported in the testing session, for true tile values indicated by arrows (increasing top to bottom). Red curves are maximum likelihood fits of the mixture model illustrated in <xref ref-type="fig" rid="pcbi.1005405.g004">Fig 4</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005405.g003" xlink:type="simple"/>
</fig>
<p>Before we draw inferences on the basis of these distributions, we would like to ensure that they reflect the true variability in the representations of value used by participants to make their decisions in the learning task. This is particularly pertinant as the distributions are obtained across, rather than within, participants, with each participant contributing a single sample to each of the histograms in <xref ref-type="fig" rid="pcbi.1005405.g003">Fig 3</xref>. We therefore calculated the frequency with which participants would choose correctly on each trial if their internal representations of value matched their reports in the testing session (see <xref ref-type="sec" rid="sec004">Methods</xref>).</p>
<p>The red dashed line in <xref ref-type="fig" rid="pcbi.1005405.g002">Fig 2a</xref> shows the mean predicted proportion correct calculated on this basis. This value (76.6% ± 1.3%) was highly consistent with empirically-observed performance at the end of the learning session (last 25 trials: 76.4% ± 1.4%, p = 0.46). Red symbols in <xref ref-type="fig" rid="pcbi.1005405.g002">Fig 2c</xref> plot the predicted proportion correct as a function of tile value: empirical frequencies obtained over the last 25 learning trials were statistically indistinguishable from the predictions based on reported values in the testing session (all p &gt; 0.16). We conclude that the distributions of reported value estimates over participants accurately correspond to the actual value information used by participants in decision-making.</p>
<p>Consistent with results from the learning session, we found only very weak correlations between error on the report task and the frequency or recency with which a reward was presented during learning (frequency, mean <italic>r</italic> = −0.087, p = 0.002; recency, mean <italic>r</italic> = 0.058, p = 0.042).</p>
<p>To capture the key properties of the distributions shown in <xref ref-type="fig" rid="pcbi.1005405.g003">Fig 3</xref> we fit them with a mixture of two component distributions. One, corresponding to an imprecise report of the true value of a tile, was represented by a beta distribution centered on the true value with some bias (the beta distribution is a bell-shaped distribution similar to the normal but confined to the range 0–1); the other, corresponding to random guessing, by a normal distribution centered in the middle of the value range (we used a normal rather than a uniform distribution to capture any bias in guesses towards the center of the range; in the absence of such a bias, the normal component could approximate a uniform distribution to arbitrary exactness). The mixture model is illustrated in <xref ref-type="fig" rid="pcbi.1005405.g004">Fig 4</xref>.</p>
<fig id="pcbi.1005405.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005405.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Mixture model.</title>
<p>The model of value estimates consisted of a mixture of a beta distribution (blue), corresponding to imprecise recall of the target value, and a normal distribution (green), capturing guessing.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005405.g004" xlink:type="simple"/>
</fig>
<p>We tested three different mixture models, differing in whether the width of the beta distribution, the mixture proportion, or both could vary across different tile values. In the best fitting model, the mixture proportion was fixed, indicating that the probability of guessing did not vary with tile value; however the width of the beta distribution did vary, indicating that there were differences in how precisely the different options were represented (AICc: width-only −840.5, both −836.2, mixture-only −715.5; BIC: width-only −757.0, both −721.5, mixture-only −632.0). The fits of the best fitting model are plotted in red in <xref ref-type="fig" rid="pcbi.1005405.g003">Fig 3</xref>.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005405.g005">Fig 5a &amp; 5b</xref> plot the bias and variability, respectively, of the beta component of the best-fitting model as a function of option value. We observed significant biases towards lower values for intermediate reward values only (asterisks in <xref ref-type="fig" rid="pcbi.1005405.g005">Fig 5a</xref> indicate significance; we also observed a very small but statistically significant bias towards higher values for the highest-valued tile). Symmetrically-valued pairs of tiles (i.e. those on opposite sides of the middle tile value) had similar biases (0.875 vs 0.125: difference = 0.002, p &gt; 0.05; 0.75 vs 0.25: difference = 0.026, p &lt; 0.05; 0.625 vs 0.375: difference = 0.016, p &gt; 0.05).</p>
<fig id="pcbi.1005405.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005405.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Maximum likelihood model parameters.</title>
<p>(a) Bias of the fitted beta distribution mean relative to the true tile value. Asterisks indicate significant deviation from zero (* p &lt; 0.05; ** p &lt; 0.01). (b) Standard deviation of the fitted beta distribution.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005405.g005" xlink:type="simple"/>
</fig>
<p>Variability also depended strongly on tile value (<xref ref-type="fig" rid="pcbi.1005405.g005">Fig 5b</xref>): the standard deviation of responses around the correct tile value was approximately three times higher for the middle-valued tiles than for either of the extreme-valued tiles (0.15 vs {0.049, 0.050}, p &lt; 0.01). There were no significant differences in variability between symmetrically-valued pairs of tiles (all p &gt; 0.05).</p>
<p>An additional analysis confined to only those participants (89 in total) who demonstrated a strongly significant (p &lt; 0.01) correlation between estimated and true tile values, revealed very similar magnitudes of effect of tile value on bias and variability, indicating that these effects were not limited to observers with poor overall recall.</p>
<p>These results indicate that extreme-valued options are represented more precisely and with less bias than intermediate-valued options. This effect could reflect either the relative value of an option within the range of values experienced, or it could reflect the absolute value relative to the bounds on possible responses in the testing session. To disambiguate these two possibilities we ran a second experiment (Exp 2) in which only six tiles were presented (one fewer than in Exp 1). The excluded tile was either the lowest- or the highest-valued tile from Exp 1.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005405.g006">Fig 6a &amp; 6b</xref> illustrate the predictions of the two models for representational variability. If variability is determined by a tile value’s absolute position within the range of possible responses, the standard deviations of responses of participants who experienced all but the lowest-valued tile (<xref ref-type="fig" rid="pcbi.1005405.g006">Fig 6a</xref>, red) should exactly overlie those of participants who experienced all but the highest-valued tile (blue). In contrast, if variability is determined by the relative position within the range of experienced tile values, the two curves should be displaced along the x-axis by a difference of one tile value (<xref ref-type="fig" rid="pcbi.1005405.g006">Fig 6b</xref>). <xref ref-type="fig" rid="pcbi.1005405.g006">Fig 6c</xref> plots the observed data. The two curves do not overlap (significant difference at tile value 0.25, p &lt; 0.05), however a formal model comparison could not consistently distinguish between the two possibilities (AICc difference [relative − absolute]: 8.8 ± 15.9, p &gt; 0.05; BIC difference: 4.9 ± 15.9, p &gt; 0.05).</p>
<fig id="pcbi.1005405.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005405.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Absolute versus relative coding affecting variability.</title>
<p>(a) Predicted variability for a model in which variability is determined by the absolute value within the bounds [0, 1]. Blue curve indicates participants for whom the highest-valued tile was omitted, red the lowest-valued. The model predicts that the two curves will exactly overlap. (b) Predicted variability for a model in which variability is determined by the relative value within the range of all rewards experienced during learning. The model predicts that the two curves will be translated relative to each other. (c) Empirical standard deviations obtained in Exp 2.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005405.g006" xlink:type="simple"/>
</fig>
<p>
<xref ref-type="fig" rid="pcbi.1005405.g007">Fig 7</xref> presents results of an identical analysis for representational bias. Here, model comparison found strong evidence in favour of a relative coding of value representations (AICc difference [relative − absolute]: −43.2 ± 20.3, p &lt; 0.05; BIC difference: −47.1 ± 20.3, p &lt; 0.05)</p>
<fig id="pcbi.1005405.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005405.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Absolute versus relative coding affecting bias.</title>
<p>(a) Predicted bias for a model in which bias is determined by the absolute value within the bounds [0, 1]. Blue curve indicates participants for whom the highest-valued tile was omitted, red the lowest-valued. The model predicts that the two curves will exactly overlap. (b) Predicted bias for a model in which bias is determined by the relative value within the range of all rewards experienced during learning. The model predicts that the two curves will be translated relative to each other. (c) Empirical biases obtained in Exp 2.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005405.g007" xlink:type="simple"/>
</fig>
<p>As in Exp 1, we found minimal correlation between error on the report task and the frequency or recency of reward (frequency, mean <italic>r</italic> = −0.040, p = 0.071; recency, mean <italic>r</italic> = 0.042, p = 0.067).</p>
<p>Comparing the distributions of value estimates between the experiments with six and seven tiles revealed an overall increase in mean variability of the beta component with increasing number of tiles (<italic>σ</italic><sub><italic>B</italic></sub> = 0.088 vs 0.097, p &lt; 0.05) and an increase in guessing (<italic>α</italic> = 0.67 vs 0.58, p &lt; 0.05). There was no significant effect on the mean bias of the beta component (<italic>ε</italic> = −0.033 vs −0.043, p &gt; 0.05) nor the width of the normal (guessing) component (<italic>σ</italic><sub><italic>N</italic></sub> = 0.25 vs 0.26, p &gt; 0.05).</p>
</sec>
<sec id="sec003" sec-type="conclusions">
<title>Discussion</title>
<p>We examined the nature of internal representation of reward by following a standard reinforcement learning task with an unexpected test, in which participants directly reported the rewards they associated with previously-experienced choices. The results demonstrated a substantial advantage in the fidelity of representation for extreme values: both low and high value rewards were represented with lower variability and less bias than intermediate values. These differences in fidelity mapped onto the decisions participants made during learning, retrospectively predicting how accurately participants chose between the different options.</p>
<p>In our interactions with the world, we preferentially exploit options that we associate with the largest rewards. For this reason, our experience unequally samples the distribution of available rewards, favoring higher values. This effect was apparent in our reinforcement learning task: although the lowest and highest rewards were made available on equal numbers of trials, the frequency with which participants were exposed to the highest rewards was many times that of the lowest. Remarkably, this oversampling of high rewards had negligible impact on the fidelity with which reward values were maintained: the lowest values were represented with the same bias and variability as the highest. This effect on action-reward associations differs dramatically from that observed for memory of other stimuli, e.g. word lists, where the accuracy with which associations are recalled depends strongly on both the frequency and recency of presentation [<xref ref-type="bibr" rid="pcbi.1005405.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005405.ref022">22</xref>]. A future study could test the effects of presenting both chosen and unchosen tile values on each trial: given the absence of frequency and recency effects in the present study, we predict that this would have minimal impact on response fidelity.</p>
<p>Theoretically, differences in the fidelity of reported value representations could be determined by a reward’s relative position in the range of experienced values, or they could depend on the reward’s absolute position on the scale of permitted responses. I.e., the more accurate reproduction of the highest reward values could arise because the reward is the highest of those experienced during learning, or because the reward is close to the edge of the response range. The absolute-coding hypothesis makes the prediction that, if one of the extreme values in the learning task is omitted, fidelity of the remaining values will not depend on which value was omitted, as this does not change their position on the absolute scale of responses. The relative-coding hypothesis makes the opposite prediction, because omitting an extreme value changes the relative position of the other values on the scale of experienced values. We performed this experiment: a model comparison based on report variability did not clearly disambiguate the two hypotheses, suggesting both may play a role, whereas a model comparison based on report bias strongly favoured the relative-coding hypothesis.</p>
<p>An additional consideration also supports the relative-coding hypothesis: the distributions of value estimates obtained by direct report very accurately reproduced performance on the learning task, indicating that the fidelity of reproduction faithfully reflected fidelity of the representations used to make choices in the preceding task. Critically, at the time these choices were made, participants had no knowledge or experience of the report task. This strongly argues against any specific effect of the response space in generating our results. We conclude that it is the value relative to the range of values experienced during learning that most strongly determines fidelity. This finding is consistent with observations of context-dependence in decision-making [<xref ref-type="bibr" rid="pcbi.1005405.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1005405.ref024">24</xref>] and relative coding in neural representations of value [<xref ref-type="bibr" rid="pcbi.1005405.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref027">27</xref>], which may be a consequence of divisive normalization [<xref ref-type="bibr" rid="pcbi.1005405.ref028">28</xref>].</p>
<p>While we have focused on the fidelity with which value is represented, a recent study [<xref ref-type="bibr" rid="pcbi.1005405.ref029">29</xref>] has obtained converging results by examining the salience of reward memories. This study presented participants with options that led with equal frequency to an extreme or an intermediate reward. On a subsequent memory test, participants were asked to report which outcome came most readily to mind when presented with each option in turn. The experimenters observed a strong bias towards reporting the extreme value over the intermediate value associated with each option. Participants also overestimated the frequency with which the extreme value was awarded in comparison with the intermediate value.</p>
<p>Recent advances in our understanding of working memory have focused on the concept of a limited memory resource that determines how precisely information is maintained [<xref ref-type="bibr" rid="pcbi.1005405.ref030">30</xref>]. Two observations have led to this characterization: first, the fidelity of representation of simple visual elements, such as orientations, declines monotonically with increasing number of elements in memory [<xref ref-type="bibr" rid="pcbi.1005405.ref031">31</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref033">33</xref>]; second, differences in the salience or goal relevance of elements results in enhanced fidelity for high priority elements and a consequent decrease in fidelity for those of lower priority [<xref ref-type="bibr" rid="pcbi.1005405.ref034">34</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref036">36</xref>]. The present results pertaining to the internal representation of value may be best understood within a similar framework. Thus, during learning, information regarding action-reward associations accumulates, increasing the fidelity of representation until an upper bound is reached resulting from a resource limit. The fidelity with which reward values are maintained at this limit may be determined by their motivational salience, favoring accurate representation of the lowest and highest values over motivationally-neutral intermediate values.</p>
<p>If fidelity is determined by a limit on available representational resources, rather than limited experience with each action-reward pair, this would account for the absence of frequency and recency effects. Further evidence consistent with a resource account comes from a comparison between learning with six and seven different action-reward pairs. The fidelity of value reproduction for all pairs was enhanced when the total number reduced, as a consequence of a decrease in both variability and guessing. Although the two conditions also differed in the frequency and recency with which the different rewards were presented, the very weak correlations between these factors and response error suggest they are unlikely to have contributed substantially to the difference between conditions. Nonetheless, the present study was not designed to test a resource hypothesis for reward representation, and this proposal, and the link to working memory, remain speculative at this time.</p>
<p>Consideration of how value is represented in cortical spiking activity provides an alternative to the motivational-salience account of the representational advantage for extreme values. In prefrontal cortex, reward-coding neurons display two opposing patterns of activity: roughly half of neurons increase their firing linearly with increasing value, whereas the other half decrease their firing [<xref ref-type="bibr" rid="pcbi.1005405.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1005405.ref038">38</xref>]. Spiking activity in cortex is approximately Poisson, i.e. standard deviation increases with the square root of the mean: hence higher firing rates encode information with greater fidelity [<xref ref-type="bibr" rid="pcbi.1005405.ref039">39</xref>]. We propose that, in such an opponent-coding system, the highest and lowest values, which elicit maximum firing in half the neural population, can be decoded with greater precision than intermediate values, which produce an intermediate firing rate in the whole population. While this would provide a parsimonious explanation for the differences in precision observed in our experiments, it should be noted that opponent-coding schemes are not universal in the brain: neither subcortical nor parietal reward-sensitive neurons display inverse relationships between firing rate and value [<xref ref-type="bibr" rid="pcbi.1005405.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005405.ref040">40</xref>].</p>
<p>With respect to the increased underestimation bias observed for intermediate values, we speculate this may have a Bayesian explanation: greater uncertainty in the internal representation of these values leads to a greater bias towards prior expectations. This would imply that participants’ prior belief is that individual actions will result in small rewards. This could be a fixed prior, similar to the low-velocity prior evident in perception [<xref ref-type="bibr" rid="pcbi.1005405.ref041">41</xref>], or it could depend on details of how a participant’s expectations are set up by the instructions and study design.</p>
<p>One caveat to our conclusions is that they are based on learning of action-reward associations on a short timescale, on the order of tens of minutes. While this is typical of laboratory studies of human reinforcement learning (e.g. [<xref ref-type="bibr" rid="pcbi.1005405.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1005405.ref042">42</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref044">44</xref>]), under ecological conditions we often make decisions based on associations learned over much longer periods, even years. Future research will examine whether the observations on fidelity presented here extend to longer timescales of learning. Another consideration is that we have examined only the representation of positive rewards; future work could investigate the fidelity with which behavioral costs are represented. Based on the success of the relative-coding hypothesis (Exp 2), we predict that if the range of experienced option values extended from negative to positive, fidelity would increase with absolute value; however, this will need to be confirmed by future experiments.</p>
<p>We found that the distribution of reported reward values was well-described by a mixture of two-components: one centered on the target value with some bias and variability, the other independent of the target but having some bias towards the center of the value range. While we have described the latter distribution as due to “guessing”, it may not be the case that these responses are purely random. Based on findings in the psychophysics and working memory literature, it is probable that some of these responses actually reflect so-called “swap” errors, in which a participant incorrectly responds with the value corresponding to a tile other than the one they are cued to report (e.g. [<xref ref-type="bibr" rid="pcbi.1005405.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1005405.ref046">46</xref>]). Assessments of the frequency of guessing will also depend on the choice of distribution for the non-guessing component: we chose a beta distribution as it is a normal-like distribution in common use with support on the range zero to one. In conjunction with a normally-distributed guessing component, this distribution proved qualitatively to be a good fit to data, however we do not rule out the possibility that the true distribution of “on-target” responses differs from the beta, e.g. by virtue of being long-tailed [<xref ref-type="bibr" rid="pcbi.1005405.ref047">47</xref>].</p>
<p>Established models of reinforcement learning [<xref ref-type="bibr" rid="pcbi.1005405.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1005405.ref017">17</xref>] do not typically consider the possibility of bias or variability in value representation. Where noise enters into the models at all it is typically at the decision stage, for example as a softmax decision rule [<xref ref-type="bibr" rid="pcbi.1005405.ref004">4</xref>]. In contrast, the present results suggest that a major contribution to the stochasticity in decision-making is due to variability in the internal representation of value, rather than in its evaluation. Taking into account the fidelity of reward representation, and in particular the biases favoring extreme values, will be critical for developing a fuller understanding of reward-based learning.</p>
</sec>
<sec id="sec004" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec005">
<title>Ethics statement</title>
<p>All participants gave informed consent, in accordance with the Declaration of Helsinki. The study was approved by the Cambridge Psychology Research Ethics Committee.</p>
</sec>
<sec id="sec006">
<title>Participants</title>
<p>Six hundred participants were recruited and run using Amazon Mechanical Turk (<ext-link ext-link-type="uri" xlink:href="https://www.mturk.com" xlink:type="simple">https://www.mturk.com</ext-link>). They were paid $0.50 for their time plus a bonus determined by rewards accumulated during the task (typically in the range $0.50 to $1). Participants completed the experimental tasks on their own computers or laptops; touchscreen devices were automatically excluded. Participants completed a demographic survey, reporting their sex, age, location, education, current illnesses and any vision problems. Twenty-six participants were subsequently excluded from analysis because they reported problems with their vision, or their age fell outside the range 18–60.</p>
</sec>
<sec id="sec007">
<title>Experiment 1</title>
<p>Two hundred participants took part in Exp 1. The experiment was divided into two parts: in the learning session, participants made choices between pairs of options (“tiles”) and received rewards. In the subsequent testing session, participants reported the reward value they associated with each option. The learning session was introduced by a short tutorial which did not mention the existence of the testing session.</p>
<p>The learning session consisted of 100 trials. On each trial, two tiles (fractal images) were presented (<xref ref-type="fig" rid="pcbi.1005405.g001">Fig 1a</xref>, top) and the participant selected one with a mouse click. The selected tile moved to reveal a reward (<xref ref-type="fig" rid="pcbi.1005405.g001">Fig 1a</xref>, bottom), represented by a coin: the diameter of the coin indicated the reward value, with larger coins corresponding to more reward. Participants were instructed to collect as much reward as possible, which would be converted into a bonus payment at the end of the experiment. A running total of the reward accumulated so far was present at all times in the upper-right of the screen.</p>
<p>The two tiles presented on each trial were selected randomly without replacement from a set of seven. Each tile was associated with a different mean reward value, evenly-spaced in the range 0.125–0.875, where a reward of 0 was indicated by no coin and a reward of 1 was indicated by the largest coin. The actual reward value obtained on each trial was drawn from a beta distribution with mean corresponding to the selected tile’s value and standard deviation 0.035. The assignment of fractal images to mean reward values was randomized for each participant.</p>
<p>In the testing session, which followed immediately after the end of the learning session, each of the seven tiles used in the preceding session was presented one at a time (<xref ref-type="fig" rid="pcbi.1005405.g001">Fig 1b</xref>) and participants were instructed to report the reward they expected to receive for choosing that tile, by dragging a slider which changed the size of a coin. Once they were satisfied that they had adjusted the coin size to match the expected reward they clicked a button marked “accept”.</p>
<p>After the testing session, participants were presented with feedback of the correct reward values associated with each tile, and told how much bonus they had earned. Participants could take as long as they wanted over each part of the experiment, but the whole task typically took about 15 minutes to complete.</p>
</sec>
<sec id="sec008">
<title>Experiment 2</title>
<p>Exp 2 was identical to Exp 1, except that only six tiles were used. The mean reward values for the six tiles were chosen by excluding either the lowest (Exp 2a; 200 participants) or highest (Exp 2b; 200 participants) value tile from the seven tiles used in Exp 1.</p>
</sec>
<sec id="sec009">
<title>Analysis</title>
<p>We defined a learning trial as correct if the tile chosen was the one with the higher mean value. To assess whether the distribution of value estimates obtained in the testing session matched performance on the learning task, we calculated for each subject the performance we would expect if their choices were based on their reported value estimates, i.e. if the response for each possible pair of tile values was determined by which tile had the higher value estimate in the testing session. These predicted frequencies were compared to the actual frequencies of correct trials at the end of the learning session (final 25 trials).</p>
<p>The distribution of value estimates <inline-formula id="pcbi.1005405.e001"><alternatives><graphic id="pcbi.1005405.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005405.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> obtained across participants in the testing session for each mean tile value <italic>x</italic> was fit with a mixture of a beta distribution centered on the true mean value with bias <italic>ε</italic> and standard deviation <italic>σ</italic><sub><italic>B</italic></sub>, and a normal distribution (intended to capture guessing) centered in the middle of the range of values (0.5) with standard deviation <italic>σ</italic><sub><italic>N</italic></sub>. The mixture parameter <italic>α</italic> corresponded to the proportion of the beta distribution in the mixture. Formally,
<disp-formula id="pcbi.1005405.e002"><alternatives><graphic id="pcbi.1005405.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005405.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>α</mml:mi> <mml:mi>β</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>;</mml:mo> <mml:mi>x</mml:mi> <mml:mo>+</mml:mo> <mml:mi>ε</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>B</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>α</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>ϕ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi>N</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>β</italic>(<italic>x</italic>; <italic>μ</italic>, <italic>σ</italic>) is the probability density function of the beta distribution with mean <italic>μ</italic> and standard deviation <italic>σ</italic>, and <italic>ϕ</italic>(<italic>x</italic>; <italic>μ</italic>, <italic>σ</italic>) is the probability density function of the normal distribution with mean <italic>μ</italic> and standard deviation <italic>σ</italic>. Note that the beta distribution is commonly parameterized by two shape parameters, <italic>a</italic> and <italic>b</italic>: these can be obtained from the mean and standard deviation as <italic>a</italic> = (<italic>μ</italic><sup>2</sup> − <italic>μ</italic><sup>3</sup>)/<italic>σ</italic><sup>2</sup> − <italic>μ</italic> and <italic>b</italic> = <italic>a</italic>(1/<italic>μ</italic> − 1).</p>
<p>Three variants of the model described by <xref ref-type="disp-formula" rid="pcbi.1005405.e002">Eq 1</xref> were tested. In one, the standard deviation of the beta component <italic>σ</italic><sub><italic>B</italic></sub> was allowed to vary with the mean tile value, while a single value of the mixture parameter <italic>α</italic> was used for all tile values. In the second, a single value of <italic>σ</italic><sub><italic>B</italic></sub> was used but <italic>α</italic> was allowed to vary. In the third, both <italic>σ</italic><sub><italic>B</italic></sub> and <italic>α</italic> varied with mean tile value. In all cases, the bias parameter <italic>ϵ</italic> was allowed to vary with mean tile value.</p>
<p>Maximum likelihood model parameters were obtained by the Nelder-Mead simplex method (<italic>fminsearch</italic> in MATLAB). Models were compared using the Akaike Information Criterion with a correction for finite sample sizes (AICc; [<xref ref-type="bibr" rid="pcbi.1005405.ref048">48</xref>]) and the Bayesian Information Criterion (BIC). Standard errors and confidence intervals on model parameters and differences between model parameters were calculated by bootstrapping: 1000 resampled datasets were generated by random sampling with replacement from the original dataset, and models fit to the resampled data to obtain a sampling distribution of parameters. Statistically significant differences between model parameters were reported when the bootstrap 95% confidence interval did not encompass zero.</p>
</sec>
</sec>
</body>
<back>
<ack>
<p>We thank Sebastian Schneegans for comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005405.ref001">
<label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Stevens</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Krebs</surname> <given-names>JR</given-names></name>. <chapter-title>Foraging theory</chapter-title>. <source>Monographs in Behavior and Ecology</source>, <publisher-name>Princeton University Press</publisher-name>, <publisher-loc>New Jersey</publisher-loc>. <year>1986</year>;.</mixed-citation>
</ref>
<ref id="pcbi.1005405.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>. <article-title>Prospect theory: An analysis of decision under risk</article-title>. <source>Econometrica: Journal of the econometric society</source>. <year>1979</year>; p. <fpage>263</fpage>–<lpage>291</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/1914185" xlink:type="simple">10.2307/1914185</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rushworth</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>. <article-title>Choice, uncertainty and value in prefrontal and cingulate cortex</article-title>. <source>Nature neuroscience</source>. <year>2008</year>;<volume>11</volume>(<issue>4</issue>):<fpage>389</fpage>–<lpage>397</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn2066" xlink:type="simple">10.1038/nn2066</ext-link></comment> <object-id pub-id-type="pmid">18368045</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Cortical substrates for exploratory decisions in humans</article-title>. <source>Nature</source>. <year>2006</year>;<volume>441</volume>(<issue>7095</issue>):<fpage>876</fpage>–<lpage>879</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature04766" xlink:type="simple">10.1038/nature04766</ext-link></comment> <object-id pub-id-type="pmid">16778890</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kennerley</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Dahmubed</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Lara</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Wallis</surname> <given-names>JD</given-names></name>. <article-title>Neurons in the Frontal Lobe Encode the Value of Multiple Decision Variables</article-title>. <source>Journal of Cognitive Neuroscience</source>. <year>2008</year>;<volume>21</volume>(<issue>6</issue>):<fpage>1162</fpage>–<lpage>1178</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn.2009.21100" xlink:type="simple">10.1162/jocn.2009.21100</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Louie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Efficient coding and the neural representation of value</article-title>. <source>Annals of the New York Academy of Sciences</source>. <year>2012</year>;<volume>1251</volume>(<issue>1</issue>):<fpage>13</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1749-6632.2012.06496.x" xlink:type="simple">10.1111/j.1749-6632.2012.06496.x</ext-link></comment> <object-id pub-id-type="pmid">22694213</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Assad</surname> <given-names>JA</given-names></name>. <article-title>Neurons in the orbitofrontal cortex encode economic value</article-title>. <source>Nature</source>. <year>2006</year>;<volume>441</volume>(<issue>7090</issue>):<fpage>223</fpage>–<lpage>226</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature04676" xlink:type="simple">10.1038/nature04676</ext-link></comment> <object-id pub-id-type="pmid">16633341</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tremblay</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Relative reward preference in primate orbitofrontal cortex</article-title>. <source>Nature</source>. <year>1999</year>;<volume>398</volume>(<issue>6729</issue>):<fpage>704</fpage>–<lpage>708</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/19525" xlink:type="simple">10.1038/19525</ext-link></comment> <object-id pub-id-type="pmid">10227292</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bayer</surname> <given-names>HM</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Midbrain dopamine neurons encode a quantitative reward prediction error signal</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>47</volume>(<issue>1</issue>):<fpage>129</fpage>–<lpage>141</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2005.05.020" xlink:type="simple">10.1016/j.neuron.2005.05.020</ext-link></comment> <object-id pub-id-type="pmid">15996553</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ljungberg</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Apicella</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Responses of monkey dopamine neurons during learning of behavioral reactions</article-title>. <source>Journal of neurophysiology</source>. <year>1992</year>;<volume>67</volume>(<issue>1</issue>):<fpage>145</fpage>–<lpage>163</lpage>. <object-id pub-id-type="pmid">1552316</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Predictive reward signal of dopamine neurons</article-title>. <source>Journal of neurophysiology</source>. <year>1998</year>;<volume>80</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>27</lpage>. <object-id pub-id-type="pmid">9658025</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>. <year>1997</year>;<volume>275</volume>(<issue>5306</issue>):<fpage>1593</fpage>–<lpage>1599</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.275.5306.1593" xlink:type="simple">10.1126/science.275.5306.1593</ext-link></comment> <object-id pub-id-type="pmid">9054347</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Critchley</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Temporal difference models and reward-related learning in the human brain</article-title>. <source>Neuron</source>. <year>2003</year>;<volume>38</volume>(<issue>2</issue>):<fpage>329</fpage>–<lpage>337</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(03)00169-7" xlink:type="simple">10.1016/S0896-6273(03)00169-7</ext-link></comment> <object-id pub-id-type="pmid">12718865</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Faisal</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Selen</surname> <given-names>LPJ</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>Noise in the nervous system</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2008</year>;<volume>9</volume>(<issue>4</issue>):<fpage>292</fpage>–<lpage>303</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2258" xlink:type="simple">10.1038/nrn2258</ext-link></comment> <object-id pub-id-type="pmid">18319728</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rescorla</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AR</given-names></name>. <article-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</article-title>. <source>Classical conditioning II: Current research and theory</source>. <year>1972</year>;<volume>2</volume>:<fpage>64</fpage>–<lpage>99</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005405.ref016">
<label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <chapter-title>Time-derivative models of Pavlovian reinforcement</chapter-title>. In: <name name-style="western"><surname>Gabriel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>J</given-names></name>, editors. <source>Learning and computational neuroscience: Foundations of adaptive networks</source>. <publisher-loc>Cambridge, MA, US</publisher-loc>: <publisher-name>The MIT Press</publisher-name>; <year>1990</year>. p. <fpage>497</fpage>–<lpage>537</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005405.ref017">
<label>17</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <source>Reinforcement learning: An introduction</source>. <volume>vol. 1</volume>. <publisher-name>MIT press</publisher-name> <publisher-loc>Cambridge</publisher-loc>; <year>1998</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005405.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Busemeyer</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Townsend</surname> <given-names>JT</given-names></name>. <article-title>Decision field theory: a dynamic-cognitive approach to decision making in an uncertain environment</article-title>. <source>Psychological review</source>. <year>1993</year>;<volume>100</volume>(<issue>3</issue>):<fpage>432</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.100.3.432" xlink:type="simple">10.1037/0033-295X.100.3.432</ext-link></comment> <object-id pub-id-type="pmid">8356185</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tsetsos</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Moran</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Moreland</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Usher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>. <article-title>Economic irrationality is optimal during noisy decision making</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2016</year>;<volume>113</volume>(<issue>11</issue>):<fpage>3102</fpage>–<lpage>3107</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1519157113" xlink:type="simple">10.1073/pnas.1519157113</ext-link></comment> <object-id pub-id-type="pmid">26929353</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tsetsos</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Usher</surname> <given-names>M</given-names></name>. <article-title>Salience driven value integration explains decision biases and preference reversal</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2012</year>;<volume>109</volume>(<issue>24</issue>):<fpage>9659</fpage>–<lpage>9664</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1119569109" xlink:type="simple">10.1073/pnas.1119569109</ext-link></comment> <object-id pub-id-type="pmid">22635271</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Murdock</surname> <given-names>BB</given-names> <suffix>Jr</suffix></name>. <article-title>The serial position effect of free recall</article-title>. <source>Journal of experimental psychology</source>. <year>1962</year>;<volume>64</volume>(<issue>5</issue>):<fpage>482</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/h0045106" xlink:type="simple">10.1037/h0045106</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hintzman</surname> <given-names>DL</given-names></name>. <article-title>Repetition and memory</article-title>. <source>Psychology of learning and motivation</source>. <year>1976</year>;<volume>10</volume>:<fpage>47</fpage>–<lpage>91</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0079-7421(08)60464-8" xlink:type="simple">10.1016/S0079-7421(08)60464-8</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Soltani</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>De Martino</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Camerer</surname> <given-names>C</given-names></name>. <article-title>A range-normalization model of context-dependent choice: a new model and evidence</article-title>. <source>PLoS Computational Biology</source>. <year>2012</year>;<volume>8</volume>(<issue>7</issue>):<fpage>e1002607</fpage>–<lpage>e1002607</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002607" xlink:type="simple">10.1371/journal.pcbi.1002607</ext-link></comment> <object-id pub-id-type="pmid">22829761</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Louie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Khaw</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Normalization is a general neural mechanism for context-dependent decision making</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2013</year>;<volume>110</volume>(<issue>15</issue>):<fpage>6139</fpage>–<lpage>6144</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1217854110" xlink:type="simple">10.1073/pnas.1217854110</ext-link></comment> <object-id pub-id-type="pmid">23530203</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name>. <article-title>Range-adapting representation of economic value in the orbitofrontal cortex</article-title>. <source>The Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>44</issue>):<fpage>14004</fpage>–<lpage>14014</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3751-09.2009" xlink:type="simple">10.1523/JNEUROSCI.3751-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19890010</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tobler</surname> <given-names>PN</given-names></name>, <name name-style="western"><surname>Fiorillo</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Adaptive coding of reward value by dopamine neurons</article-title>. <source>Science</source>. <year>2005</year>;<volume>307</volume>(<issue>5715</issue>):<fpage>1642</fpage>–<lpage>1645</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1105370" xlink:type="simple">10.1126/science.1105370</ext-link></comment> <object-id pub-id-type="pmid">15761155</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rangel</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Clithero</surname> <given-names>JA</given-names></name>. <article-title>Value normalization in decision making: theory and evidence</article-title>. <source>Current opinion in neurobiology</source>. <year>2012</year>;<volume>22</volume>(<issue>6</issue>):<fpage>970</fpage>–<lpage>981</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2012.07.011" xlink:type="simple">10.1016/j.conb.2012.07.011</ext-link></comment> <object-id pub-id-type="pmid">22939568</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Louie</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Grattan</surname> <given-names>LE</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Reward Value-Based Gain Control: Divisive Normalization in Parietal Cortex</article-title>. <source>The Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>29</issue>):<fpage>10627</fpage>–<lpage>10639</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1237-11.2011" xlink:type="simple">10.1523/JNEUROSCI.1237-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21775606</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Madan</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Ludvig</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Spetch</surname> <given-names>ML</given-names></name>. <article-title>Remembering the best and worst of times: Memories for extreme outcomes bias risky decisions</article-title>. <source>Psychonomic bulletin &amp; review</source>. <year>2014</year>;<volume>21</volume>(<issue>3</issue>):<fpage>629</fpage>–<lpage>636</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3758/s13423-013-0542-9" xlink:type="simple">10.3758/s13423-013-0542-9</ext-link></comment> <object-id pub-id-type="pmid">24189991</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Husain</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>. <article-title>Changing concepts of working memory</article-title>. <source>Nature Neuroscience</source>. <year>2014</year>;<volume>17</volume>(<issue>3</issue>):<fpage>347</fpage>–<lpage>356</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3655" xlink:type="simple">10.1038/nn.3655</ext-link></comment> <object-id pub-id-type="pmid">24569831</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Palmer</surname> <given-names>J</given-names></name>. <article-title>Attentional limits on the perception and memory of visual information</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>. <year>1990</year>;<volume>16</volume>(<issue>2</issue>):<fpage>332</fpage>–<lpage>350</lpage>. <object-id pub-id-type="pmid">2142203</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilken</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>A detection theory account of change detection</article-title>. <source>Journal of Vision</source>. <year>2004</year>;<volume>4</volume>(<issue>12</issue>):<fpage>1120</fpage>–<lpage>1135</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/4.12.11" xlink:type="simple">10.1167/4.12.11</ext-link></comment> <object-id pub-id-type="pmid">15669916</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Husain</surname> <given-names>M</given-names></name>. <article-title>Dynamic Shifts of Limited Working Memory Resources in Human Vision</article-title>. <source>Science</source>. <year>2008</year>;<volume>321</volume>(<issue>5890</issue>):<fpage>851</fpage>–<lpage>854</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1158023" xlink:type="simple">10.1126/science.1158023</ext-link></comment> <object-id pub-id-type="pmid">18687968</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Gorgoraptis</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Wee</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Marshall</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Husain</surname> <given-names>M</given-names></name>. <article-title>Temporal dynamics of encoding, storage, and reallocation of visual working memory</article-title>. <source>Journal of Vision</source>. <year>2011</year>;<volume>11</volume>(<issue>10</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/11.10.6" xlink:type="simple">10.1167/11.10.6</ext-link></comment> <object-id pub-id-type="pmid">21911739</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gorgoraptis</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Catalao</surname> <given-names>RFG</given-names></name>, <name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Husain</surname> <given-names>M</given-names></name>. <article-title>Dynamic updating of working memory resources for visual objects</article-title>. <source>Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>23</issue>):<fpage>8502</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.0208-11.2011" xlink:type="simple">10.1523/JNEUROSCI.0208-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21653854</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lara</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Wallis</surname> <given-names>JD</given-names></name>. <article-title>Capacity and Precision in an Animal Model of Visual Short-Term Memory</article-title>. <source>Journal of Vision</source>. <year>2012</year>;<volume>12</volume>(<issue>3</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/12.3.13" xlink:type="simple">10.1167/12.3.13</ext-link></comment> <object-id pub-id-type="pmid">22419756</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kennerley</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Wallis</surname> <given-names>JD</given-names></name>. <article-title>Encoding of Reward and Space During a Working Memory Task in the Orbitofrontal Cortex and Anterior Cingulate Sulcus</article-title>. <source>Journal of Neurophysiology</source>. <year>2009</year>;<volume>102</volume>(<issue>6</issue>):<fpage>3352</fpage>–<lpage>3364</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00273.2009" xlink:type="simple">10.1152/jn.00273.2009</ext-link></comment> <object-id pub-id-type="pmid">19776363</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kobayashi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>de Carvalho</surname> <given-names>OP</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Adaptation of reward sensitivity in orbitofrontal neurons</article-title>. <source>The Journal of Neuroscience</source>. <year>2010</year>;<volume>30</volume>(<issue>2</issue>):<fpage>534</fpage>–<lpage>544</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4009-09.2010" xlink:type="simple">10.1523/JNEUROSCI.4009-09.2010</ext-link></comment> <object-id pub-id-type="pmid">20071516</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tolhurst</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Movshon</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Dean</surname> <given-names>AF</given-names></name>. <article-title>The statistical reliability of signals in single neurons in cat and monkey visual cortex</article-title>. <source>Vision Research</source>. <year>1983</year>;<volume>23</volume>(<issue>8</issue>):<fpage>775</fpage>–<lpage>785</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0042-6989(83)90200-6" xlink:type="simple">10.1016/0042-6989(83)90200-6</ext-link></comment> <object-id pub-id-type="pmid">6623937</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Platt</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Neural correlates of decision variables in parietal cortex</article-title>. <source>Nature</source>. <year>1999</year>;<volume>400</volume>(<issue>6741</issue>):<fpage>233</fpage>–<lpage>238</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/22268" xlink:type="simple">10.1038/22268</ext-link></comment> <object-id pub-id-type="pmid">10421364</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Goldreich</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>J</given-names></name>. <article-title>Prediction, postdiction, and perceptual length contraction: a bayesian low-speed prior captures the cutaneous rabbit and related illusions</article-title>. <source>Frontiers in psychology</source>. <year>2012</year>;<volume>4</volume>:<fpage>221</fpage>–<lpage>221</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005405.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Flandin</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Frith</surname> <given-names>CD</given-names></name>. <article-title>Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title>. <source>Nature</source>. <year>2006</year>;<volume>442</volume>(<issue>7106</issue>):<fpage>1042</fpage>–<lpage>1045</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature05051" xlink:type="simple">10.1038/nature05051</ext-link></comment> <object-id pub-id-type="pmid">16929307</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shiner</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Seymour</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wunderlich</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Hill</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Bhatia</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Dopamine and performance in a reinforcement learning task: evidence from Parkinson’s disease</article-title>. <source>Brain: A Journal of Neurology</source>. <year>2012</year>;<volume>135</volume>(<issue>6</issue>):<fpage>1871</fpage>–<lpage>1883</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/brain/aws083" xlink:type="simple">10.1093/brain/aws083</ext-link></comment> <object-id pub-id-type="pmid">22508958</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MFS</given-names></name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nature Neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>9</issue>):<fpage>1214</fpage>–<lpage>1221</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1954" xlink:type="simple">10.1038/nn1954</ext-link></comment> <object-id pub-id-type="pmid">17676057</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Treisman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>H</given-names></name>. <article-title>Illusory conjunctions in the perception of objects</article-title>. <source>Cognitive Psychology</source>. <year>1982</year>;<volume>14</volume>(<issue>1</issue>):<fpage>107</fpage>–<lpage>141</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0010-0285(82)90006-8" xlink:type="simple">10.1016/0010-0285(82)90006-8</ext-link></comment> <object-id pub-id-type="pmid">7053925</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Catalao</surname> <given-names>RFG</given-names></name>, <name name-style="western"><surname>Husain</surname> <given-names>M</given-names></name>. <article-title>The precision of visual working memory is set by allocation of a shared resource</article-title>. <source>Journal of Vision</source>. <year>2009</year>;<volume>9</volume>(<issue>10</issue>):<fpage>7</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/9.10.7" xlink:type="simple">10.1167/9.10.7</ext-link></comment> <object-id pub-id-type="pmid">19810788</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bays</surname> <given-names>PM</given-names></name>. <article-title>Noise in Neural Populations Accounts for Errors in Working Memory</article-title>. <source>Journal of Neuroscience</source>. <year>2014</year>;<volume>34</volume>(<issue>10</issue>):<fpage>3632</fpage>–<lpage>3645</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3204-13.2014" xlink:type="simple">10.1523/JNEUROSCI.3204-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24599462</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005405.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hurvich</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Tsai</surname> <given-names>CL</given-names></name>. <article-title>Regression and time series model selection in small samples</article-title>. <source>Biometrika</source>. <year>1989</year>;<volume>76</volume>(<issue>2</issue>):<fpage>297</fpage>–<lpage>307</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biomet/76.2.297" xlink:type="simple">10.1093/biomet/76.2.297</ext-link></comment></mixed-citation>
</ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
   <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
         <publisher-name>Public Library of Science</publisher-name>
         <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
   <article-meta><article-id pub-id-type="publisher-id">10-PLCB-RA-1978R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000999</article-id><article-categories>
         <subj-group subj-group-type="heading">
            <subject>Research Article</subject>
         </subj-group>
         <subj-group subj-group-type="Discipline">
<subject>Biotechnology/Bioengineering</subject>
<subject>Computational Biology/Computational Neuroscience</subject>
<subject>Mathematics/Statistics</subject>
<subject>Neuroscience/Sensory Systems</subject>
<subject>Physiology/Sensory Systems</subject>
<subject>Neuroscience/Psychology</subject>
<subject>Computer Science/Natural and Synthetic Vision</subject>
         </subj-group>
      </article-categories><title-group><article-title>On the Inverse Problem of Binocular 3D Motion Perception</article-title><alt-title alt-title-type="running-head">Inverse Problem of 3D Motion</alt-title></title-group><contrib-group>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Lages</surname><given-names>Martin</given-names></name>
            <xref ref-type="aff" rid="aff1"/>
            <xref ref-type="corresp" rid="cor1"><sup>*</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Heron</surname><given-names>Suzanne</given-names></name>
            <xref ref-type="aff" rid="aff1"/>
         </contrib>
      </contrib-group><aff id="aff1">
         <addr-line>School of Psychology, University of Glasgow, Glasgow, Scotland</addr-line>
      </aff><contrib-group>
         <contrib contrib-type="editor" xlink:type="simple">
            <name name-style="western"><surname>Maloney</surname><given-names>Laurence T.</given-names></name>
            <role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib>
      </contrib-group><aff id="edit1">New York University, United States of America</aff><author-notes>
         <corresp id="cor1">* E-mail: <email xlink:type="simple">m.lages@psy.gla.ac.uk</email></corresp>
         <fn fn-type="con">
            <p>Conceived and designed the experiments: ML SH. Contributed reagents/materials/analysis tools: ML SH. Wrote the paper: ML SH.</p>
         </fn>
      <fn fn-type="conflict">
         <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
         <month>11</month>
         <year>2010</year>
      </pub-date><pub-date pub-type="epub">
         <day>18</day>
         <month>11</month>
         <year>2010</year>
      </pub-date><volume>6</volume><issue>11</issue><elocation-id>e1000999</elocation-id><history>
         <date date-type="received">
            <day>23</day>
            <month>3</month>
            <year>2010</year>
         </date>
         <date date-type="accepted">
            <day>14</day>
            <month>10</month>
            <year>2010</year>
         </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Lages, Heron</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
         <p>It is shown that existing processing schemes of 3D motion perception such as interocular velocity difference, changing disparity over time, as well as joint encoding of motion and disparity, do not offer a general solution to the inverse optics problem of local binocular 3D motion. Instead we suggest that local velocity constraints in combination with binocular disparity and other depth cues provide a more flexible framework for the solution of the inverse problem. In the context of the aperture problem we derive predictions from two plausible default strategies: (1) the vector normal prefers slow motion in 3D whereas (2) the cyclopean average is based on slow motion in 2D. Predicting perceived motion directions for ambiguous line motion provides an opportunity to distinguish between these strategies of 3D motion processing. Our theoretical results suggest that velocity constraints and disparity from feature tracking are needed to solve the inverse problem of 3D motion perception. It seems plausible that motion and disparity input is processed in parallel and integrated late in the visual processing hierarchy.</p>
      </abstract><abstract abstract-type="summary">
         <title>Author Summary</title>
         <p>Humans and many other predators have two eyes that are set a short distance apart so that an extensive region of the world is seen simultaneously by both eyes from slightly different points of view. Although the images of the world are essentially two-dimensional, we vividly see the world as three-dimensional. This is true for static as well as dynamic images. Here we elaborate on how the visual system may establish 3D motion perception from local input in the left and right eye. Using tools from analytic geometry we show that existing 3D motion models offer no general solution to the inverse optics problem of 3D motion perception. We suggest a flexible framework of motion and depth processing and suggest default strategies for local 3D motion estimation. Our results on the aperture and inverse problem of 3D motion are likely to stimulate computational, behavioral, and neuroscientific studies because they address the fundamental issue of how 3D motion is represented in the visual system.</p>
      </abstract><funding-group><funding-statement>ML is supported by ESRC/MRC RES-060-25-0010 (UK) and SH is supported by an EPSRC studentship (UK). The funders had no role in study design, collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
<page-count count="10"/>
</counts></article-meta>
</front>
<body>
   <sec id="s1">
      <title>Introduction</title>
      <p>The representation of the three-dimensional (3D) external world from two-dimensional (2D) retinal input is a fundamental problem that the visual system has to solve <xref ref-type="bibr" rid="pcbi.1000999-Berkeley1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Pizlo1">[4]</xref>. This is true for static scenes in 3D as well as for dynamic events in 3D space. For the latter the inverse problem extends to the inference of dynamic events in a 3D world from 2D motion signals projected into the left and right eye. In the following we exclude observer movements and only consider passively observed motion.</p>
      <p>Velocity in 3D space is described by motion direction and speed. Motion direction can be measured in terms of azimuth and elevation angle, and motion direction together with speed is conveniently expressed as a 3D motion vector in a cartesian coordinate system. Estimating such a vector locally is highly desirable for a visual system because the representation of local estimates in a dense vector field provides the basis for the perception of 3D object motion, that is direction and speed of moving objects. This information is essential for interpreting events as well as planning and executing actions in a dynamic environment.</p>
      <p>If a single moving point, corner or other unique feature serves as binocular input then intersection of constraint lines or triangulation together with a starting point provides a straightforward and unique geometrical solution to the inverse problem in a binocular viewing geometry (see <xref ref-type="sec" rid="s4">Methods</xref> and <xref ref-type="fig" rid="pcbi-1000999-g001">Fig. 1</xref> for an illustration). If, however, the moving stimulus has spatial extent, such as an edge, contour, or line inside a circular aperture <xref ref-type="bibr" rid="pcbi.1000999-Morgan1">[5]</xref> then local motion direction in corresponding receptive fields of the left and right eye remains ambiguous and additional constraints are needed to solve the aperture and inverse problem in 3D.</p>
      <fig id="pcbi-1000999-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000999.g001</object-id><label>Figure 1</label>
         <caption>
            <title>Illustration of the aperture problem of 3D motion with projections of an oriented line or contour moving in depth.</title>
            <p>The left and right eye with nodal points <bold>a</bold> and <bold>c</bold>, separated by interocular distance <italic>i</italic>, are verged on a fixation point <italic>F</italic> at viewing distance <italic>D</italic>. If an oriented stimulus (diagonal line) moves from the fixation point to a new position in depth along a known trajectory (black arrow) then perspective projection of the line stimulus onto local areas on the retinae or a fronto-parallel screen creates 2D aperture problems for the left and right eye (green and brown arrows).</p>
         </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.g001" xlink:type="simple"/></fig>
      <p>The inverse optics and the aperture problem are well-known problems in computational vision, especially in the context of stereo <xref ref-type="bibr" rid="pcbi.1000999-Poggio1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Mayhew1">[6]</xref>, structure from motion <xref ref-type="bibr" rid="pcbi.1000999-Koenderink1">[7]</xref>, and optic flow <xref ref-type="bibr" rid="pcbi.1000999-Hildreth1">[8]</xref>. Gradient constraint methods belong to the most widely used techniques of optic-flow computation from image sequences. They can be divided into local area-based <xref ref-type="bibr" rid="pcbi.1000999-Lucas1">[9]</xref> and into more global optic flow methods <xref ref-type="bibr" rid="pcbi.1000999-Horn1">[10]</xref>. Both techniques employ brightness constancy and smoothness constraints in the image to estimate velocity in an over-determined equation system. It is important to note that optical flow only provides a constraint in the direction of the image gradient, the normal component of the optical flow. As a consequence some form of regularization or smoothing is needed.</p>
      <p>Similar techniques in terms of error minimization and regularization have been offered for 3D stereo-motion detection <xref ref-type="bibr" rid="pcbi.1000999-Spies1">[11]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Scharr1">[13]</xref>. Essentially these algorithms extend processing principles of 2D optic flow to 3D scene flow.</p>
      <p>Computational studies on 3D motion algorithms are usually concerned with fast and efficient encoding when tested against ground truth. Here we are less concerned with the efficiency or robustness of a particular implementation. Instead we want to understand and predict behavioral characteristics of human 3D motion perception. 2D motion perception has been extensively researched in the context of the 2D aperture problem <xref ref-type="bibr" rid="pcbi.1000999-Wallach1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Sung1">[16]</xref> but there is a surprising lack of studies on the aperture problem and 3D motion perception.</p>
      <p>Any physiologically plausible solution to the inverse 3D motion problem has to rely on binocular sampling of local spatio-temporal information. There are at least three known cell types in early visual cortex that may be involved in local encoding of 3D motion: simple and complex motion detecting cells <xref ref-type="bibr" rid="pcbi.1000999-Hubel1">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Maunsell1">[20]</xref>, binocular disparity detecting cells <xref ref-type="bibr" rid="pcbi.1000999-Hubel3">[21]</xref> sampled over time, and joint motion and disparity detecting cells <xref ref-type="bibr" rid="pcbi.1000999-Anzai1">[22]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-DeAngelis2">[24]</xref>.</p>
      <p>It is therefore not surprising that three approaches to binocular 3D motion perception have emerged in the literature: Interocular velocity difference (IOVD), changing disparity over time (CDOT), and joint encoding of motion and disparity (JEMD).</p>
      <p>These three approaches have generated an extensive body of research but psychophysical results have been inconclusive and the nature of 3D motion processing remains an unresolved issue <xref ref-type="bibr" rid="pcbi.1000999-Regan1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Harris1">[26]</xref>. Despite the wealth of empirical studies on motion in depth there is a lack of studies on true 3D motion stimuli. Previous psychophysical and neurophysiological studies typically employ stimulus dots with unambiguous motion direction or fronto-parallel random-dot surfaces moving in depth. The aperture problem and local motion encoding however, which features so prominently in 2D motion perception <xref ref-type="bibr" rid="pcbi.1000999-Wallach1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Sung1">[16]</xref> has been neglected in the study of 3D motion perception.</p>
      <p>Large and persistent perceptual bias has been found for dot stimuli with unambiguous motion direction <xref ref-type="bibr" rid="pcbi.1000999-Harris2">[27]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Welchman1">[29]</xref> suggesting processing strategies that are different from the three main processing models <xref ref-type="bibr" rid="pcbi.1000999-Lages1">[28]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Ji1">[30]</xref>. It seems promising to investigate local motion stimuli with ambiguous motion direction such as a line or contour moving inside a circular aperture <xref ref-type="bibr" rid="pcbi.1000999-Heron1">[31]</xref> because they relate to local encoding <xref ref-type="bibr" rid="pcbi.1000999-Hubel1">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-DeAngelis2">[24]</xref> and may reveal principles of 3D motion processing <xref ref-type="bibr" rid="pcbi.1000999-Lages2">[32]</xref>.</p>
      <p>The aim of this paper is to evaluate existing models of 3D motion perception and to gain a better understanding of binocular 3D motion perception. First, we show that existing models of 3D motion perception are insufficient to solve the inverse problem of binocular 3D motion. Second, we establish velocity constraints in a binocular viewing geometry and demonstrate that additional information is necessary to disambiguate local velocity constraints and to derive a velocity estimate. Third, we compare two default strategies of perceived 3D motion when local motion direction is ambiguous. It is shown that critical stimulus conditions exist that can help to determine whether 3D motion perception favors slow 3D motion or averaged cyclopean motion.</p>
   </sec>
   <sec id="s2">
      <title>Results</title>
      <p>In the following we summarize shortcomings for each of the three main approaches to binocular 3D motion perception in terms of stereo and motion correspondence, 3D motion direction, and speed. We also provide a counterexample to illustrate the limitations of each approach.</p>
      <sec id="s2a">
         <title>Interocular velocity difference (IOVD)</title>
         <p>This influential processing model assumes that monocular spatio-temporal differentiation or motion detection <xref ref-type="bibr" rid="pcbi.1000999-Adelson2">[33]</xref> is followed by a difference computation between velocities in the left and right eye <xref ref-type="bibr" rid="pcbi.1000999-Beverley1">[34]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Regan2">[36]</xref>. The difference or ratio between monocular motion vectors in each eye, usually in a viewing geometry where interocular separation <italic>i</italic> and viewing distance <italic>D</italic> is known, provides an estimate of motion direction in terms of azimuth angle only.</p>
         <p>We argue that the standard IOVD model <xref ref-type="bibr" rid="pcbi.1000999-Welchman1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Brooks1">[37]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Rokers1">[40]</xref> is incomplete and ill-posed if we consider local motion encoding and the aperture problem. In the following the limitations of the IOVD model are illustrated.</p>
         <sec id="s2a1">
            <title>Stereo correspondence</title>
            <p>The first limitation is easily overlooked: IOVD assumes stereo correspondence between motion in the left and right eye when estimating 3D motion trajectory. The model does not specify which motion vector in the left eye should correspond to which motion vector in the right eye before computing a velocity difference. If there is only a single motion vector in the left and right eye then establishing a stereo correspondence appears trivial since there are only two positions in the left and right eye that signal dynamic information. Nevertheless, stereo correspondence is a necessary pre-requisite of IOVD processing which quickly becomes challenging if we consider multiple stimuli that excite not only one but many local motion detectors in the left and right eye. It is concluded that without explicit stereo correspondence between local motion detectors the IOVD model is incomplete.</p>
         </sec>
         <sec id="s2a2">
            <title>3D motion direction</title>
            <p>The second problem concerns 3D motion trajectories with arbitrary azimuth and elevation angles. Consider a local contour with spatial extent such as an oriented line inside a circular aperture so that the endpoints of the line are occluded. This is known as the aperture problem in stereopsis <xref ref-type="bibr" rid="pcbi.1000999-Morgan1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-vanEe1">[41]</xref>. If an observer maintains fixation at close or moderate viewing distance then the oriented line stimulus projects differently onto the left and right retina (see <xref ref-type="fig" rid="pcbi-1000999-g002">Fig. 2</xref> for an illustration with projections onto a single fronto-parallel plane). When the oriented line moves horizontally in depth at a given azimuth angle then local motion detectors tuned to different speeds respond optimally to motion normal (perpendicular) to the orientation of the line. If the normal in the left and right eye serves as a default strategy for the aperture problem in 2D <xref ref-type="bibr" rid="pcbi.1000999-Wallach1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Sung1">[16]</xref> then these vectors may have different lengths (as well as orientations if the line or edge is oriented in depth). Inverse perspective projection of the retinal motion vectors reveals that the velocity constraint lines are skew and an intersection of line constraints (IOC) does not exist. In fact, an intersection only exists if the following constraint for the motion vector in the left and right eye holds (see <xref ref-type="sec" rid="s4">Methods</xref>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e001" xlink:type="simple"/></disp-formula>(If the image planes are fronto-parallel so that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e002" xlink:type="simple"/></inline-formula> then the condition is simply <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e003" xlink:type="simple"/></inline-formula>). However, this constraint is easily violated as illustrated in <xref ref-type="fig" rid="pcbi-1000999-g002">Fig. 2</xref> and Counterexample 1 below.</p>
            <fig id="pcbi-1000999-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000999.g002</object-id><label>Figure 2</label>
               <caption>
                  <title>Inverse projection of constraint lines preferring slow 2D motion in the left and right eye.</title>
                  <p>Constraint lines through projection point <bold>b</bold> and <bold>d</bold> do not intersect and 3D motion cannot be determined (see text for details).</p>
               </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.g002" xlink:type="simple"/></fig>
         </sec>
         <sec id="s2a3">
            <title>Speed</title>
            <p>It is worth pointing out that IOVD offers no true estimate of 3D speed. This is surprising because the model is based on spatial-temporal or speed-tuned motion detectors. The problem arises because computing motion trajectory without a constraint in depth does not solve the inverse problem. As a consequence speed is typically approximated by motion in depth along the line of sight <xref ref-type="bibr" rid="pcbi.1000999-Brooks1">[37]</xref>.</p>
         </sec>
         <sec id="s2a4">
            <title>Counterexample 1</title>
            <p>If an edge or line tilted from horizontal by 0&lt;<italic>θ</italic>&lt;90° moves in depth at a fixed azimuth angle so that horizontal translations of the projected images into the left and right eye are unequal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e004" xlink:type="simple"/></inline-formula>, it follows from basic trigonometry that the local motion vectors normal to the oriented line have <italic>y</italic>-co-ordinates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e005" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e006" xlink:type="simple"/></inline-formula>, thus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e007" xlink:type="simple"/></inline-formula> (see <xref ref-type="fig" rid="pcbi-1000999-g002">Fig. 2</xref> and <xref ref-type="sec" rid="s4">Methods</xref>).</p>
            <p>Another violation occurs when the line is slanted in depth and projects with different orientations into the left and right eye. The resulting misalignment on the <italic>y</italic>-axis between motion vectors in the left and right eye is reminiscent of vertical disparity and the induced effect <xref ref-type="bibr" rid="pcbi.1000999-Ogle1">[42]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Banks1">[43]</xref> with vertical disparity increasing over time. The stereo system can reconstruct depth from input with orientation disparity and even vertical disparity <xref ref-type="bibr" rid="pcbi.1000999-Hinkle1">[44]</xref> but it seems unlikely that the binocular motion system can establish similar stereo correspondences.</p>
            <p>It is concluded that the IOVD model is incomplete and easily leads to ill-posed inverse problems. These limitations are difficult to resolve within a motion processing system and point to contributions from disparity or depth processing.</p>
         </sec>
      </sec>
      <sec id="s2b">
         <title>Changing disparity over time (CDOT)</title>
         <p>This alternative processing scheme uses disparity input and monitors changing disparity over time (CDOT). Disparity between the left and right image is detected <xref ref-type="bibr" rid="pcbi.1000999-Ohzawa1">[45]</xref> and changes over time give rise to motion-in-depth perception <xref ref-type="bibr" rid="pcbi.1000999-Cumming1">[46]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Peng1">[49]</xref>. We argue that this approach also has limitations when the inverse problem of local 3D motion is considered.</p>
         <sec id="s2b1">
            <title>Motion correspondence</title>
            <p>Assuming CDOT can always establish a suitable stereo correspondence between features including lines <xref ref-type="bibr" rid="pcbi.1000999-Morgan1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-vanEe1">[41]</xref> then the model still needs to resolve the motion correspondence problem. It needs to integrate disparity not only over time but also over 3D position to establish a 3D motion trajectory. Although this may be possible for a global feature tracking system it is unclear how CDOT arrives at estimates of local 3D motion.</p>
         </sec>
         <sec id="s2b2">
            <title>3D motion direction</title>
            <p>Detecting local disparity change alone is insufficient to determine an arbitrary 3D trajectory. CDOT has difficulties to recover arbitrary 3D motion direction because only motion-in-depth along the line of sight is well defined. 3D motion direction in terms of arbitrary azimuth and elevation requires a later global mechanism that has to solve the inverse problem by tracking not only disparity over time but also position in 3D space over time.</p>
         </sec>
         <sec id="s2b3">
            <title>Speed</title>
            <p>As a consequence the rate of change of disparity provides a speed estimate for motion-in-depth along the line of sight but not for arbitrary 3D motion trajectories.</p>
         </sec>
         <sec id="s2b4">
            <title>Counterexample 2</title>
            <p>In the context of local surface motion consider a horizontally slanted surface moving to the left or right behind a circular aperture. Without corners or other unique features CDOT can only detect local motion in depth along the line of sight. Similarly in the context of local line motion, the inverse problem remains ill posed for a local edge or line moving on a slanted surface because additional motion constraints are needed to determine a 3D motion direction.</p>
            <p>In summary, CDOT does not provide a general solution to the inverse problem of local 3D motion because it lacks information on motion direction. Even though CDOT is capable of extracting stereo correspondences over time, additional motion constraints are needed to represent arbitrary motion trajectories in 3D space.</p>
         </sec>
      </sec>
      <sec id="s2c">
         <title>Joint encoding of motion and disparity (JEMD)</title>
         <p>This approach postulates that early binocular cells are both motion and disparity selective and physiological evidence for the existence of such cells was found in cat striate cortex <xref ref-type="bibr" rid="pcbi.1000999-Anzai1">[22]</xref> and monkey V1 <xref ref-type="bibr" rid="pcbi.1000999-Pack1">[50]</xref> (see however <xref ref-type="bibr" rid="pcbi.1000999-Read1">[51]</xref>). Model cells in this hybrid approach extract motion and disparity energy from local stimulation. A read-out from population activity and population decoding is needed to explain global 3D motion phenomena such as transparent motion and Pulfrich-like effects <xref ref-type="bibr" rid="pcbi.1000999-Qian1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Qian2">[53]</xref>. Although JEMD is physiologically plausible it shares two problems with IOVD.</p>
         <sec id="s2c1">
            <title>3D motion direction</title>
            <p>Similar to cells tuned to binocular motion, model cells of JEMD prefer corresponding velocities in the left and right eye. Therefore a binocular model cell can only establish a 2D fronto-parallel velocity constraint at a given depth. Model cell activity remains ambiguous because it can be the result of local disparity or motion input <xref ref-type="bibr" rid="pcbi.1000999-Lages3">[54]</xref>. A later processing stage, possibly at the level of human V5/MT <xref ref-type="bibr" rid="pcbi.1000999-DeAngelis3">[55]</xref> needs to read out population cell activities across positions and depth planes and has to approximate global 3D motion. Similar to CDOT, the model defers the inverse problem to a later global processing stage.</p>
         </sec>
         <sec id="s2c2">
            <title>Speed</title>
            <p>Again, similar to IOVD and CDOT, JEMD provides no local 3D speed estimate. It also has to rely on sampling across depth planes in a population of cells in order to approximate speed.</p>
         </sec>
         <sec id="s2c3">
            <title>Counterexample 3</title>
            <p>Consider local 3D motion with unequal velocities in the left and right eye but the same average velocity, e.g. diagonal trajectories to the front and back through the same point in depth. JEMD has no mechanism to discriminate between these local 3D trajectories when monitoring binocular cell activity across depth planes in a given temporal window.</p>
            <p>In the following we introduce general velocity constraints for 3D motion and suggest two default strategies of 3D motion perception that are based on different processing principles (see <xref ref-type="sec" rid="s4">Methods</xref> for details).</p>
         </sec>
      </sec>
      <sec id="s2d">
         <title>Velocity constraints and two default strategies</title>
         <p>Which constraints does the visual system use to solve the inverse as well as aperture problem for local 3D line motion where endpoints are invisible or occluded? This is a critical question because it is linked to local motion encoding and the possible contribution from depth processing.</p>
         <p>The 3D motion system may establish constraint planes rather than constraint lines to capture all possible motion directions of a contour or edge, including motion in the direction of the edge's orientation. Geometrically the intersection of two constraint planes in a given binocular viewing geometry defines a constraint line oriented in 3D velocity space (see <xref ref-type="fig" rid="pcbi-1000999-g003">Fig. 3</xref> and <xref ref-type="sec" rid="s4">Methods</xref>).</p>
         <fig id="pcbi-1000999-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000999.g003</object-id><label>Figure 3</label>
            <caption>
               <title>Illustration of vector normal (VN) as a default strategy for local 3D motion perception (see text for details).</title>
               <p>The intersection of constraint planes (IOC) together with the assumption of slow motion describes the shortest vector in 3D space (blue arrow) that fulfills the velocity constraints.</p>
            </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.g003" xlink:type="simple"/></fig>
         <p>We suggest that in analogy to 2D motion perception <xref ref-type="bibr" rid="pcbi.1000999-Adelson1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Weiss1">[56]</xref> tracking of features in depth coupled with binocular velocity constraints from motion processing provides a flexible strategy to disambiguate 3D motion direction and to solve the inverse problem of 3D motion perception.</p>
         <p>But which principles or constraints are used? Does the binocular motion system prefer slow 3D motion or averaged 2D motion? Does it solve stereo correspondence before establishing binocular velocity constraints or does it average 2D velocity constraints from the left and right eye before it solves stereo correspondence? We derive predictions for two alternative strategies to address these questions.</p>
         <sec id="s2d1">
            <title>Vector normal (VN)</title>
            <p>Velocity constraints in the left and right eye provide velocity constraint planes in 3D velocity space. In <xref ref-type="fig" rid="pcbi-1000999-g003">Fig. 3</xref> they are illustrated as translucent green and brown triangles in a binocular viewing geometry. The intersection of constraint planes defines a velocity constraint line in 3D that also describes the true end-position of the moving line or contour (black line). The vector or line normal from the oriented constraint line to the starting point gives a default 3D motion estimate (blue arrow). It is the shortest distance in 3D velocity space and denotes the slowest motion vector that fulfills both constraints. Note that this strategy requires that the 3D motion system has established some stereo correspondence so that the intersection of constraints as well as the vector normal can be found in 3D velocity space.</p>
            <p>The VN strategy is a generalization of the vector normal and IOC in 2D <xref ref-type="bibr" rid="pcbi.1000999-Adelson1">[15]</xref> and it is related to area-based regression and gradient constraint models <xref ref-type="bibr" rid="pcbi.1000999-Lucas1">[9]</xref> where the local brightness constancy constraint ensures a default solution that is normal to the orientation of image intensity.</p>
         </sec>
         <sec id="s2d2">
            <title>Cyclopean average (CA)</title>
            <p>If the motion system computes slow 2D motion independently in the left and right eye then the cyclopean average provides an alternative velocity constraint <xref ref-type="bibr" rid="pcbi.1000999-Harris2">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Harris3">[57]</xref>. Averaging of monocular constraints increases robustness of the motion signal at the expense of binocular disparity information. Thus, a cyclopean average constrains velocity but gives no default estimate of velocity. However, if we attach (dynamic) disparity to the cyclopean average then the CA provides a default estimate of 3D velocity (see <xref ref-type="sec" rid="s4">Methods</xref> and <xref ref-type="fig" rid="pcbi-1000999-g004">Fig. 4</xref>).</p>
            <fig id="pcbi-1000999-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000999.g004</object-id><label>Figure 4</label>
               <caption>
                  <title>Illustration of cyclopean average (CA) as a default strategy for local 3D motion perception (see text for details).</title>
                  <p>Combining the cyclopean velocity constraint with horizontal disparity determines a vector in 3D space (red arrow) with average monocular velocity.</p>
               </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.g004" xlink:type="simple"/></fig>
            <p>The CA strategy is a generalized version of the vector average strategy for 2D motion <xref ref-type="bibr" rid="pcbi.1000999-Wilson1">[58]</xref> and can be linked to computational models of 3D motion that use global gradient and smoothness constraints <xref ref-type="bibr" rid="pcbi.1000999-Horn1">[10]</xref>. These global models amount to computing the average flow vector in the neighborhood of each point and refining the scene flow vector by the residual of the average flow vectors in the neighborhood. Interestingly, tracking the two intersection points or T junctions of a moving line with a circular aperture in the left and right eye and averaging the resulting vectors gives predictions that are equivalent to the CA strategy.</p>
         </sec>
         <sec id="s2d3">
            <title>Predictions for VN and CA strategy</title>
            <p>We use the Vector Normal (VN) and Cyclopean Average (CA) as default strategies to predict 3D velocity of an oriented line or contour moving in depth inside a circular aperture.</p>
            <p>The 3D plot in <xref ref-type="fig" rid="pcbi-1000999-g005">Fig. 5</xref> shows predictions of the VN strategy (blue) and the CA strategy (red) for a diagonal line stimulus moving on two trajectories in depth at a viewing distance <italic>D</italic> = 57 cm and interocular distance of <italic>i</italic> = 6.5 cm. The line stimulus has a trajectory to the front and left with azimuth +57.2 deg and elevation 0 deg, and a trajectory to the back and left with azimuth −57.2 deg and elevation 0 deg. Azimuth and elevation of 0 deg denotes a horizontal and fronto-parallel trajectory to the left. The starting point of each trajectory is the origin of the vector fields in the 3D plot. An open circle denotes the endpoint of a predicted motion vector. For each default strategy and stimulus trajectory a field of 120 vectors are shown with orientation disparity of the line stimulus ranging from −6° to +6° in steps of 0.1°. Orientation disparity changes perceived slant of the diagonal line so that at −6° the bottom-half of the line is slanted away from the observer and the top-half is slanted towards the observer.</p>
            <fig id="pcbi-1000999-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000999.g005</object-id><label>Figure 5</label>
               <caption>
                  <title>Velocity predictions of vector normal (VN, blue) and cyclopean average (CA, red) as default strategies of perception of local 3D line motion.</title>
                  <p>Predictions for an oriented stimulus line moving on a fixed trajectory to the front left and to the back left are shown. Predicted velocities show characteristic differences when the moving stimulus line or contour is slanted in depth (range of orientation disparities between −6° to +6°).</p>
               </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.g005" xlink:type="simple"/></fig>
            <p>If the diagonal line is fronto-parallel and has zero orientation disparity both strategies make equivalent predictions (intersection of red and blue vector fields in <xref ref-type="fig" rid="pcbi-1000999-g005">Fig. 5</xref>). If, however, the stimulus line has orientation disparity and is slanted in depth then predictions clearly discriminate between the two strategies. The VN strategy always finds the shortest vector between starting point and moving line so that velocity predictions approximate a semi-circle for changing orientation disparity. Please note that for the VN predictions the sign of orientation disparity reverses for the stimulus trajectory to the front and back. The CA strategy on the other hand computes an average vector and as a consequence the endpoints of the predictions approximate a velocity constraint line through the cyclopean origin.</p>
            <p>In a first experiment using a psychophysical matching task we measured the perceived 3D motion direction of an oriented line moving behind a circular aperture. Preliminary results from four observers indicate VN as the default strategy. Perceptual bias from depth processing reduced perceived slant of the stimulus line and this also affected motion direction <xref ref-type="bibr" rid="pcbi.1000999-Ji1">[30]</xref>.</p>
         </sec>
      </sec>
   </sec>
   <sec id="s3">
      <title>Discussion</title>
      <p>IOVD and CDOT are extreme models because they are based on either motion or disparity input. IOVD excludes contributions from binocular disparity processing but requires early stereo correspondence. It does not solve the inverse problem for local 3D line motion because it is confined to 3D motion in the <italic>x</italic>- or <italic>z</italic>-plane.</p>
      <p>CDOT on the other hand excludes contributions from motion processing and therefore has problems to establish motion correspondence and direction. Without further assumptions it is confined to motion in depth along the line of sight.</p>
      <p>If either motion or disparity input determines 3D motion perception then processing of any additional input needs to be disengaged or silenced. Instead, the visual system may take advantage of motion and disparity input <xref ref-type="bibr" rid="pcbi.1000999-Bradshaw1">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Lages4">[60]</xref> as well as additional cues. Here we favor parallel processing and late integration over early joint encoding because the inverse problem for local 3D motion remains ill posed for JEMD and a population read-out needs to be specified to approximate global 3D motion at a later stage.</p>
      <p>Combining global disparity or depth information with local velocity constraints at a later stage solves the inverse problem of local 3D motion and provides a flexible scheme that can exploit intermediate depth processing such as relative and orientation disparity in V2 and V4 <xref ref-type="bibr" rid="pcbi.1000999-Hinkle1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Thomas1">[61]</xref>. Velocity constraints may be processed in the ventral stream and binocular disparity together with other depth cues in the dorsal stream <xref ref-type="bibr" rid="pcbi.1000999-Ponce1">[62]</xref>. It seems anatomically and neurophysiologically plausible that integration of motion and disparity occurs late in subregions of human V5/MT <xref ref-type="bibr" rid="pcbi.1000999-DeAngelis3">[55]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Orban1">[63]</xref>–<xref ref-type="bibr" rid="pcbi.1000999-Rokers2">[65]</xref> if not in areas beyond V5/MT <xref ref-type="bibr" rid="pcbi.1000999-Likova1">[66]</xref>.</p>
      <p>What enables the visual system to instantaneously perceive 3D motion and to infer direction and speed of a moving object? It seems likely that the visual system exploits many cues to make this difficult inference as reliable and veridical as possible and the diverse set of effective local and global cues in psychophysical studies <xref ref-type="bibr" rid="pcbi.1000999-Bradshaw1">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-vanEe2">[67]</xref> already points at late integration within the visual processing hierarchy <xref ref-type="bibr" rid="pcbi.1000999-Ponce1">[62]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Rokers2">[65]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Likova1">[66]</xref>.</p>
      <p>More specifically, we suggest that binocular 3D motion perception may be based on parallel motion and depth processing. Thereby motion processing captures local spatio-temporal constraints in the scene whereas depth processing provides a global and dynamic depth map that helps to disambiguate motion direction and to maintain a detailed spatial representation of the scene. Late integration of motion and disparity constraints in combination with other cues can solve the inverse problem of local 3D motion and allows the visual system to remain flexible when binding and segmenting local inputs from different processing stages into a global 3D motion percept. Parallel processing and late integration may explain why, compared to 2D motion perception, 3D motion perception shows reduced spatio-temporal tuning characteristics <xref ref-type="bibr" rid="pcbi.1000999-Lages5">[68]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Tyler1">[69]</xref> and why motion perception can retain relatively fine spatial detail. The combination of local motion constraints with a global dynamic depth map from higher-order features would also explain the perception of different types of non-linear motion, such as non-rigid and 2<sup>nd</sup> order motion.</p>
      <p>The notion of parallel pathways feeding functionally different aspects of motion perception into a later stage is not new and has been advanced in the context of 2D motion direction and speed perception <xref ref-type="bibr" rid="pcbi.1000999-Braddick1">[70]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Braddick2">[71]</xref>, 2D pattern motion <xref ref-type="bibr" rid="pcbi.1000999-Adelson1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Weiss1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Wilson1">[58]</xref>, eye movements <xref ref-type="bibr" rid="pcbi.1000999-Rashbass1">[72]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Masson1">[73]</xref>, and the processing of higher order motion <xref ref-type="bibr" rid="pcbi.1000999-Ledgeway1">[74]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Lu1">[75]</xref> but was not often addressed in the context of binocular 3D motion perception <xref ref-type="bibr" rid="pcbi.1000999-Lu1">[75]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Regan3">[76]</xref>.</p>
      <p>Considering the ill-posed inverse problem of existing approaches and the under-determined characteristics of local binocular motion constraints, parallel processing and late integration of motion and disparity as well as other cues appears particularly convincing because solving the inverse problem for local 3D motion adds a functional significant aspect to the notion of parallel streams of dynamic disparity and motion processing. It will require considerable efforts to unravel the entire process but recent developments in the framework of Bayesian inference <xref ref-type="bibr" rid="pcbi.1000999-Lages1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Welchman1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Weiss1">[56]</xref> look promising to extend the geometric considerations given here.</p>
   </sec>
   <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <p>In the following we assume a fixed binocular viewing geometry with the cyclopean origin <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e008" xlink:type="simple"/></inline-formula> centered ±<italic>i/2</italic> between the nodal points of the left and right eye and the eyes verged on a fixation point straight ahead at viewing distance <italic>D</italic> (see <xref ref-type="fig" rid="pcbi-1000999-g001">Fig. 1</xref>). More complicated geometries arise if we take into account version, cyclovergence, and cyclotorsion of the eyes <xref ref-type="bibr" rid="pcbi.1000999-Read2">[77]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Schreiber1">[78]</xref>. For the sake of simplicity we ignore the non-linear aspects of visual space <xref ref-type="bibr" rid="pcbi.1000999-Lneburg1">[79]</xref> and represent perceived 3D motion as a linear vector in a three-dimensional Euclidean space where the fixation point is also the starting point of the motion stimulus.</p>
      <p>Since we are not concerned about particular algorithms and their implementation, results are given in terms of analytic geometry <xref ref-type="bibr" rid="pcbi.1000999-Jeffreys1">[80]</xref>, <xref ref-type="bibr" rid="pcbi.1000999-Gellert1">[81]</xref>.</p>
      <sec id="s4a">
         <title>Intersection of constraint lines</title>
         <p>If the eyes remain verged on a fixation point in a binocular viewing geometry then the constraint line in the left and right eye can be defined by pairs of points <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e009" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e010" xlink:type="simple"/></inline-formula>, respectively. The nodal point in the left eye <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e011" xlink:type="simple"/></inline-formula> and a projection point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e012" xlink:type="simple"/></inline-formula> of the motion vector on the left retina define a constraint line for the left eye. Similarly, points <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e013" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e014" xlink:type="simple"/></inline-formula> determine a constraint line in the right eye. The corresponding vector directions are given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e015" xlink:type="simple"/><label>(1)</label></disp-formula>Each constraint line can expressed by a pair of points <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e016" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e017" xlink:type="simple"/></inline-formula> together with scalar <italic>t</italic>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e018" xlink:type="simple"/><label>(2)</label></disp-formula>The two lines intersect for<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e019" xlink:type="simple"/><label>(3)</label></disp-formula>if and only if<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e020" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e021" xlink:type="simple"/></inline-formula> is the scalar product also called the dot product, × denotes the cross product, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e022" xlink:type="simple"/></inline-formula> the norm of a vector. Otherwise, the two lines are skew, and the inverse problem is ill posed.</p>
         <p>We can exclude the trivial case <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e023" xlink:type="simple"/></inline-formula> because the two eyes are separated by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e024" xlink:type="simple"/></inline-formula>. We also exclude the special case where the cross product is zero because the motion vectors in the left and right eye are identical or opposite.</p>
         <p>The cross product in (4) can be written as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e025" xlink:type="simple"/><label>(5)</label></disp-formula>Since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e026" xlink:type="simple"/></inline-formula> in Eq. (4) we are only concerned with the product <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e027" xlink:type="simple"/></inline-formula> which equals zero if and only if<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e028" xlink:type="simple"/><label>(6)</label></disp-formula>The ratio of <italic>z</italic> co-ordinates on the right-hand side may be different from 1 as a result of eye vergence and the left-hand side reflects the corresponding ratio of vertical displacements.</p>
         <p>In the following we consider the simpler case of projections onto a fronto-parallel screen (coplanar retinae) at a fixed viewing distance <italic>D</italic> (see <xref ref-type="fig" rid="pcbi-1000999-g002">Fig. 2</xref>). In this case epipolar lines are horizontal with equivalent co-ordinates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e029" xlink:type="simple"/></inline-formula> on the <italic>z</italic>-axis.</p>
         <p>Again, since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e030" xlink:type="simple"/></inline-formula> in (4) we only have to evaluate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e031" xlink:type="simple"/></inline-formula> which is zero if and only if:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e032" xlink:type="simple"/><label>(7)</label></disp-formula>For an intersection to exist the left and right eye motion vector must have equivalent horizontal <italic>y</italic> co-ordinates or zero vertical disparity.</p>
      </sec>
      <sec id="s4b">
         <title>Intersection of constraint planes</title>
         <p>Monocular line motion defines a constraint plane with three points: the nodal point of an eye and two points defining the end position of the projected line (see <xref ref-type="fig" rid="pcbi-1000999-g003">Fig. 3</xref>). In order to find the intersection of the left and right eye constraint plane we use the plane normal in the left and right eye. If the two planes are specified in Hessian normal form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e033" xlink:type="simple"/><label>(8)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e034" xlink:type="simple"/></inline-formula> is again the dot product, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e035" xlink:type="simple"/></inline-formula> is a vector describing the surface normal to a plane, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e036" xlink:type="simple"/></inline-formula> is a vector representing all points on the plane, and <italic>d</italic> is a scalar.</p>
         <p>We need to check whether the constraint planes are parallel or coincident, that is if<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e037" xlink:type="simple"/><label>(9)</label></disp-formula>before we can determine their intersection. The equation for the intersection of the two constraint planes is a line here written as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e038" xlink:type="simple"/><label>(10)</label></disp-formula>where <italic>u</italic> is a free parameter. Taking the dot product of the above with each plane normal gives two equations with unknown scalars <italic>c<sub>L</sub></italic> and <italic>c<sub>R</sub></italic>.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e039" xlink:type="simple"/><label>(11)</label></disp-formula>Solving the two equations for <italic>c<sub>L</sub></italic> and <italic>c<sub>R</sub></italic> gives<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e040" xlink:type="simple"/><label>(12)</label></disp-formula>Inserting <italic>c<sub>L</sub></italic> and <italic>c<sub>R</sub></italic> in (10) determines the intersection of constraints or constraint line <bold>p</bold>.</p>
         <p>In analogy to the 2D aperture problem and the intersection of constraints we can now define two plausible strategies for solving the 3D aperture problem:</p>
      </sec>
      <sec id="s4c">
         <title>Vector normal (VN)</title>
         <p>The shortest distance in 3-D (velocity) space between the starting point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e041" xlink:type="simple"/></inline-formula> of the stimulus line and the constraint line <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e042" xlink:type="simple"/></inline-formula> is the line or vector normal through point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e043" xlink:type="simple"/></inline-formula>. In order to determine the intersection point of the vector normal with the constraint line we pick two arbitrary points <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e044" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e045" xlink:type="simple"/></inline-formula> on intersection constraint line <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e046" xlink:type="simple"/></inline-formula> by choosing a scalar <italic>u</italic> (e.g., 0.5).<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e047" xlink:type="simple"/><label>(13)</label></disp-formula>Together with point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e048" xlink:type="simple"/></inline-formula> we can compute scalar <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e049" xlink:type="simple"/></inline-formula> as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e050" xlink:type="simple"/><label>(14)</label></disp-formula>which determines the closest intersection point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e051" xlink:type="simple"/></inline-formula> on the constraint line:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e052" xlink:type="simple"/><label>(15)</label></disp-formula></p>
      </sec>
      <sec id="s4d">
         <title>Cyclopean average (CA)</title>
         <p>We can define a cyclopean constraint line in terms of the cyclopean origin <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e053" xlink:type="simple"/></inline-formula> and projection point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e054" xlink:type="simple"/></inline-formula> on a fronto-parallel screen where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e055" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e056" xlink:type="simple"/></inline-formula> are the averages of the 2D normal co-ordinates for the left and right eye projections.</p>
         <p>If we measure disparity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e057" xlink:type="simple"/></inline-formula> at the same retinal coordinates as the horizontal offset between the left and right eye anchored at position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e058" xlink:type="simple"/></inline-formula> then we can define new points <bold>b</bold> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e059" xlink:type="simple"/></inline-formula> and <bold>d</bold> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e060" xlink:type="simple"/></inline-formula>. (Alternatively, we may establish an epipolar or more sophisticated disparity constraint.) The resulting two points together with the corresponding nodal points <bold>a</bold> and <bold>c</bold> define two constraint lines as in (2), one for the left and the other for the right eye. By inserting the new co-ordinates from above into (4) it is easy to see that condition (6) holds and the scalar for the intersection of lines can be found as in (3).</p>
      </sec>
      <sec id="s4e">
         <title>Transformation into spherical co-ordinates</title>
         <p>The intersection <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e061" xlink:type="simple"/></inline-formula> in cartesian co-ordinates can be transformed into spherical co-ordinates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e062" xlink:type="simple"/></inline-formula> using vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e063" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e064" xlink:type="simple"/></inline-formula> to determine azimuth <italic>α</italic> in the horizontal plane<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e065" xlink:type="simple"/><label>(16)</label></disp-formula>Similarly, for base vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e066" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e067" xlink:type="simple"/></inline-formula> elevation <italic>β</italic> is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e068" xlink:type="simple"/><label>(17)</label></disp-formula>Speed in 3D space is equivalent to the norm of vector <bold>s</bold> written as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000999.e069" xlink:type="simple"/></inline-formula>.</p>
      </sec>
   </sec>
</body>
<back>
   <ref-list>
      <title>References</title>
      <ref id="pcbi.1000999-Berkeley1">
         <label>1</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Berkeley</surname><given-names>G</given-names></name>
            </person-group>
            <year>1709/1975</year>
            <article-title>Philosophical Works; Including the Works on Vision.</article-title>
            <person-group person-group-type="editor">
               <name name-style="western"><surname>M Ayers</surname><given-names>M</given-names></name>
            </person-group>
            <comment>London, Dent</comment>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-vonHelmholtz1">
         <label>2</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>von Helmholtz</surname><given-names>H</given-names></name>
            </person-group>
            <year>1910/1962</year>
            <person-group person-group-type="editor">
               <name name-style="western"><surname>Southall</surname><given-names>JP</given-names></name>
            </person-group>
            <fpage>312</fpage>
            <lpage>313</lpage>
            <comment>Helmholtz's Treatise on Physiological Optics, Vol 1. Dover: New York, USA</comment>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Poggio1">
         <label>3</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name>
               <name name-style="western"><surname>Torre</surname><given-names>V</given-names></name>
               <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>
            </person-group>
            <year>1985</year>
            <article-title>Computational vision and regularization theory.</article-title>
            <source>Nature</source>
            <volume>317</volume>
            <fpage>314</fpage>
            <lpage>319</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Pizlo1">
         <label>4</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Pizlo</surname><given-names>Z</given-names></name>
            </person-group>
            <year>2001</year>
            <article-title>Perception viewed as an inverse problem.</article-title>
            <source>Vision Res</source>
            <volume>41</volume>
            <fpage>3145</fpage>
            <lpage>3161</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Morgan1">
         <label>5</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Morgan</surname><given-names>MJ</given-names></name>
               <name name-style="western"><surname>Castet</surname><given-names>E</given-names></name>
            </person-group>
            <year>1997</year>
            <article-title>The aperture problem in stereopsis.</article-title>
            <source>Vision Res</source>
            <volume>37</volume>
            <fpage>2737</fpage>
            <lpage>2744</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Mayhew1">
         <label>6</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Mayhew</surname><given-names>JEW</given-names></name>
               <name name-style="western"><surname>Longuet-Higgins</surname><given-names>HC</given-names></name>
            </person-group>
            <year>1982</year>
            <article-title>A computational model of binocular depth perception.</article-title>
            <source>Nature</source>
            <volume>297</volume>
            <fpage>376</fpage>
            <lpage>378</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Koenderink1">
         <label>7</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Koenderink</surname><given-names>JJ</given-names></name>
               <name name-style="western"><surname>van Doorn</surname><given-names>AJ</given-names></name>
            </person-group>
            <year>1991</year>
            <article-title>Affine structure from motion.</article-title>
            <source>J Opt Soc Am</source>
            <volume>8</volume>
            <fpage>377</fpage>
            <lpage>385</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Hildreth1">
         <label>8</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Hildreth</surname><given-names>EC</given-names></name>
            </person-group>
            <year>1984</year>
            <article-title>The computation of the velocity field.</article-title>
            <source>Proc R Soc Lond B Biol Sci</source>
            <volume>221</volume>
            <fpage>189</fpage>
            <lpage>220</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Lucas1">
         <label>9</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Lucas</surname><given-names>BD</given-names></name>
               <name name-style="western"><surname>Kanade</surname><given-names>T</given-names></name>
            </person-group>
            <year>1981</year>
            <comment>An Iterative Image Registration Technique with an Application to Stereo Vision, DARPA Image Understanding Workshop, pp121–130 (see also IJCAI'81, pp674–679)</comment>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Horn1">
         <label>10</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Horn</surname><given-names>BKP</given-names></name>
               <name name-style="western"><surname>Schunck</surname><given-names>BG</given-names></name>
            </person-group>
            <year>1981</year>
            <article-title>Determining optical flow.</article-title>
            <source>Artif Intell</source>
            <volume>17</volume>
            <fpage>185</fpage>
            <lpage>203</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Spies1">
         <label>11</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Spies</surname><given-names>H</given-names></name>
               <name name-style="western"><surname>Jähne</surname><given-names>BJ</given-names></name>
               <name name-style="western"><surname>Barron</surname><given-names>JL</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>Range flow estimation.</article-title>
            <source>Comput Vis Image Underst</source>
            <volume>85</volume>
            <fpage>209</fpage>
            <lpage>231</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Min1">
         <label>12</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Min</surname><given-names>D</given-names></name>
               <name name-style="western"><surname>Sohn</surname><given-names>K</given-names></name>
            </person-group>
            <year>2006</year>
            <article-title>Edge-preserving simultaneous joint motion-disparity estimation.</article-title>
            <source>Proceedings of the 18<sup>th</sup> International Conference on Pattern Recognition Vol</source>
            <volume>2</volume>
            <fpage>74</fpage>
            <lpage>77</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Scharr1">
         <label>13</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Scharr</surname><given-names>H</given-names></name>
               <name name-style="western"><surname>Küsters</surname><given-names>R</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>A linear model for simultaneous estimation of 3D motion and depth.</article-title>
            <fpage>1</fpage>
            <lpage>6</lpage>
            <comment>IEEE Workshop on Motion and Video Computing, Orlando FL</comment>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Wallach1">
         <label>14</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Wallach</surname><given-names>H</given-names></name>
            </person-group>
            <year>1935</year>
            <article-title>Über visuell wahrgenommene Bewegungsrichtung.</article-title>
            <source>Psychol Res</source>
            <volume>20</volume>
            <fpage>325</fpage>
            <lpage>380</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Adelson1">
         <label>15</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>
               <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>
            </person-group>
            <year>1982</year>
            <article-title>Phenomenal coherence of moving visual patterns.</article-title>
            <source>Nature</source>
            <volume>300</volume>
            <fpage>523</fpage>
            <lpage>525</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Sung1">
         <label>16</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Sung</surname><given-names>K</given-names></name>
               <name name-style="western"><surname>Wojtach</surname><given-names>WT</given-names></name>
               <name name-style="western"><surname>Purves</surname><given-names>D</given-names></name>
            </person-group>
            <year>2009</year>
            <article-title>An empirical explanation of aperture effects.</article-title>
            <source>Proc Nat Acad Sci USA</source>
            <volume>106</volume>
            <fpage>298</fpage>
            <lpage>303</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Hubel1">
         <label>17</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name>
               <name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name>
            </person-group>
            <year>1962</year>
            <article-title>Receptive fields, binocular interaction and functional architecture in the cat's visual cortex.</article-title>
            <source>J Physiol</source>
            <volume>(Lond.)160</volume>
            <fpage>106</fpage>
            <lpage>154</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Hubel2">
         <label>18</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name>
               <name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name>
            </person-group>
            <year>1968</year>
            <article-title>Receptive fields and functional architecture of monkey striate cortex.</article-title>
            <source>J Physiol</source>
            <volume>195</volume>
            <fpage>215</fpage>
            <lpage>243</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-DeAngelis1">
         <label>19</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
               <name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
               <name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
            </person-group>
            <year>1993</year>
            <article-title>Spatiotemporal organization of simple-cell receptive fields in the cat's striate cortex. 1. General characteristics and postnatal development.</article-title>
            <source>J Neurophys</source>
            <volume>69</volume>
            <fpage>1091</fpage>
            <lpage>1117</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Maunsell1">
         <label>20</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Maunsell</surname><given-names>JH</given-names></name>
               <name name-style="western"><surname>van Essen</surname><given-names>DC</given-names></name>
            </person-group>
            <year>1983</year>
            <article-title>Functional properties of neurons in middle temporal visual area of the macaque monkey: I. Selectivity for stimulus direction, speed, and orientation.</article-title>
            <source>J Neurophys</source>
            <volume>49</volume>
            <fpage>1127</fpage>
            <lpage>1147</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Hubel3">
         <label>21</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name>
               <name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name>
            </person-group>
            <year>1970</year>
            <article-title>Stereoscopic vision in macaque monkey. Cells sensitive to binocular depth in area 18 of the macaque monkey cortex.</article-title>
            <source>Nature</source>
            <volume>225</volume>
            <fpage>41</fpage>
            <lpage>42</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Anzai1">
         <label>22</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Anzai</surname><given-names>A</given-names></name>
               <name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
               <name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
            </person-group>
            <year>2001</year>
            <article-title>Joint encoding of motion and depth by visual cortical neurons: neural basis of he Pulfrich effect.</article-title>
            <source>Nat Neurosci</source>
            <volume>4</volume>
            <fpage>513</fpage>
            <lpage>518</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Bradley1">
         <label>23</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Bradley</surname><given-names>DC</given-names></name>
               <name name-style="western"><surname>Qian</surname><given-names>N</given-names></name>
               <name name-style="western"><surname>Andersen</surname><given-names>RA</given-names></name>
            </person-group>
            <year>1995</year>
            <article-title>Integration of motion and stereopsis in middle temporal cortical area of macaques.</article-title>
            <source>Nature</source>
            <volume>373</volume>
            <fpage>609</fpage>
            <lpage>611</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-DeAngelis2">
         <label>24</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
               <name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name>
            </person-group>
            <year>1999</year>
            <article-title>Organization of disparity-selective neurons in macaque area MT.</article-title>
            <source>J Neurosci</source>
            <volume>19</volume>
            <fpage>1398</fpage>
            <lpage>1415</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Regan1">
         <label>25</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Regan</surname><given-names>D</given-names></name>
               <name name-style="western"><surname>Gray</surname><given-names>R</given-names></name>
            </person-group>
            <year>2009</year>
            <article-title>Binocular processing of motion; some unresolved problems.</article-title>
            <source>Spatial Vision</source>
            <volume>22</volume>
            <fpage>1</fpage>
            <lpage>43</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Harris1">
         <label>26</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Harris</surname><given-names>JM</given-names></name>
               <name name-style="western"><surname>Nefs</surname><given-names>HT</given-names></name>
               <name name-style="western"><surname>Grafton</surname><given-names>CE</given-names></name>
            </person-group>
            <year>2008</year>
            <article-title>Binocular vision and motion-in-depth.</article-title>
            <source>Spat Vis</source>
            <volume>21</volume>
            <fpage>531</fpage>
            <lpage>547</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Harris2">
         <label>27</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Harris</surname><given-names>JM</given-names></name>
               <name name-style="western"><surname>Drga</surname></name>
            </person-group>
            <year>2005</year>
            <article-title>Using visual direction in three-dimensional motion perception.</article-title>
            <source>Nat Neurosci</source>
            <volume>8</volume>
            <fpage>229</fpage>
            <lpage>233</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Lages1">
         <label>28</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Lages</surname><given-names>M</given-names></name>
            </person-group>
            <year>2006</year>
            <article-title>Bayesian models of binocular 3-D motion perception.</article-title>
            <source>J Vision</source>
            <volume>6</volume>
            <fpage>508</fpage>
            <lpage>522</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Welchman1">
         <label>29</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Welchman</surname><given-names>AE</given-names></name>
               <name name-style="western"><surname>Lam</surname><given-names>JM</given-names></name>
               <name name-style="western"><surname>Bülthoff</surname><given-names>HH</given-names></name>
            </person-group>
            <year>2008</year>
            <article-title>Bayesian motion estimation accounts for a surprising bias in 3D vision.</article-title>
            <source>Proc Nat Acad Sci USA</source>
            <volume>105</volume>
            <fpage>12087</fpage>
            <lpage>92</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Ji1">
         <label>30</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Ji</surname><given-names>H</given-names></name>
               <name name-style="western"><surname>Fermüller</surname><given-names>C</given-names></name>
            </person-group>
            <year>2006</year>
            <article-title>Noise causes slant underestimation in stereo and motion.</article-title>
            <source>Vision Res</source>
            <volume>46</volume>
            <fpage>3105</fpage>
            <lpage>3120</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Heron1">
         <label>31</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Heron</surname><given-names>S</given-names></name>
               <name name-style="western"><surname>Lages</surname><given-names>M</given-names></name>
            </person-group>
            <year>2009</year>
            <article-title>Measuring azimuth and elevation of binocular 3D motion direction [Abstract].</article-title>
            <source>J Vision</source>
            <volume>9</volume>
            <fpage>637a</fpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Lages2">
         <label>32</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Lages</surname><given-names>M</given-names></name>
               <name name-style="western"><surname>Heron</surname><given-names>S</given-names></name>
            </person-group>
            <year>2009</year>
            <article-title>Testing generalized models of binocular 3D motion perception [Abstract].</article-title>
            <source>J Vision</source>
            <volume>9</volume>
            <fpage>636a</fpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Adelson2">
         <label>33</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>
               <name name-style="western"><surname>Bergen</surname><given-names>JR</given-names></name>
            </person-group>
            <year>1985</year>
            <article-title>Spatio-temporal energy models for the perception of motion.</article-title>
            <source>J Opt Soc Am A</source>
            <volume>2</volume>
            <fpage>284</fpage>
            <lpage>299</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Beverley1">
         <label>34</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Beverley</surname><given-names>KI</given-names></name>
               <name name-style="western"><surname>Regan</surname><given-names>D</given-names></name>
            </person-group>
            <year>1973</year>
            <article-title>Evidence for the existence of neural mechanisms selectively sensitive to the direction of movement in space.</article-title>
            <source>J Physiol</source>
            <volume>235</volume>
            <fpage>17</fpage>
            <lpage>29</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Beverley2">
         <label>35</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Beverley</surname><given-names>KI</given-names></name>
               <name name-style="western"><surname>Regan</surname><given-names>D</given-names></name>
            </person-group>
            <year>1975</year>
            <article-title>The relation between discrimination and sensitivity in the perception of motion in depth.</article-title>
            <source>J Physiol</source>
            <volume>249</volume>
            <fpage>387</fpage>
            <lpage>398</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Regan2">
         <label>36</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Regan</surname><given-names>D</given-names></name>
               <name name-style="western"><surname>Beverley</surname><given-names>KI</given-names></name>
            </person-group>
            <year>1973</year>
            <article-title>Some dynamic features of depth perception.</article-title>
            <source>Vision Res</source>
            <volume>13</volume>
            <fpage>2369</fpage>
            <lpage>2379</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Brooks1">
         <label>37</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Brooks</surname><given-names>KR</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>Interocular velocity difference contributes to stereomotion speed perception.</article-title>
            <source>J Vision</source>
            <volume>2</volume>
            <fpage>218</fpage>
            <lpage>231</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Shioiri1">
         <label>38</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Shioiri</surname><given-names>S</given-names></name>
               <name name-style="western"><surname>Saisho</surname><given-names>H</given-names></name>
               <name name-style="western"><surname>Yaguchi</surname><given-names>H</given-names></name>
            </person-group>
            <year>2000</year>
            <article-title>Motion in depth based on inter-ocular velocity differences.</article-title>
            <source>Vision Res</source>
            <volume>40</volume>
            <fpage>2565</fpage>
            <lpage>2572</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Fernandez1">
         <label>39</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Fernandez</surname><given-names>JM</given-names></name>
               <name name-style="western"><surname>Farell</surname><given-names>B</given-names></name>
            </person-group>
            <year>2005</year>
            <article-title>Seeing motion-in-depth using inter-ocular velocity differences.</article-title>
            <source>Vision Res</source>
            <volume>45</volume>
            <fpage>2786</fpage>
            <lpage>2798</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Rokers1">
         <label>40</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Rokers</surname><given-names>B</given-names></name>
               <name name-style="western"><surname>Cormack</surname><given-names>LK</given-names></name>
               <name name-style="western"><surname>Huk</surname><given-names>AC</given-names></name>
            </person-group>
            <year>2008</year>
            <article-title>Strong percepts of motion through depth without strong percepts of position in depth.</article-title>
            <source>J Vision</source>
            <volume>8</volume>
            <fpage>1</fpage>
            <lpage>10</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-vanEe1">
         <label>41</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>van Ee</surname><given-names>R</given-names></name>
               <name name-style="western"><surname>Schor</surname><given-names>CM</given-names></name>
            </person-group>
            <year>2000</year>
            <article-title>Unconstrained stereoscopic matching of lines.</article-title>
            <source>Vision Res</source>
            <volume>40</volume>
            <fpage>151</fpage>
            <lpage>162</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Ogle1">
         <label>42</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Ogle</surname><given-names>KN</given-names></name>
            </person-group>
            <year>1940</year>
            <article-title>Induced size effect with the eyes in asymmetric convergence.</article-title>
            <source>Arch Ophthal</source>
            <volume>23</volume>
            <fpage>1023</fpage>
            <lpage>1028</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Banks1">
         <label>43</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
               <name name-style="western"><surname>Backus</surname><given-names>BT</given-names></name>
            </person-group>
            <year>1998</year>
            <article-title>Extra-retinal and perspective cues cause the small range of the induced effect.</article-title>
            <source>Vision Res</source>
            <volume>38</volume>
            <fpage>187</fpage>
            <lpage>194</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Hinkle1">
         <label>44</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Hinkle</surname><given-names>DA</given-names></name>
               <name name-style="western"><surname>Connor</surname><given-names>CE</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>Three-dimensional orientation tuning in macaque area V4.</article-title>
            <source>Nat Neurosci</source>
            <volume>5</volume>
            <fpage>665</fpage>
            <lpage>670</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Ohzawa1">
         <label>45</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
               <name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
               <name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
            </person-group>
            <year>1990</year>
            <article-title>Stereoscopic depth discrimination in the visual cortex: Neurons ideally suited as disparity detectors.</article-title>
            <source>Science,</source>
            <volume>249</volume>
            <fpage>1037</fpage>
            <lpage>1041</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Cumming1">
         <label>46</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
               <name name-style="western"><surname>Parker</surname><given-names>AJ</given-names></name>
            </person-group>
            <year>1994</year>
            <article-title>Binocular mechanisms for detecting motion in depth.</article-title>
            <source>Vision Res</source>
            <volume>34</volume>
            <fpage>483</fpage>
            <lpage>495</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Beverley3">
         <label>47</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Beverley</surname><given-names>KI</given-names></name>
               <name name-style="western"><surname>Regan</surname><given-names>D</given-names></name>
            </person-group>
            <year>1974</year>
            <article-title>Temporal integration of disparity information in stereoscopic perception.</article-title>
            <source>Exp Brain Res</source>
            <volume>19</volume>
            <fpage>228</fpage>
            <lpage>232</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Julesz1">
         <label>48</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Julesz</surname><given-names>B</given-names></name>
            </person-group>
            <year>1971</year>
            <source>Foundations of Cyclopean Perception.</source>
            <publisher-name>University of Chicago Press: Chicago</publisher-name>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Peng1">
         <label>49</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Peng</surname><given-names>Q</given-names></name>
               <name name-style="western"><surname>Shi</surname><given-names>BE</given-names></name>
            </person-group>
            <year>2010</year>
            <article-title>The changing disparity energy model.</article-title>
            <source>Vision Res</source>
            <volume>50</volume>
            <fpage>181</fpage>
            <lpage>192</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Pack1">
         <label>50</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Pack</surname><given-names>CC</given-names></name>
               <name name-style="western"><surname>Born</surname><given-names>RT</given-names></name>
               <name name-style="western"><surname>Livingstone</surname><given-names>MS</given-names></name>
            </person-group>
            <year>2003</year>
            <article-title>Two-dimensional substructure of stereo and motion interactions in macaque visual cortex.</article-title>
            <source>Neuron</source>
            <volume>37</volume>
            <fpage>525</fpage>
            <lpage>535</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Read1">
         <label>51</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Read</surname><given-names>JC</given-names></name>
               <name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
            </person-group>
            <year>2005</year>
            <article-title>Effect of interocular delay on disparity-selective V1 neurons: Relationship to stereoacuity and the Pulfrich effect.</article-title>
            <source>J Neurophys</source>
            <volume>94</volume>
            <fpage>1541</fpage>
            <lpage>1553</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Qian1">
         <label>52</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Qian</surname><given-names>N</given-names></name>
            </person-group>
            <year>1994</year>
            <article-title>Computing stereo disparity and motion with known binocular cell properties.</article-title>
            <source>Neural Comp</source>
            <volume>6</volume>
            <fpage>390</fpage>
            <lpage>404</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Qian2">
         <label>53</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Qian</surname><given-names>N</given-names></name>
               <name name-style="western"><surname>Andersen</surname><given-names>RA</given-names></name>
            </person-group>
            <year>1997</year>
            <article-title>A physiological model for motion-stereo integration and a unified explanation of Pulfrich-like phenomena.</article-title>
            <source>Vision Res</source>
            <volume>37</volume>
            <fpage>1683</fpage>
            <lpage>1698</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Lages3">
         <label>54</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Lages</surname><given-names>M</given-names></name>
               <name name-style="western"><surname>Dolia</surname><given-names>A</given-names></name>
               <name name-style="western"><surname>Graf</surname><given-names>EW</given-names></name>
            </person-group>
            <year>2007</year>
            <article-title>Dichoptic motion perception limited to depth of fixation?</article-title>
            <source>Vision Res</source>
            <volume>47</volume>
            <fpage>244</fpage>
            <lpage>252</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-DeAngelis3">
         <label>55</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
               <name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name>
            </person-group>
            <year>2004</year>
            <article-title>Perceptual “read-out” of conjoined direction and disparity maps in extrastriate area MT.</article-title>
            <source>PLoS Biol</source>
            <fpage>e0394</fpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Weiss1">
         <label>56</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Weiss</surname><given-names>Y</given-names></name>
               <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>
               <name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>Motion illusions as optimal percepts.</article-title>
            <source>Nat Neurosci</source>
            <volume>5</volume>
            <fpage>598</fpage>
            <lpage>604</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Harris3">
         <label>57</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Harris</surname><given-names>JM</given-names></name>
               <name name-style="western"><surname>Rushton</surname><given-names>SK</given-names></name>
            </person-group>
            <year>2003</year>
            <article-title>Poor visibility of motion-in-depth is due to early motion averaging.</article-title>
            <source>Vision Res</source>
            <volume>43</volume>
            <fpage>385</fpage>
            <lpage>392</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Wilson1">
         <label>58</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Wilson</surname><given-names>HR</given-names></name>
               <name name-style="western"><surname>Ferrera</surname><given-names>VP</given-names></name>
               <name name-style="western"><surname>Yo</surname><given-names>C</given-names></name>
            </person-group>
            <year>1992</year>
            <article-title>A psychophysically motivated model for two-dimensional motion perception.</article-title>
            <source>Vis Neurosci</source>
            <volume>9</volume>
            <issue>1</issue>
            <fpage>79</fpage>
            <lpage>97</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Bradshaw1">
         <label>59</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Bradshaw</surname><given-names>MF</given-names></name>
               <name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
            </person-group>
            <year>1997</year>
            <article-title>The direction of retinal motion facilitates binocular stereopsis.</article-title>
            <source>Proc R Soc Lond B Biol Sci</source>
            <volume>264</volume>
            <fpage>1421</fpage>
            <lpage>1427</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Lages4">
         <label>60</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Lages</surname><given-names>M</given-names></name>
               <name name-style="western"><surname>Heron</surname><given-names>S</given-names></name>
            </person-group>
            <year>2008</year>
            <article-title>Motion and disparity processing informs Bayesian 3D motion estimation.</article-title>
            <source>Proc Nat Acad Sci USA</source>
            <volume>105</volume>
            <fpage>E117</fpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Thomas1">
         <label>61</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Thomas</surname><given-names>OM</given-names></name>
               <name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
               <name name-style="western"><surname>Parker</surname><given-names>AJ</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>A specialization for relative disparity in V2.</article-title>
            <source>Nat Neurosci</source>
            <volume>5</volume>
            <fpage>472</fpage>
            <lpage>478</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Ponce1">
         <label>62</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Ponce</surname><given-names>CR</given-names></name>
               <name name-style="western"><surname>Lomber</surname><given-names>SG</given-names></name>
               <name name-style="western"><surname>Born</surname><given-names>RT</given-names></name>
            </person-group>
            <year>2008</year>
            <article-title>Integrating motion and depth via parallel pathways.</article-title>
            <source>Nat Neurosci</source>
            <volume>11</volume>
            <fpage>216</fpage>
            <lpage>223</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Orban1">
         <label>63</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Orban</surname><given-names>GA</given-names></name>
            </person-group>
            <year>2008</year>
            <article-title>Higher order visual processing in macaque extrastriate cortex.</article-title>
            <source>Physio Rev</source>
            <volume>88</volume>
            <fpage>59</fpage>
            <lpage>89</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Majaj1">
         <label>64</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Majaj</surname><given-names>N</given-names></name>
               <name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>
               <name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>
            </person-group>
            <year>2007</year>
            <article-title>Motion integration by neurons in macaque MT is local not global.</article-title>
            <source>J Neurosci</source>
            <volume>27</volume>
            <fpage>366</fpage>
            <lpage>370</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Rokers2">
         <label>65</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Rokers</surname><given-names>B</given-names></name>
               <name name-style="western"><surname>Cormack</surname><given-names>LK</given-names></name>
               <name name-style="western"><surname>Huk</surname><given-names>AC</given-names></name>
            </person-group>
            <year>2009</year>
            <article-title>Disparity- and velocity-based signals for three-dimensional motion perception in human MT+.</article-title>
            <source>Nat Neurosci</source>
            <volume>12</volume>
            <fpage>1050</fpage>
            <lpage>1055</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Likova1">
         <label>66</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Likova</surname><given-names>LT</given-names></name>
               <name name-style="western"><surname>Tyler</surname><given-names>CW</given-names></name>
            </person-group>
            <year>2007</year>
            <article-title>Stereomotion processing in the human occipital cortex.</article-title>
            <source>Neuroimage</source>
            <volume>38</volume>
            <fpage>293</fpage>
            <lpage>305</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-vanEe2">
         <label>67</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>van Ee</surname><given-names>R</given-names></name>
               <name name-style="western"><surname>Anderson</surname><given-names>BL</given-names></name>
            </person-group>
            <year>2001</year>
            <article-title>Motion direction, speed and orientation in binocular matching.</article-title>
            <source>Nature</source>
            <volume>410</volume>
            <fpage>690</fpage>
            <lpage>694</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Lages5">
         <label>68</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Lages</surname><given-names>M</given-names></name>
               <name name-style="western"><surname>Mamassian</surname><given-names>P</given-names></name>
               <name name-style="western"><surname>Graf</surname><given-names>EW</given-names></name>
            </person-group>
            <year>2003</year>
            <article-title>Spatial and temporal tuning of motion-in-depth.</article-title>
            <source>Vision Res</source>
            <volume>43</volume>
            <fpage>2861</fpage>
            <lpage>2873</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Tyler1">
         <label>69</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Tyler</surname><given-names>CW</given-names></name>
            </person-group>
            <year>1971</year>
            <article-title>Stereoscopic depth movement: Two eyes less sensitive than one.</article-title>
            <source>Science</source>
            <volume>174</volume>
            <fpage>958</fpage>
            <lpage>961</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Braddick1">
         <label>70</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Braddick</surname><given-names>OJ</given-names></name>
            </person-group>
            <year>1974</year>
            <article-title>A short-range process in apparent motion.</article-title>
            <source>Vision Res</source>
            <volume>14</volume>
            <fpage>519</fpage>
            <lpage>527</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Braddick2">
         <label>71</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Braddick</surname><given-names>OJ</given-names></name>
            </person-group>
            <year>1980</year>
            <article-title>Low-level and high-level processes in apparent motion.</article-title>
            <source>Philos Trans R Soc</source>
            <volume>290B</volume>
            <fpage>137</fpage>
            <lpage>151</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Rashbass1">
         <label>72</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Rashbass</surname><given-names>C</given-names></name>
               <name name-style="western"><surname>Westheimer</surname><given-names>G</given-names></name>
            </person-group>
            <year>1961</year>
            <article-title>Disjunctive eye movements.</article-title>
            <source>J Physiol</source>
            <volume>159</volume>
            <fpage>339</fpage>
            <lpage>360</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Masson1">
         <label>73</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Masson</surname><given-names>GS</given-names></name>
               <name name-style="western"><surname>Castet</surname><given-names>E</given-names></name>
            </person-group>
            <year>2002</year>
            <article-title>Parallel motion processing for the intitiation of short-latency ocular following in humans.</article-title>
            <source>J Neurosci</source>
            <volume>22</volume>
            <fpage>5149</fpage>
            <lpage>5163</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Ledgeway1">
         <label>74</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Ledgeway</surname><given-names>T</given-names></name>
               <name name-style="western"><surname>Smith</surname><given-names>AT</given-names></name>
            </person-group>
            <year>1994</year>
            <article-title>Evidence for separate motion-detecting mechanisms for first-order and 2<sup>nd</sup>-order motion in human vision.</article-title>
            <source>Vision Res</source>
            <volume>34</volume>
            <fpage>2727</fpage>
            <lpage>2740</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Lu1">
         <label>75</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Lu</surname><given-names>Z-L</given-names></name>
               <name name-style="western"><surname>Sperling</surname><given-names>G</given-names></name>
            </person-group>
            <year>2001</year>
            <article-title>Three systems theory of human visual motion perception: review and update.</article-title>
            <source>J Opt Soc Am A</source>
            <volume>18</volume>
            <fpage>2331</fpage>
            <lpage>2370</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Regan3">
         <label>76</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Regan</surname><given-names>D</given-names></name>
               <name name-style="western"><surname>Beverley</surname><given-names>KI</given-names></name>
               <name name-style="western"><surname>Cynader</surname><given-names>M</given-names></name>
               <name name-style="western"><surname>Lennie</surname><given-names>P</given-names></name>
            </person-group>
            <year>1979</year>
            <article-title>Stereoscopic subsystems for position in depth and for motion in depth.</article-title>
            <source>Proc R Soc Lon B</source>
            <volume>42</volume>
            <fpage>485</fpage>
            <lpage>501</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Read2">
         <label>77</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
               <name name-style="western"><surname>Phillipson</surname><given-names>GP</given-names></name>
               <name name-style="western"><surname>Glennerster</surname><given-names>A</given-names></name>
            </person-group>
            <year>2009</year>
            <article-title>Latitude and longitude vertical disparities.</article-title>
            <source>J Vision</source>
            <volume>9</volume>
            <fpage>1</fpage>
            <lpage>37</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Schreiber1">
         <label>78</label>
         <element-citation publication-type="journal" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Schreiber</surname><given-names>KM</given-names></name>
               <name name-style="western"><surname>Hillis</surname><given-names>JM</given-names></name>
               <name name-style="western"><surname>Filippini</surname><given-names>HR</given-names></name>
               <name name-style="western"><surname>Schor</surname><given-names>CM</given-names></name>
               <name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
            </person-group>
            <year>2008</year>
            <article-title>The surface of the empirical horopter.</article-title>
            <source>J Vision</source>
            <volume>8</volume>
            <fpage>1</fpage>
            <lpage>20</lpage>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Lneburg1">
         <label>79</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Lüneburg</surname><given-names>RK</given-names></name>
            </person-group>
            <year>1947</year>
            <source>Mathematical analysis of binocular vision</source>
            <publisher-loc>Princeton, NJ</publisher-loc>
            <publisher-name>Princeton University Press</publisher-name>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Jeffreys1">
         <label>80</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="author">
               <name name-style="western"><surname>Jeffreys</surname><given-names>H</given-names></name>
               <name name-style="western"><surname>Jeffreys</surname><given-names>BS</given-names></name>
            </person-group>
            <year>1988</year>
            <source>Methods of Mathematical Physics 3<sup>rd</sup> ed</source>
            <publisher-loc>Cambridge, England</publisher-loc>
            <publisher-name>Cambridge University Press</publisher-name>
         </element-citation>
      </ref>
      <ref id="pcbi.1000999-Gellert1">
         <label>81</label>
         <element-citation publication-type="other" xlink:type="simple">
            <person-group person-group-type="editor">
               <name name-style="western"><surname>Gellert</surname><given-names>W</given-names></name>
               <name name-style="western"><surname>Gottwald</surname><given-names>S</given-names></name>
               <name name-style="western"><surname>Hellwich</surname><given-names>M</given-names></name>
               <name name-style="western"><surname>Kästner</surname><given-names>H</given-names></name>
               <name name-style="western"><surname>Künstner</surname><given-names>H</given-names></name>
            </person-group>
            <year>1989</year>
            <source>Plane. In VNR Concise encyclopedia of mathematics (2<sup>nd</sup> ed)</source>
            <publisher-loc>New York</publisher-loc>
            <publisher-name>Van Nostrand Reinhold</publisher-name>
         </element-citation>
      </ref>
   </ref-list>
   
</back></article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-1052R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000754</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Sensory Systems</subject><subject>Neuroscience/Theoretical Neuroscience</subject><subject>Neuroscience/Natural and Synthetic Vision</subject></subj-group></article-categories><title-group><article-title>Vertical Binocular Disparity is Encoded Implicitly within a Model Neuronal Population Tuned to Horizontal Disparity and Orientation</article-title><alt-title alt-title-type="running-head">Implicit Encoding of Vertical Disparity</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Read</surname><given-names>Jenny C. A.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group><aff id="aff1">          <addr-line>Institute of Neuroscience, Newcastle University, Newcastle upon Tyne, United Kingdom</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Maloney</surname><given-names>Laurence T.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">New York University, United States of America</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">j.c.a.read@ncl.ac.uk</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: JCAR. Performed the experiments: JCAR. Analyzed the data: JCAR. Wrote the paper: JCAR.</p></fn>
<fn fn-type="conflict"><p>The author has declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>4</month><year>2010</year></pub-date><pub-date pub-type="epub"><day>22</day><month>4</month><year>2010</year></pub-date><volume>6</volume><issue>4</issue><elocation-id>e1000754</elocation-id><history>
<date date-type="received"><day>3</day><month>9</month><year>2009</year></date>
<date date-type="accepted"><day>22</day><month>3</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2010</copyright-year><copyright-holder>Jenny C. A. Read</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Primary visual cortex is often viewed as a “cyclopean retina”, performing the initial encoding of binocular disparities between left and right images. Because the eyes are set apart horizontally in the head, binocular disparities are predominantly horizontal. Yet, especially in the visual periphery, a range of non-zero vertical disparities do occur and can influence perception. It has therefore been assumed that primary visual cortex must contain neurons tuned to a range of vertical disparities. Here, I show that this is not necessarily the case. Many disparity-selective neurons are most sensitive to changes in disparity orthogonal to their preferred orientation. That is, the disparity tuning surfaces, mapping their response to different two-dimensional (2D) disparities, are elongated along the cell's preferred orientation. Because of this, even if a neuron's optimal 2D disparity has zero vertical component, the neuron will still respond best to a non-zero vertical disparity when probed with a sub-optimal horizontal disparity. This property can be used to decode 2D disparity, even allowing for realistic levels of neuronal noise. Even if all V1 neurons at a particular retinotopic location are tuned to the expected vertical disparity there (for example, zero at the fovea), the brain could still decode the magnitude and sign of departures from that expected value. This provides an intriguing counter-example to the common wisdom that, in order for a neuronal population to encode a quantity, its members must be tuned to a range of values of that quantity. It demonstrates that populations of disparity-selective neurons encode much richer information than previously appreciated. It suggests a possible strategy for the brain to extract rarely-occurring stimulus values, while concentrating neuronal resources on the most commonly-occurring situations.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>Because our eyes are set apart horizontally in our head, the images they see are mainly offset horizontally. However, small vertical disparities also occur, and can have a measurable effect on perception, showing that they must be detected by the visual system. The trouble is that encoding a two-dimensional quantity is much more expensive for neuronal systems than encoding a one-dimensional quantity. This paper shows that, for two-dimensional disparity, the brain could potentially take advantage of a major simplification. This strategy would avoid the need to build neurons tuned to a range of vertical disparities at each retinotopic location. For example, at the centre of the visual field, vertical disparities are almost always zero. The brain could make sure all its neurons at this location respond best to zero vertical disparity, ensuring best performance for the most common disparities. But the brain would still know what the vertical disparity actually was, which would be useful on rare occasions where it was not zero, e.g., when the eyes are misaligned. This is an interesting example because usually, neuronal populations which are all tuned to the same value of a quantity cannot encode that quantity (e.g., a retina with only one type of cone cell cannot encode color).</p>
</abstract><funding-group><funding-statement>This research was supported by Royal Society University Research Fellowship UF041260 (<ext-link ext-link-type="uri" xlink:href="http://www.royalsociety.org" xlink:type="simple">www.royalsociety.org</ext-link>) and Medical Research Council New Investigator Award 80154 (<ext-link ext-link-type="uri" xlink:href="http://www.mrc.ac.uk" xlink:type="simple">www.mrc.ac.uk</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="15"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>It is commonly accepted that in order for a neuronal population to encode the value of a quantity x, it must contain cells tuned to a range of values of x. Thus for example the retina can encode information about the wavelength of light because it contains three different types of cones with different tuning to wavelength, and the primary visual cortex can encode feature orientation because it contains neurons tuned to a range of orientations. This is unproblematic because natural images contain a wide range of light wavelengths and object orientations. However, the same argument applied to stereo vision produces some more challenging conclusions.</p>
<p>The expected vertical disparity in natural viewing depends on position in the retina, with opposite signs in opposite quadrants of the visual field. The range in vertical disparities encountered at a given position depends on a number of assumptions about eye movement and scene statistics, but all attempts to estimate it agree that it is extremely narrowly distributed compared to horizontal disparity <xref ref-type="bibr" rid="pcbi.1000754-Liu1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Hibbard1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Read1">[3]</xref>. Thus, if disparity sensors in the brain were to reflect disparity in the natural world, we would expect the distribution of two-dimensional disparity tuning at a given retinotopic location to be highly elongated, virtually one-dimensional, with a wide range of horizontal disparity and a narrow range of vertical disparity, centered on the value expected for that retinotopic location. Yet, vertical disparities which hardly ever occur in normal visual experience can still have demonstrable effects on perception in the lab <xref ref-type="bibr" rid="pcbi.1000754-Helmholtz1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Ogle1">[5]</xref>, and there is evidence that stereo matching occurs in all 2D directions, vertical as well as horizontal <xref ref-type="bibr" rid="pcbi.1000754-Farell1">[6]</xref>. Thus, the brain clearly can extract unusual vertical disparities, on relatively local scales <xref ref-type="bibr" rid="pcbi.1000754-SerranoPedraza1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Rogers1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Kaneko1">[9]</xref>. This has led to the conclusion that the brain must contain neurons tuned to a range of vertical disparities, including highly unusual ones, on the assumption that otherwise, these disparities could not be perceived <xref ref-type="bibr" rid="pcbi.1000754-Durand1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Durand2">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Gonzalez1">[12]</xref>.</p>
<p>Motivated by this, a number of physiological studies have examined two-dimensional disparity tuning in cortical neurons in monkey primary visual cortex (V1). Near the fovea, most disparity-tuned neurons are tuned to vertical disparities which are not significantly different from zero, given the confidence interval on the measurement <xref ref-type="bibr" rid="pcbi.1000754-Cumming1">[13]</xref>. In the visual periphery, neurons tuned to non-zero vertical disparities have been reported <xref ref-type="bibr" rid="pcbi.1000754-Durand1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Durand2">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Gonzalez1">[12]</xref>. Unfortunately, these studies only reported disparity in head-centric coordinates, which can differ substantially from retino-centric disparity <xref ref-type="bibr" rid="pcbi.1000754-Read2">[14]</xref>. For example, it is perfectly possible for a neuron tuned to a substantial head-centric vertical disparity, say 0.3°, to be tuned to a vertical disparity of 0° on the retina <xref ref-type="bibr" rid="pcbi.1000754-Read1">[3]</xref>. Thus, the published data do not enable us to draw any conclusions about 2D disparity tuning on the retina. Furthermore, these studies did not report the retinal location of individual neurons, making it impossible to assess whether a range of vertical disparity tuning is found at a single retinotopic location.</p>
<p>Given this lack of data from physiology, theoretical considerations become important. A clear understanding of how, in principle, neurons could represent two-dimensional disparity is essential for guiding future physiology experiments. We recently argued <xref ref-type="bibr" rid="pcbi.1000754-Read3">[15]</xref> that a population of model binocular neurons like that shown in <xref ref-type="fig" rid="pcbi-1000754-g001">Figure 1</xref>, tuned to a range of horizontal disparities and orientations but all tuned to zero vertical disparity on the retina, nevertheless encodes information about the vertical disparity of the stimulus. This original model only extracted the magnitude, not the sign, of the local vertical disparity, and we later demonstrated that this was inconsistent with human psychophysics <xref ref-type="bibr" rid="pcbi.1000754-SerranoPedraza2">[16]</xref>. However, this model did not make optimal use of the information available in the population. In the present paper, I show that this population of disparity sensors does contain information about both the magnitude and the sign of the vertical disparity at that point in the retina, even if all neurons in the population are tuned to the same vertical disparity. With an appropriate decoding technique, information about the two-dimensional disparity can be deduced from activity in this one-dimensional population. This result is of interest in its own right as a theoretical demonstration that it is possible to extract the value of a quantity from a neuronal population, all of whose members respond optimally to the same value of that quantity. From the point of view of understanding stereo vision, it means that two-dimensional disparity may be represented far more efficiently than previously appreciated.</p>
<fig id="pcbi-1000754-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g001</object-id><label>Figure 1</label><caption>
<title>A neuronal population which explicitly encodes horizontal, but not vertical, disparity.</title>
<p>The shaded region represents the space of two-dimensional disparity on the retina <xref ref-type="bibr" rid="pcbi.1000754-Read2">[14]</xref>. The purple disks represent the preferred 2D disparity of an idealized population of disparity sensors. Although these sensors form a one-dimensional population, all tuned to zero vertical disparity, they can nevertheless encode two-dimensional stimulus disparity, e.g. the stimulus disparity represented by the green dot, which has both a horizontal and a vertical component. (Cf <xref ref-type="fig" rid="pcbi-1000754-g001">figure 1</xref> of Serrano-Pedraza &amp; Read <xref ref-type="bibr" rid="pcbi.1000754-SerranoPedraza2">[16]</xref>.)</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g001" xlink:type="simple"/></fig></sec><sec id="s2" sec-type="methods">
<title>Methods</title>
<sec id="s2a">
<title>Overview</title>
<p>The essential insight guiding this paper is relatively trivial. According to the stereo energy model of disparity-selective neurons <xref ref-type="bibr" rid="pcbi.1000754-Ohzawa1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Ohzawa2">[18]</xref>, cells with obliquely-oriented receptive fields will also have obliquely-oriented disparity tuning surfaces, like the one illustrated in <xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2A</xref>. This cell's optimal disparity is marked with a red circle. It has zero vertical component, i.e. the cell responds best to zero vertical disparity. <xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2B</xref> shows two cross-sections through this surface, corresponding to vertical disparity tuning curves for two different horizontal disparities, as indicated by the vertical lines in <xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2A</xref>. At the optimal horizontal disparity (red curve), the cell responds best to zero vertical disparity. But at horizontal disparities away from the optimum (e.g. purple curve), the cell's response is reduced, but is now tuned to a non-zero vertical disparity. Thus, while the cell in <xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2</xref> is “tuned to zero vertical disparity” in that its optimum 2D disparity has zero vertical component, when it is probed at horizontal disparities on either side of the optimum, it responds best to vertical disparities on either side of zero. This suggests that, given cells tuned to a range of orientations and horizontal disparities, one could potentially extract the stimulus orientation, horizontal disparity <italic>and</italic> vertical disparity. Of course, it may not be quite that simple. In order to use the cells' tuning to vertical disparity away from the optimal horizontal disparity, one has to know what the horizontal disparity is. Extracting this may be hard in the presence of vertical disparity, since then none of the cells in the population is tuned to the correct stimulus disparity. Also, because the tuning to vertical disparity occurs only at sub-optimal horizontal disparities, the neuron's activity is weaker, so more subject to noise. Thus, this intuitive idea has to be rigorously tested by simulation. This is what is achieved in this paper.</p>
<fig id="pcbi-1000754-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g002</object-id><label>Figure 2</label><caption>
<title>Cells with obliquely oriented 2D disparity tuning surfaces are tuned to non-zero vertical disparities at non-optimal horizontal disparities.</title>
<p>A: 2D disparity tuning surface. The preferred 2D disparity is marked with a red circle: it has no vertical component. B: 1D disparity tuning curves showing neuron's response to vertical disparity, at the horizontal disparities marked with the red and purple lines in A. At the non-optimal horizontal disparity (purple curve), the neuron responds best to non-zero vertical disparities.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g002" xlink:type="simple"/></fig>
<p>The simulations consist of two neuronal populations: one encoding population, which takes left and right retinal images and performs the initial encoding of binocular disparity, and one decoding population, which estimates the disparity of the stimulus. The encoding population is like that in <xref ref-type="fig" rid="pcbi-1000754-g001">Figure 1</xref>: it consists of a set of neurons tuned to a range of horizontal disparities, orientations and spatial frequencies, but all tuned to the same vertical disparity. For simplicity, I shall set this vertical disparity to be zero, which is appropriate for the parafoveal region.</p>
<p>The encoding neurons are based on the stereo energy model <xref ref-type="bibr" rid="pcbi.1000754-Ohzawa1">[17]</xref>, normalized so as to report the effective local binocular correlation <xref ref-type="bibr" rid="pcbi.1000754-Read3">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Banks1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Filippini1">[20]</xref>. The activity of this population is then decoded by a separate, higher-level population, using a template-matching approach like that of Tsai &amp; Victor <xref ref-type="bibr" rid="pcbi.1000754-Tsai1">[21]</xref>. The synaptic weights from the encoding to the decoding population store the mean response of the population to stimuli with a range of different two-dimensional disparities. To estimate the two-dimensional disparity of a test image, I simply calculate the correlation between the population response to the test image, and the stored average population response for each known 2D disparity. The stimulus disparity is taken to be that giving the highest correlation, i.e. the best match to the mean response.</p>
</sec><sec id="s2b">
<title>Disparity encoding</title>
<sec id="s2b1">
<title>Receptive fields</title>
<p>The monocular receptive fields were Gabor functions varying in their preferred orientation θ, spatial frequency f, receptive field size σ, receptive field phase φ, and position on the retina (<xref ref-type="fig" rid="pcbi-1000754-g003">Figure 3</xref>). The two receptive fields of a given binocular neurons always had the same orientation, frequency and size, but could differ in their phase and position, reflecting the properties of real neurons in primary visual cortex <xref ref-type="bibr" rid="pcbi.1000754-DeAngelis1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Anzai1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Prince1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Bridge1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Read4">[26]</xref>. Thus, the model binocular simple cells in general had both position and phase disparity <xref ref-type="bibr" rid="pcbi.1000754-DeAngelis1">[22]</xref>. All model binocular simple cells were tuned to the same cyclopean position, which was the origin. That is, the mean of the receptive field centers in the left and right eyes was (0,0) for all cells.</p>
<fig id="pcbi-1000754-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g003</object-id><label>Figure 3</label><caption>
<title>Example receptive fields in the two eyes.</title>
<p>The columns show the 5 different spatial frequencies, f; the receptive field envelope σ was set to 0.25/f. The two rows show 2 different phases φ: top row, even phase (φ = 0), bottom row, odd phase (φ = π/2). θ and Δx are chosen randomly in each plot from the values included in the population. Matlab code to generate this figure is <xref ref-type="supplementary-material" rid="pcbi.1000754.s001">Protocol S1</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g003" xlink:type="simple"/></fig>
<p>The aim of this study is to demonstrate that vertical disparity can be implicitly encoded by a population of neurons that are all tuned to a single vertical disparity. Here, I choose this single vertical disparity tuning to be zero, reflecting the vertical disparity expected at the fovea, (0,0). At other retinotopic locations, a different value would be appropriate, reflecting the expected vertical disparity at that location <xref ref-type="bibr" rid="pcbi.1000754-Read2">[14]</xref>. The particular value chosen is not important to the demonstration, only the fact that it is the same for all neurons in the population. Including phase disparity in the model makes this slightly more complicated, since for neurons tuned to non-vertical orientations, phase disparity adds both a horizontal and a vertical component to the preferred disparity. To deal with this, each neuron is given a position disparity chosen to cancel out the component introduced by the phase disparity. Thus, even in considering a single neuron, there are several different meanings of disparity to distinguish. In this paper, Δ<italic>x</italic><sub>enc</sub> will indicate the preferred horizontal disparity of an encoding neuron, i.e. the horizontal disparity which elicits its maximum firing rate (the preferred vertical disparity of all encoding neurons is Δ<italic>y</italic><sub>enc</sub> = 0). Δφ indicates the phase disparity of an encoding neuron. Finally (Δ<italic>x</italic><sub>pos</sub>,Δ<italic>y</italic><sub>pos</sub>) indicates the two-dimensional position disparity, chosen to be<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e001" xlink:type="simple"/><label>(1)</label></disp-formula>For sufficiently narrow-band cells, this ensures that the neuron is tuned to the desired horizontal disparity of Δ<italic>x</italic><sub>enc</sub>, and to zero vertical disparity.</p>
<p>The left and right eye receptive fields of the binocular simple cell tuned to orientation θ, frequency f, receptive field size σ, phase φ and horizontal disparity Δx are then<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e002" xlink:type="simple"/><label>(2)</label></disp-formula>where x′ and y′ are retinal coordinates offset to the centre of the receptive field, and rotated to line up with the cell's preferred orientation:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e003" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e004" xlink:type="simple"/></disp-formula>taking the + signs for <italic>x</italic>′<sub>L</sub>, <italic>y</italic>′<sub>L</sub>, and the − minus signs for <italic>x</italic>′<sub>R</sub>, <italic>y</italic>′<sub>R</sub>, and where the position disparity (Δ<italic>x</italic><sub>pos</sub>,Δ<italic>y</italic><sub>pos</sub>) is as specified in Equation 1.</p>
<p>The population included a range of values for preferred orientation θ, spatial frequency <italic>f</italic>, receptive field size σ, phase φ, phase disparity Δφ and horizontal disparity Δ<italic>x</italic><sub>enc</sub> , as follows:</p>
<list list-type="simple"><list-item>
<p>Orientation θ: 6 values, −60°, −30°, 0°, 30°, 60° and 90°. 90° is horizontal, 0° is vertical.</p>
</list-item><list-item>
<p>Phase φ: 2 values, 0 or π/2 (this is all that is needed to achieve a phase-invariant complex cell)</p>
</list-item><list-item>
<p>Horizontal position disparity Δ<italic>x</italic><sub>enc</sub>: 21 values, −10 to 10 pixels in steps of 1 pixel.</p>
</list-item><list-item>
<p>Spatial frequency: 5 values, 0.200, 0.112, 0.0707, 0.0420, 0.0250 cycles per pixel, corresponding to spatial periods λ of 5.00, 8.41, 14.14, 23.81, 40.00 pixels. Receptive field size σ was set equal to 0.35λ.</p>
</list-item><list-item>
<p>Phase disparity Δφ: 5 values, 0, ±π/4 and ±π/2.</p>
</list-item></list>
<p>Thus, there were 6×2×21×5×5 = 6300 binocular simple cells. These values were chosen to maximize physiological plausibility while giving reasonable simulation run-times. The different parameters have different effects on the model's performance. Self-evidently, sensitivity to a range of horizontal disparities is essential. The model's ability to extract the sign of vertical disparity depends on neurons tuned to oblique orientations (<xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2</xref>). A range of spatial frequencies is not required for the model to extract vertical disparity in principle, but does improve the range of vertical disparity magnitudes over which the model performs well. For small vertical disparities, neurons tuned to high spatial frequencies are most sensitive to the disparity. For large vertical disparities, it is neurons tuned to low spatial frequencies which are most informative, since only these have receptive fields large enough to detect the disparity. A range of phase and phase disparity is not necessary for the model to work in principle, but helps to improve the model's accuracy <xref ref-type="bibr" rid="pcbi.1000754-Read5">[27]</xref>.</p>
</sec><sec id="s2b2">
<title>Stereo energy model</title>
<p>The output from each receptive field was taken to be the inner product of each eye's image I(x,y) with the corresponding receptive field:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e005" xlink:type="simple"/></disp-formula>and similarly for <italic>v</italic><sub>R</sub>. <italic>I</italic>(<italic>x</italic>,<italic>y</italic>) represents the contrast of the image at the point (<italic>x</italic>,<italic>y</italic>) relative to the mean luminance: positive values represent bright pixels, and negative values dark ones. In the standard energy model <xref ref-type="bibr" rid="pcbi.1000754-Ohzawa1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Ohzawa2">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Qian1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Qian2">[29]</xref>, the response of binocular simple cells would be<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e006" xlink:type="simple"/></disp-formula>It will be convenient to split this into monocular and binocular terms:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e007" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e008" xlink:type="simple"/></disp-formula>Energy-model complex cells, which are invariant to stimulus phase, are built by summing the response of binocular simple cells tuned to different phases:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e009" xlink:type="simple"/><label>(3)</label></disp-formula>As noted in the previous section, my population of simple cells includes only two values of phase, 90° apart. This produces the same results as summing over large number of simple cells with randomly-scattered phase, and is thus a widely-used short-cut in simulating complex-cell responses <xref ref-type="bibr" rid="pcbi.1000754-Qian1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Adelson1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Fleet1">[31]</xref>.</p>
<p>The stereo energy, E, represents something close to the cross-correlation function between the filtered, windowed images. The problem with using this to extract stimulus disparity is that it reflects not only the degree of similarity between the shifted left- and right-eye images, but also their monocular contrast energy. Thus an energy-model unit may respond strongly either because it is genuinely tuned to the stimulus disparity, or because both its monocular receptive fields happen to contain features which drive them well – whether or not those features match between the eyes. This makes it difficult to extract stimulus disparity from the stereo energy computed in Equation 3.</p>
</sec><sec id="s2b3">
<title>Effective binocular correlation</title>
<p>To overcome this, I based my template-matching on the response of normalized correlation detectors <xref ref-type="bibr" rid="pcbi.1000754-Read3">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Banks1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Filippini1">[20]</xref>. These are based on the stereo energy model, but are normalized so that their response ranges between +1 (when the left and right images are identical), and −1 (when the left image is an inverted version of the right). This is achieved by dividing the binocular terms of the energy-model complex cell by the monocular terms:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e010" xlink:type="simple"/><label>(4)</label></disp-formula>Physiologically, this could be computed by combining the outputs of energy-model neurons with phase-disparities π apart. If two neurons are identical except that their phase-disparities are π apart, then if the first neuron computes E = (M+B), the second will compute (M−B). M and B are then available from the sum and difference of this pair of neurons. Thus the simulations implicitly use the full range of phase disparity, even though only phase disparity in the range [−π/2,+π/2] is explicitly simulated.</p>
<p>The quantity <italic>C</italic> computes the correlation coefficient between filtered, local regions of the left and right eye's images <xref ref-type="bibr" rid="pcbi.1000754-Read5">[27]</xref>. It can be thought of as the effective binocular correlation experienced by that cell, and takes values in the range [−1,1]. To avoid any later confusion, note that this correlation is quite distinct from the Pearson product-moment correlation coefficient used below to assess how well population activity elicited by a test stimulus matches a template.</p>
<p>I view the population of binocular correlation detectors, <italic>C</italic>(<italic>θ</italic>, <italic>f</italic>,Δφ,Δ<italic>x</italic><sub>enc</sub>), as performing the initial encoding of disparity within my model. Recall that there are 6 different orientations, 5 different frequencies, 5 different phase disparities and 21 different horizontal disparities, so the population <italic>C</italic>(<italic>θ</italic>, <italic>f</italic>,Δφ,Δ<italic>x</italic><sub>enc</sub>) consists of 3150 different correlation-detectors.</p>
<p>Normalizing the stereo energy <italic>E</italic> so as to obtain the effective binocular correlation <italic>C</italic> removes the confounding effect of monocular contrast, making it much easier to extract the stimulus disparity from peaks in the population activity. <italic>C</italic> has the useful property that it is exactly equal to 1 when the stimulus disparity matches the cell's preferred disparity. This is true for <italic>any</italic> pair of stereo images, irrespective of spectral content etc, provided only that the left eye's image is related to the right eye's image by exactly the same offset relating left and right receptive fields. Under these circumstances, <italic>v</italic><sub>L</sub>(<italic>θ, f,φ,Δφ,Δx</italic><sub>enc</sub>) = <italic>v</italic><sub>R</sub>(<italic>θ, f,φ,Δφ,Δx</italic><sub>enc</sub>) for all <italic>θ, f,φ,Δφ,Δx</italic><sub>enc</sub>; 2<italic>v</italic><sub>L</sub><italic>v</italic><sub>R</sub> is then the same as <italic>v</italic><sub>L</sub><sup>2</sup>+<italic>v</italic><sub>R</sub><sup>2</sup>, and it follows immediately that <italic>C</italic> = 1.</p>
</sec><sec id="s2b4">
<title>Noise</title>
<p>As <xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2</xref> makes clear, these neurons become effectively tuned to non-zero vertical disparities only when stimulated at their non-optimal horizontal disparity. Thus, in this model, vertical disparity is encoded only by neurons firing at below their optimal rate. Given this, it becomes important to be sure that this signal would not be lost in noise in a real neuronal population. To incorporate realistic neuronal noise, I convert the correlation <italic>C</italic>, which can take values [−1,1], into an observed spike count, which is necessarily positive or zero. First, I define the mean spike count, <italic>R</italic><sub>m</sub>, as <italic>R</italic><sub>m</sub> = <italic>U</italic>(1+<italic>C</italic>), where <italic>U</italic> is the mean number of spikes elicited by a binocularly uncorrelated stimulus. R<sub>m</sub> is in the range [0,2<italic>U</italic>], where 2<italic>U</italic> is the mean number of spikes a perfectly binocularly correlated stimulus elicits from neurons tuned to its disparity. I model neuronal noise as a Poisson process <xref ref-type="bibr" rid="pcbi.1000754-Dean1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Bair1">[33]</xref>. Thus, the actual number of spikes elicited by the stimulus on any given presentation is <italic>R</italic>, where <italic>R</italic> is a random variable drawn from a Poisson distribution with mean <italic>R</italic><sub>m</sub>.</p>
<p>The effective level of neuronal noise then depends on the value chosen for <italic>U</italic>. This will depend on the neurons' maximal firing rate and the length of time assumed to be available for the judgment. If we assume that the firing rate for the optimal disparity is 100Hz <xref ref-type="bibr" rid="pcbi.1000754-Prince2">[34]</xref> and that the neuronal response is averaged over a 160ms window (since humans can discriminate temporal changes in disparity up to ∼6Hz, <xref ref-type="bibr" rid="pcbi.1000754-Norcia1">[35]</xref>), this suggests that the most active neurons might fire 16 spikes in the time available for a disparity judgment, yielding an estimate of around 8 spikes for <italic>U</italic>. Since the variance of Poisson noise is equal to its mean, larger values of <italic>U</italic> produce lower noise, and smaller values would mean greater neuronal noise. In fact, as I discuss below, the model is extremely resilient to neuronal noise. To demonstrate this, the results presented here use <italic>U</italic> = 1. This means that the average neuron fires only 1 spike in the time available for a perceptual judgment, resulting in a very large amount of neuronal noise (coefficient of variance 70% for even optimally-tuned neurons).</p>
<p>Variation in the stimuli also contributes an additional effective source of noise. In this model, a stereo stimulus where left and right images are related simply by a shift will always produce an effective binocular correlation of <italic>C</italic> = 1 in neurons tuned to the disparity of the stimulus. However, neurons which are not tuned to the stimulus will produce a correlation which is on average less than 1, but whose precise value depends on the particular properties of the image, e.g. where the regions of high and low contrast happen to fall in relation to the receptive fields. When it comes to estimating the disparity of a single image, this stimulus-driven variation in response has the same deleterious effect as neuronal noise. If the stimulus disparity has a vertical component, it will stimulate none of the neurons optimally, meaning that <italic>C</italic> will be less than 1 (thus variable) for all neurons, and the neurons will be firing at a lower rate (thus subject to more Poisson noise). Thus, both sources of noise are larger for stimuli with vertical disparity.</p>
</sec></sec><sec id="s2c">
<title>Disparity decoding</title>
<sec id="s2c1">
<title>Storing templates</title>
<p>The first step was to generate many examples of the population's response to stimuli of known disparity. These “template” stimuli were uniform-disparity random noise patterns. Each pixel in the left eye's image, <italic>I</italic><sub>L</sub>, was given a random value drawn from a Gaussian with zero mean and unit standard deviation. The right eye's image, <italic>I</italic><sub>R</sub>, was offset horizontally and/or vertically from the first eye's image, and new random pixels were generated to fill the gap (<xref ref-type="fig" rid="pcbi-1000754-g004">Figure 4</xref>).</p>
<fig id="pcbi-1000754-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g004</object-id><label>Figure 4</label><caption>
<title>Example image-pair.</title>
<p>These have horizontal disparity 2 pixels and vertical disparity 1 pixel. For clarity, these images are just 9×9 pixels; the actual images used in the simulations were 81×81 pixels. The colored dot marks corresponding pixels in the left and right images; the pink arrow shows the disparity vector. Matlab code to generate this figure is <xref ref-type="supplementary-material" rid="pcbi.1000754.s002">Protocol S2</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g004" xlink:type="simple"/></fig>
<p>I produced random noise images with different horizontal and vertical disparities Δ<italic>x</italic><sub>stim</sub> and Δ<italic>y</italic><sub>stim</sub>. Δ<italic>x</italic><sub>stim</sub> and Δ<italic>y</italic><sub>stim</sub> both ranged from −10 to 10 pixel in steps of 1 pixel, making a total of 441 different two-dimensional stimulus disparities. At each of these 441 stimulus disparities, I generated 500 random image-pairs, each generated with a different random seed <italic>j</italic>, making a total of 220,500 test stereograms.</p>
<p>For each image-pair (Δ<italic>x</italic><sub>stim</sub>,Δ<italic>y</italic><sub>stim</sub>, <italic>j</italic>), I calculated the effective binocular correlation as described in Equation 4. I converted this to a mean spike count, and averaged this over 500 different random images, to obtain<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e011" xlink:type="simple"/><label>(5)</label></disp-formula><italic>W</italic> is the mean number of spikes produced by sensors tuned to orientation θ, frequency <italic>f</italic>, phase disparity Δφ and horizontal disparity tuning Δ<italic>x</italic><sub>enc</sub>, when averaged over many different presentations of many different noise images with the same 2D stimulus disparity (Δ<italic>x</italic><sub>stim</sub>,Δ<italic>y</italic><sub>stim</sub>). The averaging over different presentations of the same image removes the neuronal noise, while the averaging over different images removes stimulus-dependent noise. I envisage this as representing the information stored in the system as a result of visual experience.</p>
</sec><sec id="s2c2">
<title>Template matching</title>
<p>The disparity of an unknown test stimulus can then be estimated by comparing the response of the population to that particular test image with the stored, average response elicited by stimuli with known two-dimensional disparity. The stimulus is taken to have the 2D disparity whose stored activity profile best matches the current activity <xref ref-type="bibr" rid="pcbi.1000754-Tsai1">[21]</xref>.</p>
<p>Let <italic>R</italic><sub>test</sub>(<italic>θ</italic>, <italic>f</italic>, Δ<italic>φ</italic>, Δ<italic>x<sub>enc</sub></italic>) be the number of spikes fired by the encoding population to the particular test image under consideration. Remember that this neuronal population includes cells tuned to 6 different orientations θ, 5 different frequencies <italic>f</italic>, 5 different phase disparities and 21 different horizontal disparities Δ<italic>x</italic><sub>enc</sub>, so <italic>R</italic><sub>test</sub>(<italic>θ</italic>, <italic>f</italic>, Δ<italic>φ</italic>, Δ<italic>x</italic><sub>enc</sub>) is a set of 3150 individual spike-counts. To estimate the disparity of the test stimulus, I compare the population's response to the test image, <italic>R</italic><sub>test</sub>(θ, <italic>f</italic>, Δ<italic>φ</italic>, Δ<italic>x<sub>enc</sub></italic>), with the stored mean spike-counts, W, for each of the 441 template stimulus disparities. That is, for each possible two-dimensional disparity (Δ<italic>x</italic><sub>dec</sub>, Δ<italic>y</italic><sub>dec</sub>) (subscript “dec” for decoding), I calculate the Pearson correlation coefficient, <italic>r</italic>(Δ<italic>x</italic><sub>dec</sub>, Δ<italic>y</italic><sub>dec</sub>), between the set of 3150 spike-counts obtained for this particular test image, <italic>R</italic><sub>test</sub>(θ, <italic>f</italic>, Δφ, Δ<italic>x<sub>enc</sub></italic>), and the set of 3150 values stored in <italic>W</italic>(<italic>θ</italic>, <italic>f</italic>, Δ<italic>φ</italic>,Δ<italic>x</italic><sub>enc</sub>;Δ<italic>x</italic><sub>dec</sub>, Δ<italic>y</italic><sub>dec</sub>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e012" xlink:type="simple"/></disp-formula>where Corr(a,b) represents the usual Pearson product-moment correlation coefficient between a and b:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e013" xlink:type="simple"/><label>(6)</label></disp-formula>where the sum Σ, averages &lt;&gt; and standard deviations std are all taken over <italic>θ</italic>, <italic>f</italic>, Δ<italic>φ</italic>, Δ<italic>x</italic><sub>enc</sub>, while holding Δ<italic>x</italic><sub>dec</sub> and Δ<italic>y</italic><sub>dec</sub> constant.</p>
<p>I shall always use the word Pearson when referring to this correlation, in order to avoid possible confusion with the effective binocular correlation computed by the encoding neurons, Equation 4. In the figures, I shall use a “jet” colormap (running from blue-green-red) to represent spike-counts based on effective binocular correlation, and a “hot” colormap (black-red-yellow-white) to represent Pearson correlation.</p>
<p>To model the lack of sensitivity to disparity in anti-correlated stereograms <xref ref-type="bibr" rid="pcbi.1000754-Cogan1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Read6">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Tanabe1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Janssen1">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Cumming2">[40]</xref>, I finally set any negative correlations to zero, computing<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.e014" xlink:type="simple"/><label>(7)</label></disp-formula>where ⌊⌋ indicates halfwave rectification: ⌊<italic>x</italic>⌋ = <italic>x</italic> for <italic>x</italic>&gt;0, and zero otherwise.</p>
<p>The two-dimensional disparity of the test stimulus is then taken to be the values (Δ<italic>x</italic><sub>dec</sub>, Δ<italic>y</italic><sub>dec</sub>) which maximizes the halfwave-rectified Pearson correlation <italic>P</italic>(Δ<italic>x</italic><sub>dec</sub>,Δ<italic>y</italic><sub>dec</sub>).</p>
<p>Matlab code (The Mathworks, Natick, MA; <ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com" xlink:type="simple">www.mathworks.com</ext-link>) to run the simulations and generate most of the figures is available as Supplementary Material (although due to the size of the neuronal populations, running all the simulations presented in this paper takes weeks). Details of which functions to use are given in each figure legend. Other functions called by this code are grouped together in the file <xref ref-type="supplementary-material" rid="pcbi.1000754.s011">Protocol S11</xref>.</p>
</sec></sec></sec><sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>All members of the neuronal population are tuned to zero vertical disparity</title>
<p>First, it is important to establish that – despite their wide range in phase disparity, position disparity and orientation – all the units in our encoding population genuinely are tuned to zero vertical disparity. To this end, <xref ref-type="fig" rid="pcbi-1000754-g005">Figure 5</xref> shows two-dimensional disparity tuning surfaces for 15 example members of the model population of 3150 neurons. Disparity tuning surfaces like this have been measured for real neurons by Cumming <xref ref-type="bibr" rid="pcbi.1000754-Cumming1">[13]</xref>, Durand et al, <xref ref-type="bibr" rid="pcbi.1000754-Durand1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Durand2">[11]</xref> and Gonzalez et al <xref ref-type="bibr" rid="pcbi.1000754-Gonzalez1">[12]</xref>. Each panel in <xref ref-type="fig" rid="pcbi-1000754-g005">Figure 5</xref> shows the disparity tuning surface for a different model neuron in the encoding population. The pseudocolor represents the mean number of spikes fired by that neuron to stimuli with a given disparity, averaged over many different random noise images. All the neurons shown have the same spatial frequency, f = 0.071cyc/pix, and preferred horizontal disparity, Δ<italic>x</italic><sub>enc</sub> = 6pix. The three rows show neurons tuned to different orientations: vertical, oblique and horizontal, as specified to the left of each row. The five columns show neurons with different phase-disparities Δ<italic>φ</italic>, as labelled at the top of each column. The phase disparity controls the symmetry of the disparity tuning surface: odd-symmetric for Δ<italic>φ</italic> = ±<italic>π</italic>/2, even-symmetric for Δ<italic>φ</italic> = 0, intermediate for Δ<italic>φ</italic> = ±<italic>π</italic>/4. As described in the <xref ref-type="sec" rid="s2">Methods</xref>, phase disparity shifts the preferred disparity in a direction orthogonal to the neuron's orientation. Model neurons in the encoding population were given just the right amount of position disparity (Equation 1) to cancel this out and place their peak sensitivity in the region expected for normal vision. This 2D position disparity (Δ<italic>x</italic><sub>pos</sub>,Δ<italic>y</italic><sub>pos</sub>) is indicated above each panel. When there is no phase disparity (Δ<italic>φ</italic> = 0, middle column), the position disparity is simply equal to the desired disparity tuning, here (6,0). Elsewhere, the model neurons have to be given additional amounts of vertical and/or horizontal position disparity in order to bring the preferred 2D disparity back to the desired value. The white cross in each panel marks the stimulus disparity which elicited the highest response from that neuron, averaged over the 500 images. In every case this is very close to (6,0), indicating that the position disparity specified in Equation 1 has had the desired effect. This was true for all 1350 neurons in our population, as well as the 15 examples shown in <xref ref-type="fig" rid="pcbi-1000754-g005">Figure 5</xref>, demonstrating that Equation 1 achieves its aim of making all neurons in the encoding population respond best to zero vertical disparity.</p>
<fig id="pcbi-1000754-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g005</object-id><label>Figure 5</label><caption>
<title>Disparity tuning surfaces for 15 example disparity-encoding neurons with different phase disparities and orientations.</title>
<p>Each panel represents the 2D disparity tuning surface for one neuron, that is, the mean spike count elicited from that neuron in response to stimuli with the two-dimensional disparity specified on the horizontal and vertical axes. Specifically, each panel shows W(θ,f,Δφ,Δx<sub>enc</sub>;Δx<sub>stim</sub>,Δy<sub>stim</sub>) (Equation 5), as a function of Δx<sub>stim</sub> and Δy<sub>stim</sub>, for Δx<sub>enc</sub> = 6pix, spatial frequency tuning <italic>f</italic> = 0.071cyc/pix, and the different θ and Δφ specified in the row/column labels. Each neuron's two-dimensional position disparity (Δx<sub>pos</sub>,Δy<sub>pos</sub>) is indicated at the top of each panel. This was set as in Equation 1, to ensure its preferred horizontal disparity is Δx<sub>enc</sub> (here 6pix) and its preferred vertical disparity is 0. The white cross marks the pixel for which the spike count was highest. The fact that this empirical preferred disparity closely agrees with the desired value (6,0) shows that the position disparity successfully cancels out any vertical component introduced by the phase disparity. Matlab code: The mean response was obtained with <xref ref-type="supplementary-material" rid="pcbi.1000754.s003">Protocol S3</xref>, averaging over 500 stimuli, and the figure was generated with <xref ref-type="supplementary-material" rid="pcbi.1000754.s004">Protocol S4</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g005" xlink:type="simple"/></fig></sec><sec id="s3b">
<title>Vertical disparity is implicitly encoded in the pattern of activity across the population</title>
<p>We now move to considering how stimulus vertical disparity is encoded within this population. To do this, instead of plotting the mean response of individual neurons to stimuli with different disparities, as was done in <xref ref-type="fig" rid="pcbi-1000754-g005">Figure 5</xref>, we now plot the mean response of many neurons to stimuli with a given disparity. This is what is shown in <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6</xref>.</p>
<fig id="pcbi-1000754-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g006</object-id><label>Figure 6</label><caption>
<title>Average population response, W(θ,f,Δφ,Δx<sub>enc</sub>;Δx<sub>stim</sub>,Δy<sub>stim</sub>), for different stimulus vertical disparities.</title>
<p>Only neurons with zero phase disparity are shown (the key features discussed in the text are the same for all phase disparities). The stimulus disparity is fixed in each panel, and the horizontal axis is the preferred horizontal disparity of the neurons (unlike <xref ref-type="fig" rid="pcbi-1000754-g005">Figure 5</xref>, where the neuron's preferred horizontal disparity was fixed in each panel and the horizontal axis was the horizontal disparity of the stimulus). Each panel shows the mean number of spikes which stimuli with this disparity elicit from 126 neurons, tuned to 21 different horizontal disparities Δx<sub>enc</sub> and 6 orientations θ, plotted on the horizontal and vertical axes respectively. The 5 panels in each row show sets of 126 neurons tuned to 5 different preferred spatial frequencies. Thus together each row shows the mean response of the zero-phase-disparity sub-population, 630 neurons, averaged over 500 random stimuli with the same stimulus disparity. The stimulus horizontal disparity, Δx<sub>stim</sub>, was set equal to −2 pixels throughout (marked with the arrow in each panel); the stimulus vertical disparity, Δy<sub>stim</sub>, was set to a different value in each row, as indicated to the left of each row. The colorscale is the same as in <xref ref-type="fig" rid="pcbi-1000754-g005">Figure 5</xref>, indicated on the right. Matlab code: The mean responses were obtained with <xref ref-type="supplementary-material" rid="pcbi.1000754.s003">Protocol S3</xref>, and the figure was generated with <xref ref-type="supplementary-material" rid="pcbi.1000754.s005">Protocol S5</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g006" xlink:type="simple"/></fig>
<p>Each row of <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6</xref> shows the average spike count, <italic>W</italic>(<italic>θ</italic>, <italic>f</italic>,Δ<italic>φ</italic>,Δ<italic>x</italic><sub>enc</sub>;Δ<italic>x</italic><sub>stim</sub>,Δ<italic>y</italic><sub>stim</sub>), for all zero-phase-disparity neurons in the population, elicited by one particular stimulus disparity (Δ<italic>x</italic><sub>stim</sub>,Δ<italic>y</italic><sub>stim</sub>). (The choice to display the 630 neurons with Δφ = 0 is arbitrary; qualitatively similar plots are obtained for the other phase disparities.) The 6 rows show the response of this population to 6 different stimulus vertical disparities Δy<sub>stim</sub>, as indicated to the left of each row. In each case the stimulus horizontal disparity is Δ<italic>x</italic><sub>stim</sub> = −2 pixels, marked with the arrow in each panel. Each panel shows <italic>W</italic>(<italic>θ</italic>, <italic>f</italic>,Δ<italic>φ</italic>,Δ<italic>x</italic><sub>enc</sub>;Δ<italic>x</italic><sub>stim</sub>,Δ<italic>y</italic><sub>stim</sub>) as a function of Δ<italic>x</italic><sub>enc</sub> (horizontal axis) and θ (vertical axis), for the spatial frequency <italic>f</italic> indicated at the top of the column. Thus, the 6 rows of <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6</xref> correspond to 6 of the 441 stored responses of this population, which will be used in our template-matching algorithm to extract an estimate of stimulus disparity.</p>
<p>The neurons above the arrow in each panel are those tuned to the horizontal disparity of the stimulus under consideration, Δ<italic>x</italic><sub>enc</sub> = Δ<italic>x</italic><sub>stim</sub>. As one would expect, the effective correlation is generally high in this region (dark red colors). The stimulus vertical disparity Δ<italic>y</italic><sub>stim</sub> is 4 pixels in row A, 2 pixels in row B, 0 pixels in row C, and so on as indicated to the left of each row. Although the cells in the population are tuned to many different horizontal disparities, Δ<italic>x</italic><sub>enc</sub>, they are all tuned to zero vertical disparity. Thus the middle row, <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6C</xref>, is the only case where any neurons are tuned to the exact two-dimensional disparity of the stimulus. Here, neurons with Δ<italic>x</italic><sub>enc</sub> = Δ<italic>x</italic><sub>stim</sub> = −2 have receptive fields which exactly match the binocular disparity of the stimulus. Their correlation is therefore <italic>C</italic> = 1 for every noise image with this disparity, and so the mean spike-count <italic>W</italic> = (1+<italic>C</italic>) is exactly 2. The mean spike-count falls below 2 to either side of the arrow, as the difference between the horizontal disparity of the stimulus and that preferred by the neurons increases. The rate of decrease depends on the spatial frequency channel, since this controls the size of the receptive fields. For the left-most column, <italic>f</italic> = 0.2 cycles/pixel, the standard deviation of the receptive field envelope, σ, is just 1.25 pixels. For the right-most column, <italic>f</italic> = 0.025 cycles/pixel and σ = 10 pixels, meaning that the effective correlation experienced by these neurons is still high even for neurons tuned to disparities several pixels away from the stimulus. The rate of decrease also depends on the orientation. In our model population, the receptive field envelopes are isotropic, but the rate of change of the receptive field function is still fastest orthogonal to the cell's preferred orientation <italic>θ</italic> (see <xref ref-type="fig" rid="pcbi-1000754-g003">Figure 3</xref>). Thus, for each spatial frequency channel, the rate of change along the horizontal direction is fastest for the vertically-oriented cells (<italic>θ</italic> = 0°), and slowest for the horizontally-oriented ones (<italic>θ</italic> = ±90°). This effect can be seen in <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6C</xref>: the red region of high correlation extends further to either side of the optimal disparity for the horizontally-oriented cells at the top and bottom of each panel.</p>
<p>The same effect of receptive-field size can be seen as we look at rows other than row C, thus increasing the distance between the neurons' preferred vertical disparity (0) and that of the stimulus. The peak response anywhere in the population declines as we move along a column away from Δ<italic>y</italic><sub>stim</sub> = 0, as described by Read &amp; Cumming <xref ref-type="bibr" rid="pcbi.1000754-Read3">[15]</xref>. Again, this decrease is most apparent for the higher-frequency channels, where receptive fields are smaller. For the highest-frequency channel (0.2 cyc/pix), where σ is just 1.25 pixels, a vertical disparity of −8 pixels (row F) is enough to make the portions of the images falling within the left and right-eye receptive fields completely uncorrelated. This means that the average binocular correlation is zero, and so with the spiking model I have adopted, the mean spike count is just 1, everywhere in the panel.</p>
<p>The most interesting, and informative, panels of <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6</xref> are those where the stimulus has a non-zero, but relatively small, vertical disparity (rows A,B,D,E). Here, the effective binocular correlation C has fallen below 1, but is still above zero. In this case, the red region of high spike-counts takes on a distinctive diagonal slant, whose direction depends on the sign of stimulus vertical disparity. Where stimulus vertical disparity is positive (rows A, B), spike-counts are highest for receptive fields tilted counter-clockwise from vertical (positive <italic>θ</italic>) when horizontal disparity is positive, and for receptive fields tilted clockwise from vertical (negative <italic>θ</italic>) when horizontal disparity is negative. When stimulus vertical disparity is negative (rows D, E, F), the situation is reversed. The reason is exactly the geometry sketched in <xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2</xref>. This slant is the “signature” of vertical disparity, and will enable us to decode vertical disparity from this population.</p>
</sec><sec id="s3c">
<title>2D stimulus disparity can be extracted from the response of this population</title>
<p><xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6</xref> showed the average response of a neuronal population, averaged across thousands of stimuli with the same disparity. As we have seen, this average response possesses a structure which reflects the vertical disparity of the stimulus. However, this averaging process conceals important features of the response to single images. Most importantly, the response of the neuronal population to single images is affected not only by the disparity, but also by the luminance features of the particular image. These features cancel out to nothing when averaged over many random images, but the brain cannot take advantage of this when estimating the disparity of a single image. The stereo correspondence problem is complicated by these “false matches” due to particular features of the image <xref ref-type="bibr" rid="pcbi.1000754-Fleet1">[31]</xref>. Normalizing stereo energy so as to calculate the effective binocular correlation <italic>C</italic> is enough to solve the problem in the absence of vertical disparity. Then, as explained in the <xref ref-type="sec" rid="s2">Methods</xref>, the stimulus horizontal disparity can be identified from the horizontal disparity tuning of the cell with <italic>C</italic> = 1 (mean spike count = 2<italic>U</italic>). However, when there is a mismatch between the cell's preferred vertical disparity and the vertical disparity of the stimulus, the correlation will not usually reach 1 even for cells tuned to the horizontal disparity of the stimulus, so the false-match problem creeps in again. Secondly, neuronal populations are subject to noise. In principle, this may be reduced by averaging either over a long time period, or over a large pool of neurons with similar tuning and independent noise. Here, I have made the conservative assumption that neither of these options is available, so the neuronal population is subject to very large amounts of trial-to-trial noise, with the coefficient of variation at least 70%.</p>
<p>To bring home just how much variation these two sources of noise contribute, <xref ref-type="fig" rid="pcbi-1000754-g007">Figure 7</xref> shows the spikes elicited in response to a single example test image, with stimulus disparity Δ<italic>x</italic><sub>stim</sub> = −2 and Δ<italic>y</italic><sub>stim</sub> = +2 pixels. For comparison, <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6B</xref> showed the average response of the same population to stimuli with this disparity, with both neuronal and stimulus-driven noise averaged away. The 5 panels of <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6B</xref> are thus the “template” which <xref ref-type="fig" rid="pcbi-1000754-g007">Figure 7</xref> is meant to match (though note that because up to 6 spikes were produced by the single presentation in <xref ref-type="fig" rid="pcbi-1000754-g007">Figure 7</xref>, while the mean number of spikes never rises above 2, different colorscales were used in the two plots). At first glance, the task might appear to be impossible, given the very high levels of noise. However, certain features of similarity are indeed detectable between <xref ref-type="fig" rid="pcbi-1000754-g007">Figure 7</xref> and <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6B</xref>. At the lower spatial frequencies (right-hand panels), where the stimulus vertical disparity is not so large as a fraction of receptive field size, there is a slight tendency for neurons tuned to the horizontal disparity of the stimulus, marked with the arrows, to fire more spikes. Similarly, the slanted structure of the most responsive region is already hinted at. Furthermore, recall that for reasons of space, <xref ref-type="fig" rid="pcbi-1000754-g006">Figures 6</xref> and <xref ref-type="fig" rid="pcbi-1000754-g007">7</xref> show only the 630 neurons with zero phase-disparity; once we include the other phase disparities, there are a further 2520 neurons whose instantaneous response can be matched to the corresponding template. As I show below, despite the major differences between the single-image response shown in <xref ref-type="fig" rid="pcbi-1000754-g007">Figure 7</xref> and its template shown in <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6B</xref>, the population provides enough information for the correct template to be reliably identified.</p>
<fig id="pcbi-1000754-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g007</object-id><label>Figure 7</label><caption>
<title>Neuronal spike counts, R<sub>test</sub>(θ,f,Δφ,Δx<sub>enc</sub>), elicited by a single presentation of a single test image, with stimulus disparity (Δx<sub>stim</sub>, Δy<sub>stim</sub>) = (−2, +2).</title>
<p>As in <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6</xref>, only neurons with zero phase disparity are shown, Δφ = 0. The different panels each show 126 neurons tuned to different spatial frequencies <italic>f</italic>, while 21 preferred horizontal disparity tunings Δx<sub>enc</sub> and 6 orientations θ are shown by the horizontal and vertical axes, respectively. In each panel, an arrow marks the neurons tuned to the horizontal disparity of the stimulus. The colorscale is the same in all panels. The average response of the population to all Gaussian-noise stimuli with this disparity was shown in <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6B</xref> (note different colorscale). This mean response differs from the single-stimulus response shown here because the latter is affected by stimulus-dependent variation, reflecting the properties of this particular image, and Poissonian noise on neuronal spiking. Matlab code: This figure was generated by <xref ref-type="supplementary-material" rid="pcbi.1000754.s006">Protocol S6</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g007" xlink:type="simple"/></fig>
<p>As described in the <xref ref-type="sec" rid="s2">Methods</xref>, I assess the quality of the match between the population response to a single image and the stored average population response by calculating the Pearson correlation coefficient between the two. <xref ref-type="fig" rid="pcbi-1000754-g008">Figure 8</xref> uses pseudocolor to show the Pearson correlation coefficients <italic>r</italic>(Δ<italic>x</italic><sub>dec</sub>,Δ<italic>y</italic><sub>dec</sub>) for all 441 disparities. The black cross marks the disparity of the stimulus. In this example, the highest Pearson correlation is obtained from the decoder tuned to this disparity, so for this single test image, the stimulus disparity is correctly extracted.</p>
<fig id="pcbi-1000754-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g008</object-id><label>Figure 8</label><caption>
<title>Response of the population of disparity decoders (before rectification) to a test image with horizontal disparity Δx<sub>test</sub> = −2pix, Δy<sub>test</sub> = +2pix, marked with the cross.</title>
<p>Each pixel in the plot represents a decoding neuron, tuned to the 2D disparity (Δx<sub>dec</sub>,Δy<sub>dec</sub>) indicated on the horizontal and vertical axes. The pseudocolor represents the Pearson correlation coefficient between the activity in the encoding population elicited by the test image, and the stored “templates” representing the mean activity to stimuli with disparity (Δx<sub>dec</sub>,Δy<sub>dec</sub>). The disparity of the test image was correctly estimated from the peak activity in the decoding population. Matlab code: This figure was also generated by <xref ref-type="supplementary-material" rid="pcbi.1000754.s006">Protocol S6</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g008" xlink:type="simple"/></fig>
<p><xref ref-type="fig" rid="pcbi-1000754-g009">Figure 9</xref> quantifies the accuracy with which this algorithm performs across many test images. The plots show frequency histograms for the estimated disparity (red for horizontal disparity, blue for vertical) for 1000 different random test images with a fixed disparity. None of the 1000 test images was in the set of 500 images used to obtain the template responses, although they were all Gaussian noise images like those in <xref ref-type="fig" rid="pcbi-1000754-g004">Figure 4</xref>. Each column in <xref ref-type="fig" rid="pcbi-1000754-g009">Figure 9</xref> shows results for a different test disparity (Δ<italic>x</italic><sub>test</sub>,Δ<italic>y</italic><sub>test</sub>). The root-mean-squared error between the disparity estimated for each test image and its actual value is given above each panel. The algorithm's performance does not depend on the horizontal disparity of the test image (provided, of course, that it falls within the range to which the encoding population is tuned), so the three particular horizontal disparities chosen are immaterial. In contrast, performance does depend strongly on the vertical disparity tested. The three rows of <xref ref-type="fig" rid="pcbi-1000754-g009">Figure 9</xref> show results for increasing vertical disparity magnitudes: A: Δ<italic>y</italic><sub>test</sub> = 0, B: Δ<italic>y</italic><sub>test</sub> = 2, C: Δ<italic>y</italic><sub>test</sub> = −4 pixels.</p>
<fig id="pcbi-1000754-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g009</object-id><label>Figure 9</label><caption>
<title>Results of estimating 2D stimulus disparity from the 1D disparity encoding population.</title>
<p>Each panel shows the distribution of the estimated disparity component (left column, red: horizontal disparity; right column, blue: vertical disparity). The rows show three different test disparities (Δx<sub>test</sub>,Δy<sub>test</sub>), as indicated by the black vertical lines in each column. In each case, 1000 images with the specified test disparity were generated, and their 2D disparity was estimated as being the value of (Δx<sub>dec</sub>,Δy<sub>dec</sub>) which gave the best match between the population activity R<sub>test</sub>(θ,f,Δφ, Δx<sub>enc</sub>) evoked by the test image, and the stored W(θ,f,Δφ,Δx<sub>enc</sub>;Δx<sub>dec</sub>,Δy<sub>dec</sub>), as in <xref ref-type="fig" rid="pcbi-1000754-g008">Figure 8</xref>. The root-mean-squared error between the estimated disparity and the correct value is indicated at the top of each panel. Matlab code: The disparity estimates were obtained with <xref ref-type="supplementary-material" rid="pcbi.1000754.s007">Protocol S7</xref>, and the figure was generated with <xref ref-type="supplementary-material" rid="pcbi.1000754.s008">Protocol S8</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g009" xlink:type="simple"/></fig>
<p>In <xref ref-type="fig" rid="pcbi-1000754-g009">Figure 9A</xref>, the test images had zero vertical disparity. Thus, the encoding population contains sensors tuned to the exact 2D disparity of the test images. Under these circumstances, unsurprisingly, both horizontal and vertical disparity are reconstructed with great accuracy. In <xref ref-type="fig" rid="pcbi-1000754-g009">Figure 9B</xref>, the test images had a vertical disparity of 2 pixels. An example population response to a single test image with this disparity was shown in <xref ref-type="fig" rid="pcbi-1000754-g007">Figure 7</xref>, while the template response (averaged over many training images with this disparity) was shown in <xref ref-type="fig" rid="pcbi-1000754-g006">Figure 6B</xref>. Here, no sensors in the encoding population are tuned to the 2D disparity of the stimulus. This naturally reduces the accuracy, but the RMS error is still only half a pixel. Critically, both the magnitude and sign of the vertical disparity can still be estimated from the reduction in the peak spike count <xref ref-type="bibr" rid="pcbi.1000754-Read3">[15]</xref> and the slant in the region of high spike count.</p>
<p><xref ref-type="fig" rid="pcbi-1000754-g009">Figure 9C</xref> shows results when the test images had a vertical disparity of −8 pixels. This is large compared to the receptive field size of most channels, so the RMS error increases further, but the sign of the vertical disparity is still reliably detected. Horizontal disparity is also extracted, but with a larger error which would correspond to a reduced stereoacuity. This is qualitatively consistent with human performance: human stereo perception becomes worse as vertical disparity increases, and is destroyed by relatively small amounts <xref ref-type="bibr" rid="pcbi.1000754-Stevenson1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Prazdny1">[42]</xref>. Here, almost all the “work” is being done by the low spatial-frequency channels, but these are still enough to extract 2D disparity, without being excessively degraded by the higher-frequency channels for which the stimulus is effectively uncorrelated. Ultimately, of course, as vertical disparity moves beyond the range spanned by the largest receptive fields, performance will fall to chance, again as human performance does.</p>
</sec><sec id="s3d">
<title>Response to anti-correlated stereograms</title>
<p>Disparity is encoded within this model by the population of binocular correlation detectors <italic>C</italic>(<italic>θ</italic>, <italic>f</italic>,Δ<italic>x</italic>). This population, which is all tuned to zero vertical disparity on the retina, performs the initial encoding of disparity. It was chosen to resemble primary visual cortex, V1. For example, these initial disparity encoders are tuned to a particular spatial frequency and orientation, and they continue to respond to disparity in anti-correlated stimuli. Anti-correlated stereograms are those in which one eye's image has been contrast-inverted, so that black pixels are replaced with white. Since I use zero to represent the mean luminance, this corresponds to inverting the sign of one eye's image. Thus, the product <italic>v</italic><sub>L</sub><italic>v</italic><sub>R</sub> changes sign when the stimulus is made anti-correlated. This means that the disparity tuning of binocular correlation-detectors inverts for anti-correlated stimuli. A similar inversion is found in V1 <xref ref-type="bibr" rid="pcbi.1000754-Cumming3">[43]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Ohzawa3">[44]</xref>, although with a slight reduction in amplitude.</p>
<p>Disparity is extracted from the activity of these V1 correlation-detectors by a higher-level brain area. The properties of this decoding area should ideally match those of human perception. For example, neurons in this region should not respond to disparity in anti-correlated stereograms, since these produce no perception of depth in humans or monkeys <xref ref-type="bibr" rid="pcbi.1000754-Cogan1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Read6">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Cumming2">[40]</xref>, and neurons in higher visual areas such as IT and V4 do not respond to disparity in anti-correlated stimuli <xref ref-type="bibr" rid="pcbi.1000754-Tanabe1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Janssen1">[39]</xref>. In this paper, I have used the Pearson correlation coefficient, <italic>r</italic>, to quantify how well the population response to a test image matches the mean population response to template images. To match the lack of response to disparity in anti-correlated stereograms, I set the response of the decoding population equal to the half-wave-rectified Pearson correlation, replacing negative <italic>r</italic> with 0. This has no effect on correlated stereograms, where the maximum <italic>r</italic> is positive, but it prevents the decoder responding systematically to disparity in anti-correlated stereograms.</p>
<p><xref ref-type="fig" rid="pcbi-1000754-g008">Figure 8</xref> illustrated the response of the population of disparity decoders (prior to the half-wave rectification) to one example test stimulus, showing that the maximally-responding decoders were those tuned to disparities close to that of the stimulus. <xref ref-type="fig" rid="pcbi-1000754-g010">Figure 10</xref> plots the disparity tuning surface of a single disparity decoder, the one tuned to (Δ<italic>x</italic><sub>stim</sub>,Δ<italic>y</italic><sub>stim</sub>) = (−6,−3), for both correlated and anti-correlated stereograms. The pseudocolor of each pixel shows the mean &lt;<italic>P</italic>(Δ<italic>x</italic><sub>stim</sub>,Δ<italic>y</italic><sub>stim</sub>)&gt; averaged across 40 different random images with the same disparity (Δ<italic>x</italic><sub>test</sub>,Δ<italic>y</italic><sub>test</sub>), specified by the pixel's position on the axes. <xref ref-type="fig" rid="pcbi-1000754-g010">Figure 10A</xref> shows the disparity tuning surface for normal, correlated stereograms. Unsurprisingly, the response is largest when the two-dimensional disparity of the test stimulus matches the preferred disparity of the decoder, indicated with the cross. Similar disparity tuning surfaces were plotted in <xref ref-type="fig" rid="pcbi-1000754-g005">Figure 5</xref> for the encoding neurons. The disparity tuning surfaces for the decoding neurons differ in two respects. First, they are isotropic rather than elongated, because the decoding neurons receive inputs from cells tuned to all orientations (<xref ref-type="fig" rid="pcbi-1000754-g011">Figure 11</xref>). Second, the peak response is obtained for a non-zero vertical disparity, whereas the encoding neurons were all tuned to zero vertical disparity.</p>
<fig id="pcbi-1000754-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g010</object-id><label>Figure 10</label><caption>
<title>Disparity tuning surface for the disparity decoder tuned to Δx<sub>stim</sub> = −6 and Δy<sub>stim</sub> = 3, indicated by the cross in each panel.</title>
<p>The color of each pixel in the plot shows the mean response, &lt;P(Δx<sub>stim</sub>,Δy<sub>stim</sub>)&gt;, averaged over 40 test stimuli with the disparity (Δx<sub>test</sub>,Δy<sub>test</sub>) specified by that pixel's position on the horizontal and vertical axes. A: for correlated stimuli. B: for anti-correlated stimuli. The same colorscale is used in both panels. Matlab code: The results were generated by <xref ref-type="supplementary-material" rid="pcbi.1000754.s009">Protocol S9</xref> and the figure was plotted by <xref ref-type="supplementary-material" rid="pcbi.1000754.s010">Protocol S10</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g010" xlink:type="simple"/></fig><fig id="pcbi-1000754-g011" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000754.g011</object-id><label>Figure 11</label><caption>
<title>Sketch of the model's physiological interpretation.</title>
<p>Disparity is initially encoded by a population tuned entirely to zero vertical disparity. A higher brain area extracts two-dimensional disparity from the activity of this population. The synaptic weights of the projection from the encoding to the decoding population store the mean activity of the encoding population to stimuli with different 2D disparity. For simplicity, synaptic connections onto only two, color-coded, decoding neurons are shown. The call-outs show examples of the 2D disparity tuning for the two populations (encoding: oriented, optimal vertical disparity is zero; decoding: isotropic, optimal vertical disparity may be non-zero).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.g011" xlink:type="simple"/></fig>
<p><xref ref-type="fig" rid="pcbi-1000754-g010">Figure 10B</xref> shows the disparity tuning surface for the same decoder as in <xref ref-type="fig" rid="pcbi-1000754-g010">Figure 10A</xref>, but this time obtained with anti-correlated stereograms. As noted, anti-correlated stimuli elicit no perception of depth, and neurons in brain areas which are believed to have solved the correspondence problem do not discriminate disparity in anti-correlated stereograms. The Pearson correlation coefficient <italic>r</italic> between the response to an anti-correlated stereogram and the stored average responses for correlated stereograms is almost always negative, meaning that half-wave rectification ensures the decoder response <italic>P</italic>(Δ<italic>x</italic><sub>stim</sub>,Δ<italic>y</italic><sub>stim</sub>) is zero. Accordingly, the disparity tuning surface in <xref ref-type="fig" rid="pcbi-1000754-g010">Figure 10B</xref> is almost completely flat, in agreement with the physiological data for areas IT and V4 <xref ref-type="bibr" rid="pcbi.1000754-Tanabe1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Janssen1">[39]</xref>. Thus, both encoding and decoding neurons in this simulation have properties consistent with those of the corresponding neuronal populations, as far as these are known.</p>
</sec></sec><sec id="s4">
<title>Discussion</title>
<p>This paper has implemented a simple physiologically-inspired two-dimensional stereo correspondence algorithm. It consists of two model “brain areas”: one which performs the initial encoding of binocular disparity between left and right images, and one which decodes this activity so as to arrive at an estimate of the two-dimensional disparity in the images. The unusual feature of this model is that the encoding neurons are all tuned to the same vertical disparity (zero). Despite this, the decoding neurons are able to successfully recover 2D stimulus disparity. This is possible because vertical disparity causes distinctive patterns of activity across the encoding population. The model uses its stored knowledge about these patterns, in the form of templates of expected activity, to deduce the stimulus disparity.</p>
<sec id="s4a">
<title>Neuronal correlates</title>
<p>The model has a simple physiological interpretation. The population of disparity encoders, C(θ,f,Δx<sub>enc</sub>), was designed to represent primary visual cortex, V1. Neurons in this area are tuned to different orientations <italic>θ</italic>, spatial frequencies <italic>f</italic> and horizontal disparities Δ<italic>x</italic><sub>enc</sub>, and respond to disparity in anti-correlated stereograms. This encoding area projects to a higher brain area which extracts stimulus disparity. Neurons in this decoding area are tuned to both horizontal and vertical disparity, but are not sensitive to orientation or spatial frequency. They do not respond to disparity in anti-correlated stereograms. The perceived disparity corresponds to the preferred disparity of the most active neuron in the decoding area.</p>
<p>The stored templates of the population activity expected for different stimulus disparities, <italic>W</italic>, can be viewed as the synaptic weights in the projection from the early encoding area to the decoding area (<xref ref-type="fig" rid="pcbi-1000754-g011">Figure 11</xref>). That is, <italic>W</italic>(<italic>θ</italic>, <italic>f</italic>,Δ<italic>φ</italic>,Δ<italic>x</italic><sub>enc</sub>;Δ<italic>x</italic><sub>dec</sub>,Δ<italic>y</italic><sub>dec</sub>) describes the strength of the synaptic connection from the encoding neuron tuned to orientation <italic>θ</italic>, frequency <italic>f</italic>, phase disparity Δ<italic>φ</italic> and horizontal disparity Δ<italic>x</italic><sub>enc</sub>, onto the decoding neuron tuned to horizontal disparity Δ<italic>x</italic><sub>dec</sub> and vertical disparity Δ<italic>y</italic><sub>dec</sub>. The firing rate of the decoding neuron depends on the total activity of its input neurons weighted by the strength of each synapse (the term <italic>Σ R</italic><sub>test</sub><italic>W</italic> in Equation 6), after undergoing a subtractive and a divisive normalization, and finally a threshold non-linearity (Equation 7). The threshold non-linearity is a universal feature of neuronal circuits, since firing rates cannot go negative. Both subtractive and divisive normalization have been extensively discussed in the literature, and plausible neuronal mechanisms have been proposed to implement them <xref ref-type="bibr" rid="pcbi.1000754-Carandini1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Carandini2">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Heeger1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Simoncelli1">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Tolhurst1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Ayaz1">[50]</xref>.</p>
</sec><sec id="s4b">
<title>Robustness to noise</title>
<p>This model is able to successfully decode two-dimensional disparity, including both the magnitude and sign of vertical disparity, from the activity of the encoding population. This demonstrates that information regarding vertical disparity is implicitly encoded within this population. The accuracy of this information, unsurprisingly, declines as the vertical disparity of the stimulus increases (<xref ref-type="fig" rid="pcbi-1000754-g009">Figure 9</xref>), consistent with psychophysical data. In the model, this decline occurs because information about the stimulus disparity is being carried by neurons which are not optimally tuned to it. Partly, this is because of neuronal noise: the effective signal-to-noise level declines as we move away from the peak of the neuron's tuning surface. I modelled neuronal spiking as a Poisson process, and deliberately chose a low spike count so that the Poisson noise would be large. In these simulations, neurons optimally tuned to the stimulus disparity have a coefficient of variation (CV, the ratio of standard deviation to mean) of 70%, while neurons which are tuned so far from the stimulus disparity that it appears effectively uncorrelated to them have a CV of 100%. However, the main reason for the decline in decoding accuracy is not neuronal noise, but fluctuations in the stimulus. For the uniform-disparity stimuli examined here, receptive fields tuned to the 2D stimulus disparity always experience an effective binocular correlation of exactly 1 (CV = 0%), whereas away from the 2D stimulus disparity the effective binocular correlation is, on average, smaller, and also much more variable. This means that as vertical disparity moves away from the value to which the neurons are tuned (here, zero), the stimulus-dependent fluctuations contribute much more variability to the neuronal spiking.</p>
<p>Nevertheless, despite these two potent sources of noise in the model, the simulations reveal that it performs extremely well. This is because the decoding process uses the responses of thousands of encoding neurons. Although every neuron is tuned to different parameters, and so their responses cannot be directly pooled, the decoding process effectively averages out noise when it correlates the responses of thousands of neurons with the stored templates. For this reason, the model is extremely robust to neuronal noise. If the reader runs the code in the Supplementary Material, reducing the Poisson noise by setting <monospace>Neurons.MeanSpikeUncorr</monospace> to a value greater than its current value of 1, s/he will be able to verify that the results show only a slight improvement in accuracy.</p>
</sec><sec id="s4c">
<title>Relationship to previous models of vertical disparity encoding</title>
<p>The model of Read &amp; Cumming <xref ref-type="bibr" rid="pcbi.1000754-Read3">[15]</xref> was discussed in the <xref ref-type="sec" rid="s1">Introduction</xref>. That model worked by detecting changes in vertical disparity magnitude across the visual field. In contrast, the present model is purely local; all neurons simulated were tuned to the same cyclopean position in the visual field. This model would therefore work even with the induced-effect stimulus of Serrano-Pedraza &amp; Read <xref ref-type="bibr" rid="pcbi.1000754-SerranoPedraza2">[16]</xref>. Serrano-Pedraza &amp; Read <xref ref-type="bibr" rid="pcbi.1000754-SerranoPedraza2">[16]</xref> were correct to reject the particular decoding model proposed by Read &amp; Cumming <xref ref-type="bibr" rid="pcbi.1000754-Read3">[15]</xref>, but wrong to conclude that vertical disparity must be explicitly encoded. A more sophisticated decoding of the same encoding population is consistent with their psychophysical results.</p>
<p>Matthews et al. <xref ref-type="bibr" rid="pcbi.1000754-Matthews1">[51]</xref> also modelled the perceptual effects of vertical disparity using energy-model neurons with different orientation tuning. The present algorithm differs substantially from theirs. Most importantly, their model does not ever estimate stimulus vertical disparity. Their decoding algorithm extracts a one-dimensional estimate of horizontal disparity, assuming that vertical disparity is zero. This means that when vertical disparity actually is present, it causes horizontal disparity to be mis-estimated: a vertical disparity V is misinterpreted as a horizontal disparity of Vcotθ, where θ is the cell's preferred orientation relative to horizontal (eq. 6 of Matthews et al.). They postulate that the perceptual effects of vertical disparity are a direct consequence of this confusion between horizontal and vertical disparity components. In contrast, the present model explicitly decodes both horizontal and vertical disparity. Vertical disparity does not cause horizontal disparity to be systematically mis-estimated (although it does increase the random error, <xref ref-type="fig" rid="pcbi-1000754-g009">Figure 9</xref>). Thus, the present model is agnostic on the question of how vertical disparity causes its perceptual effects: the two-dimensional disparity decoded by the present algorithm would have to be fed into one of the many models of that process (e.g. <xref ref-type="bibr" rid="pcbi.1000754-Read2">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Garding1">[52]</xref>,<xref ref-type="bibr" rid="pcbi.1000754-Backus1">[53]</xref>,<xref ref-type="bibr" rid="pcbi.1000754-Gillam1">[54]</xref>,<xref ref-type="bibr" rid="pcbi.1000754-Mayhew1">[55]</xref>. Second, in order to explain how the “mistaken” disparity <italic>V</italic>cot<italic>θ</italic> produces a perceptual effect when averaged over neurons tuned to all possible orientations <italic>θ</italic>, Matthews et al. <xref ref-type="bibr" rid="pcbi.1000754-Matthews1">[51]</xref> invoke a radial bias for <italic>θ</italic> <xref ref-type="bibr" rid="pcbi.1000754-Leventhal1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Vidyasagar1">[57]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Bauer1">[58]</xref>. The present algorithm does not depend on any such anisotropy. In the simulations presented here, <italic>θ</italic> was assumed to be isotropic; any anisotropy would not affect the performance of the algorithm. This means that the present model is almost the opposite of that in Matthews et al. Their neuronal population explicitly encodes both horizontal and vertical disparity, but their decoding algorithm deliberately extracts only horizontal disparity. My population explicitly encodes only horizontal disparity, but my decoding algorithm extracts both horizontal and vertical disparity.</p>
</sec><sec id="s4d">
<title>Consistency with known physiology</title>
<p>As sketched in <xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2</xref>, the present algorithm depends critically on the obliquely-oriented disparity-tuning surfaces predicted by the stereo energy model. It is therefore important to know whether real neurons display such oriented disparity-tuning surfaces. In monkey V1, Cumming <xref ref-type="bibr" rid="pcbi.1000754-Cumming1">[13]</xref> examined two-dimensional disparity-tuning surfaces for random-dot patterns, and compared their orientation to the cell's orientation tuning for grating stimuli. He found many cells with the obliquely-oriented disparity tuning used here. However, most cells had disparity-tuning surfaces elongated along the horizontal axis, independent of the cell's orientation tuning for gratings. Cumming argued that this represented a specialization for horizontal disparity not predicted by the energy model. This non-energy-model population can be modeled by combining several energy-model units with different horizontal disparity tuning <xref ref-type="bibr" rid="pcbi.1000754-Read1">[3]</xref>. The oblique disparity tuning predicted by the energy model is also found in cat visual cortex <xref ref-type="bibr" rid="pcbi.1000754-Sasaki1">[59]</xref>, and in peripheral monkey V1 <xref ref-type="bibr" rid="pcbi.1000754-Durand2">[11]</xref>. Thus, the existing physiological evidence suggests that neurons with the obliquely-oriented disparity-tuning surfaces used by this model do exist, and may form the inputs for a second stage of disparity encoding consisting of neurons with horizontally-oriented disparity-tuning surfaces.</p>
<p>Neurons in V1 contain both position and phase disparity <xref ref-type="bibr" rid="pcbi.1000754-DeAngelis1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Anzai1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Prince1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Anzai2">[60]</xref>. The model presented here works equally well whether position disparity alone, or both position and phase disparity, are included. In this paper, I specified a relationship between position disparity, phase disparity, frequency and orientation (Equation 1) which ensured that all neurons in the population were tuned to zero vertical disparity. (If this relationship did not hold, the model would contain neurons tuned to a range of vertical disparities, so its success would be trivial.) No physiological study has yet quantified both phase disparity and vertical disparity tuning, yet the results of <xref ref-type="bibr" rid="pcbi.1000754-Cumming1">[13]</xref> imply that something like Equation 1 may hold in reality, at least in the central 10° or so of the visual field.</p>
<p>In the visual periphery, very little is currently known about the distribution of 2D retinal disparity, despite the fact that this is where the range of naturally-occurring vertical disparities is largest <xref ref-type="bibr" rid="pcbi.1000754-Read2">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1000754-Rogers2">[61]</xref>. The existing physiological studies have reported their results only in head-centric Helmholtz coordinates, and have not examined tuning as a function of position on the retina. The encoding population described here, where all neurons at a given retinotopic location are tuned to the same vertical disparity on the retina (<xref ref-type="fig" rid="pcbi-1000754-g001">Figure 1</xref>), is consistent with the very limited existing physiological data available <xref ref-type="bibr" rid="pcbi.1000754-Read3">[15]</xref>. Only future physiological studies can resolve the issue. These should obtain a full 2D disparity tuning surface for every neuron; as <xref ref-type="fig" rid="pcbi-1000754-g002">Figure 2</xref> shows, 1D cross-sections can give misleading results. They should be clear about the definition of vertical disparity they are using, reporting data in retinal, as well as head-centric, coordinates. Finally, they need to examine disparity tuning as a function of position on the retina (not just eccentricity), in order to test whether the mean and variation in preferred vertical disparity varies across the retina as predicted from natural image statistics <xref ref-type="bibr" rid="pcbi.1000754-Read2">[14]</xref>. These studies should be carried out in both early visual cortex and in higher areas such as IT believed to underlie perception. The present model predicts that the range of preferred vertical disparities will be larger in the higher cortical areas.</p>
</sec><sec id="s4e">
<title>Significance</title>
<p>This paper demonstrates a highly efficient strategy for representing 2D stimulus disparity. 2D disparity is represented explicitly only at the decoding level, with the initial encoding being one-dimensional. Because the disparity decoding area does not represent other stimulus properties such as orientation, spatial frequency and phase, this results in a huge reduction in the number of neurons required.</p>
<p>Irrespective of whether the model here is ultimately validated physiologically, it nevertheless provides a vivid demonstration that populations of disparity-tuned neurons contain a much richer array of information than previously appreciated. It places a caveat on the common wisdom that in order to encode a quantity <italic>X</italic>, a neuronal population needs to be tuned to a range of values of <italic>X</italic>. In this example, horizontal and vertical disparity are completely independent quantities in the external world, but they are bound together with orientation at the initial encoding stage in the brain. Subsequently, vertical disparity can be extracted from neurons via their tuning to horizontal disparity and orientation alone. Under these very special circumstances, the common wisdom ceases to hold.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1000754.s001" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s001" xlink:type="simple"><label>Protocol S1</label><caption>
<p>Matlab code for running the simulations presented in this paper (Fig_ExampleRFs.m)</p>
<p>(1.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s002" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s002" xlink:type="simple"><label>Protocol S2</label><caption>
<p>Matlab code for generating <xref ref-type="fig" rid="pcbi-1000754-g004">Fig 4</xref> (Fig_ExampleImages.m)</p>
<p>(1.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s003" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s003" xlink:type="simple"><label>Protocol S3</label><caption>
<p>Matlab code (<ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com" xlink:type="simple">www.mathworks.com</ext-link>) for running the simulations presented in this paper (gets templates). GetTemplates.m</p>
<p>(1.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s004" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s004" xlink:type="simple"><label>Protocol S4</label><caption>
<p>Matlab file, for generating <xref ref-type="fig" rid="pcbi-1000754-g005">Fig 5</xref> (Fig_DispTunSurfEncoders.m)</p>
<p>(3.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s005" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s005" xlink:type="simple"><label>Protocol S5</label><caption>
<p>Matlab code (<ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com" xlink:type="simple">www.mathworks.com</ext-link>) for running the simulations presented in this paper (Fig_MeanResponses.m)</p>
<p>(2.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s006" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s006" xlink:type="simple"><label>Protocol S6</label><caption>
<p>Matlab code (<ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com" xlink:type="simple">www.mathworks.com</ext-link>) for running the simulations presented in this paper (Fig_FitDisparity.m)</p>
<p>(3.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s007" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s007" xlink:type="simple"><label>Protocol S7</label><caption>
<p>Matlab code (<ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com" xlink:type="simple">www.mathworks.com</ext-link>) for running the simulations presented in this paper (FitDisparity.m)</p>
<p>(2.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s008" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s008" xlink:type="simple"><label>Protocol S8</label><caption>
<p>Matlab code (<ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com" xlink:type="simple">www.mathworks.com</ext-link>) for running the simulations presented in this paper (Fig_FreqHists.m)</p>
<p>(3.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s009" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s009" xlink:type="simple"><label>Protocol S9</label><caption>
<p>Matlab code for generating <xref ref-type="fig" rid="pcbi-1000754-g010">Fig 10</xref> (DispTunSurfDecoders.m)</p>
<p>(2.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s010" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s010" xlink:type="simple"><label>Protocol S10</label><caption>
<p>Matlab code for generating <xref ref-type="fig" rid="pcbi-1000754-g010">Fig 10</xref> (Fig_DispTunSurfDecoders.m)</p>
<p>(1.00 KB TXT)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1000754.s011" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000754.s011" xlink:type="simple"><label>Protocol S11</label><caption>
<p>Zip archive containing 7 files with Matlab functions necessary to run the simulations and generate the figures in the paper (Protocol_S11.zip)</p>
<p>(0.14 MB ZIP)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>Thanks to Bruce Cumming for helpful discussions, and to Ignacio Serrano-Pedraza for helpful comments on the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000754-Liu1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Bovik</surname><given-names>AC</given-names></name>
<name name-style="western"><surname>Cormack</surname><given-names>LK</given-names></name>
</person-group>             <year>2008</year>             <article-title>Disparity statistics in natural scenes.</article-title>             <source>J Vis</source>             <volume>8</volume>             <fpage>19 11</fpage>             <lpage>14</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Hibbard1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hibbard</surname><given-names>PB</given-names></name>
</person-group>             <year>2007</year>             <article-title>A statistical model of binocular disparity.</article-title>             <source>Visual Cognition</source>             <volume>15</volume>             <fpage>149</fpage>             <lpage>165</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Read1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
</person-group>             <year>2004</year>             <article-title>Understanding the cortical specialization for horizontal disparity.</article-title>             <source>Neural Comput</source>             <volume>16</volume>             <fpage>1983</fpage>             <lpage>2020</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Helmholtz1"><label>4</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Helmholtz</surname><given-names>Hv</given-names></name>
</person-group>             <year>1925</year>             <source>Treatise on physiological optics</source>             <publisher-loc>Rochester, NY</publisher-loc>             <publisher-name>Optical Society of America</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000754-Ogle1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ogle</surname><given-names>KN</given-names></name>
</person-group>             <year>1952</year>             <article-title>Space perception and vertical disparity.</article-title>             <source>J Opt Soc Am</source>             <volume>42</volume>             <fpage>145</fpage>             <lpage>146</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Farell1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Farell</surname><given-names>B</given-names></name>
</person-group>             <year>1998</year>             <article-title>Two-dimensional matches from one-dimensional stimulus components in human stereopsis.</article-title>             <source>Nature</source>             <volume>395</volume>             <fpage>689</fpage>             <lpage>693</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-SerranoPedraza1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Serrano-Pedraza</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Phillipson</surname><given-names>GP</given-names></name>
<name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
</person-group>             <year>2009</year>             <article-title>A specialization for vertical disparity discontinuities.</article-title>             <source>Journal of Vision in press</source>          </element-citation></ref>
<ref id="pcbi.1000754-Rogers1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rogers</surname><given-names>BJ</given-names></name>
<name name-style="western"><surname>Koenderink</surname><given-names>J</given-names></name>
</person-group>             <year>1986</year>             <article-title>Monocular aniseikonia: a motion parallax analogue of the disparity-induced effect.</article-title>             <source>Nature</source>             <volume>322</volume>             <fpage>62</fpage>             <lpage>63</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Kaneko1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kaneko</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Howard</surname><given-names>IP</given-names></name>
</person-group>             <year>1997</year>             <article-title>Spatial limitation of vertical-size disparity processing.</article-title>             <source>Vision Res</source>             <volume>37</volume>             <fpage>2871</fpage>             <lpage>2878</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Durand1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Durand</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Zhu</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Celebrini</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Trotter</surname><given-names>Y</given-names></name>
</person-group>             <year>2002</year>             <article-title>Neurons in parafoveal areas V1 and V2 encode vertical and horizontal disparities.</article-title>             <source>J Neurophysiol</source>             <volume>88</volume>             <fpage>2874</fpage>             <lpage>2879</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Durand2"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Durand</surname><given-names>JB</given-names></name>
<name name-style="western"><surname>Celebrini</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Trotter</surname><given-names>Y</given-names></name>
</person-group>             <year>2006</year>             <article-title>Neural Bases of Stereopsis across Visual Field of the Alert Macaque Monkey.</article-title>             <source>Cereb Cortex</source>          </element-citation></ref>
<ref id="pcbi.1000754-Gonzalez1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gonzalez</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Justo</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Bermudez</surname><given-names>MA</given-names></name>
<name name-style="western"><surname>Perez</surname><given-names>R</given-names></name>
</person-group>             <year>2003</year>             <article-title>Sensitivity to horizontal and vertical disparity and orientation preference in areas V1 and V2 of the monkey.</article-title>             <source>Neuroreport</source>             <volume>14</volume>             <fpage>829</fpage>             <lpage>832</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Cumming1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
</person-group>             <year>2002</year>             <article-title>An unexpected specialization for horizontal disparity in primate primary visual cortex.</article-title>             <source>Nature</source>             <volume>418</volume>             <fpage>633</fpage>             <lpage>636</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Read2"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
<name name-style="western"><surname>Phillipson</surname><given-names>GP</given-names></name>
<name name-style="western"><surname>Glennerster</surname><given-names>A</given-names></name>
</person-group>             <year>2009</year>             <article-title>Latitude and longitude vertical disparity.</article-title>             <source>Journal of Vision in press</source>          </element-citation></ref>
<ref id="pcbi.1000754-Read3"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
</person-group>             <year>2006</year>             <article-title>Does visual perception require vertical disparity detectors?</article-title>             <source>Journal of Vision</source>             <volume>6</volume>             <fpage>1323</fpage>             <lpage>1355</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-SerranoPedraza2"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Serrano-Pedraza</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
</person-group>             <year>2009</year>             <article-title>Stereo vision requires an explicit encoding of vertical disparity.</article-title>             <source>Journal of Vision</source>             <volume>9</volume>             <fpage>1</fpage>             <lpage>13</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Ohzawa1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
<name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
</person-group>             <year>1990</year>             <article-title>Stereoscopic depth discrimination in the visual cortex: neurons ideally suited as disparity detectors.</article-title>             <source>Science</source>             <volume>249</volume>             <fpage>1037</fpage>             <lpage>1041</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Ohzawa2"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
</person-group>             <year>1998</year>             <article-title>Mechanisms of stereoscopic vision: the disparity energy model.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>8</volume>             <fpage>509</fpage>             <lpage>515</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Banks1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>Gepshtein</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>
</person-group>             <year>2004</year>             <article-title>Why is spatial stereoresolution so low?</article-title>             <source>J Neurosci</source>             <volume>24</volume>             <fpage>2077</fpage>             <lpage>2089</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Filippini1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Filippini</surname><given-names>HR</given-names></name>
<name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
</person-group>             <year>2009</year>             <article-title>Limits of stereopsis explained by local cross-correlation.</article-title>             <source>J Vis</source>             <volume>9</volume>             <fpage>8 1</fpage>             <lpage>18</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Tsai1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tsai</surname><given-names>JJ</given-names></name>
<name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name>
</person-group>             <year>2003</year>             <article-title>Reading a population code: a multi-scale neural model for representing binocular disparity.</article-title>             <source>Vision Res</source>             <volume>43</volume>             <fpage>445</fpage>             <lpage>466</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-DeAngelis1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
</person-group>             <year>1991</year>             <article-title>Depth is encoded in the visual cortex by a specialised receptive field structure.</article-title>             <source>Nature</source>             <volume>352</volume>             <fpage>156</fpage>             <lpage>159</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Anzai1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Anzai</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
</person-group>             <year>1999</year>             <article-title>Neural mechanisms for encoding binocular disparity: receptive field position versus phase.</article-title>             <source>J Neurophysiol</source>             <volume>82</volume>             <fpage>874</fpage>             <lpage>890</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Prince1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Prince</surname><given-names>SJ</given-names></name>
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
<name name-style="western"><surname>Parker</surname><given-names>AJ</given-names></name>
</person-group>             <year>2002</year>             <article-title>Range and mechanism of encoding of horizontal disparity in macaque V1.</article-title>             <source>J Neurophysiol</source>             <volume>87</volume>             <fpage>209</fpage>             <lpage>221</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Bridge1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bridge</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
</person-group>             <year>2001</year>             <article-title>Responses of macaque V1 neurons to binocular orientation differences.</article-title>             <source>J Neurosci</source>             <volume>21</volume>             <fpage>7293</fpage>             <lpage>7302</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Read4"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
</person-group>             <year>2003</year>             <article-title>Testing quantitative models of binocular disparity selectivity in primary visual cortex.</article-title>             <source>J Neurophysiol</source>             <volume>90</volume>             <fpage>2795</fpage>             <lpage>2817</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Read5"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
</person-group>             <year>2007</year>             <article-title>Sensors for impossible stimuli may solve the stereo correspondence problem.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>1322</fpage>             <lpage>1328</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Qian1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Qian</surname><given-names>N</given-names></name>
</person-group>             <year>1994</year>             <article-title>Computing stereo disparity and motion with known binocular cell properties.</article-title>             <source>Neural Computation</source>             <volume>6</volume>             <fpage>390</fpage>             <lpage>404</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Qian2"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Qian</surname><given-names>N</given-names></name>
</person-group>             <year>1997</year>             <article-title>Binocular disparity and the perception of depth.</article-title>             <source>Neuron</source>             <volume>18</volume>             <fpage>359</fpage>             <lpage>368</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Adelson1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Adelson</surname><given-names>EH</given-names></name>
<name name-style="western"><surname>Bergen</surname><given-names>JR</given-names></name>
</person-group>             <year>1985</year>             <article-title>Spatiotemporal energy models for the perception of motion.</article-title>             <source>J Opt Soc Am [A]</source>             <volume>2</volume>             <fpage>284</fpage>             <lpage>299</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Fleet1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fleet</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Wagner</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Heeger</surname><given-names>D</given-names></name>
</person-group>             <year>1996</year>             <article-title>Neural encoding of binocular disparity: energy models, position shifts and phase shifts.</article-title>             <source>Vision Res</source>             <volume>36</volume>             <fpage>1839</fpage>             <lpage>1857</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Dean1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dean</surname><given-names>AF</given-names></name>
</person-group>             <year>1981</year>             <article-title>The variability of discharge of simple cells in the cat striate cortex.</article-title>             <source>Exp Brain Res</source>             <volume>44</volume>             <fpage>437</fpage>             <lpage>440</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Bair1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bair</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Newsome</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Britten</surname><given-names>K</given-names></name>
</person-group>             <year>1994</year>             <article-title>Power spectrum analysis of bursting cells in area MT in the behaving monkey.</article-title>             <source>J Neurosci</source>             <volume>14</volume>             <fpage>2870</fpage>             <lpage>2892</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Prince2"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Prince</surname><given-names>SJ</given-names></name>
<name name-style="western"><surname>Pointon</surname><given-names>AD</given-names></name>
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
<name name-style="western"><surname>Parker</surname><given-names>AJ</given-names></name>
</person-group>             <year>2002</year>             <article-title>Quantitative analysis of the responses of V1 neurons to horizontal disparity in dynamic random-dot stereograms.</article-title>             <source>J Neurophysiol</source>             <volume>87</volume>             <fpage>191</fpage>             <lpage>208</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Norcia1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Norcia</surname><given-names>AM</given-names></name>
<name name-style="western"><surname>Tyler</surname><given-names>CW</given-names></name>
</person-group>             <year>1984</year>             <article-title>Temporal frequency limits for stereoscopic apparent motion processes.</article-title>             <source>Vision Res</source>             <volume>24</volume>             <fpage>395</fpage>             <lpage>401</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Cogan1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cogan</surname><given-names>AI</given-names></name>
<name name-style="western"><surname>Lomakin</surname><given-names>AJ</given-names></name>
<name name-style="western"><surname>Rossi</surname><given-names>AF</given-names></name>
</person-group>             <year>1993</year>             <article-title>Depth in anticorrelated stereograms: effects of spatial density and interocular delay.</article-title>             <source>Vision Res</source>             <volume>33</volume>             <fpage>1959</fpage>             <lpage>1975</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Read6"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Read</surname><given-names>JCA</given-names></name>
<name name-style="western"><surname>Eagle</surname><given-names>RA</given-names></name>
</person-group>             <year>2000</year>             <article-title>Reversed stereo depth and motion direction with anti-correlated stimuli.</article-title>             <source>Vision Res</source>             <volume>40</volume>             <fpage>3345</fpage>             <lpage>3358</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Tanabe1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tanabe</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Umeda</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Fujita</surname><given-names>I</given-names></name>
</person-group>             <year>2004</year>             <article-title>Rejection of false matches for binocular correspondence in macaque visual cortical area V4.</article-title>             <source>J Neurosci</source>             <volume>24</volume>             <fpage>8170</fpage>             <lpage>8180</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Janssen1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Janssen</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Vogels</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Orban</surname><given-names>GA</given-names></name>
</person-group>             <year>2003</year>             <article-title>At least at the level of inferior temporal cortex, the stereo correspondence problem is solved.</article-title>             <source>Neuron</source>             <volume>37</volume>             <fpage>693</fpage>             <lpage>701</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Cumming2"><label>40</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
<name name-style="western"><surname>Shapiro</surname><given-names>SE</given-names></name>
<name name-style="western"><surname>Parker</surname><given-names>A</given-names></name>
</person-group>             <year>1998</year>             <article-title>Disparity detection in anticorrelated stereograms.</article-title>             <source>Perception</source>             <volume>27</volume>             <fpage>1367</fpage>             <lpage>1377</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Stevenson1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stevenson</surname><given-names>SB</given-names></name>
<name name-style="western"><surname>Schor</surname><given-names>CM</given-names></name>
</person-group>             <year>1997</year>             <article-title>Human stereo matching is not restricted to epipolar lines.</article-title>             <source>Vision Res</source>             <volume>37</volume>             <fpage>2717</fpage>             <lpage>2723</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Prazdny1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Prazdny</surname><given-names>K</given-names></name>
</person-group>             <year>1985</year>             <article-title>Vertical disparity tolerance in random-dot stereograms.</article-title>             <source>Bulletin of the Psychonomic Society</source>             <volume>23</volume>             <fpage>413</fpage>             <lpage>414</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Cumming3"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cumming</surname><given-names>BG</given-names></name>
<name name-style="western"><surname>Parker</surname><given-names>AJ</given-names></name>
</person-group>             <year>1997</year>             <article-title>Responses of primary visual cortical neurons to binocular disparity without depth perception.</article-title>             <source>Nature</source>             <volume>389</volume>             <fpage>280</fpage>             <lpage>283</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Ohzawa3"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
<name name-style="western"><surname>DeAngelis</surname><given-names>GC</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
</person-group>             <year>1997</year>             <article-title>Encoding of binocular disparity by complex cells in the cat's visual cortex.</article-title>             <source>J Neurophysiol</source>             <volume>77</volume>             <fpage>2879</fpage>             <lpage>2909</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Carandini1"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Heeger</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Movshon</surname><given-names>T</given-names></name>
</person-group>             <year>1999</year>             <article-title>Linearity and gain control in V1 simple cells.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>U</surname><given-names>PS</given-names></name>
<name name-style="western"><surname>J</surname><given-names>EG</given-names></name>
<name name-style="western"><surname>P</surname><given-names>A</given-names></name>
</person-group>             <source>Cerebral cortex: models of cortical function</source>             <fpage>401</fpage>             <lpage>443</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Carandini2"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>
</person-group>             <year>1997</year>             <article-title>Linearity and normalization in simple cells of the macaque primary visual cortex.</article-title>             <source>J Neurosci</source>             <volume>17</volume>             <fpage>8621</fpage>             <lpage>8644</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Heeger1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>
</person-group>             <year>1992</year>             <article-title>Normalization of cell responses in cat striate cortex.</article-title>             <source>Vis Neurosci</source>             <volume>9</volume>             <fpage>181</fpage>             <lpage>197</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Simoncelli1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>
<name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>
</person-group>             <year>1998</year>             <article-title>A model of neuronal responses in visual area MT.</article-title>             <source>Vision Res</source>             <volume>38</volume>             <fpage>743</fpage>             <lpage>761</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Tolhurst1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name>
</person-group>             <year>1997</year>             <article-title>Comparison of contrast-normalization and threshold models of the responses of simple cells in cat striate cortex.</article-title>             <source>Vis Neurosci</source>             <volume>14</volume>             <fpage>293</fpage>             <lpage>309</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Ayaz1"><label>50</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ayaz</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Chance</surname><given-names>FS</given-names></name>
</person-group>             <year>2009</year>             <article-title>Gain modulation of neuronal responses by subtractive and divisive mechanisms of inhibition.</article-title>             <source>J Neurophysiol</source>             <volume>101</volume>             <fpage>958</fpage>             <lpage>968</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Matthews1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Matthews</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Meng</surname><given-names>X</given-names></name>
<name name-style="western"><surname>Xu</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Qian</surname><given-names>N</given-names></name>
</person-group>             <year>2003</year>             <article-title>A physiological theory of depth perception from vertical disparity.</article-title>             <source>Vision Res</source>             <volume>43</volume>             <fpage>85</fpage>             <lpage>99</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Garding1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Garding</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Porrill</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Mayhew</surname><given-names>JE</given-names></name>
<name name-style="western"><surname>Frisby</surname><given-names>JP</given-names></name>
</person-group>             <year>1995</year>             <article-title>Stereopsis, vertical disparity and relief transformations.</article-title>             <source>Vision Res</source>             <volume>35</volume>             <fpage>703</fpage>             <lpage>722</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Backus1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Backus</surname><given-names>BT</given-names></name>
<name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name>
<name name-style="western"><surname>van Ee</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Crowell</surname><given-names>JA</given-names></name>
</person-group>             <year>1999</year>             <article-title>Horizontal and vertical disparity, eye position, and stereoscopic slant perception.</article-title>             <source>Vision Res</source>             <volume>39</volume>             <fpage>1143</fpage>             <lpage>1170</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Gillam1"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gillam</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Lawergren</surname><given-names>B</given-names></name>
</person-group>             <year>1983</year>             <article-title>The induced effect, vertical disparity, and stereoscopic theory.</article-title>             <source>Percept Psychophys</source>             <volume>34</volume>             <fpage>121</fpage>             <lpage>130</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Mayhew1"><label>55</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Mayhew</surname><given-names>JE</given-names></name>
<name name-style="western"><surname>Longuet-Higgins</surname><given-names>HC</given-names></name>
</person-group>             <year>1982</year>             <article-title>A computational model of binocular depth perception.</article-title>             <source>Nature</source>             <volume>297</volume>             <fpage>376</fpage>             <lpage>378</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Leventhal1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Leventhal</surname><given-names>AG</given-names></name>
</person-group>             <year>1983</year>             <article-title>Relationship between preferred orientation and receptive field position of neurons in cat striate cortex.</article-title>             <source>J Comp Neurol</source>             <volume>220</volume>             <fpage>476</fpage>             <lpage>483</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Vidyasagar1"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vidyasagar</surname><given-names>TR</given-names></name>
<name name-style="western"><surname>Henry</surname><given-names>GH</given-names></name>
</person-group>             <year>1990</year>             <article-title>Relationship between preferred orientation and ordinal position in neurones of cat striate cortex.</article-title>             <source>Vis Neurosci</source>             <volume>5</volume>             <fpage>565</fpage>             <lpage>569</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Bauer1"><label>58</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bauer</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Dow</surname><given-names>BM</given-names></name>
</person-group>             <year>1989</year>             <article-title>Complementary global maps for orientation coding in upper and lower layers of the monkey's foveal striate cortex.</article-title>             <source>Exp Brain Res</source>             <volume>76</volume>             <fpage>503</fpage>             <lpage>509</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Sasaki1"><label>59</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sasaki</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Tabuchi</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
</person-group>             <year>2009</year>             <article-title>Complex cells in the early visual cortex have multiple disparity detectors in the 3D binocular RFs.</article-title>             <comment>Computational and Systems Neuroscience Meeting. Salt Lake City, Utah</comment>          </element-citation></ref>
<ref id="pcbi.1000754-Anzai2"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Anzai</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Ohzawa</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Freeman</surname><given-names>RD</given-names></name>
</person-group>             <year>1997</year>             <article-title>Neural mechanisms underlying binocular fusion and stereopsis: position vs. phase.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>94</volume>             <fpage>5438</fpage>             <lpage>5443</lpage>          </element-citation></ref>
<ref id="pcbi.1000754-Rogers2"><label>61</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rogers</surname><given-names>BJ</given-names></name>
<name name-style="western"><surname>Bradshaw</surname><given-names>MF</given-names></name>
</person-group>             <year>1993</year>             <article-title>Vertical disparities, differential perspective and binocular stereopsis.</article-title>             <source>Nature</source>             <volume>361</volume>             <fpage>253</fpage>             <lpage>255</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>
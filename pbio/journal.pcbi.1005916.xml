<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-01367</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005916</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Ecology</subject><subj-group><subject>Community ecology</subject><subj-group><subject>Trophic interactions</subject><subj-group><subject>Predation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Ecology and environmental sciences</subject><subj-group><subject>Ecology</subject><subj-group><subject>Community ecology</subject><subj-group><subject>Trophic interactions</subject><subj-group><subject>Predation</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Foraging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject><subj-group><subject>Foraging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Population biology</subject><subj-group><subject>Population dynamics</subject><subj-group><subject>Predator-prey dynamics</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Chemistry</subject><subj-group><subject>Chemical compounds</subject><subj-group><subject>Organic compounds</subject><subj-group><subject>Amines</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Norepinephrine</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Chemistry</subject><subj-group><subject>Organic chemistry</subject><subj-group><subject>Organic compounds</subject><subj-group><subject>Amines</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Norepinephrine</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Neurochemistry</subject><subj-group><subject>Neurotransmitters</subject><subj-group><subject>Biogenic amines</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Norepinephrine</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurochemistry</subject><subj-group><subject>Neurotransmitters</subject><subj-group><subject>Biogenic amines</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Norepinephrine</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Hormones</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Norepinephrine</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Agriculture</subject><subj-group><subject>Animal management</subject><subj-group><subject>Animal performance</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Physical laws and principles</subject><subj-group><subject>Conservation of energy</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Interrupting behaviour: Minimizing decision costs via temporal commitment and low-level interrupts</article-title>
<alt-title alt-title-type="running-head">Interrupting behaviour</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7744-7562</contrib-id>
<name name-style="western">
<surname>Lloyd</surname> <given-names>Kevin</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff001"/>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dayan</surname> <given-names>Peter</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>Gatsby Computational Neuroscience Unit, London, United Kingdom</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Nieuwenhuis</surname> <given-names>Sander</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Leiden University, NETHERLANDS</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">klloyd@gatsby.ucl.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>1</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>16</day>
<month>1</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>1</issue>
<elocation-id>e1005916</elocation-id>
<history>
<date date-type="received">
<day>14</day>
<month>8</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>5</day>
<month>12</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Lloyd, Dayan</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005916"/>
<abstract>
<p>Ideal decision-makers should constantly assess all sources of information about opportunities and threats, and be able to redetermine their choices promptly in the face of change. However, perpetual monitoring and reassessment impose inordinate sensing and computational costs, making them impractical for animals and machines alike. The obvious alternative of committing for extended periods of time to limited sensory strategies associated with particular courses of action can be dangerous and wasteful. Here, we explore the intermediate possibility of making provisional temporal commitments whilst admitting interruption based on limited broader observation. We simulate foraging under threat of predation to elucidate the benefits of such a scheme. We relate our results to diseases of distractibility and roving attention, and consider mechanistic substrates such as noradrenergic neuromodulation.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Animals should ideally be able to monitor all relevant aspects of their environment constantly and be ever prepared to alter their course of action in the face of unexpected change. However, the impractically high costs of continual monitoring and deliberation mean that a more realistic strategy is required. Here, we explore a solution in which an animal makes provisional commitments to a temporally-extended action while maintaining the ability to interrupt this behaviour prematurely on the basis of more limited sensing. We demonstrate the benefits of such a scheme through the example of foraging under predation risk, and propose a simple mechanism for implementing interruption. We suggest possible relationships between these results and neural substrates, particularly norepinephrine, and also highlight potential relevance to diseases of distractibility.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by funding from the Gatsby Charitable Foundation. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="0"/>
<page-count count="23"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-01-26</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>For code, see <ext-link ext-link-type="uri" xlink:href="https://github.com/kevilloyd/foraging-code" xlink:type="simple">https://github.com/kevilloyd/foraging-code</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>It might seem optimal for decision-makers to be constantly open to all sources of potential information and to be able to change their course of action at a moment’s notice. However, a range of physical and computational constraints makes such a prospect infeasible.</p>
<p>In terms of sensation, relevant information may not always be accessible when the agent engages in an activity that naturally restricts sensory access. In other words, agents create <italic>partially observable</italic> environments for themselves, even when those environments could be more fully observable [<xref ref-type="bibr" rid="pcbi.1005916.ref001">1</xref>]. Furthermore, even if information is available in principle, limited computational resources mean that only a subset of this information can in practice be subject to enhanced perceptual or central processing. These considerations lead to forms of selective attention [<xref ref-type="bibr" rid="pcbi.1005916.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1005916.ref004">4</xref>].</p>
<p>Constant reassessment of decisions seems similarly impractical. Working out the correct course of action in terms of maximizing expected utility is computationally demanding, requiring consideration of the possible consequences of each current option. Even when only approximate optimality or satisficing is sought [<xref ref-type="bibr" rid="pcbi.1005916.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref006">6</xref>], it is desirable to minimize the frequency with which such costly operations take place. Equally, switching between courses of action likely incurs overheads in terms of time or even energetic costs [<xref ref-type="bibr" rid="pcbi.1005916.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1005916.ref009">9</xref>]. The obvious alternative is to commit to particular courses of action or undertakings for extended periods of time, limiting the frequency of expensive deliberation steps.</p>
<p>There is a synergy between temporal commitment and selective attention: during extended periods of performing a single undertaking, the decision-maker could focus on just that part of the external information which is strictly relevant. The trouble with this strategy is that of being insufficiently <italic>reactive</italic>, potentially leading to failures to respond appropriately to unexpected opportunities or threats [<xref ref-type="bibr" rid="pcbi.1005916.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref011">11</xref>]. Here, we therefore consider the intermediate strategy of making provisional temporal commitments while also allowing ongoing behaviour to be <italic>interrupted</italic>. Such interruptions are occasioned by a strictly limited monitoring process that collects broader, but lower quality, information about the environment. This combination balances the desire to minimize decision-making costs with the ability to respond in a timely and appropriate way to changing requirements. The possibility of interruption would be a form of strategic hedge against potentially changing circumstances.</p>
<p>Such considerations are venerable: the need to plan and act in a way that is responsive to real-world demands, but which is sensitive to constraints on time and resources, has been extensively discussed in the artificial intelligence and related literatures [<xref ref-type="bibr" rid="pcbi.1005916.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref013">13</xref>]. This includes recognition of the benefits of planning with temporally-extended units of activity in terms of search complexity [<xref ref-type="bibr" rid="pcbi.1005916.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref015">15</xref>], and exploration of issues surrounding replanning, such as the need for monitoring to determine whether replanning is required [<xref ref-type="bibr" rid="pcbi.1005916.ref016">16</xref>], and the use of contingency plans that specify—to varying degrees of detail—what to do under different future scenarios [<xref ref-type="bibr" rid="pcbi.1005916.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref018">18</xref>]. Similarly, conventional computers use interrupts for a variety of purposes, including allowing external events, such as the press of a key on a keyboard, to prompt the central processing unit to set aside its current activity; this is an alternative to engaging in constant ‘polling’ of the relevant devices (see, e.g., [<xref ref-type="bibr" rid="pcbi.1005916.ref019">19</xref>]).</p>
<p>In the natural world, these forms of interruption can be expected to apply over the timescale of a behaviour such as a bout of foraging (i.e., over multiple seconds or even minutes). In this paper, we use a detailed example to examine this particular timescale. By contrast, previous work on natural aspects of interruption has focused on day-long [<xref ref-type="bibr" rid="pcbi.1005916.ref020">20</xref>] and sub-second [<xref ref-type="bibr" rid="pcbi.1005916.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref022">22</xref>] interruption. In both of these cases, norepinephrine (NE), a neuromodulator involved in arousal, vigilance and attention [<xref ref-type="bibr" rid="pcbi.1005916.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref024">24</xref>], has been implicated as a medium for an interrupt signal, putatively in virtue of reporting forms of unexpected uncertainty [<xref ref-type="bibr" rid="pcbi.1005916.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref026">26</xref>].</p>
<p>Illustrating the operation of such a scheme requires an environment with costs and benefits for action, and both uncertainty and change. We consider the case of foraging under predation risk [<xref ref-type="bibr" rid="pcbi.1005916.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref028">28</xref>], in which a decision-maker faces various potential tradeoffs between energetic gain and danger [<xref ref-type="bibr" rid="pcbi.1005916.ref029">29</xref>]. This offers a flexible framework to explore choices of existential importance, for instance between a habitat that promises a high rate of gain but a high risk of predation, and one that promises a lower rate of gain but less risk. We also explore the case that foraging is incompatible with high quality, active assessments of threats.</p>
<p>The rest of the paper is organised as follows. We first consider a simple motivating example that illustrates the basic ideas. We then detail the full model, describing the nature and capacities of a foraging agent and the environment in which it operates. We proceed to explore optimal behaviour in the full model with and without the possibility of an interrupt, and with and without decision costs. We also examine the possibility of using a computationally simpler interruption scheme. Finally, we discuss possible links to NE and diseases of interruptibility.</p>
<sec id="sec002">
<title>Simple foraging example</title>
<p>The full model of foraging under predation risk that we consider below includes a number of detailed components. Therefore, in order to illustrate and provide intuition for the workings of interruption, we start with a simple, stripped-down model.</p>
<p>Consider an animal (e.g., a rat) foraging in a habitat (<xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1A</xref>) in which a predator (e.g., a hawk) arrives with probability 0.01 per unit time. The animal has to choose between three actions: (i) to continue to <italic>feed</italic>; (ii) to stop feeding to <italic>assess</italic> whether a predator is present; or (iii) to <italic>escape</italic>. Opting to <italic>feed</italic> has the benefit of gaining resources (worth 1 unit of reward per unit time), but has the drawback of providing only poor information (+) about whether the predator is present (e.g., because it restricts the animal’s field of view). Furthermore, if the predator is present, then the animal gets caught with probability 0.1 per unit time, incurring a cost of −100 units of reward, and causing the task to terminate. By contrast, <italic>assess</italic> provides the animal with improved information (++) about the presence of the predator, but has reward 0 per unit time. The exact details of how the quality of information is varied shall be described below, but the important point here is that <italic>feed</italic> and <italic>assess</italic> have distinct informational consequences. Finally, choosing to <italic>escape</italic> leads to a location that is safe, but does not permit foraging, thus gaining 0 reward; it also causes the task to terminate. The animal’s assumed task is to maximize the expected sum of its undiscounted future rewards (we consider the more conventional case of long run discounted rewards when we amplify this simple example).</p>
<fig id="pcbi.1005916.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005916.g001</object-id>
<label>Fig 1</label>
<caption>
<title>The ability to interrupt behaviour promotes temporal commitment.</title>
<p>(A) Simple foraging example. A rat chooses to <italic>feed</italic> (reward +1 per time step), <italic>assess</italic> (reward 0), or <italic>escape</italic> (reward 0), in a habitat where the predator arrives with probability 0.01 per time step and then stays. Although <italic>assess</italic> is not rewarded, it provides more reliable information about whether the predator has arrived (++) than <italic>feed</italic> (+). If the predator has arrived, the probability that the rat gets caught if it remains in the habitat is 0.1 per time step. The decision process terminates (indicated by a <bold>!</bold>) either when the rat is caught (reward −100) or chooses to <italic>escape</italic>. (B) If the animal makes decisions at a high frequency, for example committing to an action <italic>a</italic> for only the minimum amount of time <italic>τ</italic><sub>min</sub> (top), it will be able to respond to unexpected changes (such as the arrival of the predator; grey box) but will also incur large decision costs; each decision incurs a cost of <italic>c</italic><sub><italic>d</italic></sub>. Committing for a longer duration <italic>τ</italic> has the advantage of reducing decision costs (middle), but is risky—the predator may arrive before the action terminates—unless the animal has the option to interrupt its behaviour at an earlier time (bottom). (C–F) Optimal policies, comprising an optimal action <italic>a</italic>* (left) and corresponding optimal duration <italic>τ</italic>* (right), for four different conditions. (C) No decision cost, <italic>c</italic><sub><italic>d</italic></sub> = 0. The optimal duration <italic>τ</italic>* is always as short as possible, meaning that the animal will be best able to respond appropriately if the predator arrives. (D) Decision cost <italic>c</italic><sub><italic>d</italic></sub> = 0.01, no interrupt. Optimal durations are essentially still as short as possible; the animal pays the greater cost of making high-frequency decisions in order to maintain its responsiveness. (E) Decision cost <italic>c</italic><sub><italic>d</italic></sub> = 0.01, interrupt. With the capacity to interrupt ongoing behaviour, the animal now selects long durations for <italic>feed</italic> and <italic>assess</italic>; the interrupt allows the animal to minimize its decision costs and also remain reactive, since it can always interrupt and make a new decision when required. (F) When the decision cost is increased further, <italic>c</italic><sub><italic>d</italic></sub> = 1, the shape of the policy changes so that <italic>escape</italic> is more predominant. (G) Ratio of average total amount of reward per trial (non-interrupt/interrupt) for different decision costs. For each decision cost, optimal non-interruptible and interruptible policies performed 1000 trials of the foraging task. (H) Average number of decisions per time step, and (I) average number of time steps of the optimal non-interrupible (blue circles) and interruptible (magenta squares) policies as a function of decision cost.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005916.g001" xlink:type="simple"/>
</fig>
<p>The animal here has to negotiate two fundamental tradeoffs. One is between the rewards that can be directly obtained by choosing to <italic>feed</italic> and the improved information that can be obtained by choosing to <italic>assess</italic>. The second tradeoff is between future possible rewards that may be obtained by remaining in the habitat, and the sacrifice of those rewards in favour of safety by choosing to <italic>escape</italic>.</p>
<p>The final detail of the example is that each time the animal makes a choice about what to do, it selects both an action <italic>a</italic> (i.e., <italic>feed</italic>, <italic>assess</italic>, or <italic>escape</italic>) and a duration <italic>τ</italic> with which to perform it. Critically, each time the animal makes a decision it may incur a <italic>decision cost</italic>, <italic>c</italic><sub><italic>d</italic></sub> ≥ 0, which summarizes the various computational demands associated with such a decision; as discussed above, these may include planning and/or switching costs. If this decision cost is non-negligible, the animal additionally faces a tradeoff between reducing decision costs by making a prolonged temporal commitment to an action—i.e., reducing decision frequency by choosing a long duration <italic>τ</italic>—and being able to respond quickly if it is likely that the predator has arrived (<xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1B</xref>).</p>
<p>Whether or not the animal is able to <italic>interrupt</italic> its ongoing behaviour is a critical determinant of its optimal policy. Here, a policy is a mapping between the degree to which the animal believes that the predator has arrived/is present, <italic>β</italic>(<italic>P</italic>), and an action-duration pair (<italic>a</italic>, <italic>τ</italic>). <xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1C–1F</xref> display optimal policies, comprising optimal actions <italic>a</italic>* (left) and associated optimal durations <italic>τ</italic>* (right), for four different cases. The first (<xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1C</xref>) is the optimal policy when there is no decision cost, <italic>c</italic><sub><italic>d</italic></sub> = 0. In terms of actions, the animal chooses to <italic>feed</italic> when it is unlikely that the predator has arrived (<italic>β</italic>(<italic>P</italic>) low), to <italic>escape</italic> when this is more likely than not (<italic>β</italic>(<italic>P</italic>) &gt; 0.5), and to <italic>assess</italic> otherwise. More importantly for our purposes is the observation that optimal durations <italic>τ</italic>* are uniformly chosen to be as short as possible. Since making a decision has no cost, doing so at the highest possible frequency is the best way to ensure that the animal is best able to respond if it thinks the predator may have arrived.</p>
<p>Next, we consider the case where there is a small decision cost, <italic>c</italic><sub><italic>d</italic></sub> = 0.01, and the animal is unable to interrupt its own activity (<xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1D</xref>). That is, if the animal chooses to engage in an action for <italic>τ</italic> seconds, it will be fully committed to performing the action for that duration. Here, there is no change in choice of actions, and very little change in duration except a slight increase in <italic>τ</italic>* for <italic>feed</italic> when the predator is very unlikely to have arrived. The low durations here, even though this entails a high frequency of decisions, mean that the animal is willing to pay these decision costs in order to remain responsive to possible threat.</p>
<p>In <xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1E</xref>, the decision cost remains the same (<italic>c</italic><sub><italic>d</italic></sub> = 0.01), but the animal is now able to interrupt its behaviour. Interrupts also occur as a function of <italic>β</italic>(<italic>P</italic>), but (a) as noted, the information available to change <italic>β</italic>(<italic>P</italic>) is of lower quality during <italic>feed</italic> than <italic>assess</italic>; and (b) we assume that interruption itself is <italic>free</italic> (although there is then a standard decision cost associated with the necessary re-planning). Again, we see no change in which actions are chosen, but now both <italic>feed</italic> and <italic>assess</italic> are chosen to have the <italic>longest</italic> possible duration (in this example, there is no advantage to the animal of choosing to spend longer on <italic>escape</italic>). Since the animal can always interrupt itself, making such provisional commitments means that it can minimize decision costs by interrupting and making a new decision only when strictly necessary.</p>
<p>Finally, if the decision cost is increased further, changes in the pattern of optimal actions are observed. <xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1F</xref> shows the optimal policy for <italic>c</italic><sub><italic>d</italic></sub> = 1, showing an increased propensity of the animal to <italic>escape</italic>. The alternatives are increasingly disfavoured by the animal not because of any change in risk of predation—this is unchanged—but because of the increased expense of making on-going decisions if it remains in the habitat.</p>
<p>The preceding discussion suggests that the ability to interrupt behaviour should be advantageous: it allows an animal to minimize decision costs by making provisional commitments to temporally-extended actions, while maintaining its ability to respond to changes in the environment. Indeed, an advantage in terms of rate of rewards is observed (<xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1G</xref>). When there is no decision cost (<italic>c</italic><sub><italic>d</italic></sub> = 0), the ratio of reward rates (non-interruptible/interruptible) is 1, reflecting the fact that an animal would perform equally well whether or not it is equipped with an interrupt. However, as <italic>c</italic><sub><italic>d</italic></sub> increases, this ratio decreases, reflecting a reward advantage when the option to interrupt is available. Beyond a critical value, the ratio reverts to 1, with the animal deciding to escape immediately.</p>
<p>This advantage in terms of reward rate arises from the reduction in the frequency of decisions when the animal is able to interrupt (<xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1H</xref>). This reduced decision rate makes it worthwhile for the animal to spend more time (safely) foraging in the environment (<xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1I</xref>), thereby increasing its haul of rewards. The advantage disappears when planning is so expensive that the animal <italic>escape</italic>s immediately. However, the cost at which this occurs is lower when interruption is not possible (cf. <xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1H and 1I</xref>).</p>
</sec>
</sec>
<sec id="sec003" sec-type="materials|methods">
<title>Methods</title>
<p>Our simple example serves to demonstrate the following basic points: when making decisions is costly, the ability to interrupt on-going behaviour promotes provisional commitments to temporally-extended actions, and this ability confers a demonstrable advantage in terms of rewards. However, it makes a number of unrealistic assumptions, notably a single possible interaction with the predator.</p>
<p>We therefore constructed a more detailed example of foraging under predation risk in order to elaborate and amplify these points. Along with making the task recurrent, it includes two structural extensions (shown in <xref ref-type="fig" rid="pcbi.1005916.g002">Fig 2A</xref>). First, we expand the number of environmental variables that might influence the animal’s decisions by additionally allowing the foraging quality of the environment to vary over time. Second, we now model two different locations that the animal may occupy and continuously move between: a <italic>patch</italic> location, in which the animal may forage, and a <italic>refuge</italic> location, where the animal is safe but cannot forage.</p>
<fig id="pcbi.1005916.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005916.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Model of foraging under predation risk.</title>
<p>(A) The animal can either remain safely in its refuge or forage outside in a ‘patch’ location. The payoff for foraging depends on the habitat quality, which varies between <italic>good</italic> (<italic>G</italic>) and <italic>bad</italic> (<italic>B</italic>) states with transition rates (<italic>γ</italic><sub><italic>GB</italic></sub>, <italic>γ</italic><sub><italic>BG</italic></sub>), and whether a predator is <italic>absent</italic> (<italic>A</italic>) or <italic>present</italic> (<italic>P</italic>), as determined by transition rates (<italic>γ</italic><sub><italic>AP</italic></sub>, <italic>γ</italic><sub><italic>PA</italic></sub>). Grey boxes indicate that the values of the predator and habitat quality variables are hidden, i.e., are not directly observed but have to be inferred by the animal. Different actions are available to the animal depending on its current location. (B) Examples of the evolution of the belief that the habitat is <italic>good</italic>, <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>). Here, the environment switches from <italic>good</italic> to <italic>bad</italic> after 60s. For most actions, uncertainty will simply increase over time, and for <italic>γ</italic><sub><italic>GB</italic></sub> = <italic>γ</italic><sub><italic>BG</italic></sub>, will tend to 0.5 (dashed line). If the animal chooses to <italic>feed</italic>, its rate of encounter with <italic>rich</italic> patches (black points) provides information about current habitat quality (solid line). (C) Examples of the evolution of the belief that a predator is <italic>present</italic>, <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>). Here, a predator enters and remains in the environment at 60s. If the animal is in the refuge and selects <italic>rest</italic>, there is no information about the state of predation, and uncertainty increases over time (again to <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>) = 0.5; long dashed line). For most of the other activities, indirect cues <italic>o</italic><sub><italic>i</italic></sub> (black points) are freely available, which provide some information about the state of predation (short dashed line). For <italic>assess</italic>, both indirect cues <italic>o</italic><sub><italic>i</italic></sub> and direct cues <italic>o</italic><sub><italic>d</italic></sub> (red points) are available; the latter provide more reliable information about whether a predator is <italic>present</italic> or <italic>absent</italic> (solid line). Parameters: <italic>γ</italic><sub><italic>GB</italic></sub> = <italic>γ</italic><sub><italic>BG</italic></sub> = 0.01, <inline-formula id="pcbi.1005916.e001"><alternatives><graphic id="pcbi.1005916.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>r</mml:mi> <mml:mi>G</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>8</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005916.e002"><alternatives><graphic id="pcbi.1005916.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mrow><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>r</mml:mi> <mml:mi>B</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>; <italic>γ</italic><sub><italic>AP</italic></sub> = <italic>γ</italic><sub><italic>PA</italic></sub> = 0.1, <inline-formula id="pcbi.1005916.e003"><alternatives><graphic id="pcbi.1005916.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mo>-</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow> <mml:mo>-</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005916.e004"><alternatives><graphic id="pcbi.1005916.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mo>+</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005916.e005"><alternatives><graphic id="pcbi.1005916.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow> <mml:mo>+</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>9</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005916.g002" xlink:type="simple"/>
</fig>
<p>More formally, the model is a <italic>partially observable semi-Markov decision process</italic> (POSMDP) which can be described in terms of states, actions, transitions, rewards, observations, and a discount factor.</p>
<sec id="sec004">
<title>States</title>
<p>States are determined by the values of three binary variables: 1) <italic>location</italic> ∈ {<italic>refuge</italic>, <italic>patch</italic>}, where <italic>refuge</italic> affords safety but not food, while <italic>patch</italic> affords foraging but also possible predation; 2) <italic>habitat quality</italic> ∈ {<italic>good</italic>(<italic>G</italic>), <italic>bad</italic>(<italic>B</italic>)}, which determines the current utility of feeding (see below); and 3) <italic>predator</italic> ∈ {<italic>present</italic>(<italic>P</italic>), <italic>absent</italic>(<italic>A</italic>)}, which describes whether there is currently a predator in the vicinity or not. We assume that the animal always knows its location, but that the state of predation and habitat quality are hidden variables whose values need to be inferred based on evidence.</p>
</sec>
<sec id="sec005">
<title>Actions</title>
<p>As before, choice involves selection of both an action <italic>a</italic> and a duration <italic>τ</italic> for its performance, and we refer to an action-duration pair (<italic>a</italic>, <italic>τ</italic>) as an <italic>activity</italic>.</p>
<p>Possible actions are location-specific. In the <italic>refuge</italic>, the set is <inline-formula id="pcbi.1005916.e006"><alternatives><graphic id="pcbi.1005916.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:msub><mml:mi mathvariant="script">A</mml:mi> <mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>u</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>rest</italic> is a recuperative behaviour; <italic>assess</italic> specifically aims to increase certainty about whether a predator is currently in the environment from a position of relative safety (e.g., sniffing near the entrance of the <italic>refuge</italic>); and <italic>transit</italic> simply means moving to the <italic>patch</italic> location to forage.</p>
<p>In the <italic>patch</italic> location, the set of available actions is <inline-formula id="pcbi.1005916.e007"><alternatives><graphic id="pcbi.1005916.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:msub><mml:mi mathvariant="script">A</mml:mi> <mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>f</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>z</mml:mi><mml:mi>e</mml:mi> <mml:mo>,</mml:mo> <mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>feed</italic> refers to the ingestion of food; <italic>assess</italic>, as before, is aimed at detecting whether a predator is present, though here from a position of possible danger; <italic>freeze</italic> aims at avoiding predation by decreasing the probability of detection; and <italic>escape</italic> also aims at evading predation but through returning the animal back to the <italic>refuge</italic>.</p>
</sec>
<sec id="sec006">
<title>Transitions</title>
<p>The patch quality and predator presence are assumed to obey simple semi-Markov dynamics which are independent of the animal’s actions (we capture the consequences of feeding and predation in the rewards; see <xref ref-type="sec" rid="sec018">Discussion</xref>). In particular, we assume that (a) the predator transitions from being <italic>absent</italic> (<italic>A</italic>) to <italic>present</italic> (<italic>P</italic>) with transition rate <italic>γ</italic><sub><italic>AP</italic></sub>, and from <italic>present</italic> to <italic>absent</italic> with transition rate <italic>γ</italic><sub><italic>PA</italic></sub>; and similarly, (b) the habitat quality transitions between being <italic>good</italic> (<italic>G</italic>) and <italic>bad</italic> (<italic>B</italic>) according to transition rates (<italic>γ</italic><sub><italic>GB</italic></sub>, <italic>γ</italic><sub><italic>BG</italic></sub>).</p>
<p>In terms of predation risk, a crucial factor is the probability that the animal is detected and subsequently caught if a predator is present, given that the animal is currently engaged in a particular action. One of the more substantial simplifications we make is to assume that being detected inevitably leads to getting caught, but incurs only a fixed, finite, negative reward, rather than having a more extreme sanction. We formulate predation risk directly in terms of a rate of detection, assuming that this is directly mirrored in the predation rate. For <italic>rest</italic> and <italic>assess</italic> in the <italic>refuge</italic> location, we assume that this rate is 0; in the <italic>patch</italic> location, we assume that the detection rate is a function of the current action, written in abbreviated form as <italic>δ</italic><sub><italic>a</italic></sub>, where <italic>a</italic> denotes the current action. We assume that detection rate is lowest when the animal chooses <italic>freeze</italic>, and more generally assume the ordering <italic>δ</italic><sub><italic>escape</italic></sub> ≥ <italic>δ</italic><sub><italic>transit</italic></sub> ≥ <italic>δ</italic><sub><italic>feed</italic></sub> &gt; <italic>δ</italic><sub><italic>assess</italic></sub> &gt; <italic>δ</italic><sub><italic>freeze</italic></sub>. Note that we assume that the risk of being caught is also lower if the animal chooses <italic>assess</italic>, since <italic>assess</italic> and <italic>freeze</italic> may reasonably be seen as lying on a continuum which trades off the degree of immobility with the amount of information garnered through risk assessment [<xref ref-type="bibr" rid="pcbi.1005916.ref030">30</xref>].</p>
<p>Habitats which are <italic>good</italic> (<italic>G</italic>) or <italic>bad</italic> (<italic>B</italic>) are defined in terms of the animal’s encounter rate with either <italic>rich</italic> or <italic>poor</italic> patches while feeding. A habitat which is <italic>good</italic> has a relatively high encounter rate <inline-formula id="pcbi.1005916.e008"><alternatives><graphic id="pcbi.1005916.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>r</mml:mi> <mml:mi>G</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> with <italic>rich</italic> patches and low encounter rate <inline-formula id="pcbi.1005916.e009"><alternatives><graphic id="pcbi.1005916.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>p</mml:mi> <mml:mi>G</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> with <italic>poor</italic> patches. Conversely, a habitat which is <italic>bad</italic> yields a low encounter rate <inline-formula id="pcbi.1005916.e010"><alternatives><graphic id="pcbi.1005916.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>r</mml:mi> <mml:mi>B</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> with <italic>rich</italic> patches, and a high encounter rate <inline-formula id="pcbi.1005916.e011"><alternatives><graphic id="pcbi.1005916.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>p</mml:mi> <mml:mi>B</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> with <italic>poor</italic> patches.</p>
</sec>
<sec id="sec007">
<title>Rewards</title>
<p>Each action is associated with a reward rate <italic>r</italic>. These are assumed to be negative (indicating an energetic cost) except for <italic>feed</italic> (net positive) and <italic>rest</italic> (zero). For net-negative reward actions, we assume the general ordering <italic>r</italic><sub><italic>escape</italic></sub> &lt; <italic>r</italic><sub><italic>transit</italic></sub> ≤ <italic>r</italic><sub><italic>assess</italic></sub> ≤ <italic>r</italic><sub><italic>freeze</italic></sub>, so that <italic>escape</italic> is assumed to be most costly, while we are generally agnostic about the relative energetic costs of the other actions. For the <italic>feed</italic> action, the reward rate depends on whether the currently-encountered <italic>patch</italic> is <italic>rich</italic> (rate <inline-formula id="pcbi.1005916.e012"><alternatives><graphic id="pcbi.1005916.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow> <mml:mi>r</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>) or <italic>poor</italic> (rate <inline-formula id="pcbi.1005916.e013"><alternatives><graphic id="pcbi.1005916.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow> <mml:mi>p</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>). A large negative reward <italic>r</italic><sub><italic>pred</italic></sub> ≪ 0 is associated with being detected/caught by a predator (note that this is not a rate), which may be considered a cost of injury (we return to the issue of modelling predation costs in the Discussion).</p>
<p>As in the simple example above, we assume that making a decision incurs a constant decision cost, <italic>c</italic><sub><italic>d</italic></sub> ≥ 0, which summarizes the computational, and presumably metabolic, costs associated with deliberation about which activity to pursue.</p>
</sec>
<sec id="sec008">
<title>Observations</title>
<p>The animal’s location is assumed to be directly observed, while the values of the <italic>predator</italic> and <italic>habitat</italic> variables are assumed to be only partially-observable. The animal is therefore required to make inferences about the latter which will depend on both prior knowledge of environment dynamics and observations.</p>
<p>We assume that certain observations are more probable when a predator is <italic>present</italic> rather than <italic>absent</italic>, provided the animal takes appropriate measures to detect them. Two distinct types of cue are assumed. Firstly, we assume that an <italic>indirect</italic>, or ‘passive’, cue <italic>o</italic><sub><italic>i</italic></sub> is available regardless of the activity in which the animal is engaged (e.g., hearing a rustle in the bushes). This is emitted at a rate <inline-formula id="pcbi.1005916.e014"><alternatives><graphic id="pcbi.1005916.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mo>+</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> when a predator is present, and at a rate <inline-formula id="pcbi.1005916.e015"><alternatives><graphic id="pcbi.1005916.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mo>-</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> when a predator is absent. We write ¬<italic>o</italic><sub><italic>i</italic></sub> for a <italic>non-observation</italic> of <italic>o</italic><sub><italic>i</italic></sub> when it could potentially have been observed. Secondly, we assume that a <italic>direct</italic>, or ‘active’, cue <italic>o</italic><sub><italic>d</italic></sub> is additionally available, but only if the animal is engaged in the <italic>assess</italic> activity (e.g., detecting a visual pattern at a particular location in the foliage). This is emitted at a rate <inline-formula id="pcbi.1005916.e016"><alternatives><graphic id="pcbi.1005916.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow> <mml:mo>+</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> when a predator is present, and at a rate <inline-formula id="pcbi.1005916.e017"><alternatives><graphic id="pcbi.1005916.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow> <mml:mo>-</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> when a predator is absent. Again, ¬<italic>o</italic><sub><italic>d</italic></sub> represents the non-observation of <italic>o</italic><sub><italic>d</italic></sub> when the latter would have been possible. Therefore, the animal may enter into different ‘information states’ regarding the <italic>predator</italic> variable depending on its choice of action, with <italic>assess</italic> providing the most reliable evidence. We assume that neither type of cue is available when the animal is engaged in <italic>rest</italic>. An absence of information is different from information about absence, as in ¬<italic>o</italic><sub><italic>i</italic></sub> or ¬<italic>o</italic><sub><italic>d</italic></sub>.</p>
<p>Information about habitat quality is assumed to be only available when the animal opts to <italic>feed</italic>. The relevant cue here is the current reward rate <inline-formula id="pcbi.1005916.e018"><alternatives><graphic id="pcbi.1005916.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:mi>r</mml:mi> <mml:mo>∈</mml:mo> <mml:mo>{</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow> <mml:mi>r</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow> <mml:mi>p</mml:mi></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> experienced while feeding. This will to some degree be informative about (by depending on) habitat quality—<italic>rich</italic> patches are more commonly encountered in a <italic>good</italic> habitat—but will not completely disambiguate the quality of the current habitat, since both types of habitat contain <italic>rich</italic> and <italic>poor</italic> patches.</p>
</sec>
<sec id="sec009">
<title>Discount factor</title>
<p>The animal is assumed to discount future rewards according to an exponential function with rate <italic>α</italic> ∈ [0, 1] (i.e., a unit reward received after a delay of <italic>τ</italic> seconds is treated as having present value <italic>e</italic><sup>−<italic>ατ</italic></sup>, so that a larger value of <italic>α</italic> leads to more rapid discounting). The effect on behaviour of varying the discount rate is not a primary focus of the current work, and it is set to <italic>α</italic> = 0.1 throughout.</p>
</sec>
<sec id="sec010">
<title>Belief states</title>
<p>In addition to its current location, the animal’s belief about whether a predator is <italic>present</italic> (<inline-formula id="pcbi.1005916.e019"><alternatives><graphic id="pcbi.1005916.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mi>t</mml:mi> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>) and whether the habitat is <italic>good</italic> (<inline-formula id="pcbi.1005916.e020"><alternatives><graphic id="pcbi.1005916.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mi>t</mml:mi> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>) are jointly a sufficient basis on which to choose its actions. These collectively form the animal’s ‘belief state’—allowing us to solve the induced belief state semi-Markov decision process.</p>
</sec>
<sec id="sec011">
<title>Belief state updates</title>
<p>How the animal’s beliefs change over time depends on both prior knowledge of the environment’s dynamics and any pertinent observations made. Since the <italic>predator</italic> and <italic>habitat quality</italic> variables evolve independently, we can consider belief updates for these separately.</p>
<p>In the case where there is no observation (such as when the animal engages in <italic>rest</italic> within the <italic>refuge</italic>), belief updates only depend on the environment dynamics. The two components of the belief state change from time <italic>t</italic> to <italic>t</italic> + <italic>τ</italic> according to
<disp-formula id="pcbi.1005916.e022"><alternatives><graphic id="pcbi.1005916.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e022" xlink:type="simple"/><mml:math display="block" id="M22"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi></mml:mrow> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>A</mml:mi> <mml:mi>P</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>A</mml:mi> <mml:mi>P</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>P</mml:mi> <mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mi>t</mml:mi> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mfrac><mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>A</mml:mi> <mml:mi>P</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>A</mml:mi> <mml:mi>P</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>P</mml:mi> <mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>A</mml:mi> <mml:mi>P</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>P</mml:mi> <mml:mi>A</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula> <disp-formula id="pcbi.1005916.e023"><alternatives><graphic id="pcbi.1005916.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi></mml:mrow> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>=</mml:mo> <mml:mfrac><mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>B</mml:mi> <mml:mi>G</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>B</mml:mi> <mml:mi>G</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>G</mml:mi> <mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mo>(</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mi>t</mml:mi> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mfrac><mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>B</mml:mi> <mml:mi>G</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>B</mml:mi> <mml:mi>G</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>G</mml:mi> <mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>B</mml:mi> <mml:mi>G</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>G</mml:mi> <mml:mi>B</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
For convenience, we consider an approximation to this for <italic>τ</italic> = Δ<italic>t</italic> ≪ 1
<disp-formula id="pcbi.1005916.e024"><alternatives><graphic id="pcbi.1005916.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>≈</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mi>t</mml:mi> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>P</mml:mi> <mml:mi>A</mml:mi></mml:mrow></mml:msub> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mi>t</mml:mi> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>A</mml:mi> <mml:mi>P</mml:mi></mml:mrow></mml:msub> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula> <disp-formula id="pcbi.1005916.e025"><alternatives><graphic id="pcbi.1005916.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>≈</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mi>t</mml:mi> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>G</mml:mi> <mml:mi>B</mml:mi></mml:mrow></mml:msub> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>β</mml:mi> <mml:mi>t</mml:mi> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mi>γ</mml:mi> <mml:mrow><mml:mi>B</mml:mi> <mml:mi>G</mml:mi></mml:mrow></mml:msub> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
When additional information is provided by observations, this needs to be combined with prior expectations according to Bayes rule. If the animal is engaged in an activity for which only indirect observations <italic>o</italic><sub><italic>i</italic></sub> provide information about the state of predation, then from Bayes rule, the updated belief <inline-formula id="pcbi.1005916.e026"><alternatives><graphic id="pcbi.1005916.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>β</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> having received an instance of <italic>o</italic><sub><italic>i</italic></sub> in the interval (<italic>t</italic> + Δ<italic>t</italic>) is
<disp-formula id="pcbi.1005916.e027"><alternatives><graphic id="pcbi.1005916.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e027" xlink:type="simple"/><mml:math display="block" id="M27"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>β</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∝</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
where <inline-formula id="pcbi.1005916.e028"><alternatives><graphic id="pcbi.1005916.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:msubsup><mml:mo>λ</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo></mml:msubsup> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1005916.e029"><alternatives><graphic id="pcbi.1005916.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is given by <xref ref-type="disp-formula" rid="pcbi.1005916.e024">Eq (3)</xref>. For an omission, ¬<italic>o</italic><sub><italic>i</italic></sub>, the likelihood <inline-formula id="pcbi.1005916.e030"><alternatives><graphic id="pcbi.1005916.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>¬</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:msubsup><mml:mo>λ</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo></mml:msubsup> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is used instead. If the animal has access to both indirect and direct observations (i.e., when engaging in <italic>assess</italic>), belief updates follow a similar pattern, e.g.,
<disp-formula id="pcbi.1005916.e031"><alternatives><graphic id="pcbi.1005916.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>β</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∝</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>D</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>P</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
where <inline-formula id="pcbi.1005916.e032"><alternatives><graphic id="pcbi.1005916.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:msubsup><mml:mo>λ</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>+</mml:mo></mml:msubsup> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, and so forth for the possible combinations of values for <italic>o</italic><sub><italic>i</italic></sub> and <italic>o</italic><sub><italic>d</italic></sub>.</p>
<p>Relevant information about the quality of the habitat is only available when the animal selects <italic>feed</italic>, and encounters either <italic>rich</italic> or <italic>poor</italic> patches. Thus, the updated belief <inline-formula id="pcbi.1005916.e033"><alternatives><graphic id="pcbi.1005916.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>β</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> when encountering a <italic>rich</italic> patch in the interval (<italic>t</italic> + Δ<italic>t</italic>) is
<disp-formula id="pcbi.1005916.e034"><alternatives><graphic id="pcbi.1005916.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>β</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>∝</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi> <mml:mspace width="4pt"/><mml:mo>|</mml:mo> <mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
where <inline-formula id="pcbi.1005916.e035"><alternatives><graphic id="pcbi.1005916.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi> <mml:mspace width="4pt"/><mml:mo>|</mml:mo> <mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>r</mml:mi> <mml:mi>G</mml:mi></mml:msubsup> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1005916.e036"><alternatives><graphic id="pcbi.1005916.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:msubsup><mml:mi>β</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mi>Q</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is given by <xref ref-type="disp-formula" rid="pcbi.1005916.e025">Eq (4)</xref>. If the encounter is with a <italic>poor</italic> patch, the likelihood <inline-formula id="pcbi.1005916.e037"><alternatives><graphic id="pcbi.1005916.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi> <mml:mo>|</mml:mo> <mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:msubsup><mml:mi>ρ</mml:mi> <mml:mi>p</mml:mi> <mml:mi>G</mml:mi></mml:msubsup> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> is used instead.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005916.g002">Fig 2B and 2C</xref> illustrate how beliefs <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) and <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>) evolve over time for the various different cases.</p>
</sec>
<sec id="sec012">
<title>Interruption</title>
<p>When available, interruption is defined as the ability to stop an activity prematurely and make a new decision. That is, given an initial commitment at time <italic>t</italic> to an activity (<italic>a</italic>, <italic>τ</italic>), interruption is the capacity to stop that activity at any intermediate time in the interval (<italic>t</italic>, <italic>t</italic> + <italic>τ</italic>), and make a new decision (at a cost of <italic>c</italic><sub><italic>d</italic></sub>). Interruption can therefore be thought of as an additional, ‘internal’ action; how decisions about this action should be made, as well as issues surrounding its potential cost and mechanisms, are the principal concerns of the following sections.</p>
</sec>
</sec>
<sec id="sec013" sec-type="results">
<title>Results</title>
<p>While partially-observable problems are generally too large to be solved exactly, the current model is sufficiently simple that we can solve a discretized version of the (actually continuous time and continuous probability) belief state semi-Markov problem for the optimal policy using value iteration. Beliefs <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>) and <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) lie in the interval [0, 1] and were discretized at a resolution of Δ<italic>β</italic> = 0.01; time was discretized at intervals of Δ<italic>t</italic> = 1 s; and selections of duration <italic>τ</italic> were from {1, 2, …, 15} seconds. Note that this rather severe discretization makes for some apparent discontinuities in the optimal policy, but the general form of choice remains.</p>
<sec id="sec014">
<title>Basic model behaviour</title>
<p>To examine the basic behaviour of the model, we start by setting the decision cost to zero, <italic>c</italic><sub><italic>d</italic></sub> = 0. <xref ref-type="fig" rid="pcbi.1005916.g003">Fig 3A</xref> displays the optimal actions <italic>a</italic>* as a function of the animal’s location, <italic>refuge</italic> (left) or <italic>patch</italic> (right), and belief state {<italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>), <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>)}. In the <italic>refuge</italic>, the animal opts to <italic>transit</italic> to the <italic>patch</italic> only if a predator is unlikely, chooses to <italic>rest</italic> if a predator is likely, and selects <italic>assess</italic> when more uncertain. Choice is modulated by the probability that the habitat quality is <italic>good</italic>: the animal is slightly more likely to tolerate a higher probability that a predator is <italic>present</italic> in order to <italic>transit</italic>, while if the habitat quality is probably <italic>bad</italic>, the animal is increasingly likely to <italic>rest</italic>, in fact even when the probability of a predator is lower than 0.5. Note that even though the utility of <italic>rest</italic> was assumed to be 0, there are conditions under which the animal chooses it anyway. This occurs when the cost associated with <italic>assess</italic> is deemed too high to be worth paying (i.e., when it is highly probable that a predator is <italic>present</italic>, or when the habitat quality is likely to be <italic>bad</italic>). The advantage of <italic>assess</italic> is that it more quickly moves the animal to a state of increased certainty about whether a predator is <italic>present</italic> or not: if the predator is likely <italic>present</italic>, it is better to conserve energy by selecting <italic>rest</italic>; if the predator is likely <italic>absent</italic>, then the sooner the animal chooses to <italic>transit</italic>, the better.</p>
<fig id="pcbi.1005916.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005916.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Optimal policies in the absence of a decision cost.</title>
<p>(A) Optimal actions <italic>a</italic>* as a function of current location (left, <italic>refuge</italic>; right, <italic>patch</italic>), and current beliefs that a predator is <italic>present</italic>, <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>), and that the current habitat quality is <italic>good</italic>, <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>). The discretization of the state space leads to the apparently rough solution. (B) If <italic>escape</italic> does not lead to safety, then <italic>freeze</italic> will always be selected in the <italic>patch</italic> instead. (C–E) The distribution of behaviour shown by the optimal policy depends on whether there is a predator in the environment (black bars) or not (white bars). This includes (C) the proportion of time spent in <italic>refuge</italic> vs. <italic>patch</italic>, and (D) the proportion of time spent in different activities. (E) Even though the policy selects activity durations to be as short as possible (<italic>τ</italic>* = 1 s), contiguous periods of a given action (‘bouts’) may be longer, reflecting successive choices of the same action. The bars show mean bout lengths measured over 100 instantiations of a 15-minute period; error bars indicate ±1 standard error. Environment parameters as above; reward rates <inline-formula id="pcbi.1005916.e038"><alternatives><graphic id="pcbi.1005916.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005916.e039"><alternatives><graphic id="pcbi.1005916.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi> <mml:mrow><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow> <mml:mi>p</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <italic>r</italic><sub><italic>rest</italic></sub> = 0, <italic>r</italic><sub><italic>transit</italic></sub> = <italic>r</italic><sub><italic>assess</italic></sub> = <italic>r</italic><sub><italic>freeze</italic></sub> = −0.1, <italic>r</italic><sub><italic>escape</italic></sub> = −1; detection rates <italic>δ</italic><sub><italic>feed</italic></sub> = <italic>δ</italic><sub><italic>transit</italic></sub> = <italic>δ</italic><sub><italic>escape</italic></sub> = 0.05, <italic>δ</italic><sub><italic>assess</italic></sub> = 0.02, <italic>δ</italic><sub><italic>freeze</italic></sub> = 0.01, <italic>δ</italic><sub><italic>rest</italic></sub> = 0; predation punishment <italic>r</italic><sub><italic>pred</italic></sub> = −100; decision cost <italic>c</italic><sub><italic>d</italic></sub> = 0.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005916.g003" xlink:type="simple"/>
</fig>
<p>When in the <italic>patch</italic> location, the animal selects <italic>feed</italic> when <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>) is low, <italic>assess</italic> when there is greater uncertainty, and chooses a defensive action ∈ {<italic>freeze</italic>, <italic>escape</italic>} when a predator is more likely than not to be <italic>present</italic>. Again, these tendencies are slightly modulated by the belief <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>). The decision between <italic>freeze</italic> and <italic>escape</italic> is controlled by a number of factors in the model. Firstly, there is a difference in the cost of performing these actions, as we assumed that <italic>escape</italic> is more costly than <italic>freeze</italic>. Secondly, there is a difference in detectability while performing these actions—it is assumed that the detection rate is higher for <italic>escape</italic> than for <italic>freeze</italic>. Finally, there is the fact—which is the reason why <italic>escape</italic> is selected at all—that a successful <italic>escape</italic> will get the animal back to safety, while <italic>freeze</italic> leaves the animal in the <italic>patch</italic> location. Unsurprisingly, if <italic>escape</italic> is rendered ineffectual, in the sense that its performance also leaves the animal in the <italic>patch</italic>, then <italic>freeze</italic> is always preferred (<xref ref-type="fig" rid="pcbi.1005916.g003">Fig 3B</xref>), consistent with changes in defensive pattern observed in rats and mice when flight is not possible [<xref ref-type="bibr" rid="pcbi.1005916.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref031">31</xref>].</p>
<p>As in the simple example considered above, when there is no decision cost it is always optimal for the animal to choose <italic>τ</italic> to be as short as possible (see ‘Supporting information’, <xref ref-type="supplementary-material" rid="pcbi.1005916.s001">S1 Fig</xref>). This is because there is no cost to doing so, while, in the absence of an interrupt, there is a potential cost of committing to longer durations (<italic>viz.</italic>, not being able to change course of action if observations indicate a change in the environment). <italic>τ</italic> becomes relevant when we consider a nonzero decision cost below.</p>
<p>In <xref ref-type="fig" rid="pcbi.1005916.g003">Fig 3C–3E</xref>, we summarize aspects of behaviour when the optimal policy is repeatedly exposed to an environment where a predator is either <italic>absent</italic> (white bars) or <italic>present</italic> (black bars). Unsurprisingly, when a predator is <italic>present</italic>, the animal spends most of its time in the <italic>refuge</italic> (<xref ref-type="fig" rid="pcbi.1005916.g003">Fig 3C</xref>) engaged in either <italic>rest</italic> or <italic>assess</italic> activity (<xref ref-type="fig" rid="pcbi.1005916.g003">Fig 3D</xref>), whereas it spends most of its time feeding in the <italic>patch</italic> when there is no predator. The adaptiveness of these behaviours is evident, and qualitatively similar reconfigurations of activity patterns in response to predator presence/absence are observed in laboratory-based ethological studies (e.g., [<xref ref-type="bibr" rid="pcbi.1005916.ref030">30</xref>]). <xref ref-type="fig" rid="pcbi.1005916.g003">Fig 3E</xref> makes the further point that even if the shortest duration <italic>τ</italic> is always selected, this doesn’t mean that ‘bouts’ of behaviour, defined as continuous periods of performing a single action, will always be of minimal duration. Instead, an external observer would sometimes measure longer behavioural bouts, particularly in the case of <italic>rest</italic> and <italic>feed</italic> activities.</p>
</sec>
<sec id="sec015">
<title>The price of responsiveness: Decision cost, without interrupt</title>
<p>As the decision cost rises from zero (<italic>c</italic><sub><italic>d</italic></sub> &gt; 0), optimal behaviour changes. <xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4A</xref> shows the optimal policy for decision cost <italic>c</italic><sub><italic>d</italic></sub> = 0.01, now displaying both optimal actions <italic>a</italic>* (left panels) in each location and corresponding optimal durations <italic>τ</italic>* (right panels). Optimal actions <italic>a</italic>* are essentially identical to the <italic>c</italic><sub><italic>d</italic></sub> = 0 case above (cf. <xref ref-type="fig" rid="pcbi.1005916.g003">Fig 3A</xref>), and optimal durations <italic>τ</italic>* are generally selected to be as short as possible. The exception engendered by this rather minimal decision cost comes in the case of <italic>rest</italic>, where longer durations are observed, particularly when the habitat is likely to be <italic>bad</italic>. These reflect the dynamics of the environment: if habitat quality is currently likely to be <italic>bad</italic>, and conditions change relatively slowly, then conditions are likely to remain <italic>bad</italic> in the near future. Thus, rather than making another (costly) decision to <italic>rest</italic> at that future time, the animal can safely commit to <italic>rest</italic> for a longer period.</p>
<fig id="pcbi.1005916.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005916.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Non-zero decision costs encourage temporally-extended activity when interruption is possible.</title>
<p>In each case, there are four plots: the optimal choices of action <italic>a</italic>* (left plots) and duration <italic>τ</italic>* (right plots) are shown as a function of location (<italic>refuge</italic>, upper; <italic>patch</italic>, lower) and belief {<italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>), <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>)}. (A;B) Optimal non-interruptible policies for decision costs (A) <italic>c</italic><sub><italic>d</italic></sub> = 0.01 and (B) <italic>c</italic><sub><italic>d</italic></sub> = 0.2. (C;D) Optimal interruptible policies for the same decision costs: (C) <italic>c</italic><sub><italic>d</italic></sub> = 0.01 and (D) <italic>c</italic><sub><italic>d</italic></sub> = 0.2. Parameters otherwise set as above.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005916.g004" xlink:type="simple"/>
</fig>
<p>By contrast, all other actions are associated with short durations. As in the previous case, this is sensible considering the consequences of doing otherwise. For example, when in the <italic>refuge</italic>, an animal that commits to <italic>assess</italic> for an extended duration may thereby forego time that could be better spent foraging or resting; in the <italic>patch</italic>, the same commitment risks foregoing the opportunity to <italic>feed</italic> or respond defensively (<italic>freeze</italic>/<italic>escape</italic>).</p>
<p>If decisions are made even more expensive, e.g. <italic>c</italic><sub><italic>d</italic></sub> = 0.2, further changes in policy are observed (<xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4B</xref>). In the <italic>refuge</italic>, <italic>rest</italic> becomes the most prominent action, with a duration that is uniformly chosen to be the longest possible. This minimizes decision costs when the environment is determined to be unfavourable. Note that under the assumed environment dynamics, beliefs <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>) and <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) will both move towards 0.5 once <italic>rest</italic> is initiated (recall that no observation is available during this activity), and yet the belief state (0.5, 0.5) yields the selection of <italic>rest</italic> under this policy. In other words, once this policy initiates <italic>rest</italic>, it will never do anything else, since the potential benefits of doing anything else are outweighed by the costs (i.e., any other option must have an average reward &lt; 0, since <italic>rest</italic> has net reward 0). Of course, in reality, various factors would militate against this, including the stochasticity of action choice and progressive starvation (see <xref ref-type="sec" rid="sec018">Discussion</xref>). In the <italic>patch</italic>, it is notable that <italic>freeze</italic> has all but disappeared from the behavioural repertoire, replaced by <italic>escape</italic>. This is because its benefits—lower detectability and the avoidance of unnecessary excursions back to the <italic>refuge</italic>— are now outweighed by the burden of greater future decision costs incurred in the <italic>patch</italic>. Some subtle increases in <italic>τ</italic>* are discernible for <italic>feed</italic> at low levels of <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>); but overall, variation in <italic>τ</italic>* remains limited.</p>
</sec>
<sec id="sec016">
<title>The benefit of interruptibility: Decision cost, with interrupt</title>
<p>What happens if we now allow the animal to interrupt activities prior to their completion? The animal’s optimal policy only recommends the activity (<italic>a</italic>*, <italic>τ</italic>*) in initial belief state {<italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>), <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>)} which is best <italic>in expectation</italic> over possible future belief trajectories. It is therefore perfectly possible that, having chosen optimally with respect to the initial belief state, experience sends the animal on a particular trajectory where it reaches a belief state in which an alternative activity would be preferable. Described at the level of a meta-decision, interruption should occur exactly when the benefit of interrupting an activity is greater than that of continuing it (cf. [<xref ref-type="bibr" rid="pcbi.1005916.ref015">15</xref>]).</p>
<p>
<xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4C</xref> shows the optimal interruptible policy for the same <italic>c</italic><sub><italic>d</italic></sub> = 0.01 case as before. The clear difference is that for actions <italic>assess</italic>, <italic>feed</italic>, and <italic>freeze</italic>, it is optimal to set the duration to be as <italic>long</italic> as possible: <italic>τ</italic>* = <italic>τ</italic><sub>max</sub>. Equipped with the (free) option of interrupting itself at any time, the animal can minimize its decision costs by provisionally committing to long activity durations, only interrupting and making another decision when it really needs to.</p>
<p>The exceptions are <italic>transit</italic> and <italic>escape</italic>. For <italic>transit</italic> (i.e., moving from <italic>refuge</italic> to <italic>patch</italic>), choosing a longer duration never makes any sense—it would only increase the associated energetic cost and predation risk—and there is no advantage to interrupting this activity in the model. The same reasoning applies to <italic>escape</italic>. Since beliefs evolve in a predictable manner for <italic>rest</italic>, there is never a reason to interrupt this activity—the duration is calibrated in the same manner as in the non-interruptible case.</p>
<p>
<xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4D</xref> displays the optimal interruptible policy for the more expensive, <italic>c</italic><sub><italic>d</italic></sub> = 0.2, case. <italic>Rest</italic> begins to occupy greater regions of belief space when in the <italic>refuge</italic>. This is similar to the trend in the non-interruptible case (cf. <xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4B</xref>), albeit to a lesser extent. The interruptible policy does not get ‘stuck’ permanently selecting <italic>rest</italic>, but will rather select <italic>assess</italic> when uncertainty is greatest (i.e., at (0.5, 0.5)), and at many other points in this region. Note also that in contrast to the uniform choice of the longest duration for <italic>rest</italic> in the non-interruptible case, there is still some gradation in choice of <italic>τ</italic> in the interruptible policy (<xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4D</xref>, upper right panel): when it is strongly believed that habitat quality is currently <italic>good</italic>, it is better to choose shorter durations of <italic>rest</italic> to be able to take advantage of predator-free foraging conditions in the near future (cf. <xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4A and 4C</xref>).</p>
<p>Equipped with the capacity to interrupt itself, an animal should perform at least as well as when lacking this capacity (cf. [<xref ref-type="bibr" rid="pcbi.1005916.ref015">15</xref>], Theorem 2). At worst, decisions could be taken at maximum frequency, and the same decision costs incurred as in the non-interruptible case. We expect the interruptible case to do better than this, however: interruption should allow the animal to commit to extended activity flexibly, and so decrease the cost of unnecessary decisions—just as in the simplified example we first considered.</p>
<p>As in that example, we compared performance in a simulated experiment. Here, behaviour is measured over a 6-minute period in which a predator is initially <italic>absent</italic> (2 min), then <italic>present</italic> (2 min), then <italic>absent</italic> again (2 min); habitat quality is allowed to fluctuate randomly. We ran this experiment 1000 times for different settings of the decision cost <italic>c</italic><sub><italic>d</italic></sub>, ensuring that conditions were exactly matched between policies. We measured the resulting rewards averaged over both episodes and experiments. <xref ref-type="fig" rid="pcbi.1005916.g005">Fig 5A</xref> (inverted triangles; ‘exact’) plots the reward rate achieved by the non-interruptible policy as a fraction of that achieved by the interruptible policy (cf. <xref ref-type="fig" rid="pcbi.1005916.g001">Fig 1G</xref>). As seen before, when <italic>c</italic><sub><italic>d</italic></sub> = 0, this fraction is 1, reflecting the fact that the optimal strategy here is to make decisions as often as possible, since there is no penalty to doing so. However, as decisions become increasingly expensive (i.e., <italic>c</italic><sub><italic>d</italic></sub> becomes larger), the fractional utility rate decreases, reflecting the fact that the interruptible policy is achieving higher rewards. Beyond a certain level of decision cost (here, <italic>c</italic><sub><italic>d</italic></sub> &gt; 0.4), the fraction reverts to 1.</p>
<fig id="pcbi.1005916.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005916.g005</object-id>
<label>Fig 5</label>
<caption>
<title>The ability to interrupt on-going behaviour confers a reward advantage.</title>
<p>(A) Ratio of average total amount of reward per trial (non-interrupt/interrupt) for different decision costs. This is shown both for the exact interruptible policy (black triangles, dashed line), and the approximate interruptible policy (red asterisks) which is based on a linear approximation (as detailed in the Section ‘A cheap interruption mechanism’ below). For each decision cost, optimal non-interruptible and interruptible policies performed 1000 trials. (B) Average number of decisions per time step and (C) average percentage time spent in <italic>rest</italic> for the optimal non-interrupible (blue circles) and interruptible (magenta squares) policies. (D) Behaviour and beliefs of the optimal non-interruptible (upper) and interruptible (lower) policy for a particular trial when <italic>c</italic><sub><italic>d</italic></sub> = 0.1. Time points at which decisions are made are indicated by vertical dashed lines. Model parameters otherwise set as above.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005916.g005" xlink:type="simple"/>
</fig>
<p>Again, the reward advantage comes from the reduction in the frequency of decisions that is possible when the animal has the capacity to interrupt (<xref ref-type="fig" rid="pcbi.1005916.g005">Fig 5B</xref>). Reversion of the fractional reward rate to 1 in this case corresponds to the point at which simply spending all of its time engaged in <italic>rest</italic> is the optimal course of action for the animal, regardless of the capacity to interrupt. If we explicitly compare the average time during the experiment spent at <italic>rest</italic> for non-interruptible and interruptible policies, both are eventually driven to exclusive choice of this action as decisions become more expensive. However, this occurs for lower values of <italic>c</italic><sub><italic>d</italic></sub> when interruption is unavailable (<xref ref-type="fig" rid="pcbi.1005916.g005">Fig 5C</xref>).</p>
<p>
<xref ref-type="fig" rid="pcbi.1005916.g005">Fig 5D</xref> compares the behaviour and beliefs of the non-interruptible (upper) and interruptible (lower) policies for a particular run of the experiment at an intermediate decision cost, <italic>c</italic><sub><italic>d</italic></sub> = 0.1. This clearly illustrates the fact that the non-interruptible policy makes decisions at a much higher frequency (vertical dashed lines), but also highlights differences in choices. Most notably, in both cases the animal returns to the <italic>patch</italic> after the predator has been removed from the environment, but when faced with observations that may indicate a potential threat, their behaviour differs. In the non-interruptible case, the animal opts to escape to the <italic>refuge</italic> and engage in <italic>rest</italic>, since the costs of foraging are deemed too high when a predator is thought likely and habitat quality is low (<xref ref-type="fig" rid="pcbi.1005916.g005">Fig 5D</xref>, upper). By contrast, in the interruptable case, the animal opts to <italic>assess</italic> whether there is a real threat, and continues to <italic>feed</italic> when it transpires that no predator is around—it is sufficiently flexible in its behaviour for it to be worthwhile to continue in the <italic>patch</italic> and intermix periods of both feeding and assessment (<xref ref-type="fig" rid="pcbi.1005916.g005">Fig 5D</xref>, lower). Note also the shorter bouts of <italic>rest</italic> in the interruptible case, leading to a greater frequency of <italic>assess</italic> and so, at least in this case, a marginally earlier return to the <italic>patch</italic>.</p>
</sec>
<sec id="sec017">
<title>A cheap interruption mechanism</title>
<p>Interruption is evidently useful; however, we have not considered the costs of the calculations associated with this operation. Since interruption can be thought of as another layer of decision-making, we might just have increased the computational burden. One answer is to conceive of a cheap and ‘light-weight’ interruption process.</p>
<p>The points at which interruption should be triggered effectively form a boundary on belief space. We might therefore consider that at the outset of an activity, one could ‘construct’ such a boundary, or <italic>threshold</italic>, and then have interruption occur whenever this threshold is breached. Belief-monitoring would still be required to recognize if and when the animal enters the termination set of beliefs. This still implies a decision—whether or not this threshold has been reached—but of a particularly simple kind.</p>
<p><xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6A–6C</xref> (symbols) plot the optimal interruption thresholds <italic>θ</italic>, i.e., levels of belief <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>) at which activities should be interrupted, as a function of decision cost <italic>c</italic><sub><italic>d</italic></sub> and three fixed levels of belief <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>). The thresholds are plotted for <italic>feed</italic> and for <italic>assess</italic> ∈ {<italic>patch</italic>, <italic>refuge</italic>}, which are activities that show a robust increase in duration with nonzero decision costs (cf. <xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4C and 4D</xref> above); since <italic>freeze</italic> tends to be disfavoured at higher decision costs (cf. <xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4D</xref>), data points are much more sparse, and so we do not consider it here. Note that <italic>feed</italic> only has an upper boundary on <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>), while <italic>assess</italic> has both upper and lower boundaries. Also, for some combinations of <italic>c</italic><sub><italic>d</italic></sub> and <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>), the set of beliefs {<italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>)} for which <italic>assess</italic> in the <italic>refuge</italic> location is optimal (i.e., the ‘initiation set’) is empty, and so interruption thresholds are omitted in these cases (e.g., for <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) = 0.2, <italic>c</italic><sub><italic>d</italic></sub> &gt; 0.2; <xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6C</xref>).</p>
<fig id="pcbi.1005916.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005916.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Optimal and approximate interruption thresholds.</title>
<p>(A–C) Optimal thresholds <italic>θ</italic> (symbols) for degree of belief <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>) as a function of decision cost <italic>c</italic><sub><italic>d</italic></sub> and (fixed) belief level <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>). These are shown for (A) <italic>feed</italic>, (B) <italic>assess</italic> (in <italic>patch</italic>), and (C) <italic>assess</italic> (in <italic>refuge</italic>). The lines show a linear approximation to the thresholds. (D–F) Optimal and approximate thresholds for the same activities as a function of <italic>c</italic><sub><italic>d</italic></sub> and cue reliability (i.e., higher or lower true positive rate for indirect observations, <inline-formula id="pcbi.1005916.e040"><alternatives><graphic id="pcbi.1005916.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mo>+</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>, or direct observations, <inline-formula id="pcbi.1005916.e041"><alternatives><graphic id="pcbi.1005916.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow> <mml:mo>+</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula>); <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) = 0.5. Unless otherwise indicated, the default reliabilities were <inline-formula id="pcbi.1005916.e042"><alternatives><graphic id="pcbi.1005916.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:msubsup><mml:mo>λ</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005916.e043"><alternatives><graphic id="pcbi.1005916.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:msubsup><mml:mo>λ</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005916.e044"><alternatives><graphic id="pcbi.1005916.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:msubsup><mml:mo>λ</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub> <mml:mo>-</mml:mo></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1005916.e045"><alternatives><graphic id="pcbi.1005916.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:msub><mml:mo>λ</mml:mo> <mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:msub> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>9</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. Other parameters as previous.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005916.g006" xlink:type="simple"/>
</fig>
<p>As one might expect from the example optimal policies seen previously (cf. <xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4C and 4D</xref>), the interruption threshold for <italic>feed</italic> increases for higher <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>), i.e., as the payoff for feeding increases (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6A</xref>). With <italic>assess</italic> in the <italic>patch</italic> location, the upper and lower thresholds move upwards as <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) increases, respectively indicating a greater willingness to interrupt and initiate feeding (lower boundary), and a greater reluctance to trigger defensive behaviour (upper boundary) (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6B</xref>). For <italic>assess</italic> in the <italic>refuge</italic>, the upper boundary moves upwards as <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) increases, indicating greater reluctance to interrupt and initiate <italic>rest</italic> when habitat quality is likely to be <italic>good</italic>; the lower boundary shows less variation—the animal requires <italic>β</italic><sup><italic>D</italic></sup>(<italic>P</italic>) to be very low to interrupt and initiate <italic>transit</italic>, regardless of <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6C</xref>).</p>
<p>The thresholds <italic>θ</italic> for the first two cases are well approximated by linear functions of <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) and <italic>c</italic><sub><italic>d</italic></sub>, while this is less true of <italic>assess</italic> in the <italic>refuge</italic> location (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6A–6C</xref>, dashed lines). We can nevertheless ask how well, in comparison to the optimal policy, an animal will do when selecting interruption thresholds according to the linear function which most closely approximates the optimal thresholds. <xref ref-type="fig" rid="pcbi.1005916.g005">Fig 5A</xref> (red asterisks) shows that this simple, approximate way of setting thresholds leads to benefits that are extremely close to that of the exact case.</p>
<p>It is also informative to examine how interruption thresholds change as a function of cue reliability. <xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6D–6F</xref> show these as a function of decision cost <italic>c</italic><sub><italic>d</italic></sub> and true positive rates for either indirect cues, <inline-formula id="pcbi.1005916.e046"><alternatives><graphic id="pcbi.1005916.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mo>+</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6D</xref>), or direct cues, <inline-formula id="pcbi.1005916.e021"><alternatives><graphic id="pcbi.1005916.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005916.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:msubsup><mml:mo>λ</mml:mo> <mml:mrow><mml:msub><mml:mi>o</mml:mi> <mml:mi>d</mml:mi></mml:msub></mml:mrow> <mml:mo>+</mml:mo></mml:msubsup></mml:math></alternatives></inline-formula> (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6E and 6F</xref>), while <italic>β</italic><sup><italic>Q</italic></sup>(<italic>G</italic>) is kept constant. Reducing the true positive rate in either case means less reliable information about the predator.</p>
<p>For <italic>feed</italic>, thresholds decrease with less reliable indirect cues, consistent with greater caution—the animal is increasingly prepared to interrupt feeding in order to <italic>assess</italic> and gain better information (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6D</xref>).</p>
<p>For <italic>assess</italic> in the <italic>patch</italic> location, upper thresholds similarly decrease with less reliable direct cues, reflecting a greater willingness to trigger interruption and switch to defensive behaviour (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6E</xref>, upper). That lower thresholds actually increase with less reliable cues indicates a greater willingness to interrupt and initiate <italic>feed</italic> in spite of having less reliable predation cues; this might seem the exact opposite of more cautious behaviour. The reason is that gathering information via <italic>assess</italic> decreases in marginal value for unreliable cues, making <italic>feed</italic> an increasingly attractive alternative. Note that the relative reliabilities of direct and indirect cues are important in this trade off, since <italic>feed</italic> still provides some information via the latter class of cues.</p>
<p>Finally, thresholds for <italic>assess</italic> in the <italic>refuge</italic> location follow a qualitatively similar pattern (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6F</xref>). With less reliable cues, the animal is quicker to interrupt its behaviour and initiate <italic>rest</italic>, thereby conserving its energy; with more reliable cues, the animal is more conservative in making this transition (<xref ref-type="fig" rid="pcbi.1005916.g006">Fig 6F</xref>, upper thresholds). The difference in thresholds is less pronounced in the downwards direction, so that a relatively high degree of certainty regarding predator absence is required before initiating <italic>transit</italic> in all cases.</p>
</sec>
</sec>
<sec id="sec018" sec-type="conclusions">
<title>Discussion</title>
<p>We used the simple example of foraging under predation risk to explore the possible advantages of being able to interrupt on-going behaviours. We showed that this allows animals to make provisional commitments to courses of behaviour rather than having either to check obsessively or just not to exploit available resources at all. This had measurable benefits in terms of efficiency and effectiveness. We also showed that it is not necessary to solve a complex decision problem to choose whether to interrupt, but rather that a simple, cheaply-parameterized, approximate, threshold-based policy can perform almost as well as the optimal policy across a variety of parameter settings.</p>
<p>In our model, decision cost was summarized by a simple scalar value. However it may in reality comprise separate components, including an intrinsic (e.g., metabolic) cost of performing the computation, and an opportunity cost, which summarizes what could have been obtained by employing the engaged resource (time, computation) otherwise [<xref ref-type="bibr" rid="pcbi.1005916.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005916.ref034">34</xref>]. The cost we considered, <italic>c</italic><sub><italic>d</italic></sub>, is a version of the former, and could arise from steps of expansion and calculation in a decision tree used for planning. The opportunity cost of time arises from discounting—the fact that taking time to think postpones <italic>future</italic> rewards, making them less valuable (an issue more extensively explored in the case of long-run average reward; cf. [<xref ref-type="bibr" rid="pcbi.1005916.ref035">35</xref>]). The opportunity cost of the use of other cognitive resources for deliberation, such as working memory, are starting to be considered and quantified [<xref ref-type="bibr" rid="pcbi.1005916.ref036">36</xref>–<xref ref-type="bibr" rid="pcbi.1005916.ref039">39</xref>]. Model-free planning [<xref ref-type="bibr" rid="pcbi.1005916.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref041">41</xref>] is likely to impose far smaller cognitive costs than the sort of model-based planning that we have so far been considering. However, at the very least, there will still be costs associated with task switching [<xref ref-type="bibr" rid="pcbi.1005916.ref042">42</xref>].</p>
<p>The activities (<italic>a</italic>, <italic>τ</italic>) that formed the objects of choice in the current work may be recognised as a simple form of <italic>option</italic> [<xref ref-type="bibr" rid="pcbi.1005916.ref015">15</xref>]—a policy for taking actions over an extended period of time—which has formed one basis (amongst many, cf. [<xref ref-type="bibr" rid="pcbi.1005916.ref043">43</xref>]) for exploring the issue of temporal abstraction in reinforcement learning. The benefit of being able to interrupt an option before it would otherwise terminate was highlighted in the initial options paper by Sutton and colleagues [<xref ref-type="bibr" rid="pcbi.1005916.ref015">15</xref>] (the authors also cite previous work by Kaelbling [<xref ref-type="bibr" rid="pcbi.1005916.ref044">44</xref>]), but issues surrounding decision cost, plausible mechanisms for interruption, and partial observability were not considered there. More recent work by Precup and colleagues [<xref ref-type="bibr" rid="pcbi.1005916.ref045">45</xref>], who introduce an ‘option-critic architecture’ in the context of discovering and learning options, explicitly considers the idea that a form of switching cost could encourage commitment to option execution.</p>
<p>We showed that changing the informativeness of cues about the predator had consequences such as increasing the propensity to feed and altering interruption thresholds. The effects of such changes on the observed temporal structure of behaviour are subtle, since the speed with which the belief about the presence of the predator changes will also change. In the case we simulated, observations remained sufficiently informative that the latter effect had little impact, but it would be interesting to examine more systematically how thresholds and speeds interact in determining when interruption occurs. Since this would require some significant adjustments to the current model, we leave exploration of this subtlety for future work.</p>
<p>The trade off between energetic gain and predation risk is a central topic of behavioural ecology [<xref ref-type="bibr" rid="pcbi.1005916.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref046">46</xref>] and has been the subject of extensive previous theoretical work, though principally at more ‘molar’ levels of analysis than our approach here [<xref ref-type="bibr" rid="pcbi.1005916.ref028">28</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref048">48</xref>]. While our model of foraging under predation risk was loosely inspired by ethological and ethoexperimental studies of rodent behaviour in such settings [<xref ref-type="bibr" rid="pcbi.1005916.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref049">49</xref>–<xref ref-type="bibr" rid="pcbi.1005916.ref051">51</xref>], a more realistic model would extend this in a number of ways.</p>
<p>A first extension concerns the model of predation. Most notably, in our detailed model, getting caught by the predator was associated with a large negative cost (as from a severe injury) rather than an outright termination of the decision process (as from extermination). If the cost of injury is sufficient, then the difference becomes rather moot; however, a more realistic model involving procreation and death from natural and unnatural causes would be most interesting. Second, we made the assumption that when a predator is <italic>present</italic>, the animal has a constant probability of being detected and harmed—indeed, we made no distinction between detection and being caught, and have not otherwise separated out the ‘subcomponents’ of predation risk [<xref ref-type="bibr" rid="pcbi.1005916.ref027">27</xref>]. Third, we assumed that the rate at which a predator enters and leaves the environment is constant, whereas one might expect that the predator would be more likely to remain in the environment if it has detected prey. Finally, since the model is non-spatial, it cannot address important factors such as differences in time to reach safety from different locations, and associated variation in the distance an animal will tolerate from a simulated predator before initiating flight (‘flight-initiation distance’ in the light of predatory imminence [<xref ref-type="bibr" rid="pcbi.1005916.ref051">51</xref>–<xref ref-type="bibr" rid="pcbi.1005916.ref053">53</xref>]).</p>
<p>Further unmodelled complexity arises through the behavioural sophistication that animals display both in assessing predation risk and in responding to the presence of a predator. These behaviours have been extensively studied in wild and laboratory rats [<xref ref-type="bibr" rid="pcbi.1005916.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref051">51</xref>], including investigations of approach-avoidance conflict [<xref ref-type="bibr" rid="pcbi.1005916.ref054">54</xref>]. Predatory risk assessment alternates between cautious forays into a potentially dangerous area and rapid retreat to safety, if available. If escape or concealment is not possible, the animal instead alternates between freezing and scanning with the head and vibrissae. When actually confronted with a predator, a rat will variously respond by fleeing, freezing, or attacking, depending on the nature of the current environment—particularly whether a place of relative safety, or refuge, is available—and the intensity of the perceived threat, or ‘defensive distance’ [<xref ref-type="bibr" rid="pcbi.1005916.ref055">55</xref>]. Capturing the latter concept would require a richer spatial and perhaps temporal model.</p>
<p>There were also marked simplifications concerning the benefits of foraging, both in terms of the agent and the environment. In terms of the former, we did not capture the possibility of running out of resources. Thus, for instance, it would have been possible for the agent to stay in <italic>rest</italic> in perpetuity (as indeed would seem optimal for expensive decision-making and no interruption; <xref ref-type="fig" rid="pcbi.1005916.g004">Fig 4B</xref>). In reality, as threats to homeostatic integrity loom, we can expect animals to exhibit more risk-seeking behaviour [<xref ref-type="bibr" rid="pcbi.1005916.ref056">56</xref>]. This would emerge in the current formulation given a more realistic characterization of the utilities [<xref ref-type="bibr" rid="pcbi.1005916.ref057">57</xref>]. In terms of the environment, a key simplification is to ignore resource depletion by the agent, and the existence of multiple patches. Then, critical concerns in foraging theory such as the marginal value theorem [<xref ref-type="bibr" rid="pcbi.1005916.ref058">58</xref>] would be important, and the rate of prey encounter or capture might also contribute to interruption.</p>
<p>While we primarily focused on the computational and algorithmic aspects of interruption, it is of clear interest to relate the current work to neural substrates. The present theory of interruption can be seen as a mesoscopic bridge between the macroscopic view of the neuromodulator norepinephrine (NE) suggested by the reversal experiments of Devauges and Sara [<xref ref-type="bibr" rid="pcbi.1005916.ref020">20</xref>], in which it reports changes to the whole rules of the environment [<xref ref-type="bibr" rid="pcbi.1005916.ref025">25</xref>], and the microscopic view of Bouret and Sara [<xref ref-type="bibr" rid="pcbi.1005916.ref021">21</xref>], and Dayan and Yu’s [<xref ref-type="bibr" rid="pcbi.1005916.ref026">26</xref>] interpretation of [<xref ref-type="bibr" rid="pcbi.1005916.ref022">22</xref>], in which it reports the current level of uncertainty about the ongoing belief state in a single perceptual inference problem, triggering interruption on reaching a pre-defined threshold, allowing switching to a better hypothesis [<xref ref-type="bibr" rid="pcbi.1005916.ref059">59</xref>]. This was proposed as part of the approximate strategy of provisionally committing to a single hypothesis, but keeping track of how this might be erroneous. At all levels, the common theme is the question of whether to interrupt a default state, whether that be a default belief about the current state of the world, as in [<xref ref-type="bibr" rid="pcbi.1005916.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref026">26</xref>], or a default program of activity, as in the current case. Closer examination of recordings from noradrenergic neurons and associated circuitry during naturalistic behaviour (including foraging tasks) for evidence of the sort of multilevel dynamics predicted by these three accounts would therefore be merited. NE activity has also be associated with arousal [<xref ref-type="bibr" rid="pcbi.1005916.ref060">60</xref>]; the relationship between this concept and that of interrupts is the subject of on-going theoretical work. Its association with other functions such as learning [<xref ref-type="bibr" rid="pcbi.1005916.ref061">61</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref062">62</xref>] and exploration [<xref ref-type="bibr" rid="pcbi.1005916.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref064">64</xref>] are arguably further removed. Possible divisions of labour and interactions between cortical and subcortical systems in this context are also of interest [<xref ref-type="bibr" rid="pcbi.1005916.ref065">65</xref>].</p>
<p>One can speculate about the relationship between the putative function of NE as an interrupt and its association with stress-induced anxiety [<xref ref-type="bibr" rid="pcbi.1005916.ref066">66</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref067">67</xref>]. In environments with a high proportion of unpredictable events, or indeed an environment that is either frankly aversive or believed to contain possible sources of threat, the interrupt mechanism is likely to be frequently engaged, whether received stimuli reflect real threats or not. This state of high interruptibility, or distractibility—reminiscent in some respects of ‘hypervigilance’—is plausibly associated with higher costs, both in terms of time and energy, and would be manifest in our own model in a greater frequency of costly deliberations. In the limit of an extremely inconstant environment, interruptibility loses any net benefit; however, whether this happens before the costs are such that the animal will refuse to engage with the environment at all depends on the details of the cost structure.</p>
<p>All these forms of interrupt are likely to be distinct from the motor interrupt that plays a critical role in tasks such as the stop signal reaction time task [<xref ref-type="bibr" rid="pcbi.1005916.ref068">68</xref>], or the ‘hold your horses’ interrupt [<xref ref-type="bibr" rid="pcbi.1005916.ref069">69</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref070">70</xref>] that has been suggested to suppress a prepotent action temporarily to allow time for a correct choice to be made. The former may also be associated with the form of cognitive state change associated with the phasic NE signal [<xref ref-type="bibr" rid="pcbi.1005916.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref026">26</xref>], but this would be a distinct consequence of the same underlying detection. Indeed, the neural substrates for these others forms of inhibition are notably different, implicating regions of the superior colliculus and basal ganglia, respectively.</p>
<p>Although we focused on the benefits of interruption and its possible mechanisms in the context of foraging, similar considerations are expected to be more generally applicable. One area of particular interest is decisions about ‘internal’ rather than external behaviour (i.e., meta-cognition). Indeed, the interpretation of NE we mentioned above as a signal for interrupting a likely incorrect ongoing belief is an example of this [<xref ref-type="bibr" rid="pcbi.1005916.ref026">26</xref>]. The strategy of provisional commitment could be particularly beneficial when there are such large numbers of potential hypotheses that they cannot simultaneously be entertained.</p>
<p>As another example, consider the problem of trying to decide whether to perform a particular action by considering its possible future consequences (i.e., by model-based planning; [<xref ref-type="bibr" rid="pcbi.1005916.ref040">40</xref>]). Ultimately, this will be intractable due to the myriad possibilities, and the challenge of determining the uncertainties and utilities of each. However, some degree of planning should be useful, until the fog of uncertainties about the future and the complexity of calculating it overwhelm the utility of attempting to do so. This question has also been of great interest in artificial intelligence [<xref ref-type="bibr" rid="pcbi.1005916.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref071">71</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref072">72</xref>].</p>
<p>One could try to determine how deep to plan before planning—planning to plan—but doing so optimally presents an even more formidable computational challenge. A more realistic option would be to commit to the planning process provisionally, while monitoring its progress (e.g., the extent to which one’s uncertainty about the value of the action decreases with planning depth), and to interrupt this process when further planning appears unjustifiable (see, e.g., [<xref ref-type="bibr" rid="pcbi.1005916.ref073">73</xref>]). In such cases of diminishing marginal returns, interruption according to a relatively simple threshold rule may apply, similar to the logic of the marginal value theorem in foraging theory [<xref ref-type="bibr" rid="pcbi.1005916.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref058">58</xref>]. Consideration of how long to run an algorithm is a central concern of work on anytime algorithms (or ‘interruptible’ algorithms), i.e., algorithms which are always guaranteed to return a valid solution but where the solution quality typically improves with time [<xref ref-type="bibr" rid="pcbi.1005916.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref074">74</xref>, <xref ref-type="bibr" rid="pcbi.1005916.ref075">75</xref>]. It is pressing to consider these insights in the light of what we know about the neural substrates of interruption.</p>
</sec>
<sec id="sec019">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005916.s001" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005916.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Optimal policies in the absence of a decision cost.</title>
<p>When there is no decision cost, it is always optimal to choose <italic>τ</italic> to be as short as possible.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We are extremely grateful to Tiago Branco, Dominic Evans, Kyo Iigaya, James Marshall, John McNamara, and Pete Trimmer for their comments on an earlier version of the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005916.ref001">
<label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Russell</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Norvig</surname> <given-names>P</given-names></name>. <source>Artificial intelligence: A modern approach</source>, <edition>3rd edition</edition>. <publisher-name>Pearson</publisher-name>; <year>2009</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref002">
<label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Broadbent</surname> <given-names>DE</given-names></name>. <source>Perception and communication</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Pergamon Press</publisher-name>; <year>1958</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref003">
<label>3</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>. <source>Attention and effort</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Prentice Hall</publisher-name>; <year>1973</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref004">
<label>4</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Pashler</surname> <given-names>H</given-names></name>. <source>The psychology of attention</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>1996</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref005">
<label>5</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Simon</surname> <given-names>HA</given-names></name>. <source>Models of bounded rationality, volume 1</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>1982</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref006">
<label>6</label>
<mixed-citation publication-type="other" xlink:type="simple">Horvitz EJ. Reasoning about beliefs and actions under computational resource constraints. In: Proceedings of the Third Workshop on Uncertainty in Artificial Intelligence. Mountain View, CA: AAAI Press; 1987. p. 429–444.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Houston</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sumida</surname> <given-names>B</given-names></name>. <article-title>A positive feedback model for switching between two activities</article-title>. <source>Animal Behaviour</source>. <year>1985</year>;<volume>33</volume>(<issue>1</issue>):<fpage>315</fpage>–<lpage>325</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0003-3472(85)80145-7" xlink:type="simple">10.1016/S0003-3472(85)80145-7</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Marshall</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Favreau-Peigne</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Fromhage</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Mcnamara</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Meah</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>Houston</surname> <given-names>AI</given-names></name>. <article-title>Cross inhibition improves activity selection when switching incurs time costs</article-title>. <source>Current Zoology</source>. <year>2015</year>;<volume>61</volume>(<issue>2</issue>):<fpage>242</fpage>–<lpage>250</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/czoolo/61.2.242" xlink:type="simple">10.1093/czoolo/61.2.242</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Monsell</surname> <given-names>S</given-names></name>. <article-title>Task switching</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2003</year>;<volume>7</volume>(<issue>3</issue>):<fpage>134</fpage>–<lpage>140</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1364-6613(03)00028-7" xlink:type="simple">10.1016/S1364-6613(03)00028-7</ext-link></comment> <object-id pub-id-type="pmid">12639695</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brooks</surname> <given-names>R</given-names></name>. <article-title>A robust layered control system for a mobile robot</article-title>. <source>IEEE Journal of Robotics and Automation</source>. <year>1986</year>;<volume>2</volume>(<issue>1</issue>):<fpage>14</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/JRA.1986.1087032" xlink:type="simple">10.1109/JRA.1986.1087032</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref011">
<label>11</label>
<mixed-citation publication-type="other" xlink:type="simple">Agre PE, Chapman D. Pengi: An implementation of a theory of activity. In: Proceedings of the Sixth National Conference on Artificial Intelligence. Menlo Park, California: AAAI Press; 1987. p. 268–272.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref012">
<label>12</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Maes</surname> <given-names>P</given-names></name>. <source>Designing autonomous agents: Theory and practice from biology to engineering and back</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT press</publisher-name>; <year>1990</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref013">
<label>13</label>
<mixed-citation publication-type="other" xlink:type="simple">Wilson SW. The animat path to AI. In: Meyer JA, Wilson SW, editors. From Animals to Animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior. Cambridge, MA: MIT Press; 1991. p. 15–22.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sacerdoti</surname> <given-names>ED</given-names></name>. <article-title>Planning in a hierarchy of abstraction spaces</article-title>. <source>Artificial Intelligence</source>. <year>1974</year>;<volume>5</volume>(<issue>2</issue>):<fpage>115</fpage>–<lpage>135</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0004-3702(74)90026-5" xlink:type="simple">10.1016/0004-3702(74)90026-5</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Precup</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Singh</surname> <given-names>S</given-names></name>. <article-title>Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning</article-title>. <source>Artificial Intelligence</source>. <year>1999</year>;<volume>112</volume>(<issue>1-2</issue>):<fpage>181</fpage>–<lpage>211</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0004-3702(99)00052-1" xlink:type="simple">10.1016/S0004-3702(99)00052-1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilkins</surname> <given-names>DE</given-names></name>. <article-title>Recovering from execution errors in SIPE</article-title>. <source>Computational Intelligence</source>. <year>1985</year>;<volume>1</volume>(<issue>1</issue>):<fpage>33</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-8640.1985.tb00057.x" xlink:type="simple">10.1111/j.1467-8640.1985.tb00057.x</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McDermott</surname> <given-names>D</given-names></name>. <article-title>Planning and acting</article-title>. <source>Cognitive Science</source>. <year>1978</year>;<volume>2</volume>(<issue>2</issue>):<fpage>71</fpage>–<lpage>100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1207/s15516709cog0202_1" xlink:type="simple">10.1207/s15516709cog0202_1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref018">
<label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Hoffmann J, Brafman R. Contingent planning via heuristic forward search with implicit belief states. In: Biundo S, Myers K, Rajan K, editors. Proceedings of the Fifteenth International Conference on Automated Planning and Scheduling. vol. 2005. AAAI Press; 2005. p. 71–80.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref019">
<label>19</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Silberschatz</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Galvin</surname> <given-names>PB</given-names></name>, <name name-style="western"><surname>Gagne</surname> <given-names>G</given-names></name>. <source>Operating systems concepts</source>. <publisher-name>John Wiley &amp; Sons</publisher-name>; <year>2013</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Devauges</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Sara</surname> <given-names>SJ</given-names></name>. <article-title>Activation of the noradrenergic system facilitates an attentional shift in the rat</article-title>. <source>Behavioural Brain Research</source>. <year>1990</year>;<volume>39</volume>(<issue>1</issue>):<fpage>19</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0166-4328(90)90118-X" xlink:type="simple">10.1016/0166-4328(90)90118-X</ext-link></comment> <object-id pub-id-type="pmid">2167690</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bouret</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sara</surname> <given-names>SJ</given-names></name>. <article-title>Network reset: A simplified overarching theory of locus coeruleus noradrenaline function</article-title>. <source>Trends in Neurosciences</source>. <year>2005</year>;<volume>28</volume>(<issue>11</issue>):<fpage>574</fpage>–<lpage>582</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tins.2005.09.002" xlink:type="simple">10.1016/j.tins.2005.09.002</ext-link></comment> <object-id pub-id-type="pmid">16165227</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clayton</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Rajkowski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>. <article-title>Phasic activation of monkey locus ceruleus neurons by simple decisions in a forced-choice task</article-title>. <source>The Journal of Neuroscience</source>. <year>2004</year>;<volume>24</volume>:<fpage>9914</fpage>–<lpage>9920</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2446-04.2004" xlink:type="simple">10.1523/JNEUROSCI.2446-04.2004</ext-link></comment> <object-id pub-id-type="pmid">15525776</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>An integrative theory of locus coeruleus-norepinephrine function: Adaptive gain and optimal performance</article-title>. <source>Annual Reviews Neuroscience</source>. <year>2005</year>;<volume>28</volume>:<fpage>403</fpage>–<lpage>450</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.neuro.28.061604.135709" xlink:type="simple">10.1146/annurev.neuro.28.061604.135709</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sara</surname> <given-names>SJ</given-names></name>. <article-title>The locus coeruleus and noradrenergic modulation of cognition</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2009</year>;<volume>10</volume>(<issue>3</issue>):<fpage>211</fpage>–<lpage>223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nrn2573" xlink:type="simple">10.1038/nrn2573</ext-link></comment> <object-id pub-id-type="pmid">19190638</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yu</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty, neuromodulation, and attention</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>46</volume>:<fpage>681</fpage>–<lpage>692</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2005.04.026" xlink:type="simple">10.1016/j.neuron.2005.04.026</ext-link></comment> <object-id pub-id-type="pmid">15944135</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>AJ</given-names></name>. <article-title>Phasic norepinephrine: A neural interrupt signal for unexpected events</article-title>. <source>Network: Computation in Neural Systems</source>. <year>2006</year>;<volume>17</volume>(<issue>4</issue>):<fpage>335</fpage>–<lpage>350</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/09548980601004024" xlink:type="simple">10.1080/09548980601004024</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lima</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Dill</surname> <given-names>LM</given-names></name>. <article-title>Behavioral decsions made under the risk of predation: A review and prospectus</article-title>. <source>Canadian Journal of Zoology</source>. <year>1990</year>;<volume>68</volume>:<fpage>619</fpage>–<lpage>640</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1139/z90-092" xlink:type="simple">10.1139/z90-092</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref028">
<label>28</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Houston</surname> <given-names>AI</given-names></name>, <name name-style="western"><surname>McNamara</surname> <given-names>JM</given-names></name>. <source>Models of adaptive behaviour</source>. <publisher-loc>Cambridge</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>1999</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Houston</surname> <given-names>AI</given-names></name>, <name name-style="western"><surname>McNamara</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Hutchinson</surname> <given-names>JMC</given-names></name>. <article-title>General results concerning the trade-off between gaining energy and avoiding predation</article-title>. <source>Philosophical Transactions: Biological Sciences</source>. <year>1993</year>;<volume>341</volume>(<issue>1298</issue>):<fpage>375</fpage>–<lpage>397</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rstb.1993.0123" xlink:type="simple">10.1098/rstb.1993.0123</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Blanchard</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Blanchard</surname> <given-names>RJ</given-names></name>. <article-title>Ethoexperimental approaches to the biology of emotion</article-title>. <source>Annual Review of Psychology</source>. <year>1988</year>;<volume>39</volume>:<fpage>43</fpage>–<lpage>68</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.ps.39.020188.000355" xlink:type="simple">10.1146/annurev.ps.39.020188.000355</ext-link></comment> <object-id pub-id-type="pmid">2894198</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vale</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Evans</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Branco</surname> <given-names>T</given-names></name>. <article-title>Rapid spatial learning controls instinctive defensive behavior in mice</article-title>. <source>Current Biology</source>. <year>2017</year>;<volume>27</volume>:<fpage>1</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2017.03.031" xlink:type="simple">10.1016/j.cub.2017.03.031</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Boureau</surname> <given-names>YL</given-names></name>, <name name-style="western"><surname>Sokol-Hessner</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Deciding how to decide: Self-control and meta-decision making</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2015</year>;<volume>19</volume>(<issue>11</issue>):<fpage>700</fpage>–<lpage>710</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2015.08.013" xlink:type="simple">10.1016/j.tics.2015.08.013</ext-link></comment> <object-id pub-id-type="pmid">26483151</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kurzban</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Duckworth</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kable</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Myers</surname> <given-names>J</given-names></name>. <article-title>An opportunity cost model of subjective effort and task performance</article-title>. <source>Behavioral and Brain Sciences</source>. <year>2013</year>;<volume>36</volume>(<issue>6</issue>):<fpage>661</fpage>–<lpage>679</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0140525X12003196" xlink:type="simple">10.1017/S0140525X12003196</ext-link></comment> <object-id pub-id-type="pmid">24304775</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shenhav</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Musslick</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lieder</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Kool</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <etal>et al</etal>. <article-title>Toward a rational and mechanistic account of mental effort</article-title>. <source>Annual Review of Neuroscience</source>. <year>2017</year>;<volume>40</volume>:<fpage>99</fpage>–<lpage>124</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-neuro-072116-031526" xlink:type="simple">10.1146/annurev-neuro-072116-031526</ext-link></comment> <object-id pub-id-type="pmid">28375769</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Joel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Tonic dopamine: Opportunity costs and the control of response vigor</article-title>. <source>Psychopharmacology</source>. <year>2007</year>;<volume>191</volume>(<issue>3</issue>):<fpage>507</fpage>–<lpage>520</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00213-006-0502-4" xlink:type="simple">10.1007/s00213-006-0502-4</ext-link></comment> <object-id pub-id-type="pmid">17031711</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kool</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>McGuire</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Rosen</surname> <given-names>ZB</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>MM</given-names></name>. <article-title>Decision making and the avoidance of cognitive demand</article-title>. <source>Journal of Experimental Psychology: General</source>. <year>2010</year>;<volume>139</volume>:<fpage>665</fpage>–<lpage>682</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Keramati</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dezfouli</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Piray</surname> <given-names>P</given-names></name>. <article-title>Speed/accuracy trade-off between the habitual and the goal-directed processes</article-title>. <source>PLoS Computational Biology</source>. <year>2011</year>;<volume>7</volume>:<fpage>e1002055</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002055" xlink:type="simple">10.1371/journal.pcbi.1002055</ext-link></comment> <object-id pub-id-type="pmid">21637741</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pezzulo</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rigoli</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Chersi</surname> <given-names>F</given-names></name>. <article-title>The mixed instrumental controller: Using value of information to combine habitual choice and mental simulation</article-title>. <source>Frontiers in Psychology</source>. <year>2013</year>;<volume>4</volume>:<fpage>92</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2013.00092" xlink:type="simple">10.3389/fpsyg.2013.00092</ext-link></comment> <object-id pub-id-type="pmid">23459512</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Keramati</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Smittenaar</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Adaptive integration of habits into depth-limited planning defines a habitual-goal-directed spectrum</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2016</year>;<volume>113</volume>(<issue>45</issue>):<fpage>12868</fpage>–<lpage>12873</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1609094113" xlink:type="simple">10.1073/pnas.1609094113</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref040">
<label>40</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <source>Reinforcement learning: An introduction</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>1998</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nature Neuroscience</source>. <year>2005</year>;<volume>8</volume>(<issue>12</issue>):<fpage>1704</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1560" xlink:type="simple">10.1038/nn1560</ext-link></comment> <object-id pub-id-type="pmid">16286932</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rogers</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Monsell</surname> <given-names>S</given-names></name>. <article-title>Costs of a predictible switch between simple cognitive tasks</article-title>. <source>Journal of Experimental Psychology: General</source>. <year>1995</year>;<volume>124</volume>(<issue>2</issue>):<fpage>207</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-3445.124.2.207" xlink:type="simple">10.1037/0096-3445.124.2.207</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Mahadevan</surname> <given-names>S</given-names></name>. <article-title>Recent advances in hierarchical reinforcement learning</article-title>. <source>Discrete Event Dynamic Systems: Theory and Applications</source>. <year>2003</year>;<volume>13</volume>:<fpage>343</fpage>–<lpage>379</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1023/A:1022140919877" xlink:type="simple">10.1023/A:1022140919877</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref044">
<label>44</label>
<mixed-citation publication-type="other" xlink:type="simple">Kaelbling LP. Hierarchical learning in stochastic domains: Preliminary results. In: Proceedings of the 10th International Conference on Machine Learning. San Mateo, CA: Morgan Kaufmann; 1993. p. 167–173.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref045">
<label>45</label>
<mixed-citation publication-type="other" xlink:type="simple">Bacon PL, Harb J, Precup D. The option-critic architecture. arXiv preprint arXiv:160905140. 2016;.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lima</surname> <given-names>SL</given-names></name>. <article-title>Stress and decision making under the risk of predation: Recent developments from behavioral, reproductive, and ecological perspectives</article-title>. <source>Advances in the Study of Behavior</source>. <year>1998</year>;<volume>27</volume>:<fpage>215</fpage>–<lpage>290</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0065-3454(08)60366-6" xlink:type="simple">10.1016/S0065-3454(08)60366-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brown</surname> <given-names>JS</given-names></name>. <article-title>Vigilance, patch use and hahabit selection: Foraging under predation risk</article-title>. <source>Evolutionary Ecology Research</source>. <year>1999</year>;<volume>1</volume>:<fpage>49</fpage>–<lpage>71</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brown</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Kotler</surname> <given-names>BP</given-names></name>. <article-title>Hazardous duty pay and the foraging cost of predation</article-title>. <source>Ecology Letters</source>. <year>2004</year>;<volume>7</volume>:<fpage>999</fpage>–<lpage>1014</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1461-0248.2004.00661.x" xlink:type="simple">10.1111/j.1461-0248.2004.00661.x</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Blanchard</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Flannelly</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Blanchard</surname> <given-names>DC</given-names></name>. <article-title>Defensive behaviors of laboratory and wild Rattus norvegicus</article-title>. <source>Journal of Comparative Psychology</source>. <year>1986</year>;<volume>100</volume>(<issue>2</issue>):<fpage>101</fpage>–<lpage>107</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0735-7036.100.2.101" xlink:type="simple">10.1037/0735-7036.100.2.101</ext-link></comment> <object-id pub-id-type="pmid">3720282</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Blanchard</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Blanchard</surname> <given-names>DC</given-names></name>. <article-title>Antipredator defensive behaviors in a visible burrow system</article-title>. <source>Journal of Comparative Psychology</source>. <year>1989</year>;<volume>103</volume>(<issue>1</issue>):<fpage>70</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0735-7036.103.1.70" xlink:type="simple">10.1037/0735-7036.103.1.70</ext-link></comment> <object-id pub-id-type="pmid">2924531</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Blanchard</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Blanchard</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Rodgers</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Weiss</surname> <given-names>SM</given-names></name>. <article-title>The characterization and modelling of antipredator defensive behavior</article-title>. <source>Neuroscience and Biobehavioral Reviews</source>. <year>1990</year>;<volume>14</volume>(<issue>4</issue>):<fpage>463</fpage>–<lpage>472</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0149-7634(05)80069-7" xlink:type="simple">10.1016/S0149-7634(05)80069-7</ext-link></comment> <object-id pub-id-type="pmid">2287483</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bolles</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Fanselow</surname> <given-names>MS</given-names></name>. <article-title>A perceptual-defensive-recuperative model of fear and pain</article-title>. <source>Behavioral and Brain Sciences</source>. <year>1980</year>;<volume>3</volume>:<fpage>291</fpage>–<lpage>323</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0140525X0000491X" xlink:type="simple">10.1017/S0140525X0000491X</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ydenberg</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Dill</surname> <given-names>LM</given-names></name>. <article-title>The economics of fleeing from predators</article-title>. <source>Advances in the Study of Behavior</source>. <year>1986</year>;<volume>16</volume>:<fpage>229</fpage>–<lpage>249</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0065-3454(08)60192-8" xlink:type="simple">10.1016/S0065-3454(08)60192-8</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Aupperle</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Paulus</surname> <given-names>MP</given-names></name>. <article-title>Neural systems underlying approach and avoidance in anxiety disorders</article-title>. <source>Dialogues in Clinical Neuroscience</source>. <year>2010</year>;<volume>12</volume>:<fpage>517</fpage>–<lpage>531</lpage>. <object-id pub-id-type="pmid">21319496</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McNaughton</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Corr</surname> <given-names>PJ</given-names></name>. <article-title>A two-dimensional neuropsychology of defense: Fear/anxiety and defensive distance</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>. <year>2004</year>;<volume>28</volume>:<fpage>285</fpage>–<lpage>305</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neubiorev.2004.03.005" xlink:type="simple">10.1016/j.neubiorev.2004.03.005</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stephens</surname> <given-names>DW</given-names></name>. <article-title>The logic of risk-sensitive foraging preferences</article-title>. <source>Animal Behaviour</source>. <year>1981</year>;<volume>29</volume>(<issue>2</issue>):<fpage>628</fpage>–<lpage>629</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0003-3472(81)80128-5" xlink:type="simple">10.1016/S0003-3472(81)80128-5</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Keramati</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gutkin</surname> <given-names>B</given-names></name>. <article-title>Homeostatic reinforcement learning for integrating reward collection and physiological stability</article-title>. <source>Elife</source>. <year>2014</year>;<volume>3</volume>:<fpage>e04811</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.04811" xlink:type="simple">10.7554/eLife.04811</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Charnov</surname> <given-names>EL</given-names></name>. <article-title>Optimal foraging: The marginal value theorem</article-title>. <source>Theoretical Population Biology</source>. <year>1976</year>;<volume>9</volume>(<issue>2</issue>):<fpage>129</fpage>–<lpage>136</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0040-5809(76)90040-X" xlink:type="simple">10.1016/0040-5809(76)90040-X</ext-link></comment> <object-id pub-id-type="pmid">1273796</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>West</surname> <given-names>M</given-names></name>. <article-title>Bayesian model monitoring</article-title>. <source>Journal of the Royal Statistical Society Series B (Methodological)</source>. <year>1986</year>;<volume>48</volume>(<issue>1</issue>):<fpage>70</fpage>–<lpage>78</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Robbins</surname> <given-names>TW</given-names></name>. <article-title>Cortical noradrenaline, attention and arousal</article-title>. <source>Psychological Medicine</source>. <year>1984</year>;<volume>14</volume>:<fpage>13</fpage>–<lpage>21</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1017/S0033291700003032" xlink:type="simple">10.1017/S0033291700003032</ext-link></comment> <object-id pub-id-type="pmid">6709778</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Rumsey</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Parikh</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Heasly</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>Rational regulation of learning dynamics by pupil-linked arousal systems</article-title>. <source>Nature Neuroscience</source>. <year>2012</year>;<volume>15</volume>(<issue>7</issue>):<fpage>1040</fpage>–<lpage>1046</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3130" xlink:type="simple">10.1038/nn.3130</ext-link></comment> <object-id pub-id-type="pmid">22660479</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Preuschoff</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Marius’t Hart</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Einhäuser</surname> <given-names>W</given-names></name>. <article-title>Pupil dilation signals surprise: Evidence for noradrenaline’s role in decision making</article-title>. <source>Frontiers in Neuroscience</source>. <year>2011</year>;<volume>5</volume>:<fpage>115</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnins.2011.00115" xlink:type="simple">10.3389/fnins.2011.00115</ext-link></comment> <object-id pub-id-type="pmid">21994487</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Warren</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>van der Wee</surname> <given-names>NJ</given-names></name>, <name name-style="western"><surname>Giltay</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>van Noorden</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <etal>et al</etal>. <article-title>The effect of atomoxetine on random and directed exploration in humans</article-title>. <source>PLoS ONE</source>. <year>2017</year>;<volume>12</volume>(<issue>4</issue>):<fpage>e0176034</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0176034" xlink:type="simple">10.1371/journal.pone.0176034</ext-link></comment> <object-id pub-id-type="pmid">28445519</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gilzenrat</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Nieuwenhuis</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Jepma</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>Pupil diameter tracks changes in control state predicted by the adaptive gain theory of locus coeruleus function</article-title>. <source>Cognitive, Affective, &amp; Behavioral Neuroscience</source>. <year>2010</year>;<volume>10</volume>(<issue>2</issue>):<fpage>252</fpage>–<lpage>269</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/CABN.10.2.252" xlink:type="simple">10.3758/CABN.10.2.252</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Trimmer</surname> <given-names>PC</given-names></name>, <name name-style="western"><surname>Houston</surname> <given-names>AI</given-names></name>, <name name-style="western"><surname>Marshall</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Bogacz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Paul</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Mendl</surname> <given-names>MT</given-names></name>, <etal>et al</etal>. <article-title>Mammalian choices: Combining fast-but-inaccurate and slow-but-accurate decision-making systems</article-title>. <source>Proceedings of the Royal Society of London B: Biological Sciences</source>. <year>2008</year>;<volume>275</volume>:<fpage>2353</fpage>–<lpage>2361</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1098/rspb.2008.0417" xlink:type="simple">10.1098/rspb.2008.0417</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Koob</surname> <given-names>GF</given-names></name>. <article-title>Corticotropin-releasing factor, norepinephrine, and stress</article-title>. <source>Biological Psychiatry</source>. <year>1999</year>;<volume>46</volume>(<issue>9</issue>):<fpage>1167</fpage>–<lpage>1180</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0006-3223(99)00164-X" xlink:type="simple">10.1016/S0006-3223(99)00164-X</ext-link></comment> <object-id pub-id-type="pmid">10560023</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McCall</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Al-Hasani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Siuda</surname> <given-names>ER</given-names></name>, <name name-style="western"><surname>Hong</surname> <given-names>DY</given-names></name>, <name name-style="western"><surname>Norris</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Ford</surname> <given-names>CP</given-names></name>, <etal>et al</etal>. <article-title>CRH engagement of the locus coeruleus noradrenergic system mediates stress-induced anxiety</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>87</volume>(<issue>3</issue>):<fpage>605</fpage>–<lpage>620</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.07.002" xlink:type="simple">10.1016/j.neuron.2015.07.002</ext-link></comment> <object-id pub-id-type="pmid">26212712</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hanes</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Schall</surname> <given-names>JD</given-names></name>. <article-title>Neural control of voluntary movement initiation</article-title>. <source>Science</source>. <year>1996</year>;<volume>274</volume>:<fpage>427</fpage>–<lpage>430</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.274.5286.427" xlink:type="simple">10.1126/science.274.5286.427</ext-link></comment> <object-id pub-id-type="pmid">8832893</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>Hold your horses: a dynamic computational role for the subthalamic nucleus in decision making</article-title>. <source>Neural Networks</source>. <year>2006</year>;<volume>19</volume>(<issue>8</issue>):<fpage>1120</fpage>–<lpage>1136</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neunet.2006.03.006" xlink:type="simple">10.1016/j.neunet.2006.03.006</ext-link></comment> <object-id pub-id-type="pmid">16945502</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Samanta</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Moustafa</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Sherman</surname> <given-names>SJ</given-names></name>. <article-title>Hold your horses: Impulsitivity, deep brain stimulation, and medication in Parkinsonism</article-title>. <source>Science</source>. <year>2007</year>;<volume>318</volume>:<fpage>1309</fpage>–<lpage>1312</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1146157" xlink:type="simple">10.1126/science.1146157</ext-link></comment> <object-id pub-id-type="pmid">17962524</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref071">
<label>71</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Newell</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Simon</surname> <given-names>HA</given-names></name>. <source>Human problem solving</source>. <publisher-loc>Englewood Cliffs, NJ</publisher-loc>: <publisher-name>Prentice-Hall</publisher-name>; <year>1972</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref072">
<label>72</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Russell</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Wefald</surname> <given-names>EH</given-names></name>. <source>Do the right thing: Studies in limited rationality</source>. <publisher-name>MIT Press</publisher-name>; <year>1991</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hansen</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Zilberstein</surname> <given-names>S</given-names></name>. <article-title>Monitoring and control of anytime algorithms: A dynamic programming approach</article-title>. <source>Artificial Intelligence</source>. <year>2001</year>;<volume>126</volume>(<issue>1-2</issue>):<fpage>139</fpage>–<lpage>157</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0004-3702(00)00068-0" xlink:type="simple">10.1016/S0004-3702(00)00068-0</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005916.ref074">
<label>74</label>
<mixed-citation publication-type="other" xlink:type="simple">Dean T, Boddy M. An analysis of time-dependent planning. In: Proceedings of the Seventh National Conference on Artificial Intelligence. Morgan Kaufmann; 1988. p. 49–54.</mixed-citation>
</ref>
<ref id="pcbi.1005916.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zilberstein</surname> <given-names>S</given-names></name>. <article-title>Operational rationality through compilation of anytime algorithms</article-title>. <source>AI Magazine</source>. <year>1995</year>;<volume>16</volume>(<issue>2</issue>):<fpage>79</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
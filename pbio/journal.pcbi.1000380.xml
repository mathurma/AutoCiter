<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
    <front>
        <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
                <publisher-name>Public Library of Science</publisher-name>
                <publisher-loc>San Francisco, USA</publisher-loc>
            </publisher></journal-meta>
        <article-meta><article-id pub-id-type="publisher-id">08-PLCB-RA-1007R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000380</article-id><article-categories>
                <subj-group subj-group-type="heading">
                    <subject>Research Article</subject>
                </subj-group>
                <subj-group subj-group-type="Discipline">
                    <subject>Neuroscience/Sensory Systems</subject>
                    <subject>Neuroscience/Theoretical Neuroscience</subject>
                </subj-group>
            </article-categories><title-group><article-title>Pairwise Maximum Entropy Models for Studying Large Biological
                    Systems: When They Can Work and When They Can't</article-title><alt-title alt-title-type="running-head">Maximum Entropy Models for Biological
                    Systems</alt-title></title-group><contrib-group>
                <contrib contrib-type="author" xlink:type="simple">
                    <name name-style="western">
                        <surname>Roudi</surname>
                        <given-names>Yasser</given-names>
                    </name>
                    <xref ref-type="aff" rid="aff1">
                        <sup>1</sup>
                    </xref>
                    <xref ref-type="aff" rid="aff2">
                        <sup>2</sup>
                    </xref>
                </contrib>
                <contrib contrib-type="author" xlink:type="simple">
                    <name name-style="western">
                        <surname>Nirenberg</surname>
                        <given-names>Sheila</given-names>
                    </name>
                    <xref ref-type="aff" rid="aff2">
                        <sup>2</sup>
                    </xref>
                </contrib>
                <contrib contrib-type="author" xlink:type="simple">
                    <name name-style="western">
                        <surname>Latham</surname>
                        <given-names>Peter E.</given-names>
                    </name>
                    <xref ref-type="aff" rid="aff1">
                        <sup>1</sup>
                    </xref>
                    <xref ref-type="corresp" rid="cor1">
                        <sup>*</sup>
                    </xref>
                </contrib>
            </contrib-group><aff id="aff1">
                <label>1</label>
                <addr-line>Gatsby Computational Neuroscience Unit, University College London,
                    London, United Kingdom</addr-line>
            </aff><aff id="aff2">
                <label>2</label>
                <addr-line>Department of Physiology and Biophysics, Weill Medical College of Cornell
                    University, New York, United States of America</addr-line>
            </aff><contrib-group>
                <contrib contrib-type="editor" xlink:type="simple">
                    <name name-style="western">
                        <surname>Sporns</surname>
                        <given-names>Olaf</given-names>
                    </name>
                    <role>Editor</role>
                    <xref ref-type="aff" rid="edit1"/>
                </contrib>
            </contrib-group><aff id="edit1">Indiana University, United States of America</aff><author-notes>
                <corresp id="cor1">* E-mail: <email xlink:type="simple">pel@gatsby.ucl.ac.uk</email></corresp>
                <fn fn-type="con">
                    <p>Analyzed the data: YR PEL. Wrote the paper: YR SN PEL. Conceived and designed
                        the study: YR SN PEL. Performed the experiments/simulations/mathematical
                        derivations: YR PEL.</p>
                </fn>
            <fn fn-type="conflict">
                <p>The authors have declared that no competing interests exist.</p>
            </fn></author-notes><pub-date pub-type="collection">
                <month>5</month>
                <year>2009</year>
            </pub-date><pub-date pub-type="epub">
                <day>8</day>
                <month>5</month>
                <year>2009</year>
            </pub-date><volume>5</volume><issue>5</issue><elocation-id>e1000380</elocation-id><history>
                <date date-type="received">
                    <day>10</day>
                    <month>11</month>
                    <year>2008</year>
                </date>
                <date date-type="accepted">
                    <day>1</day>
                    <month>4</month>
                    <year>2009</year>
                </date>
            </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Roudi et al</copyright-holder><license><license-p>This is an open-access article distributed under the
                terms of the Creative Commons Attribution License, which permits unrestricted use,
                distribution, and reproduction in any medium, provided the original author and
                source are credited.</license-p></license></permissions><abstract>
                <p>One of the most critical problems we face in the study of biological systems is
                    building accurate statistical descriptions of them. This problem has been
                    particularly challenging because biological systems typically contain large
                    numbers of interacting elements, which precludes the use of standard brute force
                    approaches. Recently, though, several groups have reported that there may be an
                    alternate strategy. The reports show that reliable statistical models can be
                    built without knowledge of all the interactions in a system; instead, pairwise
                    interactions can suffice. These findings, however, are based on the analysis of
                    small subsystems. Here, we ask whether the observations will generalize to
                    systems of realistic size, that is, whether pairwise models will provide
                    reliable descriptions of true biological systems. Our results show that, in most
                    cases, they will not. The reason is that there is a crossover in the predictive
                    power of pairwise models: If the size of the subsystem is below the crossover
                    point, then the results have no predictive power for large systems. If the size
                    is above the crossover point, then the results may have predictive power. This
                    work thus provides a general framework for determining the extent to which
                    pairwise models can be used to predict the behavior of large biological systems.
                    Applied to neural data, the size of most systems studied so far is below the
                    crossover point.</p>
            </abstract><abstract abstract-type="summary">
                <title>Author Summary</title>
                <p>Biological systems are exceedingly complicated: They consist of a large number of
                    elements, those elements interact in nonlinear and highly unpredictable ways,
                    and collective interactions typically play a critical role. It would seem
                    surprising, then, that one could build a quantitative description of biological
                    systems based only on knowledge of how pairs of elements interact. Yet, that is
                    what a number of studies have found. Those studies, however, focused on
                    relatively small systems. Here, we ask the question: Do their conclusions extend
                    to large systems? We show that the answer depends on the size of the system
                    relative to a crossover point: Below the crossover point the results on the
                    small system have no predictive power for large systems; above the crossover
                    point the results on the small system may have predictive power. Moreover, the
                    crossover point can be computed analytically. This work thus provides a general
                    framework for determining the extent to which pairwise models can be used to
                    predict the behavior of large biological systems. It also provides a useful
                    heuristic for designing experiments: If one is interested in understanding truly
                    large systems via pairwise interactions, then make sure that the system one
                    studies is above the crossover point.</p>
            </abstract><funding-group><funding-statement>YR and PEL were supported by the Gatsby Charitable Foundation (<ext-link ext-link-type="uri" xlink:href="http://www.gatsby.org.uk" xlink:type="simple">http://www.gatsby.org.uk</ext-link>) and by the US National Institute of
                    Mental Health grant R01 MH62447. SN was supported by the US National Eye
                    Institute grant R01 EY12978. The funders had no role in study design, data
                    collection and analysis, decision to publish, or preparation of the
                manuscript.</funding-statement></funding-group><counts>
                <page-count count="18"/>
            </counts></article-meta>
    </front>
    <body>
        <sec id="s1">
            <title>Introduction</title>
            <p>Many fundamental questions in biology are naturally treated in a probabilistic
                setting. For instance, deciphering the neural code requires knowledge of the
                probability of observing patterns of activity in response to stimuli <xref ref-type="bibr" rid="pcbi.1000380-Rieke1">[1]</xref>;
                determining which features of a protein are important for correct folding requires
                knowledge of the probability that a particular sequence of amino acids folds
                naturally <xref ref-type="bibr" rid="pcbi.1000380-Russ1">[2]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Socolich1">[3]</xref>; and determining the patterns of foraging of
                animals and their social and individual behavior requires knowledge of the
                distribution of food and species over both space and time <xref ref-type="bibr" rid="pcbi.1000380-Oates1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Eisenberg1">[6]</xref>.</p>
            <p>Constructing these probability distributions is, however, hard. There are several
                reasons for this: i) biological systems are composed of large numbers of elements,
                and so can exhibit a huge number of configurations—in fact, an
                exponentially large number, ii) the elements typically interact with each other,
                making it impossible to view the system as a collection of independent entities, and
                iii) because of technological considerations, the descriptions of biological systems
                have to be built from very little data. For example, with current technology in
                neuroscience, we can record simultaneously from only about 100 neurons out of
                approximately 100 billion in the human brain. So, not only are we faced with the
                problem of estimating probability distributions in high dimensional spaces, we must
                do this based on a small fraction of the neurons in the network.</p>
            <p>Despite these apparent difficulties, recent work has suggested that the situation may
                be less bleak than it seems, and that an accurate statistical description of systems
                can be achieved without having to examine all possible configurations <xref ref-type="bibr" rid="pcbi.1000380-Russ1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1000380-Socolich1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref>. One merely has to measure
                the probability distribution over pairs of elements and use those to build the full
                distribution. These “pairwise models” potentially offer a
                fundamental simplification, as the number of pairs is quadratic in the number of
                elements, not exponential. However, support for the efficacy of pairwise models has,
                necessarily, come from relatively small subsystems—small enough that the
                true probability distribution could be measured experimentally <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref>. While
                these studies have provided a key first step, a critical question remains: will the
                results from the analysis of these small subsystems extrapolate to large ones? That
                is, if a pairwise model predicts the probability distribution for a subset of the
                elements in a system, will it also predict the probability distribution for the
                whole system? Here we find that, for a biologically relevant class of systems, this
                question can be answered quantitatively and, importantly,
                generically—independent of many of the details of the biological system
                under consideration. And the answer is, generally, “no.” In this
                paper, we explain, both analytically and with simulations, why this is the case.</p>
        </sec>
        <sec id="s2">
            <title>Results</title>
            <sec id="s2a">
                <title>The extrapolation problem</title>
                <p>To gain intuition into the extrapolation problem, let us consider a specific
                    example: neuronal spike trains. <xref ref-type="fig" rid="pcbi-1000380-g001">Fig. 1A</xref> shows a typical spike train for a small population of
                    neurons. Although the raw spike times provide a complete description, they are
                    not a useful representation, as they are too high-dimensional. Therefore, we
                    divide time into bins and re-represent the spike train as 0 s and 1 s: 0 if
                    there is no spike in a bin; 1 otherwise (<xref ref-type="fig" rid="pcbi-1000380-g001">Fig. 1B</xref>) <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref>. For
                    now we assume that the bins are independent (an assumption whose validity we
                    discuss below, and in more detail in the section “Is there anything
                    wrong with using small time bins?”). The problem, then, is to find <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e001" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e002" xlink:type="simple"/></inline-formula> is a binary variable indicating no spike (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e003" xlink:type="simple"/></inline-formula>) or one or more spikes (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e004" xlink:type="simple"/></inline-formula>) on neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e005" xlink:type="simple"/></inline-formula>. Since this, too, is a high dimensional problem (though less
                    so than the original spike time representation), suppose that we instead
                    construct a pairwise approximation to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula>, which we denote <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e007" xlink:type="simple"/></inline-formula>, for a population of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>. (The pairwise model derives its name from the fact that it
                    has the same mean and pairwise correlations as the true model; see Eq. (15).)
                    Our question, then, is: if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e007" xlink:type="simple"/></inline-formula> is close to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula> for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, what can we say about how close the two distributions are for
                    large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>?</p>
                <fig id="pcbi-1000380-g001" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000380.g001</object-id>
                    <label>Figure 1</label>
                    <caption>
                        <title>Transforming spike trains to spike count.</title>
                        <p>(A) Spike rasters. Tick marks indicate spike times; different rows
                            correspond to different neurons. The horizontal dashed lines are the bin
                            boundaries. (B) Spike count in each bin. In this example the bins are
                            small enough that there is at most one spike per bin, but this is not
                            necessary—one could use bigger bins and have larger spike
                            counts.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.g001" xlink:type="simple"/>
                </fig>
                <p>To answer this question quantitatively, we need a measure of distance. The
                    measure we use, denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, is defined in Eq. (3) below, but all we need to know about it
                    for now is that if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e014" xlink:type="simple"/></inline-formula> then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e015" xlink:type="simple"/></inline-formula>, and if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> is near one then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e007" xlink:type="simple"/></inline-formula> is far from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula>. In terms of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, our main results are as follows. First, for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, in what we call the perturbative regime, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> is proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e022" xlink:type="simple"/></inline-formula>. In other words, as the population size increases, the
                    pairwise model becomes a worse and worse approximation to the true distribution.
                    Second, this behavior is entirely generic: for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> increases linearly, no matter what the true distribution is.
                    This is illustrated schematically in <xref ref-type="fig" rid="pcbi-1000380-g002">Fig. 2</xref>, which shows the generic behavior of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>. The solid red part of the curve is the perturbative regime,
                    where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> is a linearly increasing function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>; the dashed curves show possible behavior beyond the
                    perturbative regime.</p>
                <fig id="pcbi-1000380-g002" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000380.g002</object-id>
                    <label>Figure 2</label>
                    <caption>
                        <title>Cartoon illustrating the dependence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>.</title>
                        <p>For small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> there is always a perturbative regime in which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> increases linearly with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> (solid red line). When <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> becomes large, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> may continue increasing with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> (red and black dashed lines) or it may plateau (cyan
                            dashed line), depending on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula>. The observation that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> increases linearly with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> does not, therefore, provide much, if any information
                            about the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> behavior.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.g002" xlink:type="simple"/>
                </fig>
                <p>These results have an important corollary: if one does an experiment and finds
                    that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> is increasing linearly with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, then one has no information at all about the true
                    distribution. The flip side of this is more encouraging: if one can measure the
                    true distribution for sufficiently large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> saturates, as for the dashed blue line in <xref ref-type="fig" rid="pcbi-1000380-g002">Fig. 2</xref>, then there is a chance that
                    extrapolation to large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> is meaningful. The implications for the interpretation of
                    experiments is, therefore, that one can gain information about large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> behavior only if one can analyze data past the perturbative
                    regime.</p>
                <p>Under what conditions is a subsystem in the perturbative regime? The answer turns
                    out to be simple: the size of the system, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, times the average probability of observing a spike in a bin,
                    must be small compared to 1. For example, if the average probability is 1/100,
                    then a system will be in the perturbative regime if the number of neurons is
                    small compared to 100. This last observation would seem to be good news: if we
                    divide the spike trains into sufficiently small time bins and ignore temporal
                    correlations, then we can model the data very well with a pairwise distribution.
                    The problem with this, though, is that temporal correlations can be ignored only
                    when time bins are large compared to the autocorrelation time. This leads to a
                    kind of catch-22: pairwise models are guaranteed to work well (in the sense that
                    they describe spike trains in which temporal correlations are ignored) if one
                    uses small time bins, but small time bins is the one regime where ignoring
                    temporal correlations is not a valid approximation.</p>
                <p>In the next several sections we quantify the qualitative picture presented above:
                    we write down an explicit expression for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, explain why it increases linearly with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> is small, and provide additional tests, besides assessing the
                    linearity of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, to determine whether or not one is in the perturbative
                    regime.</p>
            </sec>
            <sec id="s2b">
                <title>Quantifying how well the pairwise model explains the data</title>
                <p>A natural measure of the distance between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e007" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula> is the Kullback-Leibler (KL) divergence <xref ref-type="bibr" rid="pcbi.1000380-Kullback1">[12]</xref>, denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e053" xlink:type="simple"/></inline-formula> and defined as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e054" xlink:type="simple"/><label>(1)</label></disp-formula></p>
                <p>The KL divergence is zero if the two distributions are equal; otherwise it is
                    nonzero.</p>
                <p>Although the KL divergence is a very natural measure, it is not easy to interpret
                    (except, of course, when it is exactly zero). That is because a nonzero KL
                    divergence tells us that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e055" xlink:type="simple"/></inline-formula>, but it does not give us any real handle on how good, or bad,
                    the pairwise model really is. To make sense of the KL divergence, we need
                    something to compare it to. A reasonable reference quantity, used by a number of
                    authors <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>, is the KL divergence
                    between the true distribution and the independent one, the latter denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e056" xlink:type="simple"/></inline-formula>. The independent distribution, as its name suggests, is a
                    distribution in which the variables are taken to be independent,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e057" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e058" xlink:type="simple"/></inline-formula> is the distribution of the response of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e059" xlink:type="simple"/></inline-formula> neuron, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e060" xlink:type="simple"/></inline-formula>. With this choice for a comparison, we define a normalized
                    distance measure—a measure of how well the pairwise model explains the data—as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e061" xlink:type="simple"/><label>(3)</label></disp-formula></p>
                <p>Note that the denominator in this expression, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e062" xlink:type="simple"/></inline-formula>, is usually referred to as the multi-information <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Friedman1">[13]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Slonim1">[14]</xref>.</p>
                <p>The quantity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> lies between 0 and 1, and measures how well a pairwise model
                    does relative to an independent model. If it is 0, the pairwise model is equal
                    to the true model (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e064" xlink:type="simple"/></inline-formula>); if it is near 1, the pairwise model offers little
                    improvement over the independent model; and if it is exactly 1, the pairwise
                    model is equal to the independent model (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e065" xlink:type="simple"/></inline-formula>), and so offers no improvement.</p>
                <p>How do we attach intuitive meaning to the two divergences <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e066" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e067" xlink:type="simple"/></inline-formula>? For the latter, we use the fact that, as is easy to show,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e068" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> are the entropies <xref ref-type="bibr" rid="pcbi.1000380-Shannon1">[15]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Cover1">[16]</xref> of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e071" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula>, respectively, defined, as usual, to be <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e073" xlink:type="simple"/></inline-formula>. For the former, we use the definition of the KL divergence to write<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e074" xlink:type="simple"/><label>(5)</label></disp-formula></p>
                <p>The quantity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e075" xlink:type="simple"/></inline-formula> has the flavor of an entropy, although it is a true entropy
                    only when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e007" xlink:type="simple"/></inline-formula> is maximum entropy as well as pairwise (see Eq. (6) below).
                    For other pairwise distributions, all we need to know is that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e077" xlink:type="simple"/></inline-formula> lies between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula>. A plot illustrating the relationship between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, the two entropies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula>, and the entropy-like quantity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e083" xlink:type="simple"/></inline-formula>, is shown in <xref ref-type="fig" rid="pcbi-1000380-g003">Fig.
                        3</xref>.</p>
                <fig id="pcbi-1000380-g003" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000380.g003</object-id>
                    <label>Figure 3</label>
                    <caption>
                        <title>Schematic plot of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula> (black line), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e085" xlink:type="simple"/></inline-formula> (cyan line) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> (red line).</title>
                        <p>The better the pairwise model, the closer <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e087" xlink:type="simple"/></inline-formula> is to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula>. This is reflected in the normalized distance measure, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, which is the distance between the red and cyan lines
                            divided by the distance between the red and black lines.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.g003" xlink:type="simple"/>
                </fig>
                <p>Note that for pairwise maximum entropy models (or maximum entropy models for
                    short), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> has a particularly simple interpretation, since in this case <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e091" xlink:type="simple"/></inline-formula> really is an entropy. Using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e092" xlink:type="simple"/></inline-formula> to denote the pairwise entropy of a maximum entropy model, for
                    this case we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e093" xlink:type="simple"/><label>(6)</label></disp-formula>as is easy to see by inserting Eqs. (4) and (5) into (3). This
                    expression has been used previously by a number of authors <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>.</p>
            </sec>
            <sec id="s2c">
                <title><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> in the perturbative regime</title>
                <p>The extrapolation problem discussed above is the problem of determining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> in the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> limit. This is hard to do in general, but there is a
                    perturbative regime in which it is possible. The small parameter that defines
                    this regime is the average number of spikes produced by the whole population of
                    neurons in each time bin. It is given quantitatively by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e097" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> is the bin size and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e099" xlink:type="simple"/></inline-formula> the average firing rate,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e100" xlink:type="simple"/><label>(7)</label></disp-formula>with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e101" xlink:type="simple"/></inline-formula> the firing rate of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e102" xlink:type="simple"/></inline-formula>.</p>
                <p>The first step in the perturbation expansion is to compute the two quantities
                    that make up <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e104" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e105" xlink:type="simple"/></inline-formula>. As we show in the section “Perturbative
                    Expansion” (<xref ref-type="sec" rid="s4">Methods</xref>), these are
                    given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e106" xlink:type="simple"/><label>(8a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e107" xlink:type="simple"/><label>(8b)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e108" xlink:type="simple"/><label>(9a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e109" xlink:type="simple"/><label>(9b)</label></disp-formula></p>
                <p>Here and in what follows we use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e110" xlink:type="simple"/></inline-formula> to denote terms that are proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e111" xlink:type="simple"/></inline-formula> in the limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e112" xlink:type="simple"/></inline-formula>. The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e113" xlink:type="simple"/></inline-formula> in Eq. (9a) has been noted previously <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>, although the
                    authors did not compute the prefactor, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula>.</p>
                <p>The prefactors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula>, which are given explicitly in Eqs. (42) and (44), depend on
                    the low order statistics of the spike trains: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> depends on the second order normalized correlation
                    coefficients, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> depends on the second and third order normalized correlation
                    coefficients (the normalized correlation coefficients are defined in Eq. (16)
                    below), and both depend on the firing rates of the individual cells. The details
                    of that dependence, however, are not important for now; what is important is
                    that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> are independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e122" xlink:type="simple"/></inline-formula> (at least on average; see next section).</p>
                <p>Inserting Eq. (8) into Eq. (3) (into the definition of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>) and using Eq. (9), we arrive at our main result,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e124" xlink:type="simple"/><label>(10a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e125" xlink:type="simple"/><label>(10b)</label></disp-formula></p>
                <p>Note that in the regime <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e126" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> is necessarily small. This explains why, in an analytic study
                    of non-pairwise model in which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e128" xlink:type="simple"/></inline-formula> was small, Shlens et al. found that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> was rarely greater than 0.1 <xref ref-type="bibr" rid="pcbi.1000380-Shlens1">[8]</xref>.</p>
                <p>We refer to quantities with a superscript zero as “zeroth
                    order.” Note that, via Eqs. (4) and (5), we can also define zeroth
                    order entropies,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e130" xlink:type="simple"/><label>(11a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e131" xlink:type="simple"/><label>(11b)</label></disp-formula></p>
                <p>These quantities are important primarily because differences between them and the
                    actual entropies indicate a breakdown of the perturbation expansion (see in
                    particular <xref ref-type="fig" rid="pcbi-1000380-g004">Fig. 4</xref> below).</p>
                <fig id="pcbi-1000380-g004" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000380.g004</object-id>
                    <label>Figure 4</label>
                    <caption>
                        <title>Cartoon showing extrapolations of the zeroth order KL divergences and
                            entropies (see Eqs. (9) and (11)).</title>
                        <p>These extrapolations illustrate why the two natural quantities derived
                            from them, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e132" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e133" xlink:type="simple"/></inline-formula>, occur beyond the point at which the extrapolation is
                            meaningful. (A) Extrapolations on a log-log scale. Black: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula>; green: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e135" xlink:type="simple"/></inline-formula>; cyan: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e136" xlink:type="simple"/></inline-formula>. The red points are the data. The points <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e132" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e133" xlink:type="simple"/></inline-formula> label the intersections of the two extrapolations with
                            the independent entropy, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula>. (B) Extrapolation of the entropies rather than the KL
                            divergences, plotted on a linear-linear scale. The data, again shown in
                            red, is barely visible in the lower left hand corner. Black: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula>; solid orange: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e141" xlink:type="simple"/></inline-formula>; solid maroon: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e142" xlink:type="simple"/></inline-formula>. The dashed orange and maroon lines are the
                            extrapolations of the true entropy and true pairwise
                            “entropy”, respectively.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.g004" xlink:type="simple"/>
                </fig>
                <p>Assuming, as discussed in the next section, that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> are approximately independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e099" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>, Eq. (10) tells us that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> scales linearly with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> in the perturbative regime—the regime in which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e150" xlink:type="simple"/></inline-formula>. The key observation about this scaling is that it is
                    independent of the details of the true distribution, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula>. This has a very important consequence, one that has major
                    implications for experimental data: if one does an experiment with small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e152" xlink:type="simple"/></inline-formula> and finds that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> is proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e154" xlink:type="simple"/></inline-formula>, then the system is, with very high probability, in the
                    perturbative regime, and one does not know whether <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e007" xlink:type="simple"/></inline-formula> will remain close to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula> as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> increases. What this means in practical terms is that if one
                    wants to know whether a particular pairwise model is a good one for large
                    systems, it is necessary to consider values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> that are significantly greater than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e159" xlink:type="simple"/></inline-formula>, where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e160" xlink:type="simple"/><label>(12)</label></disp-formula></p>
                <p>We interpret <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e161" xlink:type="simple"/></inline-formula> as the value at which there is a crossover in the behavior of
                    the pairwise model. Specifically, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e162" xlink:type="simple"/></inline-formula>, the system is in the perturbative regime and the pairwise
                    model is not informative about the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> behavior, whereas if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e164" xlink:type="simple"/></inline-formula>, the system is in a regime in which it may be possible to make
                    inferences about the behavior of the full system.</p>
            </sec>
            <sec id="s2d">
                <title>The prefactors, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula></title>
                <p>As we show in <xref ref-type="sec" rid="s4">Methods</xref> (see in particular
                    Eqs. (42) and (44)), the prefactors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> depend on which neurons out of the full population are used.
                    Consequently, these quantities fluctuate around their true values (in the sense
                    that different subpopulations produce different values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula>), where “true” refers to an average over
                    all possible <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e171" xlink:type="simple"/></inline-formula> sub-populations. Here we assume that the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> neurons are chosen randomly from the full population, so any
                    set of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> neurons provides unbiased estimates of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula>. In our simulations, the fluctuations were small, as indicated
                    by the small error bars on the blue points in <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref>. However, in general the size of the
                    fluctuations is determined by the range of firing rates and correlation
                    coefficients, with larger ranges producing larger fluctuations.</p>
                <fig id="pcbi-1000380-g005" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000380.g005</object-id>
                    <label>Figure 5</label>
                    <caption>
                        <title>The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> dependence of the KL divergences and the normalized
                            distance measure, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>.</title>
                        <p>Data was generated from a third order model, as explained in the section
                            “Generating synthetic data” (<xref ref-type="sec" rid="s4">Methods</xref>), and fit to pairwise maximum entropy models
                            and independent models. All data points correspond to averages over
                            marginalizations of the true distribution (see text for details). The
                            red points were computed directly using Eqs. (1), (3) and (4); the blue
                            points are the zeroth order estimates, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e178" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e179" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e180" xlink:type="simple"/></inline-formula>, in rows 1, 2 and 3, respectively. The three columns
                            correspond to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e181" xlink:type="simple"/></inline-formula>, 0.029, and 0.037, from left to right. (A, B, C) (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e182" xlink:type="simple"/></inline-formula>). Predictions from the perturbative expansion are in
                            good agreement with the measurements up to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e183" xlink:type="simple"/></inline-formula>, indicating that the data is in the perturbative
                            regime. (D, E, F) (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e184" xlink:type="simple"/></inline-formula>). Predictions from the perturbative expansion are in
                            good agreement with the measurements up to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e185" xlink:type="simple"/></inline-formula>, indicating that the data is only partially in the
                            perturbative regime. (G, H, I) (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e186" xlink:type="simple"/></inline-formula>). Predictions from the perturbative expansion are not
                            in good agreement with the measurements, even for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, indicating that the data is outside the perturbative
                            regime.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.g005" xlink:type="simple"/>
                </fig>
                <p>Because <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> does not affect the mean values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula>, it is reasonable to think of these quantities—or at
                    least their true values—as being independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>. They are also independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e099" xlink:type="simple"/></inline-formula>, again modulo fluctuations. Finally, as we show in the section
                    “Bin size and the correlation coefficients” (<xref ref-type="sec" rid="s4">Methods</xref>), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> are independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> in the limit that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> is small compared to the width of the temporal correlations
                    among neurons. We will assume this limit applies here. In sum, then, to first
                    approximation, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> are independent of our three important quantities: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e099" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>. Thus, we treat them as effectively constant throughout our
                    analysis.</p>
            </sec>
            <sec id="s2e">
                <title>The dangers of extrapolation</title>
                <p>Although the behavior of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> in the perturbative regime does not tell us much about its
                    behavior at large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, it is possible that other quantities that can be calculated
                    in the perturbative regime, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula> (the last one exactly), are informative, as others have
                    suggested <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>. Here we show that this is not the
                    case—they also are uninformative.</p>
                <p>The easiest way to relate the perturbative regime to the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> regime is to ignore the corrections in Eqs. (8a) and (8b),
                    extrapolate the expressions for the zeroth order terms, and ask what their large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> behavior tells us. Generic versions of these extrapolations,
                    plotted on a log-log scale, are shown in <xref ref-type="fig" rid="pcbi-1000380-g004">Fig. 4A</xref>, along with a plot of the independent
                    entropy, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula> (which is necessarily linear in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>). The first thing we notice about the extrapolations is that
                    they do not, technically, have a large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> behavior: one terminates at the point labeled <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e132" xlink:type="simple"/></inline-formula>, which is where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e213" xlink:type="simple"/></inline-formula> (and thus, via Eq. (0a), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e214" xlink:type="simple"/></inline-formula>; continuing the extrapolation implies negative true zeroth
                    order entropy); the other at the point labeled <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e133" xlink:type="simple"/></inline-formula>, which is where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e216" xlink:type="simple"/></inline-formula> (and thus, via Eq. (5) and the fact that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e217" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e218" xlink:type="simple"/></inline-formula>).</p>
                <p>Despite the fact that the extrapolations end abruptly, they still might provide
                    information about the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> regime. For example, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e133" xlink:type="simple"/></inline-formula> and/or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e132" xlink:type="simple"/></inline-formula> might be values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> at which something interesting happens. To see if this is the
                    case, in <xref ref-type="fig" rid="pcbi-1000380-g004">Fig. 4B</xref> we plot the
                    naive extrapolations of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e223" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> (that is, the zeroth order quantities given in Eq. (11), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e225" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e226" xlink:type="simple"/></inline-formula>), on a linear-linear plot, along with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula>. This plot contains no new information compared to <xref ref-type="fig" rid="pcbi-1000380-g004">Fig. 4A</xref>, but it does elucidate
                    the meaning of the extrapolations. Perhaps its most striking feature is that the
                    naive extrapolation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> has a decreasing portion. As is easy to show mathematically,
                    entropy cannot decrease with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> (intuitively, that is because observing one additional neuron
                    cannot decrease the entropy of previously observed neurons). Thus, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e132" xlink:type="simple"/></inline-formula>, which occurs well beyond the point where the naive
                    extrapolation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> is decreasing, has essentially no meaning, something that has
                    been pointed out previously by Bethge and Berens <xref ref-type="bibr" rid="pcbi.1000380-Bethge1">[10]</xref>. The other
                    potentially important value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e133" xlink:type="simple"/></inline-formula>. This, though, suffers from a similar problem: when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e234" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e235" xlink:type="simple"/></inline-formula> is negative.</p>
                <p>How do the naively extrapolated entropies—the solid lines in <xref ref-type="fig" rid="pcbi-1000380-g004">Fig. 4B</xref>—compare to
                    the actual entropies? To answer this, in <xref ref-type="fig" rid="pcbi-1000380-g004">Fig. 4B</xref> we show the true behavior of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e237" xlink:type="simple"/></inline-formula> versus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> (dashed lines). Note that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> is asymptotically linear in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, even though the neurons are correlated, a fact that forces <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e241" xlink:type="simple"/></inline-formula> to be linear in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, as it is sandwiched between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e069" xlink:type="simple"/></inline-formula>. (The asymptotically linear behavior of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e070" xlink:type="simple"/></inline-formula> is typical, even in highly correlated systems. Although this
                    is not always appreciated, it is easy to show; see the section “The
                    behavior of the true entropy in the large <italic>N</italic> limit,”
                    <xref ref-type="sec" rid="s4">Methods</xref>.) Comparing the dashed and solid lines, we see that the naively
                    extrapolated and true entropies, and thus the naively extrapolated and true
                    values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, have extremely different behavior. This further suggests that
                    there is very little connection between the perturbative and large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> regimes.</p>
                <p>In fact, these observations follow directly from the fact that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> depend only on correlation coefficients up to third order (see
                    Eqs. (42) and (44)) whereas the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> behavior depends on correlations at all orders. Thus, since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> tell us very little, if anything, about higher order
                    correlations, it is not surprising that they tell us very little about the
                    behavior of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> in the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> limit.</p>
            </sec>
            <sec id="s2f">
                <title>Numerical simulations</title>
                <p>To check that our perturbation expansions, Eqs. (8–10), are correct,
                    and to investigate the regime in which they are valid, we performed numerical
                    simulations. We generated, from synthetic data, a set of true distributions,
                    computed the true distance measures, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e255" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e256" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> numerically, and compared them to the zeroth order ones, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e258" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e259" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e260" xlink:type="simple"/></inline-formula>. If the perturbation expansion is valid, then the true values
                    should be close to the zeroth order values whenever <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e261" xlink:type="simple"/></inline-formula> is small. The results are shown in <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref>, and that is, indeed, what we
                    observed. Before discussing that figure, though, we explain our procedure for
                    constructing true distributions.</p>
                <p>The set of true distributions we used were generated from a third order model (so
                    named because it includes up to third order interactions). This model has the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e262" xlink:type="simple"/><label>(13)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e263" xlink:type="simple"/></inline-formula> is a normalization constant, chosen to ensure that the
                    probability distribution sums to 1, and the sums over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e264" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e265" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e266" xlink:type="simple"/></inline-formula> run from 1 to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e267" xlink:type="simple"/></inline-formula>. The parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e268" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e269" xlink:type="simple"/></inline-formula> were chosen by sampling from distributions (see the section
                    “Generating synthetic data,” <xref ref-type="sec" rid="s4">Methods</xref>), which allowed us to
                    generate many different true distributions. In all of our simulations we
                    calculate the relevant quantities directly from Eq. (13) . Consequently, we do
                    not have to worry about issues of finite data, as would be the case in realistic
                    experiments.</p>
                <p>For a particular simulation (corresponding to a column in <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref>), we generated a true distribution
                    with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e270" xlink:type="simple"/></inline-formula>, randomly chose 5 neurons, and marginalized over them. This
                    gave us a 10-neuron true distribution. True distributions with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e271" xlink:type="simple"/></inline-formula> were constructed by marginalizing over additional neurons
                    within our 10-neuron population. To achieve a representative sample, we
                    considered all possible marginalizations (of which there are 10 choose <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e273" xlink:type="simple"/></inline-formula>). The results in <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref> are averages over these marginalizations.</p>
                <p>For neural data, the most commonly used pairwise model is the maximum entropy
                    model. Therefore, we use that one here. To emphasize the maximum entropy nature
                    of this model, we replace the label “<italic>pair</italic>”
                    that we have been using so far with
                    “<italic>maxent</italic>.” The maximum entropy distribution
                    has the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e274" xlink:type="simple"/><label>(14)</label></disp-formula></p>
                <p>Fitting this distribution requires that we choose the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e275" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e276" xlink:type="simple"/></inline-formula> so that the first and second moments match those of the true
                    distribution. Quantitatively, these conditions are<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e277" xlink:type="simple"/><label>(15a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e278" xlink:type="simple"/><label>(15b)</label></disp-formula>where the angle brackets, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e279" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e280" xlink:type="simple"/></inline-formula>, represent averages with respect to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e281" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e006" xlink:type="simple"/></inline-formula>, respectively. Once we have <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e283" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e284" xlink:type="simple"/></inline-formula> that satisfy Eq. (15), we calculate the KL divergences, Eqs.
                    (1) and (4), and use those to compute <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>.</p>
                <p>The results are shown in <xref ref-type="fig" rid="pcbi-1000380-g005">Fig.
                    5</xref>. The rows correspond to our three quantities of interest: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e286" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e287" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> (top to bottom). The columns correspond to different values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e289" xlink:type="simple"/></inline-formula>, with the smallest <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e290" xlink:type="simple"/></inline-formula> on the left and the largest on the right. Red circles are the
                    true values of these quantities; blue ones are the zeroth order predictions from
                    Eqs. (9) and (10b).</p>
                <p>As suggested by our perturbation analysis, the smaller the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e291" xlink:type="simple"/></inline-formula>, the larger the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> for which agreement between the true and zeroth order values
                    is good. Our simulations corroborate this: the left column of <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref> has <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e293" xlink:type="simple"/></inline-formula>, and agreement is almost perfect out to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e294" xlink:type="simple"/></inline-formula>; the middle column has <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e295" xlink:type="simple"/></inline-formula>, and agreement is almost perfect out to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e296" xlink:type="simple"/></inline-formula>; and the right column has <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e297" xlink:type="simple"/></inline-formula>, and agreement is not good for any value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>. Note that the perturbation expansion breaks down for values
                    of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> well below <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e300" xlink:type="simple"/></inline-formula> (defined in Eq.(12)): in the middle column of <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref> it breaks down when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e301" xlink:type="simple"/></inline-formula>, and in the right column it breaks down when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e302" xlink:type="simple"/></inline-formula>. This is not, however, especially surprising, as the
                    perturbation expansion is guaranteed to be valid only if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e303" xlink:type="simple"/></inline-formula>.</p>
                <p>These results validate the perturbation expansions in Eqs. (8) and (10), and show
                    that those expansions provide sensible predictions—at least for some
                    parameters. They also suggest a natural way to assess the significance of
                    one's data: plot <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e304" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e305" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> versus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, and look for agreement with the predictions of the
                    perturbation expansion. If agreement is good, as in the left column of <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref>, then one is in the
                    perturbative regime, and one knows very little about the true distribution. If,
                    on the other hand, agreement is bad, as in the right column, then one is out of
                    the perturbative regime, and it may be possible to extract meaningful
                    information about the relationship between the true and pairwise models.</p>
                <p>That said, the qualifier “at least for some parameters” is an
                    important one. This is because the perturbation expansion is essentially an
                    expansion that depends on the normalized correlation coefficients, and there is
                    an underlying assumption that they don't exhibit pathological behavior.
                    The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e308" xlink:type="simple"/></inline-formula> order normalized correlation coefficient for the distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e309" xlink:type="simple"/></inline-formula>, denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e310" xlink:type="simple"/></inline-formula>, is written<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e311" xlink:type="simple"/><label>(16)</label></disp-formula>A potentially problematic feature of the correlation coefficients
                    is that the denominator is a product over mean activities. If the mean
                    activities are small, the denominator can become very small, leading to very
                    large correlation coefficients. Although our perturbation expansion is always
                    valid for sufficiently small time bins (because the correlation coefficients
                    eventually becomes independent of bin size; see the section “Bin size
                    and the correlation coeffcients,” <xref ref-type="sec" rid="s4">Methods</xref>), “sufficiently
                    small” can depend in detail on the parameters. For instance, at the
                    maximum population size tested (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e312" xlink:type="simple"/></inline-formula>) and for the true distributions that had <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e313" xlink:type="simple"/></inline-formula>, the absolute error of the prediction had a median of
                    approximately 16%. However, about 11% of the runs had
                    errors larger than 60%. Thus, the exact size of the small parameter
                    at which the perturbative expansion breaks down can depend on the details of the
                    true distribution.</p>
            </sec>
            <sec id="s2g">
                <title>External fields and pairwise couplings have a simple dependence on firing
                    rates and correlation coefficients in the perturbative regime</title>
                <p>Estimation of the KL divergences and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> from real data can be hard, in the sense that it takes a large
                    amount of data for them to converge to their true values. In addition, as
                    discussed above, in the section “The prefactors
                        <italic>g<sub>ind</sub></italic> and
                    <italic>g<sub>pair</sub></italic>”, there are fluctuations in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> associated with finite subsampling of the full population of
                    neurons. Those fluctuations tend to keep <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> from being purely linear, as can seen, for example, in the
                    blue points in <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5F and
                    5I</xref>. We therefore provide a second set of relationships that can be used
                    to determine whether or not a particular data set is in the perturbative regime.
                    These relationships are between the parameters of the maximum entropy model, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e317" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e318" xlink:type="simple"/></inline-formula>, and the mean activity and normalized second order correlation
                    coefficient (the latter defined in Eq. (19) below).</p>
                <p>Since the quantity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e319" xlink:type="simple"/></inline-formula> plays a central role in our analysis, we replace it with a
                    single parameter, which we denote <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e320" xlink:type="simple"/></inline-formula>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e321" xlink:type="simple"/><label>(17)</label></disp-formula>In terms of this parameter, we find (using the same perturbative
                    approach that led us to Eqs. (8–10); see the section
                    “External fields, pairwise couplings and moments,” <xref ref-type="sec" rid="s4">Methods</xref>), that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e322" xlink:type="simple"/><label>(18a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e323" xlink:type="simple"/><label>(18b)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula>, the normalized second order correlation coefficient, is
                    defined in Eq. (16) with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e325" xlink:type="simple"/></inline-formula>; it is given explicitly by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e326" xlink:type="simple"/><label>(19)</label></disp-formula>(We don't need a superscript on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e327" xlink:type="simple"/></inline-formula> or a subscript on the angle brackets because the first and
                    second moments are the same under the true and pairwise distributions.) Equation
                    (18a) can be reconstructed from the low firing rate limit of analysis carried
                    out by Sessak and Monasson <xref ref-type="bibr" rid="pcbi.1000380-Sessak1">[17]</xref>, as can the first three terms in the
                    expansion of the log in Eq. (18b).</p>
                <p>Equation (18) tells us that the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e328" xlink:type="simple"/></inline-formula> of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e329" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e330" xlink:type="simple"/></inline-formula>, the external fields and pairwise couplings, is very weak. In
                        <xref ref-type="fig" rid="pcbi-1000380-g006">Fig. 6</xref> we confirm this
                    through numerical simulations. Equation (18b) also provides additional
                    information—it gives us a functional relationship between the pairwise
                    couplings and the normalized pairwise correlations function, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula>. In <xref ref-type="fig" rid="pcbi-1000380-g007">Fig.
                        7A–C</xref> we plot the pairwise couplings, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e332" xlink:type="simple"/></inline-formula>, versus the normalized pairwise correlation coefficient, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> (blue dots), along with the prediction from Eq. (18b) (black
                    line). Consistent with our predictions, the data in <xref ref-type="fig" rid="pcbi-1000380-g007">Fig. 7A–C</xref> essentially follows a
                    line—the line given by Eq. (18b).</p>
                <fig id="pcbi-1000380-g006" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000380.g006</object-id>
                    <label>Figure 6</label>
                    <caption>
                        <title>The true external fields and pairwise interactions compared with the
                            predictions of the perturbation expansion.</title>
                        <p>The top row shows the true external fields, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e334" xlink:type="simple"/></inline-formula>, versus those predicted from Eq. (18a), and the bottom
                            row shows the true pairwise interaction, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e335" xlink:type="simple"/></inline-formula>, versus those predicted from Eq. (18b). Values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> ranging from 5 to 10 are shown, with different colors
                            corresponding to different <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e337" xlink:type="simple"/></inline-formula>. For each value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, data is shown for 45 realization of the true
                            distribution. Insets show the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e339" xlink:type="simple"/></inline-formula> of the mean external fields (top) and mean pairwise
                            interactions (bottom). The three columns correspond exactly to the
                            columns in <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref>.
                            (A, B) (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e340" xlink:type="simple"/></inline-formula>). There is a very good match between the true and
                            predicted values of both external fields and pairwise interactions. (C,
                            D) (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e341" xlink:type="simple"/></inline-formula>). Even though <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e342" xlink:type="simple"/></inline-formula> has increased, the match is still good. (E, F) (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e343" xlink:type="simple"/></inline-formula>). The true and predicted external fields and pairwise
                            interactions do not match as well as the cases shown in (A, B, C, D).
                            There is also now a stronger <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e344" xlink:type="simple"/></inline-formula> in the mean external fields compared to (A) and (B).
                            The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e345" xlink:type="simple"/></inline-formula> of the pairwise interactions in (F) is weaker than
                            that of the external fields, but still notably stronger than the ones in
                            (B) and (D). This indicates that the perturbative expansion is starting
                            to break down.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.g006" xlink:type="simple"/>
                </fig>
                <fig id="pcbi-1000380-g007" position="float">
                    <object-id pub-id-type="doi">10.1371/journal.pcbi.1000380.g007</object-id>
                    <label>Figure 7</label>
                    <caption>
                        <title>The relation between pairwise couplings and pairwise correlations.</title>
                        <p>This figure shows that there is a simple relation between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e346" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula>, but not between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e348" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e349" xlink:type="simple"/></inline-formula>. (A, C, E) <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e350" xlink:type="simple"/></inline-formula> versus the normalized coefficients, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> (blue points), along with the predicted relationship,
                            via Eq. (18b) (black line). (B, D, F) <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e352" xlink:type="simple"/></inline-formula> versus the Pearson correlation coefficients, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e349" xlink:type="simple"/></inline-formula>, Eq. (26) (blue points). The three columns correspond
                            exactly to the columns in <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref> from left to right; that is, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e354" xlink:type="simple"/></inline-formula> for (A, B), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e355" xlink:type="simple"/></inline-formula> for (C, D), and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e356" xlink:type="simple"/></inline-formula> for (E, F). The prediction in the top row (black line)
                            matches the data well, even in the rightmost column.</p>
                    </caption>
                    <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.g007" xlink:type="simple"/>
                </fig>
                <p>A relationship between the pairwise couplings and the correlations coefficients
                    has been sought previously, but for the more standard Pearson correlation
                    coefficient <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref>. Our analysis explains why it was not found.
                    The Pearson correlation coefficient, denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e349" xlink:type="simple"/></inline-formula>, is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e358" xlink:type="simple"/><label>(20)</label></disp-formula></p>
                <p>In the small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e359" xlink:type="simple"/></inline-formula> limit—the limit of interest—the right hand
                    side of Eq. (20) is approximately equal to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e360" xlink:type="simple"/></inline-formula>. Because <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e361" xlink:type="simple"/></inline-formula> depends on the external fields, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e362" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e363" xlink:type="simple"/></inline-formula> (see Eq. (18a)) <italic>and</italic> there is a one-to-one
                    relationship between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e365" xlink:type="simple"/></inline-formula> (Eq. (18b)), there can't be a one-to-one relationship
                    between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e349" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e367" xlink:type="simple"/></inline-formula>. We verify the lack of a relationship in <xref ref-type="fig" rid="pcbi-1000380-g007">Fig. 7D and 7E</xref>, where we again plot <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e368" xlink:type="simple"/></inline-formula>, but this time versus the standard correlation coefficient, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e349" xlink:type="simple"/></inline-formula>. As predicted, the data in <xref ref-type="fig" rid="pcbi-1000380-g007">Fig. 7D and 7E</xref> is scattered over two
                    dimensions. This suggests that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula>, not <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e349" xlink:type="simple"/></inline-formula>, is the natural measure of the correlation between two neurons
                    when they have a binary representation, something that has also been suggested
                    by Amari based on information-geometric arguments <xref ref-type="bibr" rid="pcbi.1000380-Amari1">[18]</xref>.</p>
                <p>Note that the lack of a simple relationship between the pairwise couplings and
                    the standard correlation coefficient has been a major motivation in building
                    maximum entropy models <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref>. This is for good reason: if there is a
                    simple relationship, knowing the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e372" xlink:type="simple"/></inline-formula> adds essentially nothing. Thus, plotting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e373" xlink:type="simple"/></inline-formula> versus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> (but not <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e349" xlink:type="simple"/></inline-formula>) is an important test of one's data, and if the two
                    quantities fall on the curve predicted by Eq. (18b), the maximum entropy model
                    is adding very little information, if any.</p>
                <p>As an aside, we should point out that the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e376" xlink:type="simple"/></inline-formula> is a function of the variables used to represent the firing
                    patterns. Here we use 0 for no spike and 1 for one or more spikes, but another,
                    possibly more common, representation, derived from the Ising model and used in a
                    number of studies <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref>, is to use −1 and +1
                    rather than 0 and 1. This amounts to making the change of variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e377" xlink:type="simple"/></inline-formula>. In terms of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e378" xlink:type="simple"/></inline-formula>, the maximum entropy model has the form <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e379" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e380" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e381" xlink:type="simple"/></inline-formula> are given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e382" xlink:type="simple"/><label>(21a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e383" xlink:type="simple"/><label>(21b)</label></disp-formula></p>
                <p>The second term on the right side of Eq. (21a) is proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e384" xlink:type="simple"/></inline-formula>, which means the external fields in the Ising representation
                    acquire a linear <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e385" xlink:type="simple"/></inline-formula> that was not present in our 0/1 representation. The two
                    studies that reported the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e386" xlink:type="simple"/></inline-formula> of the external fields <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref> used
                    this representation, and, as predicted by our analysis, the external fields in
                    those studies had a component that was linear in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>.</p>
            </sec>
            <sec id="s2h">
                <title>Is there anything wrong with using small time bins?</title>
                <p>An outcome of our perturbative approach is that our normalized distance measure, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, is linear in bin size (see Eq. (10b)). This suggests that one
                    could make the pairwise model look better and better simply by making the bin
                    size smaller and smaller. Is there anything wrong with this? The answer is yes,
                    for reasons discussed above (see the the section “The extrapolation
                    problem”); here we emphasize and expand on this issue, as it is an
                    important one for making sense of experimental results.</p>
                <p>The problem arises because what we have been calling the
                    “true” distribution is not really the true distribution of
                    spike trains. It is the distribution assuming independent time bins, an
                    assumption that becomes worse and worse as we make the bins smaller and smaller.
                    (We use this potentially confusing nomenclature primarily because all studies of
                    neuronal data carried out so far have assumed temporal independence, and
                    compared the pairwise distribution to the temporally independent—but
                    still correlated across neurons—distribution <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref>. In
                    addition, the correct name “true under the assumption of temporal
                    independence,” is unwieldy.) Here we quantify how much worse. In
                    particular, we show that if one uses time bins that are small compared to the
                    characteristic correlation time in the spike trains, the pairwise model will not
                    provide a good description of the data. Essentially, we show that, when the time
                    bins are too small, the error one makes in ignoring temporal correlations is
                    larger than the error one makes in ignoring correlations across neurons.</p>
                <p>As usual, we divide time into bins of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>. However, because we are dropping the independence assumption,
                    we use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e390" xlink:type="simple"/></inline-formula>, rather than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e391" xlink:type="simple"/></inline-formula>, to denote the response in bin <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e392" xlink:type="simple"/></inline-formula>. The full probability distribution over all time bins is
                    denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e393" xlink:type="simple"/></inline-formula>. Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e394" xlink:type="simple"/></inline-formula> is the number of bins; it is equal to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e395" xlink:type="simple"/></inline-formula> for spike trains of length <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e396" xlink:type="simple"/></inline-formula>. If time bins are approximately independent and the
                    distribution of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e397" xlink:type="simple"/></inline-formula> is the same for all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e398" xlink:type="simple"/></inline-formula> (an assumption we make for convenience only, but do not need;
                    see the section “Extending the normalized distance measure to the time
                    domain,” <xref ref-type="sec" rid="s4">Methods</xref>), we can write<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e399" xlink:type="simple"/><label>(22)</label></disp-formula></p>
                <p>Furthermore, if the pairwise model is a good one, we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e400" xlink:type="simple"/><label>(23)</label></disp-formula></p>
                <p>Combining Eqs. (22) and Eq. (23) then gives us an especially simple expression
                    for the full probability distribution: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e401" xlink:type="simple"/></inline-formula>.</p>
                <p>The problem with small time bins lies in Eq. (22): the right hand side is a good
                    approximation to the true distribution when the time bins are large compared to
                    the spike train correlation time, but it is a bad approximation when the time
                    bins are small (because adjacent time bins become highly correlated). To
                    quantify how bad, we compare the error one makes assuming independence across
                    time to the error one makes assuming independence across neurons. The ratio of
                    those two errors, denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e402" xlink:type="simple"/></inline-formula>, is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e403" xlink:type="simple"/><label>(24)</label></disp-formula></p>
                <p>It is relatively easy to compute <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e402" xlink:type="simple"/></inline-formula> in the limit of small time bins (see the section
                    “Extending the normalized distance measure to the time
                    domain,” <xref ref-type="sec" rid="s4">Methods</xref>), and we find that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e405" xlink:type="simple"/><label>(25)</label></disp-formula></p>
                <p>As expected, this reduces to our old result, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>, when there is only one time bin (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e407" xlink:type="simple"/></inline-formula>). When <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e394" xlink:type="simple"/></inline-formula> is larger than 1, however, the second term is always at least
                    one, and for small bin size, the third term is much larger than one.
                    Consequently, if we use bins that are small compared to the temporal correlation
                    time of the spike trains, the pairwise model will do a very bad job describing
                    the full, temporally correlated spike trains.</p>
            </sec>
        </sec>
        <sec id="s3">
            <title>Discussion</title>
            <p>Probability distributions over the configurations of biological systems are extremely
                important quantities. However, because of the large number of interacting elements
                comprising such systems, these distributions can almost never be determined directly
                from experimental data. Using parametric models to approximate the true distribution
                is the only existing alternative. While such models are promising, they are
                typically applied only to small subsystems, not the full system. This raises the
                question: are they good models of the full system?</p>
            <p>We answered this question for a class of parametric models known as pairwise models.
                We focused on a particular application, neuronal spike trains, and our main result
                is as follows: if one were to record spikes from multiple neurons, use sufficiently
                small time bins and a sufficiently small number of cells, and assume temporal
                independence, then a pairwise model will almost always succeed in matching the true
                (but temporally independent) distribution—whether or not it would match
                the true (but still temporally independent) distribution for large time bins or a
                large number of cells. In other words, pairwise models in the
                “sufficiently small” regime, what we refer to as the
                perturbative regime, have almost no predictive value for what will happen with large
                populations. This makes extrapolation from small to large systems dangerous.</p>
            <p>This observation is important because pairwise models, and in particular pairwise
                maximum entropy models, have recently attracted a great deal of attention: they have
                been applied to salamander and guinea pig retinas <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>, primate retina
                    <xref ref-type="bibr" rid="pcbi.1000380-Shlens1">[8]</xref>,
                primate cortex <xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>, cultured cortical networks <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>, and cat visual
                cortex <xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref>.
                These studies have mainly operated close to the perturbative regime. For example,
                Schneidman et al. <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref> had <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e409" xlink:type="simple"/></inline-formula> (for the data set described in their <xref ref-type="fig" rid="pcbi-1000380-g005">Fig. 5</xref>), Tang et al. <xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref> had <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e410" xlink:type="simple"/></inline-formula> to 0.4 (depending on the preparation), and Yu et al. <xref ref-type="bibr" rid="pcbi.1000380-Yu1">[11]</xref> had <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e411" xlink:type="simple"/></inline-formula>. For these studies, then, it would be hard to justify
                extrapolating to large populations.</p>
            <p>The study by Shlens et al. <xref ref-type="bibr" rid="pcbi.1000380-Shlens1">[8]</xref>, on the other hand, might be more amenable to
                extrapolation. This is because spatially localized visual patterns were used to
                stimulate retinal ganglion cells, for which a nearest neighbor maximum entropy
                models provided a good fit to their data. (Nearest neighbor means <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e412" xlink:type="simple"/></inline-formula> is zero unless neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e413" xlink:type="simple"/></inline-formula> and neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e265" xlink:type="simple"/></inline-formula> are adjacent.) Our analysis still applies, but, since all but the
                nearest neighbor correlations are zero, many of the terms that make up <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> vanish (see Eqs. (42) and (44)). Consequently, the small parameter
                in the perturbative expansion becomes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e417" xlink:type="simple"/></inline-formula> (rather than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e418" xlink:type="simple"/></inline-formula>), where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e419" xlink:type="simple"/></inline-formula> is the number of nearest neighbors. Since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e420" xlink:type="simple"/></inline-formula> is fixed, independent of the population size, the small parameter
                will not change as the population size increases. Thus, Shlens et al.may have tapped
                into the large population behavior even though they considered only a few cells at a
                time in their analysis. Indeed, they have recently extended their analysis to more
                than 100 neurons, and they still find that nearest neighbor maximum entropy models
                provide very good fits to the data <xref ref-type="bibr" rid="pcbi.1000380-Shlens2">[19]</xref>.</p>
            <sec id="s3a">
                <title>Time bins and population size</title>
                <p>That the pairwise model is always good if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e421" xlink:type="simple"/></inline-formula> is sufficiently small has strong implications: if we want to
                    build a good model for a particular <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, we can simply choose a bin size that is small compared to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e423" xlink:type="simple"/></inline-formula>. However, one of the assumptions in all pairwise models used
                    on neural data is that bins at different times are independent. This produces a
                    tension between small time bins and temporal independence: small time bins
                    essentially ensure that a pairwise model will provide a close approximation to a
                    model with independent bins, but they make adjacent bins highly correlated.
                    Large time bins come with no such assurance, but they make adjacent bins
                    independent. Unfortunately, this tension is often unresolvable in large
                    populations, in the sense that pairwise models are assured to work only up to
                    populations of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e424" xlink:type="simple"/></inline-formula> where <italic>τ</italic><sub>corr</sub> is the typical
                    correlation time. Given that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e099" xlink:type="simple"/></inline-formula> is at least several Hz, for experimental paradigms in which
                    the correlation time is more than a few hundred ms, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e426" xlink:type="simple"/></inline-formula> is about one, and this assurance does not apply to even
                    moderately sized populations of neurons.</p>
                <p>These observations are especially relevant for studies that use small time bins
                    to model spike trains driven by natural stimuli. This is because the long
                    correlation times inherent in natural stimuli are passed on to the spike trains,
                    so the assumption of independence across time (which is required for the
                    independence assumption to be valid) breaks badly. Knowing that these models are
                    successful in describing spike trains under the independence assumption, then,
                    does not tell us whether they will be successful in describing full, temporally
                    correlated, spike trains. Note that for studies that use stimuli with short
                    correlation times (e.g., non-natural stimuli such as white noise), the temporal
                    correlations in the spike trains are likely to be short, and using small time
                    bins may be perfectly valid.</p>
                <p>The only study that has investigated the issue of temporal correlations in
                    maximum entropy models does indeed support the above picture <xref ref-type="bibr" rid="pcbi.1000380-Tang1">[9]</xref>: for
                    the parameters used in that study (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e427" xlink:type="simple"/></inline-formula> to 0.4), the pairwise maximum entropy model provided a good
                    fit to the data (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> was typically smaller than 0.1), but it did not do a good job
                    modeling the temporal structure of the spike trains.</p>
            </sec>
            <sec id="s3b">
                <title>Other systems—Protein folding</title>
                <p>As mentioned in the Introduction, in addition to the studies on neuronal data,
                    studies on protein folding have also emphasized the role of pairwise
                    interactions <xref ref-type="bibr" rid="pcbi.1000380-Russ1">[2]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Socolich1">[3]</xref>. Briefly, proteins
                    consist of strings of amino acids, and a major question in structural biology
                    is: what is the probability distribution of amino acid strings in naturally
                    folding proteins? One way to answer this is to approximate the full probability
                    distribution of naturally folding proteins from knowledge of single-site and
                    pairwise distributions. One can show that there is a perturbative regime for
                    proteins as well. This can be readily seen using the celebrated HP protein model
                        <xref ref-type="bibr" rid="pcbi.1000380-Dill1">[20]</xref>, where a protein is composed of only two types of
                    amino acids. If, at each site, one amino acid type is preferred and occurs with
                    high probability, say <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e429" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e430" xlink:type="simple"/></inline-formula>, then a protein of length shorter than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e431" xlink:type="simple"/></inline-formula> will be in the perturbative regime, and, therefore, a good
                    match between the true distribution and the pairwise distribution for such a
                    protein is virtually guaranteed.</p>
                <p>Fortunately, the properties of real proteins generally prevent this from
                    happening: at the majority of sites in a protein, the distribution of amino
                    acids is <italic>not</italic> sharply peaked around one amino acid. Even for
                    those sites that are sharply peaked (the evolutionarily-conserved sites), the
                    probability of the most likely amino acid, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e432" xlink:type="simple"/></inline-formula>, rarely exceeds 90% <xref ref-type="bibr" rid="pcbi.1000380-Lockless1">[21]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-VargasMadrazo1">[22]</xref>. This puts proteins consisting of only a few
                    amino acids out of the perturbative regime, and puts longer
                    proteins—the ones usually studied using pairwise models—well
                    out of it.</p>
                <p>This difference is fundamental: because many of the studies that have been
                    carried out on neural data were in the perturbative regime, the conclusions of
                    those studies—specifically, the conclusion that pairwise models
                    provide accurate descriptions of large populations of neurons—is not
                    yet supported. This is not the case for the protein studies, because they are
                    not in the perturbative regime. Thus, the evidence that pairwise models provide
                    accurate descriptions of protein folding remain strong and exceedingly
                    promising.</p>
            </sec>
            <sec id="s3c">
                <title>Open questions</title>
                <p>In our analysis, we sidestepped two issues of practical importance: finite
                    sampling and alternative measures for assessing the quality of the pairwise
                    model. These issues are beyond the scope of this paper, but in our view, they
                    are natural next steps in the analysis of pairwise models. Below we briefly
                    expand on them.</p>
                <p>Finite sampling refers to the fact that in any real experiment, one has access to
                    only a finite amount of data, and so does not know the true probability
                    distribution of the spike trains. In our analysis, however, we assumed that one
                    did have full knowledge of the true probability distribution. Since a good
                    estimate of the probability distribution is crucial for assessing whether the
                    pairwise model can be extrapolated to large populations, it is important to
                    study how such estimates are affected by finite data. Future work is needed to
                    address this issue, and to find ways to overcome data limitation—for
                    example, by finding efficient methods for removing the finite data bias that
                    affects information theoretic quantities such as the Kullback-Leibler
                    divergence.</p>
                <p>There are always many possible ways to assess the quality of a model. Our choice
                    of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> was motivated by two considerations: it is based on the
                    Kullback-Leibler divergence, which is a standard measure of
                    “distance” between probability distributions, and it is a
                    widely used measure in the field <xref ref-type="bibr" rid="pcbi.1000380-Schneidman1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Bethge1">[10]</xref>. It
                    suffers, however, from a number of shortcomings. In particular, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> can be small even when the pairwise model assigns very
                    different probabilities to many of the configurations of the system. It would,
                    therefore, be important to study the quality of pairwise models using other
                    measures.</p>
            </sec>
        </sec>
        <sec id="s4">
            <title>Methods</title>
            <sec id="s4a">
                <title>The behavior of the true entropy in the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> limit</title>
                <p>To understand how the true entropy behaves in the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> limit, it is useful to express the difference of the entropies
                    as a mutual information. Using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e437" xlink:type="simple"/></inline-formula> to denote the true entropy of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> neurons and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e439" xlink:type="simple"/></inline-formula> to denote the mutual information between one neuron and the
                    other <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> neurons in a population of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e441" xlink:type="simple"/></inline-formula>, we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e442" xlink:type="simple"/><label>(26)</label></disp-formula></p>
                <p>If knowing the activity of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> neurons does not fully constrain the firing of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e444" xlink:type="simple"/></inline-formula>, then the single neuron entropy, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e445" xlink:type="simple"/></inline-formula>, will exceed the mutual information, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e446" xlink:type="simple"/></inline-formula>, and the entropy will be an increasing function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>. For the entropy to be linear in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, all we need is that the mutual information saturates with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>. Because of synaptic noise, this is a reasonable assumption
                    for networks of neurons: even if we observed all the spikes from all the
                    neurons, there would still be residual noise associated with synaptic failures,
                    jitter in release time, variability in the amount of neurotransmitter released,
                    stochastic channel dynamics, etc. Consequently, in the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> limit, we may replace <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e451" xlink:type="simple"/></inline-formula> by its average, denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e452" xlink:type="simple"/></inline-formula>. Also replacing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e453" xlink:type="simple"/></inline-formula> by its average, denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e454" xlink:type="simple"/></inline-formula>, we see that for large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>, the difference between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e456" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e457" xlink:type="simple"/></inline-formula> approaches a constant. Specifically,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e458" xlink:type="simple"/><label>(27)</label></disp-formula>where this expression is valid in the large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula> limit and the corrections are sublinear in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e008" xlink:type="simple"/></inline-formula>.</p>
            </sec>
            <sec id="s4b">
                <title>Perturbative expansion</title>
                <p>Our main quantitative result, given in Eqs. (8–10), is that the KL
                    divergence between the true distribution and both the independent and pairwise
                    distributions can be computed perturbatively as an expansion in powers of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e461" xlink:type="simple"/></inline-formula> in the limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e462" xlink:type="simple"/></inline-formula>. Here we carry out this expansion, and derive explicit
                    expressions for the quantities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula>.</p>
                <p>To simplify our notation, here we use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e309" xlink:type="simple"/></inline-formula> for the true distribution. The critical step in computing the
                    KL divergences perturbatively is to use the Sarmanov-Lancaster expansion <xref ref-type="bibr" rid="pcbi.1000380-Sarmanov1">[23]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Johnson1">[28]</xref> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e309" xlink:type="simple"/></inline-formula>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e467" xlink:type="simple"/><label>(28)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e468" xlink:type="simple"/><label>(29a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e469" xlink:type="simple"/><label>(29b)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e470" xlink:type="simple"/><label>(29c)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e471" xlink:type="simple"/><label>(29d)</label></disp-formula></p>
                <p>This expansion has a number of important, but not immediately obvious,
                    properties. First, as can be shown by a direct calculation,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e472" xlink:type="simple"/><label>(30)</label></disp-formula>where the subscripts <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e473" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e474" xlink:type="simple"/></inline-formula> indicate an average with respect to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e309" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e476" xlink:type="simple"/></inline-formula>, respectively. This has an immediate corollary,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e477" xlink:type="simple"/></disp-formula></p>
                <p>This last relationship is important, because it tells us that if a product of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e478" xlink:type="simple"/></inline-formula> contains any terms linear in one of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e479" xlink:type="simple"/></inline-formula>, the whole product averages to zero under the independent
                    distribution. This can be used to show that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e480" xlink:type="simple"/><label>(31)</label></disp-formula>from which it follows that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e481" xlink:type="simple"/></disp-formula></p>
                <p>Thus, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e309" xlink:type="simple"/></inline-formula> is properly normalized. Finally, a slightly more involved
                    calculations provides us with a relationship between the parameters of the model
                    and the moments: for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e483" xlink:type="simple"/></inline-formula>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e484" xlink:type="simple"/><label>(32a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e485" xlink:type="simple"/><label>(32b)</label></disp-formula></p>
                <p>Virtually identical expressions hold for higher order moments. It is this last
                    set of relationships that make the Sarmanov-Lancaster expansion so useful.</p>
                <p>Note that Eqs. (32a) and (32b), along with the expression for the normalized
                    correlation coefficients given in Eq. (16), imply that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e486" xlink:type="simple"/><label>(33a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e487" xlink:type="simple"/><label>(33b)</label></disp-formula></p>
                <p>These identities will be extremely useful for simplifying expressions later on.</p>
                <p>Because the moments are so closely related to the parameters of the distribution,
                    moment matching is especially convenient: to construct a distribution whose
                    moments match those of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e309" xlink:type="simple"/></inline-formula> up to some order, one simply needs to ensure that the
                    parameters of that distribution, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e489" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e490" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e491" xlink:type="simple"/></inline-formula>, etc., are identical to those of the true distributions up to
                    the order of interest. In particular, let us write down a new distribution, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e492" xlink:type="simple"/></inline-formula>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e493" xlink:type="simple"/><label>(34a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e494" xlink:type="simple"/><label>(34b)</label></disp-formula></p>
                <p>We can recover the independent distribution by letting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e495" xlink:type="simple"/></inline-formula>, and we can recover the pairwise distribution by letting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e496" xlink:type="simple"/></inline-formula>. This allows us to compute <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e497" xlink:type="simple"/></inline-formula> in the general case, and then either set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e498" xlink:type="simple"/></inline-formula> to zero or set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e499" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e500" xlink:type="simple"/></inline-formula>.</p>
                <p>Expressions analogous to those in Eqs. (31–33) exist for averages with
                    respect to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e492" xlink:type="simple"/></inline-formula>; the only difference is that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e502" xlink:type="simple"/></inline-formula> is replaced by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e503" xlink:type="simple"/></inline-formula>.</p>
            </sec>
            <sec id="s4c">
                <title>The KL divergence in the Sarmanov-Lancaster representation</title>
                <p>Using Eqs. (28) and (34a) and a small amount of algebra, the KL divergence
                    between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e309" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e492" xlink:type="simple"/></inline-formula> may be written<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e506" xlink:type="simple"/><label>(35)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e507" xlink:type="simple"/><label>(36)</label></disp-formula></p>
                <p>To derive Eq. (35), we used the fact that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e508" xlink:type="simple"/></inline-formula> (see Eq. (31)). The extra term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e509" xlink:type="simple"/></inline-formula> was included to ensure that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e510" xlink:type="simple"/></inline-formula> and its first derivatives vanish at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e511" xlink:type="simple"/></inline-formula>, something that greatly simplifies our analysis later on.</p>
                <p>Our approach is to Taylor expand the right hand side of Eq. (35) around <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e512" xlink:type="simple"/></inline-formula>, compute each term, and then sum the <italic>whole</italic>
                    series (we do not assume that either <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e513" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e514" xlink:type="simple"/></inline-formula> is small). Using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e515" xlink:type="simple"/></inline-formula> to denote the coefficients of the Taylor series, we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e516" xlink:type="simple"/><label>(37)</label></disp-formula></p>
                <p>Note that because <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e510" xlink:type="simple"/></inline-formula> and its first derivatives vanish at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e518" xlink:type="simple"/></inline-formula>, all terms in this sum have <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e519" xlink:type="simple"/></inline-formula>.</p>
                <p>Because both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e520" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e521" xlink:type="simple"/></inline-formula> are themselves sums, an exact calculation of the terms in Eq.
                    (37) would be difficult. However, as we show below, in the section
                    “Averages of powers of <italic>ξ<sub>p</sub></italic> and
                            <italic>ξ<sub>q</sub></italic>” (see in particular
                    Eqs. (52) and (54)), they can be computed as perturbation expansions in powers
                    of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e461" xlink:type="simple"/></inline-formula>, and the result is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e523" xlink:type="simple"/><label>(38)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e524" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e525" xlink:type="simple"/></inline-formula> are given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e526" xlink:type="simple"/><label>(39)</label></disp-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e527" xlink:type="simple"/></inline-formula>. The last equality in Eq. (39) follows from a small amount of
                    algebra and the definition of the correlation coefficients given in Eq. (16).
                    Equation (38) is valid only when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e528" xlink:type="simple"/></inline-formula>, which is the case of interest to us (since the Taylor
                    expansion of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e510" xlink:type="simple"/></inline-formula> has only terms with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e530" xlink:type="simple"/></inline-formula>).</p>
                <p>The important point about Eq. (38) is that the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e531" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e532" xlink:type="simple"/></inline-formula> dependence follows that of the original Taylor expansion.
                    Thus, when we insert this equation back into Eq. (37), we recover our original
                    function—all we have to do is interchange the sums. For example,
                    consider inserting the first term in Eq. (38) into Eq. (37),<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e533" xlink:type="simple"/></disp-formula></p>
                <p>Performing the same set of manipulations on all of Eq. (38) leads to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e534" xlink:type="simple"/><label>(40)</label></disp-formula></p>
                <p>This expression is true in general (except for some technical considerations; see
                    the section “Averages of powers of
                    <italic>ξ<sub>p</sub></italic> and
                    <italic>ξ<sub>q</sub></italic>”); to restrict it to the KL
                    divergences of interest we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e309" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e536" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e492" xlink:type="simple"/></inline-formula> to either <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e538" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e539" xlink:type="simple"/></inline-formula>. In the first case (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e492" xlink:type="simple"/></inline-formula> set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e541" xlink:type="simple"/></inline-formula>), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e542" xlink:type="simple"/></inline-formula>, which implies that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e543" xlink:type="simple"/></inline-formula>, and thus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e544" xlink:type="simple"/></inline-formula>. Because <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e510" xlink:type="simple"/></inline-formula> has a quadratic minimum at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e546" xlink:type="simple"/></inline-formula>, when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e547" xlink:type="simple"/></inline-formula>, the second two terms on the right hand side of Eq. (40) are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e548" xlink:type="simple"/></inline-formula>. We thus have, to lowest nonvanishing order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e461" xlink:type="simple"/></inline-formula>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e550" xlink:type="simple"/><label>(41)</label></disp-formula>with the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e551" xlink:type="simple"/></inline-formula> correction coming from the last sum in Eq. (40). Defining<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e552" xlink:type="simple"/><label>(42)</label></disp-formula>where, recall <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e553" xlink:type="simple"/></inline-formula>, and inserting Eq. (42) into Eq. (41), we recover Eq. (8a).</p>
                <p>In the second case (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e492" xlink:type="simple"/></inline-formula> set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e555" xlink:type="simple"/></inline-formula>), the first and second moments of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e556" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e557" xlink:type="simple"/></inline-formula> are equal. This implies, using Eq. (32), that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e558" xlink:type="simple"/></inline-formula>, and thus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e559" xlink:type="simple"/></inline-formula>. Because <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e560" xlink:type="simple"/></inline-formula> (see Eq. (36)), the first three terms on the right hand side
                    of Eq. (40)—those involving <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e561" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e265" xlink:type="simple"/></inline-formula> but not <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e266" xlink:type="simple"/></inline-formula>—vanish. The next order term does not vanish, and yields<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e564" xlink:type="simple"/><label>(43)</label></disp-formula></p>
                <p>Defining<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e565" xlink:type="simple"/><label>(44)</label></disp-formula>and inserting this expression into Eq. (43), we recover Eq.
                (8b).</p>
            </sec>
            <sec id="s4d">
                <title>External fields, pairwise couplings and moments</title>
                <p>In this section we derive, to leading order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e461" xlink:type="simple"/></inline-formula>, expressions relating the external fields and pairwise
                    couplings of the maximum entropy model, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e567" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e568" xlink:type="simple"/></inline-formula>, to the first and second moments; these are the expressions
                    reported in Eq. (18). The calculation proceeds along the same lines as in the
                    previous section. There is, though, one extra step associated with the fact that
                    the quadratic term in the maximum entropy distribution given in Eq. (14) is
                    proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e569" xlink:type="simple"/></inline-formula>, not <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e570" xlink:type="simple"/></inline-formula>. However, to lowest order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e461" xlink:type="simple"/></inline-formula>, this doesn't matter. That's because<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e572" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e573" xlink:type="simple"/></inline-formula> is defined as in Eq. (29d) except with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e574" xlink:type="simple"/></inline-formula> replaced by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e575" xlink:type="simple"/></inline-formula>, and we used the fact that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e576" xlink:type="simple"/></inline-formula>. The second term introduces a correction to the external
                    fields, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e577" xlink:type="simple"/></inline-formula>. However, the correction is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e578" xlink:type="simple"/></inline-formula>, so we drop it. We should keep in mind, though, that our final
                    expression for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e579" xlink:type="simple"/></inline-formula> will have corrections of this order.</p>
                <p>Using Eq. (14), but with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e580" xlink:type="simple"/></inline-formula> replaced by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e479" xlink:type="simple"/></inline-formula> where it appears with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e582" xlink:type="simple"/></inline-formula>, we may write (after a small amount of algebra)<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e583" xlink:type="simple"/><label>(45)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e584" xlink:type="simple"/></inline-formula> is the same as the function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e585" xlink:type="simple"/></inline-formula> defined in Eq. (29a) except that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e586" xlink:type="simple"/></inline-formula> is replaced by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e587" xlink:type="simple"/></inline-formula>, the subscript “<italic>ind</italic>”
                    indicates, as usual, an average with respect to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e588" xlink:type="simple"/></inline-formula>, and the two functions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e589" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e590" xlink:type="simple"/></inline-formula> are defined by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e591" xlink:type="simple"/><label>(46)</label></disp-formula>and<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e592" xlink:type="simple"/><label>(47)</label></disp-formula></p>
                <p>Given this setup, we can use Eqs. (55) and (56) below to compute the moments
                    under the maximum entropy model. That's because both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e593" xlink:type="simple"/></inline-formula> and its first derivative vanish at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e594" xlink:type="simple"/></inline-formula>, which are the two conditions required for these equations to
                    be valid. Using also the fact that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e595" xlink:type="simple"/></inline-formula>, Eqs. (55) and (56) imply that<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e596" xlink:type="simple"/><label>(48a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e597" xlink:type="simple"/><label>(48b)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e598" xlink:type="simple"/><label>(48c)</label></disp-formula>where the first term in Eq. (48b) came from Eq. (29d) with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e599" xlink:type="simple"/></inline-formula> replaced by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e600" xlink:type="simple"/></inline-formula>, the term “<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e601" xlink:type="simple"/></inline-formula>” in Eq. (48c) came from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e602" xlink:type="simple"/></inline-formula>, and for the second two expressions we used the fact that, to
                    lowest order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e461" xlink:type="simple"/></inline-formula>, the denominator in Eq. (45) is equal to 1.</p>
                <p>Finally, using Eq. (19) for the normalized correlation coefficient, dropping the
                    subscript “<italic>maxent</italic>” (since the first and
                    second moments are the same under the maxent and true distributions), and
                    inverting Eqs. (48b) and (48c) to express the external fields and coupling
                    coefficients in terms of the first and second moments, we arrive at Eq (18).</p>
            </sec>
            <sec id="s4e">
                <title>Averages of powers of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e604" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e605" xlink:type="simple"/></inline-formula></title>
                <p>Here we compute <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e606" xlink:type="simple"/></inline-formula>, which, as can be seen in Eq. (37), is the key quantity in our
                    perturbation expansion. Our starting point is to (formally) expand the sums that
                    make up <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e607" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e608" xlink:type="simple"/></inline-formula> (see Eqs. (29b) and (34b)), which yields<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e609" xlink:type="simple"/><label>(49)</label></disp-formula></p>
                <p>The sum over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e610" xlink:type="simple"/></inline-formula> is a sum over all possible configurations of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e611" xlink:type="simple"/></inline-formula>. The coefficient <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e612" xlink:type="simple"/></inline-formula> are complicated functions of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e613" xlink:type="simple"/></inline-formula>, etc. Computing these functions is straightforward, although
                    somewhat tedious, especially when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e614" xlink:type="simple"/></inline-formula> is large; below we compute them only for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e615" xlink:type="simple"/></inline-formula> and 3. The reason <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e616" xlink:type="simple"/></inline-formula> starts at 2 is that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e617" xlink:type="simple"/></inline-formula>; see Eq. (37).</p>
                <p>We first show that all terms with superscript <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e618" xlink:type="simple"/></inline-formula> are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e619" xlink:type="simple"/></inline-formula>. To do this, we note that, because the right hand side of Eq.
                    (49) is an average with respect to the independent distribution, the average of
                    the product is the product of the averages,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e620" xlink:type="simple"/><label>(50)</label></disp-formula>Then, using the fact that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e621" xlink:type="simple"/></inline-formula> with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e622" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e623" xlink:type="simple"/></inline-formula> with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e624" xlink:type="simple"/></inline-formula> (see Eq. (29c)), we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e625" xlink:type="simple"/><label>(51)</label></disp-formula></p>
                <p>The significance of this expression is that, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e626" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e627" xlink:type="simple"/></inline-formula>, independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e628" xlink:type="simple"/></inline-formula>. Consequently, if all the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e629" xlink:type="simple"/></inline-formula> in Eq. (50) are greater than 1, then the right hand side is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e630" xlink:type="simple"/></inline-formula>. This shows that, as promised above, the superscript <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e631" xlink:type="simple"/></inline-formula> labels the order of the terms.</p>
                <p>As we saw in the section “The KL divergence in the Sarmanov-Lancaster
                    representation”, we need to go to third order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e320" xlink:type="simple"/></inline-formula>, which means we need to compute the terms on the right hand
                    side of Eq. (49) with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e633" xlink:type="simple"/></inline-formula> and 3. Let us start with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e634" xlink:type="simple"/></inline-formula>, which picks out only those terms with two unique indices.
                    Examining the expressions for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e635" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e636" xlink:type="simple"/></inline-formula> given in Eqs. (29b) and (34b), we see that we must keep only
                    terms involving <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e490" xlink:type="simple"/></inline-formula>, since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e491" xlink:type="simple"/></inline-formula> has three indices, and higher order terms have more. Thus, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e639" xlink:type="simple"/></inline-formula> contribution to the average in Eq. (49), which we denote <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e640" xlink:type="simple"/></inline-formula>, is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e641" xlink:type="simple"/></disp-formula></p>
                <p>Pulling <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e642" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e643" xlink:type="simple"/></inline-formula> out of the averages, using Eq. (33a) to eliminate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e644" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e645" xlink:type="simple"/></inline-formula> in favor of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e646" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e647" xlink:type="simple"/></inline-formula>, and applying Eq. (51) (while throwing away some of the terms
                    in that equation that are higher than second order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e320" xlink:type="simple"/></inline-formula>), the above expression may be written<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e649" xlink:type="simple"/><label>(52)</label></disp-formula></p>
                <p>Note that we were not quite consistent in our ordering with respect to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e320" xlink:type="simple"/></inline-formula>, in the sense that we kept some higher order terms and not
                    others. We did this so that we could use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> rather than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e490" xlink:type="simple"/></inline-formula>, as the former is directly observable.</p>
                <p>For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e653" xlink:type="simple"/></inline-formula> the calculation is more involved, but not substantially so.
                    Including terms with exactly three unique indices in the sum on the right hand
                    side of Eq. (49) gives us<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e654" xlink:type="simple"/><label>(53)</label></disp-formula></p>
                <p>This expression is not quite correct, since some of the terms contain only two
                    unique indices—these are the terms proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e655" xlink:type="simple"/></inline-formula>—whereas it should contain only terms with exactly
                    three unique indices. Fortunately, this turns out not to matter, for reasons we
                    discuss at the end of the section.</p>
                <p>To perform the averages in Eq. (53), we would need to use multinomial expansions,
                    and then average over the resulting powers of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e656" xlink:type="simple"/></inline-formula>. For the latter, we can work to lowest order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e479" xlink:type="simple"/></inline-formula>, which means we only take the first term in Eq. (51). This
                    amounts to replacing every <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e479" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e659" xlink:type="simple"/></inline-formula> (and similarly for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e265" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e266" xlink:type="simple"/></inline-formula>), and in addition multiplying the whole expression by an
                    overall factor of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e662" xlink:type="simple"/></inline-formula>. For example, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e663" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e664" xlink:type="simple"/></inline-formula>, one of the terms in the multinomial expansion is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e665" xlink:type="simple"/></inline-formula>. This average would yield, using Eq. (51) and considering only
                    the lowest order term, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e666" xlink:type="simple"/></inline-formula>.</p>
                <p>This procedure also is not quite correct, since terms with only one factor of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e479" xlink:type="simple"/></inline-formula>, which average to zero, are replaced with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e668" xlink:type="simple"/></inline-formula>. This also turns out not to matter; again, we discuss why at
                    the end of the section.</p>
                <p>We can, then, go ahead and use the above “replace blindly”
                    algorithm. Note that the factors of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e669" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e670" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e671" xlink:type="simple"/></inline-formula> turn <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e490" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e491" xlink:type="simple"/></inline-formula> into normalized correlation coefficients (see Eq. (33)), which
                    considerably simplifies our equations. Using also Eq. (39) for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e674" xlink:type="simple"/></inline-formula>, Eq. (53) becomes<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e675" xlink:type="simple"/><label>(54)</label></disp-formula></p>
                <p>We can now combine Eqs. (52) and (54), and insert them into Eq. (49). This gives
                    us the first two terms in the perturbative expansion of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e676" xlink:type="simple"/></inline-formula>; the result is written down in Eq. (38) above.</p>
                <p>Why can we ignore the overcounting associated with terms in which an index
                    appears exactly zero or one times? We clearly can't do this in general,
                    because for such terms, replacing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e479" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e678" xlink:type="simple"/></inline-formula> fails—either because the terms didn't exist
                    in the first place (when one of the indices never appeared) or because they
                    averaged to zero (when an index appeared exactly once). In our case, however,
                    such terms do not appear in the Taylor expansion. To see why, note first of all
                    that, because of the form of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e510" xlink:type="simple"/></inline-formula>, its Taylor expansion can be written <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e680" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e681" xlink:type="simple"/></inline-formula> is finite at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e682" xlink:type="simple"/></inline-formula> (see Eq. (36)). Consequently, the original Taylor expansion of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e683" xlink:type="simple"/></inline-formula>, Eq. (37), should contain a factor of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e684" xlink:type="simple"/></inline-formula>; i.e.,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e685" xlink:type="simple"/></disp-formula>where the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e686" xlink:type="simple"/></inline-formula> are the coefficients of the Taylor expansion of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e687" xlink:type="simple"/></inline-formula>. The factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e688" xlink:type="simple"/></inline-formula>, when expanded, has the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e689" xlink:type="simple"/></disp-formula></p>
                <p>As we saw in the previous section, we are interested in the third order term only
                    to compute <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e690" xlink:type="simple"/></inline-formula>, for which <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e691" xlink:type="simple"/></inline-formula>. Therefore, the above multiplicative factor reduces to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e692" xlink:type="simple"/></inline-formula>. It is that last factor of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e693" xlink:type="simple"/></inline-formula> that is important, since it guarantees that for every term in
                    the Taylor expansion, all indices appear at least twice. Therefore, although Eq.
                    (53) is not true in general, it is valid for our analysis.</p>
                <p>We end this section by pointing out that there is a very simple procedure for
                    computing averages to second order in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e320" xlink:type="simple"/></inline-formula>. Consider a function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e695" xlink:type="simple"/></inline-formula> that has a minimum at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e696" xlink:type="simple"/></inline-formula> and also obeys <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e697" xlink:type="simple"/></inline-formula>. Then, based on the above analysis, we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e698" xlink:type="simple"/><label>(55)</label></disp-formula></p>
                <p>Two easy corollaries of this are: for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e266" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e700" xlink:type="simple"/></inline-formula> positive integers,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e701" xlink:type="simple"/><label>(56a)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e702" xlink:type="simple"/><label>(56b)</label></disp-formula>where the sum in Eq. (56a) runs over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e265" xlink:type="simple"/></inline-formula> only, and we used the fact that both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e704" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e705" xlink:type="simple"/></inline-formula> are symmetric with respect to the interchange of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e706" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e265" xlink:type="simple"/></inline-formula>.</p>
            </sec>
            <sec id="s4f">
                <title>Generating synthetic data</title>
                <p>As can be seen in Eq. (13), the synthetic data depends on three sets of
                    parameters: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e708" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e269" xlink:type="simple"/></inline-formula>. Here we describe how they were generated.</p>
                <p>To generate the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e710" xlink:type="simple"/></inline-formula>, we draw a set of firing rates, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e711" xlink:type="simple"/></inline-formula>, from an exponential distribution with mean 0.02 (recall that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e712" xlink:type="simple"/></inline-formula>, which we set to 15, is the number of neurons in our base
                    distribution). From this we chose the external field according to Eq. (18a),<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e713" xlink:type="simple"/></disp-formula></p>
                <p>In the perturbative regime, a distribution generated with these values of the
                    external fields has firing rates approximately equal to the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e714" xlink:type="simple"/></inline-formula>; see Eq. (18a) and <xref ref-type="fig" rid="pcbi-1000380-g006">Fig. 6</xref>.</p>
                <p>To generate the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e715" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e269" xlink:type="simple"/></inline-formula>, we drew them from Gaussian distributions with means equal to
                    0.05 and 0.02 and standard deviations of 0.8 and 0.5, respectively. Using
                    non-zero values for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e491" xlink:type="simple"/></inline-formula> means that the true distribution is not pairwise.</p>
            </sec>
            <sec id="s4g">
                <title>Bin size and the correlation coefficients</title>
                <p>One of our main claims is that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> is linear in bin size, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>. This is true, however, only if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> are independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>, as can be seen from Eq. (10b). In this section we show that
                    independence is satisfied if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e723" xlink:type="simple"/></inline-formula> is smaller than the typical correlation time of the responses.
                    For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> larger than such correlation times, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> do depend on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> is no longer linear in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>. Note, though, that the correlation time is always finite, so
                    there will always be a bin size below which the linear relationship, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e730" xlink:type="simple"/></inline-formula>, is guaranteed.</p>
                <p>Examining Eqs. (42) and (44), we see that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> depend on the normalized correlation coefficients, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e674" xlink:type="simple"/></inline-formula> (we drop superscripts, since our discussion will be generic).
                    Thus, to understand how <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> depend on bin size, we need to understand how the normalized
                    correlation coefficients depend on bin size. To do that, we express them in
                    terms of standard cross-correlograms, as the cross-correlograms contain, in a
                    very natural way, information about the temporal timescales in the spike train.</p>
                <p>We start with the second order correlation coefficient, since it is simplest. The
                    corresponding cross-correlogram, which we denote <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e737" xlink:type="simple"/></inline-formula>, is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e738" xlink:type="simple"/><label>(57)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e739" xlink:type="simple"/></inline-formula> is the time of the <italic>k</italic><sup>th</sup> spike on
                    neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e740" xlink:type="simple"/></inline-formula> (and similarly for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e741" xlink:type="simple"/></inline-formula>), and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e742" xlink:type="simple"/></inline-formula> is the Dirac <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e743" xlink:type="simple"/></inline-formula>. The normalization in Eq. (57) is slightly
                    non-standard—more typical is to divide by something with units of
                    firing rate (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e744" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e745" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e746" xlink:type="simple"/></inline-formula>), to give units of spikes/s. The normalization we use is
                    convenient, however, because in the limit of large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e747" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e737" xlink:type="simple"/></inline-formula> approaches one.</p>
                <p>It is slightly tedious, but otherwise straightforward, to show that when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> is sufficiently small that only one spike can occur in a time
                    bin, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> is related to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e737" xlink:type="simple"/></inline-formula> via<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e752" xlink:type="simple"/><label>(58)</label></disp-formula></p>
                <p>The (unimportant) factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e753" xlink:type="simple"/></inline-formula> comes from the fact that the spikes occur at random locations
                    within a bin.</p>
                <p>Equation (58) has a simple interpretation: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> is the average height of the central peak of the
                    cross-correlogram relative to baseline. How strongly <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> depends on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> is thus determined by the shape of the cross-correlogram. If
                    it is smooth, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e324" xlink:type="simple"/></inline-formula> approaches a constant as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> becomes small. If, on the other hand, there is a sharp peak at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e759" xlink:type="simple"/></inline-formula>, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e760" xlink:type="simple"/></inline-formula> for small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>, so long as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> is larger than the width of the peak. (The factor of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e099" xlink:type="simple"/></inline-formula> included in the scaling is approximate; it is a placeholder
                    for an effective firing rate that depends on the indices <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e764" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e265" xlink:type="simple"/></inline-formula>. It is, however, sufficiently accurate for our purposes.) A
                    similar relationship exists between the third order correlogram and the
                    correlation coefficient. Thus, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e674" xlink:type="simple"/></inline-formula> is also independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> in the small <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula> limit, whereas if the central peak is sharp it scales as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e769" xlink:type="simple"/></inline-formula>.</p>
                <p>The upshot of this analysis is that the shape of the cross-correlogram has a
                    profound effect on the correlation coefficients and, therefore, on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>. What is the shape in real networks? The answer typically
                    depends on the physical distance between cells. If two neurons are close, they
                    are likely to receive common input and thus exhibit a narrow central peak in
                    their cross-correlogram. Just how narrow depends on the area. Early in the
                    sensory pathways, such as retina <xref ref-type="bibr" rid="pcbi.1000380-Mastronarde1">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1000380-Nirenberg1">[31]</xref> and LGN <xref ref-type="bibr" rid="pcbi.1000380-Dan1">[32]</xref>, peaks
                    can be very narrow—on the order of milliseconds. Deeper into cortex,
                    however, peaks tend to broaden, to at least tens of milliseconds <xref ref-type="bibr" rid="pcbi.1000380-Tso1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000380-Nelson1">[34]</xref>.
                    If, on the other hand, the neurons are far apart, they are less likely to
                    receive common input. In this case, the correlations come from external stimuli,
                    so the central peak tends to have a characteristic width given by the temporal
                    correlation time of the stimulus, typically 100 s of milliseconds.</p>
                <p>Although clearly both kinds of cross-correlograms exist in any single population
                    of neurons, it is convenient to analyze them separately. We have already
                    considered networks in which the cross-correlograms were broad and perfectly
                    flat, so that the correlation coefficients were strictly independent of bin
                    size. We can also consider the opposite extreme: networks in which the the
                    cross-correlograms (both second and higher order) among nearby neurons exhibit
                    sharp peaks while those among distant neurons are uniformly equal to 1. In this
                    regime, the correlation coefficients depend on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e098" xlink:type="simple"/></inline-formula>: as discussed above, the second order ones scale as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e772" xlink:type="simple"/></inline-formula> and the third as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e773" xlink:type="simple"/></inline-formula>. This means that the arguments of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e774" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e775" xlink:type="simple"/></inline-formula> are large (see Eqs. (42) and (44)). From the definition of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e510" xlink:type="simple"/></inline-formula> in Eq. (36), in this regime both are approximately linear in
                    their arguments (ignoring log corrections). Consequently, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e777" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e778" xlink:type="simple"/></inline-formula>. This implies that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e114" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e116" xlink:type="simple"/></inline-formula> scale as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e461" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e782" xlink:type="simple"/></inline-formula>, respectively, and so <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e783" xlink:type="simple"/></inline-formula>, independent of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e320" xlink:type="simple"/></inline-formula>. Thus, if the bin size is large compared to the correlation
                    time, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula> will be approximately independent of bin size.</p>
            </sec>
            <sec id="s4h">
                <title>Extending the normalized distance measure to the time domain</title>
                <p>In this section we derive the expression for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e402" xlink:type="simple"/></inline-formula> given in Eq. (25). Our starting point is its definition, Eq.
                    (24). It is convenient to define <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e787" xlink:type="simple"/></inline-formula> to be a concatenation of the responses in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e394" xlink:type="simple"/></inline-formula> time bins,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e789" xlink:type="simple"/><label>(59)</label></disp-formula>where, as in the section “Is there anything wrong with
                    using small time bins?”, the superscript labels time, so <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e790" xlink:type="simple"/></inline-formula> is the full, temporally correlated, distribution.</p>
                <p>With this definition, we may write the numerator in Eq. (24) as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e791" xlink:type="simple"/><label>(60)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e792" xlink:type="simple"/></inline-formula> is the entropy of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e790" xlink:type="simple"/></inline-formula>, the last sum follows from a marginalization over all but one
                    element of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e790" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e795" xlink:type="simple"/></inline-formula> is the true distribution at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e796" xlink:type="simple"/></inline-formula> (unlike in the section “Is there anything wrong with
                    using small time bins?”, here we do not assume that the true
                    distribution is the same in all time bins). Note that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e797" xlink:type="simple"/></inline-formula> is independent of time, since it is computed from a time
                    average of the true distribution. That time average, which we call <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e798" xlink:type="simple"/></inline-formula>, is given in terms of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e799" xlink:type="simple"/></inline-formula> as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e800" xlink:type="simple"/></disp-formula></p>
                <p>Inserting this definition into Eq. (60) eliminates the sum over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e801" xlink:type="simple"/></inline-formula>, and replaces it with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e802" xlink:type="simple"/></inline-formula>. For simplicity we consider the maximum entropy pairwise
                    model. In this case, because <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e803" xlink:type="simple"/></inline-formula> is in the exponential family, and the first and second moments
                    are the same under the true and maximum entropy distributions, we can replace <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e804" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e805" xlink:type="simple"/></inline-formula>. Consequently, Eq. (60) becomes<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e806" xlink:type="simple"/></disp-formula></p>
                <p>This gives us the numerator in the expression for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e402" xlink:type="simple"/></inline-formula> (Eq. (24)); using Eq. (4) to write <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e808" xlink:type="simple"/></inline-formula>, the full expression for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e402" xlink:type="simple"/></inline-formula> becomes<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e810" xlink:type="simple"/><label>(61)</label></disp-formula>where we added and subtracted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e811" xlink:type="simple"/></inline-formula> to the numerator.</p>
                <p>The first term on the right hand side of Eq. (61) we recognize, from Eq. (6), as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e013" xlink:type="simple"/></inline-formula>. To cast the second into a reasonable form, we define <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e813" xlink:type="simple"/></inline-formula> to be the entropy of the distribution that retains the
                    temporal correlations within each neuron but is independent across neurons.
                    Then, adding and subtracting this quantity to the numerator in Eq. (61), and
                    also adding and subtracting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e814" xlink:type="simple"/></inline-formula>, we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e815" xlink:type="simple"/><label>(62)</label></disp-formula></p>
                <p>The key observation is that if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e816" xlink:type="simple"/></inline-formula>, then<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e817" xlink:type="simple"/></disp-formula></p>
                <p>Comparing this with Eqs. (8a) and (9a), we see that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e818" xlink:type="simple"/></inline-formula> is a factor of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e819" xlink:type="simple"/></inline-formula> times larger than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e820" xlink:type="simple"/></inline-formula>. We thus have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e821" xlink:type="simple"/><label>(63)</label></disp-formula></p>
                <p>Again assuming <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e822" xlink:type="simple"/></inline-formula>, and defining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e823" xlink:type="simple"/></inline-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e824" xlink:type="simple"/></inline-formula>, the last term in this expression may be written<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e825" xlink:type="simple"/><label>(64)</label></disp-formula></p>
                <p>Inserting this into Eq. (63) and using Eqs. (4), (8a) and (9a) yields Eq. (25).</p>
                <p>We have assumed here that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e826" xlink:type="simple"/></inline-formula>; what happens when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e827" xlink:type="simple"/></inline-formula>, or larger? To answer this, we rewrite Eq. (61) as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e828" xlink:type="simple"/><label>(65)</label></disp-formula></p>
                <p>We argue that in general, as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e394" xlink:type="simple"/></inline-formula> increases, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e830" xlink:type="simple"/></inline-formula> becomes increasingly different from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e831" xlink:type="simple"/></inline-formula>, since the former was derived under the assumption that the
                    responses at different time bins were independent. Thus, Eq. (25) should be
                    considered a lower bound on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000380.e402" xlink:type="simple"/></inline-formula>.</p>
            </sec>
        </sec>
    </body>
    <back>
        <ref-list>
            <title>References</title>
            <ref id="pcbi.1000380-Rieke1">
                <label>1</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Rieke</surname>
                            <given-names>F</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Warland</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>de Ruyter van Steveninck</surname>
                            <given-names>R</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Bialek</surname>
                            <given-names>W</given-names>
                        </name>
                    </person-group>
                    <year>1997</year>
                    <source>Spikes: exploring the neural code</source>
                    <publisher-loc>Cambridge, MA</publisher-loc>
                    <publisher-name>MIT Press</publisher-name>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Russ1">
                <label>2</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Russ</surname>
                            <given-names>W</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Lowery</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Mishra</surname>
                            <given-names>P</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Yaffe</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Ranganathan</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>2005</year>
                    <article-title>Natural-like function in artificial WW domains.</article-title>
                    <source>Nature</source>
                    <volume>437</volume>
                    <fpage>579</fpage>
                    <lpage>583</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Socolich1">
                <label>3</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Socolich</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Lockless</surname>
                            <given-names>S</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Russ</surname>
                            <given-names>W</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Lee</surname>
                            <given-names>H</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Gardner</surname>
                            <given-names>K</given-names>
                        </name>
                        <etal/>
                    </person-group>
                    <year>2005</year>
                    <article-title>Evolutionary information for specifying a protein fold.</article-title>
                    <source>Nature</source>
                    <volume>437</volume>
                    <fpage>512</fpage>
                    <lpage>518</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Oates1">
                <label>4</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Oates</surname>
                            <given-names>J</given-names>
                        </name>
                    </person-group>
                    <year>1987</year>
                    <article-title>Food distribution and foraging behavior.</article-title>
                    <person-group person-group-type="editor">
                        <name name-style="western">
                            <surname>Smuts</surname>
                            <given-names>B</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Cheney</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Seyfarth</surname>
                            <given-names>R</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Wrangham</surname>
                            <given-names>R</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Struhsaker</surname>
                            <given-names>T</given-names>
                        </name>
                    </person-group>
                    <source>Primate societies</source>
                    <publisher-loc>Chicago</publisher-loc>
                    <publisher-name>University of Chicago Press</publisher-name>
                    <fpage>197</fpage>
                    <lpage>209</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Wrangham1">
                <label>5</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Wrangham</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>1987</year>
                    <article-title>Evolution of social structure.</article-title>
                    <person-group person-group-type="editor">
                        <name name-style="western">
                            <surname>Smuts</surname>
                            <given-names>B</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Cheney</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Seyfarth</surname>
                            <given-names>R</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Wrangham</surname>
                            <given-names>R</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Struhsaker</surname>
                            <given-names>T</given-names>
                        </name>
                    </person-group>
                    <source>Primate societies</source>
                    <publisher-loc>Chicago</publisher-loc>
                    <publisher-name>University of Chicago Press</publisher-name>
                    <fpage>282</fpage>
                    <lpage>298</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Eisenberg1">
                <label>6</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Eisenberg</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Muckenhirn</surname>
                            <given-names>N</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Rundran</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>1972</year>
                    <article-title>The relation between ecology a social structure in primates.</article-title>
                    <source>Science</source>
                    <volume>176</volume>
                    <fpage>863</fpage>
                    <lpage>874</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Schneidman1">
                <label>7</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Schneidman</surname>
                            <given-names>E</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Berry</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Segev</surname>
                            <given-names>R</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Bialek</surname>
                            <given-names>W</given-names>
                        </name>
                    </person-group>
                    <year>2006</year>
                    <article-title>Weak pairwise correlations imply strongly correlated network
                        states in a neural population.</article-title>
                    <source>Nature</source>
                    <volume>440</volume>
                    <fpage>1007</fpage>
                    <lpage>1012</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Shlens1">
                <label>8</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Shlens</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Field</surname>
                            <given-names>G</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Gauthier</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Grivich</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Petrusca</surname>
                            <given-names>D</given-names>
                        </name>
                        <etal/>
                    </person-group>
                    <year>2006</year>
                    <article-title>The structure of multi-neuron firing patterns in primate retina.</article-title>
                    <source>J Neurosci</source>
                    <volume>26</volume>
                    <fpage>8254</fpage>
                    <lpage>8266</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Tang1">
                <label>9</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Tang</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Jackson</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Hobbs</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Chen</surname>
                            <given-names>W</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Smith</surname>
                            <given-names>J</given-names>
                        </name>
                        <etal/>
                    </person-group>
                    <year>2008</year>
                    <article-title>A maximum entropy model applied to spatial and temporal
                        correlations from cortical networks in vitro.</article-title>
                    <source>J Neurosci</source>
                    <volume>28</volume>
                    <fpage>505</fpage>
                    <lpage>518</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Bethge1">
                <label>10</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Bethge</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Berens</surname>
                            <given-names>P</given-names>
                        </name>
                    </person-group>
                    <year>2008</year>
                    <article-title>Near-maximum entropy models for binary neural representations of
                        natural images.</article-title>
                    <person-group person-group-type="editor">
                        <name name-style="western">
                            <surname>Platt</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Koller</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Singer</surname>
                            <given-names>Y</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Roweis</surname>
                            <given-names>S</given-names>
                        </name>
                    </person-group>
                    <source>Advances in Neural Information Processing Systems 20</source>
                    <publisher-loc>Cambridge, MA</publisher-loc>
                    <publisher-name>MIT Press</publisher-name>
                    <fpage>97</fpage>
                    <lpage>104</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Yu1">
                <label>11</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Yu</surname>
                            <given-names>S</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Huang</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Singer</surname>
                            <given-names>W</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Nikolic</surname>
                            <given-names>D</given-names>
                        </name>
                    </person-group>
                    <year>2008</year>
                    <article-title>A small world of neuronal synchrony.</article-title>
                    <source>Cereb Cortex</source>
                    <volume>18</volume>
                    <fpage>2891</fpage>
                    <lpage>2901</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Kullback1">
                <label>12</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Kullback</surname>
                            <given-names>S</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Leibler</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>1951</year>
                    <article-title>On information and sufficiency.</article-title>
                    <source>Ann Math Stat</source>
                    <volume>22</volume>
                    <fpage>79</fpage>
                    <lpage>86</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Friedman1">
                <label>13</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Friedman</surname>
                            <given-names>N</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Mosenzon</surname>
                            <given-names>O</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Slonim</surname>
                            <given-names>N</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Tishby</surname>
                            <given-names>N</given-names>
                        </name>
                    </person-group>
                    <year>2001</year>
                    <article-title>Multivariate information bottleneck.</article-title>
                    <source>Proc. of Uncertainty in Artificial Intelligence (UAI-17)</source>
                    <publisher-loc>San Mateo, CA</publisher-loc>
                    <publisher-name>Morgan Kaufmann Publishers</publisher-name>
                    <fpage>152</fpage>
                    <lpage>161</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Slonim1">
                <label>14</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Slonim</surname>
                            <given-names>N</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Friedman</surname>
                            <given-names>N</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Tishby</surname>
                            <given-names>N</given-names>
                        </name>
                    </person-group>
                    <year>2006</year>
                    <article-title>Multivariate information bottleneck.</article-title>
                    <source>Neural Comput</source>
                    <volume>18</volume>
                    <fpage>1739</fpage>
                    <lpage>1789</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Shannon1">
                <label>15</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Shannon</surname>
                            <given-names>C</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Weaver</surname>
                            <given-names>W</given-names>
                        </name>
                    </person-group>
                    <year>1949</year>
                    <source>The mathematical theory of communication</source>
                    <publisher-loc>Urbana, Illinois</publisher-loc>
                    <publisher-name>University of Illinois Press</publisher-name>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Cover1">
                <label>16</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Cover</surname>
                            <given-names>T</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Thomas</surname>
                            <given-names>J</given-names>
                        </name>
                    </person-group>
                    <year>1991</year>
                    <source>Elements of information theory</source>
                    <publisher-loc>New York, NY</publisher-loc>
                    <publisher-name>John Wiley &amp; Sons</publisher-name>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Sessak1">
                <label>17</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Sessak</surname>
                            <given-names>V</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Monasson</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>2009</year>
                    <article-title>Small-correlation expansions for the inverse ising problem.</article-title>
                    <source>J Phys A</source>
                    <volume>42</volume>
                    <fpage>055001</fpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Amari1">
                <label>18</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Amari</surname>
                            <given-names>S</given-names>
                        </name>
                    </person-group>
                    <year>2009</year>
                    <article-title>Measure of correlation orthogonal to changing in firing rate.</article-title>
                    <source>Neural Comput</source>
                    <volume>21</volume>
                    <fpage>960</fpage>
                    <lpage>972</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Shlens2">
                <label>19</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Shlens</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Field</surname>
                            <given-names>G</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Gauthier</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Greschner</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Sher</surname>
                            <given-names>A</given-names>
                        </name>
                        <etal/>
                    </person-group>
                    <year>2009</year>
                    <article-title>Spatial organization of large-scale concerted activity in the
                        primate retina.</article-title>
                    <source>J Neurosci. In Press</source>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Dill1">
                <label>20</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Dill</surname>
                            <given-names>K</given-names>
                        </name>
                    </person-group>
                    <year>1985</year>
                    <article-title>Theory for the folding and stability of globular proteins.</article-title>
                    <source>Biochemistry</source>
                    <volume>24</volume>
                    <fpage>1501</fpage>
                    <lpage>1509</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Lockless1">
                <label>21</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Lockless</surname>
                            <given-names>S</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Ranganathan</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>1999</year>
                    <article-title>Evolutionarily conserved pathways of energetic connectivity in
                        protein families.</article-title>
                    <source>Science</source>
                    <volume>286</volume>
                    <fpage>295</fpage>
                    <lpage>299</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-VargasMadrazo1">
                <label>22</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Vargas-Madrazo</surname>
                            <given-names>E</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Lara-Ochoa</surname>
                            <given-names>F</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Jiménez-Montaño</surname>
                            <given-names>M</given-names>
                        </name>
                    </person-group>
                    <year>1994</year>
                    <article-title>A skewed distribution of amino acids at recognition sites of the
                        hypervariable region of immunoglobulins.</article-title>
                    <source>J Mol Evol</source>
                    <volume>38</volume>
                    <fpage>100</fpage>
                    <lpage>104</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Sarmanov1">
                <label>23</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Sarmanov</surname>
                            <given-names>O</given-names>
                        </name>
                    </person-group>
                    <year>1962</year>
                    <article-title>Maximum correlation coeffcient (nonsymmetric case).</article-title>
                    <source>Selected Translations in Mathematical Statistics and Probability. Amer.
                        Math. Soc. Volume 2</source>
                    <fpage>207</fpage>
                    <lpage>210</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Sarmanov2">
                <label>24</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Sarmanov</surname>
                            <given-names>O</given-names>
                        </name>
                    </person-group>
                    <year>1963</year>
                    <article-title>Maximum correlation coefficient (nonsymmetric case).</article-title>
                    <source>Selected Translations in Mathematical Statistics and Probability. Amer.
                        Math. Soc. Volume 4</source>
                    <fpage>271</fpage>
                    <lpage>275</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Lancaster1">
                <label>25</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Lancaster</surname>
                            <given-names>H</given-names>
                        </name>
                    </person-group>
                    <year>1958</year>
                    <article-title>The structure of bivariate distributions.</article-title>
                    <source>Ann Math Stat</source>
                    <volume>29</volume>
                    <fpage>719</fpage>
                    <lpage>736</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Lancaster2">
                <label>26</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Lancaster</surname>
                            <given-names>H</given-names>
                        </name>
                    </person-group>
                    <year>1963</year>
                    <article-title>Correlation and complete dependence of random variables.</article-title>
                    <source>Ann Math Stat</source>
                    <volume>34</volume>
                    <fpage>1315</fpage>
                    <lpage>1321</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Bahadur1">
                <label>27</label>
                <element-citation publication-type="other" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Bahadur</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>1961</year>
                    <article-title>A representation of the joint distribution of responses to n
                        dichotomous items.</article-title>
                    <person-group person-group-type="editor">
                        <name name-style="western">
                            <surname>Solomon</surname>
                            <given-names>H</given-names>
                        </name>
                    </person-group>
                    <source>Studies in Item Analysis and Prediction</source>
                    <publisher-name>Stanford University Press</publisher-name>
                    <fpage>158</fpage>
                    <lpage>168</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Johnson1">
                <label>28</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Johnson</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Goodman</surname>
                            <given-names>I</given-names>
                        </name>
                    </person-group>
                    <year>2008</year>
                    <article-title>Inferring the capacity of the vector Poisson channel with a
                        Bernoulli model.</article-title>
                    <source>Network</source>
                    <volume>19</volume>
                    <fpage>13</fpage>
                    <lpage>33</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Mastronarde1">
                <label>29</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Mastronarde</surname>
                            <given-names>D</given-names>
                        </name>
                    </person-group>
                    <year>1983</year>
                    <article-title>Correlated firing of cat retinal ganglion cells. I. spontaneously
                        active inputs to X- and Y-cells.</article-title>
                    <source>J Neurophysiol</source>
                    <volume>49</volume>
                    <fpage>303</fpage>
                    <lpage>324</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-DeVries1">
                <label>30</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>DeVries</surname>
                            <given-names>S</given-names>
                        </name>
                    </person-group>
                    <year>1999</year>
                    <article-title>Correlated firing in rabbit retinal ganglion cell.</article-title>
                    <source>J Neurophysiol</source>
                    <volume>81</volume>
                    <fpage>908</fpage>
                    <lpage>920</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Nirenberg1">
                <label>31</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Nirenberg</surname>
                            <given-names>S</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Carcieri</surname>
                            <given-names>S</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Jacobs</surname>
                            <given-names>A</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Latham</surname>
                            <given-names>P</given-names>
                        </name>
                    </person-group>
                    <year>2001</year>
                    <article-title>Retinal ganglion cells act largely as independent encoders.</article-title>
                    <source>Nature</source>
                    <volume>411</volume>
                    <fpage>698</fpage>
                    <lpage>701</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Dan1">
                <label>32</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Dan</surname>
                            <given-names>Y</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Alonso</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Usrey</surname>
                            <given-names>W</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Reid</surname>
                            <given-names>R</given-names>
                        </name>
                    </person-group>
                    <year>1998</year>
                    <article-title>Coding of visual information by precisely correlated spikes in
                        the lateral geniculate nucleus.</article-title>
                    <source>Nat Neurosci</source>
                    <volume>1</volume>
                    <fpage>501</fpage>
                    <lpage>507</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Tso1">
                <label>33</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Ts'o</surname>
                            <given-names>D</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Gilbert</surname>
                            <given-names>C</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Wiesel</surname>
                            <given-names>T</given-names>
                        </name>
                    </person-group>
                    <year>1986</year>
                    <article-title>Relationships between horizontal interactions and functional
                        architecture in cat striate cortex as revealed by cross-correlation
                        analysis.</article-title>
                    <source>J Neurosci</source>
                    <volume>6</volume>
                    <fpage>1160</fpage>
                    <lpage>1170</lpage>
                </element-citation>
            </ref>
            <ref id="pcbi.1000380-Nelson1">
                <label>34</label>
                <element-citation publication-type="journal" xlink:type="simple">
                    <person-group person-group-type="author">
                        <name name-style="western">
                            <surname>Nelson</surname>
                            <given-names>J</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Salin</surname>
                            <given-names>P</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Munk</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Arzi</surname>
                            <given-names>M</given-names>
                        </name>
                        <name name-style="western">
                            <surname>Bullier</surname>
                            <given-names>J</given-names>
                        </name>
                    </person-group>
                    <year>1992</year>
                    <article-title>Spatial and temporal coherence in cortico-cortical connections: a
                        cross-correlation study in areas 17 and 18 in the cat.</article-title>
                    <source>Vis Neurosci</source>
                    <volume>9</volume>
                    <fpage>21</fpage>
                    <lpage>37</lpage>
                </element-citation>
            </ref>
        </ref-list>
        
    </back>
</article>
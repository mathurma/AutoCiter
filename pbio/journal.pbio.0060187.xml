<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pbio</journal-id><journal-id journal-id-type="allenpress-id">plbi</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="doi">10.1371/journal.pbio.0060187</article-id><article-id pub-id-type="publisher-id">08-PLBI-RA-0602R3</article-id><article-id pub-id-type="sici">plbi-06-07-24</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Multivariate Patterns in Object-Selective Cortex Dissociate Perceptual and Physical Shape Similarity</article-title><alt-title alt-title-type="running-head">Shape Similarities in LOC</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Haushofer</surname>
            <given-names>Johannes</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Livingstone</surname>
            <given-names>Margaret S</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Kanwisher</surname>
            <given-names>Nancy</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1">
				<label>1</label><addr-line> Department of Neurobiology, Harvard Medical School, Boston, Massachusetts, United States of America
			</addr-line></aff><aff id="aff2">
				<label>2</label><addr-line> Department of Brain and Cognitive Sciences, and McGovern Institute for Brain Research, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America
			</addr-line></aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Ungerleider</surname>
            <given-names>Leslie</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">National Institute of Mental Health, National Institutes of Health, United States of America</aff><author-notes>
        <corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">haushofer@post.harvard.edu</email></corresp>
        <fn fn-type="con" id="ack1">
          <p> JH conceived and designed the experiments, performed the experiments, analyzed the data, and wrote the paper. MSL and NK provided help with design, data analysis, and writing.</p>
        </fn>
      <fn fn-type="conflict" id="ack3">
        <p> The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="ppub">
        <month>7</month>
        <year>2008</year>
      </pub-date><pub-date pub-type="epub">
        <day>29</day>
        <month>7</month>
        <year>2008</year>
      </pub-date><volume>6</volume><issue>7</issue><elocation-id>e187</elocation-id><history>
        <date date-type="received">
          <day>14</day>
          <month>2</month>
          <year>2008</year>
        </date>
        <date date-type="accepted">
          <day>19</day>
          <month>6</month>
          <year>2008</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2008</copyright-year><copyright-holder> Haushofer et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Prior research has identified the lateral occipital complex (LOC) as a critical cortical region for the representation of object shape in humans. However, little is known about the nature of the representations contained in the LOC and their relationship to the perceptual experience of shape. We used human functional MRI to measure the physical, behavioral, and neural similarity between pairs of novel shapes to ask whether the representations of shape contained in subregions of the LOC more closely reflect the physical stimuli themselves, or the perceptual experience of those stimuli. Perceptual similarity measures for each pair of shapes were obtained from a psychophysical same-different task; physical similarity measures were based on stimulus parameters; and neural similarity measures were obtained from multivoxel pattern analysis methods applied to anterior LOC (pFs) and posterior LOC (LO). We found that the pattern of pairwise shape similarities in LO most closely matched physical shape similarities, whereas shape similarities in pFs most closely matched perceptual shape similarities. Further, shape representations were similar across participants in LO but highly variable across participants in pFs. Together, these findings indicate that activation patterns in subregions of object-selective cortex encode objects according to a hierarchy, with stimulus-based representations in posterior regions and subjective and observer-specific representations in anterior regions.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <sec id="st1">
          <title/>
          <p>As early as 1031 <sc>a.d.</sc>, the Arab scholar Ibn al-Haytham suggested that visual experience was not veridical, but inherently subjective. During the last few decades, this observation has given rise to one of the core questions in visual neuroscience: how does the subjective experience of visual stimuli relate to their neural representations in the brain? It is well-known that visual shape is represented in a brain region called lateral occipital complex (LOC). However, do these representations reflect physical or perceptual stimulus characteristics? We presented observers with a set of complex visual stimuli and obtained three measures of similarity for these stimuli: a physical similarity measure based on stimulus parameters; a behavioral similarity measure based on discrimination performance; and finally a neural similarity measure based on multivariate pattern analyses in LOC. We found that in anterior LOC, neural stimulus similarities correlated with subjective perceptual similarities, but not with physical stimulus similarities; the reverse was true in posterior LOC. In addition, neural similarities were consistent across participants in posterior LOC, but highly variable across participants in anterior LOC. Together these findings suggest a two-part answer to the question of how cortical object representations relate to subjective experience: anterior regions appear to contain subjective, individually variable shape representations, whereas posterior regions contain stimulus-based shape representations.</p>
        </sec>
      </abstract><abstract abstract-type="toc">
        <p>How does the subjective experience of visual shapes relate to the neural representations of these shapes in the brain? Using psychophysics, functional MRI, and multivariate pattern analysis methods, this study shows that activation patterns in anterior, shape-selective brain regions reflect perceptual shape similarities, whereas patterns in posterior regions reflect physical similarities.</p>
      </abstract><funding-group><funding-statement> This research was supported by National Institutes of Health grant EY13455 to NK, by the National Center for Research Resources (P41-RR14075), and by EY16187 to MSL. JH was supported by a Harvard University Presidential Fellowship, the Boehringer-Ingelheim Foundation, and the German National Merit Foundation.</funding-statement></funding-group><counts>
        <page-count count="9"/>
      </counts><!--===== Restructure custom-meta-wrap to custom-meta-group =====--><custom-meta-group>
        <custom-meta>
          <meta-name>citation</meta-name>
          <meta-value>Haushofer J, Livingstone MS, Kanwisher N (2008) Multivariate patterns in object-selective cortex dissociate perceptual and physical shape similarity. PLoS Biol 6(7): e187. doi:<ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0060187" xlink:type="simple">10.1371/journal.pbio.0060187</ext-link></meta-value>
        </custom-meta>
      </custom-meta-group></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>What is the neural code for object shape? This question has been at the core of systems neuroscience for decades. In monkeys, inferotemporal (IT) cortex has been shown to contain cells selective for complex shapes [<xref ref-type="bibr" rid="pbio-0060187-b001">1</xref>]; in humans, functional magnetic resonance imaging (fMRI) has identified a brain region known as lateral occipital complex (LOC) as a neural center for object representation [<xref ref-type="bibr" rid="pbio-0060187-b002">2</xref>,<xref ref-type="bibr" rid="pbio-0060187-b003">3</xref>]. This region responds more to intact than scrambled images of everyday objects [<xref ref-type="bibr" rid="pbio-0060187-b002">2</xref>,<xref ref-type="bibr" rid="pbio-0060187-b003">3</xref>] and is thought to be critical for object recognition [<xref ref-type="bibr" rid="pbio-0060187-b004">4</xref>,<xref ref-type="bibr" rid="pbio-0060187-b005">5</xref>]. However, the nature of the representations in these object-selective regions remains poorly understood.</p>
      <p>A number of previous studies suggest that the coding of objects in high-level visual cortex may reflect subjective perceptual experience of shapes. For instance, LOC adapts across changes in low-level physical stimulus properties that leave perceived shape unaltered, but not across changes that affect perceived shape [<xref ref-type="bibr" rid="pbio-0060187-b006">6</xref>,<xref ref-type="bibr" rid="pbio-0060187-b007">7</xref>]. Furthermore, the fMRI signal in LOC tracks recognition performance more accurately than activation in retinotopic cortex [<xref ref-type="bibr" rid="pbio-0060187-b005">5</xref>,<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>], and both IT neurons and the fMRI signal in LOC reflect the perceptual similarity of stimuli [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>,<xref ref-type="bibr" rid="pbio-0060187-b009">9</xref>]. Finally, Kayaert et al. [<xref ref-type="bibr" rid="pbio-0060187-b010">10</xref>,<xref ref-type="bibr" rid="pbio-0060187-b011">11</xref>] found that IT cells are more strongly modulated by perceptually salient stimulus changes (nonaccidental properties) than by metric changes of equal physical magnitude.</p>
      <p>FMRI studies of visual processing have traditionally focused on mean activation levels, looking for brain regions showing a difference in activation between different stimulus conditions. More recent studies, in contrast, have illustrated the importance of the distributed pattern of activation in representing information about stimulus conditions [<xref ref-type="bibr" rid="pbio-0060187-b012">12</xref>–<xref ref-type="bibr" rid="pbio-0060187-b014">14</xref>]. Haxby et al. [<xref ref-type="bibr" rid="pbio-0060187-b012">12</xref>] first showed that even when there is no difference in the mean activation levels of specific conditions across occipitotemporal cortex, object category can still be determined from the distributed pattern of activation using a correlation method. Recently, Williams et al. [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>] demonstrated that activation patterns contain object-specific information only on trials where recognition is successful. This finding raises the question whether activation patterns contain detailed information about subjective visual experience.</p>
      <p>We used a combination of human fMRI and psychophysics to test the hypothesis that distributed activation patterns in LOC reflect perceived shape. We created a novel artificial shape space, in which physical similarity was controlled by gradual, parametric changes in aspect ratio and skew. Perceptual similarity was measured by psychophysical discrimination performance between the shapes, and neural similarity was measured by the correlations between the fMRI activation patterns of these shapes in LOC. (Note that we use the term “neural” to refer to fMRI activation patterns because of the high correlation between the BOLD signal and neuronal activity [<xref ref-type="bibr" rid="pbio-0060187-b015">15</xref>]) We found significant correlations between neural and perceptual similarity measures in LOC. Interestingly, this finding was restricted to the anterior portion of LOC (pFs); in the posterior portion (LO), we found significant correlations between neural and physical similarity measures. In addition, neural similarities were consistent across participants in posterior LOC, but highly variable across participants in anterior LOC. Together, these results suggest that object representations in posterior LOC reflect the physical stimulus, while representations in anterior LOC reflect subjective shape experience.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <p>We created a novel artificial stimulus space consisting of four complex objects (<xref ref-type="fig" rid="pbio-0060187-g001">Figure 1</xref>A). Each stimulus had four radially arranged protrusions (two half-parabolas joined at the vertices), which varied parametrically in aspect ratio and skew across stimuli. This stimulus space had five important features. First, IT cortex contains cells that are tuned to aspect ratio and skew, independently of one another [<xref ref-type="bibr" rid="pbio-0060187-b016">16</xref>]; thus, our stimuli varied along dimensions likely to be relevant in object-selective areas. Second, the four shapes used in the experiment were equidistant in aspect ratio and skew, and we thereby controlled important aspects of the their physical similarity; we refer to these aspects of similarity as “physical similarity,” while noting that other definitions of physical similarity are possible (see below for an analysis using a V1-like measure of similarity). Third, the stimuli were novel, allowing us to investigate shape similarities without confounds from semantic or learned associations. Fourth, spatial fMRI activation patterns in LOC have recently been shown to contain information sufficient for discrimination of such novel shapes [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>,<xref ref-type="bibr" rid="pbio-0060187-b014">14</xref>,<xref ref-type="bibr" rid="pbio-0060187-b017">17</xref>]. Finally, the stimuli were chosen such that perceptual similarities correlated somewhat with physical similarity, but not perfectly, leaving room for the neural similarities to correlate, e.g., with perceptual similarity without necessarily also correlating with physical similarity, and vice-versa.</p>
      <fig id="pbio-0060187-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0060187.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Stimuli and Analysis Method</title>
          <p>(A) The Stimuli used in the fMRI and behavioral experiments. Adjacent stimuli were equidistant in the aspect ratio/skew stimulus space, and together the four stimuli formed a straight line through this space. We could thus control physical similarity in terms of aspect ratio and skew. Area was kept constant across stimuli.</p>
          <p>(B) Example of perceptual (top left), physical (top right), and neural (bottom) similarity matrices, together with correlation coefficients between the matrices. These correlation coefficients were obtained for all participants and are summarized in <xref ref-type="fig" rid="pbio-0060187-g002">Figure 2</xref>.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060187.g001" xlink:type="simple"/>
      </fig>
      <fig id="pbio-0060187-g002" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0060187.g002</object-id>
        <label>Figure 2</label>
        <caption>
          <title>Mean Correlations across Participants between Neural and Perceptual Similarities (Left) and Neural and Physical Similarities (Right)</title>
          <p>Neural-perceptual correlations are high in pFs and low in LO, and the reverse is true for neural-physical correlations. Shown are means ± 1 (conventional) standard error (SE).</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060187.g002" xlink:type="simple"/>
      </fig>
      <p>To study the relationship between perceptual, physical, and neural similarities in pFs and LO, we obtained three similarity measures for each pair of stimuli as follows. First, for each of the six possible pairs of nonidentical stimuli, physical similarity was measured by the inverse pairwise distances of the four shapes in the aspect ratio/skew space (<xref ref-type="fig" rid="pbio-0060187-g001">Figure 1</xref>B, top right panel). As pointed out above, aspect ratio and skew were chosen because these dimensions are thought to be of relevance in high-level visual cortex [<xref ref-type="bibr" rid="pbio-0060187-b016">16</xref>]. Since the four stimuli formed a continuum with equal distances between adjacent stimuli, the six possible pairs of the four stimuli had distances of 1, 1, 1, 2, 2, and 3 steps; these distances were converted to similarities by inverting their values, to yield the similarity values 3, 3, 3, 2, 2, and 1 (see below for a different measure of physical similarity).</p>
      <p>Second, to obtain a measure of perceptual shape similarity, we conducted a separate behavioral experiment outside the scanner with the same participants. On each trial, two shapes were shown in succession, and participants responded whether the two shapes were identical or different. Each shape was shown for 17 ms, with a forward and a backward mask of 50 ms each (without gaps between stimulus and masks), followed by a 1,500 ms response period. The proportion of trials on which a particular participant responded “identical” to a pair of stimuli that were in fact different was used as a measure of the perceptual similarity of that pair of stimuli. An example of a perceptual similarity matrix is shown in <xref ref-type="fig" rid="pbio-0060187-g001">Figure 1</xref>B (top left panel). Note that we use the confusion rate merely as a proxy for true, first-person perceptual similarity, and do not wish to argue strongly that two stimuli that are confused with high probability necessarily also have highly similar qualia. Our definition of perceptual similarity is therefore merely an operational one in the context and for the practical purposes of this experiment.</p>
      <p>Finally, to obtain a measure of neural similarity, we scanned the brains of eight participants using fMRI. Since we had a specific hypothesis about neural coding in object-selective cortex, we first identified the human object-selective region LOC in an independent localizer scan, using the standard comparison of intact versus scrambled everyday objects [<xref ref-type="bibr" rid="pbio-0060187-b002">2</xref>] (<italic>p</italic> &lt; 10<sup>−4</sup>). LOC can be subdivided into a posterior portion, LO, on the lateral surface of occipitotemporal cortex; and an anterior portion, pFs, on the fusiform gyrus of the temporal lobe [<xref ref-type="bibr" rid="pbio-0060187-b018">18</xref>]. These two anatomically distinct portions of LOC were defined as separate regions of interest (ROIs). The ROI approach is of advantage because it is not subject to multiple comparisons problems.</p>
      <p>In separate scans, we presented participants with the four shapes, using an event-related design. Each stimulus was shown for 300 ms, followed by a blank period of 1,700 ms, during which the participants had to respond whether the current stimulus was identical to that on the previous trial (one-back task). The purpose of this task was to keep participants' attention focused on the stimuli. We then extracted the spatially distributed activation patterns of each individual stimulus from the two LOC ROIs, on a voxel-by-voxel basis. Thus, in each participant and for each ROI, we obtained four vectors, each representing the voxelwise activation pattern of one particular shape in that ROI. We then computed the correlations between each of the six pairs of activation patterns for nonidentical stimuli, separately for pFs and LO. This resulted in six correlation coefficients for each ROI, one for each possible pair of the four shapes. An example of a neural similarity matrix is shown in <xref ref-type="fig" rid="pbio-0060187-g001">Figure 1</xref>B (bottom panels).</p>
      <sec id="s2a">
        <title>Correlations between Neural and Perceptual/Physical Similarity in LOC</title>
        <p>Thus, we obtained physical, perceptual, and neural similarity measures for each possible pair of stimuli. We next compared these six-element similarity matrices to one another, by computing their correlation coefficients within participants and ROIs (<xref ref-type="fig" rid="pbio-0060187-g001">Figure 1</xref>B). A high correlation between, e.g., the perceptual similarity matrix and the neural similarity matrix in a given ROI would indicate that if two stimuli are similar perceptually, they are also similar neurally in that ROI, i.e., their neural activation patterns are highly correlated with one another. Our hypothesis predicted that neural and perceptual similarity should be correlated in LOC.</p>
        <p>The results confirmed this hypothesis, with an interesting twist. Neural and perceptual similarities were positively correlated in pFs, with an average correlation of 0.35 across participants, whereas in LO the average neural-perceptual correlation was only 0.001 (<xref ref-type="fig" rid="pbio-0060187-g002">Figure 2</xref>). Conversely, neural and physical similarities were strongly positively correlated in LO (average correlation 0.41), but much more weakly in pFs (average correlation 0.10; <xref ref-type="fig" rid="pbio-0060187-g002">Figure 2</xref>).</p>
        <p>To quantify these results, we initially applied the Fisher z transformation to all correlation coefficients. This method transforms the non-normally distributed correlation coefficients into normally distributed variables, which allows the use of standard analysis of variance methods [<xref ref-type="bibr" rid="pbio-0060187-b019">19</xref>] (for details, see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Statistical analysis after Fisher z transformation confirmed that across participants, the correlation coefficients between neural and perceptual similarities were significantly greater than zero in pFs (<italic>t</italic>(5) = 5.66, <italic>p</italic> &lt; 0.001), but not greater than zero in LO (<italic>t</italic>(5) = 0.10, <italic>p</italic> = 0.38). Conversely, the correlations between neural and physical similarities were significantly greater than zero in LO (<italic>t</italic>(5) = 2.66, <italic>p</italic> &lt; 0.05), but not in pFs (<italic>t</italic>(5) = 0.70, <italic>p</italic> = 0.29). A two-way analysis of variance (ANOVA) with region of interest (pFs versus LO) and correlation type (neural-perceptual versus neural-physical) as factors revealed a significant interaction of ROI and correlation type (<italic>F</italic>(1,5) = 13.79, <italic>p</italic> &lt; 0.005), confirming the dissociation between these ROIs: neural pattern similarities in pFs correspond to subjective shape similarities, while neural pattern similarities in LO correspond to physical shape similarities.</p>
        <p>These results were not due to differential mean signal levels for any of our stimuli, for two reasons: first, the correlation analysis does not take into account mean levels of activation; second, there were no differences in mean signal between the four stimuli in either region of interest (pFs: <italic>F</italic>(3,21) = 1.86, <italic>p</italic> = 0.17; LO: <italic>F</italic>(3,21) = 0.17, <italic>p</italic> = 0.92). Moreover, these results cannot be due to task performance, since critically the perceptual similarity measure was obtained in a separate testing session, while in the scanner participants performed an easy one-back task. (A control analysis for potential effects due to this task is reported below.)</p>
      </sec>
      <sec id="s2b">
        <title>Inter-Participant Reliability</title>
        <p>As a further test of this finding, we speculated that if neural similarities in pFs reflect subjective perceptual similarities, the correspondence of neural similarities across participants in this region might be low: if a given pair of stimuli is neurally similar in pFs in one participant, the same pair may be neurally different in another participant whose subjective percept is different. Conversely, if neural similarities in LO reflect physical similarities, they should not differ greatly across participants. In other words, in pFs we would expect low inter-participant reliability of the neural similarities, whereas in LO we would expect high inter-participant reliability. To test this hypothesis, we correlated the neural similarity matrices of all individual participants with one another, separately for each ROI. This resulted in two 8 × 8 matrices, where each cell represents the correlation between the neural similarity matrices of two individual participants in one ROI (<xref ref-type="fig" rid="pbio-0060187-g003">Figure 3</xref>). A high correlation in a given cell indicates that in these two participants, the stimulus pairs that are neurally similar in one participant are also neurally similar in the other participant.</p>
        <fig id="pbio-0060187-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0060187.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Inter-Participant Reliability</title>
            <p>(A) Mean neural inter-particiapnt correlation coefficients in pFs (left) and LO (right). Consistent with observer-specific, subjective similarities in pFs, and physically-based similarities in LO, inter-participant reliability is low in pFs and high in LO. Shown are means ± 1 (conventional) SE.</p>
            <p>(B) Neural inter-particiapnt reliability in pFs (top) and LO (bottom). Each cell represents the correlation coefficient between the neural similarity matrices of two individual participants. A high correlation indicates that pairs of stimuli that are neurally similar in one participant are also neurally similar in the other participant.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060187.g003" xlink:type="simple"/>
        </fig>
        <p>As predicted, inter-participant reliability was low in pFs (mean across-participant correlation: 0.07; not different from zero, <italic>t</italic>(25) = 0.92, <italic>p</italic> = 0.26; <xref ref-type="fig" rid="pbio-0060187-g003">Figure 3</xref>), but high in LO (mean: 0.42; greater than zero, <italic>t</italic>(25) = 7.83, <italic>p</italic> &lt; 0.00000005; <xref ref-type="fig" rid="pbio-0060187-g003">Figure 3</xref>). The difference between these two ROIs was significant (<italic>t</italic>(25) = −2.80, <italic>p</italic> &lt; 0.05).</p>
        <p>Note that this analysis is independent of the results described above: whether the neural similarities in pFs correlate across participants (as tested here) does not depend on whether they correlate with the behavioral similarities within participants (tested above).</p>
      </sec>
      <sec id="s2c">
        <title>Further Regions of Interest</title>
        <p>To test whether the results described above are specific to object-selective cortex, we defined a set of further regions of interest: a retinotopic ROI based on activation at the occipital pole during the localizer task, as described before [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>]; the fusiform face area (FFA [<xref ref-type="bibr" rid="pbio-0060187-b020">20</xref>]; see also [<xref ref-type="bibr" rid="pbio-0060187-b007">7</xref>]), and the occipital face area (OFA; [<xref ref-type="bibr" rid="pbio-0060187-b021">21</xref>,<xref ref-type="bibr" rid="pbio-0060187-b022">22</xref>]), based on the standard functional contrast of faces against objects (<italic>p</italic> &lt; 10<sup>−4</sup>); and the parahippocampal place area, PPA [<xref ref-type="bibr" rid="pbio-0060187-b023">23</xref>], based on the standard contrast of scenes against objects (<italic>p</italic> &lt; 10<sup>−4</sup>). In none of these regions did the neural similarities exhibit significant correlations with either perceptual or physical similarity (<xref ref-type="fig" rid="pbio-0060187-g004">Figure 4</xref>A). Moreover, we found no significant inter-participant reliability in any of these regions (<xref ref-type="fig" rid="pbio-0060187-g004">Figure 4</xref>B). With the exception of PPA, each of these regions contained at least as many voxels as pFs, ruling out the possibility that this finding is due to an inability to detect a correlation in small datasets. However, this possibility remains for PPA, which contained significantly fewer voxels than pFs. Note that FFA did not overlap with pFs in any of our participants.</p>
        <fig id="pbio-0060187-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0060187.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Correlations in Control ROIs</title>
            <p>(A) Mean correlations across participants between neural and perceptual similarities (left) and neural and physical similarities (right) in control ROIs. No bar is significantly different from zero using Fisher-z–transformed correlations and standard errors. Shown are means ± 1 (conventional) SE.</p>
            <p>(B) Neural inter-participant reliability in control ROIs. Each bar represents the average correlation coefficient between the neural similarity matrices of all pairs of individual participants. A high correlation indicates that pairs of stimuli that are neurally similar in one participant are also neurally similar in the other participant. No bar is significantly different from zero. Shown are means ± 1 (conventional) SE.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060187.g004" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2d">
        <title>Behavioral Results</title>
        <p>The psychophysical same-different task used outside the scanner to obtain a measure of perceptual similarity was made as difficult as possible by presenting stimuli for extremely short durations (17 ms each) and using both forward and backward high-energy noise masks (50 ms each). Nevertheless, the performance level was high, with an average of 93% ± 1% correct performance on the same-different task. However, this level of performance corresponds to an average of 44 ± 9 errors over the course of the psychophysical experiment; this number of errors, distributed over the four stimuli used, proved sufficient to obtain a reliable measure of perceptual similarity. In support of this claim, the inter-participant reliability of perceptual similarity was on average <italic>r</italic> = 0.28 across participants (different from zero: <italic>t</italic>(25)=2.77, <italic>p</italic> &lt; 0.05), showing that pairs of stimuli that a particular participant confused with high probability were also perceptually similar for the other participants. However, at the same time the fact that this correlation was not extremely high leaves room for subjective, observer-specific patterns of perceptual similarities.</p>
        <p>The average correlation between the physical and perceptual similarity measures across participants was <italic>r</italic> = 0.38; this value was significantly different from zero (<italic>t</italic>(5) = 2.75, <italic>p</italic> &lt; 0.05). Thus, perceptual similarity correlated with physical similarity, but not perfectly, again leaving room for the neural similarity measures to correlate with either the perceptual or the physical similarities without necessarily also correlating with the other.</p>
        <p>The one-back task participants performed in the scanner was designed purely to keep participants' attention focused on the stimuli and was very easy to perform; none of our participants made a single mistake on this task. However, to nevertheless control for any possible effects of performance in the scanner, we analyzed the reaction times during the task in the scanner as follows. Since the order of stimulus presentation was randomized using m-sequences, each stimulus was preceded equally often by each other stimulus; therefore, each of the six possible discriminations among the four stimuli entered the neural pattern an equal number of times, and differential performance on any of these conditions could therefore not influence the neural pattern. However, it is possible that the task was easier for some stimuli in general; such a difference would enter the neural pattern of those stimuli and could thus potentially bias our results. Indeed, we observed a significant difference in the reaction times of stimuli 1 and 3 (mean reaction time [RT], stimulus 1: 602 ms ± 13 ms; stimulus 3: 624 ms ± 14 ms; <italic>t</italic>(7) = 8.11, <italic>p</italic> &lt; 0.001), and stimuli 1 and 2 (mean RT, stimulus 2: 619 ms ± 17 ms; <italic>t</italic>(7) = 2.88, <italic>p</italic> &lt; 0.05). To assess the effect of this difference, we used the reaction time differences among the four stimuli during the task in the scanner as a new behavioral similarity measure within each participant; e.g., if a particular participant took an average of 635 ms to respond to stimulus 1, and 649 ms for stimulus 2, the new behavioral similarity of these stimuli would be the negative reaction time difference, i.e. −14 ms (negative to turn the measure from a “difference” into a “similarity” measure). We then re-computed the correlations between the neural similarities and this new behavioral similarity measure. None of the resulting correlations were significant in any of our ROIs, although there was a nonsignificant trend towards a correlation between neural similarities and the new reaction time similarities in LO (mean <italic>r</italic> = 0.33, <italic>t</italic>(5) = 1.75, <italic>p</italic> = 0.09).</p>
      </sec>
      <sec id="s2e">
        <title>Robustness to Subsampling</title>
        <p>As pointed out above, it is conceivable in principle that differential numbers of voxels in different ROIs affect the likelihood of detecting correlations. Indeed, LO contained more voxels on average than pFs (pFs: mean 127 ± 36 voxels, LO: mean 287 ± 107 voxels). We therefore wished to test whether the results described above depend on the number of voxels in each ROI. To this end, we conducted a control in which we randomly excluded 50% of the voxels of each ROI. This procedure was repeated 100 times, and an average correlation estimate was obtained by averaging over the 100 bootstrapping iterations. The results were the same as in the main analysis reported above (<xref ref-type="fig" rid="pbio-0060187-g005">Figures 5</xref> and <xref ref-type="fig" rid="pbio-0060187-g006">6</xref>): the average correlation between neural and perceptual similarities in pFs was 0.25 (different from zero: <italic>t</italic>(5) = 6.32, <italic>p</italic> &lt; 0.001; <xref ref-type="fig" rid="pbio-0060187-g005">Figure 5</xref>), but that between neural and physical similarities in this region was only 0.05 (not different from zero: <italic>t</italic>(5) = 0.56, <italic>p</italic> = 0.32); in contrast, LO exhibited a significant correlation between neural and physical similarities (mean <italic>r</italic> = 0.32, <italic>t</italic>(5) = 2.33, <italic>p</italic> &lt; 0.05; <xref ref-type="fig" rid="pbio-0060187-g006">Figure 6</xref>), but not between neural and perceptual similarities (mean <italic>r</italic> = 0.06, <italic>t</italic>(5) = 0.56, <italic>p</italic> = 0.32). The interaction was again significant (<italic>F</italic>(1,5) = 12.00, <italic>p</italic> &lt; 0.005). Similarly, the inter-participant reliability was again high in LO (mean <italic>r</italic> = 0.21, <italic>t</italic>(25) = 2.82, <italic>p</italic> &lt; 0.05), but low in pFs (mean <italic>r</italic> = 0.04, <italic>t</italic>(25) = 0.60, <italic>p</italic> = 0.33; <xref ref-type="fig" rid="pbio-0060187-g006">Figure 6</xref>). The difference between LO and pFs was significant (<italic>t</italic>(25) = 2.04, <italic>p</italic> = 0.05). Note, however, that subsampling reduced the inter-participant reliability in LO by a factor of one-half (mean <italic>r</italic> = 0.42 to mean <italic>r</italic> = 0.21). In light of this change, and the fact that the average sizes of pFs and LO differed by a factor greater than two, we repeated the subsampling for the inter-participant reliability analysis using not 50% of voxels, but instead equalizing voxel numbers across the two ROIs. Specifically, we excluded random subsets of voxels from the larger ROI, until its size matched that of the smaller ROI, again with 100-fold bootstrapping. The results were comparable to that of the initial analysis: the inter-participant reliability was high in LO (mean <italic>r</italic> = 0.31, <italic>t</italic>(25) = 7.79, <italic>p</italic> &lt; 0.0001), but low in pFs (mean <italic>r</italic> = 0.07, <italic>t</italic>(25) = 0.91, <italic>p</italic> = 0.26), with a significant difference between LO and pFs (<italic>t</italic>(25) = 2.65, <italic>p</italic> &lt; 0.05). Thus, our results are independent of the size of our ROIs.</p>
        <fig id="pbio-0060187-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0060187.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Robustness of Within-Participant Analysis to Subsampling</title>
            <p>Mean correlations across participants between neural and perceptual similarities (left) and neural and physical similarities (right), after random exclusion of 50% of voxels and 100-fold bootstrapping. Neural-perceptual correlations are high in pFs and low in LO, and the reverse is true for neural-physical correlations. Shown are means ± 1 (conventional) SE.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060187.g005" xlink:type="simple"/>
        </fig>
        <fig id="pbio-0060187-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0060187.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Robustness of Inter-Participant Reliability to Subsampling</title>
            <p>(A) Mean neural inter-participant correlation coefficients in pFs (left) and LO (right), after random exclusion of 50% of voxels and 100-fold bootstrapping. Consistent with observer-specific, subjective similarities in pFs, and physically-based similarities in LO, inter-participant reliability is low in pFs and high in LO. Shown are means ± 1 (conventional) SE.</p>
            <p>(B) Neural inter-participant reliability in pFs (top) and LO (bottom), after random exclusion of 50% of voxels and 100-fold bootstrapping. Each cell represents the correlation coefficient between the neural similarity matrices of two individual participants. A high correlation indicates that pairs of stimuli that are neurally similar in one participant are also neurally similar in the other participant.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060187.g006" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2f">
        <title>An Alternative Physical Similarity Measure</title>
        <p>The physical similarity measure reported above was based on the distances of the stimuli from each other in terms of aspect ratio and skew parameters. The high correlation of these aspect ratio/skew distances with neural similarities in LO is consistent with the proposal that LO encodes stimuli in terms of aspect ratio and skew, as has been reported previously for high-level visual cortex in monkeys [<xref ref-type="bibr" rid="pbio-0060187-b016">16</xref>,<xref ref-type="bibr" rid="pbio-0060187-b024">24</xref>]. This finding suggests that LO might no longer correlate with physical similarity if it was defined in a different fashion. As a test of this hypothesis, we replaced the aspect ratio/skew distance measure with an alternative physical similarity measure designed to mimic the properties of area V1: the images were convolved with a set of Gabor filters with orientation and spatial frequency selectivities similar to those found in V1 [<xref ref-type="bibr" rid="pbio-0060187-b025">25</xref>] (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>); the resulting filtered images were then compared for pixelwise similarity. The resulting mean physical similarity matrix correlated well (<italic>r</italic> = 0.67) with the physical similarity measure reported above, i.e., closeness of the stimuli in parameter space. However, the neural similarities of pFs and LO showed no correlation with this V1-type physical similarity measure: in pFs, the mean correlation of the neural similarities with the mean Gabor similarity measure was <italic>r</italic> = 0.06 (not different from zero: <italic>t</italic>(5) = 0.42, p = 0.34); in LO, it was <italic>r</italic> = 0.07 (<italic>t</italic>(5) = 0.45, <italic>p</italic> = 0.34). In addition, we repeated this analysis for each individual Gabor filter (4 orientations × 5 spatial frequencies); none of the resulting 20 correlations between neural and physical similarities were significantly different from zero across participants in either pFs (correlations ranging from −0.09 to 0.10, none significant across participants) or LO (correlations ranging from −0.11 to 0.16, none significant across participants). Thus, the correlation of neural and physical similarities in LO appears to be specific to the case when the physical similarities are described in terms of aspect ratio and skew [<xref ref-type="bibr" rid="pbio-0060187-b016">16</xref>].</p>
        <p>The neural patterns in retinotopic cortex only showed a weak correlation with the physical stimulus distances based on this V1-type similarity measure; the mean correlation between neural and Gabor similarities in retinotopic cortex was <italic>r</italic> = 0.15, which did not differ from zero across participants (<italic>t</italic>(5) = 0.76, <italic>p</italic> = 0.27). Moreover, none of the correlations were significant when the individual physical similarity matrices resulting from each of the 20 Gabor filters were correlated one-by-one with neural similarities (correlations ranging from 0.12 to 0.17, none significant across participants). This result is probably due to the fact that the images were presented with a random jitter of ∼2 degrees during scanning, which likely resulted in sufficiently nonoverlapping activations in retinotopic cortex to disrupt the neural similarity estimates in this region, and therefore also any correlation between neural and physical similarities. In support of this hypothesis, the stimuli were not distinguishable in retinotopic cortex using Haxby's pattern discrimination method [<xref ref-type="bibr" rid="pbio-0060187-b012">12</xref>] (mean percent correct discrimination: 44% ± 5%), while they were easily discriminable in pFs (66% ± 4% correct) and LO (65 ± 3% correct; for more details see next section).</p>
      </sec>
      <sec id="s2g">
        <title>Stability of Neural Patterns across Split-Halves</title>
        <p>The results reported above indicate that the neural patterns in our regions of interest contain fine-grained information about perceptual and physical stimulus similarity. These analyses were based on correlations between the neural activation patterns of pairs of stimuli; this measure controls for noise in the data because the formula for the correlation coefficient includes a division by the standard deviations of the data vectors. However, we additionally wished to confirm with a conventional analysis method that these neural patterns were indeed stable and contained information about stimulus identity. To this end, we applied the widely used technique of Haxby et al. [<xref ref-type="bibr" rid="pbio-0060187-b012">12</xref>]: we extracted the activation patterns separately for even and odd runs, and compared “within” and “between” correlations. The mean “within” correlations were 0.10 ± 0.05 and 0.04 ± 0.02 in pFs and LO, respectively, while the mean “between” correlations were 0.04 ± 0.02 and −0.001 ± 0.04 for pFs and LO, respectively. These correlations were low because we used an event-related design. Importantly, however, the “within” correlations were significantly higher than the “between” correlations, indicating that the patterns contained enough information to discriminate between same versus different stimuli (<italic>F</italic>(1,7) = 3.67, <italic>p</italic> &lt; 0.05, two-way ANOVA with ROI and within/between as factors). As a further test of pattern discriminability, we computed the “Haxby Index” [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>,<xref ref-type="bibr" rid="pbio-0060187-b012">12</xref>,<xref ref-type="bibr" rid="pbio-0060187-b013">13</xref>,<xref ref-type="bibr" rid="pbio-0060187-b026">26</xref>]. This index estimates classification performance between pairs of stimuli based on the within and between correlations, where 50% is chance performance and 100% is optimal performance. Discrimination performance was 66% ± 4% in pFs and 65% ± 3% in LO; these levels of performance were significantly above chance (pFs: <italic>t</italic>(7) = 4.20, <italic>p</italic> &lt; 0.005; LO: <italic>t</italic>(7) = 4.55, <italic>p</italic> &lt; 0.005). Thus, the patterns in both ROIs were stable enough across the split halves to successfully discriminate between our stimuli.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>In sum, we have found that distributed activation patterns in human object-selective cortex contain information about the subjective perceptual similarities between complex visual stimuli. Specifically, we show a dissociation between neural coding of perceptual versus physical similarities within LOC: using independent measures of neural, perceptual, and physical similarity on our set of novel artificial shapes, we find that the neural similarities of shapes in anterior LOC (pFs) correlate with their perceptual similarities. Conversely, the neural similarities in posterior LOC (LO) correlate with the physical similarity of the shapes in the stimulus space. Furthermore, the agreement across participants of the neural similarities is high in LO, but low in pFs, consistent with a physically based representation in LO and a representation based on observer-specific subjective shape experience in pFs.</p>
      <p>These results are specific to object-selective cortex, i.e., the regions LO and pFs; additional ROIs including retinotopic cortex, FFA, OFA, and PPA did not show significant correlations between either neural and perceptual or physical similarities. Moreover, the results did not depend on the number of voxels in each ROI.</p>
      <p>Our findings confirm previous studies showing that object representations in the ventral stream reflect subjective perception [<xref ref-type="bibr" rid="pbio-0060187-b005">5</xref>–<xref ref-type="bibr" rid="pbio-0060187-b009">9</xref>,<xref ref-type="bibr" rid="pbio-0060187-b011">11</xref>,<xref ref-type="bibr" rid="pbio-0060187-b027">27</xref>], and extend them by showing that the distributed pattern of activation in LOC contains information about idiosyncratic perceptual similarities on a fine-grained scale [<xref ref-type="bibr" rid="pbio-0060187-b014">14</xref>].</p>
      <p>Similarly, the finding that posterior LOC shows a correlation between neural and physical stimulus similarity confirms previous studies that have shown selectivity for physical shape features of moderate complexity in high-level visual cortex. In area V4, single-cell and fMRI studies have demonstrated tuning to contour curvature in monkeys [<xref ref-type="bibr" rid="pbio-0060187-b024">24</xref>,<xref ref-type="bibr" rid="pbio-0060187-b028">28</xref>,<xref ref-type="bibr" rid="pbio-0060187-b029">29</xref>] and selectivity for radial and concentric gratings [<xref ref-type="bibr" rid="pbio-0060187-b030">30</xref>] and intermediate-complexity object parts [<xref ref-type="bibr" rid="pbio-0060187-b031">31</xref>] in humans. Single cells in monkey IT cortex have been shown to be tuned to metric changes in simple geometrical shapes [<xref ref-type="bibr" rid="pbio-0060187-b010">10</xref>,<xref ref-type="bibr" rid="pbio-0060187-b016">16</xref>] and to particular combinations of simple shapes [<xref ref-type="bibr" rid="pbio-0060187-b001">1</xref>]. Moreover, IT responses are sensitive to low-level visual properties such as object size, position, and viewpoint [<xref ref-type="bibr" rid="pbio-0060187-b032">32</xref>–<xref ref-type="bibr" rid="pbio-0060187-b034">34</xref>].</p>
      <p>Putting the results from pFs and LO together, our findings are consistent with previous evidence regarding an anterior-posterior functional subdivision within LOC: Grill-Spector et al. [<xref ref-type="bibr" rid="pbio-0060187-b035">35</xref>] showed that pFs exhibits more location- and size-invariance than LO; Lerner et al. [<xref ref-type="bibr" rid="pbio-0060187-b036">36</xref>,<xref ref-type="bibr" rid="pbio-0060187-b037">37</xref>] found that pFs was more vulnerable to object scrambling than LO; and Kourtzi et al. [<xref ref-type="bibr" rid="pbio-0060187-b038">38</xref>] showed that pFs does not adapt across changes that alter an object's subjective appearance (convex versus concave), while LO does. Together, these studies suggest that object representations in pFs are more high-level, abstract, and closer to subjective perception than those in LO. Our results substantiate this claim by showing directly that neural similarities correlate with perceptual similarities in pFs but not LO, while neural similarities correlate with physical similarities in LO but not pFs. In contrast to these previous studies, our experiment shows the correspondence between perceptual and neural similarities directly and within individual participants, by using participant-specific measures of perceptual and neural similarity. Furthermore, by computing these neural similarities on the activation pattern across individual voxels, we obtain a richer and more informative measure of neural similarity than can be achieved by averaging the activation across the entire ROI [<xref ref-type="bibr" rid="pbio-0060187-b012">12</xref>].</p>
      <p>However, it should be noted that other recent studies have found evidence highlighting the informativeness and behavioral relevance of neural activation patterns in LO: Eger et al. [<xref ref-type="bibr" rid="pbio-0060187-b014">14</xref>] showed that support vector classification within categories was better in LO than pFs; Williams et al. [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>] found that correct versus incorrect recognition was reflected in the activation patterns of LO but not pFs. Thus, pFs may not always be the seat of conscious shape perception; instead, the cortical regions whose representations are most closely associated to subjective shape perception may vary with the stimulus, task, and viewing conditions [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>].</p>
      <p>Three previous studies have shown correlations between pattern information and subjective perception in object-selective cortex. First, Edelman et al. [<xref ref-type="bibr" rid="pbio-0060187-b009">9</xref>] used multi-dimensional scaling (MDS) to uncover the perceptual and neural similarities of a set of categorized stimuli, and found that both the behavioral and the neural measures of similarity followed the stimulus category boundaries (e.g., four-legged animals versus cars). However, their stimulus set consisted of photographs of familiar, every-day objects from a restricted set of categories; thus, it is unclear whether the correspondence between the neural and behavioral measures is due to low-level visual similarity of objects in the same category, category membership itself, or even matching semantic associations of stimuli in the same category. By using novel objects from a parametrized stimulus space we can disentangle perceptual from physical similarity. Moreover, we show a functional dissociation between the two subregions of LOC, which were not analyzed independently in the Edelman et al. [<xref ref-type="bibr" rid="pbio-0060187-b009">9</xref>] study.</p>
      <p>Second, Op de Beeck et al. [<xref ref-type="bibr" rid="pbio-0060187-b027">27</xref>] showed in monkeys that the firing rates of neurons in IT cortex reflect perceptual similarities in a set of complex stimuli. The present experiment was inspired by this study, and we replicate its findings in a different species (human) and using a different technique (fMRI). In addition, we show that human object-selective cortex contains both physically based and perceptually based similarity metrics, organized in a posterior-anterior hierarchy.</p>
      <p>Third, Williams et al. [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>] used a pattern analysis approach similar to the one used here to show that the activation pattern in LOC contains information sufficient for stimulus discrimination only if the participant successfully categorizes the stimulus. This study is similar to ours in that it establishes a link between the distributed activation patterns in LOC and behavioral performance. However, the question it addresses is substantially different from ours: Williams et al. asked whether the information contained in the LOC activation patterns correlated with successful object categorization; in contrast, we ask whether the activation patterns in LOC reflect physical stimulus similarities or subjective perceptual similarities. This difference is also the likely cause for a further one, namely that Williams et al. find correspondence between neural patterns and task performance in LO, but not in pFs, while we show correlations between neural and perceptual similarities in pFs but not in LO (see also [<xref ref-type="bibr" rid="pbio-0060187-b014">14</xref>]). In addition, Williams et al. used visually highly distinctive stimulus categories, whereas the differences between our stimuli were more subtle. Together these differences suggest that coarse category membership [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>] and more fine-grained similarity (this study) may be neurally distinguishable at the level of LOC.</p>
      <p>In conclusion, our results indicate that object shape may be coded in terms of physical features in posterior LOC, and in terms of subjective shape experience in anterior LOC. Of course, this claim simply replaces one puzzle with another: “What is the neural code for object shape?” is transformed into the equally difficult question, “What are the determinants of subjective shape experience?” However, the advantage of this new question is that it has been the subject of intensive study since the time of the Gestalt psychologists [<xref ref-type="bibr" rid="pbio-0060187-b039">39</xref>], and the accumulated evidence is a rich source of new hypotheses about the neural code for object shape. Combining behavioral measures with fine-grained fMRI pattern analysis methods [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>,<xref ref-type="bibr" rid="pbio-0060187-b012">12</xref>,<xref ref-type="bibr" rid="pbio-0060187-b013">13</xref>] may prove a powerful means of solving the puzzle of visual object recognition.</p>
    </sec>
    <sec id="s4">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Participants.</title>
        <p>We recruited eight participants from the MIT Human Subject Pool. Each participant was compensated US$60. The study was approved by the MIT Committee on the Use of Humans as Experimental Subjects (COUHES). All participants gave informed consent.</p>
      </sec>
      <sec id="s4b">
        <title>Stimuli.</title>
        <p><named-content content-type="genus-species" xlink:type="simple">Localizer scans</named-content>: The LOC was localized as the region that responded more strongly to grayscale images of intact objects than to images of scrambled objects (<italic>p</italic> &lt; 10<sup>−4</sup>), as described previously [<xref ref-type="bibr" rid="pbio-0060187-b002">2</xref>,<xref ref-type="bibr" rid="pbio-0060187-b006">6</xref>]. The FFA [<xref ref-type="bibr" rid="pbio-0060187-b020">20</xref>] and the OFA [<xref ref-type="bibr" rid="pbio-0060187-b021">21</xref>,<xref ref-type="bibr" rid="pbio-0060187-b022">22</xref>] were defined as the regions responding more to faces than objects (<italic>p</italic> &lt; 10<sup>−4</sup>). The PPA [<xref ref-type="bibr" rid="pbio-0060187-b023">23</xref>] was defined as the region responding more to scenes than objects (<italic>p</italic> &lt; 10<sup>−4</sup>). The retinotopic ROI was defined based on activation at the occipital pole in a contrast between all stimulus conditions versus baseline in the localizer scans (<italic>p</italic> &lt; 10<sup>−4</sup>; [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>]).</p>
        <p><italic>Experimental scans and behavioral experiment</italic>: Four novel stimuli, each measuring 10 degrees across, were used for the experimental scans. The use of novel stimuli ensured that correlations were not due to semantic associations with the stimuli; this was a potential confound in previous pattern similarity studies [<xref ref-type="bibr" rid="pbio-0060187-b009">9</xref>]. Furthermore, we wished to use shape features that are likely to be encoded in object-selective cortex. Single-cell studies have shown that aspect ratio and skew are two such features [<xref ref-type="bibr" rid="pbio-0060187-b010">10</xref>,<xref ref-type="bibr" rid="pbio-0060187-b016">16</xref>]; we therefore created our stimuli based on parametric changes in aspect ratio and skew. Specifically, each stimulus consisted of four protrusions arranged radially around a central disk. Each protrusion was composed of two adjoining half-parabolas of the form <italic>y</italic> = <italic>a x<sup>n</sup></italic>. The parameters <italic>a</italic> and <italic>n</italic> could be used to vary the skew and aspect ratio of each protrusion parametrically. In doing so, the total area of the stimuli was always kept constant to avoid low-level confounds. We defined aspect ratio as the ratio of the height to the base width of each protrusion, and skew as the position of the vertex with respect to the center of the base; for instance, 0% skew indicates a vertex directly above the center of the base, skew of 100% indicates a vertex directly above the right end of the base, and skew of −100% indicates a vertex directly above the left end of the base. From the left to the right end of the stimulus spectrum, the aspect ratio of the second and fourth protrusions (counting clockwise, beginning at 12 o'clock) decreased by 1.4 and 1.6 on each morph step, respectively; the aspect ratio of the first and third protrusions was fixed. For skew, the first, second, and fourth protrusions moved counterclockwise by 60%, 24%, and 24% for each step, respectively (where a cumulative skew change greater than 100% simply meant moving the vertex of the protrusion beyond its base); the skew of the third protrusion changed in the clockwise direction by 25% on each step. Thus, the four stimuli used were equidistant in terms of aspect ratio and skew, forming a straight line in the stimulus space. The magnitude of the parametric distances between the stimuli was chosen based on informal testing to be at the same time discriminable and not too obvious. The stimuli were filled with random dots, with a mean luminance of 50%, to ensure activation throughout the ventral visual stream. In addition, a chair and a face were included in the stimulus set, to prevent adaptation in ventral visual cortex due to the high similarity among the novel shapes.</p>
      </sec>
      <sec id="s4c">
        <title>Procedure.</title>
        <p><italic>fMRI experiment</italic>: Each participant was run in one session of about 2 h, consisting of eight experimental scans and four LOC localizer scans. Stimuli were presented using the Psychophysics Toolbox [<xref ref-type="bibr" rid="pbio-0060187-b040">40</xref>] and Matlab (Mathworks).</p>
        <p>The localizer scans were run as described previously [<xref ref-type="bibr" rid="pbio-0060187-b006">6</xref>,<xref ref-type="bibr" rid="pbio-0060187-b020">20</xref>,<xref ref-type="bibr" rid="pbio-0060187-b023">23</xref>].</p>
        <p>The experimental scans were event-related, and each scan contained 144 stimulus trials and 36 fixation trials. On each trial, one of the six possible stimuli (four novel shapes, one face, one chair) was presented at the center of the screen for 300 ms, followed by a 1,700-ms response period during which participants indicated whether the current stimulus was identical or different from the previous one. The purpose of this task was to keep participants' attention focused on the stimuli. The order of stimulus presentation was optimized using m-sequences (Optseq). Each stimulus occurred 24 times per scan, resulting in a total of 192 times for the whole experiment.</p>
        <p><named-content content-type="genus-species" xlink:type="simple">Behavioral experiment</named-content>: In a separate behavioral session that followed the fMRI experiment with a delay of at least 1 wk, each of the original participants performed a same-different task on pairs of the same four shapes, plus the face and the chair, that were presented in the fMRI experiment. On each trial, two stimuli were shown sequentially, for 17 ms each, with a forward and a backward mask (consisting of a full screen noise field of random letters with high density and overlap) of 50 ms each, followed by a 1,500-ms response period. Perceptual similarities were obtained by computing the proportion of trials on which a particular pair of different stimuli was erroneously considered “identical”. Participants performed 630 trials total. Each stimulus appeared with equal probability on each trial, and with equal probability as the first and second stimulus of each pair.</p>
      </sec>
      <sec id="s4d">
        <title>Functional imaging.</title>
        <p>fMRI scanning was performed on a 3T Siemens Trio Scanner (Siemens) at the Athinoula A. Martinos Center for Biomedical Imaging at the McGovern Institute for Brain Research at MIT. A Gradient Echo single-shot pulse sequence was used (TR = 2 s; TE = 30 ms). Twenty-five slices were collected with a 12-channel head coil. Slices were oriented roughly perpendicular to the calcarine sulcus and covered most of the occipital and posterior temporal lobes, as well as some of the inferior parietal lobes. Slices were 2 mm thick, with a 10% gap, and had an in-plane resolution of 1.6 × 1.6 mm.</p>
      </sec>
      <sec id="s4e">
        <title>Data analysis.</title>
        <p>Data analysis was performed using FS-FAST (<ext-link ext-link-type="uri" xlink:href="http://surfer.nmr.mgh.harvard.edu" xlink:type="simple">http://surfer.nmr.mgh.harvard.edu</ext-link>), fROI (<ext-link ext-link-type="uri" xlink:href="http://froi.sourceforge.net" xlink:type="simple">http://froi.sourceforge.net</ext-link>), and custom-written software. Before statistical analysis, images were motion corrected [<xref ref-type="bibr" rid="pbio-0060187-b041">41</xref>], and the data from the blocked localizer scans (not the event-related scans) were smoothed (3 mm full width at half maximum Gaussian kernel).</p>
        <p>The LOC was defined as the set of contiguous voxels in the central occipitotemporal cortex that showed significantly stronger activation (<italic>p</italic> &lt; 10<sup>−4</sup>, uncorrected) to intact objects than to scrambled versions of the same objects [<xref ref-type="bibr" rid="pbio-0060187-b002">2</xref>]. Two subregions of LOC were defined as ROIs, as described previously [<xref ref-type="bibr" rid="pbio-0060187-b042">42</xref>]: a posterior portion, LO, on the lateral surface of occipitotemporal cortex; and an anterior portion, pFs, on the fusiform gyrus of the temporal lobe [<xref ref-type="bibr" rid="pbio-0060187-b018">18</xref>]. Furthermore, we defined four control regions of interest: the FFA [<xref ref-type="bibr" rid="pbio-0060187-b020">20</xref>] and the OFA [<xref ref-type="bibr" rid="pbio-0060187-b021">21</xref>,<xref ref-type="bibr" rid="pbio-0060187-b022">22</xref>], based on the standard functional contrast of faces against objects (<italic>p</italic> &lt; 10<sup>−4</sup>); the PPA [<xref ref-type="bibr" rid="pbio-0060187-b023">23</xref>], based on the standard contrast of scenes against objects (<italic>p</italic> &lt; 10<sup>−4</sup>); and a retinotopic ROI based on activation at the occipital pole in a contrast between all stimulus conditions versus baseline in the localizer scans (<italic>p</italic> &lt; 10<sup>−4</sup>; [<xref ref-type="bibr" rid="pbio-0060187-b008">8</xref>]). The FFA did not overlap with pFs in any of our participants, as is sometimes the case.</p>
        <p>For the blocked localizer scans, statistical maps were calculated by correlating the signal time course with a gamma function (delta = 2.25, tau = 1.25) for each voxel convolved with the block timecourse. For the event-related scans, the hemodynamic response was extracted using a deconvolution analysis, without any assumptions about the shape of the response. The peaks of the fMRI responses of each of the four novel shapes were extracted from each ROI, for all voxels separately. This resulted in four patterns per ROI, each representing the distributed activation pattern to a particular stimulus in that ROI. Neural similarities were obtained by computing the Pearson correlation coefficient between these patterns, as described above.</p>
        <p>To assess the statistical significance of the correlation matrices results, we first applied the Fisher z transformation to the data and then performed <italic>t</italic>-tests and ANOVAs. This transformation is necessary because correlation coefficients do not follow a normal distribution, and are therefore strictly not amenable to analysis of variance statistics [<xref ref-type="bibr" rid="pbio-0060187-b019">19</xref>]. The Fisher z transformation converts correlation coefficients into normally distributed variables and thereby makes t-tests and ANOVAs possible. Given a correlation <italic>r</italic>, the Fisher z is given by
					<disp-formula id="pbio-0060187-e001"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0060187.e001" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>z</mml:mi><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>ln</mml:mi><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>&plus;</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>&minus;</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math> --></disp-formula>
				</p>
        <p>We took care to use the standard error formula specific to the Fisher z:
					<disp-formula id="pbio-0060187-e002"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.0060187.e002" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>&equals;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mrow><mml:mi>n</mml:mi><mml:mo>&minus;</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math> --></disp-formula>
				</p>
        <p>This formula has fewer degrees of freedom and is therefore more conservative than the conventional standard error.</p>
      </sec>
      <sec id="s4f">
        <title>V1-like physical similarity measure.</title>
        <p>To obtain a V1-like physical similarity measure, we applied a set of Gabor filters to the images and then computed pixelwise similarities between the images. This analysis was motivated by the fact that V1 cells exhibit tuning profiles that are well-described by Gabor filters [<xref ref-type="bibr" rid="pbio-0060187-b025">25</xref>,<xref ref-type="bibr" rid="pbio-0060187-b043">43</xref>]. Each image was convolved with Gabors of four different orientations (0°, 45°, 90°, and 135°; these orientations cover the whole unit circle because of the symmetry of the Gabors) and five different spatial frequencies (2, 4, 6, 8, and 10 cycles per degree). These parameters are representative of the tuning properties found in early visual cortex [<xref ref-type="bibr" rid="pbio-0060187-b025">25</xref>]. We then correlated the resulting physical similarity matrices with the neural similarities from our regions of interest, as described above; this was done both for the average across the V1-like similarities, as well as the individual matrices. The average V1-like physical similarity matrix correlated well (<italic>r</italic> = 0.67) with our other physical similarity measure, i.e. distance of the stimuli in parameter space.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We would like to thank Niko Kriegeskorte, Richard Born, Patrick Cavanagh, James DiCarlo, Hans op de Beeck, Chris Baker, and the members of the Kanwisher lab for helpful discussions</p>
    </ack>
    
    <glossary>
      <title>Abbreviations</title>
      <def-list>
        <def-item>
          <term>IT</term>
          <def>
            <p>inferotemporal</p>
          </def>
        </def-item>
        <def-item>
          <term>FFA</term>
          <def>
            <p>fusiform face area</p>
          </def>
        </def-item>
        <def-item>
          <term>fMRI</term>
          <def>
            <p>functional magnetic resonance imaging</p>
          </def>
        </def-item>
        <def-item>
          <term>LO</term>
          <def>
            <p>posterior LOC</p>
          </def>
        </def-item>
        <def-item>
          <term>LOC</term>
          <def>
            <p>lateral occipital complex</p>
          </def>
        </def-item>
        <def-item>
          <term>OFA</term>
          <def>
            <p>occipital face area</p>
          </def>
        </def-item>
        <def-item>
          <term>pFs</term>
          <def>
            <p>anterior LOC</p>
          </def>
        </def-item>
        <def-item>
          <term>PPA</term>
          <def>
            <p>parahippocampal place area</p>
          </def>
        </def-item>
        <def-item>
          <term>ROI</term>
          <def>
            <p>region of interest</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
    <ref-list>
      <title>References</title>
      <ref id="pbio-0060187-b001">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Tanaka</surname><given-names>K</given-names></name><name name-style="western"><surname>Saito</surname><given-names>H</given-names></name><name name-style="western"><surname>Fukada</surname><given-names>Y</given-names></name><name name-style="western"><surname>Moriya</surname><given-names>M</given-names></name></person-group>
					<year>1991</year>
					<article-title>Coding visual images of objects in the inferotemporal cortex of the macaque monkey.</article-title>
					<source>J Neurophysiol</source>
					<volume>66</volume>
					<fpage>170</fpage>
					<lpage>189</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b002">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Malach</surname><given-names>R</given-names></name><name name-style="western"><surname>Reppas</surname><given-names>JB</given-names></name><name name-style="western"><surname>Benson</surname><given-names>RR</given-names></name><name name-style="western"><surname>Kwong</surname><given-names>KK</given-names></name><name name-style="western"><surname>Jiang</surname><given-names>H</given-names></name><etal/></person-group>
					<year>1995</year>
					<article-title>Object-related activity revealed by functional magnetic resonance imaging in human occipital cortex.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>92</volume>
					<fpage>8135</fpage>
					<lpage>8139</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b003">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name><name name-style="western"><surname>Woods</surname><given-names>R</given-names></name><name name-style="western"><surname>Iacoboni</surname><given-names>M</given-names></name><name name-style="western"><surname>Mazziotta</surname><given-names>J</given-names></name></person-group>
					<year>1997</year>
					<article-title>A locus in human extrastriate cortex for visual shape analysis.</article-title>
					<source>J Cog Neurosci</source>
					<volume>9</volume>
					<fpage>133</fpage>
					<lpage>142</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b004">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>James</surname><given-names>TW</given-names></name><name name-style="western"><surname>Culham</surname><given-names>J</given-names></name><name name-style="western"><surname>Humphrey</surname><given-names>GK</given-names></name><name name-style="western"><surname>Milner</surname><given-names>AD</given-names></name><name name-style="western"><surname>Goodale</surname><given-names>MA</given-names></name></person-group>
					<year>2003</year>
					<article-title>Ventral occipital lesions impair object recognition but not object-directed grasping: an fMRI study.</article-title>
					<source>Brain</source>
					<volume>126</volume>
					<fpage>2463</fpage>
					<lpage>2475</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b005">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Grill-Spector</surname><given-names>K</given-names></name><name name-style="western"><surname>Kushnir</surname><given-names>T</given-names></name><name name-style="western"><surname>Hendler</surname><given-names>T</given-names></name><name name-style="western"><surname>Malach</surname><given-names>R</given-names></name></person-group>
					<year>2000</year>
					<article-title>The dynamics of object-selective activation correlate with recognition performance in humans.</article-title>
					<source>Nat Neurosci</source>
					<volume>3</volume>
					<fpage>837</fpage>
					<lpage>843</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b006">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kourtzi</surname><given-names>Z</given-names></name><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name></person-group>
					<year>2001</year>
					<article-title>Representation of perceived object shape by the human lateral occipital complex.</article-title>
					<source>Science</source>
					<volume>293</volume>
					<fpage>1506</fpage>
					<lpage>1509</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b007">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Rotshtein</surname><given-names>P</given-names></name><name name-style="western"><surname>Henson</surname><given-names>RN</given-names></name><name name-style="western"><surname>Treves</surname><given-names>A</given-names></name><name name-style="western"><surname>Driver</surname><given-names>J</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name></person-group>
					<year>2005</year>
					<article-title>Morphing Marilyn into Maggie dissociates physical and identity face representations in the brain.</article-title>
					<source>Nat Neurosci</source>
					<volume>8</volume>
					<fpage>107</fpage>
					<lpage>113</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b008">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Williams</surname><given-names>MA</given-names></name><name name-style="western"><surname>Dang</surname><given-names>S</given-names></name><name name-style="western"><surname>Kanwisher</surname><given-names>NG</given-names></name></person-group>
					<year>2007</year>
					<article-title>Only some spatial patterns of fMRI response are read out in task performance.</article-title>
					<source>Nat Neurosci</source>
					<volume>10</volume>
					<fpage>685</fpage>
					<lpage>686</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b009">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Edelman</surname><given-names>S</given-names></name><name name-style="western"><surname>Grill-Spector</surname><given-names>K</given-names></name><name name-style="western"><surname>Kushnir</surname><given-names>T</given-names></name><name name-style="western"><surname>Malach</surname><given-names>R</given-names></name></person-group>
					<year>1998</year>
					<article-title>Toward direct visualization of the internal shape representation space by fMRI.</article-title>
					<source>Psychobiology</source>
					<volume>26</volume>
					<fpage>309</fpage>
					<lpage>321</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b010">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kayaert</surname><given-names>G</given-names></name><name name-style="western"><surname>Biederman</surname><given-names>I</given-names></name><name name-style="western"><surname>Vogels</surname><given-names>R</given-names></name></person-group>
					<year>2003</year>
					<article-title>Shape tuning in macaque inferior temporal cortex.</article-title>
					<source>J Neurosci</source>
					<volume>23</volume>
					<fpage>3016</fpage>
					<lpage>3027</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b011">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kayaert</surname><given-names>G</given-names></name><name name-style="western"><surname>Biederman</surname><given-names>I</given-names></name><name name-style="western"><surname>Vogels</surname><given-names>R</given-names></name></person-group>
					<year>2005</year>
					<article-title>Representation of regular and irregular shapes in macaque inferotemporal cortex.</article-title>
					<source>Cereb Cortex</source>
					<volume>15</volume>
					<fpage>1308</fpage>
					<lpage>1321</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b012">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name><name name-style="western"><surname>Gobbini</surname><given-names>MI</given-names></name><name name-style="western"><surname>Furey</surname><given-names>ML</given-names></name><name name-style="western"><surname>Ishai</surname><given-names>A</given-names></name><name name-style="western"><surname>Schouten</surname><given-names>JL</given-names></name><etal/></person-group>
					<year>2001</year>
					<article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex.</article-title>
					<source>Science</source>
					<volume>293</volume>
					<fpage>2425</fpage>
					<lpage>2430</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b013">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Spiridon</surname><given-names>M</given-names></name><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name></person-group>
					<year>2002</year>
					<article-title>How distributed is visual category information in human occipito-temporal cortex? An fMRI study.</article-title>
					<source>Neuron</source>
					<volume>35</volume>
					<fpage>1157</fpage>
					<lpage>1165</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b014">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Eger</surname><given-names>E</given-names></name><name name-style="western"><surname>Ashburner</surname><given-names>J</given-names></name><name name-style="western"><surname>Haynes</surname><given-names>JD</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Rees</surname><given-names>G</given-names></name></person-group>
					<year>2008</year>
					<article-title>fMRI activity patterns in human LOC carry information about object exemplars within category.</article-title>
					<source>J Cogn Neurosci</source>
					<volume>20</volume>
					<fpage>356</fpage>
					<lpage>370</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b015">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name><name name-style="western"><surname>Pauls</surname><given-names>J</given-names></name><name name-style="western"><surname>Augath</surname><given-names>M</given-names></name><name name-style="western"><surname>Trinath</surname><given-names>T</given-names></name><name name-style="western"><surname>Oeltermann</surname><given-names>A</given-names></name></person-group>
					<year>2001</year>
					<article-title>Neurophysiological investigation of the basis of the fMRI signal.</article-title>
					<source>Nature</source>
					<volume>412</volume>
					<fpage>150</fpage>
					<lpage>157</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b016">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kayaert</surname><given-names>G</given-names></name><name name-style="western"><surname>Biederman</surname><given-names>I</given-names></name><name name-style="western"><surname>Op de Beeck</surname><given-names>HP</given-names></name><name name-style="western"><surname>Vogels</surname><given-names>R</given-names></name></person-group>
					<year>2005</year>
					<article-title>Tuning for shape dimensions in macaque inferior temporal cortex.</article-title>
					<source>Eur J Neurosci</source>
					<volume>22</volume>
					<fpage>212</fpage>
					<lpage>224</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b017">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Op de Beeck</surname><given-names>HP</given-names></name><name name-style="western"><surname>Baker</surname><given-names>CI</given-names></name><name name-style="western"><surname>DiCarlo</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Kanwisher</surname><given-names>NG</given-names></name></person-group>
					<year>2006</year>
					<article-title>Discrimination training alters object representations in human extrastriate cortex.</article-title>
					<source>J Neurosci</source>
					<volume>26</volume>
					<fpage>13025</fpage>
					<lpage>13036</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b018">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Grill-Spector</surname><given-names>K</given-names></name><name name-style="western"><surname>Kourtzi</surname><given-names>Z</given-names></name><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name></person-group>
					<year>2001</year>
					<article-title>The lateral occipital complex and its role in object recognition.</article-title>
					<source>Vision Res</source>
					<volume>41</volume>
					<fpage>1409</fpage>
					<lpage>1422</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b019">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Fisher</surname><given-names>R</given-names></name></person-group>
					<year>1915</year>
					<article-title>Frequency distribution of the values of the correlation coefficient in samples of an indefinitely large population.</article-title>
					<source>Biometrika</source>
					<volume>10</volume>
					<fpage>507</fpage>
					<lpage>521</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b020">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name><name name-style="western"><surname>McDermott</surname><given-names>J</given-names></name><name name-style="western"><surname>Chun</surname><given-names>MM</given-names></name></person-group>
					<year>1997</year>
					<article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception.</article-title>
					<source>J Neurosci</source>
					<volume>17</volume>
					<fpage>4302</fpage>
					<lpage>4311</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b021">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Gauthier</surname><given-names>I</given-names></name><name name-style="western"><surname>Tarr</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Moylan</surname><given-names>J</given-names></name><name name-style="western"><surname>Skudlarski</surname><given-names>P</given-names></name><name name-style="western"><surname>Gore</surname><given-names>JC</given-names></name><etal/></person-group>
					<year>2000</year>
					<article-title>The fusiform “face area” is part of a network that processes faces at the individual level.</article-title>
					<source>J Cogn Neurosci</source>
					<volume>12</volume>
					<fpage>495</fpage>
					<lpage>504</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b022">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name><name name-style="western"><surname>Yovel</surname><given-names>G</given-names></name></person-group>
					<year>2006</year>
					<article-title>The fusiform face area: a cortical region specialized for the perception of faces.</article-title>
					<source>Philos Trans R Soc Lond B Biol Sci</source>
					<volume>361</volume>
					<fpage>2109</fpage>
					<lpage>2128</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b023">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Epstein</surname><given-names>R</given-names></name><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name></person-group>
					<year>1998</year>
					<article-title>A cortical representation of the local visual environment.</article-title>
					<source>Nature</source>
					<volume>392</volume>
					<fpage>598</fpage>
					<lpage>601</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b024">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Pasupathy</surname><given-names>A</given-names></name><name name-style="western"><surname>Connor</surname><given-names>CE</given-names></name></person-group>
					<year>1999</year>
					<article-title>Responses to contour features in macaque area V4.</article-title>
					<source>J Neurophysiol</source>
					<volume>82</volume>
					<fpage>2490</fpage>
					<lpage>2502</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b025">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name><name name-style="western"><surname>Naselaris</surname><given-names>T</given-names></name><name name-style="western"><surname>Prenger</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name></person-group>
					<year>2008</year>
					<article-title>Identifying natural images from human brain activity.</article-title>
					<source>Nature</source>
					<volume>452</volume>
					<fpage>352</fpage>
					<lpage>355</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b026">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Reddy</surname><given-names>L</given-names></name><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name></person-group>
					<year>2007</year>
					<article-title>Category selectivity in the ventral visual pathway confers robustness to clutter and diverted attention.</article-title>
					<source>Curr Biol</source>
					<volume>17</volume>
					<fpage>2067</fpage>
					<lpage>2072</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b027">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Op de Beeck</surname><given-names>H</given-names></name><name name-style="western"><surname>Wagemans</surname><given-names>J</given-names></name><name name-style="western"><surname>Vogels</surname><given-names>R</given-names></name></person-group>
					<year>2001</year>
					<article-title>Inferotemporal neurons represent low-dimensional configurations of parameterized shapes.</article-title>
					<source>Nat Neurosci</source>
					<volume>4</volume>
					<fpage>1244</fpage>
					<lpage>1252</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b028">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Pasupathy</surname><given-names>A</given-names></name><name name-style="western"><surname>Connor</surname><given-names>CE</given-names></name></person-group>
					<year>2001</year>
					<article-title>Shape representation in area V4: position-specific tuning for boundary conformation.</article-title>
					<source>J Neurophysiol</source>
					<volume>86</volume>
					<fpage>2505</fpage>
					<lpage>2519</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b029">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Brincat</surname><given-names>SL</given-names></name><name name-style="western"><surname>Connor</surname><given-names>CE</given-names></name></person-group>
					<year>2004</year>
					<article-title>Underlying principles of visual shape selectivity in posterior inferotemporal cortex.</article-title>
					<source>Nat Neurosci</source>
					<volume>7</volume>
					<fpage>880</fpage>
					<lpage>886</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b030">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Wilkinson</surname><given-names>F</given-names></name><name name-style="western"><surname>James</surname><given-names>TW</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>HR</given-names></name><name name-style="western"><surname>Gati</surname><given-names>JS</given-names></name><name name-style="western"><surname>Menon</surname><given-names>RS</given-names></name><etal/></person-group>
					<year>2000</year>
					<article-title>An fMRI study of the selective activation of human extrastriate form vision areas by radial and concentric gratings.</article-title>
					<source>Curr Biol</source>
					<volume>10</volume>
					<fpage>1455</fpage>
					<lpage>1458</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b031">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hayworth</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Biederman</surname><given-names>I</given-names></name></person-group>
					<year>2006</year>
					<article-title>Neural evidence for intermediate representations in object recognition.</article-title>
					<source>Vision Res</source>
					<volume>46</volume>
					<fpage>4024</fpage>
					<lpage>4031</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b032">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Op de Beeck</surname><given-names>H</given-names></name><name name-style="western"><surname>Vogels</surname><given-names>R</given-names></name></person-group>
					<year>2000</year>
					<article-title>Spatial sensitivity of macaque inferior temporal neurons.</article-title>
					<source>J Comp Neurol</source>
					<volume>426</volume>
					<fpage>505</fpage>
					<lpage>518</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b033">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>DiCarlo</surname><given-names>JJ</given-names></name><name name-style="western"><surname>Maunsell</surname><given-names>JH</given-names></name></person-group>
					<year>2003</year>
					<article-title>Anterior inferotemporal neurons of monkeys engaged in object recognition can be highly sensitive to object retinal position.</article-title>
					<source>J Neurophysiol</source>
					<volume>89</volume>
					<fpage>3264</fpage>
					<lpage>3278</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b034">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name><name name-style="western"><surname>Pauls</surname><given-names>J</given-names></name></person-group>
					<year>1995</year>
					<article-title>Psychophysical and physiological evidence for viewer-centered object representations in the primate.</article-title>
					<source>Cereb Cortex</source>
					<volume>5</volume>
					<fpage>270</fpage>
					<lpage>288</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b035">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Grill-Spector</surname><given-names>K</given-names></name><name name-style="western"><surname>Kushnir</surname><given-names>T</given-names></name><name name-style="western"><surname>Edelman</surname><given-names>S</given-names></name><name name-style="western"><surname>Avidan</surname><given-names>G</given-names></name><name name-style="western"><surname>Itzchak</surname><given-names>Y</given-names></name><etal/></person-group>
					<year>1999</year>
					<article-title>Differential processing of objects under various viewing conditions in the human lateral occipital complex.</article-title>
					<source>Neuron</source>
					<volume>24</volume>
					<fpage>187</fpage>
					<lpage>203</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b036">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Lerner</surname><given-names>Y</given-names></name><name name-style="western"><surname>Hendler</surname><given-names>T</given-names></name><name name-style="western"><surname>Ben-Bashat</surname><given-names>D</given-names></name><name name-style="western"><surname>Harel</surname><given-names>M</given-names></name><name name-style="western"><surname>Malach</surname><given-names>R</given-names></name></person-group>
					<year>2001</year>
					<article-title>A hierarchical axis of object processing stages in the human visual cortex.</article-title>
					<source>Cereb Cortex</source>
					<volume>11</volume>
					<fpage>287</fpage>
					<lpage>297</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b037">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Lerner</surname><given-names>Y</given-names></name><name name-style="western"><surname>Hendler</surname><given-names>T</given-names></name><name name-style="western"><surname>Malach</surname><given-names>R</given-names></name></person-group>
					<year>2002</year>
					<article-title>Object-completion effects in the human lateral occipital complex.</article-title>
					<source>Cereb Cortex</source>
					<volume>12</volume>
					<fpage>163</fpage>
					<lpage>177</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b038">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kourtzi</surname><given-names>Z</given-names></name><name name-style="western"><surname>Erb</surname><given-names>M</given-names></name><name name-style="western"><surname>Grodd</surname><given-names>W</given-names></name><name name-style="western"><surname>Bulthoff</surname><given-names>HH</given-names></name></person-group>
					<year>2003</year>
					<article-title>Representation of the perceived 3-D object shape in the human lateral occipital complex.</article-title>
					<source>Cereb Cortex</source>
					<volume>13</volume>
					<fpage>911</fpage>
					<lpage>920</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b039">
        <label>39</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Koffka</surname><given-names>K</given-names></name></person-group>
					<year>1935</year>
					<source>Principles of Gestalt Psychology</source>
					<publisher-loc>London</publisher-loc>
					<publisher-name>Lund Humphreys</publisher-name>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b040">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Brainard</surname><given-names>DH</given-names></name></person-group>
					<year>1997</year>
					<article-title>The Psychophysics Toolbox.</article-title>
					<source>Spat Vis</source>
					<volume>10</volume>
					<fpage>433</fpage>
					<lpage>436</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b041">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Cox</surname><given-names>RW</given-names></name><name name-style="western"><surname>Jesmanowicz</surname><given-names>A</given-names></name></person-group>
					<year>1999</year>
					<article-title>Real-time 3D image registration for functional MRI.</article-title>
					<source>Magn Reson Med</source>
					<volume>42</volume>
					<fpage>1014</fpage>
					<lpage>1018</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b042">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Grill-Spector</surname><given-names>K</given-names></name><name name-style="western"><surname>Kushnir</surname><given-names>T</given-names></name><name name-style="western"><surname>Hendler</surname><given-names>T</given-names></name><name name-style="western"><surname>Edelman</surname><given-names>S</given-names></name><name name-style="western"><surname>Itzchak</surname><given-names>Y</given-names></name><etal/></person-group>
					<year>1998</year>
					<article-title>A sequence of object-processing stages revealed by fMRI in the human occipital lobe.</article-title>
					<source>Hum Brain Mapp</source>
					<volume>6</volume>
					<fpage>316</fpage>
					<lpage>328</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060187-b043">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name><name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name></person-group>
					<year>1959</year>
					<article-title>Receptive fields of single neurones in the cat's striate cortex.</article-title>
					<source>J Physiol</source>
					<volume>148</volume>
					<fpage>574</fpage>
					<lpage>591</lpage>
				</element-citation>
      </ref>
    </ref-list>
  </back>
</article>
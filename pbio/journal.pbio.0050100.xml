<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pbio</journal-id><journal-id journal-id-type="allenpress-id">plbi</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="doi">10.1371/journal.pbio.0050100</article-id><article-id pub-id-type="publisher-id">06-PLBI-RA-1898R3</article-id><article-id pub-id-type="sici">plbi-05-05-03</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Evolutionary Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
        <subj-group subj-group-type="System Taxonomy">
          <subject>Mammals</subject>
        </subj-group>
      </article-categories><title-group><article-title>Object-Oriented Echo Perception and Cortical Representation in Echolocating Bats </article-title><alt-title alt-title-type="running-head">Object-Oriented Echo Processing</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
          <name name-style="western">
            <surname>Firzlaff</surname>
            <given-names>Uwe</given-names>
          </name>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
        <contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
          <name name-style="western">
            <surname>Schuchmann</surname>
            <given-names>Maike</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Grunwald</surname>
            <given-names>Jan E</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Schuller</surname>
            <given-names>Gerd</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Wiegrebe</surname>
            <given-names>Lutz</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
        </contrib>
      </contrib-group><aff id="aff1">
        <label>1</label><addr-line>
        
      Department Biologie II, Ludwig-Maximilians-Universität München, Planegg-Martinsried, Germany</addr-line></aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Semple</surname>
            <given-names>Malcolm</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">New York University, United States of America</aff><author-notes>
        <fn fn-type="con" id="ack1">
          <p> UF, MS, JEG, and LW conceived and designed the experiments. UF and MS performed the experiments. UF, MS, and LW analyzed the data. GS contributed reagents/materials/analysis tools. UF, MS, and LW wrote the paper.</p>
        </fn>
        <corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">firzlaff@zi.biologie.uni-muenchen.de</email></corresp>
      <fn fn-type="conflict" id="ack3">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="ppub">
        <month>5</month>
        <year>2007</year>
      </pub-date><pub-date pub-type="epub">
        <day>10</day>
        <month>4</month>
        <year>2007</year>
      </pub-date><volume>5</volume><issue>5</issue><elocation-id>e100</elocation-id><history>
        <date date-type="received">
          <day>10</day>
          <month>10</month>
          <year>2006</year>
        </date>
        <date date-type="accepted">
          <day>9</day>
          <month>2</month>
          <year>2007</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2007</copyright-year><copyright-holder>Firzlaff et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Echolocating bats can identify three-dimensional objects exclusively through the analysis of acoustic echoes of their ultrasonic emissions. However, objects of the same structure can differ in size, and the auditory system must achieve a size-invariant, normalized object representation for reliable object recognition. This study describes both the behavioral classification and the cortical neural representation of echoes of complex virtual objects that vary in object size. In a phantom-target playback experiment, it is shown that the bat <named-content content-type="genus-species" xlink:type="simple">Phyllostomus discolor</named-content> spontaneously classifies most scaled versions of objects according to trained standards. This psychophysical performance is reflected in the electrophysiological responses of a population of cortical units that showed an object-size invariant response (14/109 units, 13%). These units respond preferentially to echoes from objects in which echo duration (encoding object depth) and echo amplitude (encoding object surface area) co-varies in a meaningful manner. These results indicate that at the level of the bat's auditory cortex, an object-oriented rather than a stimulus-parameter–oriented representation of echoes is achieved.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <sec id="st1">
          <title/>
          <p>Bats can orientate and hunt for prey in complete darkness using echolocation. Bats use this extraordinary ability, not only to localize objects in space, but also to identify them. The same object, however, can come in different sizes. Here, we use a combination of psychophysical phantom-target experiments and electrophysiological recordings to investigate how echolocating bats perceive objects of different sizes, and how the echoes reflected from these objects are represented in the bat auditory cortex. We trained the neotropical bat <named-content content-type="genus-species" xlink:type="simple">Phyllostomus discolor</named-content> to identify virtual objects, and found that these bats spontaneously associated scaled versions of these objects with the corresponding trained object. Interestingly, we identified neurons in the bat auditory cortex that respond to specific objects irrespective of object size. These findings highlight the sensory capabilities and sophisticated neural processes underlying bat echolocation. This suggests that like the visual system, echolocation meets an important requirement of an effective object-recognition system in that it allows the identification of objects independent of object size.</p>
        </sec>
      </abstract><abstract abstract-type="toc">
        <p>Auditory cortical neurons in echolocating bats fire selectively to objects despite changes in object size.</p>
      </abstract><funding-group><funding-statement>This work was supported by the Volkswagen Foundation (I/79782).</funding-statement></funding-group><counts>
        <page-count count="10"/>
      </counts><!--===== Restructure custom-meta-wrap to custom-meta-group =====--><custom-meta-group>
        <custom-meta>
          <meta-name>citation</meta-name>
          <meta-value>Firzlaff U, Schuchmann M, Grunwald JE, Schuller G, Wiegrebe L (2007) Object-oriented echo perception and cortical representation in echolocating bats. PLoS Biol 5(5): e100. doi:<ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0050100" xlink:type="simple">10.1371/journal.pbio.0050100</ext-link></meta-value>
        </custom-meta>
      </custom-meta-group></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>For both the visual and the auditory domain, the formation of perceptual objects from physical stimuli is an essential task. Reliable object recognition is complicated by the variability of naturally occurring objects, e.g., in object size. In the visual system, the effect of object size on object recognition and underlying neural substrates has been investigated in detail (for review see Logothetis and Sheinberg [<xref ref-type="bibr" rid="pbio-0050100-b001">1</xref>]). For example, neurons in the inferior temporal lobe can exhibit object-size invariant responses [<xref ref-type="bibr" rid="pbio-0050100-b002">2</xref>].</p>
      <p>In the auditory domain, however, the definition of an object is not straightforward [<xref ref-type="bibr" rid="pbio-0050100-b003">3</xref>]. It is hypothesized that the auditory cortex segregates auditory objects depending on the auditory background, i.e., it adjusts its sensitivity for the boundaries of auditory objects along both the auditory time and frequency axes based on the spectrotemporal fluctuation statistics of the auditory background [<xref ref-type="bibr" rid="pbio-0050100-b004">4</xref>]. In humans, the analysis of auditory objects is thought to be implemented along “where” and “what” pathways in the auditory cortex [<xref ref-type="bibr" rid="pbio-0050100-b005">5</xref>,<xref ref-type="bibr" rid="pbio-0050100-b006">6</xref>], as recently corroborated in a combined functional magnetic resonance imaging (fMRI) and magneto encephalography (MEG) study [<xref ref-type="bibr" rid="pbio-0050100-b007">7</xref>]. The perception of size information in auditory objects, as part of the “what” analysis, has only recently been addressed. Human psychophysical studies have shown that information about speaker size is well preserved in human speech, that the human auditory system can segregate size information from information about the content, and thus that the auditory system can compensate for the effect of speaker size on perceived speech [<xref ref-type="bibr" rid="pbio-0050100-b008">8</xref>]: The same vowel pronounced by an adult and a child differs dramatically in its spectral content. However, it is readily perceived as the same vowel. Smith et al. [<xref ref-type="bibr" rid="pbio-0050100-b008">8</xref>,<xref ref-type="bibr" rid="pbio-0050100-b009">9</xref>] and Ives et al. [<xref ref-type="bibr" rid="pbio-0050100-b010">10</xref>] showed that recognition of vowels as well as the ability to judge relative size of speakers work well beyond the normally occurring range of speaker size. In an fMRI study, von Kriegstein et al. [<xref ref-type="bibr" rid="pbio-0050100-b011">11</xref>] showed that information about the vocal-tract length of a speaker, as an acoustic marker of body size, may be processed as early as the auditory thalamus and that an interaction between a voice's fundamental frequency (which can also mediate size information) may occur in non-primary auditory cortex.</p>
      <p>For an echolocating bat, the definition of an auditory object is readily obtained: it is the information a bat gains from analyzing the echoes of self-generated sounds reflected by a physical, three-dimensional object in its environment. This clear definition of an echo-acoustic object allows the systematic investigation of the perception [<xref ref-type="bibr" rid="pbio-0050100-b012">12</xref>–<xref ref-type="bibr" rid="pbio-0050100-b014">14</xref>] and neural encoding of auditory object features [<xref ref-type="bibr" rid="pbio-0050100-b015">15</xref>,<xref ref-type="bibr" rid="pbio-0050100-b016">16</xref>] in an animal model. Behaviorally, echolocating bats can identify three-dimensional objects exclusively through the analysis of the echoes of their ultrasonic emissions. It was shown that bats use echolocation for object identification to find fruit [<xref ref-type="bibr" rid="pbio-0050100-b017">17</xref>,<xref ref-type="bibr" rid="pbio-0050100-b018">18</xref>] and flowers [<xref ref-type="bibr" rid="pbio-0050100-b019">19</xref>]. Schmidt et al. [<xref ref-type="bibr" rid="pbio-0050100-b020">20</xref>] showed that the gleaning bat <named-content content-type="genus-species" xlink:type="simple">Megaderma lyra</named-content> uses echolocation to identify prey of different size. The bats also discriminated edible prey from dummies of the same size.</p>
      <p>In all the above-mentioned cases, object normalization is crucial for compensating for inevitable variations in object size. In fact, it has been shown in behavioral experiments that bats are able to discriminate simple shapes independent of their size [<xref ref-type="bibr" rid="pbio-0050100-b021">21</xref>]. Acoustically, an object is defined by its impulse response (IR). The IR is the sum of the reflections when an object is ensonified with a Dirac impulse, i.e., an impulse of theoretically infinite shortness and amplitude. With increasing object size, there is a proportional change in both object surface area and object depth. Because the strength of the reflection depends on the size of the reflecting surface, the IR becomes louder with increasing object size. In addition, the IR becomes temporally expanded because object depth, and thus the temporal delay between single reflections, increases with increasing object size. This expansion corresponds to a compression of the spectral interference pattern. Taken together, much of the information about the three-dimensional structure of an object is represented in its IR, and much of the variability of the IR relates to the size of the object.</p>
      <p>An echolocating bat does not perceive the IR as such, but it perceives the IR convolved with its echolocation call. Thus, the acoustic image of an object is imprinted on the echolocation call to produce an echo. The echo carries the acoustic properties of both the echolocation call and the IR. For a bat, it is essential to extract the IR from the echo [<xref ref-type="bibr" rid="pbio-0050100-b013">13</xref>,<xref ref-type="bibr" rid="pbio-0050100-b022">22</xref>]. Specifically, the loudness of an echo will not only depend on the loudness of the IR (encoding object size), but also on the loudness of the call. Echo loudness also depends on the distance between the bat and the object. Note, however, that the bat has full information about these parameters, because both the call loudness and the object distance are encoded in the auditory system. This information allows for a call loudness–independent and object distance–independent evaluation of the IR.</p>
      <p>The aim of this study was to search for a size-invariant echo-acoustic object representation in a combined psychophysical and electrophysiological approach.</p>
      <p>In the psychophysical phantom-object experiment, fruit-eating bats <italic>(Phyllostomus discolor)</italic> were trained to discriminate echoes of their sonar emissions. These echoes consisted of the emission convolved with the IRs of two objects. Each IR consisted of 12 randomly spaced reflections of different amplitude (<xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>A, third row). Once the bats had learned this task, test trials were randomly interspersed, in which a scaled version of one of the standard objects was presented (<xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>A), and the bats' spontaneous classification of theses scaled objects was assessed. The bats' psychophysical performance was compared to the performance of a spectrotemporal pattern recognizer being fed with auditory representations of the echoes, as they were perceived by the bats.</p>
      <fig id="pbio-0050100-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Stimuli Used for the Psychophysical and Electrophysiological Experiments</title>
          <p>(A) Impulse responses, (B) waveforms of the echo after convolution of an echolocation call with the IR, and (C) magnitude spectra of the echoes of object 1 and object 2 (left and right column, respectively). In the psychophysical experiments, the bats were trained to discriminate echoes of the standard objects shown the third row of A (scaling factor [Scf] 1). Once the bats had learned this task, presentations of scaled objects (scaling factors 0.67, 0.8, 1.25, and 1.5) were interspersed, and the spontaneous classification of these scaled objects was assessed. For the electrophysiological experiments, the IRs of the standard objects were scaled in terms of the delay and amplitude of the reflections with the same scaling factors and convolved with an echolocation call. The resulting 5 × 5 stimulus matrix is shown in (D). In this matrix the object-surface area and object depth vary along the vertical and the horizontal dimension, respectively. The red squares mark the properly scaled versions of the objects which are shown in (A–C). The physical parameters that changed in the vertical and horizontal dimension were amplitude and echo duration. Note, that all stimuli had very similar magnitude spectra. (E) Spectrogram of the echolocation call of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> used for convolution with the IRs.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g001" xlink:type="simple"/>
      </fig>
      <p>In the electrophysiological experiment, the ability of neurons in the auditory cortex of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> to encode a normalized representation of the two objects that have been characterized psychophysically was tested. The IRs of both standard objects were scaled in terms of the delay and amplitude of the reflections and then convolved with a standard <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> echolocation call. For each object, the resulting stimuli are represented in a 5 × 5 matrix (<xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>D) in which object depth and object surface area co-varied in a meaningful manner only along the diagonal axis, thus representing properly scaled versions of the object. Acoustically, the object–surface area parameter is encoded in the echo level, the object-depth parameter is encoded in the echo duration.</p>
      <p>The psychophysical results show that <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> spontaneously classified most scaled versions of standard objects correctly. A population of cortical units was found that reflected normalized object features in their response rates. This population may serve as a substrate for the perceptual compensation of size-induced object variations.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Psychophysics</title>
        <p>Behavioral results are based on a total of 4,500 trials obtained from three bats. Bat 1 spontaneously classified all four scaled versions for both of the two objects significantly correctly (<xref ref-type="fig" rid="pbio-0050100-g002">Figure 2</xref>A). Bat 2 did so for all four scaled versions of object 1 and two of the scaled versions of object 2 (<xref ref-type="fig" rid="pbio-0050100-g002">Figure 2</xref>B). Bat 3 showed a similar trend in evaluating the scaled objects, but failed to achieve significant performance in five of eight cases (<xref ref-type="fig" rid="pbio-0050100-g002">Figure 2</xref>C). The performance of a spectrotemporal pattern recognizer is shown in <xref ref-type="fig" rid="pbio-0050100-g002">Figure 2</xref>D. This pattern recognizer worked on a representation of the object echoes as generated by the bat's auditory periphery (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>, <xref ref-type="fig" rid="pbio-0050100-g003">Figure 3</xref>). The mean-squared differences between the auditory spectrograms of the two standard objects (<xref ref-type="fig" rid="pbio-0050100-g003">Figure 3</xref>A and <xref ref-type="fig" rid="pbio-0050100-g003">3</xref>B) and those of the scaled objects (examples in <xref ref-type="fig" rid="pbio-0050100-g003">Figure 3</xref>C–<xref ref-type="fig" rid="pbio-0050100-g003">3</xref>F) were calculated. Based on the mean-squared differences, the recognizer cannot reliably classify the peripheral representation of the scaled objects as one of the trained standard objects. Thus, even the bat that showed the weakest normalization behavior (bat 3) performed considerably better than the spectrotemporal pattern recognizer. Note that such a model could successfully predict responses in other echo-acoustic playback experiments [<xref ref-type="bibr" rid="pbio-0050100-b012">12</xref>,<xref ref-type="bibr" rid="pbio-0050100-b013">13</xref>]. These simulation results show that a dedicated neural mechanism beyond the auditory periphery is required to explain the bats' compensation for size-induced echo variations.</p>
        <fig id="pbio-0050100-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Psychophysical Classification Performance and Simulation Results</title>
            <p>Spontaneous classification of scaled virtual objects by three bats (A–C) and a simulation (D) based on a spectrotemporal pattern recognizer. Significantly correct classification of scaled objects is marked by a single star (<italic>p</italic> &lt; 0.05) or two stars (<italic>p</italic> &lt; 0.01). The number of test trials for each condition is superimposed on each bar. Although the spectrotemporal pattern recognizer cannot classify the scaled objects correctly, the bats' performance is in the majority of test conditions significantly better.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g002" xlink:type="simple"/>
        </fig>
        <fig id="pbio-0050100-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Auditory Spectrograms Generated by Echoes As They Are Perceived by the Bats</title>
            <p>Examples of auditory spectrograms produced by echoes generated with the IRs of both standard and scaled objects. The spectrograms incorporate the limits of spectral and temporal resolution of the auditory periphery of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content>. These spectrograms serve as inputs to the spectrotemporal pattern recognizer that tries to associate the spectrograms generated with different scaled objects (middle column [C–F]) to those generated with the two standard objects (A and B). Simulation results are shown in <xref ref-type="fig" rid="pbio-0050100-g002">Figure 2</xref>D.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g003" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2b">
        <title>Electrophysiology</title>
        <p>Recordings were derived from a total of 109 units from four bats (two females and two males, weighing between 33 and 44 g, lightly anaesthetized with a combination of medetomidin, midazolam, and fentanyl ([MMF]; see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). All units were tested with both objects. The stimuli for each object consisted of a standard echolocation call convolved with the 25 object IRs. For quantifying the neural responses, we computed the number of spikes for each of the 25 stimuli, with the spikes counted in a post-stimulus time window that was set separately for each unit according to the limits of statistically significant deviations from spontaneous activity (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). The 25 responses to each object were arranged in a 5 × 5 matrix and normalized such that the maximum response was set to unity. Then, each response matrix was assigned to one of six categories (“scaled,” “depth,” “surface,” “ambiguous,” “insensitive,” and “irresponsive”; see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). An illustration of the categorization principles with synthetic response matrices is shown in <xref ref-type="fig" rid="pbio-0050100-g004">Figure 4</xref>. Note that because each unit was tested with both objects, and units could respond differently to the two objects, percentages given below add up to more than 100%.</p>
        <fig id="pbio-0050100-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Illustration of the Principles Used to Categorize the Recorded Response Matrices</title>
            <p>The panels show synthetic response matrices and the results of the Kolmogorov-Smirnoff test applied along the vertical dimension (object depth), horizontal dimension (object surface area), and diagonal dimension (object scale). Test results are given above each response matrix. The results were used for the categorization as follows: if the null hypothesis could be rejected with <italic>p</italic> &lt; 0.05 either for the vertical, horizontal, or the diagonal dimension, the matrix was assigned to the “depth” (A and F), “surface” (B and G), or “scaled” (C and H) category, respectively. If the null hypothesis could be rejected for more than one dimension, the matrix was categorized as “ambiguous” (D and I). If the null hypothesis could be rejected for none of the dimensions, the matrix was categorized as “insensitive” (E). The “irresponsive” category (J) consists of units that did not respond significantly, i.e., no analysis window could be set (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). This precluded the use of the Kolmogorov-Smirnoff test for further analysis.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g004" xlink:type="simple"/>
        </fig>
        <p>Two recorded examples of response matrices assigned to the “depth” category are shown in <xref ref-type="fig" rid="pbio-0050100-g005">Figure 5</xref>A and <xref ref-type="fig" rid="pbio-0050100-g005">5</xref>B. In these matrices, responses were strongest either to a particular object depth or to a combination of object depths, but were largely independent of object surface area. Such response matrices were recorded in 14/109 units (13%) for at least one of the two objects.</p>
        <fig id="pbio-0050100-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Responses of Cortical Units to Virtual Echo-Acoustic Objects</title>
            <p>(A and B) Normalized responses of units that responded best to a particular object depth (“depth” category). These units were largely insensitive to changes of object surface area.</p>
            <p>(C and D) Responses of units which encoded object surface area (“surface”-category). These units were largely insensitive to changes of object depth.</p>
            <p>The plots are arranged in the same way as the 5 × 5 stimulus matrix shown in <xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>D. Abscissa: normalized object depth. Ordinate: normalized object surface area. MaxSp, maximum number of spikes; this number was taken as the divisor for the normalization of the responses.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g005" xlink:type="simple"/>
        </fig>
        <p>Two recorded examples of response matrices assigned to the “surface” category are shown in <xref ref-type="fig" rid="pbio-0050100-g005">Figure 5</xref>C and <xref ref-type="fig" rid="pbio-0050100-g005">5</xref>D. In these matrices, responses were strongest either to a particular object surface area or to a combination of surface areas, but were largely independent of object depth. Such response matrices were recorded in 62/109 units (57%) for at least one of the two objects.</p>
        <p>Most interestingly, in a third category, the response to stimuli along the diagonal axis, and thus to scaled versions of the stimuli, was strongest (“scaled”; <xref ref-type="fig" rid="pbio-0050100-g006">Figure 6</xref>E and <xref ref-type="fig" rid="pbio-0050100-g006">6</xref>F). Such response matrices could be recorded in 14/109 units (13%) for at least one of the two objects. In these recordings, the response was not simply dependent on echo amplitude or duration, but on a meaningful combination of the two. The sophisticated properties of such a response matrix are reflected in the fact that the unit responded to this object equally strongly no matter whether it was small (the echo is faint and short) or large (the echo is loud and long). Thus, these units reflected normalized object features in their firing-rate. The effect is especially pronounced in the unit shown in <xref ref-type="fig" rid="pbio-0050100-g006">Figure 6</xref>E. Except for the position in the upper right corner, stimuli along the diagonal axis of the 5 × 5 stimulus matrix evoked almost equally strong responses that clearly exceed the responses from other positions in the 5 × 5 matrix. In the other unit shown in <xref ref-type="fig" rid="pbio-0050100-g006">Figure 6</xref>F, the strong responses are also evoked from positions neighboring the diagonal. However, the stimuli from positions in the lower right and upper left corner of the 5 × 5 matrix evoked only weak responses, so that the diagonal orientation of positions with strong responses still prevails. As can be seen from the raster plots and peri-stimulus time histograms (PSTH) in <xref ref-type="fig" rid="pbio-0050100-g006">Figure 6</xref>A–<xref ref-type="fig" rid="pbio-0050100-g006">6</xref>D, the stimuli evoked robust responses in both units.</p>
        <fig id="pbio-0050100-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Examples of Two Cortical Units That Encoded Scaled Versions of Objects</title>
            <p>(A and B) Peri-stimulus, time histograms (PSTHs) summed up over all 25 stimuli for one object (ten repetitions for unit SPd03p45–025, 20 repetitions for unit UPd0127–015)</p>
            <p>(C and D) The corresponding raster plots. The stimulus is marked by the solid vertical line. Note that on this timescale, the stimulus duration, which ranged between 2.5 and 4 ms, corresponds to the width of the solid vertical line. The analysis window is indicated by the two dotted vertical lines in both the raster plot and the PSTH.</p>
            <p>(E and F) Normalized responses of the two units. Note that both units respond best to stimuli roughly along the diagonal axis of the 5 × 5 stimulus matrix shown in <xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>D.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g006" xlink:type="simple"/>
        </fig>
        <p>A clear assignment to a distinct response category along one dimension (“depth,” “surface,” or “scaled”) was not always possible because some response matrices showed significant responses along more than one dimension. These matrices were categorized as “ambiguous” and were recorded in 10/109 units (9%) for at least one of the two objects<bold>.</bold> However, it is noteworthy that in four of these units, a significant response occurred also along the diagonal dimension either in response to object 1 or 2.</p>
        <p>A considerable number of matrices did not show a significantly stronger response along any stimulus dimension and thus were categorized as “insensitive.” These matrices were recorded in 57/109 units (52%) for at least one of the two objects.</p>
        <p>Finally, in some units, the response to the convolved echolocation calls was generally weak and did not reach significance (“irresponsive,” 8/109 units, 7%).</p>
        <p>The number of units for which at least one of the recorded response matrices met the criteria for a response category are summarized in <xref ref-type="table" rid="pbio-0050100-t001">Table 1</xref>.</p>
        <table-wrap content-type="1col" id="pbio-0050100-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.0050100.t001</object-id><label>Table 1</label><caption>
            <p>Categorization of the Recorded Units into Six Response Categories</p>
          </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.t001" xlink:type="simple"/><!-- <table frame="hsides" rules="none"><colgroup><col id="tb1col1" align="left" charoff="0" char=""/><col id="tb1col2" align="left" charoff="0" char=""/><col id="tb1col3" align="left" charoff="0" char=""/><col id="tb1col4" align="left" charoff="0" char=""/><col id="tb1col5" align="left" charoff="0" char=""/><col id="tb1col6" align="left" charoff="0" char=""/></colgroup><thead><tr><td align="left" colspan="6"><hr/>Unit Categorization</td></tr><tr><td><hr/>Scaled</td><td><hr/>Depth</td><td><hr/>Surface</td><td><hr/>Ambiguous</td><td><hr/>Insensitive</td><td><hr/>Irresponsive</td></tr></thead><tbody><tr><td>14</td><td>14</td><td>62</td><td>10</td><td>57</td><td>8</td></tr></tbody></table> --><!-- <table-wrap-foot><fn id="nt101"><p>The numbers shown represent the number of units for which at least one of the two recorded response matrices met a specific category. Because the total number of recorded matrices is double the number of recorded units (each unit was tested with two objects), the numbers add up to more than the 109 recorded units.</p></fn></table-wrap-foot> --></table-wrap>
        <p>Each unit was tested with two virtual objects. The combination of response categories in response to the two objects is given for each unit in <xref ref-type="table" rid="pbio-0050100-t002">Table 2</xref>. This table shows the number of units that, for the two objects, fall into a specific combination of response categories. In only 53/109 of the recorded units (49%), the recorded response matrices for the two objects were assigned to the same category. This is remarkable because the echoes generated with the IRs of both objects had very similar loudness and spectral content; they differed only in their temporal structure. Most units responded best to a particular object surface area (i.e., stimulus amplitude) or did not show any preference for a certain object dimension at all. A smaller number of units responded strongest to a particular object depth (i.e., stimulus duration) or to scaled versions of an object.</p>
        <table-wrap content-type="1col" id="pbio-0050100-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.0050100.t002</object-id><label>Table 2</label><caption>
            <p>Observed Combinations of Response Categories for the Two Investigated Objects</p>
          </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.t002" xlink:type="simple"/><!-- <table frame="hsides" rules="none"><colgroup><col id="tb2col1" align="left" charoff="0" char=""/><col id="tb2col2" align="left" charoff="0" char=""/><col id="tb2col3" align="left" charoff="0" char=""/><col id="tb2col4" align="char" charoff="0" char="."/><col id="tb2col5" align="left" charoff="0" char=""/><col id="tb2col6" align="char" charoff="0" char="."/><col id="tb2col7" align="left" charoff="0" char=""/><col id="tb2col8" align="char" charoff="0" char="."/></colgroup><thead><tr><td align="left" rowspan="2"><hr/>Categorization of Responses to Object 1</td><td colspan="7"><hr/>Categorization of Responses to Object 2</td></tr><tr><td><hr/>Scaled</td><td><hr/>Depth</td><td><hr/>Surface</td><td><hr/>Ambiguous</td><td><hr/>Insensitive</td><td><hr/>Irresponsive</td><td><hr/>Sum</td></tr></thead><tbody><tr><td>Scaled</td><td>1</td><td>1</td><td>1</td><td>0</td><td>4</td><td>0</td><td>7</td></tr><tr><td>Depth</td><td>1</td><td>1</td><td>3</td><td>0</td><td>2</td><td>1</td><td>8</td></tr><tr><td>Surface</td><td>1</td><td>2</td><td>26</td><td>2</td><td>16</td><td>0</td><td>47</td></tr><tr><td>Ambiguous</td><td>2</td><td>0</td><td>3</td><td>0</td><td>2</td><td>0</td><td>7</td></tr><tr><td>Insensitive</td><td>3</td><td>3</td><td>8</td><td>1</td><td>18</td><td>0</td><td>33</td></tr><tr><td>Irresponsive</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>7</td><td>7</td></tr><tr><td>Sum</td><td>8</td><td>7</td><td>41</td><td>3</td><td>42</td><td>8</td><td>109</td></tr></tbody></table> --><!-- <table-wrap-foot><fn id="nt201"><p>The numbers given correspond to the number of units whose response matrices for the two objects fall into the specific combination of response categories. For example, one unit was found for which the response matrices in response to both objects fall into the &ldquo;scaled&rdquo; category (top left). Eighteen units were found that were insensitive to any object feature for both object 1 and 2 (third row from bottom, third column from right). The right-most column and the bottom row show the summed numbers of units in a category for objects 1 and 2, respectively.</p></fn></table-wrap-foot> --></table-wrap>
        <p>Only one recorded unit was assigned to the “scaled” category in response to both objects. Most of the other units that responded in a “scaled” way to one object were “insensitive” to object depth, surface area, or scale in response to the other object.</p>
      </sec>
      <sec id="s2c">
        <title>Spatial Distribution of Response Categories</title>
        <p>Recording sites were located at positions along the rostro-caudal axis over about 4,000 μm and along the dorsoventral axis over about 3,500 μm. This area roughly corresponds to the anatomically evaluated dimensions of the auditory cortex in <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> (S. Radtke-Schuller, personal communication). The different response categories were almost uniformly distributed over the whole cortical area from which recordings were derived, and no topological order could be detected (<xref ref-type="fig" rid="pbio-0050100-g007">Figure 7</xref>B and <xref ref-type="fig" rid="pbio-0050100-g007">7</xref>C). However, units that responded most strongly to scaled versions of objects were absent in the most anterior region of auditory cortex. There is no detailed information published about different cortical fields in the auditory cortex of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content>. However, in the auditory cortex of a closely related species <italic>(Carollia perspicillata),</italic> dorsally located, non-tonotopic–organized fields have been distinguished from more ventrally located fields with tonotopic organization, presumably the primary auditory cortex and an anterior auditory field [<xref ref-type="bibr" rid="pbio-0050100-b023">23</xref>]. These data, combined with a preliminary partitioning of the <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> auditory cortex based on 563 units in our laboratory, suggest that scale-invariant response matrices were recorded in the high-frequency parts of the primary auditory cortex and the adjacent anterior auditory field. Notably, scale-invariant responses were absent in the non-tonotopical dorsal fields.</p>
        <fig id="pbio-0050100-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Location of Recording Sites in the Auditory Cortex of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content></title>
            <p>The limits of the two scatter plots (B and C) are superimposed on the photograph of the <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> brain (A) (box). The scatter plots show the recording sites for units tested with objects 1 (B) and 2 (C). Units selective for scaled versions of an object (shown as filled red circles) were absent in the most anterior region of auditory cortex.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g007" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2d">
        <title>Influence of Stimulus Level</title>
        <p>The average presentation level for the recordings was set so that the loudest echoes were 20 to 30 dB above unit threshold. The surface-area axis of the presentation matrix translates to an echo-amplitude axis (larger surfaces produce louder echoes). Along the surface-area axis, echo level varies by 15 dB (see Neurophysiology, Materials and Methods). A change of the response category due to the change of stimulus level for either object 1 or object 2 occurred in 18 out of 21 units tested. The effect of changing the overall presentation level by 10 dB is illustrated in <xref ref-type="fig" rid="pbio-0050100-g008">Figure 8</xref>. The data show that the categorization of a unit as “scaled” depends on the choice of an adequate range of presentation levels.</p>
        <fig id="pbio-0050100-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Influence of Overall Presentation Level on Responses of Cortical Units</title>
            <p>(A) The unit shown in the figure responded best to properly scaled versions of object 2 (diagonal axis) only at an adequate range of presentation levels.</p>
            <p>(B) A 10-dB change in the overall presentation level pushed the stimuli out of the range the unit was sensitive to. The overall presentation level is indicated above each panel. Abscissa: normalized object depth. Ordinate: normalized surface area.</p>
            <p>maxSp, maximum number of spikes.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g008" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>In a combined psychophysical and electrophysiological approach, this study tested the ability of the echolocating bat <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> to normalize for size-induced variations of virtual echo-acoustic objects. The psychophysical results showed that the bats spontaneously associated most scaled virtual objects with the corresponding standard object. A simulation of the psychophysical paradigm based on spectrotemporal pattern recognition indicates that a complex central auditory circuitry is required to explain the bats' performance. A neurophysiological correlate of this perceptual accomplishment is found in size-invariant responses to echoes from these virtual objects recorded from units in the auditory cortex. The population of these units comprised 13% of all cortical units investigated.</p>
      <p>The psychophysical experiment was implemented as a real-time playback experiment. Consequently, any changes in the bat's echolocation call loudness, or in the distance between the bat and the virtual object in the setup, are preserved in the echo. If for example, a bat chose to emit a louder call towards a relatively faint IR from a small object, the perceived echo may be louder than the echo of a fainter call towards a louder IR. Thus, as in a natural echo-imaging task, this experimental paradigm requires the bats to evaluate the IR independent of the echo variations caused by call-loudness or object-distance variations. The psychophysical results show that, in most cases, the bats spontaneously normalized this extracted IR information for size-induced variations.</p>
      <p>In the electrophysiological experiments, on the other hand, the animals were not echolocating, but were listening to the echoes passively. Thus, the neural circuitry had no information about both the virtual-object distance and the echolocation call loudness. Moreover, the 5 × 5 stimulus matrix for each of the two tested objects covered only a limited space along the dimensions of object depth and surface area. In consequence, the parameter space where a neuron potentially shows size-invariant responses could not always be covered by stimulating with a single 5 × 5 matrix. This is illustrated in <xref ref-type="fig" rid="pbio-0050100-g008">Figure 8</xref>, where a variation of the overall presentation level adjusted the parameter space to fit the size-invariant response range. It is conceivable that in an actively echolocating animal, this range is adjusted according to the echolocation call loudness and the object distance.</p>
      <p>The “scaled” category represents units that show the required response invariance along the object-size axis and may thus serve as a neural substrate for the bats' psychophysical tolerance to object scale. Reliable object recognition requires not only generality, i.e., response invariance to several objects belonging to the same class, but also specificity, i.e., different response characteristics for objects belonging to different object classes. The following analysis assessed to what extent neurons from the “scaled” category met both these requirements. This analysis was confined to those “scaled” category units that showed response invariance along the main diagonal (seven units) to allow a direct comparison to the behavioral results. The simulation paradigm is equal to that for the spectrotemporal pattern recognizer, i.e., the response strength to the “standard” echoes was compared to the response strengths to all test echoes. Simulation results with outputs from a “scaled” category unit as a simulation substrate instead of the spectrotemporal pattern recognizer are shown in <xref ref-type="fig" rid="pbio-0050100-g009">Figure 9</xref>. This unit replicated the behavioral performance much better than the spectrotemporal pattern recognizer. Overall, two of the seven units combined both the required degree of specificity and generality in their responses, whereas the other five units did not meet the required object specificity.</p>
      <fig id="pbio-0050100-g009" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0050100.g009</object-id>
        <label>Figure 9</label>
        <caption>
          <title>Putative Performance of Single Units in the Psychophysical Paradigm</title>
          <p>(A and B) show the rate responses of a unit to all versions of both standard objects. This unit responded best to scaled versions of object 2. Responses to object 1 were assigned to the “depth” category.</p>
          <p>(C and D) show the results of a simulation of both the behavioral discrimination and classification based on the rate responses of this cortical unit. The unit was not only able to respond best selectively to scaled versions of object 2, but also to discriminate the two objects and assign most responses to scaled versions of both objects to the correct standard.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0050100.g009" xlink:type="simple"/>
      </fig>
      <p>In summary, a sizeable number of units showed response invariance along the object-size axis, but only two units combined this response invariance with the ability to discriminate between the two objects. In our view, both these levels of processing represent important stages towards a neural correlate of echo-acoustic object recognition. Compared to what is known about visual-object recognition, the current findings can only be seen as a first step towards an understanding of the neural basis of echo-acoustic object recognition.</p>
      <sec id="s3a">
        <title>Comparison with Previous Studies</title>
        <p>In nature, a bat can evaluate an object by integrating the echo information of the object from different ensonification angles. In fact, the echo spectra of bat-pollinated flowers changed significantly with the angle of incident sound, whereas echoes from single positions often were quite similar [<xref ref-type="bibr" rid="pbio-0050100-b019">19</xref>]. von Helversen [<xref ref-type="bibr" rid="pbio-0050100-b021">21</xref>] showed correct size-independent discrimination of real targets performed by the echolocating bat <named-content content-type="genus-species" xlink:type="simple">Glossophaga soricina</named-content>. von Helversen proposed that correct object classification is guided by the changes in the spectral pattern of the returning echoes at different ensonification angles. Object recognition could then depend on serial integration of acoustic signals. The ability to integrate over a sequence of signal has been demonstrated in songbirds and mammals (e.g., see [<xref ref-type="bibr" rid="pbio-0050100-b024">24</xref>,<xref ref-type="bibr" rid="pbio-0050100-b025">25</xref>]). In contrast, the bats in the current study were confronted with the IRs of static, virtual objects. Thus, the bats received only a one-dimensional echo-acoustic image of these virtual objects. Nevertheless, the bats were able to classify scaled versions of these IRs correctly, although the information from different ensonification angles was missing. Hypothetically, the bats' echo-acoustic object-normalization ability will improve further when they can evaluate sequences of echoes from different ensonification angles.</p>
      </sec>
      <sec id="s3b">
        <title>Cortical Representation of Objects</title>
        <p>The stimuli used in this study differ fundamentally from those used in many previous investigations in which cortical sensitivity for a specific stimulus parameter is investigated. Namely, echoes from objects of different size differ both in echo intensity (larger objects produce louder echoes) and in the echo duration (larger objects produce longer echoes). Thus, a normalized object representation requires response invariance for a meaningful co-variation of these two acoustical parameters.</p>
        <p>Heil [<xref ref-type="bibr" rid="pbio-0050100-b026">26</xref>] showed that neurons in the cat auditory cortex were tuned to the slope of the stimulus onset. In principle, such a mechanism could account for the described scale-invariant responses. When the size of the presented virtual objects changes, the change in signal duration affects the stimulus slope linearly. However, the corresponding change in surface area affects the stimulus slope quadratically (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Consequently, the slope of the stimulus onset is not constant over different scales of the same virtual object. Thus, tuning to onset slope cannot fully account for the described scale-invariant responses.</p>
        <p>Galazyuk and Feng [<xref ref-type="bibr" rid="pbio-0050100-b027">27</xref>] showed that the best duration in duration-sensitive neurons in the auditory cortex of the little brown bat decreased with increasing amplitude. In our experiments, echo duration increased with object depth and thus co-varied in a systematic manner with echo amplitude for scaled versions of objects. Thus, stimulus intensity–dependent duration sensitivity of cortical units might be the underlying mechanism in units that encoded scaled versions of complex objects.</p>
        <p>An important parameter influencing object normalization might be the bats own vocalization. It was shown for neurons in the inferior colliculus of the greater horseshoe bat <italic>(Rhinolophus ferrumequinum)</italic> that the bat's own vocalization altered the response to pure tones and frequency-modulated stimuli, presumably via direct neuronal influence of vocal activity onto collicular neurons [<xref ref-type="bibr" rid="pbio-0050100-b028">28</xref>]. This finding makes it highly likely that the response to scaled versions of acoustic objects is also influenced by the bat's own vocalization. As mentioned above, a mechanism like this would also be very favorable for bats, because the bats could compensate for differences in their outgoing echolocation calls that could otherwise be misattributed to object properties.</p>
        <p>Units that responded most strongly to scaled versions of objects were not found in the most anterior parts of the auditory cortex, but were mostly located in the high-frequency parts of primary auditory cortex. This finding is interesting, because units that were sensitive to echo roughness were mainly located in anterior regions of the auditory cortex of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> [<xref ref-type="bibr" rid="pbio-0050100-b015">15</xref>]. Because the processing of temporal envelope features is a prerequisite for encoding of echo roughness, the stimuli used in the present study provided no temporal envelope cues that could be used for object normalization; the spatial distribution of roughness-encoding units on the one hand and size-invariant units on the other hand seems to reflect a principle separation of encoding properties in anterior and posterior parts of the auditory cortex of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content>.</p>
        <p>The current study supports the hypothesis that the auditory system has dedicated mechanisms to deal with the compensation of size-induced variations of acoustic sources. The fact that the size-invariant neural responses were obtained from individuals that had not been exposed to the stimuli behaviorally, indicates that this mechanism is not experience dependent, but hard wired.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Experimental animals.</title>
        <p>The experimental animal used in this study was the New World bat <named-content content-type="genus-species" xlink:type="simple">Phyllostomus discolor</named-content> (family: Phyllostomidae). The animals originated from a breeding colony in the Department Biologie II of the Ludwig-Maximilians-University in Munich. <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> emits short (&lt;3 ms) broadband downward-modulated multiharmonic echolocation calls in the frequency range between 40 and 90 kHz (see <xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>E). It feeds mainly on fruit, pollen, and insects [<xref ref-type="bibr" rid="pbio-0050100-b029">29</xref>], the insects being gleaned mainly from the vegetation.</p>
      </sec>
      <sec id="s4b">
        <title>Psychophysics.</title>
        <p>The psychophysical experiments were implemented as virtual-object playback experiments. The bats were required to evaluate echoes of their own echolocation calls. These echoes were generated by convolving in real time the calls with IRs of a virtual object. Thus, unlike in classical psychoacoustic experiments, the bats did not hear a sound unless they emitted echolocation calls.</p>
        <p>Five adult <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> (four females, one male, body weight 30 to 40 g) took part in the training. The animals were housed in boxes (80 cm × 40 cm × 50 cm) with free access to water, and separated for sexes. In these boxes, they were only fed on days without training sessions, i.e., only for 2 d after a 5-d training period. During the training period, they were fed with banana pulp for reward. On the days without training, they had access to mealworms (larvae of <named-content content-type="genus-species" xlink:type="simple">Tenebrio molitor</named-content>) ad libitum.</p>
      </sec>
      <sec id="s4c">
        <title>Impulse responses.</title>
        <p>A hundred IRs with 12 single reflections each of random relative level were generated (750 samples, 1.86 ms). Then, those two IRs with the largest mean-squared difference in the time domain were determined. These two IRs were taken as standard IRs of virtual objects 1 and 2.</p>
        <p>Both IRs then were scaled with the following scaling factors (Scf): 0.67, 0.8, 1.25, and 1.5. The time delay of each reflection was scaled with Scf. The amplitude of each reflection was scaled with Scf<sup>2</sup> because the level of a reflection is proportional to surface area and the latter is proportional to the square of the radius. Consequently, the IR produced with an Scf of 0.67 was 15 dB fainter than the same IR scaled with Scf of 1.5. The scaled IRs of both objects are shown in <xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>A. All IRs had frequency-independent, white magnitude spectra. A convolution of these IRs with an echolocation call is equivalent to the multiplication of the spectra of call and IR. Thus, the high similarity of the echo spectra shown in <xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>C reflects the similarity of the IR spectra. This similarity occurs because the 12 reflections with random delays do not produce a systematic spectral ripple.</p>
      </sec>
      <sec id="s4d">
        <title>Experimental set up.</title>
        <p>The bats were trained in a two-alternative, forced-choice (2-AFC) playback setup as used in former experiments with <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> [<xref ref-type="bibr" rid="pbio-0050100-b012">12</xref>,<xref ref-type="bibr" rid="pbio-0050100-b015">15</xref>,<xref ref-type="bibr" rid="pbio-0050100-b030">30</xref>]. It consists of a Y-shaped maze, inversely mounted on the wall of an echo-attenuated chamber at an angle of 45°. A starting perch was located at the top end, and a feeder was mounted at the end of each leg. The angle between the legs was 60°. A 1/4-in microphone (Microtech Gefell MK 301; Gefell, Germany) was located in the middle of the maze to pick up the bats' sonar emissions. The ultrasonic emissions were amplified (model 2160; Bruel &amp; Kjaer, Naerum, Denmark) and then digitized by a data-acquisition board (data acquisition processor 5200a; Microstar, Bellevue, Washington, United States) at a sampling rate of 250 kHz. On the processor, a software trigger was implemented to look for input values larger than about a tenth of the possible input range. When triggering occurred, 500 samples (50 before the trigger event, and 450 after the event) were processed. The data-acquisition board convolved this input with the desired IR by zero padding both the recorded call and the IR to 2,048 samples, and multiplying the complex spectra of the recorded call and the IR. The resulting artificial echo was then again amplified (model 6110; Harman/Kardon, Château du Loir, France) and played back via an ultrasonic speaker (model EAS10 TH800D; Matsushita, Osaka, Japan) which was placed at a distance of 20 cm from the starting position in the middle between the two legs. The digital processing time for the echo generation was 6 ms. Together with the physical delay of the sound from the bat to the microphone and from the speaker to the bat, this resulted in an overall echo delay of about 7.5 ms. The corresponding virtual-object distance was 127 cm. This distance was fixed for both objects and scaling factors. The target strength of the virtual objects depended on the IR and ranged between −21 and −6 dB. The experimenter was seated outside the chamber, controlling the experimental procedure via a computer interface and an infrared camera. Data acquisition and analysis was implemented in Matlab 6.5 (Mathworks, Natick, Massachusetts, United States).</p>
      </sec>
      <sec id="s4e">
        <title>Training procedure.</title>
        <p>In a 2-AFC experiment with food reward, five individuals of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> were trained to discriminate the two standard IRs, representing two virtual objects. Dependent on the presented object, the bat had to crawl into leg one (object 1) or two (object 2) to obtain a food reward. Three out of five trained animals were able to solve this task. When the bats' performance in these standard trials exceeded 80% correct, test trials were randomly interspersed with a probability of 25%. In these test trials, scaled versions of object 1 or 2 were presented. Test trials were always rewarded, independent of the bats' decision. Thus, in the test trials, the bats' spontaneous classification of the scaled objects as either object 1 or object 2 was assessed. Data acquisition stopped when the slowest animal had performed at least 30 trials for each scaled object. The spontaneous performance for each scaled object was numerically tested for significance by simulating 10,000 repetitions of the 2-AFC experiment with the given number of trials and a random performance. Significance was set at <italic>p</italic> &lt; 0.05.</p>
      </sec>
      <sec id="s4f">
        <title>Simulation of the classification of scaled virtual objects via auditory spectrograms in <italic>P. discolor.</italic></title>
        <p>A bat does not hear the IR of an object itself, but the IR convolved with its echolocation call. Moreover, these convolved calls are modified in the auditory periphery of the bats. To simulate the classification of the scaled objects used in this study, we have to take account of these modifications. We simulated the auditory periphery up to the stage of the auditory nerve. First, we convolved each IR of each object with a standard echolocation call. Then, the convolved signal was sent through outer and middle ear filters that mimicked the absolute thresholds of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> as described by Esser and Daucher [<xref ref-type="bibr" rid="pbio-0050100-b031">31</xref>]. To simulate the inner ear characteristics, we applied a gammatone filter bank, consisting of 25 channels with center frequencies equally spaced on a log frequency axis between 20 and 110 kHz. The transfer function of the gammatone filters is designed to mimic the shape of the distortion product, otoacoustic-emission tuning curves of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> as measured by Wittekindt et al. [<xref ref-type="bibr" rid="pbio-0050100-b032">32</xref>]. After half-wave rectification and exponential compression, we applied a phase-locking filter (cutoff frequency: 1 kHz; 12 dB/octave). The resulting signal is then resampled at 20 kHz. Thus, we obtained the auditory spectrograms generated by echoes as they are perceived by the bats in the experimental setup.</p>
        <p>The auditory spectrograms generated with the two standard objects are shown in <xref ref-type="fig" rid="pbio-0050100-g003">Figure 3</xref>A and <xref ref-type="fig" rid="pbio-0050100-g003">3</xref>B. Examples of auditory spectrograms for four of the eight scaled versions of the standard objects are shown in <xref ref-type="fig" rid="pbio-0050100-g003">Figure 3</xref>C–<xref ref-type="fig" rid="pbio-0050100-g003">3</xref>F.</p>
        <p>Next, the mean-squared differences between the auditory spectrograms generated with scaled objects and those generated with standard objects were calculated. Based on these mean-squared differences, the simulation classified the auditory spectrograms of the scaled objects as either similar to the spectrograms of standard object 1 or standard object 2. Thus, the simulation works as a spectrotemporal pattern recognizer. Note that this simulation has no concept of scaling, and thus it serves as a null hypothesis for a behavioral test of echo-acoustic object normalization.</p>
      </sec>
      <sec id="s4g">
        <title>Neurophysiology—surgery.</title>
        <p>Four adult bats were used for the neurophysiological experiments. All experiments complied with the principles of laboratory animal care and were conducted under the regulations of the current version of the German Law on Animal Protection (approval 209.1/211-2531–68/03, Reg. Oberbayern). The principle surgical procedure has been described in detail elsewhere [<xref ref-type="bibr" rid="pbio-0050100-b033">33</xref>]. In brief, bats were anesthetized using MMF (medetomidin 0.4 μg, midazolam 4 μg, and fentanyl 0.04 μg per gram body weight). The skin overlying the skull was opened along the midline and the skull surface was freed from tissue. A small metal tube was fixed to the skull using a microglass composite in order to fixate the animal to a stereotaxic device, and the accurate skull position in stereotaxic coordinates was determined as described in detail elsewhere [<xref ref-type="bibr" rid="pbio-0050100-b034">34</xref>].</p>
      </sec>
      <sec id="s4h">
        <title>Neurophysiology—stimulus production and recording of neural responses.</title>
        <p>Experiments were conducted in a sound-attenuated chamber. Acoustic stimuli were computer generated (Matlab; Mathworks), digital-analog converted (RX6 [Tucker Davis Technologies, Gainesville, Florida, United States], sampling rate: 260 kHz), attenuated (PA5; Tucker Davis Technologies), and binaurally presented via ultrasonic earphones with a flat frequency response (±3 dB) between 10 and 100 kHz [<xref ref-type="bibr" rid="pbio-0050100-b035">35</xref>].</p>
        <p>Stimuli consisted of a typical echolocation call of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> (<xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>E) convolved with IRs identical to the IRs used in the psychophysical experiments. The standard IRs of object 1 and object 2 were scaled in terms of the delay and amplitude of the reflections by scaling factors of 0.67, 0.83, 1, 1.25, and 1.5. The resulting stimuli can be represented in a 5 × 5 matrix in which object surface area (vertical dimension) and object depth (horizontal dimension) co-varied in a meaningful manner only along the diagonal axis, thus representing properly scaled versions of the object (<xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>D). Along the vertical dimension, the acoustical parameter that changed was amplitude, whereas along the horizontal dimension, echo duration changed (<xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>D). For both virtual objects, the echoes span a level range of 15 dB. Dependent on the duration of the IRs, the resulting stimulus duration varied between about 2.5 and 4 ms (<xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>B). Note that all 50 echoes from the two objects had very similar spectral envelopes (<xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>C).</p>
        <p>The sound level was chosen so that the loudest echoes were 20 to 30 dB above a unit's pure-tone threshold. The set of 50 echoes was presented in a randomized order at a repetition period of 770 ms (inter-stimulus interval between 766 and 767.5 ms). Within each period, the echo was preceded by a 10 to 50 ms silent period to determine the spontaneous activity (see below). The set of 50 echoes was presented 10 or 20 times.</p>
        <p>For electrophysiological recordings, bats were anaesthetized with MMF (0.4 μg, 4 μg, and 0.04 μg per gram body weight, respectively). During recording, anesthesia was maintained by injecting the half of the initial dose of MMF every 2 h. Recording sessions could last up to 5 h per day and were repeated 4 d a week. Action potentials from neurons in the auditory cortex were recorded extracellularly using either glass microelectrodes filled with 2 M NaCl and 4% Pontamine Sky Blue (3–8 MΩ impedance) or carbon fiber microelectrodes (Carbostar-1 [Kation Scientific, Minneapolis, Minnesota, United States], 0.4–0.8 MΩ impedance). Because it was not always possible to clearly discriminate the activity of a single neuron, the term <italic>unit</italic> will be used in the following to describe the activity of one neuron to clusters of three neurons recorded at a distinct recording site. Neural activity was monitored audiovisually, and threshold and best frequency of a unit were roughly determined. Action potentials were amplified using conventional methods and recorded using an AD converter (RP2.1 [Tucker Davis Technologies], sampling rate: 25 kHz) and Brainware (Tucker Davis Technologies). Electrode penetrations were made tangentially to the brain surface. After the completion of an experiment, lesions were made to the brain in order to reconstruct the position of recording sites from subsequent histological processing in standardized coordinates of a brain atlas of <named-content content-type="genus-species" xlink:type="simple">P. discolor</named-content> (A. Nixdorf, T. Fenzl, B. Schwellnus, unpublished data).</p>
      </sec>
      <sec id="s4i">
        <title>Data analysis.</title>
        <p>Spike responses from all 25 stimuli for each object were displayed as raster plots (see <xref ref-type="fig" rid="pbio-0050100-g006">Figure 6</xref>C and <xref ref-type="fig" rid="pbio-0050100-g006">6</xref>D). An analysis window was set automatically by moving a 10-ms window in 1-ms steps over the time course of recorded activity and computing a Wilcoxon signed rank test (<italic>p</italic> &lt; 0.01, Matlab Statistics Toolbox, Mathworks) over the 25 stimuli and the first 10–50 ms preceding each stimulus (spontaneous activity). The first point at which two successive windows led to significant responses was taken as the start of the analysis window; the last position of two successive significant windows was taken as the end of the analysis window. Spikes were summed in the analysis window and normalized such that the maximum number of spikes was set to unity. The normalized responses were arranged as color-coded plots in a 5 × 5 matrix corresponding to the stimulus matrix (cf. <xref ref-type="fig" rid="pbio-0050100-g001">Figure 1</xref>D). If no significant response was detected by the analysis window, the neuron was categorized as “irresponsive” (<xref ref-type="fig" rid="pbio-0050100-g004">Figure 4</xref>J).</p>
        <p>In all other cases, a Kolmogorov-Smirnov test (kstest2, Matlab Statistics Toolbox, Mathworks) was used to test whether the five responses, e.g., for a specific object depth, belonged to the same, continuous distribution as all other responses in the response matrix. Exemplary, synthetic response matrices, in which this hypothesis can be rejected with <italic>p</italic> &lt; 0.05, are illustrated in <xref ref-type="fig" rid="pbio-0050100-g004">Figure 4</xref>A and <xref ref-type="fig" rid="pbio-0050100-g004">4</xref>F. This analysis was performed, not only along the vertical dimension (object depth), but also along the horizontal dimension (object surface area, <xref ref-type="fig" rid="pbio-0050100-g004">Figure 4</xref>B and <xref ref-type="fig" rid="pbio-0050100-g004">4</xref>G) and along the diagonal dimension (object scale, <xref ref-type="fig" rid="pbio-0050100-g004">Figure 4</xref>C and <xref ref-type="fig" rid="pbio-0050100-g004">4</xref>H). The test along the diagonal was performed for the main diagonal and one parallel above and below. This was done in order to avoid miscategorizing units due to the comparison of only low numbers of positions in the 5 × 5 matrix (the shortest diagonal line in the matrix would contain only two positions). If the null hypothesis could be rejected for more than one of the three tested dimensions, the response matrix was categorized as “ambiguous.” If the null hypothesis could be rejected for none of the three dimensions, the response matrix was categorized as “insensitive.”</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Susanne Radtke-Schuller and Claudia Schulte for their help with the reconstruction of recording sites and histological procedures, and Horst König for technical help. Special thanks go to Susanne Hoffmann for help during the experiments. We would like to thank Benedikt Grothe, Roy Patterson, and Gerhard Neuweiler for many fruitful discussions about the current topic. We also thank two anonymous reviewers for very constructive comments on earlier versions of the manuscript.</p>
    </ack>
    
    <glossary>
      <title>Abbreviations</title>
      <def-list>
        <def-item>
          <term>IR</term>
          <def>
            <p>impulse response</p>
          </def>
        </def-item>
        <def-item>
          <term>MMF</term>
          <def>
            <p>medetomidin, midazolam, and fentanyl</p>
          </def>
        </def-item>
        <def-item>
          <term>Scf</term>
          <def>
            <p>scaling factor</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
    <ref-list>
      <title>References</title>
      <ref id="pbio-0050100-b001">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Logothetis</surname><given-names>NK</given-names></name><name name-style="western"><surname>Sheinberg</surname><given-names>DL</given-names></name></person-group>
					<year>1996</year>
					<article-title>Visual object recognition.</article-title>
					<source>Annu Rev Neurosci</source>
					<volume>19</volume>
					<fpage>577</fpage>
					<lpage>621</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b002">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Ito</surname><given-names>M</given-names></name><name name-style="western"><surname>Tamura</surname><given-names>H</given-names></name><name name-style="western"><surname>Fujita</surname><given-names>I</given-names></name><name name-style="western"><surname>Tanaka</surname><given-names>K</given-names></name></person-group>
					<year>1995</year>
					<article-title>Size and position invariance of neuronal responses in monkey inferotemporal cortex.</article-title>
					<source>J Neurophysiol</source>
					<volume>73</volume>
					<fpage>218</fpage>
					<lpage>226</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b003">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Griffiths</surname><given-names>TD</given-names></name><name name-style="western"><surname>Warren</surname><given-names>JD</given-names></name></person-group>
					<year>2004</year>
					<article-title>What is an auditory object?</article-title>
					<source>Nat Rev Neurosci</source>
					<volume>5</volume>
					<fpage>887</fpage>
					<lpage>892</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b004">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name></person-group>
					<year>2004</year>
					<article-title>Processing of complex stimuli and natural scenes in the auditory cortex.</article-title>
					<source>Curr Opin Neurobiol</source>
					<volume>14</volume>
					<fpage>474</fpage>
					<lpage>480</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b005">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Rauschecker</surname><given-names>JP</given-names></name><name name-style="western"><surname>Tian</surname><given-names>B</given-names></name></person-group>
					<year>2000</year>
					<article-title>Mechanisms and streams for processing of “what” and “where” in auditory cortex.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>97</volume>
					<fpage>11800</fpage>
					<lpage>11806</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b006">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Rauschecker</surname><given-names>JP</given-names></name></person-group>
					<year>1998</year>
					<article-title>Parallel processing in the auditory cortex of primates.</article-title>
					<source>Audiol Neurootol</source>
					<volume>3</volume>
					<fpage>86</fpage>
					<lpage>103</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b007">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Ahveninen</surname><given-names>J</given-names></name><name name-style="western"><surname>Jaaskelainen</surname><given-names>IP</given-names></name><name name-style="western"><surname>Raij</surname><given-names>T</given-names></name><name name-style="western"><surname>Bonmassar</surname><given-names>G</given-names></name><name name-style="western"><surname>Devore</surname><given-names>S</given-names></name><etal/></person-group>
					<year>2006</year>
					<article-title>Task-modulated “what” and “where” pathways in human auditory cortex.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>103</volume>
					<fpage>14608</fpage>
					<lpage>14613</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b008">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>DR</given-names></name><name name-style="western"><surname>Patterson</surname><given-names>RD</given-names></name><name name-style="western"><surname>Turner</surname><given-names>R</given-names></name><name name-style="western"><surname>Kawahara</surname><given-names>H</given-names></name><name name-style="western"><surname>Irino</surname><given-names>T</given-names></name></person-group>
					<year>2005</year>
					<article-title>The processing and perception of size information in speech sounds.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>117</volume>
					<fpage>305</fpage>
					<lpage>318</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b009">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>DR</given-names></name><name name-style="western"><surname>Patterson</surname><given-names>RD</given-names></name></person-group>
					<year>2005</year>
					<article-title>The interaction of glottal-pulse rate and vocal-tract length in judgements of speaker size, sex, and age.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>118</volume>
					<fpage>3177</fpage>
					<lpage>3186</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b010">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Ives</surname><given-names>DT</given-names></name><name name-style="western"><surname>Smith</surname><given-names>DR</given-names></name><name name-style="western"><surname>Patterson</surname><given-names>RD</given-names></name></person-group>
					<year>2005</year>
					<article-title>Discrimination of speaker size from syllable phrases.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>118</volume>
					<fpage>3816</fpage>
					<lpage>3822</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b011">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>von Kriegstein</surname><given-names>K</given-names></name><name name-style="western"><surname>Warren</surname><given-names>JD</given-names></name><name name-style="western"><surname>Ives</surname><given-names>DT</given-names></name><name name-style="western"><surname>Patterson</surname><given-names>RD</given-names></name><name name-style="western"><surname>Griffiths</surname><given-names>TD</given-names></name></person-group>
					<year>2006</year>
					<article-title>Processing the acoustic effect of size in speech sounds.</article-title>
					<source>Neuroimage</source>
					<volume>32</volume>
					<fpage>368</fpage>
					<lpage>375</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b012">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Grunwald</surname><given-names>JE</given-names></name><name name-style="western"><surname>Schörnich</surname><given-names>S</given-names></name><name name-style="western"><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group>
					<year>2004</year>
					<article-title>Classification of natural textures in echolocation.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>101</volume>
					<fpage>5670</fpage>
					<lpage>5674</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b013">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Weissenbacher</surname><given-names>P</given-names></name><name name-style="western"><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group>
					<year>2003</year>
					<article-title>Classification of virtual objects in the echolocating bat, <named-content content-type="genus-species" xlink:type="simple">Megaderma lyra</named-content>.</article-title>
					<source>Behav Neurosci</source>
					<volume>117</volume>
					<fpage>833</fpage>
					<lpage>839</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b014">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Simmons</surname><given-names>JA</given-names></name><name name-style="western"><surname>Neretti</surname><given-names>N</given-names></name><name name-style="western"><surname>Intrator</surname><given-names>N</given-names></name><name name-style="western"><surname>Altes</surname><given-names>RA</given-names></name><name name-style="western"><surname>Ferragamo</surname><given-names>MJ</given-names></name><etal/></person-group>
					<year>2004</year>
					<article-title>Delay accuracy in bat sonar is related to the reciprocal of normalized echo bandwidth, or Q.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>101</volume>
					<fpage>3638</fpage>
					<lpage>3643</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b015">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Firzlaff</surname><given-names>U</given-names></name><name name-style="western"><surname>Schörnich</surname><given-names>S</given-names></name><name name-style="western"><surname>Hoffmann</surname><given-names>S</given-names></name><name name-style="western"><surname>Schuller</surname><given-names>G</given-names></name><name name-style="western"><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group>
					<year>2006</year>
					<article-title>A neural correlate of stochastic echo imaging.</article-title>
					<source>J Neurosci</source>
					<volume>26</volume>
					<fpage>785</fpage>
					<lpage>791</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b016">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Sanderson</surname><given-names>MI</given-names></name><name name-style="western"><surname>Simmons</surname><given-names>JA</given-names></name></person-group>
					<year>2002</year>
					<article-title>Selectivity for echo spectral interference and delay in the auditory cortex of the big brown bat <named-content content-type="genus-species" xlink:type="simple">Eptesicus fuscus</named-content>.</article-title>
					<source>J Neurophysiol</source>
					<volume>87</volume>
					<fpage>2823</fpage>
					<lpage>2834</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b017">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kalko</surname><given-names>EKV</given-names></name><name name-style="western"><surname>Condon</surname><given-names>MA</given-names></name></person-group>
					<year>1998</year>
					<article-title>Echolocation, olfaction and fruit display: How bats find fruit of flagellichorous cucurbits.</article-title>
					<source>Funct Ecol</source>
					<volume>12</volume>
					<fpage>364</fpage>
					<lpage>372</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b018">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Thies</surname><given-names>W</given-names></name><name name-style="western"><surname>Kalko</surname><given-names>EKV</given-names></name><name name-style="western"><surname>Schnitzler</surname><given-names>HU</given-names></name></person-group>
					<year>1998</year>
					<article-title>The roles of echolocation and olfaction in two Neotropical fruit-eating bats, <named-content content-type="genus-species" xlink:type="simple">Carollia perspicillata</named-content> and <italic>C. castanea,</italic> feeding on Piper.</article-title>
					<source>Behav Ecol Sociobiol</source>
					<volume>42</volume>
					<fpage>397</fpage>
					<lpage>409</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b019">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>von Helversen</surname><given-names>D</given-names></name><name name-style="western"><surname>von Helversen</surname><given-names>O</given-names></name></person-group>
					<year>2003</year>
					<article-title>Object recognition by echolocation: A nectar-feeding bat exploiting the flowers of a rain forest vine.</article-title>
					<source>J Comp Physiol [A]</source>
					<volume>189</volume>
					<fpage>327</fpage>
					<lpage>336</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b020">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schmidt</surname><given-names>S</given-names></name><name name-style="western"><surname>Hanke</surname><given-names>S</given-names></name><name name-style="western"><surname>Pillat</surname><given-names>J</given-names></name></person-group>
					<year>2000</year>
					<article-title>The role of echolocation in the hunting of terrestrial prey—New evidence for an underestimated strategy in the gleaning bat, <named-content content-type="genus-species" xlink:type="simple">Megaderma lyra</named-content>.</article-title>
					<source>J Comp Physiol [A]</source>
					<volume>186</volume>
					<fpage>975</fpage>
					<lpage>988</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b021">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>von Helversen</surname><given-names>D</given-names></name></person-group>
					<year>2004</year>
					<article-title>Object classification by echolocation in nectar feeding bats: Size-independent generalization of shape.</article-title>
					<source>J Comp Physiol [A]</source>
					<volume>190</volume>
					<fpage>515</fpage>
					<lpage>521</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b022">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Simmons</surname><given-names>JA</given-names></name></person-group>
					<year>1989</year>
					<article-title>A view of the world through the bat's ear: The formation of acoustic images in echolocation.</article-title>
					<source>Cognition</source>
					<volume>33</volume>
					<fpage>155</fpage>
					<lpage>199</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b023">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Esser</surname><given-names>KH</given-names></name><name name-style="western"><surname>Eiermann</surname><given-names>A</given-names></name></person-group>
					<year>1999</year>
					<article-title>Tonotopic organization and parcellation of auditory cortex in the FM-bat <named-content content-type="genus-species" xlink:type="simple">Carollia perspicillata</named-content>.</article-title>
					<source>Eur J Neurosci</source>
					<volume>11</volume>
					<fpage>3669</fpage>
					<lpage>3682</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b024">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hulse</surname><given-names>SH</given-names></name><name name-style="western"><surname>Cynx</surname><given-names>J</given-names></name></person-group>
					<year>1986</year>
					<article-title>Interval and contour in serial pitch perception by a passerine bird, the European starling <italic>(Sturnus vulgaris)</italic>.</article-title>
					<source>J Comp Psychol</source>
					<volume>100</volume>
					<fpage>215</fpage>
					<lpage>228</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b025">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Ralston</surname><given-names>JV</given-names></name><name name-style="western"><surname>Herman</surname><given-names>LM</given-names></name></person-group>
					<year>1995</year>
					<article-title>Perception and generalization of frequency contours by a bottle-nosed dolphin <italic>(Tursiops truncatus)</italic>.</article-title>
					<source>J Comp Psychol</source>
					<volume>109</volume>
					<fpage>268</fpage>
					<lpage>277</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b026">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Heil</surname><given-names>P</given-names></name></person-group>
					<year>1997</year>
					<article-title>Auditory cortical onset responses revisited. II. Response strength.</article-title>
					<source>J Neurophysiol</source>
					<volume>77</volume>
					<fpage>2642</fpage>
					<lpage>2660</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b027">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Galazyuk</surname><given-names>AV</given-names></name><name name-style="western"><surname>Feng</surname><given-names>AS</given-names></name></person-group>
					<year>1997</year>
					<article-title>Encoding of sound duration by neurons in the auditory cortex of the little brown bat, <named-content content-type="genus-species" xlink:type="simple">Myotis lucifugus</named-content>.</article-title>
					<source>J Comp Physiol [A]</source>
					<volume>180</volume>
					<fpage>301</fpage>
					<lpage>311</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b028">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schuller</surname><given-names>G</given-names></name></person-group>
					<year>1979</year>
					<article-title>Vocalization influences auditory processing in collicular neurons of the CF-FM bat, <named-content content-type="genus-species" xlink:type="simple">Rhinolophus ferrumequinum</named-content>.</article-title>
					<source>J Comp Physiol [A]</source>
					<volume>132</volume>
					<fpage>39</fpage>
					<lpage>46</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b029">
        <label>29</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Novak</surname><given-names>RM</given-names></name></person-group>
					<year>1994</year>
					<source>Walker's bats of the world</source>
					<publisher-loc>Baltimore (Maryland)</publisher-loc>
					<publisher-name>Johns Hopkins University Press</publisher-name>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">287</size>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b030">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schuchmann</surname><given-names>M</given-names></name><name name-style="western"><surname>Hübner</surname><given-names>M</given-names></name><name name-style="western"><surname>Wiegrebe</surname><given-names>L</given-names></name></person-group>
					<year>2006</year>
					<article-title>The absence of spatial echo suppression in the echolocating bats <named-content content-type="genus-species" xlink:type="simple">Megaderma lyra</named-content> and <named-content content-type="genus-species" xlink:type="simple">Phyllostomus discolor</named-content>.</article-title>
					<source>J Exp Biol</source>
					<volume>209</volume>
					<fpage>152</fpage>
					<lpage>157</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b031">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Esser</surname><given-names>KH</given-names></name><name name-style="western"><surname>Daucher</surname><given-names>A</given-names></name></person-group>
					<year>1996</year>
					<article-title>Hearing in the FM-bat <italic>Phyllostomus discolor:</italic> A behavioral audiogram.</article-title>
					<source>J Comp Physiol [A]</source>
					<volume>178</volume>
					<fpage>779</fpage>
					<lpage>785</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b032">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Wittekindt</surname><given-names>A</given-names></name><name name-style="western"><surname>Drexl</surname><given-names>M</given-names></name><name name-style="western"><surname>Kössl</surname><given-names>M</given-names></name></person-group>
					<year>2005</year>
					<article-title>Cochlear sensitivity in the lesser spear-nosed bat, <named-content content-type="genus-species" xlink:type="simple">Phyllostomus discolor</named-content>.</article-title>
					<source>J Comp Physiol [A]</source>
					<volume>191</volume>
					<fpage>31</fpage>
					<lpage>36</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b033">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schuller</surname><given-names>G</given-names></name><name name-style="western"><surname>O'Neill</surname><given-names>WE</given-names></name><name name-style="western"><surname>Radtke-Schuller</surname><given-names>S</given-names></name></person-group>
					<year>1991</year>
					<article-title>Fascilitation and delay sensitivity of auditory cortex neurons in CF-FM bats <named-content content-type="genus-species" xlink:type="simple">Rhinolophus rouxi</named-content> and <italic>Pteronotus p. parnellii</italic>.</article-title>
					<source>Eur J Neurosci</source>
					<volume>3</volume>
					<fpage>1165</fpage>
					<lpage>1181</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b034">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schuller</surname><given-names>G</given-names></name><name name-style="western"><surname>Radtke-Schuller</surname><given-names>S</given-names></name><name name-style="western"><surname>Betz</surname><given-names>M</given-names></name></person-group>
					<year>1986</year>
					<article-title>A stereotaxic method for small animals using experimentally determined reference profiles.</article-title>
					<source>J Neurosci Methods</source>
					<volume>18</volume>
					<fpage>339</fpage>
					<lpage>350</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0050100-b035">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schuller</surname><given-names>G</given-names></name></person-group>
					<year>1997</year>
					<article-title>A cheap earphone for small animals with good frequency response in the ultrasonic frequency range.</article-title>
					<source>J Neurosci Methods</source>
					<volume>71</volume>
					<fpage>187</fpage>
					<lpage>190</lpage>
				</element-citation>
      </ref>
    </ref-list>
  </back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-00141</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002079</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Computer science</subject>
          <subj-group>
            <subject>Computer modeling</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Statistics</subject>
            <subj-group>
              <subject>Statistical methods</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Medicine</subject>
          <subj-group>
            <subject>Neurology</subject>
            <subj-group>
              <subject>Neuroimaging</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computer Science</subject>
          <subject>Neurological Disorders</subject>
          <subject>Mathematics</subject>
        </subj-group>
      </article-categories><title-group><article-title>Generative Embedding for Model-Based Classification of fMRI Data</article-title><alt-title alt-title-type="running-head">Generative Embedding for fMRI</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Brodersen</surname>
            <given-names>Kay H.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Schofield</surname>
            <given-names>Thomas M.</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Leff</surname>
            <given-names>Alexander P.</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Ong</surname>
            <given-names>Cheng Soon</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Lomakina</surname>
            <given-names>Ekaterina I.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Buhmann</surname>
            <given-names>Joachim M.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Stephan</surname>
            <given-names>Klaas E.</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Computer Science, ETH Zurich, Zurich, Switzerland</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Laboratory for Social and Neural Systems Research, Department of Economics, University of Zurich, Zurich, Switzerland</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Wellcome Trust Centre for Neuroimaging, University College London, London, United Kingdom</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Sporns</surname>
            <given-names>Olaf</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Indiana University, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">kay.brodersen@inf.ethz.ch</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: TMS APL KES. Performed the experiments: TMS APL. Analyzed the data: KHB TMS APL CSO EIL JMB KES. Wrote the paper: KHB.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>6</month>
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>23</day>
        <month>6</month>
        <year>2011</year>
      </pub-date><volume>7</volume><issue>6</issue><elocation-id>e1002079</elocation-id><history>
        <date date-type="received">
          <day>7</day>
          <month>1</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>20</day>
          <month>4</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Brodersen et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Decoding models, such as those underlying multivariate classification algorithms, have been increasingly used to infer cognitive or clinical brain states from measures of brain activity obtained by functional magnetic resonance imaging (fMRI). The practicality of current classifiers, however, is restricted by two major challenges. First, due to the high data dimensionality and low sample size, algorithms struggle to separate informative from uninformative features, resulting in poor generalization performance. Second, popular discriminative methods such as support vector machines (SVMs) rarely afford mechanistic interpretability. In this paper, we address these issues by proposing a novel generative-embedding approach that incorporates neurobiologically interpretable generative models into discriminative classifiers. Our approach extends previous work on trial-by-trial classification for electrophysiological recordings to subject-by-subject classification for fMRI and offers two key advantages over conventional methods: it may provide more accurate predictions by exploiting discriminative information encoded in ‘hidden’ physiological quantities such as synaptic connection strengths; and it affords mechanistic interpretability of clinical classifications. Here, we introduce generative embedding for fMRI using a combination of dynamic causal models (DCMs) and SVMs. We propose a general procedure of DCM-based generative embedding for subject-wise classification, provide a concrete implementation, and suggest good-practice guidelines for unbiased application of generative embedding in the context of fMRI. We illustrate the utility of our approach by a clinical example in which we classify moderately aphasic patients and healthy controls using a DCM of thalamo-temporal regions during speech processing. Generative embedding achieves a near-perfect balanced classification accuracy of 98% and significantly outperforms conventional activation-based and correlation-based methods. This example demonstrates how disease states can be detected with very high accuracy and, at the same time, be interpreted mechanistically in terms of abnormalities in connectivity. We envisage that future applications of generative embedding may provide crucial advances in dissecting spectrum disorders into physiologically more well-defined subgroups.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>Neurological and psychiatric spectrum disorders are typically defined in terms of particular symptom sets, despite increasing evidence that the same symptom may be caused by very different pathologies. Pathophysiological classification and effective treatment of such disorders will increasingly require a mechanistic understanding of inter-individual differences and clinical tools for making accurate diagnostic inference in individual patients. Previous classification studies have shown that functional magnetic resonance imaging (fMRI) can be used to differentiate between healthy controls and neurological or psychiatric patients. However, these studies are typically based on descriptive patterns and indirect measures of neural activity, and they rarely afford mechanistic insights into the underlying condition. In this paper, we address this challenge by proposing a classification approach that rests on a model of brain function and exploits the rich discriminative information encoded in directed interregional connection strengths. Based on an fMRI dataset acquired from moderately aphasic patients and healthy controls, we illustrate that our approach enables more accurate classification and deeper mechanistic insights about disease processes than conventional classification methods.</p>
      </abstract><funding-group><funding-statement>This study was funded by the University Research Priority Program ‘Foundations of Human Social Behaviour’ at the University of Zurich (KHB, KES), the SystemsX.ch project NEUROCHOICE (KHB, KES; <ext-link ext-link-type="uri" xlink:href="http://www.systemsx.ch/" xlink:type="simple">http://www.systemsx.ch/</ext-link>), the NCCR ‘Neural Plasticity’ (KES; <ext-link ext-link-type="uri" xlink:href="http://www.nccr-neuro.uzh.ch/" xlink:type="simple">http://www.nccr-neuro.uzh.ch/</ext-link>), the Wellcome Trust (APL; grant ME033459MES), and the NIHR CBRC at University College Hospitals London (APL). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="19"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Recent years have seen a substantial increase in the use of functional neuroimaging data for investigating healthy brain function and detecting abnormalities. The most popular type of analysis is statistical parametric mapping (SPM), a mass-univariate encoding model of fMRI data in which the statistical relationship between experimental (or clinical) variables and haemodynamic measurements of neural activity is examined independently for every voxel in the brain <xref ref-type="bibr" rid="pcbi.1002079-Friston1">[1]</xref>. While this approach has led to many insights about functional abnormalities in psychiatric and neurological disorders, it suffers from two limitations. First, since univariate models are insensitive to spatially distributed patterns of neural activity, they may fail to detect subtle, distributed differences between patients and healthy controls that are not expressed as local peaks or clusters of activity <xref ref-type="bibr" rid="pcbi.1002079-Koutsouleris1">[2]</xref>. Second, while encoding models such as SPM are excellent for describing regional differences in brain activity across clinical groups, they are less well suited for clinical decision making, where the challenge is to predict the disease state of an individual subject from measured brain activity <xref ref-type="bibr" rid="pcbi.1002079-Fu1">[3]</xref>–<xref ref-type="bibr" rid="pcbi.1002079-Wang1">[5]</xref>.</p>
      <p>An alternative approach is provided by multivariate decoding methods, in particular classification algorithms. Unlike mass-univariate encoding models, these methods predict an experimental variable (e.g., a trial-specific condition or subject-specific disease state) from the activity pattern across voxels (see <xref ref-type="bibr" rid="pcbi.1002079-Norman1">[6]</xref>–<xref ref-type="bibr" rid="pcbi.1002079-Pereira1">[10]</xref> for reviews). Using multivariate decoding models instead of mass-univariate encoding models has interesting potential for clinical practice, particularly for diseases that are difficult to diagnose. Consequently, much work is currently being invested in constructing classifiers that can predict the diagnosis of individual subjects from structural or functional brain data <xref ref-type="bibr" rid="pcbi.1002079-Ford1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fu1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fan1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fan2">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Shen1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Klppel1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1002079-Yoon1">[16]</xref>. Historically, these efforts date back to positron emission tomography (PET) studies in the early 1990s <xref ref-type="bibr" rid="pcbi.1002079-OToole1">[8]</xref>. Today, attempts of using multivariate classifiers for subject-by-subject diagnosis largely focus on MRI and fMRI data <xref ref-type="bibr" rid="pcbi.1002079-Ford1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fu1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fan1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fan3">[17]</xref>.</p>
      <sec id="s1a">
        <title>Challenges for current classification approaches</title>
        <p>Despite their increasing popularity, two challenges critically limit the practical applicability of current classification methods for functional neuroimaging data. First, classifying subjects directly in voxel space is often a prohibitively difficult task. This is because functional neuroimaging datasets (i) typically exhibit a low signal-to-noise ratio, (ii) are obtained in an extremely high-dimensional measurement space (a conventional fMRI scan contains more than 100,000 voxels), and (iii) are characterized by a striking mismatch between the large number of voxels and the small number of available subjects. As a result, even the most carefully designed algorithms have great difficulties in reliably finding jointly informative voxels while ignoring uninformative sources of noise. Popular strategies include: preselecting voxels based on an anatomical mask <xref ref-type="bibr" rid="pcbi.1002079-Haynes2">[18]</xref>,  or a separate functional localizer <xref ref-type="bibr" rid="pcbi.1002079-Cox1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Serences1">[21]</xref>; spatial subsampling <xref ref-type="bibr" rid="pcbi.1002079-Davatzikos1">[22]</xref>; finding informative voxels using univariate models <xref ref-type="bibr" rid="pcbi.1002079-Fu1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Ford1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fan1">[12]</xref> or locally multivariate searchlight methods <xref ref-type="bibr" rid="pcbi.1002079-Kriegeskorte1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Haynes3">[24]</xref>; and unsupervised dimensionality reduction <xref ref-type="bibr" rid="pcbi.1002079-Shen1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-MouraoMiranda1">[25]</xref>. Other recently proposed strategies attempt to account for the inherent spatial structure of the feature space <xref ref-type="bibr" rid="pcbi.1002079-Kriegeskorte1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Soon1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Grosenick1">[27]</xref> or use voxel-wise models to infer a particular stimulus identity <xref ref-type="bibr" rid="pcbi.1002079-Kay1">[28]</xref>–<xref ref-type="bibr" rid="pcbi.1002079-Formisano1">[30]</xref>. Finally, those submissions that performed best in the Pittsburgh Brain Activity Interpretation Competition (PBAIC 2007) highlighted the utility of kernel ridge regression <xref ref-type="bibr" rid="pcbi.1002079-Chu1">[31]</xref> and relevance vector regression <xref ref-type="bibr" rid="pcbi.1002079-Chu1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Valente1">[32]</xref>. The common assumption underlying all of these approaches is that interesting variations of the data with regard to the class variable are confined to a manifold that populates a latent space of much lower dimensionality than the measurement space.</p>
        <p>The second challenge for classification methods concerns the interpretation of their results. Most classification studies to date draw conclusions from overall prediction accuracies <xref ref-type="bibr" rid="pcbi.1002079-Mitchell2">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Ford1">[11]</xref>, the spatial deployment of informative voxels <xref ref-type="bibr" rid="pcbi.1002079-Kamitani1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Kamitani2">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Haynes2">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Hampton1">[35]</xref>–<xref ref-type="bibr" rid="pcbi.1002079-Howard1">[39]</xref>, the temporal evolution of discriminative information <xref ref-type="bibr" rid="pcbi.1002079-Polyn1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Grosenick2">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Bode1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Harrison1">[42]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Soon1">[26]</xref>, or patterns of undirected regional correlations <xref ref-type="bibr" rid="pcbi.1002079-Craddock1">[43]</xref>. These approaches may support discriminative decisions, but they are blind to the neuronal mechanisms (such as effective connectivity or synaptic plasticity) that underlie discriminability of brain or disease states. In other words: while some conventional classification studies have achieved impressive diagnostic accuracy <xref ref-type="bibr" rid="pcbi.1002079-Klppel1">[14]</xref>, their results have not improved our mechanistic understanding of disease processes.</p>
      </sec>
      <sec id="s1b">
        <title>Generative embedding</title>
        <p>Generative embedding for model-based classification may provide a solution to the challenges outlined above. It is based on the idea that both the performance and interpretability of conventional approaches could be improved by taking into account available prior knowledge about the process generating the observed data (see <xref ref-type="bibr" rid="pcbi.1002079-ShaweTaylor1">[44]</xref> for an overview). (The term <italic>generative embedding</italic> is sometimes used to denote a particular model-induced feature space, or so-called generative score space, in which case the associated line of research is said to be concerned with <italic>generative embeddings</italic>. Here, we will use the term in singular form to denote the process of using a generative model to project the data into a generative score space, rather than using the term to denote the space itself.) Generative embedding rests on two components: a generative model for principled selection of mechanistically interpretable features and a discriminative method for classification (see <xref ref-type="fig" rid="pcbi-1002079-g001">Figure 1</xref>).</p>
        <fig id="pcbi-1002079-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Conceptual overview of generative embedding for fMRI.</title>
            <p>This schematic illustrates the key principles by which generative embedding enables model-based classification for functional magnetic resonance imaging (fMRI). Initially, each subject is represented by a measure of blood oxygen level dependent (BOLD) activity with one temporal and three spatial dimensions. In the first analysis step (model inversion), these subject-specific data are used to estimate the parameters of a generative model, which represents a mapping of the data <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e001" xlink:type="simple"/></inline-formula> onto a probability distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e002" xlink:type="simple"/></inline-formula> in a parametric family <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e003" xlink:type="simple"/></inline-formula> (see Sections ‘DCM for fMRI’ and ‘Model inversion’). In the second step (kernel construction), a kernel function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e004" xlink:type="simple"/></inline-formula> is defined that represents a similarity metric between any two fitted models <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e005" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e006" xlink:type="simple"/></inline-formula>. This step can be split up into an initial mapping <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e007" xlink:type="simple"/></inline-formula> followed by a conventional kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e008" xlink:type="simple"/></inline-formula>. The kernel implies a generative score space (or model-based feature space; see Section ‘Kernel construction’), which provides a comprehensive statistical representation of every subject. In this illustrative participant, the influence of region A on region B as well as the self-connection of region B were particularly strong. In the third step, a classifier is used to find a separating hyperplane between groups of subjects, based exclusively on their model-based representations (see Section ‘Classification’). When using a linear kernel, each feature corresponds to the coupling strength between two regions, which, in the fourth step, enables a mechanistic interpretation of feature weights in the context of the underlying model (see Section ‘Interpretation of the feature space’). Here, the influence of A on B and C were jointly most informative in distinguishing between groups. For a concrete implementation of this procedure, see <xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2</xref>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g001" xlink:type="simple"/>
        </fig>
        <p><italic>Generative models</italic> have proven powerful in explaining how observed data are caused by the underlying (neuronal) system. Unlike their discriminative counterparts, generative models capture the joint probability of the observed data and the class labels, governed by a set of parameters of a postulated generative process. One example in neuroimaging is <italic>dynamic causal modelling</italic> (DCM) <xref ref-type="bibr" rid="pcbi.1002079-Friston3">[45]</xref>. DCM enables statistical inference on physiological quantities that are not directly observable with current methods, such as directed interregional coupling strengths and their modulation, e.g., by synaptic gating <xref ref-type="bibr" rid="pcbi.1002079-Stephan1">[46]</xref>. (We use the term <italic>DCM</italic> to refer both to a specific dynamic causal model and to dynamic causal modelling as a method.) From a pathophysiological perspective, disturbances of synaptic plasticity and neuromodulation are at the heart of psychiatric spectrum diseases such as schizophrenia <xref ref-type="bibr" rid="pcbi.1002079-Stephan2">[47]</xref> or depression <xref ref-type="bibr" rid="pcbi.1002079-Castren1">[48]</xref>. It is therefore likely that classification of disease states could benefit from exploiting estimates of these quantities. While DCM is a natural (and presently the only) candidate for obtaining model-based estimates of synaptic plasticity (cf. <xref ref-type="bibr" rid="pcbi.1002079-Stephan1">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-denOuden1">[49]</xref>), the most widely used approach to classification relies on <italic>discriminative methods</italic>, such as support vector machines (SVMs) <xref ref-type="bibr" rid="pcbi.1002079-Mller1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Schlkopf1">[51]</xref>. Together, DCM and SVM methods thus represent natural building blocks for classification of disease states.</p>
        <p>Generative embedding represents a special case of using <italic>generative kernels</italic> for classification, such as the <italic>P</italic>-kernel <xref ref-type="bibr" rid="pcbi.1002079-Haussler1">[52]</xref> or the Fisher kernel <xref ref-type="bibr" rid="pcbi.1002079-Jaakkola1">[53]</xref>. Generative kernels have been fruitfully exploited in a range of applications <xref ref-type="bibr" rid="pcbi.1002079-Bicego1">[54]</xref>–<xref ref-type="bibr" rid="pcbi.1002079-Hofmann1">[66]</xref> and define an active area of research <xref ref-type="bibr" rid="pcbi.1002079-Minka1">[67]</xref>–<xref ref-type="bibr" rid="pcbi.1002079-Martins1">[70]</xref>. In the special case of generative embedding, a generative kernel is used to construct a <italic>generative score space</italic>. This is a model-based feature space in which the original observations have been replaced by statistical representations that potentially yield better class separability when fed into a discriminative classifier. Thus, an unsupervised embedding step is followed by a supervised classification step. In previous work, we suggested a concrete implementation of this approach for the trial-by-trial classification of electrophysiological recordings <xref ref-type="bibr" rid="pcbi.1002079-Brodersen1">[61]</xref>. In this paper, we propose a DCM-based generative-embedding approach for subject-by-subject classification of fMRI data, demonstrate its performance using a clinical data set, and highlight potential methodological pitfalls (and how to avoid them).</p>
        <p>DCM <xref ref-type="bibr" rid="pcbi.1002079-Friston3">[45]</xref> views the brain as a nonlinear dynamical system of interconnected neuronal populations whose directed connection strengths are modulated by external perturbations (i.e., experimental conditions) or endogenous activity. Here, we will use DCM to replace high-dimensional fMRI time series by a low-dimensional vector of parameter estimates. The discriminative part of our approach will be based on an SVM with a linear kernel. This algorithm learns to discriminate between two groups of subjects by estimating a separating hyperplane in their feature space. Since this paper brings together techniques from different statistical domains that tend to be used by different communities, we have tried to adopt a tutorial-like style and introduce basic concepts of either approach in the <xref ref-type="sec" rid="s2">Methods</xref> section.</p>
        <p>Generative embedding for fMRI may offer three substantial advantages over conventional classification methods. First, because the approach aims to fuse the strengths of generative models with those of discriminative methods, it may outperform conventional voxel-based schemes, especially in those cases where crucial discriminative information is encoded in ‘hidden’ quantities such as directed (synaptic) connection strengths. Second, the construction of the feature space is governed and constrained by a biologically motivated systems model. As a result, feature weights can be interpreted mechanistically in the context of this model. Incidentally, the curse of dimensionality faced by many conventional feature-extraction methods may turn into a blessing when using generative embedding: the higher the temporal and spatial resolution of the fMRI data, the more precise the estimation of the parameters of the generative model, leading to better discriminability. Third, our approach can be used to compare alternative generative model architectures in situations where evidence-based approaches, such as Bayesian model selection, are not applicable. We will deal with these three points in more detail in the <xref ref-type="sec" rid="s4">Discussion</xref>.</p>
      </sec>
      <sec id="s1c">
        <title>Structure of this paper</title>
        <p>The remainder of this paper is structured as follows. First, we summarize the general ideas of generative embedding and the specific generative and discriminative components used here, i.e., DCM and SVM. We then inspect different procedures of how generative embedding could be implemented practically while distinguishing between approaches with and without bias. Third, we illustrate the utility of our approach, using empirical data obtained during speech processing in healthy volunteers and patients with moderate aphasia. These data have been explored in a previous study, in which DCM and Bayesian model selection (BMS) were applied to investigate the effective connectivity among cortical areas activated by intelligible speech <xref ref-type="bibr" rid="pcbi.1002079-Leff1">[71]</xref>. In a subsequent study, we extended this analysis to patients with aphasia (Schofield et al., <italic>in preparation</italic>). In the present paper, we ask whether subject-specific directed connection strengths among cortical regions involved in speech processing contain sufficiently rich discriminative information to enable accurate predictions of the diagnostic category (healthy or aphasic) of a previously unseen individual. In brief, we found that (i) generative embedding yielded a near-perfect classification accuracy, (ii) significantly outperformed conventional ‘gold standard’ activation-based and correlation-based classification schemes, and (iii) afforded a novel mechanistic interpretation of the differences between aphasic patients and healthy controls during processing of speech and speech-like sounds.</p>
      </sec>
    </sec>
    <sec id="s2" sec-type="methods">
      <title>Methods</title>
      <sec id="s2a">
        <title>Ethics statement</title>
        <p>The study was approved by the local research ethics committee at UCL, and all participants gave informed consent.</p>
      </sec>
      <sec id="s2b">
        <title>Combining generative models and discriminative methods</title>
        <p>Most methods for classification attempt to find a linear function that separates examples as accurately as possible in a space of features (e.g., voxel-wise measurements). Such <italic>discriminative</italic> classification methods differ from <italic>generative</italic> methods in two ways. First, rather than trying to estimate the joint density of observations and class labels, which is not needed for classification, or trying to estimate class-conditional probability densities, which can be difficult, discriminative classifiers directly model the class an example belongs to. Second, many discriminative methods do not operate on examples themselves but are based on the similarity between any two examples, expressed as the inner product between their feature vectors. This provides an elegant way of transforming a linear classifier into a more powerful nonlinear one. (Note that the term <italic>discriminative methods</italic> is used here to collectively describe the class of learning algorithms that find a <italic>discriminant function</italic> for mapping an example <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e009" xlink:type="simple"/></inline-formula> onto a class label <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e010" xlink:type="simple"/></inline-formula>, typically without invoking probability theory. This is in contrast to <italic>discriminative models,</italic> which model the conditional probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e011" xlink:type="simple"/></inline-formula>, and <italic>generative models,</italic> which first model the full joint probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e012" xlink:type="simple"/></inline-formula> and then derive <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e013" xlink:type="simple"/></inline-formula>.)</p>
        <p>The most popular classification algorithm of the above kind is the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e014" xlink:type="simple"/></inline-formula>-norm soft-margin support vector machine (SVM) <xref ref-type="bibr" rid="pcbi.1002079-Mller1">[50]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Schlkopf1">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Boser1">[72]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-BenHur1">[73]</xref>. The only way in which examples <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e015" xlink:type="simple"/></inline-formula> enter an SVM is in terms of an inner product <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e016" xlink:type="simple"/></inline-formula>. This product can be replaced by the evaluation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e017" xlink:type="simple"/></inline-formula> of a <italic>kernel function</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e018" xlink:type="simple"/></inline-formula>, which implicitly computes the inner product between the examples in a new feature space, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e019" xlink:type="simple"/></inline-formula>.</p>
        <p>The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e020" xlink:type="simple"/></inline-formula>-norm SVM is a natural choice when the goal is maximal prediction accuracy. However, it usually leads to a dense solution (as opposed to a sparse solution) in which almost all features are used for classification. This is suboptimal when one wishes to understand which model parameters contribute most to distinguishing groups, which will be the focus in the Section ‘Interpretation of the feature space.’ In this case, an SVM that enforces <italic>feature sparsity</italic> may be more useful. One simple way of inducing sparsity is to penalize the number of non-zero coefficients by using an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e021" xlink:type="simple"/></inline-formula>-regularizer. Unlike other regularizers, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e022" xlink:type="simple"/></inline-formula>-norm (also known as the <italic>counting norm</italic>) reduces the feature-selection bias inherent in unbounded regularizers such as the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e023" xlink:type="simple"/></inline-formula>- or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e024" xlink:type="simple"/></inline-formula>-norm. The computational cost of optimizing an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e025" xlink:type="simple"/></inline-formula>-SVM objective function is prohibitive, because the number of subsets of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e026" xlink:type="simple"/></inline-formula> items which are of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e027" xlink:type="simple"/></inline-formula> is exponential in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e028" xlink:type="simple"/></inline-formula>. We therefore replace the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e029" xlink:type="simple"/></inline-formula>-norm by a capped <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e030" xlink:type="simple"/></inline-formula>-regularizer which has very similar properties <xref ref-type="bibr" rid="pcbi.1002079-Zhang1">[74]</xref>. One way of solving the resulting optimization problem is to use a bilinear programming approach <xref ref-type="bibr" rid="pcbi.1002079-Peleg1">[75]</xref>. Here, we use a more efficient difference-of-convex-functions algorithm (Ong &amp; Thi, <italic>under review</italic>).</p>
        <p>In summary, we will use two types of SVM. For the purpose of classification (Section ‘Classification’), we aim to maximize the potential for highly accurate predictions by using an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e031" xlink:type="simple"/></inline-formula>-norm SVM. For the purpose of feature selection and interpretation (Section ‘Interpretation of the feature space’), we will focus on feature sparsity by using an approximation to an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e032" xlink:type="simple"/></inline-formula>-norm SVM, which will highlight those DCM parameters jointly deemed most informative in distinguishing between groups.</p>
        <p>Most current applications of classification algorithms in neuroimaging begin by embedding the measured recordings of each subject in a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e033" xlink:type="simple"/></inline-formula>-dimensional Euclidean space <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e034" xlink:type="simple"/></inline-formula>. In fMRI, for example, a subject can be represented by a vector of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e035" xlink:type="simple"/></inline-formula> features, each of which corresponds to the signal measured in a particular voxel at a particular point in time. This approach makes it possible to use any learning algorithm that expects vectorial input, such as an SVM; but it ignores the spatio-temporal structure of the data as well as the process that generated them. This limitation has motivated the search for kernel methods that provide a more natural way of measuring the similarity between the functional datasets of two subjects, for example by incorporating prior knowledge about how the data were generated, which has led to the idea of <italic>generative kernels</italic>, as described below.</p>
        <p>Generative kernels are functions that define a similarity metric for observed examples using a generative model. In the case of a dynamic causal model (DCM), for example, the observed time series are modelled by a system of parameterized differential equations with Gaussian observation noise. Generative embedding defines a generative kernel by transferring the models into a vectorial feature space in which an appropriate similarity metric is defined (see <xref ref-type="fig" rid="pcbi-1002079-g001">Figure 1</xref>). This feature space, which we will refer to as a <italic>generative score space,</italic> embodies a model-guided dimensionality reduction of the observed data. The kernel defined in this space could be a simple inner product of feature vectors, or it could be based on any other higher-order function, as long as it is positive definite <xref ref-type="bibr" rid="pcbi.1002079-Mercer1">[76]</xref>. In conclusion, model-based classification via generative embedding is a hybrid generative-discriminative approach: it merges the explanatory abilities of generative models with the classification power of discriminative methods.</p>
        <p>The specific implementation for fMRI data proposed in this paper consists of four conceptual steps which are summarized in <xref ref-type="fig" rid="pcbi-1002079-g001">Figure 1</xref> and described in the following subsections. First, a mapping <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e036" xlink:type="simple"/></inline-formula> is designed that projects an example <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e037" xlink:type="simple"/></inline-formula> from data space onto a multivariate probability distribution in a parametric family <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e038" xlink:type="simple"/></inline-formula>. In our case, we use the fMRI data from each subject to estimate the posterior density of the parameters of a DCM (Sections ‘DCM for fMRI’ and ‘Model inversion’). Second, a probability kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e039" xlink:type="simple"/></inline-formula> is constructed that represents a similarity measure between two inverted DCMs. Here, we use a simple linear kernel on the <italic>maximum a posteriori</italic> (MAP) estimates of the model parameters (Sections ‘Strategies for unbiased model specification and inversion’ and ‘Kernel construction’). Third, this kernel is used for training and testing a discriminative classifier (Section ‘Classification’). Here, we employ a linear SVM to distinguish between patients and healthy controls. Fourth, the constructed feature space can be investigated to find out which model parameters jointly contributed most to distinguishing the two groups (Section ‘Interpretation of the feature space’). We will conclude with an example in which we distinguish between patients with moderate aphasia and healthy controls (Sections ‘Experimental design, data acquisition, and preprocessing,’ ‘Implementation of generative embedding,’ and ‘Comparative analyses’).</p>
      </sec>
      <sec id="s2c">
        <title>DCM for fMRI</title>
        <p>DCM regards the brain as a nonlinear dynamic system of interconnected nodes, and an experiment as a designed perturbation of the system's dynamics <xref ref-type="bibr" rid="pcbi.1002079-Friston3">[45]</xref>. Its goal is to provide a mechanistic model for explaining experimental measures of brain activity. While the mathematical formulation of DCMs varies across measurement types, common mechanisms modelled by all DCMs include synaptic connection strengths and experimentally induced modulation thereof <xref ref-type="bibr" rid="pcbi.1002079-Stephan1">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-David1">[77]</xref>–<xref ref-type="bibr" rid="pcbi.1002079-Daunizeau1">[80]</xref>. Generally, DCMs strive for neurobiological interpretability of their parameters; this is one core feature distinguishing them from alternative approaches, such as multivariate autoregressive models <xref ref-type="bibr" rid="pcbi.1002079-Roebroeck1">[81]</xref> which characterize inter-regional connectivity in a phenomenological fashion.</p>
        <p>DCMs consist of two hierarchical layers <xref ref-type="bibr" rid="pcbi.1002079-Stephan3">[82]</xref>. The first layer is a <italic>neuronal model</italic> of the dynamics of interacting neuronal populations in the context of experimental perturbations. Critically, its parameters are neurobiologically interpretable, representing, for example, synaptic weights and their context-specific modulation; electrophysiological DCMs describe even more fine-grained processes such as spike-frequency adaptation or conduction delays. Experimental manipulations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e040" xlink:type="simple"/></inline-formula> enter the model in two different ways: they can elicit responses through direct influences on specific regions (e.g., sensory inputs), or they can modulate the strength of coupling among regions (e.g., task demands or learning). The second layer of a DCM is a biophysically motivated <italic>forward model</italic> that describes how a given neuronal state translates into a measurement. Depending on the measurement modality, this can be a set of nonlinear differential equations (as for fMRI <xref ref-type="bibr" rid="pcbi.1002079-Stephan4">[83]</xref>) or a simple linear equation (as for EEG <xref ref-type="bibr" rid="pcbi.1002079-Kiebel1">[84]</xref>). While the forward model plays a critical role in model inversion, it is the parameters of the neuronal model that are typically of primary scientific interest.</p>
        <p>In this paper, we will use the classical bilinear DCM for fMRI <xref ref-type="bibr" rid="pcbi.1002079-Friston3">[45]</xref> as implemented in the software package SPM8/DCM10,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e041" xlink:type="simple"/><label>(1)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e042" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e043" xlink:type="simple"/></inline-formula> represents the neuronal state vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e044" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e045" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e046" xlink:type="simple"/></inline-formula> is a matrix of endogenous connection strengths, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e047" xlink:type="simple"/></inline-formula> represents the additive change of these connection strengths induced by modulatory input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e048" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e049" xlink:type="simple"/></inline-formula> denotes the strengths of direct (driving) inputs. These neuronal parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e050" xlink:type="simple"/></inline-formula> are rate constants with units <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e051" xlink:type="simple"/></inline-formula>.</p>
        <p>The haemodynamic forward model is given by the function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e052" xlink:type="simple"/></inline-formula>, a nonlinear operator that links a neuronal state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e053" xlink:type="simple"/></inline-formula> to a predicted blood oxygen level dependent (BOLD) signal via changes in vasodilation, blood flow, blood volume, and deoxyhaemoglobin content (see <xref ref-type="bibr" rid="pcbi.1002079-Stephan4">[83]</xref> for details). This forward model has haemodynamic parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e054" xlink:type="simple"/></inline-formula> and Gaussian measurement error <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e055" xlink:type="simple"/></inline-formula>. The haemodynamic parameters primarily serve to account for variations in neurovascular coupling across regions and subjects and are typically not of primary scientific interest. In addition, the haemodynamic parameters exhibit strong inter-dependencies and thus high posterior covariances and low precision <xref ref-type="bibr" rid="pcbi.1002079-Stephan4">[83]</xref>, which makes it difficult to establish the distinct contribution afforded by each parameter. For these reasons, the model-induced feature spaces in this paper will be based exclusively on the neuronal parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e056" xlink:type="simple"/></inline-formula>.</p>
        <p>In summary, DCM provides a mechanistic model for explaining measured time series of brain activity as the outcome of hidden dynamics in an interconnected network of neuronal populations and its experimentally induced perturbations. Inverting such a model (see next section) means to infer the posterior distribution of the parameters of both the neuronal and the forward model from observed responses of a specific subject. Its mechanistic interpretability and applicability to single-subject data makes DCM an attractive candidate for generative embedding of fMRI data.</p>
      </sec>
      <sec id="s2d">
        <title>Model inversion</title>
        <p>Bayesian inversion of a given dynamic causal model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e057" xlink:type="simple"/></inline-formula> defines a map <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e058" xlink:type="simple"/></inline-formula> that projects a given example <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e059" xlink:type="simple"/></inline-formula> (i.e., data from a single subject) onto a multivariate probability distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e060" xlink:type="simple"/></inline-formula> in a parametric family <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e061" xlink:type="simple"/></inline-formula>. The model architecture <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e062" xlink:type="simple"/></inline-formula> specifies the neuronal populations (regions) of interest, experimentally controlled inputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e063" xlink:type="simple"/></inline-formula>, synaptic connections, and a prior distribution over the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e064" xlink:type="simple"/></inline-formula>. Given the model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e065" xlink:type="simple"/></inline-formula> and subject-specific data <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e066" xlink:type="simple"/></inline-formula>, model inversion proceeds in an unsupervised and subject-by-subject fashion, i.e., in ignorance of the subject label that will later be used in the context of classification. (The literature on DCM has adopted the convention of denoting the hidden states by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e067" xlink:type="simple"/></inline-formula> and the data by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e068" xlink:type="simple"/></inline-formula>. Here, in order to keep the notation consistent with the literature on classification, we use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e069" xlink:type="simple"/></inline-formula> for the data and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e070" xlink:type="simple"/></inline-formula> for the labels. A distinct symbol for the hidden states is not required here.) DCM uses a fully Bayesian approach to parameter estimation, with empirical priors for the haemodynamic parameters and conservative shrinkage priors for the coupling parameters <xref ref-type="bibr" rid="pcbi.1002079-Friston4">[85]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Friston3">[45]</xref>. Combining the prior density over the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e071" xlink:type="simple"/></inline-formula> with the likelihood function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e072" xlink:type="simple"/></inline-formula> yields the posterior density <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e073" xlink:type="simple"/></inline-formula>. This inversion can be carried out efficiently by maximizing a variational free-energy bound to the log model evidence, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e074" xlink:type="simple"/></inline-formula>, under Gaussian assumptions about the posterior (the Laplace assumption; see <xref ref-type="bibr" rid="pcbi.1002079-Friston5">[86]</xref> for details). Given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e075" xlink:type="simple"/></inline-formula> parameters, model inversion thus yields a subject-specific probability density <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e076" xlink:type="simple"/></inline-formula> that can be fully described in terms of a vector of posterior means <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e077" xlink:type="simple"/></inline-formula> and a covariance matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e078" xlink:type="simple"/></inline-formula>.</p>
        <p>Model specification and selection is an important theme in DCM <xref ref-type="bibr" rid="pcbi.1002079-Stephan5">[87]</xref>. In this paper we are not concerned with the question of which of several alternative DCMs may be optimal for explaining the data or for classifying subjects; these issues can be addressed using Bayesian evidence methods <xref ref-type="bibr" rid="pcbi.1002079-Stephan6">[88]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Penny1">[89]</xref> or by applying cross-validation to the classifications suggested by each of the models, respectively (see <xref ref-type="bibr" rid="pcbi.1002079-Brodersen1">[61]</xref> for an example). However, an important issue is that model specification cannot be treated in isolation from its subsequent use for classification. Specifically, some procedures for selecting time series can lead to biased estimation of classification accuracy. In the next section, we therefore provide a detailed assessment of different strategies for time series selection in DCM-based generative embedding and highlight those procedures which safeguard against obtaining optimistic estimates of classification performance.</p>
      </sec>
      <sec id="s2e">
        <title>Strategies for unbiased model specification and inversion</title>
        <p>For conventional fMRI classification procedures, good-practice guidelines have been suggested for avoiding an optimistic bias in assessing classification performance <xref ref-type="bibr" rid="pcbi.1002079-OToole1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Pereira1">[10]</xref>. Generally, to obtain an unbiased estimate of generalization accuracy, a classifier must be applied to test data that have not been used during training. In generative embedding, this principle implies that the specification of the generative model cannot be treated in isolation from its use for classification. In this section, we structure different strategies in terms of a decision tree and evaluate the degree of bias they invoke (see <xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2</xref>).</p>
        <fig id="pcbi-1002079-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Strategies for unbiased DCM-based generative embedding.</title>
            <p>This figure illustrates how generative embedding can be implemented using dynamic causal modelling. Depending on whether regions of interest are defined anatomically, based on across-subjects functional contrasts, or based on between-group contrasts, there are several possible practical procedures. Some of these procedures may lead to biased estimates of classification accuracy (grey boxes). Procedures <italic>a</italic>, <italic>c</italic>, and <italic>f</italic> avoid this bias, and are therefore recommended (green boxes). The analysis of the illustrative dataset described in this paper follows procedure <italic>c</italic>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g002" xlink:type="simple"/>
        </fig>
        <p>The first distinction is based on whether the regions of interest (ROIs) underlying the DCM are defined <italic>anatomically</italic> or <italic>functionally</italic>. When ROIs are defined exclusively on the basis of anatomical masks (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2a</xref>), the selection of voxels is independent of the functional data. Using time series from these regions, the model is inverted separately for each subject. Thus, given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e079" xlink:type="simple"/></inline-formula> subjects, a single initial model-specification step is followed by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e080" xlink:type="simple"/></inline-formula> subject-wise model inversions. The resulting parameter estimates can be safely submitted to a cross-validation procedure to obtain an unbiased estimate of classification performance.</p>
        <p>Whenever <italic>functional</italic> contrasts have played a role in defining ROIs, subsequent classification may no longer be unbiased. This is because a functional contrast introduces statistics of the data into voxel selection, which usually generates a bias. In this case, we ask whether contrasts are defined in an <italic>across-subjects</italic> or a <italic>between-groups</italic> fashion. In the case of an across-subjects contrast (which does not take into account group membership), one might be tempted to follow the same logic as in the case of anatomical ROI definitions: a single across-subjects contrast, computed for all subjects, guides the selection of voxels, and the resulting DCM is inverted separately for each subject (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2b</xref>). Unfortunately, this procedure is problematic. When using the resulting parameter estimates in a leave-one-out cross-validation scheme, in every repetition the features would be based on a model with regions determined by a group contrast that was based on the data from all subjects, including the left-out test subject. This means that training the classifier would no longer be independent of the test data, which violates the independence assumption underlying cross-validation, a situation referred to as <italic>peeking</italic> <xref ref-type="bibr" rid="pcbi.1002079-Pereira1">[10]</xref>. In consequence, the resulting generalization estimate may exhibit an optimistic bias. To avoid this bias, model specification must be integrated into cross-validation (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2c</xref>). Specifically, in each fold, we leave out one subject as a test subject and compute an across-subjects group contrast from the remaining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e081" xlink:type="simple"/></inline-formula> subjects. The resulting choice of voxels is then used for specifying time series in each subject and the resulting model is inverted separately for each subject, including the left-out test subject. This procedure is repeated <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e082" xlink:type="simple"/></inline-formula> times, each time leaving out a different subject. In total, the model will be inverted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e083" xlink:type="simple"/></inline-formula> times. In this way, within each cross-validation fold, the selection of voxels is exclusively based on the training data, and no peeking is involved. This is the strategy adopted for the dataset analysed in this paper, as detailed in the Section ‘Implementation of generative embedding’.</p>
        <p>When functional contrasts are not defined <italic>across</italic> all subjects but <italic>between</italic> groups, the effect of peeking may become particularly severe. Using a between-groups contrast to define regions of interest on the basis of all available data, and using these regions to invert the model for each subject (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2d</xref>) would introduce information about group membership into the process of voxel selection. Thus, feature selection for both training and test data would be influenced by both the data and the label of the left-out test subject. One way of decreasing the resulting bias is to integrate model specification into cross-validation (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2e</xref>). In this procedure, the between-groups contrast is computed separately for each training set (i.e., based on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e084" xlink:type="simple"/></inline-formula> subjects), and the resulting regions are used to invert the model for the test subject. This means that the class label of the test subject is no longer involved in selecting features for the test subject. However, the test label continues to influence the features of the training set, since these are based on contrasts defined for a group that included the test subject. This bias can only be removed by adopting the same laborious procedure as with across-subjects contrasts: by using a between-groups contrast involving <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e085" xlink:type="simple"/></inline-formula> subjects, inverting the resulting model separately for each subject, and repeating this procedure <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e086" xlink:type="simple"/></inline-formula> times (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2f</xref>). This procedure guarantees that neither the training procedure nor the features selected for the test subject were influenced by the data or the label of the test subject.</p>
        <p>In summary, the above analysis shows that there are three practical strategies for the implementation of generative embedding that yield an unbiased cross-validated accuracy estimate. If regions are defined anatomically, the model is inverted separately for each subject, and the resulting parameter estimates can be safely used in cross-validation (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2a</xref>). Otherwise, if regions are defined by a functional contrast, both the definition of ROIs and model inversion for all subjects need to be carried out separately for each cross-validation fold (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2c,f</xref>).</p>
      </sec>
      <sec id="s2f">
        <title>Kernel construction</title>
        <p>Given a set of inverted subject-specific generative models, the kernel defines the similarity metric under which these models are assessed within a discriminative classifier. In generative embedding, the choice of an appropriate kernel depends on the definition of the generative score space. A straightforward way to create a Euclidean vector space from an inverted DCM is to consider the posterior means or <italic>maximum a posteriori</italic> (MAP) estimates of model parameters of interest (e.g., parameters encoding synaptic connection strengths). More formally, we can define a mapping <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e087" xlink:type="simple"/></inline-formula> that extracts a subset of MAP estimates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e088" xlink:type="simple"/></inline-formula> from the posterior distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e089" xlink:type="simple"/></inline-formula>. This simple <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e090" xlink:type="simple"/></inline-formula>-dimensional vector space expresses discriminative information encoded in the connection strengths between regions, as opposed to activity levels within these regions. Alternatively, one could also incorporate elements of the posterior covariance matrix into the vector space. This would be beneficial if class differences were revealed by the precision with which connection strengths can be estimated from the data.</p>
        <p>Once a generative score space has been created, any conventional kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e091" xlink:type="simple"/></inline-formula> can be used to compare two inverted models. The simplest one is the linear kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e092" xlink:type="simple"/></inline-formula>, representing the inner product between two vectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e093" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e094" xlink:type="simple"/></inline-formula>. Nonlinear kernels, such as quadratic, polynomial or radial basis function kernels, transform the generative score space, which makes it possible to consider quadratic (or higher-order) class boundaries and therefore account for possible interactions between features. Nonlinear kernels, however, have several disadvantages for generative embedding. As the complexity of the kernel increases, so does the risk of overfitting. Furthermore, feature weights are easiest to interpret in relation to the underlying model when they do not undergo further transformation; then, the contribution of a particular feature (i.e., model parameter) to the success of the classifier can be understood as the degree to which the neuronal mechanism represented by that parameter aids classification. A simple linear kernel will therefore be our preferred choice.</p>
        <p>In summary, in this paper, we define a mapping <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e095" xlink:type="simple"/></inline-formula> from a subject-specific posterior distribution of model parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e096" xlink:type="simple"/></inline-formula> to a feature vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e097" xlink:type="simple"/></inline-formula>. We then use a linear kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e098" xlink:type="simple"/></inline-formula> for this model-based feature space. Together, these two steps define a probability kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e099" xlink:type="simple"/></inline-formula> that represents a similarity metric between two inverted models and allows for mechanistic interpretations of how group membership of different subjects is encoded by spatiotemporal fMRI data.</p>
      </sec>
      <sec id="s2g">
        <title>Classification</title>
        <p>While a kernel describes how two subjects can be compared using a generative model of their fMRI data, it does not specify how such a comparison could be used for making predictions. This gap is filled by discriminative classification methods. As described in the Section ‘Combining generative models and discriminative methods’, a natural choice is the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e100" xlink:type="simple"/></inline-formula>-norm soft-margin support vector machine (SVM), which currently represents the most widely used kernel method for classification <xref ref-type="bibr" rid="pcbi.1002079-Boser1">[72]</xref>.</p>
        <p>An estimate of classification performance with minimal variance can be obtained by leave-one-out cross-validation. In each fold, the classifier is trained on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e101" xlink:type="simple"/></inline-formula> subjects and tested on the left-out one. Using the training set only, the SVM can be fine-tuned by carrying out a simple line search over the regularization hyperparameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e102" xlink:type="simple"/></inline-formula> (Eqn. 1), a procedure known as nested cross-validation <xref ref-type="bibr" rid="pcbi.1002079-Stone1">[90]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Cawley1">[91]</xref>.</p>
        <p>There are many ways of assessing the generalization performance of a classifier. Here, we are primarily interested in the <italic>balanced accuracy</italic>, that is, the mean accuracy obtained on either class,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e103" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e104" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e105" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e106" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e107" xlink:type="simple"/></inline-formula> represent the number of true positives, false positives, true negatives, and false negatives, respectively <xref ref-type="bibr" rid="pcbi.1002079-Brodersen2">[92]</xref>. The balanced accuracy represents the arithmetic mean between sensitivity and specificity. If the classifier performs equally well on either class, it reduces to the ordinary accuracy (i.e., the ratio of correct predictions to all predictions). If, however, the classifier has taken advantage of an imbalanced dataset, then the ordinary accuracy will be inflated, whereas the balanced accuracy will drop to chance (50%), as desired. The balanced accuracy thus removes the bias from estimates of generalizability that may arise in the presence of imbalanced datasets. A probability interval can be computed by considering the convolution of two Beta-distributed random variables that correspond to the true accuracies on positive and negative examples, respectively. A <italic>p</italic>-value can then be obtained by computing the posterior probability of the accuracy being below chance <xref ref-type="bibr" rid="pcbi.1002079-Brodersen2">[92]</xref>.</p>
      </sec>
      <sec id="s2h">
        <title>Interpretation of the feature space</title>
        <p>Most classification algorithms can not only be used for making predictions and obtaining an estimate of their generalization error; they can also be used to quantify how much each feature has contributed to classification performance. Such <italic>feature weights</italic> can sometimes be of greater interest than the classification accuracy itself. In the case of a generative score space, as defined above, each feature is associated with a neurobiologically interpretable model parameter. Provided there are no complex transformations of feature weights (see above), they can be interpreted in the context of the underlying model.</p>
        <p>As described in the Section ‘Combining generative models and discriminative methods’, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e108" xlink:type="simple"/></inline-formula>-norm soft-margin SVM is a natural choice when the goal is maximal prediction accuracy. However, its solution usually implies that almost all features are used for classification. This is suboptimal when one wishes to understand which model parameters, and thus mechanisms, contribute most to distinguishing groups. Therefore, for the purposes of interpreting the model-induced feature space, we use an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e109" xlink:type="simple"/></inline-formula>-regularizer. This approach allows us to characterize the feature space by counting how often a particular feature has been selected in leave-one-out cross-validation.</p>
      </sec>
      <sec id="s2i">
        <title>Experimental design, data acquisition, and preprocessing</title>
        <p>In order to illustrate the utility of generative embedding for fMRI, we used data from two groups of participants (patients with moderate aphasia vs. healthy controls) engaged in a simple speech-processing task. The conventional SPM and DCM analyses of these data are published elsewhere; we refer to <xref ref-type="bibr" rid="pcbi.1002079-Leff1">[71]</xref> and Schofield et al. (<italic>in preparation</italic>) for detailed descriptions of all experimental procedures.</p>
        <p>The two groups of subjects consisted of 26 right-handed healthy participants with normal hearing, English as their first language, and no history of neurological disease (12 female; mean age 54.1 years; range 26–72 years); and 11 patients diagnosed with moderate aphasia due to stroke (1 female; mean age 66.1; range 45–90 years). The patients' aphasia profile was characterized using the Comprehensive Aphasia Test <xref ref-type="bibr" rid="pcbi.1002079-Swinburn1">[93]</xref>. As a group, they had scores in the aphasic range for: spoken and written word comprehension (single word and sentence level), single word repetition and object naming. It is important to emphasize that the lesions did not affect any of the temporal regions which we included in our model described below (see Schofield et al., <italic>in preparation</italic>, for detailed information on lesion localization).</p>
        <p>Subjects were presented with two types of auditory stimulus: (i) normal speech; and (ii) time-reversed speech, which is unintelligible but retains both speaker identity and the spectral complexity of normal speech. Subjects were given an incidental task, to make a gender judgment on each auditory stimulus, which they indicated with a button press.</p>
        <p>Functional T2*-weighted echo-planar images (EPI) with BOLD contrast were acquired using a Siemens Sonata 1.5 T scanner (in-plane resolution 3 mm×3 mm; slice thickness 2 mm; inter-slice gap 1 mm; TR 3.15 s). In total, 122 volumes were recorded in each of 4 consecutive sessions. In addition, a T1-weighted anatomical image was acquired. Following realignment and unwarping of the functional images, the mean functional image of each subject was coregistered to its high-resolution structural image. This image was spatially normalized to standard Montreal Neurological Institute (MNI152) space, and the resulting deformation field was applied to the functional data. These data were then spatially smoothed using an isotropic Gaussian kernel (FWHM 8 mm). In previous work, these data have been analysed using a conventional general linear model (GLM) and DCM; the results are described in Schofield et al. (<italic>in preparation</italic>). Here, we re-examined the dataset using the procedure shown in <xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2c</xref>, as described in detail in the next subsection.</p>
      </sec>
      <sec id="s2j">
        <title>Implementation of generative embedding</title>
        <sec id="s2j1">
          <title>First-level analysis</title>
          <p>The first level of our statistical analysis employed a mass-univariate analysis in each subject. Each auditory stimulus was modelled as a separate delta function, and the resulting trains of auditory events were convolved with a canonical haemodynamic response function. The first regressor in the design matrix contained all auditory events (i.e., normal and time-reversed speech stimuli); the second regressor modelled intelligibility (normal vs. time-reversed speech) as a parametric modulation. Beta coefficients were estimated for all brain voxels using the general linear model <xref ref-type="bibr" rid="pcbi.1002079-Friston1">[1]</xref>. To identify regions responding to auditory stimulation per se, we used an ‘all auditory events’ contrast based on the first regressor (i.e., a contrast between auditory stimuli and background scanner noise), designed to find early auditory regions required for the perception of any broad-band stimulus, whether it is speech or speech-like.</p>
        </sec>
        <sec id="s2j2">
          <title>Second-level (group) analysis</title>
          <p>The second level analysis served to select regions whose voxels entered the subject-specific DCMs (in terms of the first eigenvariate of their time series). In the previous study of these data (Schofield et al., <italic>in preparation</italic>), we had compared a set of 512 alternative DCMs that embodied competing hypotheses about the architecture of the thalamo-temporal network processing speech-like stimuli per se. Here, we focus on the model which was found to have the highest evidence in our previous study, i.e., the model providing the best trade-off between accuracy and complexity in explaining the data <xref ref-type="bibr" rid="pcbi.1002079-Raftery1">[94]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Stephan4">[83]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Stephan6">[88]</xref>. Note that this selection procedure is ignorant of subject labels, which prevents test labels from influencing the training procedure. (An alternative, computationally more expensive approach would be to select the model that affords the best classification accuracy, and integrate this selection step into an overall cross-validation scheme. See <xref ref-type="bibr" rid="pcbi.1002079-Brodersen1">[61]</xref> for an example.) In addition, the selection of time series remains independent of the test data. The DCM we used contains 6 regions (medial geniculate body, MGB; Heschl's gyrus, HG; planum temporale, PT), three in each hemisphere, and 14 interregional connections (see <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>). Note that this model concerned processing of acoustic stimuli with speech-like spectral properties <italic>per se</italic>, not differentiating between normal and time-reversed speech; therefore, it did not contain modulatory inputs (corresponding to an empty <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e110" xlink:type="simple"/></inline-formula> matrix, see Eqn. 4). Critically, instead of identifying regions functionally by a group contrast, we pre-defined large anatomical masks (16 mm×16 mm×16 mm) that specified only the rough location of the 6 regions of interest (see <xref ref-type="table" rid="pcbi-1002079-t001">Table 1</xref> and Supplementary Material). These masks served to guide the selection of time series, using a leave-one-out approach to feature selection as described below.</p>
          <fig id="pcbi-1002079-g003" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g003</object-id>
            <label>Figure 3</label>
            <caption>
              <title>Dynamic causal model of speech processing.</title>
              <p>The diagram illustrates the specific dynamic causal model (DCM) that was used for the illustrative application of generative embedding in this study. It consists of 6 regions (circles), 15 interregional connections (straight arrows between regions), 6 self-connections (circular arrows), and 2 stimulus inputs (straight arrows at the bottom). The specific set of connections shown here is the result of Bayesian model selection that was carried out on the basis of a large set of competing connectivity layouts (for details, see Schofield et al., <italic>in preparation</italic>). A sparse set of 9 out of 23 connectivity and input parameters (see <xref ref-type="fig" rid="pcbi-1002079-g010">Figure 10</xref>) was found to be sufficiently informative to distinguish between aphasic patients and healthy controls with near-perfect accuracy (see <xref ref-type="fig" rid="pcbi-1002079-g005">Figure 5</xref>). The connections corresponding to these 9 parameters are highlighted in red. Only three parameters were selected in all cross-validation folds and are thus particularly meaningful for classification (bold red arrows); these refer to connections mediating information transfer from the right to the left hemisphere, converging on left PT, which is a key structure in speech processing.</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g003" xlink:type="simple"/>
          </fig>
          <table-wrap id="pcbi-1002079-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.t001</object-id><label>Table 1</label><caption>
              <title>Regions of interest.</title>
            </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1002079-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.t001" xlink:type="simple"/><table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" colspan="2" rowspan="1">Region</td>
                  <td align="left" colspan="1" rowspan="1">MNI coordinates</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" colspan="1" rowspan="1">L.MGB</td>
                  <td align="left" colspan="1" rowspan="1">left medial geniculate body</td>
                  <td align="left" colspan="1" rowspan="1">−23 mm, −23 mm, −1 mm</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">L.HG</td>
                  <td align="left" colspan="1" rowspan="1">left Heschl's gyrus (A1)</td>
                  <td align="left" colspan="1" rowspan="1">−47 mm, −26 mm, 7 mm</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">L.PT</td>
                  <td align="left" colspan="1" rowspan="1">left planum temporale</td>
                  <td align="left" colspan="1" rowspan="1">−64 mm, −23 mm, 8 mm</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">R.MGB</td>
                  <td align="left" colspan="1" rowspan="1">right medial geniculate body</td>
                  <td align="left" colspan="1" rowspan="1">22 mm, −21 mm, −1 mm</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">R.HG</td>
                  <td align="left" colspan="1" rowspan="1">right Heschl's gyrus (A1)</td>
                  <td align="left" colspan="1" rowspan="1">48 mm, −24 mm, 6 mm</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">R.PT</td>
                  <td align="left" colspan="1" rowspan="1">right planum temporale</td>
                  <td align="left" colspan="1" rowspan="1">65 mm, −22 mm, 3 mm</td>
                </tr>
              </tbody>
            </table></alternatives><table-wrap-foot>
              <fn id="nt101">
                <label/>
                <p>Speech processing can be modelled using a dynamic causal model (DCM) with 6 regions. The table lists the central coordinates of these regions in MNI152 space. These coordinates define the centre of the rough anatomical masks (16 mm×16 mm×16 mm) that guided the specification of the exact location and extent of the regions of interest underlying model inversion (see Section ‘Implementation of generative embedding’). For an illustration of these masks, see <xref ref-type="supplementary-material" rid="pcbi.1002079.s001">Figure S1</xref> in the Supplementary Material.</p>
              </fn>
            </table-wrap-foot></table-wrap>
        </sec>
        <sec id="s2j3">
          <title>Model specification</title>
          <p>To specify the exact location and extent of our 6 regions of interest, and thus the exact time series that would be modelled by DCM, we used a leave-one-out approach to feature selection. For this purpose, we carried out <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e111" xlink:type="simple"/></inline-formula> separate second-level analyses, each time leaving out one subject, and then used a conventional summary-statistic approach <xref ref-type="bibr" rid="pcbi.1002079-Friston6">[95]</xref> across the remaining <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e112" xlink:type="simple"/></inline-formula> subjects to find voxels that survived a one-sample ‘all auditory events’ t-test with a statistical threshold of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e113" xlink:type="simple"/></inline-formula> (uncorrected), across all subjects, within the anatomical masks described above. Note that this contrast is agnostic about diagnostic status (corresponding to <xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2c</xref>). (With the cross-validation scheme used here, a between-group contrast could have been used as well without risking bias; see Section ‘Strategies for unbiased model specification and inversion’. This case would correspond to <xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2f</xref>.) Within each leave-one-out repetition, our procedure yielded 6 voxel sets, one for each region of interest. We used the first eigenvariate over voxels as a representative time series for each region in DCM.</p>
        </sec>
        <sec id="s2j4">
          <title>Model inversion</title>
          <p>Inversion of the DCM was carried out independently for each subject, and separately for each cross-validation fold (i.e., each group contrast). With regions (and thus modelled time series) differing each time depending on the current set of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e114" xlink:type="simple"/></inline-formula> subjects, this procedure resulted in a total of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e115" xlink:type="simple"/></inline-formula> fitted DCMs. We emphasize once more that model inversion was carried out in an unsupervised fashion, i.e., without reference to the subjects' diagnostic status.</p>
        </sec>
        <sec id="s2j5">
          <title>Kernel construction</title>
          <p>A generative score space was constructed on the basis of the MAP estimates of the neuronal model parameters (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e116" xlink:type="simple"/></inline-formula> in Eqn. 5). The rzzesulting space contained 22 features: 20 interregional connection strengths (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e117" xlink:type="simple"/></inline-formula> matrix), no modulatory parameters (as the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e118" xlink:type="simple"/></inline-formula> matrix was empty in the DCM we used), and 2 input parameters (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e119" xlink:type="simple"/></inline-formula> matrix). All feature vectors were normalized to unit length. To minimize the risk of overfitting and enable a clear interpretation of feature weights, we used a linear kernel. Consequently, the similarity between two subjects was defined as the inner product between the normalized vectors of the posterior means of their model parameters.</p>
        </sec>
        <sec id="s2j6">
          <title>Classification</title>
          <p>An <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e120" xlink:type="simple"/></inline-formula>-norm soft-margin linear support vector machine (SVM) was trained and tested using leave-one-out cross-validation. Specifically, in each fold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e121" xlink:type="simple"/></inline-formula>, the classifier was trained on all subjects except <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e122" xlink:type="simple"/></inline-formula>, on the basis of the DCM parameter estimates obtained from fitting the voxel time series selected by the group analysis based on all subjects except <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e123" xlink:type="simple"/></inline-formula>. The classifier was then tested by applying it to DCM parameter estimates for the time series from subject <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e124" xlink:type="simple"/></inline-formula> (using the same voxels as the rest of the group). Crucially, in this way, test data and test labels were neither used for model specification nor for classifier training, preventing optimistic estimates of classification performance. The principles of this unbiased procedure are summarized in <xref ref-type="fig" rid="pcbi-1002079-g004">Figure 4</xref>.</p>
          <fig id="pcbi-1002079-g004" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g004</object-id>
            <label>Figure 4</label>
            <caption>
              <title>Practical implementation of generative embedding for fMRI.</title>
              <p>This figure summarizes the three core steps involved in the practical implementation of generative embedding proposed in this paper. This procedure integrates the inversion of a generative model into cross-validation. In step 1, within a given repetition <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e125" xlink:type="simple"/></inline-formula>, the model is specified using all subjects except <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e126" xlink:type="simple"/></inline-formula>. This yields a set of time series <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e127" xlink:type="simple"/></inline-formula> for each subject <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e128" xlink:type="simple"/></inline-formula>. In step 2, the model is inverted independently for each subject, giving rise to a set of subject-specific posterior parameter means <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e129" xlink:type="simple"/></inline-formula>. In step 3, these parameter estimates are used to train a classifier on all subjects except <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e130" xlink:type="simple"/></inline-formula> and test it on subject <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e131" xlink:type="simple"/></inline-formula>, which yields a prediction about the class label of subject <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e132" xlink:type="simple"/></inline-formula>. After having repeated these three steps for all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e133" xlink:type="simple"/></inline-formula>, the set of predicted labels can be compared with the true labels, which allows us to estimate the algorithm's generalization performance. In addition, parameters that proved jointly discriminative can be interpreted in the context of the underlying generative model. The sequence of steps shown here corresponds to the procedure shown in <xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2c and 2f</xref>, where it is contrasted with alternative procedures that are simpler but risk an optimistic bias in estimating generalization performance.</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g004" xlink:type="simple"/>
          </fig>
          <p>Within each fold, the complexity penalty <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e134" xlink:type="simple"/></inline-formula> of the SVM was selected by a line search in log<sub>2</sub> space, to minimize an estimate of the generalization error on the training set (nested cross-validation). To discourage the classifier from acquiring a bias in favour of the majority class, the training set was balanced using a stochastic oversampling strategy. We assessed the generalization performance of the classifier by comparing its <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e135" xlink:type="simple"/></inline-formula> predictions to the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e136" xlink:type="simple"/></inline-formula> true subject labels (‘patient’ or ‘healthy control’), resulting in a 2×2 confusion matrix that forms the basis of various common performance measures, such as the accuracy or the area under the receiver-operator characteristic (ROC) curve.</p>
        </sec>
      </sec>
      <sec id="s2k">
        <title>Comparative analyses</title>
        <p>We compared the performance of generative embedding to a range of alternative approaches. To begin with, we examined several conventional activation-based classification schemes. The first method was based on a feature space composed of all voxels within the predefined anatomical masks used for guiding the specification of the DCMs. As above, we used a linear SVM, and all training sets were balanced by oversampling. We will refer to this approach as <italic>anatomical feature selection</italic>.</p>
        <p>The second method, in contrast to the first one, was not only based on the same classifier as in generative embedding but also used exactly the same voxels. Specifically, voxels were selected on the basis of the same ‘all auditory events’ contrast as above, which is a common approach to defining a voxel-based feature space in subject-by-subject classification <xref ref-type="bibr" rid="pcbi.1002079-Ford1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fan1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Pereira1">[10]</xref>. In every cross-validation fold, only those voxels entered the classifier that survived a t-test (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e137" xlink:type="simple"/></inline-formula>, uncorrected) in the current set of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e138" xlink:type="simple"/></inline-formula> subjects. Training sets were balanced by oversampling. We will refer to this method as <italic>contrast feature selection</italic>.</p>
        <p>The third activation-based method employed a locally multivariate ‘searchlight’ strategy for feature selection. Specifically, in each cross-validation fold, a searchlight sphere (radius 4 mm) was passed across all voxels contained in the anatomical masks described above <xref ref-type="bibr" rid="pcbi.1002079-Kriegeskorte1">[23]</xref>. Using the training set only, a nested leave-one-out cross-validation scheme was used to estimate the generalization performance of each sphere using a linear SVM with a fixed regularization hyperparameter (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e139" xlink:type="simple"/></inline-formula>). Next, all spheres with an accuracy greater than 75% were used to form the feature space for the current outer cross-validation fold, which corresponds to selecting all voxels whose local neighbourhoods allowed for a significant discrimination between patients and healthy controls at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e140" xlink:type="simple"/></inline-formula>. Both outer and inner training sets were balanced by oversampling. We will refer to this method as <italic>searchlight feature selection</italic>. To illustrate the location of the most informative voxels, we carried out an additional searchlight analysis, based on the entire dataset as opposed to a subset of size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e141" xlink:type="simple"/></inline-formula>, and used the results to generate a discriminative map (see <xref ref-type="supplementary-material" rid="pcbi.1002079.s001">Figure S1</xref> in the Supplementary Material).</p>
        <p>The fourth conventional method was based on a principal component analysis (PCA) to reduce the dimensionality of the feature space constructed from all voxels in the anatomical masks described above. Unlike generative embedding, PCA-based dimensionality reduction finds a linear manifold in the data without a mechanistic view of how those data might have been generated. We sorted all principal components in decreasing order of explained variance. By retaining the 22 top components, the resulting dimensionality matched the dimensionality of the feature space used in generative embedding.</p>
        <p>In addition to the above activation-based methods, we compared generative embedding to several approaches based on undirected regional correlations. We began by averaging the activity within each region of interest to obtain region-specific representative time series. We then computed pairwise correlation coefficients to obtain a 15-dimensional feature space of functional connectivity. Next, instead of computing spatial averages, we summarized the activity within each region in terms of the first eigenvariate. Thus, in this approach, the exact same data was used to estimate functional connectivity as was used by DCM to infer effective connectivity. Finally, as suggested in <xref ref-type="bibr" rid="pcbi.1002079-Craddock1">[43]</xref>, we created yet another feature space by transforming the correlation coefficients on eigenvariates into z-scores using the Fisher transformation <xref ref-type="bibr" rid="pcbi.1002079-Fisher1">[96]</xref>.</p>
        <p>In addition to conventional activation- and correlation-based approaches, we also investigated the dependence of generative embedding on the structure of the underlying model. Specifically, we repeated our original analysis on the basis of three alternative models. For the first model, we constructed a <italic>feedforward</italic> system by depriving the original model of all feedback and interhemispheric connections (<xref ref-type="fig" rid="pcbi-1002079-g005">Figure 5a</xref>); while this model could still, in principle, explain neuronal dynamics throughout the system of interest, it was neurobiologically less plausible. For the second and third model, we kept all connections from the original model but modelled either only the <italic>left hemisphere</italic> (<xref ref-type="fig" rid="pcbi-1002079-g005">Figure 5b</xref>) or only the <italic>right hemisphere</italic> (<xref ref-type="fig" rid="pcbi-1002079-g005">Figure 5c</xref>).</p>
        <fig id="pcbi-1002079-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Biologically unlikely alternative models.</title>
            <p>To illustrate the specificity of generative embedding, the analysis described in the main text was repeated on the basis of three biologically less plausible models. In contrast to the full model shown in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>, these alternative models either (a) contained no feedback or interhemispheric connections, (b) accounted for activity in the left hemisphere only, or (c) focussed exclusively on the right hemisphere. For results, see <xref ref-type="table" rid="pcbi-1002079-t002">Table 2</xref> and <xref ref-type="fig" rid="pcbi-1002079-g006">Figure 6</xref>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g005" xlink:type="simple"/>
        </fig>
        <p>In summary, we compared the primary approach proposed in this paper to 4 conventional activation-based methods, 3 conventional correlation-based methods, and 3 generative-embedding analyses using reduced and biologically less plausible models.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <sec id="s3a">
        <title>Classification performance</title>
        <p>The classification performance of generative embedding was evaluated using the procedure described in <xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2c</xref>. This procedure was compared to several conventional activation-based and correlation-based approaches. As an additional control, generative embedding was carried out on the basis of three biologically ill-informed models. In all cases, a leave-one-subject-out cross-validation scheme was used to obtain the posterior distribution of the balanced accuracy <xref ref-type="bibr" rid="pcbi.1002079-Brodersen2">[92]</xref> as well as smooth estimates of the underlying receiver-operating characteristic (ROC) and precision-recall (PC) curves <xref ref-type="bibr" rid="pcbi.1002079-Brodersen3">[97]</xref>. Results are presented in <xref ref-type="table" rid="pcbi-1002079-t002">Table 2</xref> and <xref ref-type="fig" rid="pcbi-1002079-g006">Figure 6</xref>.</p>
        <fig id="pcbi-1002079-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Classification performance.</title>
            <p>Classification based on generative embedding using the model shown in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref> was compared to ten alternative methods: anatomical feature selection, contrast feature selection, searchlight feature selection, PCA-based dimensionality reduction, regional correlations based on region means, regional correlations based on eigenvariates, regional z-transformed correlations based on eigenvariates, as well as generative embedding using three biologically unlikely alternative models (see inset legends for abbreviations). (a) The balanced accuracy and its central 95% posterior probability interval show that all methods performed significantly better than chance (50%) with the exception of classification with anatomical feature selection and generative embedding using a nonsensical model. Differences between activation-based methods (light grey) and correlation-based methods (dark grey) were largely statistically indistinguishable. By contrast, using the full model shown in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>, generative embedding (blue) significantly outperformed all other methods, except when used with biologically unlikely models (<xref ref-type="fig" rid="pcbi-1002079-g005">Figure 5</xref>). (b) Receiver-operating characteristic (ROC) curves of the eleven methods illustrate the trade-off between true positive rate (sensitivity) and false positive rate (1 – specificity) across the entire range of detection thresholds. A larger area under the curve is better. (c) Precision-recall (PR) curves illustrate the trade-off between positive prediction value (precision) and true positive rate (recall). A larger area under the curve is better. Smooth ROC and PR curves were obtained using a binormal assumption on the underlying decision values <xref ref-type="bibr" rid="pcbi.1002079-Brodersen3">[97]</xref>. For a numerical summary of all results, see <xref ref-type="table" rid="pcbi-1002079-t002">Table 2</xref>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g006" xlink:type="simple"/>
        </fig>
        <table-wrap id="pcbi-1002079-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.t002</object-id><label>Table 2</label><caption>
            <title>Classification results.</title>
          </caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1002079-t002-2" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.t002" xlink:type="simple"/><table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" colspan="1" rowspan="1">Measure (<italic>n</italic> = 37)</td>
                <td align="left" colspan="1" rowspan="1">Anatomical feature selection</td>
                <td align="left" colspan="1" rowspan="1">Contrast feature selection</td>
                <td align="left" colspan="1" rowspan="1">Searchlight feature selection</td>
                <td align="left" colspan="1" rowspan="1">PCA-based dimensionality reduction</td>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" colspan="1" rowspan="1">(1) Accuracy</td>
                <td align="left" colspan="1" rowspan="1">0.649</td>
                <td align="left" colspan="1" rowspan="1">0.757</td>
                <td align="left" colspan="1" rowspan="1">0.730</td>
                <td align="left" colspan="1" rowspan="1">0.865</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">(2) Balanced accuracy</td>
                <td align="left" colspan="1" rowspan="1">0.619</td>
                <td align="left" colspan="1" rowspan="1">0.748</td>
                <td align="left" colspan="1" rowspan="1">0.729</td>
                <td align="left" colspan="1" rowspan="1">0.799</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">(3) Significantly above chance</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>≈0.089</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>≈0.003</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>≈0.006</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>&lt;0.001</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">(4) True positive rate (TPR; sensitivity; recall)</td>
                <td align="left" colspan="1" rowspan="1">0.545</td>
                <td align="left" colspan="1" rowspan="1">0.727</td>
                <td align="left" colspan="1" rowspan="1">0.727</td>
                <td align="left" colspan="1" rowspan="1">0.636</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">(5) True negative rate (TNR; specificity)</td>
                <td align="left" colspan="1" rowspan="1">0.692</td>
                <td align="left" colspan="1" rowspan="1">0.769</td>
                <td align="left" colspan="1" rowspan="1">0.731</td>
                <td align="left" colspan="1" rowspan="1">0.962</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">(6) Positive predictive value (PPV; precision)</td>
                <td align="left" colspan="1" rowspan="1">0.429</td>
                <td align="left" colspan="1" rowspan="1">0.571</td>
                <td align="left" colspan="1" rowspan="1">0.533</td>
                <td align="left" colspan="1" rowspan="1">0.875</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">(7) Negative predictive value (NPV)</td>
                <td align="left" colspan="1" rowspan="1">0.783</td>
                <td align="left" colspan="1" rowspan="1">0.870</td>
                <td align="left" colspan="1" rowspan="1">0.864</td>
                <td align="left" colspan="1" rowspan="1">0.862</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">(8) Area under the ROC curve (AUC)</td>
                <td align="left" colspan="1" rowspan="1">0.657</td>
                <td align="left" colspan="1" rowspan="1">0.829</td>
                <td align="left" colspan="1" rowspan="1">0.794</td>
                <td align="left" colspan="1" rowspan="1">0.846</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">(9) Area under the PR curve (average precision)</td>
                <td align="left" colspan="1" rowspan="1">0.756</td>
                <td align="left" colspan="1" rowspan="1">0.854</td>
                <td align="left" colspan="1" rowspan="1">0.842</td>
                <td align="left" colspan="1" rowspan="1">0.885</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>…</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Region-means correlations</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Eigenvariates correlations</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Eigenvariates z-correlations</bold>
                </td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.730</td>
                <td align="left" colspan="1" rowspan="1">0.865</td>
                <td align="left" colspan="1" rowspan="1">0.784</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.703</td>
                <td align="left" colspan="1" rowspan="1">0.825</td>
                <td align="left" colspan="1" rowspan="1">0.741</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>≈0.011</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>&lt;0.001</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>≈0.002</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.636</td>
                <td align="left" colspan="1" rowspan="1">0.727</td>
                <td align="left" colspan="1" rowspan="1">0.636</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.769</td>
                <td align="left" colspan="1" rowspan="1">0.923</td>
                <td align="left" colspan="1" rowspan="1">0.846</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.538</td>
                <td align="left" colspan="1" rowspan="1">0.800</td>
                <td align="left" colspan="1" rowspan="1">0.636</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.833</td>
                <td align="left" colspan="1" rowspan="1">0.889</td>
                <td align="left" colspan="1" rowspan="1">0.846</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.804</td>
                <td align="left" colspan="1" rowspan="1">0.958</td>
                <td align="left" colspan="1" rowspan="1">0.857</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.873</td>
                <td align="left" colspan="1" rowspan="1">0.945</td>
                <td align="left" colspan="1" rowspan="1">0.914</td>
                <td align="left" colspan="1" rowspan="1"/>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1">
                  <bold>…</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Generative embedding (full model)</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Generative embedding (feedforward model)</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Generative embedding (left hemisphere)</bold>
                </td>
                <td align="left" colspan="1" rowspan="1">
                  <bold>Generative embedding (right hemisphere)</bold>
                </td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.973</td>
                <td align="left" colspan="1" rowspan="1">0.784</td>
                <td align="left" colspan="1" rowspan="1">0.838</td>
                <td align="left" colspan="1" rowspan="1">0.649</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.981</td>
                <td align="left" colspan="1" rowspan="1">0.767</td>
                <td align="left" colspan="1" rowspan="1">0.806</td>
                <td align="left" colspan="1" rowspan="1">0.593</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>&lt;0.001</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>≈0.001</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>&lt;0.001</td>
                <td align="left" colspan="1" rowspan="1"><italic>p</italic>≈0.134</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">1.000</td>
                <td align="left" colspan="1" rowspan="1">0.727</td>
                <td align="left" colspan="1" rowspan="1">0.727</td>
                <td align="left" colspan="1" rowspan="1">0.455</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.962</td>
                <td align="left" colspan="1" rowspan="1">0.808</td>
                <td align="left" colspan="1" rowspan="1">0.885</td>
                <td align="left" colspan="1" rowspan="1">0.731</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.917</td>
                <td align="left" colspan="1" rowspan="1">0.615</td>
                <td align="left" colspan="1" rowspan="1">0.727</td>
                <td align="left" colspan="1" rowspan="1">0.417</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">1.000</td>
                <td align="left" colspan="1" rowspan="1">0.875</td>
                <td align="left" colspan="1" rowspan="1">0.885</td>
                <td align="left" colspan="1" rowspan="1">0.760</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.990</td>
                <td align="left" colspan="1" rowspan="1">0.867</td>
                <td align="left" colspan="1" rowspan="1">0.923</td>
                <td align="left" colspan="1" rowspan="1">0.706</td>
              </tr>
              <tr>
                <td align="left" colspan="1" rowspan="1"/>
                <td align="left" colspan="1" rowspan="1">0.957</td>
                <td align="left" colspan="1" rowspan="1">0.916</td>
                <td align="left" colspan="1" rowspan="1">0.934</td>
                <td align="left" colspan="1" rowspan="1">0.803</td>
              </tr>
            </tbody>
          </table></alternatives><table-wrap-foot>
            <fn id="nt102">
              <label/>
              <p>This table contrasts the classification results obtained through generative embedding with those afforded by three conventional methods. As described in the main text, the underlying dataset serves illustrative purposes, and so, due to its small sample size (<italic>n</italic> = 37), all numbers are associated with considerable uncertainty. The measure of primary interest is the balanced accuracy (2). Its uncertainty can be captured by computing a posterior probability interval (as shown in <xref ref-type="fig" rid="pcbi-1002079-g006">Figure 6a</xref>), or by computing a <italic>p</italic>-value (3), which represents the probability with which the observed performance would have been obtained by chance.</p>
            </fn>
          </table-wrap-foot></table-wrap>
        <p>The strongest classification performance was obtained when using generative embedding with the full model shown in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>. The approach correctly associated 36 out of 37 subjects with their true disease state, corresponding to a balanced accuracy of 98%. Regarding conventional activation-based methods, classification based on anatomical feature selection did not perform significantly above chance (balanced accuracy 62%, <italic>p</italic>≈0.089). Contrast feature selection (75%, <italic>p</italic>≈0.003), searchlight feature selection (73%, <italic>p</italic>≈0.006), and PCA-based dimensionality reduction (80%, <italic>p</italic>&lt;0.001) did perform significantly above chance; however, all methods were outperformed significantly by generative embedding (<italic>p</italic>≈0.003, <italic>p</italic>≈0.001, and <italic>p</italic>≈0.045, paired-sample Wald test). Regarding conventional correlation-based methods, all three approaches performed above chance, whether based on correlations amongst the means (70%, <italic>p</italic>≈0.011), correlations amongst eigenvariates (83%, <italic>p</italic>&lt;0.001), or z-transformed correlations amongst eigenvariates (74%, <italic>p</italic>≈0.002). Critically, however, all were significantly outperformed by generative embedding (<italic>p</italic>&lt;0.001, <italic>p</italic>≈0.045, <italic>p</italic>≈0.006). Regarding generative embedding itself, when replacing the original model shown in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref> by a biologically less plausible feedforward model (<xref ref-type="fig" rid="pcbi-1002079-g005">Figure 5a</xref>) or by a model that captured the left hemisphere only (<xref ref-type="fig" rid="pcbi-1002079-g005">Figure 5b</xref>), we observed a significant decrease in performance, from 98% down to 77% (<italic>p</italic>≈0.002) and 81% (<italic>p</italic>≈0.008), respectively, although both accuracies remained significantly above chance (<italic>p</italic>≈0.001 and <italic>p</italic>&lt;0.001). By contrast, when modelling the right hemisphere only (<xref ref-type="fig" rid="pcbi-1002079-g005">Figure 5c</xref>), performance dropped to a level indistinguishable from chance (59.3%, <italic>p</italic>≈0.134).</p>
        <p>In order to provide a better intuition as to how the generative model shown in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref> created a score space in which examples were much better separated than in the original voxel-based feature space, we produced two scatter plots of the data (see <xref ref-type="fig" rid="pcbi-1002079-g007">Figure 7</xref>). The first plot is based on the peak voxels of the three most discriminative clusters among all regions of interest, evaluated by a searchlight classification analysis. The second plot, by analogy, is based on the three most discriminative model parameters, as measured by two-sample t-tests in the (normalized) generative score space. This illustration shows how the voxel-based projection (left) leads to classes that still overlap considerably, whereas the model-based projection (right) provides an almost perfectly linear separation of patients and controls.</p>
        <fig id="pcbi-1002079-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Induction of a generative score space.</title>
            <p>This figure provides an intuition of how a generative model transforms the data from a voxel-based feature space into a generative score space (or model-based feature space), in which classes become more separable. The left plot shows how aphasic patients (red) and healthy controls (grey) are represented in voxel space, based on t-scores from a simple ‘all auditory events’ contrast (see main text). The three axes represent the peaks of those three clusters that showed the strongest discriminability between patients and controls, based on a locally multivariate searchlight classification analysis. They are located in L.PT, L.HG, and R.PT, respectively (cf. <xref ref-type="table" rid="pcbi-1002079-t001">Table 1</xref>). The right plot shows the three individually most discriminative parameters (two-sample t-test) in the (normalized) generative score space induced by a dynamic causal model of speech processing (see <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>). The plot illustrates how aphasic patients and healthy controls become almost perfectly linearly separable in the new space. Note that this figure is based on normalized examples (as used by the classifier), which means the marginal densities are not the same as those shown in <xref ref-type="fig" rid="pcbi-1002079-g009">Figure 9</xref> but are exactly those seen by the classifier. A stereogram of the generative score space can be found in the Supplementary Material (<xref ref-type="supplementary-material" rid="pcbi.1002079.s004">Figure S4</xref>).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g007" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s3b">
        <title>Characterization of the feature space</title>
        <p>The low dimensionality of the model-based feature space makes it possible to visualize each example in a radial coordinate system, where each axis corresponds to a particular model parameter (see <xref ref-type="fig" rid="pcbi-1002079-g008">Figure 8</xref>). When using parameters that represent directed connection strengths, this form of visualization is reminiscent of the notion of ‘connectional fingerprints’ for characterizing individual cortical regions <xref ref-type="bibr" rid="pcbi.1002079-Passingham1">[98]</xref>. In our case, there is no immediately obvious visual difference in fingerprints between aphasic patients and healthy controls. On the contrary, the plot gives an impression of the large variability across subjects and suggests that differences might be subtle and possibly jointly encoded in multiple parameters.</p>
        <fig id="pcbi-1002079-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Connectional fingerprints.</title>
            <p>Given the low dimensionality of the model-induced feature space, subjects can be visualized in terms of ‘connectional fingerprints’ <xref ref-type="bibr" rid="pcbi.1002079-Passingham1">[98]</xref> that are based on a simple radial coordinate system in which each axis corresponds to the <italic>maximum a posteriori</italic> (MAP) estimate of a particular model parameter. The plot shows that the difference between aphasic patients (red) and healthy controls (grey) is not immediately obvious, suggesting that it might be subtle and potentially of a distributed nature.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g008" xlink:type="simple"/>
        </fig>
        <p>One way of characterizing the discriminative information encoded in individual model parameters more directly is to estimate class-conditional univariate feature densities (see <xref ref-type="fig" rid="pcbi-1002079-g009">Figure 9</xref>). Here, densities were estimated in a nonparametric way using a Gaussian kernel with an automatically selected bandwidth, making no assumptions about the distributions other than smoothness <xref ref-type="bibr" rid="pcbi.1002079-Scott1">[99]</xref>. While most densities are heavily overlapping, a two-sample t-test revealed significant group differences in four model parameters (denoted by stars in <xref ref-type="fig" rid="pcbi-1002079-g009">Figure 9</xref>): the self-connection of L.HG (parameter 4); the influence that L.HG exerts over L.PT (parameter 5); the influence R.MGB on R.PT (parameter 13); and the influence of R.HG on L.HG (parameter 14). All of these were significant at the 0.001 level while no other parameter survived <italic>p</italic> = 0.05. An extended plot of all bivariate feature distributions, illustrating how well any two features jointly discriminated between patients and healthy controls, can be found in the Supplementary Material (<xref ref-type="supplementary-material" rid="pcbi.1002079.s002">Figure S2</xref>).</p>
        <fig id="pcbi-1002079-g009" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g009</object-id>
          <label>Figure 9</label>
          <caption>
            <title>Univariate feature densities.</title>
            <p>Separately for patients (red) and healthy controls (grey), the figure shows nonparametric estimates of the class-conditional densities of the <italic>maximum a posteriori</italic> (MAP) estimates of model parameters. The estimates themselves are shown as a rug along the x-axis. The results of individual (uncorrected) two-sample t-tests, thresholded at <italic>p</italic> = 0.05, are indicated in the title of each diagram. Three stars (***) correspond to <italic>p</italic>&lt;0.001, indicating that the associated model parameter assumes very different values for patients and controls.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g009" xlink:type="simple"/>
        </fig>
        <p>In order to better understand which DCM parameters jointly enabled the distinction between patients and controls, we examined the frequency with which features were selected in leave-one-out cross-validation when using an SVM with a sparsity-inducing regularizer <xref ref-type="bibr" rid="pcbi.1002079-Peleg1">[75]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Zhang1">[74]</xref> (see <xref ref-type="fig" rid="pcbi-1002079-g010">Figure 10</xref>). We found that the classifier favoured a highly consistent and sparse set of 9 (out of 22) model parameters; the corresponding synaptic connections are highlighted in red in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>. Notably, this 9-dimensional feature space, when used with the original <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e142" xlink:type="simple"/></inline-formula>-norm SVM, yielded the same balanced classification accuracy (98%) as the full 22-dimensional feature space, despite discarding more than two thirds of its dimensions.</p>
        <fig id="pcbi-1002079-g010" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002079.g010</object-id>
          <label>Figure 10</label>
          <caption>
            <title>Discriminative features.</title>
            <p>A support vector machine with a sparsity-inducing regularizer (capped <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e143" xlink:type="simple"/></inline-formula>-regularizer) was trained and tested in a leave-one-out cross-validation scheme, resulting in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e144" xlink:type="simple"/></inline-formula> subsets of selected features. The figure summarizes these subsets by visualizing how often each feature (printed along the y-axis) was selected across the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e145" xlink:type="simple"/></inline-formula> repetitions (given as a fraction on the x-axis). Error bars represent central 95% posterior probability intervals of a Beta distribution with a flat prior over the interval [0, 1]. A group of 9 features was consistently found jointly informative for discriminating between aphasic patients and healthy controls (see main text). An additional figure showing which features were selected in each cross-validation fold can be found in the Supplementary Material (<xref ref-type="supplementary-material" rid="pcbi.1002079.s003">Figure S3</xref>). Crucially, since each feature corresponds to a model parameter that describes one particular interregional connection strength, the group of informative features can be directly related back to the underlying dynamic causal model (see highlighted connections in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.g010" xlink:type="simple"/>
        </fig>
        <p>The above representation disclosed interesting potential mechanisms. For example, discriminative parameters were restricted to cortico-cortical and thalamo-cortical connection strengths, whereas parameters representing auditory inputs to thalamic nuclei did not contribute to the distinction between patients and healthy controls. This finding implies that, as one would expect, low-level processing of auditory stimuli, from brain stem to thalamus, is unimpaired in aphasia and that processing deficiencies are restricted to thalamo-cortical and cortico-cortical networks. In particular, the discriminative connections included the top-down connections from planum temporale to Heschl's gyrus bilaterally; the importance of these connections had also been highlighted by the previous univariate analyses of group-wise DCM parameters in the study by Schofield et al. (<italic>in preparation</italic>). Furthermore, all of the connections from the right to the left hemisphere were informative for group membership, but none of the connections in the reverse direction. This pattern is interesting given the known specialization of the left hemisphere in language and speech processing and previous findings that language-relevant information is transferred from the right hemisphere to the left, but not vice versa <xref ref-type="bibr" rid="pcbi.1002079-Stephan7">[100]</xref>. It implies that aphasia leads to specific changes in connectivity, even in non-lesioned parts of the language network, with a particular effect on inter-hemispheric transfer of speech information. This specificity is seen even more clearly when considering only those three parameters which were selected 100% of the time (i.e., in all cross-validation folds) and are thus particularly meaningful for classification (bold red arrows in <xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>). The associated connections mediate information transfer from the right to the left hemisphere and converge on the left planum temporale which is a critical structure for processing of language and speech <xref ref-type="bibr" rid="pcbi.1002079-Price1">[101]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Dehaene1">[102]</xref>.</p>
        <p>In summary, all selected features represented connectivity parameters (as opposed to stimulus input), their selection was both sparse and highly consistent across resampling repetitions, and their combination was sufficient to afford the same classification accuracy as the full feature set.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <sec id="s4a">
        <title>Perspectives for generative embedding of fMRI data</title>
        <p>Generative embedding for subject-by-subject classification provides three potential advantages over conventional voxel-based methods. The first advantage is that it combines the explanatory strengths of generative models with the classification power of discriminative methods. Thus, in contrast to purely discriminative or purely generative methods, generative embedding is a hybrid approach. It fuses a feature space that captures both the data and their generative process with a classifier that finds the maximum-margin boundary for class separation. Intuitively, this exploits the idea that differences in the generative process between two examples (observations) might provide optimal discriminative information required to enable accurate predictions. In the case of DCM for fMRI, this rationale should pay off whenever the directed connection strengths between brain regions contain more information about a disease state than regional activations or undirected correlations. Indeed, this is what we found in our analyses (cf. <xref ref-type="fig" rid="pcbi-1002079-g006">Figure 6</xref>). Using a DCM-informed data representation might prove particularly relevant in psychiatric disorders, such as schizophrenia or depression, where aberrant effective connectivity and synaptic plasticity are central to the disease process <xref ref-type="bibr" rid="pcbi.1002079-Castren1">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Stephan2">[47]</xref>.</p>
        <p>The second advantage of generative embedding for fMRI is that it enables an intuitive and mechanistic interpretation of features and their weights, an important property not afforded by most conventional classification methods <xref ref-type="bibr" rid="pcbi.1002079-Lao1">[103]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Thomaz1">[104]</xref>. By using parameter estimates from a mechanistically interpretable model for constructing a feature space, the subsequent classification no longer yields ‘black box’ results but allows one to assess the relative importance of different mechanisms for distinguishing groups (e.g., whether or not synaptic plasticity alters the strengths of certain connections in a particular context). Put differently, generative embedding embodies a shift in perspective: rather than representing sequential data in terms of high-dimensional and potentially highly complex trajectories, we are viewing the data in terms of the coefficients of a well-behaved model of system dynamics. Again, this may be of particular importance for clinical applications, as discussed in more detail below. It is also interesting to note that models like DCM, when used in the context of generative embedding, turn the curse of dimensionality faced by conventional classification methods into a blessing: the higher the spatial and temporal resolution of the underlying fMRI data, the more precise the resulting DCM parameter estimates; this in turn should lead to more accurate predictions.</p>
        <p>The third advantage provided by generative embedding is related to model comparison. For any given dataset, there is an infinite number of possible dynamic causal models, differing in the number and location of nodes, in connectivity structure, and in their parameterization (e.g., priors). Competing models can be compared using Bayesian model selection (BMS) <xref ref-type="bibr" rid="pcbi.1002079-Penny1">[89]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Stephan4">[83]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Friston5">[86]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Stephan6">[88]</xref>, where the best model is the one with the highest model evidence, that is, the highest probability of the data given the model <xref ref-type="bibr" rid="pcbi.1002079-MacKay1">[105]</xref>. BMS is a generic approach to distinguish between different models that is grounded in Bayesian probability theory and, when group-specific mechanisms can be mapped onto distinct models, represents a powerful technique for model-based classification in itself. However, there are two scenarios in which BMS is problematic and where classification based on generative embedding may represent a useful alternative <xref ref-type="bibr" rid="pcbi.1002079-Brodersen1">[61]</xref>. First, BMS requires the data to be identical for all competing models. Thus, in the case of current implementations of DCM for fMRI, BMS enables <italic>dynamic</italic> model selection (concerning the parameterization and mathematical form of the model equations) but not <italic>structural</italic> model selection (concerning which regions or nodes should be included in the model). Second, BMS is limited when different groups cannot be mapped onto different model structures, for example when the differences in neuronal mechanisms operate at a finer conceptual scale than can be represented within the chosen modelling framework. In this case, discriminability of subjects may be afforded by differences in (combinations of) parameter estimates under the same model structure (see <xref ref-type="bibr" rid="pcbi.1002079-Allen1">[106]</xref> for a recent example).</p>
        <p>In both these scenarios, the approach proposed in this paper may provide a solution, in that the unsupervised creation of a generative score space can be viewed as a method for biologically informed feature extraction, and the performance of the classifier reflects how much class information is encoded in the model parameters. This view enables a form of model comparison in which the best model is the one that enables the highest classification accuracy. This procedure can be applied even when (i) the underlying data (e.g., the chosen regional fMRI time series) are different, or when (ii) the difference between two models lies exclusively in the pattern of parameter estimates. In this paper, we have illustrated both ideas: <italic>structural</italic> model selection to decide between a full model and two reduced models that disregard one hemisphere; and <italic>dynamic</italic> model selection to distinguish between different groups of subjects under the same model structure.</p>
        <p>In summary, BMS evaluates the goodness of a model with regard to its generalizability for explaining the data, whereas generative embedding evaluates a model in relation to an external criterion, i.e., how well it allows for inference on group membership of any given subject. This difference is important as it highlights that the concept of a ‘good’ model can be based on fundamentally different aspects, and one could imagine scenarios where BMS and generative embedding arrive at opposing results. If, for example, discriminability of groups relies on a small subspace of the data, then one model (which provides a good accuracy-complexity trade-off for most of the data except that subspace) may have higher evidence, but another model that describes this subspace particularly well but is generally worse for the rest of the data may result in better classification performance (cf. our discussion in <xref ref-type="bibr" rid="pcbi.1002079-Allen1">[106]</xref>). We will examine the relation and complementary nature of BMS and generative-embedding approaches in future work.</p>
        <p>As discussed in this paper, there are three valid strategies for the implementation of generative embedding in fMRI that allow for an unbiased estimate of classification accuracy (<xref ref-type="fig" rid="pcbi-1002079-g002">Figure 2</xref>). If regions (and thus time series) are defined anatomically, the model is inverted separately for each subject, and the resulting parameter estimates can be safely used in cross-validation. If regions are defined by a functional contrast, both time series selection and model inversion for all subjects need to be carried out separately for each cross-validation fold. These procedures clearly have higher computational demands than conventional classification techniques, but the subject-wise nature of model inversion means that generative embedding for fMRI can exploit methods for distributed computing and can thus be implemented even for larger numbers of subjects.</p>
      </sec>
      <sec id="s4b">
        <title>Summary of our findings</title>
        <p>In order to demonstrate the utility of generative embedding for fMRI, we acquired and analysed a dataset consisting of 11 aphasic patients and 26 healthy controls. During the experiment, participants were listening to a series of speech and speech-like stimuli. In an initial analysis (Schofield et al., <italic>in preparation</italic>), we designed a dynamic causal model to explain observed activations in 6 auditory regions of interest. Here, we extended this analysis by examining whether patients and healthy controls could be distinguished on the basis of differences in subject-specific generative models. Specifically, we trained and tested a linear support vector machine on subject-wise estimates of connection strengths. This approach delivered two sets of results.</p>
        <p>First, we found strong evidence in favour of the hypothesis that aphasic patients and healthy controls may be distinguished on the basis of differences in the parameters of a generative model alone. Generative embedding did not only yield a near-perfect balanced classification accuracy (98%). It also significantly outperformed conventional activation-based methods, whether they were based on anatomical (62%), contrast (75%), searchlight feature selection (73%), or on a PCA-based dimensionality reduction (80%). Similarly, our approach outperformed conventional correlation-based methods, whether they were based on regional means (70%) or regional eigenvariates (83% and 74%). Furthermore, it is interesting to observe that group separability was reduced considerably when using a less plausible feedforward model (77%). Finally, performance decreased significantly when modelling only the left hemisphere (81%), and it dropped to chance when considering the right hemisphere by itself (60%), which is precisely what one would expect under the view that the left hemisphere is predominantly, but not exclusively, implicated in language processing. Taken together, our findings provide strong support for the central idea of this paper: that critical differences between groups of subjects may be expressed in a highly nonlinear manifold which remains inaccessible by methods relying on activations or undirected correlations, but which can be unlocked by the nonlinear transformation embodied by an appropriate generative model.</p>
        <p>Second, since features correspond to model parameters, our approach allowed us to characterize a subset of features (<xref ref-type="fig" rid="pcbi-1002079-g010">Figure 10</xref>) that can be interpreted in the context of the underlying model (<xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>). This subset showed four remarkable properties. (i) Discriminative parameters were restricted to cortico-cortical and thalamo-cortical connection strengths. On the contrary, parameters representing auditory inputs to thalamic nuclei did not contribute to the distinction between patients and healthy controls. (ii) We observed a high degree of stability across resampling folds. That is, the same 9 (out of 22) features were selected on almost every repetition. (iii) The set of discriminative parameters was found to be sparse, not just within repetitions (which is enforced by the underlying regularizer) but also across repetitions (which is not enforced by the regularizer; see <xref ref-type="supplementary-material" rid="pcbi.1002079.s003">Figure S3</xref> in the Supplementary Material). At the same time, the set was considerably larger than what would be expected from univariate feature-wise t-tests (<xref ref-type="fig" rid="pcbi-1002079-g009">Figure 9</xref>). (iv) The sparse set of discriminative parameters proved sufficient to yield the same balanced classification accuracy (98%) as the full set. These results are consistent with the notion that a distinct mechanism, and thus few parameters, are sufficient to explain differences in processing of speech and speech-like sounds between aphasic patients and healthy controls. In particular, all of the connections from the right to the left hemisphere were informative with regard to group membership, but none of the connections in the reverse direction. This asymmetry resonates with previous findings that language-relevant information is transferred from the right hemisphere to the left, but not vice versa <xref ref-type="bibr" rid="pcbi.1002079-Stephan7">[100]</xref>, and suggests that in aphasia connectivity changes in non-lesioned parts of the language network have particularly pronounced effects on inter-hemispheric transfer of speech information from the (non-dominant) right hemisphere to the (dominant) left hemisphere.</p>
        <p>It is worthwhile briefly commenting on how the present findings relate to those of the original DCM study by Schofield et al. (<italic>in preparation</italic>). Two crucial differences are that the previous study (i) applied Bayesian model averaging to a set of 512 models and (ii) statistically examined each of the resulting average connection strengths in a univariate fashion. They found group differences for most connections, highlighting in particular the top-down connections from planum temporale to primary auditory cortex bilaterally. In our multivariate analysis, these two connections were also amongst the most informative ones for distinguishing patients from controls (<xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>). Schofield et al. also found group differences for interhemispheric connection strengths between left and right Heschl's gyrus, but their univariate approach did not demonstrate any asymmetries. In contrast, our multivariate approach yielded a sparser set of discriminative connections, highlighting the asymmetries of interhemispheric connections described above (<xref ref-type="fig" rid="pcbi-1002079-g003">Figure 3</xref>).</p>
      </sec>
      <sec id="s4c">
        <title>Inference on mechanisms for clinical applications</title>
        <p>The example described in this paper was chosen to illustrate the implementation and use of generative embedding for fMRI. It is important to emphasize that this example does not represent the sort of clinical application that we envisage in the long term. Clearly, there are few diagnostic problems when dealing with aphasia and usually a clinical examination by the physician is sufficient. However, this example is useful for demonstrating the utility of generative embedding since the diagnostic status of each subject is known without doubt and the networks involved in speech processing are well characterized. In the future, we hope that our approach will be useful for addressing clinical problems of high practical relevance, for instance for dissecting psychiatric spectrum disorders, such as schizophrenia, into physiologically defined subgroups <xref ref-type="bibr" rid="pcbi.1002079-Stephan2">[47]</xref>, or for predicting the response of individual patients to specific drugs. While an increasing number of studies have tried to describe neurobiological markers for psychiatric disorders <xref ref-type="bibr" rid="pcbi.1002079-Davatzikos1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Davatzikos2">[107]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Davatzikos3">[108]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Fu1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Misra1">[109]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Nenadic1">[110]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Klppel1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1002079-Klppel2">[15]</xref>, we argue that these studies should be complemented by model-based approaches for inferring biologically plausible mechanisms. Such approaches will be useful in two domains of application: they can be used to decide between competing hypotheses (as in traditional applications of DCM and BMS); and they can harvest the potentially rich discriminative information encoded in aspects of synaptic plasticity or neuromodulation to build classifiers that distinguish between different subtypes of a psychiatric disorder on a physiological basis (using techniques such as generative embedding).</p>
        <p>In the case of the illustrative dataset analysed in this paper, generative embedding yielded stronger classification performance than conventional methods, whether they were based on activations or regional correlations. One might think that this superior ability to accurately classify individual subjects determines the clinical value of the approach. Instead, we wish to argue that its clinical value will ultimately depend on whether patients that share the same symptoms can be differentially treated according to the underlying pathophysiology of the disorder. Generative embedding, using biologically plausible and mechanistically interpretable models, may prove critical in establishing diagnostic classification schemes that distinguish between pathophysiologically distinct subtypes of spectrum diseases and allow for predicting individualized behavioural and pharmacological therapy.</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pcbi.1002079.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.s001" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <p><bold>Further characterization of the voxel-based feature space.</bold> <bold>(</bold>1) Regions of interest. In order to illustrate generative embedding for fMRI, a dynamic causal model was constructed on the basis of 6 anatomical regions of interest. As described in the paper, the exact location of these regions was determined on the basis of an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e146" xlink:type="simple"/></inline-formula> group contrast and hence varied between cross-validation folds. Regions were defined by 16 mm×16 mm×16 mm cubes centred on the group maxima (see <xref ref-type="table" rid="pcbi-1002079-t001">Table 1</xref> in the paper). The figure shows the location and extent of the anatomical masks (green) that were used to define fold-specific DCM regions. (2) Searchlight map. A conventional searchlight analysis <xref ref-type="bibr" rid="pcbi.1002079-Kriegeskorte1">[23]</xref> was carried out to illustrate the degree to which a given voxel and its local spherical environment (radius 4 mm) allowed for a separation between aphasic patients and healthy controls. The map is thresholded at <italic>p</italic> = 0.05 uncorrected and provides a qualitative account of which regions were most informative.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002079.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.s002" xlink:type="simple">
        <label>Figure S2</label>
        <caption>
          <p><bold>Further characterization of the generative score space.</bold> By analogy with the univariate feature densities shown in <xref ref-type="fig" rid="pcbi-1002079-g009">Figure 9</xref>, the discriminative information encoded in simple combinations of model parameters can be illustrated using bivariate scatter plots. The figure indicates how well any two features jointly discriminated between patients and healthy controls. Note that the matrix is symmetric.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002079.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.s003" xlink:type="simple">
        <label>Figure S3</label>
        <caption>
          <p><bold>Feature selection using a sparse SVM.</bold> A support vector machine with a sparsity-inducing regularizer <xref ref-type="bibr" rid="pcbi.1002079-Peleg1">[75]</xref> was used to investigate, based on leave-one-out cross validation, which features were typically selected across the underlying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002079.e147" xlink:type="simple"/></inline-formula> folds. (a) The left figure shows in detail which features were selected in each repetition. For example, when based on all subjects but the first, the classifier selected exactly those 9 features that were selected most of the time; when based on all subjects but the last, a slightly different group of 10 features was favoured. The figure shows that the set of selected features is both sparse and highly consistent across resampling repetitions. As described in the paper, it afforded the same classification accuracy as the full set. (b) The right figure shows the posterior variance of each model parameter, separately for selected and discarded parameters. The data provide no evidence that the algorithm simply selected those parameters that were easier to fit, as would be indicated by a lower posterior variance (two-tailed t-test, <italic>p</italic>≈0.640).</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002079.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002079.s004" xlink:type="simple">
        <label>Figure S4</label>
        <caption>
          <p><bold>Stereogram of the generative score space.</bold> Based on the generative score space illustrated in the paper (see right plot in <xref ref-type="fig" rid="pcbi-1002079-g007">Figure 7</xref>), we here show the same plot from two slightly different angles. Readers are invited to try and focus an imaginary point behind the two plots, or use a stereoscope, to recover a fully three‐dimensional impression.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002079-Friston1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Holmes</surname><given-names>AP</given-names></name><name name-style="western"><surname>Worsley</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Poline</surname><given-names>JP</given-names></name><name name-style="western"><surname>Frith</surname><given-names>CD</given-names></name><etal/></person-group>             <year>1995</year>             <article-title>Statistical parametric maps in functional imaging: A general linear approach.</article-title>             <source>Hum Brain Mapp</source>             <volume>2</volume>             <fpage>189</fpage>             <lpage>210</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Koutsouleris1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koutsouleris</surname><given-names>N</given-names></name><name name-style="western"><surname>Meisenzahl</surname><given-names>EM</given-names></name><name name-style="western"><surname>Davatzikos</surname><given-names>C</given-names></name><name name-style="western"><surname>Bottlender</surname><given-names>R</given-names></name><name name-style="western"><surname>Frodl</surname><given-names>T</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Use of neuroanatomical pattern classification to identify subjects in at-risk mental states of psychosis and predict disease transition.</article-title>             <source>Arch Gen Psychiatry</source>             <volume>66</volume>             <fpage>700</fpage>             <lpage>712</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Fu1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fu</surname><given-names>CH</given-names></name><name name-style="western"><surname>Mourao-Miranda</surname><given-names>J</given-names></name><name name-style="western"><surname>Costafreda</surname><given-names>SG</given-names></name><name name-style="western"><surname>Khanna</surname><given-names>A</given-names></name><name name-style="western"><surname>Marquand</surname><given-names>AF</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Pattern classification of sad facial processing: Toward the development of neurobiological markers in depression.</article-title>             <source>Biol Psychiatry</source>             <volume>63</volume>             <fpage>656</fpage>             <lpage>662</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Shen1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shen</surname><given-names>H</given-names></name><name name-style="western"><surname>Wang</surname><given-names>L</given-names></name><name name-style="western"><surname>Liu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Hu</surname><given-names>D</given-names></name></person-group>             <year>2010</year>             <article-title>Discriminative analysis of resting-state functional connectivity patterns of schizophrenia using low dimensional embedding of fMRI.</article-title>             <source>NeuroImage</source>             <volume>49</volume>             <fpage>3110</fpage>             <lpage>3121</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Wang1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name><name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Bhatt</surname><given-names>P</given-names></name><name name-style="western"><surname>Davatzikos</surname><given-names>C</given-names></name></person-group>             <year>2010</year>             <article-title>High-dimensional pattern regression using machine learning: From medical images to continuous clinical variables.</article-title>             <source>NeuroImage</source>             <volume>50</volume>             <fpage>1519</fpage>             <lpage>1535</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Norman1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Norman</surname><given-names>KA</given-names></name><name name-style="western"><surname>Polyn</surname><given-names>SM</given-names></name><name name-style="western"><surname>Detre</surname><given-names>GJ</given-names></name><name name-style="western"><surname>Haxby</surname><given-names>JV</given-names></name></person-group>             <year>2006</year>             <article-title>Beyond mind-reading: Multi-voxel pattern analysis of fMRI data.</article-title>             <source>Trends Cogn Sci</source>             <volume>10</volume>             <fpage>424</fpage>             <lpage>30</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Haynes1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haynes</surname><given-names>J</given-names></name><name name-style="western"><surname>Rees</surname><given-names>G</given-names></name></person-group>             <year>2006</year>             <article-title>Decoding mental states from brain activity in humans.</article-title>             <source>Nat Rev Neurosci</source>             <volume>7</volume>             <fpage>523</fpage>             <lpage>534</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-OToole1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Toole</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Jiang</surname><given-names>F</given-names></name><name name-style="western"><surname>Abdi</surname><given-names>H</given-names></name><name name-style="western"><surname>Penard</surname><given-names>N</given-names></name><name name-style="western"><surname>Dunlop</surname><given-names>JP</given-names></name><etal/></person-group>             <year>2007</year>             <article-title>Theoretical, statistical, and practical perspectives on pattern-based classification approaches to the analysis of functional neuroimaging data.</article-title>             <source>J Cogn Neurosci</source>             <volume>19</volume>             <fpage>1735</fpage>             <lpage>1752</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Friston2">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name><name name-style="western"><surname>Chu</surname><given-names>C</given-names></name><name name-style="western"><surname>Mourao-Miranda</surname><given-names>J</given-names></name><name name-style="western"><surname>Hulme</surname><given-names>O</given-names></name><name name-style="western"><surname>Rees</surname><given-names>G</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Bayesian decoding of brain images.</article-title>             <source>NeuroImage</source>             <volume>39</volume>             <fpage>181</fpage>             <lpage>205</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Pereira1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pereira</surname><given-names>F</given-names></name><name name-style="western"><surname>Mitchell</surname><given-names>T</given-names></name><name name-style="western"><surname>Botvinick</surname><given-names>M</given-names></name></person-group>             <year>2009</year>             <article-title>Machine learning classifiers and fMRI: A tutorial overview.</article-title>             <source>NeuroImage</source>             <volume>45</volume>             <fpage>S199</fpage>             <lpage>S209</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Ford1">
        <label>11</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ford</surname><given-names>J</given-names></name><name name-style="western"><surname>Farid</surname><given-names>H</given-names></name><name name-style="western"><surname>Makedon</surname><given-names>F</given-names></name><name name-style="western"><surname>Flashman</surname><given-names>LA</given-names></name><name name-style="western"><surname>McAllister</surname><given-names>TW</given-names></name><etal/></person-group>             <year>2003</year>             <article-title>Patient classification of fMRI activation maps.</article-title>             <source>Medical Image Computing and Computer-Assisted Intervention</source>             <publisher-name>MICCAI</publisher-name>             <fpage>58</fpage>             <lpage>65</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Fan1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Rao</surname><given-names>H</given-names></name><name name-style="western"><surname>Hurt</surname><given-names>H</given-names></name><name name-style="western"><surname>Giannetta</surname><given-names>J</given-names></name><name name-style="western"><surname>Korczykowski</surname><given-names>M</given-names></name><etal/></person-group>             <year>2007</year>             <article-title>Multivariate examination of brain abnormality using both structural and functional MRI.</article-title>             <source>NeuroImage</source>             <volume>36</volume>             <fpage>1189</fpage>             <lpage>1199</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Fan2">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Resnick</surname><given-names>SM</given-names></name><name name-style="western"><surname>Wu</surname><given-names>X</given-names></name><name name-style="western"><surname>Davatzikos</surname><given-names>C</given-names></name></person-group>             <year>2008</year>             <article-title>Structural and functional biomarkers of prodromal Alzheimer's disease: A high-dimensional pattern classification study.</article-title>             <source>NeuroImage</source>             <volume>41</volume>             <fpage>277</fpage>             <lpage>285</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Klppel1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Klöppel</surname><given-names>S</given-names></name><name name-style="western"><surname>Stonnington</surname><given-names>CM</given-names></name><name name-style="western"><surname>Chu</surname><given-names>C</given-names></name><name name-style="western"><surname>Draganski</surname><given-names>B</given-names></name><name name-style="western"><surname>Scahill</surname><given-names>RI</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Automatic classification of MR scans in Alzheimer's disease.</article-title>             <source>Brain</source>             <volume>131</volume>             <fpage>681</fpage>             <lpage>689</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Klppel2">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Klöppel</surname><given-names>S</given-names></name><name name-style="western"><surname>Chu</surname><given-names>C</given-names></name><name name-style="western"><surname>Tan</surname><given-names>GC</given-names></name><name name-style="western"><surname>Draganski</surname><given-names>B</given-names></name><name name-style="western"><surname>Johnson</surname><given-names>H</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Automatic detection of preclinical neurodegeneration: Presymptomatic Huntington disease.</article-title>             <source>Neurology</source>             <volume>72</volume>             <fpage>426</fpage>             <lpage>431</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Yoon1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yoon</surname><given-names>JH</given-names></name><name name-style="western"><surname>Tamir</surname><given-names>D</given-names></name><name name-style="western"><surname>Minzenberg</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Ragland</surname><given-names>JD</given-names></name><name name-style="western"><surname>Ursu</surname><given-names>S</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Multivariate pattern analysis of functional magnetic resonance imaging data reveals deficits in distributed representations in schizophrenia.</article-title>             <source>Biol Psychiatry</source>             <volume>64</volume>             <fpage>1035</fpage>             <lpage>1041</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Fan3">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Gur</surname><given-names>RE</given-names></name><name name-style="western"><surname>Gur</surname><given-names>RC</given-names></name><name name-style="western"><surname>Wu</surname><given-names>X</given-names></name><name name-style="western"><surname>Shen</surname><given-names>D</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Unaffected family members and schizophrenia patients share brain structure patterns: A high-dimensional pattern classification study.</article-title>             <source>Biol Psychiatry</source>             <volume>63</volume>             <fpage>118</fpage>             <lpage>124</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Haynes2">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haynes</surname><given-names>J</given-names></name><name name-style="western"><surname>Rees</surname><given-names>G</given-names></name></person-group>             <year>2005</year>             <article-title>Predicting the orientation of invisible stimuli from activity in human primary visual cortex.</article-title>             <source>Nat Neurosci</source>             <volume>8</volume>             <fpage>686</fpage>             <lpage>691</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Kamitani1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kamitani</surname><given-names>Y</given-names></name><name name-style="western"><surname>Tong</surname><given-names>F</given-names></name></person-group>             <year>2005</year>             <article-title>Decoding the visual and subjective contents of the human brain.</article-title>             <source>Nat Neurosci</source>             <volume>8</volume>             <fpage>679</fpage>             <lpage>685</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Cox1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cox</surname><given-names>DD</given-names></name><name name-style="western"><surname>Savoy</surname><given-names>RL</given-names></name></person-group>             <year>2003</year>             <article-title>Functional magnetic resonance imaging (fMRI) “brain reading”: Detecting and classifying distributed patterns of fMRI activity in human visual cortex.</article-title>             <source>NeuroImage</source>             <volume>19</volume>             <fpage>261</fpage>             <lpage>270</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Serences1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Serences</surname><given-names>JT</given-names></name><name name-style="western"><surname>Boynton</surname><given-names>GM</given-names></name></person-group>             <year>2007</year>             <article-title>The representation of behavioral choice for motion in human visual cortex.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>12893</fpage>             <lpage>12899</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Davatzikos1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Davatzikos</surname><given-names>C</given-names></name><name name-style="western"><surname>Ruparel</surname><given-names>K</given-names></name><name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Shen</surname><given-names>D</given-names></name><name name-style="western"><surname>Acharyya</surname><given-names>M</given-names></name><etal/></person-group>             <year>2005</year>             <article-title>Classifying spatial patterns of brain activity with machine learning methods: Application to lie detection.</article-title>             <source>NeuroImage</source>             <volume>28</volume>             <fpage>663</fpage>             <lpage>668</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Kriegeskorte1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kriegeskorte</surname><given-names>N</given-names></name><name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name><name name-style="western"><surname>Bandettini</surname><given-names>P</given-names></name></person-group>             <year>2006</year>             <article-title>Information-based functional brain mapping.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>103</volume>             <fpage>3863</fpage>             <lpage>3868</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Haynes3">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haynes</surname><given-names>J</given-names></name><name name-style="western"><surname>Sakai</surname><given-names>K</given-names></name><name name-style="western"><surname>Rees</surname><given-names>G</given-names></name><name name-style="western"><surname>Gilbert</surname><given-names>S</given-names></name><name name-style="western"><surname>Frith</surname><given-names>C</given-names></name><etal/></person-group>             <year>2007</year>             <article-title>Reading hidden intentions in the human brain.</article-title>             <source>Curr Biol</source>             <volume>17</volume>             <fpage>323</fpage>             <lpage>328</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-MouraoMiranda1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mourao-Miranda</surname><given-names>J</given-names></name><name name-style="western"><surname>Bokde</surname><given-names>A</given-names></name><name name-style="western"><surname>Born</surname><given-names>C</given-names></name><name name-style="western"><surname>Hampel</surname><given-names>H</given-names></name><name name-style="western"><surname>Stetter</surname><given-names>M</given-names></name></person-group>             <year>2005</year>             <article-title>Classifying brain states and determining the discriminating activation patterns: Support vector machine on functional MRI data.</article-title>             <source>NeuroImage</source>             <volume>28</volume>             <fpage>980</fpage>             <lpage>995</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Soon1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Soon</surname><given-names>C</given-names></name><name name-style="western"><surname>Namburi</surname><given-names>P</given-names></name><name name-style="western"><surname>Goh</surname><given-names>C</given-names></name><name name-style="western"><surname>Chee</surname><given-names>M</given-names></name><name name-style="western"><surname>Haynes</surname><given-names>J</given-names></name></person-group>             <year>2009</year>             <article-title>Surface-based information detection from cortical activity.</article-title>             <source>NeuroImage</source>             <volume>47</volume>             <fpage>S79</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Grosenick1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grosenick</surname><given-names>L</given-names></name><name name-style="western"><surname>Klingenberg</surname><given-names>B</given-names></name><name name-style="western"><surname>Greer</surname><given-names>S</given-names></name><name name-style="western"><surname>Taylor</surname><given-names>J</given-names></name><name name-style="western"><surname>Knutson</surname><given-names>B</given-names></name></person-group>             <year>2009</year>             <article-title>Whole-brain sparse penalized discriminant analysis for predicting choice.</article-title>             <source>NeuroImage</source>             <volume>47</volume>             <fpage>S58</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Kay1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kay</surname><given-names>KN</given-names></name><name name-style="western"><surname>Naselaris</surname><given-names>T</given-names></name><name name-style="western"><surname>Prenger</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name></person-group>             <year>2008</year>             <article-title>Identifying natural images from human brain activity.</article-title>             <source>Nature</source>             <volume>452</volume>             <fpage>352</fpage>             <lpage>355</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Mitchell1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mitchell</surname><given-names>TM</given-names></name><name name-style="western"><surname>Shinkareva</surname><given-names>SV</given-names></name><name name-style="western"><surname>Carlson</surname><given-names>A</given-names></name><name name-style="western"><surname>Chang</surname><given-names>K</given-names></name><name name-style="western"><surname>Malave</surname><given-names>VL</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Predicting human brain activity associated with the meanings of nouns.</article-title>             <source>Science</source>             <volume>320</volume>             <fpage>1191</fpage>             <lpage>1195</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Formisano1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Formisano</surname><given-names>E</given-names></name><name name-style="western"><surname>De Martino</surname><given-names>F</given-names></name><name name-style="western"><surname>Bonte</surname><given-names>M</given-names></name><name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name></person-group>             <year>2008</year>             <article-title>“Who” is saying “what”? Brain-based decoding of human voice and speech.</article-title>             <source>Science</source>             <volume>322</volume>             <fpage>970</fpage>             <lpage>973</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Chu1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chu</surname><given-names>C</given-names></name><name name-style="western"><surname>Ni</surname><given-names>Y</given-names></name><name name-style="western"><surname>Tan</surname><given-names>G</given-names></name><name name-style="western"><surname>Saunders</surname><given-names>CJ</given-names></name><name name-style="western"><surname>Ashburner</surname><given-names>J</given-names></name></person-group>             <year>2011</year>             <article-title>Kernel regression for fMRI pattern prediction.</article-title>             <source>NeuroImage</source>             <volume>56</volume>             <fpage>662</fpage>             <lpage>673</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Valente1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Valente</surname><given-names>G</given-names></name><name name-style="western"><surname>De Martino</surname><given-names>F</given-names></name><name name-style="western"><surname>Esposito</surname><given-names>F</given-names></name><name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name><name name-style="western"><surname>Formisano</surname><given-names>E</given-names></name></person-group>             <year>2011</year>             <article-title>Predicting subject-driven actions and sensory experience in a virtual world with Relevance Vector Machine Regression of fMRI data.</article-title>             <source>NeuroImage</source>             <volume>56</volume>             <fpage>651</fpage>             <lpage>661</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Mitchell2">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mitchell</surname><given-names>TM</given-names></name><name name-style="western"><surname>Hutchinson</surname><given-names>R</given-names></name><name name-style="western"><surname>Just</surname><given-names>MA</given-names></name><name name-style="western"><surname>Niculescu</surname><given-names>RS</given-names></name><name name-style="western"><surname>Pereira</surname><given-names>F</given-names></name><etal/></person-group>             <year>2003</year>             <article-title>Classifying instantaneous cognitive states from fMRI data.</article-title>             <source>AMIA Annu Symp Proc</source>             <volume>2003</volume>             <fpage>465</fpage>             <lpage>469</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Kamitani2">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kamitani</surname><given-names>Y</given-names></name><name name-style="western"><surname>Tong</surname><given-names>F</given-names></name></person-group>             <year>2006</year>             <article-title>Decoding seen and attended motion directions from activity in the human visual cortex.</article-title>             <source>Curr Biol</source>             <volume>16</volume>             <fpage>1096</fpage>             <lpage>1102</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Hampton1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hampton</surname><given-names>AN</given-names></name><name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name></person-group>             <year>2007</year>             <article-title>Decoding the neural substrates of reward-related decision making with functional MRI.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>104</volume>             <fpage>1377</fpage>             <lpage>1382</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Kriegeskorte2">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kriegeskorte</surname><given-names>N</given-names></name><name name-style="western"><surname>Formisano</surname><given-names>E</given-names></name><name name-style="western"><surname>Sorger</surname><given-names>B</given-names></name><name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name></person-group>             <year>2007</year>             <article-title>Individual faces elicit distinct response patterns in human anterior temporal cortex.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>104</volume>             <fpage>20600</fpage>             <lpage>20605</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Grosenick2">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grosenick</surname><given-names>L</given-names></name><name name-style="western"><surname>Greer</surname><given-names>S</given-names></name><name name-style="western"><surname>Knutson</surname><given-names>B</given-names></name></person-group>             <year>2008</year>             <article-title>Interpretable classifiers for fMRI improve prediction of purchases.</article-title>             <source>IEEE Trans Neural Syst Rehabil Eng</source>             <volume>16</volume>             <fpage>539</fpage>             <lpage>548</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Hassabis1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hassabis</surname><given-names>D</given-names></name><name name-style="western"><surname>Chu</surname><given-names>C</given-names></name><name name-style="western"><surname>Rees</surname><given-names>G</given-names></name><name name-style="western"><surname>Weiskopf</surname><given-names>N</given-names></name><name name-style="western"><surname>Molyneux</surname><given-names>PD</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Decoding neuronal ensembles in the human hippocampus.</article-title>             <source>Curr Biol</source>             <volume>19</volume>             <fpage>546</fpage>             <lpage>554</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Howard1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Howard</surname><given-names>JD</given-names></name><name name-style="western"><surname>Plailly</surname><given-names>J</given-names></name><name name-style="western"><surname>Grueschow</surname><given-names>M</given-names></name><name name-style="western"><surname>Haynes</surname><given-names>J</given-names></name><name name-style="western"><surname>Gottfried</surname><given-names>JA</given-names></name></person-group>             <year>2009</year>             <article-title>Odor quality coding and categorization in human posterior piriform cortex.</article-title>             <source>Nat Neurosci</source>             <volume>12</volume>             <fpage>932</fpage>             <lpage>938</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Polyn1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Polyn</surname><given-names>SM</given-names></name><name name-style="western"><surname>Natu</surname><given-names>VS</given-names></name><name name-style="western"><surname>Cohen</surname><given-names>JD</given-names></name><name name-style="western"><surname>Norman</surname><given-names>KA</given-names></name></person-group>             <year>2005</year>             <article-title>Category-specific cortical activity precedes retrieval during memory search.</article-title>             <source>Science</source>             <volume>310</volume>             <fpage>1963</fpage>             <lpage>1966</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Bode1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bode</surname><given-names>S</given-names></name><name name-style="western"><surname>Haynes</surname><given-names>J</given-names></name></person-group>             <year>2009</year>             <article-title>Decoding sequential stages of task preparation in the human brain.</article-title>             <source>NeuroImage</source>             <volume>45</volume>             <fpage>606</fpage>             <lpage>613</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Harrison1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Harrison</surname><given-names>SA</given-names></name><name name-style="western"><surname>Tong</surname><given-names>F</given-names></name></person-group>             <year>2009</year>             <article-title>Decoding reveals the contents of visual working memory in early visual areas.</article-title>             <source>Nature</source>             <volume>458</volume>             <fpage>632</fpage>             <lpage>635</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Craddock1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Craddock</surname><given-names>RC</given-names></name><name name-style="western"><surname>III</surname><given-names>PEH</given-names></name><name name-style="western"><surname>Hu</surname><given-names>XP</given-names></name><name name-style="western"><surname>Mayberg</surname><given-names>HS</given-names></name></person-group>             <year>2009</year>             <article-title>Disease state prediction from resting state functional connectivity.</article-title>             <source>Magn Reson Med</source>             <volume>62</volume>             <fpage>1619</fpage>             <lpage>1628</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-ShaweTaylor1">
        <label>44</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shawe-Taylor</surname><given-names>J</given-names></name><name name-style="western"><surname>Cristianini</surname><given-names>N</given-names></name></person-group>             <year>2004</year>             <article-title>Kernel methods for pattern analysis.</article-title>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Friston3">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Harrison</surname><given-names>L</given-names></name><name name-style="western"><surname>Penny</surname><given-names>W</given-names></name></person-group>             <year>2003</year>             <article-title>Dynamic causal modelling.</article-title>             <source>NeuroImage</source>             <volume>19</volume>             <fpage>1273</fpage>             <lpage>1302</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Stephan1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Kasper</surname><given-names>L</given-names></name><name name-style="western"><surname>Harrison</surname><given-names>LM</given-names></name><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><name name-style="western"><surname>den Ouden</surname><given-names>HE</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>Nonlinear dynamic causal models for fMRI.</article-title>             <source>NeuroImage</source>             <volume>42</volume>             <fpage>649</fpage>             <lpage>662</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Stephan2">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Frith</surname><given-names>CD</given-names></name></person-group>             <year>2009</year>             <article-title>Dysconnection in schizophrenia: From abnormal synaptic plasticity to failures of self-monitoring.</article-title>             <source>Schizophr Bull</source>             <volume>35</volume>             <fpage>509</fpage>             <lpage>527</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Castren1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Castren</surname><given-names>E</given-names></name></person-group>             <year>2005</year>             <article-title>Is mood chemistry?</article-title>             <source>Nat Rev Neurosci</source>             <volume>6</volume>             <fpage>241</fpage>             <lpage>246</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-denOuden1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>den Ouden</surname><given-names>HEM</given-names></name><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><name name-style="western"><surname>Roiser</surname><given-names>J</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name></person-group>             <year>2010</year>             <article-title>Striatal prediction error modulates cortical coupling.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>3210</fpage>             <lpage>3219</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Mller1">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Müller</surname><given-names>KR</given-names></name><name name-style="western"><surname>Mika</surname><given-names>S</given-names></name><name name-style="western"><surname>Ratsch</surname><given-names>G</given-names></name><name name-style="western"><surname>Tsuda</surname><given-names>K</given-names></name><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name></person-group>             <year>2001</year>             <article-title>An introduction to kernel-based learning algorithms.</article-title>             <source>IEEE Trans Neural Netw</source>             <volume>12</volume>             <fpage>181</fpage>             <lpage>201</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Schlkopf1">
        <label>51</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Smola</surname><given-names>AJ</given-names></name></person-group>             <year>2002</year>             <article-title>Learning with kernels: Support vector machines, regularization, optimization, and beyond.</article-title>             <publisher-name>MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Haussler1">
        <label>52</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haussler</surname><given-names>D</given-names></name></person-group>             <year>1999</year>             <article-title>Convolution kernels on discrete structures.</article-title>             <comment>UCSC-CRL-99-10. Available: <ext-link ext-link-type="uri" xlink:href="http://www.cbse.ucsc.edu/sites/default/files/convolutions.pdf" xlink:type="simple">http://www.cbse.ucsc.edu/sites/default/files/convolutions.pdf</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Jaakkola1">
        <label>53</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jaakkola</surname><given-names>TS</given-names></name><name name-style="western"><surname>Haussler</surname><given-names>D</given-names></name></person-group>             <year>1999</year>             <article-title>Exploiting generative models in discriminative classifiers.</article-title>             <source>Advances in Neural Information Processing Systems</source>             <fpage>487</fpage>             <lpage>493</lpage>             <comment>Proceedings of the Tenth Conference on Advances in Neural Information Processing Systems</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Bicego1">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bicego</surname><given-names>M</given-names></name><name name-style="western"><surname>Murino</surname><given-names>V</given-names></name><name name-style="western"><surname>Figueiredo</surname><given-names>MA</given-names></name></person-group>             <year>2004</year>             <article-title>Similarity-based classification of sequences using hidden Markov models.</article-title>             <source>Pattern Recognit</source>             <volume>37</volume>             <fpage>2281</fpage>             <lpage>2291</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Jebara1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jebara</surname><given-names>T</given-names></name><name name-style="western"><surname>Kondor</surname><given-names>R</given-names></name><name name-style="western"><surname>Howard</surname><given-names>A</given-names></name></person-group>             <year>2004</year>             <article-title>Probability product kernels.</article-title>             <source>J Mach Learn Res</source>             <volume>5</volume>             <fpage>844</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Hein1">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hein</surname><given-names>M</given-names></name><name name-style="western"><surname>Bousquet</surname><given-names>O</given-names></name></person-group>             <year>2004</year>             <article-title>Hilbertian metrics and positive definite kernels on probability measures.</article-title>             <source>Proc AI Statistics</source>             <volume>10</volume>             <fpage>136</fpage>             <lpage>143</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Cuturi1">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cuturi</surname><given-names>M</given-names></name><name name-style="western"><surname>Fukumizu</surname><given-names>K</given-names></name><name name-style="western"><surname>Vert</surname><given-names>J</given-names></name></person-group>             <year>2006</year>             <article-title>Semigroup kernels on measures.</article-title>             <source>J Mach Learn Res</source>             <volume>6</volume>             <fpage>1169</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Bosch1">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bosch</surname><given-names>A</given-names></name><name name-style="western"><surname>Zisserman</surname><given-names>A</given-names></name><name name-style="western"><surname>Munoz</surname><given-names>X</given-names></name></person-group>             <year>2006</year>             <article-title>Scene classification via pLSA.</article-title>             <source>Proc ECCV</source>             <volume>4</volume>             <fpage>517</fpage>             <lpage>530</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Bosch2">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bosch</surname><given-names>A</given-names></name><name name-style="western"><surname>Zisserman</surname><given-names>A</given-names></name><name name-style="western"><surname>Pujol</surname><given-names>M</given-names></name><name name-style="western"><surname>Muoz</surname><given-names>X</given-names></name></person-group>             <year>2008</year>             <article-title>Scene classification using a hybrid generative/discriminative approach.</article-title>             <source>IEEE Trans Pattern Anal Mach Intell</source>             <volume>30</volume>             <fpage>712</fpage>             <lpage>727</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Bicego2">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bicego</surname><given-names>M</given-names></name><name name-style="western"><surname>Pekalska</surname><given-names>E</given-names></name><name name-style="western"><surname>Tax</surname><given-names>DM</given-names></name><name name-style="western"><surname>Duin</surname><given-names>RP</given-names></name></person-group>             <year>2009</year>             <article-title>Component-based discriminative classification for hidden Markov models.</article-title>             <source>Pattern Recognit</source>             <volume>42</volume>             <fpage>2637</fpage>             <lpage>2648</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Brodersen1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brodersen</surname><given-names>KH</given-names></name><name name-style="western"><surname>Haiss</surname><given-names>F</given-names></name><name name-style="western"><surname>Ong</surname><given-names>C</given-names></name><name name-style="western"><surname>Jung</surname><given-names>F</given-names></name><name name-style="western"><surname>Tittgemeyer</surname><given-names>M</given-names></name><etal/></person-group>             <year>2011</year>             <article-title>Model-based feature construction for multivariate decoding.</article-title>             <source>NeuroImage</source>             <volume>56</volume>             <fpage>601</fpage>             <lpage>615</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Smith1">
        <label>62</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>N</given-names></name><name name-style="western"><surname>Niranjan</surname><given-names>M</given-names></name></person-group>             <year>2000</year>             <article-title>Data-dependent kernels in SVM classification of speech patterns.</article-title>             <source>Proceedings of the 6th International Conference on Spoken Language Processing Beijing, China</source>             <fpage>297</fpage>             <lpage>300</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Holub1">
        <label>63</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Holub</surname><given-names>AD</given-names></name><name name-style="western"><surname>Welling</surname><given-names>M</given-names></name><name name-style="western"><surname>Perona</surname><given-names>P</given-names></name></person-group>             <year>2005</year>             <article-title>Combining generative models and fisher kernels for object recognition.</article-title>             <source>IEEE International Conference on Computer Vision</source>             <publisher-loc>Los Alamitos, CA, USA</publisher-loc>             <publisher-name>IEEE Computer Society</publisher-name>             <fpage>136</fpage>             <lpage>143</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Jaakkola2">
        <label>64</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jaakkola</surname><given-names>T</given-names></name><name name-style="western"><surname>Diekhans</surname><given-names>M</given-names></name><name name-style="western"><surname>Haussler</surname><given-names>D</given-names></name></person-group>             <year>1999</year>             <article-title>Using the Fisher kernel method to detect remote protein homologies.</article-title>             <source>Proceedings of the 7th International Conference on Intelligent Systems for Molecular Biology</source>             <publisher-name>AAAI Press</publisher-name>             <fpage>149</fpage>             <lpage>158</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Bicego3">
        <label>65</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bicego</surname><given-names>M</given-names></name><name name-style="western"><surname>Cristani</surname><given-names>M</given-names></name><name name-style="western"><surname>Murino</surname><given-names>V</given-names></name><name name-style="western"><surname>Pekalska</surname><given-names>E</given-names></name><name name-style="western"><surname>Duin</surname><given-names>R</given-names></name></person-group>             <year>2009</year>             <article-title>Clustering-based construction of hidden Markov models for generative kernels.</article-title>             <source>Proceedings of the 7th International Conference on Energy Minimization Methods in Computer Vision and Pattern Recognition</source>             <publisher-loc>Heidelberg</publisher-loc>             <publisher-name>Springer-Verlag Berlin</publisher-name>             <fpage>466</fpage>             <lpage>479</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Hofmann1">
        <label>66</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hofmann</surname><given-names>T</given-names></name></person-group>             <year>2000</year>             <article-title>Learning the similarity of documents: An information-geometric approach to document retrieval and categorization.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Solla</surname><given-names>SA</given-names></name><name name-style="western"><surname>Leen</surname><given-names>TK</given-names></name><name name-style="western"><surname>Müller</surname><given-names>KR</given-names></name></person-group>             <source>Advances in Neural Information Processing Systems 12</source>             <publisher-name>MIT Press</publisher-name>             <fpage>914</fpage>             <lpage>920</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Minka1">
        <label>67</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Minka</surname><given-names>T</given-names></name></person-group>             <year>2005</year>             <article-title>Discriminative models, not discriminative training. Microsoft Research.</article-title>             <comment>Available at: <ext-link ext-link-type="uri" xlink:href="ftp://ftp.research.microsoft.com/pub/tr/TR-2005-144.pdf" xlink:type="simple">ftp://ftp.research.microsoft.com/pub/tr/TR-2005-144.pdf</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Lasserre1">
        <label>68</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lasserre</surname><given-names>JA</given-names></name><name name-style="western"><surname>Bishop</surname><given-names>CM</given-names></name><name name-style="western"><surname>Minka</surname><given-names>TP</given-names></name></person-group>             <year>2006</year>             <article-title>Principled hybrids of generative and discriminative models.</article-title>             <source>IEEE Computer Society Conference on Computer Vision and Pattern Recognition</source>             <publisher-loc>Los Alamitos, CA, USA</publisher-loc>             <publisher-name>IEEE Computer Society</publisher-name>             <fpage>87</fpage>             <lpage>94</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Perina1">
        <label>69</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Perina</surname><given-names>A</given-names></name><name name-style="western"><surname>Cristani</surname><given-names>M</given-names></name><name name-style="western"><surname>Castellani</surname><given-names>U</given-names></name><name name-style="western"><surname>Murino</surname><given-names>V</given-names></name><name name-style="western"><surname>Jojic</surname><given-names>N</given-names></name></person-group>             <year>2010</year>             <article-title>A hybrid generative/discriminative classification framework based on free-energy terms.</article-title>             <source>IEEE 12th International Conference on Computer Vision</source>             <publisher-loc>Kyoto, Japan</publisher-loc>             <fpage>2058</fpage>             <lpage>2065</lpage>             <comment>29 Sept-2 Oct 2009;</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Martins1">
        <label>70</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Martins</surname><given-names>A</given-names></name><name name-style="western"><surname>Bicego</surname><given-names>M</given-names></name><name name-style="western"><surname>Murino</surname><given-names>V</given-names></name><name name-style="western"><surname>Aguiar</surname><given-names>P</given-names></name><name name-style="western"><surname>Figueiredo</surname><given-names>M</given-names></name></person-group>             <year>2010</year>             <article-title>Information theoretical kernels for generative embeddings based on Hidden Markov Models.</article-title>             <source>Structural Syntactic and Statistical Pattern Recognition</source>             <publisher-loc>Izmir, Turkey</publisher-loc>             <fpage>463</fpage>             <lpage>472</lpage>             <comment>2010:</comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Leff1">
        <label>71</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Leff</surname><given-names>AP</given-names></name><name name-style="western"><surname>Schofield</surname><given-names>TM</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Crinion</surname><given-names>JT</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><etal/></person-group>             <year>2008</year>             <article-title>The cortical dynamics of intelligible speech.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>13209</fpage>             <lpage>13215</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Boser1">
        <label>72</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Boser</surname><given-names>BE</given-names></name><name name-style="western"><surname>Guyon</surname><given-names>IM</given-names></name><name name-style="western"><surname>Vapnik</surname><given-names>VN</given-names></name></person-group>             <year>1992</year>             <article-title>A training algorithm for optimal margin classifiers.</article-title>             <source>Proceedings of the 5th Annual Workshop on Computational Learning Theory</source>             <fpage>144</fpage>             <lpage>152</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-BenHur1">
        <label>73</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ben-Hur</surname><given-names>A</given-names></name><name name-style="western"><surname>Ong</surname><given-names>CS</given-names></name><name name-style="western"><surname>Sonnenburg</surname><given-names>S</given-names></name><name name-style="western"><surname>Schölkopf</surname><given-names>B</given-names></name><name name-style="western"><surname>Rätsch</surname><given-names>G</given-names></name></person-group>             <year>2008</year>             <article-title>Support Vector Machines and Kernels for Computational Biology.</article-title>             <source>PLoS Comput Biol</source>             <volume>4</volume>             <fpage>e1000173</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Zhang1">
        <label>74</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>T</given-names></name></person-group>             <year>2009</year>             <article-title>Some sharp performance bounds for least squares regression with L1 regularization.</article-title>             <source>Ann Stat</source>             <volume>37</volume>             <fpage>2109</fpage>             <lpage>2144</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Peleg1">
        <label>75</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Peleg</surname><given-names>D</given-names></name><name name-style="western"><surname>Meir</surname><given-names>R</given-names></name></person-group>             <year>2008</year>             <article-title>A bilinear formulation for vector sparsity optimization.</article-title>             <source>Signal Process</source>             <volume>88</volume>             <fpage>375</fpage>             <lpage>389</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Mercer1">
        <label>76</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mercer</surname><given-names>J</given-names></name></person-group>             <year>1909</year>             <article-title>Functions of positive and negative type, and their connection with the theory of integral equations.</article-title>             <source>Proc R Soc Lond A Math Phys Sci</source>             <volume>209</volume>             <fpage>415</fpage>             <lpage>446</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-David1">
        <label>77</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>David</surname><given-names>O</given-names></name><name name-style="western"><surname>Kiebel</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Harrison</surname><given-names>LM</given-names></name><name name-style="western"><surname>Mattout</surname><given-names>J</given-names></name><name name-style="western"><surname>Kilner</surname><given-names>JM</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>Dynamic causal modeling of evoked responses in EEG and MEG.</article-title>             <source>NeuroImage</source>             <volume>30</volume>             <fpage>1255</fpage>             <lpage>1272</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Moran1">
        <label>78</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Moran</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Seidenbecher</surname><given-names>T</given-names></name><name name-style="western"><surname>Pape</surname><given-names>H</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Dynamic causal models of steady-state responses.</article-title>             <source>NeuroImage</source>             <volume>44</volume>             <fpage>796</fpage>             <lpage>811</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Chen1">
        <label>79</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>CC</given-names></name><name name-style="western"><surname>Kiebel</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2008</year>             <article-title>Dynamic causal modelling of induced responses.</article-title>             <source>NeuroImage</source>             <volume>41</volume>             <fpage>1293</fpage>             <lpage>1312</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Daunizeau1">
        <label>80</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><name name-style="western"><surname>Kiebel</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2009</year>             <article-title>Dynamic causal modelling of distributed electromagnetic responses.</article-title>             <source>NeuroImage</source>             <volume>47</volume>             <fpage>590</fpage>             <lpage>601</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Roebroeck1">
        <label>81</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Roebroeck</surname><given-names>A</given-names></name><name name-style="western"><surname>Formisano</surname><given-names>E</given-names></name><name name-style="western"><surname>Goebel</surname><given-names>R</given-names></name></person-group>             <year>2005</year>             <article-title>Mapping directed influence over the brain using Granger causality and fMRI.</article-title>             <source>NeuroImage</source>             <volume>25</volume>             <fpage>230</fpage>             <lpage>242</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Stephan3">
        <label>82</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Harrison</surname><given-names>LM</given-names></name><name name-style="western"><surname>Kiebel</surname><given-names>SJ</given-names></name><name name-style="western"><surname>David</surname><given-names>O</given-names></name><name name-style="western"><surname>Penny</surname><given-names>WD</given-names></name><etal/></person-group>             <year>2007</year>             <article-title>Dynamic causal models of neural system dynamics: Current state and future extensions.</article-title>             <source>J Biosci</source>             <volume>32</volume>             <fpage>129</fpage>             <lpage>44</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Stephan4">
        <label>83</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Weiskopf</surname><given-names>N</given-names></name><name name-style="western"><surname>Drysdale</surname><given-names>PM</given-names></name><name name-style="western"><surname>Robinson</surname><given-names>PA</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2007</year>             <article-title>Comparing hemodynamic models with DCM.</article-title>             <source>NeuroImage</source>             <volume>38</volume>             <fpage>387</fpage>             <lpage>401</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Kiebel1">
        <label>84</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kiebel</surname><given-names>SJ</given-names></name><name name-style="western"><surname>David</surname><given-names>O</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2006</year>             <article-title>Dynamic causal modelling of evoked responses in EEG/MEG with lead field parameterization.</article-title>             <source>NeuroImage</source>             <volume>30</volume>             <fpage>1273</fpage>             <lpage>1284</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Friston4">
        <label>85</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2002</year>             <article-title>Bayesian estimation of dynamical systems: An application to fMRI.</article-title>             <source>NeuroImage</source>             <volume>16</volume>             <fpage>513</fpage>             <lpage>530</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Friston5">
        <label>86</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name><name name-style="western"><surname>Mattout</surname><given-names>J</given-names></name><name name-style="western"><surname>Trujillo-Barreto</surname><given-names>N</given-names></name><name name-style="western"><surname>Ashburner</surname><given-names>J</given-names></name><name name-style="western"><surname>Penny</surname><given-names>W</given-names></name></person-group>             <year>2007</year>             <article-title>Variational free energy and the Laplace approximation.</article-title>             <source>NeuroImage</source>             <volume>34</volume>             <fpage>220</fpage>             <lpage>234</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Stephan5">
        <label>87</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>K</given-names></name><name name-style="western"><surname>Penny</surname><given-names>W</given-names></name><name name-style="western"><surname>Moran</surname><given-names>R</given-names></name><name name-style="western"><surname>den Ouden</surname><given-names>H</given-names></name><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Ten simple rules for dynamic causal modeling.</article-title>             <source>NeuroImage</source>             <volume>49</volume>             <fpage>3099</fpage>             <lpage>3109</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Stephan6">
        <label>88</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Penny</surname><given-names>WD</given-names></name><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><name name-style="western"><surname>Moran</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2009</year>             <article-title>Bayesian model selection for group studies.</article-title>             <source>NeuroImage</source>             <volume>46</volume>             <fpage>1004</fpage>             <lpage>1017</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Penny1">
        <label>89</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Penny</surname><given-names>WD</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Mechelli</surname><given-names>A</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name></person-group>             <year>2004</year>             <article-title>Comparing dynamic causal models.</article-title>             <source>NeuroImage</source>             <volume>22</volume>             <fpage>1157</fpage>             <lpage>1172</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Stone1">
        <label>90</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stone</surname><given-names>M</given-names></name></person-group>             <year>1974</year>             <article-title>Cross-validatory choice and assessment of statistical predictions.</article-title>             <source>J R Stat Soc Series B Stat Methodol</source>             <fpage>111</fpage>             <lpage>147</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Cawley1">
        <label>91</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cawley</surname><given-names>GC</given-names></name><name name-style="western"><surname>Talbot</surname><given-names>NLC</given-names></name></person-group>             <year>2010</year>             <article-title>On over-fitting in model selection and subsequent selection bias in performance evaluation.</article-title>             <source>J Mach Learn Res</source>             <volume>11</volume>             <fpage>2079</fpage>             <lpage>2107</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Brodersen2">
        <label>92</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brodersen</surname><given-names>KH</given-names></name><name name-style="western"><surname>Ong</surname><given-names>CS</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Buhmann</surname><given-names>JM</given-names></name></person-group>             <year>2010</year>             <article-title>The balanced accuracy and its posterior distribution.</article-title>             <source>Proceedings of the 20th International Conference on Pattern Recognition</source>             <publisher-name>IEEE Computer Society</publisher-name>             <fpage>3121</fpage>             <lpage>3124</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Swinburn1">
        <label>93</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Swinburn</surname><given-names>K</given-names></name><name name-style="western"><surname>Porter</surname><given-names>G</given-names></name><name name-style="western"><surname>Howard</surname><given-names>D</given-names></name></person-group>             <year>2004</year>             <article-title>Comprehensive Aphasia Test.</article-title>             <publisher-loc>New York</publisher-loc>             <publisher-name>Psychology Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Raftery1">
        <label>94</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Raftery</surname><given-names>AE</given-names></name></person-group>             <year>1995</year>             <article-title>Bayesian model selection in social research.</article-title>             <source>Sociol Methodol</source>             <volume>25</volume>             <fpage>111</fpage>             <lpage>163</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Friston6">
        <label>95</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Lund</surname><given-names>TE</given-names></name><name name-style="western"><surname>Morcom</surname><given-names>A</given-names></name><name name-style="western"><surname>Kiebel</surname><given-names>S</given-names></name></person-group>             <year>2005</year>             <article-title>Mixed-effects and fMRI studies.</article-title>             <source>NeuroImage</source>             <volume>24</volume>             <fpage>244</fpage>             <lpage>252</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Fisher1">
        <label>96</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fisher</surname><given-names>RA</given-names></name></person-group>             <year>1915</year>             <article-title>Frequency Distribution of the Values of the Correlation Coefficient in Samples from an Indefinitely Large Population.</article-title>             <source>Biometrika</source>             <volume>10</volume>             <fpage>507</fpage>             <lpage>521</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Brodersen3">
        <label>97</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brodersen</surname><given-names>KH</given-names></name><name name-style="western"><surname>Ong</surname><given-names>CS</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Buhmann</surname><given-names>JM</given-names></name></person-group>             <year>2010</year>             <article-title>The binormal assumption on precision-recall curves.</article-title>             <source>Proceedings of the 20th International Conference on Pattern Recognition</source>             <publisher-name>IEEE Computer Society</publisher-name>             <fpage>4263</fpage>             <lpage>4266</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Passingham1">
        <label>98</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Passingham</surname><given-names>RE</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Kotter</surname><given-names>R</given-names></name></person-group>             <year>2002</year>             <article-title>The anatomical basis of functional localization in the cortex.</article-title>             <source>Nat Rev Neurosci</source>             <volume>3</volume>             <fpage>606</fpage>             <lpage>616</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Scott1">
        <label>99</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Scott</surname><given-names>DW</given-names></name></person-group>             <year>1992</year>             <article-title>Kernel density estimators.</article-title>             <source>Multivariate Density Estimation: Theory, Practice, and Visualization</source>             <publisher-name>Wiley</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Stephan7">
        <label>100</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Marshall</surname><given-names>JC</given-names></name><name name-style="western"><surname>Penny</surname><given-names>WD</given-names></name><name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name><name name-style="western"><surname>Fink</surname><given-names>GR</given-names></name></person-group>             <year>2007</year>             <article-title>Interhemispheric integration of visual processing during task-driven lateralization.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>3512</fpage>             <lpage>3522</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Price1">
        <label>101</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Price</surname><given-names>CJ</given-names></name></person-group>             <year>2010</year>             <article-title>The anatomy of language: a review of 100 fMRI studies published in 2009.</article-title>             <source>Ann N Y Acad Sci</source>             <volume>1191</volume>             <fpage>62</fpage>             <lpage>88</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Dehaene1">
        <label>102</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dehaene</surname><given-names>S</given-names></name><name name-style="western"><surname>Pegado</surname><given-names>F</given-names></name><name name-style="western"><surname>Braga</surname><given-names>LW</given-names></name><name name-style="western"><surname>Ventura</surname><given-names>P</given-names></name><name name-style="western"><surname>Nunes Filho</surname><given-names>G</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>How learning to read changes the cortical networks for vision and language.</article-title>             <source>Science</source>             <volume>330</volume>             <fpage>1359</fpage>             <lpage>1364</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Lao1">
        <label>103</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lao</surname><given-names>Z</given-names></name><name name-style="western"><surname>Shen</surname><given-names>D</given-names></name><name name-style="western"><surname>Xue</surname><given-names>Z</given-names></name><name name-style="western"><surname>Karacali</surname><given-names>B</given-names></name><name name-style="western"><surname>Resnick</surname><given-names>SM</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Morphological classification of brains via high-dimensional shape transformations and machine learning methods.</article-title>             <source>NeuroImage</source>             <volume>21</volume>             <fpage>46</fpage>             <lpage>57</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Thomaz1">
        <label>104</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Thomaz</surname><given-names>CE</given-names></name><name name-style="western"><surname>Boardman</surname><given-names>JP</given-names></name><name name-style="western"><surname>Hill</surname><given-names>DL</given-names></name><name name-style="western"><surname>Hajnal</surname><given-names>JV</given-names></name><name name-style="western"><surname>Edwards</surname><given-names>DD</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Using a maximum uncertainty LDA-based approach to classify and analyse MR brain images.</article-title>             <source>7th International Conference on Medical Image Computing and Computer-Assisted Intervention</source>             <publisher-name>Springer-Verlag Berlin</publisher-name>             <fpage>291</fpage>             <lpage>300</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-MacKay1">
        <label>105</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>MacKay</surname><given-names>DJC</given-names></name></person-group>             <year>1992</year>             <article-title>Bayesian interpolation.</article-title>             <source>Neural Comput</source>             <volume>4</volume>             <fpage>415</fpage>             <lpage>447</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Allen1">
        <label>106</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Allen</surname><given-names>P</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>KE</given-names></name><name name-style="western"><surname>Mechelli</surname><given-names>A</given-names></name><name name-style="western"><surname>Day</surname><given-names>F</given-names></name><name name-style="western"><surname>Ward</surname><given-names>N</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Cingulate activity and fronto-temporal connectivity in people with prodromal signs of psychosis.</article-title>             <source>NeuroImage</source>             <volume>49</volume>             <fpage>947</fpage>             <lpage>955</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Davatzikos2">
        <label>107</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Davatzikos</surname><given-names>C</given-names></name><name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Wu</surname><given-names>X</given-names></name><name name-style="western"><surname>Shen</surname><given-names>D</given-names></name><name name-style="western"><surname>Resnick</surname><given-names>SM</given-names></name></person-group>             <year>2008</year>             <article-title>Detection of prodromal Alzheimer's disease via pattern classification of magnetic resonance imaging.</article-title>             <source>Neurobiol Aging</source>             <volume>29</volume>             <fpage>514</fpage>             <lpage>523</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Davatzikos3">
        <label>108</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Davatzikos</surname><given-names>C</given-names></name><name name-style="western"><surname>Resnick</surname><given-names>S</given-names></name><name name-style="western"><surname>Wu</surname><given-names>X</given-names></name><name name-style="western"><surname>Parmpi</surname><given-names>P</given-names></name><name name-style="western"><surname>Clark</surname><given-names>C</given-names></name></person-group>             <year>2008</year>             <article-title>Individual patient diagnosis of AD and FTD via high-dimensional pattern classification of MRI.</article-title>             <source>NeuroImage</source>             <volume>41</volume>             <fpage>1220</fpage>             <lpage>1227</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Misra1">
        <label>109</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Misra</surname><given-names>C</given-names></name><name name-style="western"><surname>Fan</surname><given-names>Y</given-names></name><name name-style="western"><surname>Davatzikos</surname><given-names>C</given-names></name></person-group>             <year>2009</year>             <article-title>Baseline and longitudinal patterns of brain atrophy in MCI patients, and their use in prediction of short-term conversion to AD: Results from ADNI.</article-title>             <source>NeuroImage</source>             <volume>44</volume>             <fpage>1415</fpage>             <lpage>1422</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002079-Nenadic1">
        <label>110</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nenadic</surname><given-names>I</given-names></name><name name-style="western"><surname>Sauer</surname><given-names>H</given-names></name><name name-style="western"><surname>Gaser</surname><given-names>C</given-names></name></person-group>             <year>2010</year>             <article-title>Distinct pattern of brain structural deficits in subsyndromes of schizophrenia delineated by psychopathology.</article-title>             <source>NeuroImage</source>             <volume>49</volume>             <fpage>1153</fpage>             <lpage>1160</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
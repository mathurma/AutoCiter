<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="other" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.1002542</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-16-00517</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Perspective</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>People and places</subject><subj-group><subject>Population groupings</subject><subj-group><subject>Professions</subject><subj-group><subject>Scientists</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Bibliometrics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Economics</subject><subj-group><subject>Labor economics</subject><subj-group><subject>Employment</subject><subj-group><subject>Careers</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Meta-analysis</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Meta-analysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Peer review</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Information technology</subject><subj-group><subject>Text mining</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Scientific publishing</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>Citation Metrics: A Primer on How (Not) to Normalize</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Ioannidis</surname>
<given-names>John P. A.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Boyack</surname>
<given-names>Kevin</given-names>
</name>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Wouters</surname>
<given-names>Paul F.</given-names>
</name>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Meta-Research Innovation Center at Stanford (METRICS), Stanford University, Stanford, California, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Stanford Prevention Research Center, Department of Medicine, Stanford University School of Medicine, Stanford, California, United States of America</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Department of Health Research and Policy, Stanford University School of Medicine, Stanford, California, United States of America</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Department of Statistics, Stanford University School of Humanities and Sciences, Stanford, California, United States of America</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>SciTech Strategies, Inc., Albuquerque, New Mexico, United States of America</addr-line></aff>
<aff id="aff006"><label>6</label> <addr-line>Centre for Science and Technology Studies, Leiden University, Leiden, Netherlands</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">jioannid@stanford.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>6</day>
<month>9</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>9</month>
<year>2016</year>
</pub-date>
<volume>14</volume>
<issue>9</issue>
<elocation-id>e1002542</elocation-id>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Ioannidis et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.1002542"/>
<abstract>
<p>Citation metrics are increasingly used to appraise published research. One challenge is whether and how to normalize these metrics to account for differences across scientific fields, age (year of publication), type of document, database coverage, and other factors. We discuss the pros and cons for normalizations using different approaches. Additional challenges emerge when citation metrics need to be combined across multiple papers to appraise the corpus of scientists, institutions, journals, or countries, as well as when trying to attribute credit in multiauthored papers. Different citation metrics may offer complementary insights, but one should carefully consider the assumptions that underlie their calculation.</p>
</abstract>
<abstract abstract-type="toc">
<p>Citation metrics are very influential and their normalization is a contentious issue. Each normalization approach has advantages and disadvantages that need to be understood for proper use of these metrics.</p>
</abstract>
<funding-group>
<funding-statement>The authors received no specific funding for this work.</funding-statement>
</funding-group>
<counts>
<fig-count count="0"/>
<table-count count="2"/>
<page-count count="7"/>
</counts>
</article-meta>
</front>
<body>
<p>Citation metrics have proliferated over the years. This rapidly growing literature is aiming to find the most fair and unbiased approach to appraise papers, scientists, institutions, and journals. Thus, citation metrics can have major implications that affect the entire scientific community and are not of interest just to experts in bibliometrics. Their use and misuse cause controversies not only for technical reasons but also for emotional reasons because these metrics judge scientific careers, rewards, and reputations [<xref ref-type="bibr" rid="pbio.1002542.ref001">1</xref>]. Scientists, journals, or institutions scoring badly in specific metrics may hate them and those scoring well may love them.</p>
<p>A core question about citation indicators is whether and how to normalize them. The basic premise of normalization is that not all citations are equal. Therefore, normalization can be seen as a process of benchmarking that is needed to enhance comparability across diverse scientists, fields, papers, time periods, and so forth. The term “rescaling” is also used instead of “normalization” in some disciplines, such as physics and computational sciences [<xref ref-type="bibr" rid="pbio.1002542.ref002">2</xref>–<xref ref-type="bibr" rid="pbio.1002542.ref004">4</xref>].</p>
<p>One can focus first on normalizing citations received by single papers, since a single paper is the smallest unit for which normalization can be considered. This offers a good way to illustrate the main concepts and challenges involved. However, normalization issues can be expanded from the single paper to the assessment of larger units of published work including many papers. These collections of papers may pertain to whole scientific fields or subfields, CVs of single scientists, teams of scientists, and institutions, nations, and journals. In particular, there is a very extensive literature on normalized journal-level metrics, such as the Source Normalized Impact Per Paper (SNIP). Journal-level metrics are a hot field because of the longstanding debate about whether any valid inferences can be made from them to “rank” journals. Their detailed discussion goes beyond the scope of the current paper.</p>
<p>Article-level citation counts tend to have very long-tailed distributions, with many articles getting no or few citations and a few articles getting a large number of citations. For papers in the long tail, it is sometimes difficult to say what constitutes a large enough difference (e.g., whether 50 citations received in two years is meaningfully different from 30 citations received in the same time frame). The long tails are generated by a preferential attachment process, in which some articles attract more and more citations. Citations mean that the work has attracted interest, but the exact reasons why it has attracted interest may vary for different papers.</p>
<p>Ideally, one wants citation indicators to measure impact in a monotonic fashion: the higher the metric, the “better” the paper. Citations received by a single paper may depend on multiple factors beyond pure merit. These include the scientific field where the paper belongs (different fields have different numbers of publishing and citing scientists and citing cultures, and thus different citation density), the age (how long ago it was published), the type of document (article, review, letter, editorial), and the coverage of the database where citations are counted.</p>
<p>Scientific field normalization sounds intuitive [<xref ref-type="bibr" rid="pbio.1002542.ref005">5</xref>]. One wants to correct for imbalance of citation opportunity. Other things being equal, an influential paper in a theoretical mathematics field where reference lists are traditionally short may attract fewer citations than influential papers in fields where papers typically have much longer reference lists [<xref ref-type="bibr" rid="pbio.1002542.ref006">6</xref>]. Moreover, sometimes the fact that citations are higher in one field than in another may simply reflect that the research in the former field is, in a certain sense, more important scientifically and more fruitful than the research in the latter. After all, it is implausible that all scientific fields contribute equally to the stock of scientific knowledge and share an equal proportion of great scientists among their investigators. The scientific workforce and, even more so, great scientists are particularly attracted to specific disciplines and research questions that change over time. The widely used Web of Science classification of fields is based on classifying journals in subject categories, and these subject categories may be very unequal in importance, newsworthiness, or genuine breadth of appeal. E.g., in Web of Science, the subject category “Medicine, General and Internal” includes all major medical journals; these journals justifiably receive far more citations than journals in specialty categories. Also, innovative “sleeping beauty” papers may be minimally cited until their results are recognized by the scientific community. Furthermore, the very criteria for truth and excellence are not historical constants but evolve as part of science and scholarship [<xref ref-type="bibr" rid="pbio.1002542.ref007">7</xref>].</p>
<p>A major challenge is how to define scientific fields for normalization. Fields have been categorized in the past on the basis of journals or library categories. Within-field citations are usually denser than between-field citations. However, no field is isolated, and between-field communication is increasingly common nowadays [<xref ref-type="bibr" rid="pbio.1002542.ref008">8</xref>]. In some areas, the boundaries between fields seem to become less distinct. Different categorizations may segregate science to anywhere between a dozen [<xref ref-type="bibr" rid="pbio.1002542.ref009">9</xref>] to several thousands of disciplines or specialties [<xref ref-type="bibr" rid="pbio.1002542.ref010">10</xref>]. Fields may be defined a priori (e.g., based on the journals where research gets published) or dynamically (e.g., based on citing or cited papers or on the references of citing or cited papers) [<xref ref-type="bibr" rid="pbio.1002542.ref011">11</xref>]. The rationale is that citing papers consider cited papers relevant to their work, so they belong to the same field. Obviously, this is not true for all citations—e.g., some methods (statistical, laboratory, or other) can be used by multiple unrelated fields, and there are also substantive interdisciplinary references.</p>
<p>When fields are very broad, they spuriously conglomerate many subfields with very different citation densities and/or importance. Conversely, when fields are very specific, normalization is based on a few reference papers and has a large error margin. Moreover, narrow fields may vary enormously in their contribution to the advancement of knowledge. Normalizations using fields defined from citing or cited papers may lead also to counterintuitive situations; e.g., when a paper starts being cited in another, remote field, this may signify it has acquired extra importance. However, if that paper is cited by another field that has high citation density, its normalized citation score may decrease rather than increase, depending on the precise construction of the normalization procedure [<xref ref-type="bibr" rid="pbio.1002542.ref012">12</xref>]. Overall, there is some evidence that definition of fields based on cocitation, such as the approach recently proposed by the relative citation ratio (RCR) method [<xref ref-type="bibr" rid="pbio.1002542.ref013">13</xref>], is better than using taxonomies using journal categories. Alternative approaches to define fields that use direct citation and bibliographic coupling have been proposed to be even better [<xref ref-type="bibr" rid="pbio.1002542.ref014">14</xref>], but the verdict is not final. The superiority of one approach over others may depend on the time frame, the database, and types of articles used. The extent to which limitations of different approaches are frequent or not requires further empirical evaluation [<xref ref-type="bibr" rid="pbio.1002542.ref008">8</xref>,<xref ref-type="bibr" rid="pbio.1002542.ref015">15</xref>]. For example, in an assessment of 200,000 articles published between 2003 and 2010, only 0.2% experienced a drop in RCR of 0.1 [<xref ref-type="bibr" rid="pbio.1002542.ref013">13</xref>].</p>
<p>Age (year of publication) seems a straightforward normalizing factor. A paper published in 2000 has had more time to accrue citations than one published in 2015. Therefore, each paper can be compared against papers published in the same year. However, with an acceleration in the number of scientific papers published annually, influential old papers had a far smaller literature that could have cited them within a few years of publication as compared with more recent influential papers. Moreover, scientific fields (no matter how defined) don’t make the same progress each and every year. There are good and bad years. A paper in the top 10% of citations published in a year of major progress may be a more fundamental knowledge contribution than a paper in the top 1% of a year when the field stagnated. Finally, calendar year–based normalization produces noisy results in very recent papers. These are the papers for which the most rigorous appraisal of impact is desirable, since they reflect the recent or current dynamism of a scientist or institution. A paper published in January 2015 has had 14 months to be cited until March 2016, while a paper published in December 2015 has had only 3 months. Many journals also use advance online posting, so a paper published in 2015 might have been available to cite since 2013.</p>
<p>Normalization for type of document also poses several challenges. Review articles receive more citations than articles with new empirical data, and some types of papers (such as letters or editorials) often receive few or no citations [<xref ref-type="bibr" rid="pbio.1002542.ref016">16</xref>,<xref ref-type="bibr" rid="pbio.1002542.ref017">17</xref>]. A first challenge is to identify accurately the different types of document categories. Besides misclassification errors (i.e., reviews tagged as articles with new data and vice versa [<xref ref-type="bibr" rid="pbio.1002542.ref018">18</xref>]), each document category can include article types with different connotations and citation profiles. “Reviews” may include nonsystematic expert assessments, systematic reviews, meta-analyses, prospective meta-analyses, collaborative consortia analyses, etc. These differ enormously in inherent credibility, scientific value, amount of work required, contribution to science, and reasons for being cited. Many high-quality “reviews” are more important in all these aspects than the vast majority of uninformative “original research.” Penalizing these reviews would be inappropriate; their higher citations reflect their higher value. Conversely, many expert reviews propagate unfounded opinions in large citation networks; their numerous citations may simply measure how they distort science [<xref ref-type="bibr" rid="pbio.1002542.ref019">19</xref>]. Letters and editorials are often easier to identify accurately in databases and are more homogeneous in getting few citations. Therefore, one may exclude them in assessing citation indicators. Nevertheless, occasionally timely editorials may contribute more to scientific progress than “original” papers. Disruptively innovative ideas may be easier to express in non–peer-reviewed editorials than in peer-reviewed research.</p>
<p>Citation database coverage may affect all of the factors discussed above. Detailed discussion of citation databases is beyond our scope here. Briefly, databases have variable coverage of different scientific fields, years, and types of documents, and coverage may change over time [<xref ref-type="bibr" rid="pbio.1002542.ref020">20</xref>]. Errors and transparency on included document sources also differ. Among the most popular databases (Web of Science, Google Scholar, and Scopus), Web of Science has the longest historical coverage. Both Web of Science and Scopus have higher transparency and data quality but lower overall coverage than Google Scholar and prominent deficiencies in social sciences, humanities, and many other fields. Depending on the goal of the bibliometric analysis, more complete coverage may be desirable, but it needs to be consistent, otherwise the inclusion of irrelevant items (e.g., trade journals) may complicate the delineation of fields and proper normalization of indicators. Besides database coverage, differences may also exist in preprint culture across fields. Some fields, such as economics, have protracted peer review, and many papers are available as preprints; thus, a large share of citations are made to preprints. Conversely, molecular biology has had no preprint culture to date (although this may change in the future with efforts such as BioRxiv).</p>
<p>Multiple other contentious factors may be considered as options to model in the normalization process. Should citations matter more when they come from journals and/or papers that score more highly themselves in citation metrics? This may promote a self-reinforcing effect. Text mining approaches may also allow giving different weight to citations based on the context in which they are made, how often they are mentioned in the citing paper, and whether they are favorable or critical of the work being cited [<xref ref-type="bibr" rid="pbio.1002542.ref021">21</xref>,<xref ref-type="bibr" rid="pbio.1002542.ref022">22</xref>]. However, text mining requires full texts (often nonaccessible), and it is unclear whether one can easily separate generation of fruitful debate (even if the citing authors disagree) from renunciation of error. Negative citations tend to be relatively rare [<xref ref-type="bibr" rid="pbio.1002542.ref023">23</xref>], except in some of the social sciences, where disputes may be played out by citing each other (rather than by ignoring one another). Some controversy exists also on how to handle self-citations. <xref ref-type="table" rid="pbio.1002542.t001">Table 1</xref> summarizes factors that may be considered or debated during normalization and shows for comparison two systems, the RCR method [<xref ref-type="bibr" rid="pbio.1002542.ref013">13</xref>] and the normalization used in the Leiden Ranking of universities (<ext-link ext-link-type="uri" xlink:href="http://www.leidenranking.com/" xlink:type="simple">http://www.leidenranking.com</ext-link>), both of which use citation data from the Web of Science.</p>
<table-wrap id="pbio.1002542.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002542.t001</object-id>
<label>Table 1</label> <caption><title>Factors that have been considered in normalization of citation metrics and their application in two normalization systems.<xref ref-type="table-fn" rid="t001fn001">*</xref></title></caption>
<alternatives>
<graphic id="pbio.1002542.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002542.t001" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left"/>
<th align="left"><italic>Relative citation ratio</italic></th>
<th align="left"><italic>Leiden system</italic></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Scientific field definition</td>
<td align="left">Defined by network of citing papers</td>
<td align="left">3,822 micro-level fields based on citations of all papers</td>
</tr>
<tr>
<td align="left">Scientific field fixed or dynamic</td>
<td align="left">Dynamic, different for each cited paper</td>
<td align="left">Each paper is assigned to one micro-field</td>
</tr>
<tr>
<td align="left">Scientific field broad or narrow</td>
<td align="left">Can vary a lot</td>
<td align="left">Mostly moderate size</td>
</tr>
<tr>
<td align="left">Age (year of publication)</td>
<td align="left">Accounted for</td>
<td align="left">Accounted for</td>
</tr>
<tr>
<td align="left">Type of documents</td>
<td align="left">Multiple types</td>
<td align="left">Articles and reviews</td>
</tr>
<tr>
<td align="left">Citing sources</td>
<td align="left">Not adjusted for</td>
<td align="left">Not adjusted for</td>
</tr>
<tr>
<td align="left">Place of citations in citing sources</td>
<td align="left">Not adjusted for</td>
<td align="left">Not adjusted for</td>
</tr>
<tr>
<td align="left">Multiplicity of reference in citing source</td>
<td align="left">Not adjusted for</td>
<td align="left">Not adjusted for</td>
</tr>
<tr>
<td align="left">Context of citation in citing source (supportive versus negative or critical)</td>
<td align="left">Not adjusted for</td>
<td align="left">Not adjusted for</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>*This does not mean necessarily that normalization for these factors improves the validity of the citation results.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>Additional challenges emerge when extending to the assessment of multiple papers—e.g., the published corpus of a scientist, institution, or country. For example, how should the (normalized) metrics of single papers be summarized and interpreted? Multiple options exist (<xref ref-type="table" rid="pbio.1002542.t002">Table 2</xref>).</p>
<table-wrap id="pbio.1002542.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002542.t002</object-id>
<label>Table 2</label> <caption><title>Some options for summarizing and interpreting (normalized) citation metrics from single papers across multiple papers.</title></caption>
<alternatives>
<graphic id="pbio.1002542.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1002542.t002" xlink:type="simple"/>
<table>
<colgroup>
<col align="left" valign="middle"/>
</colgroup>
<tbody>
<tr>
<td align="left">Averaging ratios of actual citations versus expected citations for each paper</td>
</tr>
<tr>
<td align="left">Ratio of sum of actual citations divided by sum of expected citations</td>
</tr>
<tr>
<td align="left">Proportion of papers in top 1% of normalization or other reference group</td>
</tr>
<tr>
<td align="left">Proportion of papers in top 10% of normalization or other reference group</td>
</tr>
<tr>
<td align="left">Proportion of papers in top 50% of normalization or other reference group</td>
</tr>
<tr>
<td align="left">Other combinations of percentile ranks of multiple papers—e.g., R(6), R(100), R(6,k), R(100,k)</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>For example, it can also make a difference on whether one focuses on extremely highly cited papers, top 1%, top 10%, the average paper, or other parts of the distribution. Do we prefer an institution or scientists producing papers that are mostly above the average but none that have extremely high impact, or those producing papers mostly at the average or even below but that occasionally come up with an extremely high-impact publication? Normalization is most unstable at the extremes, where few papers compete. It would be silly to try to normalize the <italic>Origin of Species</italic> versus the description of the DNA helix (32,556 and 11,551 citations per Google Scholar, respectively, as of February 2, 2016) to see which one is better.</p>
<p>Another major confounding issue is the allocation of credit. An increasing number of papers are authored by many authors. Given the large extent of multiauthorship in most scientific fields [<xref ref-type="bibr" rid="pbio.1002542.ref024">24</xref>,<xref ref-type="bibr" rid="pbio.1002542.ref025">25</xref>], adjustments for multiauthorship and author contributions may have a much larger impact on citation indicators for scientists than other types of normalization and/or correction. Unfortunately, the exact contributions of authors are rarely disclosed, disclosures may be inaccurate, and even when accurate they are not easy to translate unambiguously into a quantitative equivalent. Author order is a widely used surrogate of contribution, with greater contributions typically attributed to first and last and/or corresponding authors. However, alphabetic author ordering is used in some fields [<xref ref-type="bibr" rid="pbio.1002542.ref026">26</xref>,<xref ref-type="bibr" rid="pbio.1002542.ref027">27</xref>]. There is an array of different quantitative approaches on how to correct for author order and multiauthorship [<xref ref-type="bibr" rid="pbio.1002542.ref028">28</xref>–<xref ref-type="bibr" rid="pbio.1002542.ref030">30</xref>].</p>
<p>Given the large volume of papers on variously normalized citation metrics, one may falsely infer that citation metrics are so confusing that they should be abandoned in favor of appraisal by experts in the field. Yet, citation metrics are so widely visible that no expert can close their eyes to them anyhow, even if he or she wanted to do so. Scientometrics may help put this type of information into perspective and understand the strengths and limitations of each metric in each setting and allow for diversity and plurality of career paths. Metrics and normalizations should be seen in the context of their assumptions. When results and conclusions are similar with different assumptions, this is reassuring. Conversely, when conclusions differ, one has to examine why and what the different assumptions signify. Finally, some metrics may be better suited than others in particular applications. E.g., different metrics and normalizations may make more sense in trying to identify top researchers versus finding out whether an institution is above or below average. Judicious use of citation metrics can still be very useful, especially when they are robust, transparent, and their limitations are properly recognized.</p>
</body>
<back>
<ack>
<p>We thank Ludo Waltman for commenting on earlier versions.</p>
</ack>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>RCR</term>
<def><p>relative citation ratio</p></def>
</def-item>
<def-item><term>SNIP</term>
<def><p>Source Normalized Impact Per Paper</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.1002542.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hicks</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wouters</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Waltman</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>de Rijcke</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rafols</surname> <given-names>I</given-names></name>. <article-title>Bibliometrics: The Leiden Manifesto for research metrics</article-title>. <source>Nature</source> <year>2015</year>;<volume>520</volume>:<fpage>429</fpage>–<lpage>431</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/520429a" xlink:type="simple">10.1038/520429a</ext-link></comment> <object-id pub-id-type="pmid">25903611</object-id></mixed-citation></ref>
<ref id="pbio.1002542.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Radicchi</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Fortunato</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Castellano</surname> <given-names>C</given-names></name>. <article-title>Universality of citation distributions: Toward an objective measure of scientific impact</article-title>. <source>Proceedings of the National Academy of Sciences</source> <year>2008</year>;<volume>105</volume>(<issue>45</issue>):<fpage>17268</fpage>–<lpage>17272</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Radicchi</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Castellano</surname> <given-names>C</given-names></name>. <article-title>Rescaling citations of publications in physics</article-title>. <source>Physical Review E</source> <year>2011</year>;<volume>83</volume>(<issue>4</issue>):<fpage>046116</fpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaur</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Radicchi</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Menczer</surname> <given-names>F</given-names></name>. <article-title>Universality of scholarly impact metrics</article-title>. <source>Journal of Informetrics</source> <year>2013</year>;<volume>7</volume>(<issue>4</issue>):<fpage>924</fpage>–<lpage>932</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Waltman</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Van Eck</surname> <given-names>NJ</given-names></name>. <article-title>A systematic empirical comparison of different approaches for normalizing citation impact indicators</article-title>. <source>Journal of Informetrics</source> <year>2013</year>;<volume>7</volume>:<fpage>833</fpage>–<lpage>849</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Althouse</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>West</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Bergstrom</surname> <given-names>JT</given-names></name>, <name name-style="western"><surname>Bergstrom</surname> <given-names>T</given-names></name>. <article-title>Differences in impact factor across fields and over time</article-title>. <source>Journal of the American Society for Information Science and Technology</source> <year>2009</year>; <volume>60</volume>(<issue>1</issue>): <fpage>27</fpage>–<lpage>34</lpage></mixed-citation></ref>
<ref id="pbio.1002542.ref007"><label>7</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Daston</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Gallison</surname> <given-names>P</given-names></name>. <source>Objectivity</source>. <publisher-loc>Brooklyn, NY</publisher-loc>, <publisher-name>Zone Books</publisher-name>, <year>2007</year>.</mixed-citation></ref>
<ref id="pbio.1002542.ref008"><label>8</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Larivière</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Gingras</surname> <given-names>Y</given-names></name>. <chapter-title>Measuring interdisciplinarity</chapter-title>. In: <name name-style="western"><surname>Cronin</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Sugimoto</surname> <given-names>C. R.</given-names></name>, editors. <source>Beyond Bibliometrics: Harnessing Multidimensional Indicators of Scholarly Impact</source> (pp. <fpage>187</fpage>–<lpage>200</lpage>). <publisher-loc>Cambridge MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>, <year>2014</year>.</mixed-citation></ref>
<ref id="pbio.1002542.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Börner</surname> <given-names>K</given-names></name> <etal>et al</etal>. <article-title>Design and update of a classification system: The UCSD map of science</article-title>. <source>PLoS ONE</source> <year>2012</year>;<volume>7</volume>:<fpage>e39464</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0039464" xlink:type="simple">10.1371/journal.pone.0039464</ext-link></comment> <object-id pub-id-type="pmid">22808037</object-id></mixed-citation></ref>
<ref id="pbio.1002542.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruiz-Castillo</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Waltman</surname> <given-names>L</given-names></name>. <article-title>Field-normalized citation impact indicators using algorithmically constructed classification systems of science</article-title>. <source>Journal of Informetrics</source> <year>2015</year>;<volume>9</volume>:<fpage>102</fpage>–<lpage>117</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Moed</surname> <given-names>H. F.</given-names></name> <article-title>Measuring contextual citation impact of scientific journals</article-title>. <source>Journal of Informetrics</source> <year>2010</year>;<volume>4</volume>:<fpage>265</fpage>–<lpage>277</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref012"><label>12</label><mixed-citation publication-type="other" xlink:type="simple">Waltman, L. NIH's new citation metric: A step forward in quantifying scientific impact? Retrieved November 10, 2015. <ext-link ext-link-type="uri" xlink:href="https://www.cwts.nl/blog?article=n-q2u294" xlink:type="simple">https://www.cwts.nl/blog?article=n-q2u294</ext-link></mixed-citation></ref>
<ref id="pbio.1002542.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hutchins</surname> <given-names>BI</given-names></name>, <name name-style="western"><surname>Yuan</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Santangelo</surname> <given-names>GM</given-names></name>. <article-title>Relative citation ratio (RCR): a new metric that uses citation rates to measure influence at the article level</article-title>. <source>PLoS Biol</source>. <year>2016</year>:<volume>14</volume>(<issue>9</issue>) <fpage>e1002541</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1002541" xlink:type="simple">10.1371/journal.pbio.1002541</ext-link></comment></mixed-citation></ref>
<ref id="pbio.1002542.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klavans</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Boyack</surname> <given-names>KW</given-names></name>. <article-title>Which type of citation analysis generates the most accurate taxonomy of scientific and technical knowledge?</article-title> <source>JASIST</source> <year>2016</year>. In Press. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/ftp/arxiv/papers/1511/1511.05078.pdf" xlink:type="simple">http://arxiv.org/ftp/arxiv/papers/1511/1511.05078.pdf</ext-link>.</mixed-citation></ref>
<ref id="pbio.1002542.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bornmann</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Haunschild</surname> <given-names>R</given-names></name>. <article-title>Relative Citation Ratio (RCR): A first empirical attempt to study a new field-normalized bibliometric indicator</article-title>. <source>JASIST</source> <year>2016</year>. In press. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/ftp/arxiv/papers/1511/1511.08088.pdf" xlink:type="simple">https://arxiv.org/ftp/arxiv/papers/1511/1511.08088.pdf</ext-link></mixed-citation></ref>
<ref id="pbio.1002542.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Patsopoulos</surname> <given-names>NA</given-names></name>1, <name name-style="western"><surname>Analatos</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>. <article-title>Relative citation impact of various study designs in the health sciences</article-title>. <source>JAMA</source> <year>2005</year>;<volume>293</volume>:<fpage>2362</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">15900006</object-id></mixed-citation></ref>
<ref id="pbio.1002542.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Leeuwen</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Costas</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Calero-Medina</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Visser</surname> <given-names>M</given-names></name>. <article-title>The role of editorial material in bibliometric research performance assessments</article-title>. <source>Scientometrics</source> <year>2013</year>;<volume>95</volume>:<fpage>817</fpage>–<lpage>828</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref018"><label>18</label><mixed-citation publication-type="other" xlink:type="simple">Colebunders R, Rousseau R. On the definition of a review, and does it matter? Proceedings of ISSI 2013 Vienna, (Juan Gorraiz, Edgar Schiebel, Christian Gumpenberger, Marianne Hörlesberger, Henk Moed, eds.), AIT Austrian Institute of Technology, Vienna, p. 2072–2074.</mixed-citation></ref>
<ref id="pbio.1002542.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Greenberg</surname> <given-names>SA</given-names></name>. <article-title>How citation distortions create unfounded authority: analysis of a citation network</article-title>. <source>BMJ</source> <year>2009</year>;<volume>339</volume>:<fpage>b2680</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1136/bmj.b2680" xlink:type="simple">10.1136/bmj.b2680</ext-link></comment> <object-id pub-id-type="pmid">19622839</object-id></mixed-citation></ref>
<ref id="pbio.1002542.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harzing</surname> <given-names>AW</given-names></name>. <article-title>A longitudinal study of Google Scholar coverage between 2012 and 2013</article-title>. <source>Scientometrics</source> <year>2014</year>;<volume>98</volume>:<fpage>565</fpage>–<lpage>575</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Catalini</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lacetera</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Oettl</surname> <given-names>A</given-names></name>. <article-title>The incidence and role of negative citations in science</article-title>. <source>Proceedings of the National Academy of Sciences</source> <year>2015</year>;<volume>112</volume>(<issue>45</issue>):<fpage>13823</fpage>–<lpage>13826</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ding</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Guo</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Cronin</surname> <given-names>B</given-names></name>. <article-title>The distribution of references across texts: Some implications for citation analysis</article-title>. <source>J Informetrics</source> <year>2013</year>;<volume>7</volume>:<fpage>583</fpage>–<lpage>592</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hu</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>Z</given-names></name>. <article-title>Where are citations located in the body of scientific articles? A study of the distributions of citation locations</article-title>. <source>J Informetrics</source> <year>2013</year>;<volume>7</volume>:<fpage>887</fpage>–<lpage>896</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shen</surname> <given-names>HW</given-names></name>, <name name-style="western"><surname>Barabási</surname> <given-names>AL</given-names></name>. <article-title>Collective credit allocation in science</article-title>. <source>Proceedings of the National Academy of Sciences</source> <year>2014</year>;<volume>111</volume>(<issue>34</issue>):<fpage>12325</fpage>–<lpage>12330</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wuchty</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>BF</given-names></name>, <name name-style="western"><surname>Uzzi</surname> <given-names>B</given-names></name>. <article-title>The increasing dominance of teams in production of knowledge</article-title>. <source>Science</source> <year>2007</year>;<volume>316</volume>(<issue>5827</issue>):<fpage>1036</fpage>–<lpage>1039</lpage>. <object-id pub-id-type="pmid">17431139</object-id></mixed-citation></ref>
<ref id="pbio.1002542.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zbar</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>E</given-names></name>. <article-title>Significance of authorship position: an open-ended international assessment</article-title>. <source>Am J Med Sci</source> <year>2011</year>;<volume>341</volume>:<fpage>106</fpage>–<lpage>109</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1097/MAJ.0b013e3181f683a1" xlink:type="simple">10.1097/MAJ.0b013e3181f683a1</ext-link></comment> <object-id pub-id-type="pmid">20924283</object-id></mixed-citation></ref>
<ref id="pbio.1002542.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Waltman</surname> <given-names>L</given-names></name>. <article-title>An empirical analysis of the use of alphabetical authorship in scientific publishing</article-title>. <source>J Informetrics</source> <year>2012</year>;<volume>6</volume>:<fpage>700</fpage>–<lpage>711</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tol</surname> <given-names>RS</given-names></name>. <article-title>Credit where credit's due: accounting for co-authorship in citation counts</article-title>. <source>Scientometrics</source> <year>2011</year>;<volume>89</volume>:<fpage>291</fpage>–<lpage>299</lpage>. <object-id pub-id-type="pmid">21957320</object-id></mixed-citation></ref>
<ref id="pbio.1002542.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schreiber</surname> <given-names>M</given-names></name>. <article-title>A modification of the h-index: The hm-index accounts for multi-authored manuscripts</article-title>. <source>J Informetrics</source> <year>2008</year>;<volume>2</volume>:<fpage>211</fpage>–<lpage>216</lpage>.</mixed-citation></ref>
<ref id="pbio.1002542.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname> <given-names>CT</given-names></name> <article-title>A proposal for calculating weighted citations based on author rank</article-title>. <source>EMBO Reports</source> <year>2009</year>;<volume>10</volume>(<issue>5</issue>):<fpage>416</fpage>–<lpage>417</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/embor.2009.74" xlink:type="simple">10.1038/embor.2009.74</ext-link></comment> <object-id pub-id-type="pmid">19415071</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
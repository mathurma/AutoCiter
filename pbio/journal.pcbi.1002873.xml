<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
      <journal-id journal-id-type="pmc">ploscomp</journal-id>
      <journal-title-group>
        <journal-title>PLoS Computational Biology</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1553-734X</issn>
      <issn pub-type="epub">1553-7358</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-00821</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pcbi.1002873</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
              <subj-group>
                <subject>Coding mechanisms</subject>
                <subject>Sensory systems</subject>
              </subj-group>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Sensory perception</subject>
              <subj-group>
                <subject>Psychophysics</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Sensory systems</subject>
              <subj-group>
                <subject>Visual system</subject>
              </subj-group>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
            <subj-group>
              <subject>Psychophysics</subject>
              <subject>Sensory perception</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>How Sensitive Is the Human Visual System to the Local Statistics of Natural Images?</article-title>
        <alt-title alt-title-type="running-head">Sensitivity to Local Natural Image Statistics</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Gerhard</surname>
            <given-names>Holly E.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Wichmann</surname>
            <given-names>Felix A.</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
          <xref ref-type="aff" rid="aff5">
            <sup>5</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Bethge</surname>
            <given-names>Matthias</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <label>1</label>
        <addr-line>Computational Vision and Neuroscience Group, Max Planck Institute for Biological Cybernetics, Tübingen, Germany</addr-line>
      </aff>
      <aff id="aff2">
        <label>2</label>
        <addr-line>Werner Reichardt Centre for Integrative Neuroscience, University of Tübingen, Tübingen, Germany</addr-line>
      </aff>
      <aff id="aff3">
        <label>3</label>
        <addr-line>Bernstein Center for Computational Neuroscience, Tübingen, Germany</addr-line>
      </aff>
      <aff id="aff4">
        <label>4</label>
        <addr-line>AG Neuronale Informationsverarbeitung, Mathematisch-Naturwissenschaftliche Fakultät, Eberhard Karls Universität Tübingen, Tübingen, Germany</addr-line>
      </aff>
      <aff id="aff5">
        <label>5</label>
        <addr-line>Abteilung Empirische Inferenz, Max-Planck-Institut für Intelligente Systeme, Tübingen, Germany</addr-line>
      </aff>
      <aff id="aff6">
        <label>6</label>
        <addr-line>Institute of Theoretical Physics, Eberhard Karls Universität Tübingen, Tübingen, Germany</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Kording</surname>
            <given-names>Konrad P.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>Northwestern University, United States of America</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">holly.gerhard@bethgelab.org</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: HEG FAW MB. Performed the experiments: HEG. Analyzed the data: HEG. Wrote the paper: HEG FAW MB.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <month>1</month>
        <year>2013</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>24</day>
        <month>1</month>
        <year>2013</year>
      </pub-date>
      <volume>9</volume>
      <issue>1</issue>
      <elocation-id>e1002873</elocation-id>
      <history>
        <date date-type="received">
          <day>18</day>
          <month>5</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>21</day>
          <month>11</month>
          <year>2012</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2013</copyright-year>
        <copyright-holder>Gerhard et al</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>A key hypothesis in sensory system neuroscience is that sensory representations are adapted to the statistical regularities in sensory signals and thereby incorporate knowledge about the outside world. Supporting this hypothesis, several probabilistic models of local natural image regularities have been proposed that reproduce neural response properties. Although many such physiological links have been made, these models have not been linked directly to visual sensitivity. Previous psychophysical studies of sensitivity to natural image regularities focus on global perception of large images, but much less is known about sensitivity to local natural image regularities. We present a new paradigm for controlled psychophysical studies of local natural image regularities and compare how well such models capture perceptually relevant image content. To produce stimuli with precise statistics, we start with a set of patches cut from natural images and alter their content to generate a matched set whose joint statistics are equally likely under a probabilistic natural image model. The task is forced choice to discriminate natural patches from model patches. The results show that human observers can learn to discriminate the higher-order regularities in natural images from those of model samples after very few exposures and that no current model is perfect for patches as small as 5 by 5 pixels or larger. Discrimination performance was accurately predicted by model likelihood, an information theoretic measure of model efficacy, indicating that the visual system possesses a surprisingly detailed knowledge of natural image higher-order correlations, much more so than current image models. We also perform three cue identification experiments to interpret how model features correspond to perceptually relevant image features.</p>
      </abstract>
      <abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>Several aspects of primate visual physiology have been identified as adaptations to local regularities of natural images. However, much less work has measured visual sensitivity to local natural image regularities. Most previous work focuses on global perception of large images and shows that observers are more sensitive to visual information when image properties resemble those of natural images. In this work we measure human sensitivity to local natural image regularities using stimuli generated by patch-based probabilistic natural image models that have been related to primate visual physiology. We find that human observers can learn to discriminate the statistical regularities of natural image patches from those represented by current natural image models after very few exposures and that discriminability depends on the degree of regularities captured by the model. The quick learning we observed suggests that the human visual system is biased for processing natural images, even at very fine spatial scales, and that it has a surprisingly large knowledge of the regularities in natural images, at least in comparison to the state-of-the-art statistical models of natural images.</p>
      </abstract>
      <funding-group>
        <funding-statement>This work was supported by the Max Planck Society (<ext-link ext-link-type="uri" xlink:href="http://www.mpg.de/en" xlink:type="simple">http://www.mpg.de/en</ext-link>) and the German Ministry of Education, Science, Research and Technology (BMBF) through the Bernstein award to MB (BMBF; FKZ: 01GQ0601). Further, FAW acknowledges funding from the BMBF through the Bernstein Center for Computational Neuroscience Tuebingen (BMBF; FKZ: 01GQ1002). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="15"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>We operate in a world exhibiting statistical regularities. In a very different universe where every point in space were independent from all others, white noise images (<xref ref-type="fig" rid="pcbi-1002873-g001">Figure 1A</xref>) would be common place. Of course, our world appears much more structured (<xref ref-type="fig" rid="pcbi-1002873-g001">Figure 1B</xref>). It contains objects with smoothly and slowly varying surface features, which make nearby parts of space appear similar. If there is such structure in the world, visual representations in the brain should take these correlations into account, as stated by the efficient coding hypothesis <xref ref-type="bibr" rid="pcbi.1002873-Attneave1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Barlow1">[2]</xref>. One way to test this idea is to build models that specify a probability density function over the space of natural images and compare the resulting model features with known physiological properties of the visual system. Similarities between model features and neural properties are frequently taken as evidence that the visual system has similarly acquired knowledge of the natural image distribution: bandpass filtering <xref ref-type="bibr" rid="pcbi.1002873-Atick1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Dan1">[4]</xref>, orientation selectivity <xref ref-type="bibr" rid="pcbi.1002873-Olshausen1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Bell1">[6]</xref>, divisive normalization <xref ref-type="bibr" rid="pcbi.1002873-Schwartz1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Sinz1">[10]</xref>, and complex cell pooling <xref ref-type="bibr" rid="pcbi.1002873-Karklin1">[11]</xref>. These findings are at least consistent with the idea that the visual system is adapted to the statistical regularities in natural images. In the present work, we take a different approach, which is to measure the visual sensitivity of human observers to statistical regularities in natural images.</p>
      <fig id="pcbi-1002873-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Different kinds of images.</title>
          <p><bold>A.</bold> A white noise image free of spatial correlations between pixel gray values. <bold>B.</bold> A natural image. In the present work, we study sensitivity to local regularities in natural images.</p>
        </caption>
        <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g001" position="float" xlink:type="simple"/>
      </fig>
      <p>Much of the previous psychophysical work using natural images focuses on full size images and sensitivity to measures derived from the Fourier transform. For example, natural images show a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e001" xlink:type="simple"/></inline-formula> fall-off in their amplitude spectra <xref ref-type="bibr" rid="pcbi.1002873-Deriugin1">[12]</xref>. When amplitude spectra are similar to those of natural images, human observers perform better on a variety of discrimination tasks <xref ref-type="bibr" rid="pcbi.1002873-Knill1">[13]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Prraga2">[17]</xref>. Other studies have explored sensitivity to properties encoded in the Fourier phase spectrum with varied approaches and results <xref ref-type="bibr" rid="pcbi.1002873-Tadmor2">[18]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Emrith1">[25]</xref>. The phase spectrum globally encodes shape information <xref ref-type="bibr" rid="pcbi.1002873-Oppenheim1">[26]</xref>. Fewer psychophysical studies have focused on sensitivity to local natural image regularities. Observers can predict extremely local image values better in natural than in random images <xref ref-type="bibr" rid="pcbi.1002873-Kersten1">[27]</xref>, indicating that the visual system also makes use of local natural image regularities. The texture modeling literature has also established several local image statistics as perceptually important for successful reproduction of natural textures <xref ref-type="bibr" rid="pcbi.1002873-Heeger1">[28]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Balas1">[30]</xref>.</p>
      <p>In this work, we measure human sensitivity to local regularities in natural images using probabilistic models learned on patches of natural images, which allows us to construct stimuli that pit the full range of local natural image regularities against a limited range controlled by a model. In so doing, we test the efficacy of different kinds of natural image models in capturing perceptually prominent image features. Depending on the nature of a model's assumptions, it captures a particular degree of the statistical regularities present in natural images, which can be estimated via model likelihood. The five probabilistic models we utilize for stimulus generation have been evaluated quantitatively using cross-validated model likelihood estimates (<xref ref-type="table" rid="pcbi-1002873-t001">Table 1</xref>) and represent a range of advances in capturing natural image regularities, e.g. <xref ref-type="bibr" rid="pcbi.1002873-Atick1">[3]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Karklin1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Wainwright1">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Bethge1">[33]</xref>. They can also be grouped into classes that differ in characteristic features related to primate visual physiology (<xref ref-type="table" rid="pcbi-1002873-t001">Table 1</xref>).</p>
      <table-wrap id="pcbi-1002873-t001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.t001</object-id>
        <label>Table 1</label>
        <caption>
          <title>Natural image model features and likelihood estimates.</title>
        </caption>
        <alternatives>
          <graphic id="pcbi-1002873-t001-1" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.t001" xlink:type="simple"/>
          <table>
            <colgroup span="1">
              <col align="left" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
              <col align="center" span="1"/>
            </colgroup>
            <thead>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">BF</td>
                <td align="left" rowspan="1" colspan="1">OS</td>
                <td align="left" rowspan="1" colspan="1">DN</td>
                <td align="left" rowspan="1" colspan="1">CP</td>
                <td align="left" rowspan="1" colspan="1">Likelihood</td>
                <td align="left" rowspan="1" colspan="1">References</td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">(bits/pixel)</td>
                <td align="left" rowspan="1" colspan="1"/>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>RND/PCA/Whitening</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">2.7</td>
                <td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pcbi.1002873-Eichhorn1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Bethge2">[43]</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <bold>ICA</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">2.9</td>
                <td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pcbi.1002873-Eichhorn1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Bethge2">[43]</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <inline-formula>
                    <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e002" xlink:type="simple"/>
                  </inline-formula>
                  <bold>-spherical</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">3.05</td>
                <td align="left" rowspan="1" colspan="1"><xref ref-type="bibr" rid="pcbi.1002873-Eichhorn1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Sinz1">[10]</xref></td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1">
                  <inline-formula>
                    <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e003" xlink:type="simple"/>
                  </inline-formula>
                  <bold>-spherical</bold>
                </td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1"/>
                <td align="left" rowspan="1" colspan="1">3.17</td>
                <td align="left" rowspan="1" colspan="1">
                  <xref ref-type="bibr" rid="pcbi.1002873-Sinz3">[62]</xref>
                </td>
              </tr>
              <tr>
                <td align="left" rowspan="1" colspan="1"><bold>MEC with</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e004" xlink:type="simple"/></inline-formula></td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1">x</td>
                <td align="left" rowspan="1" colspan="1">3.3</td>
                <td align="left" rowspan="1" colspan="1">
                  <xref ref-type="bibr" rid="pcbi.1002873-Bethge1">[33]</xref>
                </td>
              </tr>
            </tbody>
          </table>
        </alternatives>
        <table-wrap-foot>
          <fn id="nt101">
            <label/>
            <p>The natural image models we tested along with the neural response properties they mimic: “BF” is bandpass filtering, “OS” is orientation selectivity, “DN” is divisive normalization, and “CP” is complex cell pooling. We also show cited likelihood estimates. MEC is the mixture of elliptically contoured distributions model <xref ref-type="bibr" rid="pcbi.1002873-Bethge1">[33]</xref>. All models are described in detail in the “Models Tested” section. Higher likelihood indicates that a model captures more of the regularities present in natural images than a model with lower likelihood.</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <p>In our paradigm, observers perform a discrimination task where model generated samples are pitted against true natural image patches. We tile the two sets of image patches into separate textures, such as are shown in <xref ref-type="fig" rid="pcbi-1002873-g002">Figure 2</xref>, and ask the observer to select the texture of true natural image patches. The model samples are generated by redistributing the natural image content under the specific model assumptions, which preserves the patches' joint probability under the model but destroys higher-order regularities that the model assumptions fail to capture. Following Julesz's original conjecture <xref ref-type="bibr" rid="pcbi.1002873-Julesz1">[34]</xref>, above chance performance results only when the observer can make use of those additional higher-order regularities present in the natural image patches.</p>
      <fig id="pcbi-1002873-g002" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g002</object-id>
        <label>Figure 2</label>
        <caption>
          <title>Example stimulus.</title>
          <p>The left texture contains model samples, and the right texture contains only true natural image samples. Each texture is a square tiling of 64 samples, where each sample is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e005" xlink:type="simple"/></inline-formula> pixels in size. The observer's task is to indicate the texture made only of natural image samples. Feedback was given, and a short training sequence was performed before every experiment.</p>
        </caption>
        <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g002" position="float" xlink:type="simple"/>
      </fig>
      <p>The benefits of our approach are two-fold. First, by comparing the natural image models in a psychophysical framework, we complement the model comparisons based on likelihoods by a rigorous evaluation of how well the different models are able to capture perceptually relevant features. Second, we learn about the biases of the human visual system by examining whether differences in difficulty between the models relate to their statistical properties. Because our experiments are relatively short in duration (each less than 90 minutes), and natural images contain very complex regularities, fast learning results only if the human visual system is biased to process natural images <xref ref-type="bibr" rid="pcbi.1002873-Wolpert1">[35]</xref>.</p>
      <p>In the first experiment, we measure discrimination performance for all models using grayscale patches that contain a number of potential cues. We find that human observers achieve above chance performance whenever image patches are at least 5 by 5 pixels in size and that performance depends on model likelihood, suggesting the human visual system is optimized for processing natural image regularities even at a small scale. We cannot tell directly from a single experiment how the human visual system is biased for this task. Previous psychophysical studies using images with controlled regularities have identified several image statistics to which the human visual system is sensitive, including luminance histogram features <xref ref-type="bibr" rid="pcbi.1002873-Chubb1">[36]</xref>, and structural shape-related features <xref ref-type="bibr" rid="pcbi.1002873-Julesz2">[37]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Victor2">[40]</xref>. Furthermore, pixel histograms and other Fourier-based features are known to be important in the representation of natural textures <xref ref-type="bibr" rid="pcbi.1002873-Balas1">[30]</xref>. In three cue identification experiments, we examine the extent to which these kinds of features explain the discriminability of our models from the natural image distribution.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Measuring sensitivity to local natural image regularities</title>
        <p>To create stimuli with controlled regularities, we start with a set of natural image patches and generate a set of model patches equal in joint probability under the model. The patches are therefore matched in terms of the regularities captured by the model. The generation process makes use of the model assumptions critical for avoiding the curse of dimensionality: we shuffle the content of the natural image patches by applying the symmetry or independence assumptions of the model. The two sets of image patches then comprise a single discrimination trial.</p>
        <p>To illustrate the image generation process, we now step through an example of applying the independence assumption to a set of natural image patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e006" xlink:type="simple"/></inline-formula>, cut from random locations in various photographs of a natural image database <xref ref-type="bibr" rid="pcbi.1002873-vanHateren1">[41]</xref>. <xref ref-type="fig" rid="pcbi-1002873-g003">Figure 3A</xref> shows a set of 64 such patches. Consider the independent components analysis model (ICA) <xref ref-type="bibr" rid="pcbi.1002873-Bell1">[6]</xref>. Learning the model on a very large database of natural image samples, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e007" xlink:type="simple"/></inline-formula>, yields an ICA basis. To apply the independence assumption to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e008" xlink:type="simple"/></inline-formula> and generate a new set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e009" xlink:type="simple"/></inline-formula> matched in joint-probability under ICA, we first transform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e010" xlink:type="simple"/></inline-formula> into ICA coordinates and then shuffle the values of each coordinate separately across the patches, which preserves the marginal distributions of the coordinates. The resulting ICA-matched patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e011" xlink:type="simple"/></inline-formula> are shown in <xref ref-type="fig" rid="pcbi-1002873-g003">Figure 3D</xref>. We plot the first two non-DC components of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e012" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1002873-g003">Figure 3B</xref> and of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e013" xlink:type="simple"/></inline-formula> in <xref ref-type="fig" rid="pcbi-1002873-g003">Figure 3E</xref> with their marginal distributions. As shown, the marginal distributions are preserved after applying the ICA independence assumption. The radial distribution, however, has changed as shown in <xref ref-type="fig" rid="pcbi-1002873-g003">Figure 3F</xref> versus <xref ref-type="fig" rid="pcbi-1002873-g003">Figure 3C</xref>, indicating that the independence assumption of ICA is not fulfilled for natural images.</p>
        <fig id="pcbi-1002873-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Generating model samples using ICA.</title>
            <p><bold>A.</bold> A set of 64 <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e014" xlink:type="simple"/></inline-formula> pixel natural image patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e015" xlink:type="simple"/></inline-formula>. <bold>B.</bold> The coefficients of the first two (non-DC) ICA components are plotted against each other for all 64 patches along with their marginal distributions. <bold>C.</bold> Histogram of the 64 patches' norms in the ICA basis. <bold>D.</bold> To apply the ICA independence assumption to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e016" xlink:type="simple"/></inline-formula>, we shuffle the ICA coefficients across samples separately for each component. Shown are the resulting matched model patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e017" xlink:type="simple"/></inline-formula>. <bold>E.</bold> The coefficients of the first two (non-DC) ICA components of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e018" xlink:type="simple"/></inline-formula>. The marginal distributions are the same as those of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e019" xlink:type="simple"/></inline-formula> shown in <bold>B</bold>. <bold>F.</bold> Histogram of the coefficient norms of the 64 patches in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e020" xlink:type="simple"/></inline-formula>. Applying the ICA assumption has changed the radial distribution so that the variance is much lower than that of the original distribution shown in <bold>C</bold>.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g003" position="float" xlink:type="simple"/>
        </fig>
        <p>The image patches in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e021" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e022" xlink:type="simple"/></inline-formula> are then used as stimuli for a discrimination task. In each trial, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e023" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e024" xlink:type="simple"/></inline-formula> are presented simultaneously on a black background, each shown as a texture made by tightly tiling the 64 image patches (e.g. <xref ref-type="fig" rid="pcbi-1002873-g004">Figure 4</xref>). The observer's task is to indicate which texture is composed of true natural image patches.</p>
        <fig id="pcbi-1002873-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Image patch examples from Experiment 1.</title>
            <p>In Experiment 1, we tested six models in one session (RND, ICA, L2, LP, IPS, GPS) and the four mixture models in a separate session (MEC2, MEC4, MEC8, MEC16). Shown are example textures for each model. The 64 samples comprising each model texture are matched to the 64 natural image samples shown on the left. Patch size here is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e025" xlink:type="simple"/></inline-formula> pixels. On any single trial, observers viewed only one set of natural image samples and one set of model samples (e.g. as shown in <xref ref-type="fig" rid="pcbi-1002873-g002">Figure 2</xref>).</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g004" position="float" xlink:type="simple"/>
        </fig>
        <p>To measure the discriminability of a particular model from the natural image distribution, we perform several trials with different <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e026" xlink:type="simple"/></inline-formula>. If the human visual system were sensitive only to the regularities described by the model, discriminability should be at chance. Above chance performance indicates sensitivity to the natural image regularities not captured by the model. To increase the sample size of natural images contributing to each discriminability estimate, we will pool estimates over observers and trials since each trial uses a unique set of natural image patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e027" xlink:type="simple"/></inline-formula>, sampled uniformly across a very large database of natural images.</p>
        <p>In the following section, we provide detailed descriptions of the models tested, their shuffling procedures, and proofs that joint probability is matched after shuffling.</p>
      </sec>
      <sec id="s2b">
        <title>Models tested</title>
        <p>All models were learned on log-luminance natural images from the Van Hateren natural image database <xref ref-type="bibr" rid="pcbi.1002873-vanHateren1">[41]</xref>. We used log-luminance values because uniform changes in logarithmic luminance are equally detectable following the Weber-Fechner law. The log transform is also a standard procedure in natural image modeling because it decreases the asymmetry of the natural image luminance distribution, making it easier to model the higher order regularities.</p>
        <p>From the model capturing the fewest regularities to the model capturing the most, we test: 1) a random second-order model capturing only second-order correlations (RND), 2) the independent components analysis model (ICA), 3) the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e028" xlink:type="simple"/></inline-formula>-spherical model (L2), 4) the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e029" xlink:type="simple"/></inline-formula>-spherical model (LP), and 5) the mixture of elliptically contoured distributions model with four levels of mixtures (MEC with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e030" xlink:type="simple"/></inline-formula>) <xref ref-type="bibr" rid="pcbi.1002873-Bethge1">[33]</xref>. Roughly speaking, MEC is able to capture similar correlations like the Karklin &amp; Lewicki model <xref ref-type="bibr" rid="pcbi.1002873-Karklin1">[11]</xref>, or the mixture of Gaussian scale mixtures model <xref ref-type="bibr" rid="pcbi.1002873-GuerreroColon1">[32]</xref>, yet MEC uses hard clustering to partition the natural image distribution which we make use of in the stimulus generation process. Thus, each cluster is described exclusively by a zero-mean elliptically contoured distribution with its own covariance.</p>
        <p>We first discuss RND and ICA, the two linear models of natural images that we test. A linear model is defined to have statistically independent components after a linear transformation of the pixel values. The RND model consists of a set of un-oriented “pink noise” filters that capture only the covariance of natural image gray values, and ICA consists of a set of oriented filters additionally optimized for higher-order correlations. In the following, we will use vectorized image patch notation to describe a set of natural image patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e031" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e032" xlink:type="simple"/></inline-formula> is a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e033" xlink:type="simple"/></inline-formula> matrix of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e034" xlink:type="simple"/></inline-formula> patches containing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e035" xlink:type="simple"/></inline-formula> pixels each. We use lower case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e036" xlink:type="simple"/></inline-formula> to denote a single image patch in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e037" xlink:type="simple"/></inline-formula>. A linear model is fully specified by its filter matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e038" xlink:type="simple"/></inline-formula>. To obtain the coefficients of a single patch in the representation space of that model, we compute <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e039" xlink:type="simple"/></inline-formula>. The joint probability of a set of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e040" xlink:type="simple"/></inline-formula> image patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e041" xlink:type="simple"/></inline-formula> is given by<disp-formula id="pcbi.1002873.e042"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002873.e042" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e043" xlink:type="simple"/></inline-formula> denotes the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e044" xlink:type="simple"/></inline-formula>-th row vector of the filter matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e045" xlink:type="simple"/></inline-formula> and is one of many filters of the linear transformation. In general, it holds that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e046" xlink:type="simple"/></inline-formula> since the patches are drawn independently from the same distribution. Therefore, we obtain<disp-formula id="pcbi.1002873.e047"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002873.e047" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e048" xlink:type="simple"/></inline-formula> denotes an arbitrary permutation over the patches in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e049" xlink:type="simple"/></inline-formula>. As this equation shows–-by the commutativity of products—we can generate a new, equally probable set of patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e050" xlink:type="simple"/></inline-formula> by shuffling the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e051" xlink:type="simple"/></inline-formula>-indicies.</p>
        <p>The other three natural image models we test, L2, LP, and MEC, do not assume independence after the linear transformation. Instead they assume that after some linear transformation, the natural image distribution obeys certain symmetry assumptions and can be transformed into a factorial representation of independent components only by non-linear transformations.</p>
        <p>The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e052" xlink:type="simple"/></inline-formula>-spherically symmetric model is a generalization of Gaussian scale mixtures <xref ref-type="bibr" rid="pcbi.1002873-Wainwright1">[31]</xref> which assumes spherical symmetry after whitening and can be made factorial by radial Gaussianization <xref ref-type="bibr" rid="pcbi.1002873-Lyu1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Sinz1">[10]</xref>. Due to the spherical symmetry, the model is only sensitive to the power spectrum of the filters but insensitive to their detailed shape–-i.e., the model is sensitive to changes in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e053" xlink:type="simple"/></inline-formula> and thus ignores changes in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e054" xlink:type="simple"/></inline-formula> that result from an orthogonal mapping. Thus, like for RND, we chose random filter shapes for L2 akin to pink noise that capture the second-order correlations but have no specific shape otherwise.</p>
        <p>The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e055" xlink:type="simple"/></inline-formula>-spherical model is a generalization of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e056" xlink:type="simple"/></inline-formula>-spherical model which allows one to optimize the detailed filter shapes for additional higher-order correlations. While the density, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e057" xlink:type="simple"/></inline-formula>, of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e058" xlink:type="simple"/></inline-formula>-model is a function of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e059" xlink:type="simple"/></inline-formula>-norm and thus invariant under arbitrary rotations of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e060" xlink:type="simple"/></inline-formula>, the density of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e061" xlink:type="simple"/></inline-formula>-model, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e062" xlink:type="simple"/></inline-formula>, is a function of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e063" xlink:type="simple"/></inline-formula>-norm, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e064" xlink:type="simple"/></inline-formula>, which is invariant only under permutations of the coordinates. Optimizing the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e065" xlink:type="simple"/></inline-formula>-model for the van Hateren dataset <xref ref-type="bibr" rid="pcbi.1002873-vanHateren1">[41]</xref>, which we used to test the models, yields <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e066" xlink:type="simple"/></inline-formula> and the same oriented filter shapes as in the ICA model <xref ref-type="bibr" rid="pcbi.1002873-Sinz1">[10]</xref>. Also, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e067" xlink:type="simple"/></inline-formula>-spherical distribution can be made factorial by using radial factorization instead of radial Gaussianization <xref ref-type="bibr" rid="pcbi.1002873-Sinz1">[10]</xref>.</p>
        <p>The joint probability of a set of natural image patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e068" xlink:type="simple"/></inline-formula> under either the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e069" xlink:type="simple"/></inline-formula>- or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e070" xlink:type="simple"/></inline-formula>-model can be written as<disp-formula id="pcbi.1002873.e071"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002873.e071" xlink:type="simple"/><label>(3)</label></disp-formula>where in the case of L2, the filter matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e072" xlink:type="simple"/></inline-formula> is the same as that for RND, and in the case of LP, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e073" xlink:type="simple"/></inline-formula> is the same as that for ICA.</p>
        <p>We now show why permutation of the model's representation coordinates, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e074" xlink:type="simple"/></inline-formula>, within a patch preserves the patch's norm. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e075" xlink:type="simple"/></inline-formula>, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e076" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e077" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e078" xlink:type="simple"/></inline-formula> because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e079" xlink:type="simple"/></inline-formula>. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e080" xlink:type="simple"/></inline-formula>, then <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e081" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e082" xlink:type="simple"/></inline-formula> is a random permutation of the coordinate indices and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e083" xlink:type="simple"/></inline-formula> is the Kronecker delta, which equals 1 when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e084" xlink:type="simple"/></inline-formula> and zero otherwise. After permuting the coefficients within an image patch, we denote the new image patch as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e085" xlink:type="simple"/></inline-formula>. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e086" xlink:type="simple"/></inline-formula>-norm of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e087" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e088" xlink:type="simple"/></inline-formula>. Therefore, permuting the coordinates of a patch obtained from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e089" xlink:type="simple"/></inline-formula> preserves the norm in the model's representation space, and the set of generated image patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e090" xlink:type="simple"/></inline-formula> is equally probable to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e091" xlink:type="simple"/></inline-formula> following <xref ref-type="disp-formula" rid="pcbi.1002873.e071">Equation 3</xref>.</p>
        <p>Because MEC uses hard clustering to obtain non-overlapping clusters, we model each cluster by its own <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e092" xlink:type="simple"/></inline-formula>-model each using a different whitening transform. Thus, we can simply apply the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e093" xlink:type="simple"/></inline-formula>-norm symmetry to each patch once it has been transformed into the appropriate representation of its cluster.</p>
        <p>The models vary in complexity which is also reflected by the transforms necessary to obtain a factorial representation. The properties of these redundancy reduction transforms can be related to primate visual physiology (<xref ref-type="table" rid="pcbi-1002873-t001">Table 1</xref>). Linear models are linked to linear response properties that can be further divided into power and phase spectral information. RND captures the <italic>power</italic> spectral properties that are common to center-surround models of retina and LGN <xref ref-type="bibr" rid="pcbi.1002873-Atick1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Dan1">[4]</xref> and the PCA and ICA models <xref ref-type="bibr" rid="pcbi.1002873-Hyvrinen1">[42]</xref>, but it does not reproduce the more special filter shape properties determined by the differences between the models in the <italic>phase</italic> spectra. RND is therefore useful as a baseline model to disentangle the contribution of matching the second-order statistics from more specific receptive field properties. At the other extreme, ICA optimizes the more specific filter shape properties determined by the phase spectra with respect to higher-order correlations <xref ref-type="bibr" rid="pcbi.1002873-Bell1">[6]</xref>, making ICA the best possible linear model. (The center-surround model or PCA model constitute intermediate cases because their filter shape properties are better matched to natural image statistics than RND but less matched than ICA <xref ref-type="bibr" rid="pcbi.1002873-Bethge2">[43]</xref>.) The difference in performance between RND and ICA thus reflects the maximal effect among linear models that the phase spectral properties of filter shapes can have.</p>
        <p>L2 and LP are nonlinear models from the class of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e094" xlink:type="simple"/></inline-formula>-spherical models, which are related to contrast gain control <xref ref-type="bibr" rid="pcbi.1002873-Schwartz1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Sinz1">[10]</xref>. Because L2 and LP use the same filters as RND and ICA respectively, again the difference in performance between L2 and LP represents the maximal effect that the filter shapes can have beyond matching the power spectra.</p>
        <p>The mixture model also captures oriented features and represents different classes of images separately, and it is related to the model of Karklin and Lewicki, another mixture model learned on the natural image distribution which showed complex cell-like pooling properties <xref ref-type="bibr" rid="pcbi.1002873-Karklin1">[11]</xref>.</p>
        <p>Another important reason why we selected this set of models to test is because cross-validated likelihood estimates have already been reported in the literature for each of them, which we list with citations in <xref ref-type="table" rid="pcbi-1002873-t001">Table 1</xref>. All of these likelihoods were estimated in the most conservative way, where test sets and training sets of the same size were used, and the difference in likelihood between the training and test sets was tiny.</p>
        <p>We also test two Fourier “models” of natural image patches. Although we do not have their likelihood estimates, these models are intended as comparisons where patch-based Fourier statistics are isolated. Both preserve the amplitude spectra of the patchwise Fourier transforms of each patch in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e095" xlink:type="simple"/></inline-formula>, which carries most of the image appearance information for small patches <xref ref-type="bibr" rid="pcbi.1002873-Morgan1">[44]</xref>. We test independent phase scrambling (IPS), in which we preserve the patchwise power spectra and randomize the patchwise phase spectra, and we test global phase scrambling (GPS), which preserves all correlations between phases and between amplitudes yet destroys dependencies between the two.</p>
      </sec>
      <sec id="s2c">
        <title>Scale of local regularities</title>
        <p>Natural image patches were sampled from a database of grayscale photographs of outdoor scenes where 1 pixel equals approximately 2 minutes of arc <xref ref-type="bibr" rid="pcbi.1002873-vanHateren1">[41]</xref>. Discriminability was measured for different model generated stimuli at the following patch sizes: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e096" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e097" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e098" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e099" xlink:type="simple"/></inline-formula> pixels, corresponding to a range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e100" xlink:type="simple"/></inline-formula> in the original photographs. We therefore examined regularities occurring at a very fine scale in natural images, one above yet nearing the human resolution limit. We always magnified the patches on the screen because we were interested in whether observers can discriminate the regularities present in natural images at this fine scale and not in whether acuity was good enough for the task at this scale.</p>
      </sec>
      <sec id="s2d">
        <title>Experiment 1: Grayscale stimuli with many potential cues</title>
        <p>In Experiment 1, observers discriminated grayscale natural image samples from model samples, and the stimuli included all potential cues. A pair of example stimulus textures is shown in <xref ref-type="fig" rid="pcbi-1002873-g004">Figure 4</xref>. In one session, 16 observers performed the task for RND, ICA, L2, LP, IPS, and GPS at patch sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e101" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e102" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e103" xlink:type="simple"/></inline-formula> pixels. In a second session, 12 observers performed the task for the four versions of MEC with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e104" xlink:type="simple"/></inline-formula>. Because MEC is among the best in terms of likelihood (<xref ref-type="table" rid="pcbi-1002873-t001">Table 1</xref>), we additionally included <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e105" xlink:type="simple"/></inline-formula> pixel patches. Each observer completed 30 trials for each model at each patch size for a total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e106" xlink:type="simple"/></inline-formula> trials in session one and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e107" xlink:type="simple"/></inline-formula> trials in session two.</p>
        <p>Average discrimination performance is plotted in <xref ref-type="fig" rid="pcbi-1002873-g005">Figure 5</xref> as a function of patch size with 95% binomial confidence intervals. Discriminability estimates are also printed in <xref ref-type="table" rid="pcbi-1002873-t002">Table 2</xref> with stars to indicate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e108" xlink:type="simple"/></inline-formula>values. MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e109" xlink:type="simple"/></inline-formula> was the most difficult model to discriminate, and only the MEC models brought performance to chance (with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e110" xlink:type="simple"/></inline-formula> pixel patches). Observers were near ceiling with the linear models, RND and ICA, achieving respectively 96% and 94% correct on average. The spherical models, L2 and LP, were more difficult, with average discriminability dropping to 71% and 67% correct respectively. IPS and GPS were roughly between the linear and spherical models in terms of difficulty, with average discriminability at 84% and 73% correct respectively. Overall, the large proportion of data points above chance indicates that the human visual system is highly sensitive to the local features of natural images, even to the higher-order regularities the best models fail to capture. Discriminability estimates were always significantly above chance for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e111" xlink:type="simple"/></inline-formula> pixel patches and larger, indicating that no model sufficiently captured all the prominent features for patches larger than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e112" xlink:type="simple"/></inline-formula> pixels in size.</p>
        <fig id="pcbi-1002873-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Experiment 1 results.</title>
            <p>Discriminability estimates with 95% binomial confidence intervals are shown by model as a function of patch size, where data are pooled over subjects. Sixteen subjects participated in session one with RND, ICA, L2, LP, IPS, and GPS, and 12 participated in session two with the MEC models. Each subject performed 30 test trials per data point in the plot. Therefore, each data point for session one is based on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e113" xlink:type="simple"/></inline-formula> trials, and each for session two is based on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e114" xlink:type="simple"/></inline-formula> trials.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g005" position="float" xlink:type="simple"/>
        </fig>
        <table-wrap id="pcbi-1002873-t002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.t002</object-id>
          <label>Table 2</label>
          <caption>
            <title>Experiment 1 average discriminability for all models.</title>
          </caption>
          <alternatives>
            <graphic id="pcbi-1002873-t002-2" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.t002" xlink:type="simple"/>
            <table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td colspan="4" align="left" rowspan="1">Patch size (pixels)</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"/>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e115" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e116" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e117" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                  <td align="left" rowspan="1" colspan="1">
                    <inline-formula>
                      <inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e118" xlink:type="simple"/>
                    </inline-formula>
                  </td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>RND</bold>
                  </td>
                  <td align="left" rowspan="1" colspan="1">92.1<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e119" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">98.3<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e120" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">98.3<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e121" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>ICA</bold>
                  </td>
                  <td align="left" rowspan="1" colspan="1">92.7<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e122" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">94.6<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e123" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">94.4<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e124" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>IPS</bold>
                  </td>
                  <td align="left" rowspan="1" colspan="1">71.3<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e125" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">88.1<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e126" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">92.7<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e127" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>GPS</bold>
                  </td>
                  <td align="left" rowspan="1" colspan="1">59.7<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e128" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">73.8<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e129" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">84.4<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e130" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>L2</bold>
                  </td>
                  <td align="left" rowspan="1" colspan="1">62.6<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e131" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">72.8<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e132" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">77.9<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e133" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1">
                    <bold>LP</bold>
                  </td>
                  <td align="left" rowspan="1" colspan="1">55.2<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e134" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">69.2<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e135" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">77.5<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e136" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">-</td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"><bold>MEC,</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e137" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">52.8</td>
                  <td align="left" rowspan="1" colspan="1">65.0<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e138" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">75.8<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e139" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">90.3<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e140" xlink:type="simple"/></inline-formula></td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"><bold>MEC,</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e141" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">53.3</td>
                  <td align="left" rowspan="1" colspan="1">60.8<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e142" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">72.8<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e143" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">88.1<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e144" xlink:type="simple"/></inline-formula></td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"><bold>MEC,</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e145" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">50.0</td>
                  <td align="left" rowspan="1" colspan="1">63.3<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e146" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">63.6<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e147" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">81.1<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e148" xlink:type="simple"/></inline-formula></td>
                </tr>
                <tr>
                  <td align="left" rowspan="1" colspan="1"><bold>MEC,</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e149" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">49.4</td>
                  <td align="left" rowspan="1" colspan="1">55.8<sup>*</sup></td>
                  <td align="left" rowspan="1" colspan="1">61.7<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e150" xlink:type="simple"/></inline-formula></td>
                  <td align="left" rowspan="1" colspan="1">73.6<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e151" xlink:type="simple"/></inline-formula></td>
                </tr>
              </tbody>
            </table>
          </alternatives>
          <table-wrap-foot>
            <fn id="nt102">
              <label/>
              <p>Average percent corrects are listed for each model at each patch size tested. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e152" xlink:type="simple"/></inline-formula> subjects for the first six models, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e153" xlink:type="simple"/></inline-formula> subjects for the MEC models. In starred conditions the null hypothesis that performance was at chance (50%) can be rejected at the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e154" xlink:type="simple"/></inline-formula> level (*), the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e155" xlink:type="simple"/></inline-formula> level (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e156" xlink:type="simple"/></inline-formula>), or the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e157" xlink:type="simple"/></inline-formula> level (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e158" xlink:type="simple"/></inline-formula>). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e159" xlink:type="simple"/></inline-formula> pixel patches were tested only for the MEC models.</p>
            </fn>
          </table-wrap-foot>
        </table-wrap>
        <p>To examine how performance was related to model likelihood, we plotted model discriminability in order of increasing model likelihood, based on the likelihood estimates in <xref ref-type="table" rid="pcbi-1002873-t001">Table 1</xref> where RND is equivalent to PCA, and MEC's likelihood increases with more mixtures. (We do not include the Fourier models here as they are not probabilistic models and hence do not have likelihoods.) Each bar in <xref ref-type="fig" rid="pcbi-1002873-g006">Figure 6A</xref> is one model's discriminability with 95% binomial confidence intervals for data pooled over subjects and patch sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e160" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e161" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e162" xlink:type="simple"/></inline-formula> pixels. RND, ICA, L2, and LP estimates are based on 1,440 trials each, and MEC models on 1,080 trials each. Discriminability decreases as model likelihood increases.</p>
        <fig id="pcbi-1002873-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Model discriminability and likelihood.</title>
            <p><bold>A.</bold> Discriminability estimates with 95% binomial confidence intervals plotted in order of increasing model likelihood. Data is pooled over subjects and patch sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e163" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e164" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e165" xlink:type="simple"/></inline-formula> pixels. Each data point for RND, ICA, L2, and LP contains 1,440 trials, and 1,080 trials for the MEC models. MEC models are identified by the number of mixtures. Chance performance was 50%. <bold>B.</bold> Discriminability estimates with 95% binomial confidence intervals for one subject who performed 5 sessions of a four alternative choice version of the experiment. Each data point for RND, ICA, L2, and LP contains 576 trials, and 144 for the MEC models. Chance was 25%. <bold>C.</bold> Discriminability ranks of the models from most difficult to easiest are plotted against likelihood ranks from lowest likelihood to highest. Diamonds show group average data from <bold>A</bold>, and circles show the individual subject's data from <bold>B</bold>. The group data contain more trials and show a clear decrease in discriminability with increased likelihood. The same order is shown in the individual subject data within the range of the 95% confidence intervals, which overlap for L2, LP, and MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e166" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g006" position="float" xlink:type="simple"/>
        </fig>
        <p>We analogously examined the data of a single subject, plotted in <xref ref-type="fig" rid="pcbi-1002873-g006">Figure 6B</xref>. The subject performed 4,032 trials of a more sensitive version of the experiment (chance = 25%) in 4 sessions with RND, ICA, L2, LP, IPS, and GPS and one session with the MEC models. In <xref ref-type="fig" rid="pcbi-1002873-g006">Figure 6B</xref>, estimates for RND, ICA, L2, and LP are based on 576 trials each, and MEC estimates on 144 trials each. Within the range of the 95% binomial confidence intervals, which overlap for L2, LP, and MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e167" xlink:type="simple"/></inline-formula>, theses data show the same pattern of decreased discriminability with increased model likelihood.</p>
        <p>In <xref ref-type="fig" rid="pcbi-1002873-g006">Figure 6C</xref>, we plot the model ranks in terms of discriminability against the model ranks in terms of likelihood for all the data points in <xref ref-type="fig" rid="pcbi-1002873-g006">Figure 6A and B</xref>. The pattern shows that discriminability decreases as model likelihood increases.</p>
        <p>Feedback was provided throughout the experiment, so we analyzed the data for learning by splitting the data in half over time and comparing discriminability estimates across the two halves. If the 95% binomial confidence intervals of the two estimates do not overlap, there may have been learning (or anti-learning). Binomial confidence intervals assume trial independence and therefore underestimate confidence interval width in the case that subjects' behavior was non-stationary <xref ref-type="bibr" rid="pcbi.1002873-Frnd1">[45]</xref>, so the test we report is biased away from false negatives and thus rather over sensitive to learning. We applied this test for each model separately with data pooled over subjects and patch sizes. In the 2AFC version of the experiment with 16 subjects, the only significant effect was for the ICA model: discriminability increased by 4% from 91% to 95% correct. In the 4AFC version of the experiment with 1 subject, discriminability with ICA also improved from 87% to 96% correct and with IPS from 70% to 82% correct.</p>
      </sec>
      <sec id="s2e">
        <title>Experiment 2: Luminance histogram cues only</title>
        <p>Human observers can discriminate textures on the basis of three mechanisms sensitive to luminance histogram features <xref ref-type="bibr" rid="pcbi.1002873-Chubb1">[36]</xref>. We therefore hypothesized that luminance histogram differences between natural samples and model samples were a prominent cue. We tested this hypothesis in Experiment 2, where we compared two new manipulations to performance in Experiment 1, whose stimuli contained several potential cues, including both shape and luminance features. We will refer to them as the “unperturbed” stimuli. The two new manipulations used pixel-scrambling, which was applied to the unperturbed stimuli as a final post-processing step before presenting the textures. In one condition we permuted the pixels globally within each texture to produce “global scrambles” (<xref ref-type="fig" rid="pcbi-1002873-g007">Figure 7A</xref>). In the second condition, we permuted pixels within each unperturbed image patch separately to produce “sample scrambles” (<xref ref-type="fig" rid="pcbi-1002873-g007">Figure 7B</xref>).</p>
        <fig id="pcbi-1002873-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Experiment 2 texture scrambles.</title>
            <p>Here we show example textures for each model tested in Experiment 2: RND, ICA, L2, LP, IPS, GPS, and MEC16. Both <bold>A</bold> and <bold>B</bold> are scrambled versions of the corresponding model stimuli shown in <xref ref-type="fig" rid="pcbi-1002873-g004">Figure 4</xref>. On any single trial the observer viewed only one texture based on natural image samples and one texture based on samples from a single model. <bold>A.</bold> Global scrambles, where the pixels of each texture were scrambled as a final post-processing step. <bold>B.</bold> Sample scrambles, where the pixels of each image patch were scrambled individually to preserve variations in luminance histograms across samples.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g007" position="float" xlink:type="simple"/>
        </fig>
        <p>We tested all models from Experiment 1 except that we tested only the best MEC model, MEC with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e168" xlink:type="simple"/></inline-formula>, for which we excluded <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e169" xlink:type="simple"/></inline-formula> pixel patches since observers were at chance in Experiment 1 at that size. All other aspects of Experiment 2 were identical to Experiment 1. Three observers participated. Each completed 30 trials per patch size per model per condition for a total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e170" xlink:type="simple"/></inline-formula> trials.</p>
        <p>The results are shown in <xref ref-type="fig" rid="pcbi-1002873-g008">Figure 8A</xref> as percent corrects pooled over the 3 observers with 95% binomial confidence intervals. Solid lines are these observers' discriminability estimates for the unperturbed stimuli (from Experiment 1). Dotted lines are for the global scrambles, and long dashed lines are for the sample scrambles. Discriminability of the linear models, RND and ICA, was unaffected by both types of pixel scrambling and remained near ceiling. This indicates that luminance histogram cues were sufficient for observers to discriminate the unperturbed RND and ICA samples from natural samples. Furthermore, ceiling performance indicates the luminance histogram cues were highly prominent for RND and ICA. With L2 and LP, discriminability dropped close to chance with global scrambles, but there was very little difference between discriminability of sample scrambles and of unperturbed stimuli, which indicates that the L2 and LP models failed to reproduce luminance histogram variations across natural samples. Observers were at chance with both types of scrambles for IPS, GPS, and for MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e171" xlink:type="simple"/></inline-formula>.</p>
        <fig id="pcbi-1002873-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Experiment 2 results.</title>
            <p><bold>A.</bold> Discriminability estimates with 95% binomial confidence intervals are shown by model as a function of patch size. Three subjects participated, and each performed 30 test trials per model per patch size per condition, so each data point is based on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e172" xlink:type="simple"/></inline-formula> trials. We did not measure discriminability for MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e173" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e174" xlink:type="simple"/></inline-formula> pixel patches as observers were at chance with them in Experiment 1. The solid line shows these observers' data in Experiment 1, i.e. with unperturbed stimuli, the dotted line shows performance for global scrambles, and the dashed line for sample scrambles. <bold>B.</bold> Discriminability estimates averaged over patch size for each model are plotted in order of increasing likelihood. The colored bars are the data from Experiment 1, the translucent bars with dashed edges are for the global scrambles, and the bars with solid edges are for the sample scrambles. In all three conditions, the ordering is the same: higher likelihood is linked with lower discriminability.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g008" position="float" xlink:type="simple"/>
        </fig>
        <p>We also plot discriminability estimates averaged over all patch sizes in order of model likelihood in <xref ref-type="fig" rid="pcbi-1002873-g008">Figure 8B</xref> for each condition separately: colored bars are for the Experiment 1 data, translucent bars with dashed edges for the global scrambles, and transparent bars with solid edges for the sample scrambles. The same ordering in terms of discriminability was found in all conditions and followed the likelihood ordering as in Experiment 1.</p>
        <p>The overall results indicate that contrast fluctuations are a highly prominent feature of natural images that is completely lost by linear models and poorly captured by the spherically symmetric models. Of the probabilistic models we tested, only MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e175" xlink:type="simple"/></inline-formula> captured the contrast fluctuations so well as to fool the human observer.</p>
        <p>Using the learning test reported in Experiment 1, we also analyzed the data for each model separately for the two conditions with data pooled over subjects and patch sizes. There were no significant effects of learning, but discriminability significantly decreased for LP in the global scrambling condition by 10% from 66% to 56% correct.</p>
      </sec>
      <sec id="s2f">
        <title>Experiment 3: Grayscale shape cues highlighted</title>
        <p>In Experiment 3, we measured sensitivity to the shape content of natural images separately from the effects of the highly prominent contrast fluctuations found in Experiment 2. To this end, we developed a procedure for removing the contrast fluctuation cue by matching the contrast fluctuations across model samples to those in the natural samples on a trial-by-trial basis. An example stimulus is shown in <xref ref-type="fig" rid="pcbi-1002873-g009">Figure 9</xref>. <xref ref-type="fig" rid="pcbi-1002873-g004">Figure 4</xref> contains the unperturbed version of the same samples.</p>
        <fig id="pcbi-1002873-g009" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g009</object-id>
          <label>Figure 9</label>
          <caption>
            <title>Experiment 3 contrast fluctuation matched model samples.</title>
            <p>The contrast fluctuations of each model sample set have been artificially matched to the contrast fluctuations across the natural samples by matching the distribution of grayscale pixel norms to that of the natural samples. Each texture is the fluctuation matched version of the corresponding stimulus in <xref ref-type="fig" rid="pcbi-1002873-g004">Figure 4</xref>.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g009" position="float" xlink:type="simple"/>
        </fig>
        <p>This manipulation makes the task more difficult, so we modified the task to allow observers to inspect the images as long as they needed while also encouraging them to reply as quickly as possible without sacrificing accuracy. We compare discriminability estimates for the unperturbed version and the contrast fluctuation matched version both run under the same experiment parameters. The experiment was therefore two conditions, which we randomly interleaved in one session. We tested only RND, ICA, L2, and LP. In Experiment 2 we found that MEC, IPS, and GPS perfectly model the contrast fluctuations for observers, indicating that the results of Experiment 1 had already revealed how well these models capture shape information when luminance histograms are well matched. To avoid redundancy and make good use of our observers' time, we therefore excluded them here. We measured performance at patch sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e176" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e177" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e178" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e179" xlink:type="simple"/></inline-formula> pixels. Nine observers participated. Each observer completed 36 test trials per model per condition per patch size for a total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e180" xlink:type="simple"/></inline-formula> trials. All other experiment details were the same as in Experiment 1. We use <sup>*</sup> after model names for the condition where contrast fluctuations were artificially matched to the natural samples since the manipulation alters the probabilistic models.</p>
        <p><xref ref-type="sec" rid="s2">Results</xref> are shown in <xref ref-type="fig" rid="pcbi-1002873-g010">Figure 10A</xref> for the unperturbed stimuli and in <xref ref-type="fig" rid="pcbi-1002873-g010">Figure 10B</xref> for the contrast fluctuation matched stimuli. We plot the average discriminability over all patch sizes for each model in order of increasing likelihood in <xref ref-type="fig" rid="pcbi-1002873-g010">Figure 10C</xref>, where unfilled bars are for unperturbed stimuli and filled are for matched stimuli. The unperturbed results are similar to the Experiment 1 results. In particular, the discriminability rankings of the models were the same. Surprisingly, the rankings followed a different pattern with contrast fluctuation matched stimuli: estimates were very similar for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e181" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e182" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e183" xlink:type="simple"/></inline-formula>, on average 74% correct, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e184" xlink:type="simple"/></inline-formula> was more difficult than the other models. In fact, the average discriminability of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e185" xlink:type="simple"/></inline-formula>, 62% correct averaged over patch sizes, was on par with that of MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e186" xlink:type="simple"/></inline-formula> in Experiment 1, 60% correct. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e187" xlink:type="simple"/></inline-formula> also brought performance to chance for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e188" xlink:type="simple"/></inline-formula> pixel patches, a great improvement over the unperturbed version.</p>
        <fig id="pcbi-1002873-g010" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g010</object-id>
          <label>Figure 10</label>
          <caption>
            <title>Experiment 3 results.</title>
            <p>Discriminability estimates are plotted with 95% binomial confidence intervals. Nine subjects participated, and each performed 36 test trials per model per condition per patch size, so each data point in <bold>A</bold> and <bold>B</bold> is based on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e189" xlink:type="simple"/></inline-formula> trials. MEC, IPS, and GPS were not included in the experiment because they perfectly captured the contrast fluctuation cue in Experiment 2. <bold>A.</bold> <xref ref-type="sec" rid="s2">Results</xref> from the unperturbed stimulus condition. <bold>B.</bold> <xref ref-type="sec" rid="s2">Results</xref> from the contrast fluctuation matched stimulus condition. <bold>C.</bold> Discriminability estimates pooled over patch sizes and plotted in order of increasing model likelihood. The unfilled bars are for the unperturbed stimulus data in <bold>A</bold>, the filled bars for the data in <bold>B</bold>. As expected the model ordering for the data in <bold>A</bold> are the same as in Experiment 1, but the model ordering changed for the contrast fluctuation matched data, showing that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e190" xlink:type="simple"/></inline-formula> brought performance closest to chance out of all models whereas ICA was near ceiling with the unperturbed stimuli.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g010" position="float" xlink:type="simple"/>
        </fig>
        <p>Using the learning test reported in Experiment 1, we also analyzed the data for each model separately for the two conditions with data pooled over subjects and patch sizes. There were no significant effects of learning.</p>
      </sec>
      <sec id="s2g">
        <title>Experiment 4: Binary images</title>
        <p>In Experiment 3, where we highlighted the shape content of natural images, we found a surprising result that the discriminability ranking of the models changed dramatically when the contrast fluctuation cue was removed. To examine the robustness of this effect, we performed a second manipulation focusing on shape content. This time we preserved the statistical properties of the models by using binary images as stimuli, where we thresholded gray values as a final post-processing step before presenting the stimuli. This procedure preserves luminance contours and hence some basic shape content.</p>
        <p>To avoid homogeneous patches lacking shape content, we limited our natural samples to high contrast image patches. In a pilot binary experiment where we considered all possible natural image patches, we found that the number of homogeneous patches is a highly prominent cue, so we wanted to remove it from this experiment and focus instead on shape information located in the heterogenous regions of natural images. However, it turned out that using only high contrast patches increases the difficulty of the task greatly, so we again used unlimited presentation times as in Experiment 3. To account for the increased difficulty of the high contrast stimulus set, we measured performance for grayscale (unperturbed) stimuli in addition to the binary version. A set of high contrast grayscale stimuli is shown in <xref ref-type="fig" rid="pcbi-1002873-g011">Figure 11A</xref> with the binary version in <xref ref-type="fig" rid="pcbi-1002873-g011">Figure 11B</xref>.</p>
        <fig id="pcbi-1002873-g011" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g011</object-id>
          <label>Figure 11</label>
          <caption>
            <title>Experiment 4 high contrast stimuli.</title>
            <p>To focus on regions of natural images containing shape information, we automatically selected high contrast natural image patches for use as stimuli. <bold>A.</bold> Grayscale stimuli for the 8 models we tested: RND, ICA, L2, LP, MEC2, MEC4, MEC8, MEC16. <bold>B.</bold> The binary version of <bold>A</bold> where the number of on and off pixels are held equal. On any only trial, the observer viewed only one set of natural image samples and one set of samples from a single model.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g011" position="float" xlink:type="simple"/>
        </fig>
        <p>All experimental parameters and models were the same as in Experiment 3, except that we tested all four MEC models with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e191" xlink:type="simple"/></inline-formula> mixtures. MEC models were blocked into two sessions, one for the grayscale high contrast patches, the other for the binary version. The other models were analogously blocked. Seven subjects participated. Each completed 36 test trials per model per patch size per session for a total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e192" xlink:type="simple"/></inline-formula> trials.</p>
        <p><xref ref-type="sec" rid="s2">Results</xref> are shown in <xref ref-type="fig" rid="pcbi-1002873-g012">Figure 12</xref>, where we plot discriminability estimates with 95% binomial confidence intervals for each model in order of increasing likelihood, with trials pooled over patch sizes. Unfilled bars show estimates for grayscale stimuli and filled bars for binary stimuli. Grayscale stimuli led to the same discriminability ranking of the models as in Experiment 1. In the binary condition, on the other hand, the model ordering disappeared. The above chance performance indicates that all models failed to capture the binary shape cues perfectly for the observers.</p>
        <fig id="pcbi-1002873-g012" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002873.g012</object-id>
          <label>Figure 12</label>
          <caption>
            <title>Experiment 4 results.</title>
            <p>Discriminability estimates with 95% binomial confidence intervals are shown by model in order of increasing likelihood where data are pooled over subjects and patch sizes (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e193" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e194" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e195" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e196" xlink:type="simple"/></inline-formula>). Seven subjects participated, and each performed 36 test trials per model per patch size per condition, so each data point is based on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e197" xlink:type="simple"/></inline-formula> trials. Unfilled bars are for the grayscale high contrast stimuli, and filled bars the binary version. Within the range of the error bars, the estimates for the grayscale stimuli followed the same ordering as in Experiment 1, yet the data for the binary stimuli show no ordering.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002873.g012" position="float" xlink:type="simple"/>
        </fig>
        <p>Again, using the learning test reported in Experiment 1, we analyzed the data for each model separately for the two conditions with data pooled over subjects and patch sizes. There were no significant effects of learning.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>Several psychophysical studies have measured texture discrimination in terms of statistical constraints used to generate artificial stimuli <xref ref-type="bibr" rid="pcbi.1002873-Chubb1">[36]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Victor2">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Klein1">[46]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Victor3">[49]</xref> and have established an extensive description of local image statistics to which the human visual system is sensitive. One study <xref ref-type="bibr" rid="pcbi.1002873-Tkacik1">[50]</xref> has linked sensitivity to synthetic textures with the informativeness of natural image regularities as well. In the current study we use probability density function models of natural images to directly measure sensitivity to statistical regularities present in natural images. Previous work with such models largely focuses on the link between natural image statistics and neurophysiology <xref ref-type="bibr" rid="pcbi.1002873-Atick1">[3]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Karklin1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Wainwright1">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Bethge1">[33]</xref> although one study evaluates the perceptual redundancy of the independent components analysis model <xref ref-type="bibr" rid="pcbi.1002873-Bethge3">[51]</xref>. In this work we evaluated the link between perceptual sensitivity and a variety of probability density function models of natural images.</p>
      <p>After testing a series of natural image models from one capturing only second-order correlations (RND) to one among the current state-of-the-art in capturing higher-order correlations (MEC, <xref ref-type="bibr" rid="pcbi.1002873-Bethge1">[33]</xref>), we found that human observers achieved above chance performance in most cases (<xref ref-type="fig" rid="pcbi-1002873-g005">Figure 5</xref>) and that discriminability was worse for models with higher likelihood, i.e., models that captured more natural image regularities. However, even for the model with the highest likelihood, observers were well above chance to discriminate natural image regularities from model regularities for patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e198" xlink:type="simple"/></inline-formula> pixels (approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e199" xlink:type="simple"/></inline-formula> during natural viewing) in size or larger, which suggests that the human visual system possesses a surprisingly detailed knowledge of the natural image distribution, at least in comparison to the models currently studied in the machine learning community.</p>
      <p>There were a number of reasons we might not have found such high levels of performance. The stimulus patches corresponded to very local image regions, and the pixel quantization was clearly visible, which could have masked some of the low spatial frequency content of the stimuli. Furthermore, the natural image dataset <xref ref-type="bibr" rid="pcbi.1002873-vanHateren1">[41]</xref> is likely to include some images with significant blur whenever there was a limitation in the depth of field. To the extent that these kinds of issues affected our data, they could only underestimate human potential on the task, so the impressive levels of above chance performance we report are only lower bounds.</p>
      <p>The second important conclusion relates to the model ordering in terms of discriminability. To explain the significance of this result in terms of understanding the human visual system, we need to return to the idea of the natural image distribution, which we alluded to in the <xref ref-type="sec" rid="s1">Introduction</xref> with <xref ref-type="fig" rid="pcbi-1002873-g001">Figure 1</xref>. The distribution of all possible natural images has a particular density that differs greatly from uniform because natural images have a high degree of correlations. Model likelihood describes how well a model captures the true density. A separate question is how sensitive human observers are to the natural image distribution. The human visual system need not be sensitive to all information in images and thus may be optimized only for a subset of regularities that are perceptually relevant. In this case, if higher likelihood merely indicates that a model captures more regularities regardless of perceptual relevance, models with high likelihood need not lead to more natural looking samples than low likelihood models. However, for all models tested here, human performance was worse with increased model likelihood. We found this ordering relationship in all experiments where luminance values were unperturbed (<xref ref-type="fig" rid="pcbi-1002873-g006">Figures 6A, 6B</xref>, <xref ref-type="fig" rid="pcbi-1002873-g008">8B</xref>, <xref ref-type="fig" rid="pcbi-1002873-g010">10C</xref>, and <xref ref-type="fig" rid="pcbi-1002873-g012">12</xref> unfilled bars). We regard this ordering as evidence that the visual system is biased for processing natural images.</p>
      <p>Our discrimination task constitutes a high dimensional classification problem. Each experiment was run in a single session less than 90 minutes in duration, and in all cases we found very little or no evidence of learning during the test trials. The fact that observers could learn this task so quickly during the few training trials indicates a bias of the system for processing natural images. In machine learning, the “no free lunch” theorem <xref ref-type="bibr" rid="pcbi.1002873-Wolpert1">[35]</xref> states that all classification algorithms perform the same on average over all tasks. Put another way, the performance of a classification algorithm–-including those of human observers–-on our task reflects how biased it is for this particular task. While the pattern of performance provides evidence for the existence of a bias, it does not provide specific feedback about how the bias is implemented by the visual system. In the three cue identification experiments, we examined which natural image features were prominent cues to the discrimination task.</p>
      <p>We can draw two clear conclusions about the perceptual importance of some of the model features.</p>
      <p>The first conclusion relates to the importance of filter shapes. We tested two pairs of models that differed only in filter shape: a random second-order model and the independent components analysis model (RND vs. ICA) and the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e200" xlink:type="simple"/></inline-formula>-spherically symmetric model using random filter shapes and the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e201" xlink:type="simple"/></inline-formula>-spherical model using the ICA filters (L2 vs. LP). Even though a general proportionality between discriminability and model likelihood does not exist (only an ordering relationship), the previously reported small effect of filter shape on likelihood <xref ref-type="bibr" rid="pcbi.1002873-Eichhorn1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Bethge2">[43]</xref> was mirrored by very small differences in discriminability here. As shown in <xref ref-type="fig" rid="pcbi-1002873-g006">Figures 6A and 6B</xref>, the differences from RND to ICA and from L2 to LP are very small, indicating that using a linear transformation with oriented filters translates into a very small perceptual benefit. This result implies that the oriented filters of the independent components analysis model make only a small improvement over a pink-noise like representation in capturing perceptually prominent natural image features.</p>
      <p>The second conclusion is that spherical models do not fully reproduce local luminance histogram variations sufficiently (<xref ref-type="fig" rid="pcbi-1002873-g008">Figure 8A</xref> long dashed lines) even though they are meant to capture contrast fluctuations <xref ref-type="bibr" rid="pcbi.1002873-Schwartz1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Sinz1">[10]</xref>. Overall, the most difficult model to discriminate from natural images was the mixture of elliptically contoured distributions model, which apparently reproduced the luminance histograms sufficiently but failed to capture the structural patterns in natural images sufficiently at the largest sizes we tested.</p>
      <sec id="s3a">
        <title>Local structure information</title>
        <p>Our results indicated that luminance histogram features are highly informative about model versus natural image identity for most of the models we tested. In Experiments 3 and 4, we aimed to “partial out” these cues and evaluate model efficacy with respect to structural information instead. Previous studies of human sensitivity to local shape structure show that particular fourth-order correlations in binary images are perceptually salient <xref ref-type="bibr" rid="pcbi.1002873-Victor1">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Victor2">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Victor3">[49]</xref> and correspond to informative features of natural images <xref ref-type="bibr" rid="pcbi.1002873-Tkacik1">[50]</xref>. We wanted to examine the extent to which the models we tested capture any kind of perceptually prominent structural information at the patch sizes presented.</p>
        <p>In Experiment 3, where we removed the contrast fluctuation cue, the ordering of the models in terms of discriminability dramatically changed. The originally large difference from our second-order model (RND) to the spherical models capturing higher-order correlations (L2, LP) disappeared, and all three models were the same in terms of difficulty (<xref ref-type="fig" rid="pcbi-1002873-g010">Figures 10B</xref>). This suggests that the main advantage of the spherical models has little to do with capturing the structural or shape content of natural images. Rather, when this result is taken together with the results of Experiment 2, where L2 and LP were more difficult than RND with luminance histograms as the only cue (<xref ref-type="fig" rid="pcbi-1002873-g008">Figure 8</xref>), it is clear that the main advantage of spherical models is due to better preservation of contrast fluctuations. What was more surprising was that the ICA model became the most difficult model to discriminate from natural images (<xref ref-type="fig" rid="pcbi-1002873-g010">Figures 10B</xref>), suggesting that the shape of the ICA filters offers some advantage over random filters although they are not perfect, as indicated by above chance performance.</p>
        <p>In Experiment 4, we removed all luminance histogram cues by using binary image patches as stimuli (where patches were automatically selected to contain spatial variations). Thresholding the luminance values preserves the shape of the luminance contours. When this kind of shape information is the only cue, all models were equally difficult although observers were still above chance (<xref ref-type="fig" rid="pcbi-1002873-g012">Figure 12</xref> filled bars), meaning that they can make use of such shape cues. Even though the percent correct for ICA was again lower than the other models, this difference is not significant here. Discriminability was not affected by binarization for LP and all higher likelihood models (overlap of filled and unfilled bars in <xref ref-type="fig" rid="pcbi-1002873-g012">Figure 12</xref>), which suggests that the luminance contour shapes are likely to be one of the main cues used to discriminate these models from natural images. We take these results as an indication that the shapes of the luminance contours preserved after binarization are an important perceptual feature of natural images. Elder has demonstrated their perceptual informativeness using a different technique in which he reproduced the appearance of photographic images very well from only such contours and local contrast values <xref ref-type="bibr" rid="pcbi.1002873-Elder1">[52]</xref>. Our results suggest that none of the common grayscale natural image models captures these contour statistics sufficiently and that higher likelihood models are no better with it than a random second-order model.</p>
      </sec>
      <sec id="s3b">
        <title>Studying visual sensitivity to natural image regularities</title>
        <p>Studying sensitivity to natural image regularities is a challenging pursuit for several reasons, not least of which is their high-dimensional complexity. One approach is to focus on a particular aspect of natural images, measure its distribution, and examine whether the visual system is biased for the empirical distribution. Girschick and colleagues <xref ref-type="bibr" rid="pcbi.1002873-Girshick1">[53]</xref> have taken such an approach to study the visual system's knowledge of local orientation statistics in natural images. Other approaches rely on generating stimuli with controlled natural image features. The more classical technique has been to use the Fourier transform to examine sensitivity to higher-order natural image correlations via phase quantization or scrambling in large images, e.g. <xref ref-type="bibr" rid="pcbi.1002873-Thomson1">[19]</xref>–<xref ref-type="bibr" rid="pcbi.1002873-Emrith1">[25]</xref>, and a more recent technique is to use a texture synthesis model, such as the Portilla-Simoncelli model <xref ref-type="bibr" rid="pcbi.1002873-Portilla1">[29]</xref>, which can represent a wide range of natural textures very convincingly and whose parameters can be interpreted in terms of neural responses. Psychophysical studies using the Portilla-Simoncelli model have advanced our understanding of peripheral visual processing <xref ref-type="bibr" rid="pcbi.1002873-Balas2">[54]</xref>,<xref ref-type="bibr" rid="pcbi.1002873-Rosenholtz1">[55]</xref>, and have uncovered physiological properties of early visual cortex <xref ref-type="bibr" rid="pcbi.1002873-Freeman1">[56]</xref>.</p>
        <p>We used a new technique to generate stimulus images. Our approach is to selectively randomize the content of true natural images within the assumptions of a probabilistic natural image model. The primary difference between our approach and previous ones is that our stimuli are explicitly constructed to be equally probable for a given probabilistic image model, so it allows us to test the model assumptions. Furthermore, by using models whose likelihoods have been computed, we can directly relate performance to the degree of regularities captured by the model.</p>
      </sec>
      <sec id="s3c">
        <title>Natural image model evaluation</title>
        <p>It is an open question how best to evaluate probabilistic models of natural images, and a variety of quantitative analyses have been used previously, including reconstruction error, multi-information and likelihood evaluation (e.g. in <xref ref-type="bibr" rid="pcbi.1002873-Eichhorn1">[8]</xref>). Likelihood is proportional to the amount of regularities a model captures, yet the total amount of regularities present in the natural image distribution is not known, nor was it known whether likelihood relates to perceptual measures of model efficacy. The results of our experiments show, however, that likelihood seems to have good predictive power about perceptual relevance.</p>
        <p>While many machine learning studies have based their model comparisons on <italic>ad hoc</italic> judgments about the perceptual resemblance to natural images, our paradigm provides a rigorous tool for model evaluation and comparison: psychophysical discriminability measures, which vary from chance (perfect model) to ceiling (significant model failure). Furthermore, the paradigm can be used to measure model performance at capturing particular natural image features (e.g. our cue identification experiments).</p>
      </sec>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <sec id="s4a">
        <title>Ethic statement</title>
        <p>The experiments were approved by the Ethics Commission of the Medical Faculties of the Eberhard Karls University and the University Clinics of Tübingen. All subjects gave informed consent prior to the experiment.</p>
      </sec>
      <sec id="s4b">
        <title>Subjects</title>
        <p>Subjects were adults with normal or corrected-to-normal vision. All subjects were naive except author HEG who participated in Experiment 1 session 1, and Experiments 2–4.</p>
      </sec>
      <sec id="s4c">
        <title>Apparatus</title>
        <p>Stimuli were displayed on a linearized Siemens SMM 21106 LS 21-inch CRT monochrome display, which had a maximum luminance of 423 cd/m<sup>2</sup>, in a dim room. A forehead bar and chinrest were used to fix the viewing distance at 90 cm. Experiments 1 and 2 used a Cambridge Research Systems Visage graphics controller with a 14-bit grayscale resolution, Cedrus RB-530 response box, and were programmed using the Cambridge Research Systems VSG toolbox for MATLAB. Experiments 3 and 4 used a custom DATAPixx controller with 16-bit grayscale resolution, the 5 button RESPONSEPixx response box, and were programmed using the Psychophysics Toolbox for MATLAB <xref ref-type="bibr" rid="pcbi.1002873-Brainard1">[57]</xref>, <xref ref-type="bibr" rid="pcbi.1002873-Kleiner1">[58]</xref>.</p>
      </sec>
      <sec id="s4d">
        <title>Natural image samples</title>
        <p>All natural image sampling and modeling was performed using the Natural Image Statistics Density Estimation Toolbox (nisdet) <xref ref-type="bibr" rid="pcbi.1002873-Sinz2">[59]</xref>. For each patch size (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e202" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e203" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e204" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e205" xlink:type="simple"/></inline-formula> pixels), a set of 64,000 natural image patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e206" xlink:type="simple"/></inline-formula>, were sampled uniformly both across and within the images of the van Hateren natural image database <xref ref-type="bibr" rid="pcbi.1002873-vanHateren1">[41]</xref>. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e207" xlink:type="simple"/></inline-formula> is an <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e208" xlink:type="simple"/></inline-formula> matrix where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e209" xlink:type="simple"/></inline-formula> is the number of pixels in the patch. We stored the natural logarithm of the individual pixel values in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e210" xlink:type="simple"/></inline-formula>. We centered <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e211" xlink:type="simple"/></inline-formula> by removing the row mean from each entry in each row and the column mean from each entry in each column and then scaled the result such that the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e212" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e213" xlink:type="simple"/></inline-formula> is a matrix that projects out the DC component using a QR decomposition, which makes whitening a volume conserving transform <xref ref-type="bibr" rid="pcbi.1002873-Eichhorn1">[8]</xref>.</p>
        <p>We preprocessed the data with filter matrices <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e214" xlink:type="simple"/></inline-formula> of the form <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e215" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e216" xlink:type="simple"/></inline-formula> is the aforementioned matrix that projects out the DC component, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e217" xlink:type="simple"/></inline-formula> is a whitening matrix, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e218" xlink:type="simple"/></inline-formula> is an orthogonal matrix (i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e219" xlink:type="simple"/></inline-formula>). While we kept <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e220" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e221" xlink:type="simple"/></inline-formula> fixed, we varied <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e222" xlink:type="simple"/></inline-formula> to determine the actual filter shapes. Note that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e223" xlink:type="simple"/></inline-formula> is white for any orthogonal matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e224" xlink:type="simple"/></inline-formula>. Each filter matrix can be inverted to define a complimentary synthesis matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e225" xlink:type="simple"/></inline-formula> such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e226" xlink:type="simple"/></inline-formula>.</p>
        <p>We used two types of orthogonal matrices: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e227" xlink:type="simple"/></inline-formula>, a random orthogonal matrix, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e228" xlink:type="simple"/></inline-formula>, the independent components analysis model basis. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e229" xlink:type="simple"/></inline-formula> was learned using the fastICA <xref ref-type="bibr" rid="pcbi.1002873-Hyvarinen1">[60]</xref> algorithm to initialize the filter shapes. We then optimized them via a gradient ascent on the log-likelihood of a factorial model with exponential power distributed marginals <xref ref-type="bibr" rid="pcbi.1002873-Eichhorn1">[8]</xref>. Below, the subindex of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e230" xlink:type="simple"/></inline-formula> denotes which <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e231" xlink:type="simple"/></inline-formula> was used.</p>
        <p>For each mixture of elliptically contoured distributions model, we first clustered the natural image data into <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e232" xlink:type="simple"/></inline-formula> clusters using k-means. Then we calculated the inverse square root covariance matrix of each cluster, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e233" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e234" xlink:type="simple"/></inline-formula> indexes the cluster number from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e235" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e236" xlink:type="simple"/></inline-formula> depending on the number of mixtures in the model.</p>
      </sec>
      <sec id="s4e">
        <title>Model samples</title>
        <p>To generate model samples, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e237" xlink:type="simple"/></inline-formula>, we start with 64 image patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e238" xlink:type="simple"/></inline-formula>, randomly sampled from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e239" xlink:type="simple"/></inline-formula>. (In a single experimental session, different <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e240" xlink:type="simple"/></inline-formula> are sampled on every trial for each model patch size combination, but the same superset of all <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e241" xlink:type="simple"/></inline-formula> used to test one model patch size combination are used to test all other models at that patch size.) We use the following general formula: 1) transform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e242" xlink:type="simple"/></inline-formula> to the coordinate system of the model using the appropriate filter matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e243" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e244" xlink:type="simple"/></inline-formula>, 2) apply the model assumptions to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e245" xlink:type="simple"/></inline-formula> to obtain a new <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e246" xlink:type="simple"/></inline-formula>, 3) transform back to pixel space using the appropriate synthesis matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e247" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e248" xlink:type="simple"/></inline-formula>.</p>
        <p>The kind of shuffling applied in step 2 is determined by the model assumptions. We use two types of such shuffling. The first type applies an independence assumption to the data and shuffles the non-DC coefficients within each coordinate separately across all samples in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e249" xlink:type="simple"/></inline-formula>. The second type applies a symmetry assumption to the data and permutes the non-DC coefficients separately within each patch in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e250" xlink:type="simple"/></inline-formula>. Because the norm of a patch is permutation invariant, this permutation preserves the norms of the patches in the whitened space.</p>
        <p>To create RND samples and ICA samples, we apply the independence assumption shuffling procedure, using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e251" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e252" xlink:type="simple"/></inline-formula> respectively.</p>
        <p>To create L2, LP, and MEC samples, we apply the symmetry assumption shuffling procedure. For L2 samples, we use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e253" xlink:type="simple"/></inline-formula>, the second order basis. To create LP samples, we use <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e254" xlink:type="simple"/></inline-formula> since ICA is the optimal basis for LP <xref ref-type="bibr" rid="pcbi.1002873-Sinz1">[10]</xref>. For MEC samples under an MEC model with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e255" xlink:type="simple"/></inline-formula> mixtures, we first assign each patch in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e256" xlink:type="simple"/></inline-formula> to one of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e257" xlink:type="simple"/></inline-formula> clusters of the model by evaluating the patch's maximum likelihood cluster membership. Then for all patches in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e258" xlink:type="simple"/></inline-formula>-th cluster we use the corresponding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e259" xlink:type="simple"/></inline-formula> analysis matrix of the maximum likelihood cluster.</p>
        <p>The Fourier phase scrambled samples were created using a different approach. IPS samples were created by storing the amplitude spectra of the patches in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e260" xlink:type="simple"/></inline-formula> and combining them with random phases before inverse Fourier transforming back to image pixel space. GPS samples were created by storing both the amplitude and phase spectra of the patches in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e261" xlink:type="simple"/></inline-formula> and then reassigning the individual phase spectra randomly to different patches in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e262" xlink:type="simple"/></inline-formula> before inverse Fourier transforming back to image pixel space.</p>
        <p>The resulting matched samples, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e263" xlink:type="simple"/></inline-formula>, where then tiled tightly into a square texture as were the samples of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e264" xlink:type="simple"/></inline-formula>. For grayscale conditions, the gray values of the two textures taken together were normalized from the range <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e265" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e266" xlink:type="simple"/></inline-formula> to utilize the full gamut of the CRT monitor. For the binary textures of Experiment 4, the gray values of each patch in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e267" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e268" xlink:type="simple"/></inline-formula> were thresholded such that the resulting binary patch had equal numbers of white and black pixels (4 white pixels for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e269" xlink:type="simple"/></inline-formula> and 12 white pixels for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e270" xlink:type="simple"/></inline-formula> pixel patches). Binary textures did not utilize the full gamut of the monitor as this level of contrast was uncomfortable to view for extended periods. Instead, luminance was lowered such that white was approximately <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e271" xlink:type="simple"/></inline-formula>.</p>
      </sec>
      <sec id="s4f">
        <title>Experiment 1</title>
        <p>In Experiment 1 we used a two-alternative forced choice task to measure the discriminability of textures of natural image samples from textures of model samples. In the first session with 16 subjects, RND, ICA, L2, LP, IPS, and GPS were used to generate stimuli at patch sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e272" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e273" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e274" xlink:type="simple"/></inline-formula> pixels. In session two with 12 subjects, MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e275" xlink:type="simple"/></inline-formula>, MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e276" xlink:type="simple"/></inline-formula>, MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e277" xlink:type="simple"/></inline-formula>, and MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e278" xlink:type="simple"/></inline-formula> were used to generate stimuli at patch sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e279" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e280" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e281" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e282" xlink:type="simple"/></inline-formula> pixels. In both experiments, observers first completed 20 training trials with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e283" xlink:type="simple"/></inline-formula> pixel patches for each model before starting the experimental session with 30 test trials per model per patch size. Trials were grouped in small runs by model in order of decreasing image patch size. The ordering of the models across runs was randomized.</p>
        <p>Texture sizes were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e284" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e285" xlink:type="simple"/></inline-formula> pixel patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e286" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e287" xlink:type="simple"/></inline-formula> pixel patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e288" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e289" xlink:type="simple"/></inline-formula> pixel patches, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e290" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e291" xlink:type="simple"/></inline-formula> pixel patches. The textures were presented side by side for 3000 msec with additional 200 msec sinusoidal ramps on and off. There was a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e292" xlink:type="simple"/></inline-formula> blank space between the two textures. The true natural samples appeared on the right and left sides with equal probability. After stimulus extinction, the subject reported which side contained the true natural image samples and was provided immediate feedback by an auditory tone. If the incorrect texture was chosen, the stimulus was shown again for 3900 msec with the correct texture highlighted by a white frame.</p>
        <p>One subject completed 4,032 trials of a four-alternative forced choice version of the experiment, where each stimulus included four textures: one contained the true natural image samples, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e293" xlink:type="simple"/></inline-formula>, and the other three contained model generated samples, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e294" xlink:type="simple"/></inline-formula>, each matched statistically to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e295" xlink:type="simple"/></inline-formula> but different in exact appearance. The four textures were arranged in an invisible <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e296" xlink:type="simple"/></inline-formula> grid on the screen with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e297" xlink:type="simple"/></inline-formula> blank space separating them. As in the main experiment, the task was to select the one texture made of natural samples, which appeared at each location in the grid with equal probability. We used this design as it is the preferred method for naive observers <xref ref-type="bibr" rid="pcbi.1002873-Jaekel1">[61]</xref>. The subject completed four sessions with RND, ICA, L2, LP, IPS, and GPS, and one session with the MEC models. Each session contained 36 test trials per model per patch size tested, which were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e298" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e299" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e300" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e301" xlink:type="simple"/></inline-formula>. Because this version of the experiment contains much more visual information to inspect on each trial, we allowed the subject to view the stimuli for as long as needed but instructed that the response should be made as quickly as possible without sacrificing accuracy. Feedback screens were shown for 5400 msec. We adjusted the texture sizes so that four could be presented simultaneously and so that the texture sizes would be approximately the same to facilitate faster responses. The texture sizes were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e302" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e303" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e304" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e305" xlink:type="simple"/></inline-formula> pixel patches and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e306" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e307" xlink:type="simple"/></inline-formula> pixel patches.</p>
      </sec>
      <sec id="s4g">
        <title>Experiment 2</title>
        <p>Experiment 2 measured sensitivity to luminance histogram cues in natural image samples. It was identical in design to the two alternative forced choice version of Experiment 1 except that we scrambled the pixels of the textures as a final post-processing step before painting them to the screen. We excluded MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e308" xlink:type="simple"/></inline-formula>, MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e309" xlink:type="simple"/></inline-formula>, and MEC <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e310" xlink:type="simple"/></inline-formula>, and the experiment was run in two one-hour sessions separated by condition. In the first condition we permuted the pixels globally within each texture to produce “global scrambles.” In the second condition, we permuted pixels within each sample separately to produce “sample scrambles.” Three subjects participated.</p>
      </sec>
      <sec id="s4h">
        <title>Experiment 3</title>
        <p>In Experiment 3, we used a two alternative forced choice task to measure sensitivity to the grayscale shape information in natural image samples separately from the contrast fluctuation cue. Because MEC, IPS, and GPS perfectly captured the contrast fluctuation cue in Experiment 2, we excluded them and measured discriminability only for RND, ICA, L2, and LP at patch sizes <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e311" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e312" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e313" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e314" xlink:type="simple"/></inline-formula> pixels. Nine observers participated, each contributing 36 test trials per model per patch size.</p>
        <p>We matched the distribution of gray value norms in the model samples, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e315" xlink:type="simple"/></inline-formula>, to the distribution of gray value norms in the natural image samples, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e316" xlink:type="simple"/></inline-formula>, on a trial-by-trial basis, where the gray value norm of a patch is the Euclidean length of the vector of pixel values. Because the norms are measured on patches with zero mean, they are related to r.m.s. contrast. Patches whose pixel values vary greatly across the patch (high contrast) have large norms, and homogeneous patches have much lower norms independent of the mean gray value. Our procedure was the following: 1) compute the gray value norms of all patches in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e317" xlink:type="simple"/></inline-formula> and in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e318" xlink:type="simple"/></inline-formula> 2) sort the norms of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e319" xlink:type="simple"/></inline-formula> in increasing order, 3) sort the patches of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e320" xlink:type="simple"/></inline-formula> in increasing order of their norms, 4) scale the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e321" xlink:type="simple"/></inline-formula>-th patch in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e322" xlink:type="simple"/></inline-formula> to have the value of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e323" xlink:type="simple"/></inline-formula>-th entry in the sorted norms of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e324" xlink:type="simple"/></inline-formula>, 3) shuffle the patch positions within <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e325" xlink:type="simple"/></inline-formula>. For RND and ICA samples, we scaled each sample in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e326" xlink:type="simple"/></inline-formula> by a gamma random variable prior to step 1. Gamma distribution parameters had been optimized beforehand via simulations to minimize perturbations in pixel covariances.</p>
        <p>Because the task is more difficult when the contrast fluctuation cue is removed, we allowed subjects to view the stimuli as long as necessary. However, we encouraged them to respond as quickly as possible without sacrificing accuracy and also used different texture sizes than in Experiments 1 and 2, so that the stimuli would be roughly the same size on every trial to facilitate faster visual processing. The texture sizes were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e327" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e328" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e329" xlink:type="simple"/></inline-formula> pixel patches and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e330" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e331" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e332" xlink:type="simple"/></inline-formula> pixel patches. We measured discriminability for the unperturbed stimuli as well under the same timing and size parameters. The experiment therefore had two randomly interleaved conditions, one for the unperturbed stimuli, the other for the contrast distribution matched stimuli. All other aspects of the experimental design were identical to the two alternative forced choice version of Experiment 1.</p>
      </sec>
      <sec id="s4i">
        <title>Experiment 4</title>
        <p>In Experiment 4, we used a two alternative forced choice task to measure sensitivity to the cues present in binary images. Only natural image patches above the median patch contrast value were used as stimuli. Natural patches, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e333" xlink:type="simple"/></inline-formula>, of patch size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e334" xlink:type="simple"/></inline-formula> were therefore selected only from the upper half (in terms of contrast) of the corresponding dataset <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e335" xlink:type="simple"/></inline-formula>. The discrimination task was more difficult with these high contrast stimuli than with the stimuli of Experiment 1, so we therefore used the timing and textures sizes of Experiment 3. We measured discriminability for all models with grayscale unperturbed stimuli in addition to the binary version. The experiment was two one-hour sessions: session 1 for RND, ICA, L2, and LP, and session 2 for the four MEC models. Each one-hour session consisted of two shorter sessions, the first was the grayscale version, and the second was the binary version. Seven subjects participated, each contributing 36 test trials per model per patch size (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e336" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e337" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e338" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002873.e339" xlink:type="simple"/></inline-formula> pixels). All other design details were identical to the two alternative forced choice version of Experiment 1.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Fabian Sinz, Philipp Berens, and Alexander Ecker for comments on the manuscript. We also thank Fabian Sinz and Sebastian Gerwinn for discussions of the data analysis and Thomas Wiecki for implementing and piloting Experiment 1.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002873-Attneave1">
        <label>1</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Attneave</surname><given-names>F</given-names></name> (<year>1954</year>) <article-title>Some informational aspects of visual perception</article-title>. <source>Psychological review</source> <volume>61</volume>: <fpage>183</fpage>–<lpage>193</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Barlow1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barlow</surname><given-names>H</given-names></name> (<year>1959</year>) <article-title>Sensory mechanisms, the reduction of redundancy, and intelligence</article-title>. <source>In: The mechanisation of thought processes. Her Majesty's Stationery Office London</source>. <fpage>535</fpage>–<lpage>539</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Atick1">
        <label>3</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name> (<year>1992</year>) <article-title>What does the retina know about natural scenes?</article-title> <source>Neural Computation</source> <volume>4</volume>: <fpage>196</fpage>–<lpage>210</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Dan1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Reid</surname><given-names>RC</given-names></name> (<year>1996</year>) <article-title>Efficient coding of natural scenes in the lateral geniculate nucleus: experimental test of a computational theory</article-title>. <source>The Journal of Neuroscience</source> <volume>16</volume>: <fpage>3351</fpage>–<lpage>3362</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Olshausen1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1996</year>) <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source> <volume>381</volume>: <fpage>607</fpage>–<lpage>609</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Bell1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1997</year>) <article-title>The “Independent Components” of Natural Scenes are Edge Filters</article-title>. <source>Vision Research</source> <volume>37</volume>: <fpage>3327</fpage>–<lpage>3338</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Schwartz1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2001</year>) <article-title>Natural signal statistics and sensory gain control</article-title>. <source>Nature Neuroscience</source> <volume>4</volume>: <fpage>819</fpage>–<lpage>825</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Eichhorn1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eichhorn</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Natural image coding in V1: how much use is orientation selectivity?</article-title> <source>PLoS Computational Biology</source> <volume>5</volume>: <fpage>1</fpage>–<lpage>16</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Lyu1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lyu</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2009</year>) <article-title>Nonlinear extraction of independent components of natural images using radial gaussianization</article-title>. <source>Neural Computation</source> <volume>21</volume>: <fpage>1485</fpage>–<lpage>1519</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Sinz1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>The conjoint effect of divisive normalization and orientation selectivity on redundancy reduction</article-title>. <source>In: Advances in Neural Information Processing Systems</source> <volume>21</volume>: <fpage>1521</fpage>–<lpage>1528</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Karklin1">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Karklin</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name> (<year>2009</year>) <article-title>Emergence of complex cell properties by learning to generalize in natural scenes</article-title>. <source>Nature</source> <volume>457</volume>: <fpage>83</fpage>–<lpage>86</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Deriugin1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deriugin</surname><given-names>N</given-names></name> (<year>1956</year>) <article-title>The power spectrum and the correlation function of the television signal</article-title>. <source>Telecommunications</source> <volume>1</volume>: <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Knill1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knill</surname><given-names>DC</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Kersten</surname><given-names>D</given-names></name> (<year>1990</year>) <article-title>Human discrimination of fractal images</article-title>. <source>Journal of the Optical Society of America A</source> <volume>7</volume>: <fpage>1113</fpage>–<lpage>1123</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Tadmor1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tadmor</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name> (<year>1994</year>) <article-title>Discrimination of changes in the second-order statistics of natural and synthetic images</article-title>. <source>Vision Research</source> <volume>34</volume>: <fpage>541</fpage>–<lpage>554</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Tolhurst1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Tadmor</surname><given-names>Y</given-names></name> (<year>2000</year>) <article-title>Discrimination of spectrally blended natural images: Optimisation of the human visual system for encoding natural images</article-title>. <source>Perception</source> <volume>29</volume>: <fpage>1087</fpage>–<lpage>1100</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Prraga1">
        <label>16</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Párraga</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Troscianko</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name> (<year>2000</year>) <article-title>The human visual system is optimised for processing the spatial information in natural visual images</article-title>. <source>Current Biology</source> <volume>10</volume>: <fpage>35</fpage>–<lpage>38</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Prraga2">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Párraga</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Troscianko</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name> (<year>2005</year>) <article-title>The effects of amplitude-spectrum statistics on foveal and peripheral discrimination of changes in natural images, and a multi-resolution model</article-title>. <source>Vision Research</source> <volume>45</volume>: <fpage>3145</fpage>–<lpage>3168</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Tadmor2">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tadmor</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name> (<year>1993</year>) <article-title>Both the phase and the amplitude spectrum may determine the appearance of natural images</article-title>. <source>Vision Research</source> <volume>33</volume>: <fpage>141</fpage>–<lpage>145</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Thomson1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thomson</surname><given-names>MGA</given-names></name>, <name name-style="western"><surname>Foster</surname><given-names>DH</given-names></name> (<year>1997</year>) <article-title>Role of second- and third-order statistics in the discriminability of natural images</article-title>. <source>Journal of the Optical Society of America A</source> <volume>14</volume>: <fpage>2081</fpage>–<lpage>2090</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Thomson2">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thomson</surname><given-names>MGA</given-names></name>, <name name-style="western"><surname>Foster</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Summers</surname><given-names>RJ</given-names></name> (<year>2000</year>) <article-title>Human sensitivity to phase perturbations in natural images: a statistical framework</article-title>. <source>Perception</source> <volume>29</volume>: <fpage>1057</fpage>–<lpage>1069</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Wichmann1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wichmann</surname><given-names>FA</given-names></name>, <name name-style="western"><surname>Braun</surname><given-names>DI</given-names></name>, <name name-style="western"><surname>Gegenfurtner</surname><given-names>KR</given-names></name> (<year>2006</year>) <article-title>Phase noise and the classification of natural images</article-title>. <source>Vision Research</source> <volume>46</volume>: <fpage>1520</fpage>–<lpage>1529</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Hansen1">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hansen</surname><given-names>BC</given-names></name>, <name name-style="western"><surname>Hess</surname><given-names>RF</given-names></name> (<year>2007</year>) <article-title>Structural sparseness and spatial phase alignment in natural scenes</article-title>. <source>Journal of the Optical Society of America A</source> <volume>24</volume>: <fpage>1873</fpage>–<lpage>1885</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Baker1">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Baker</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Yoonessi</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Arsenault</surname><given-names>E</given-names></name> (<year>2008</year>) <article-title>Texture segmentation in natural images: Contribution of higher-order image statistics to psychophysical performance</article-title>. <source>Journal of Vision</source> <volume>8</volume>: <fpage>350</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Joubert1">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Joubert</surname><given-names>OR</given-names></name>, <name name-style="western"><surname>Rousselet</surname><given-names>GA</given-names></name>, <name name-style="western"><surname>Fabre-Thorpe</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Fize</surname><given-names>D</given-names></name> (<year>2009</year>) <article-title>Rapid visual categorization of natural scene contexts with equalized amplitude spectrum and increasing phase noise</article-title>. <source>Journal of Vision</source> <volume>9</volume>: <fpage>2.1</fpage>–<lpage>16</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Emrith1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Emrith</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Chantler</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Green</surname><given-names>PR</given-names></name>, <name name-style="western"><surname>Maloney</surname><given-names>LT</given-names></name>, <name name-style="western"><surname>Clarke</surname><given-names>ADF</given-names></name> (<year>2010</year>) <article-title>Measuring perceived differences in surface texture due to changes in higher order statistics</article-title>. <source>Journal of the Optical Society of America A</source> <volume>27</volume>: <fpage>1232</fpage>–<lpage>1244</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Oppenheim1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Oppenheim</surname><given-names>AV</given-names></name>, <name name-style="western"><surname>Lim</surname><given-names>JS</given-names></name> (<year>1981</year>) <article-title>Importance of Phase in Signals</article-title>. <source>In: Proceedings of the IEEE</source> <volume>volume 69</volume>: <fpage>529</fpage>–<lpage>541</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Kersten1">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kersten</surname><given-names>D</given-names></name> (<year>1987</year>) <article-title>Predictability and redundancy of natural images</article-title>. <source>Journal of the Optical Society of America A</source> <volume>4</volume>: <fpage>2395</fpage>–<lpage>2400</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Heeger1">
        <label>28</label>
        <mixed-citation publication-type="other" xlink:type="simple">Heeger DJ, Bergen JR (1995) Pyramid-based texture analysis/synthesis. In: Proceedings of the 22nd annual conference on Computer graphics and interactive techniques. SIGGRAPH. New York, NY, USA: ACM. pp. 229–238.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Portilla1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Portilla</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2000</year>) <article-title>A parametric texture model based on joint statistics of complex wavelet coefficients</article-title>. <source>International Journal of Computer Vision</source> <volume>40</volume>: <fpage>49</fpage>–<lpage>70</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Balas1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balas</surname><given-names>BJ</given-names></name> (<year>2006</year>) <article-title>Texture synthesis and perception: Using computational models to study texture representations in the human visual system</article-title>. <source>Vision Research</source> <volume>46</volume>: <fpage>299</fpage>–<lpage>309</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Wainwright1">
        <label>31</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wainwright</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>E</given-names></name> (<year>2000</year>) <article-title>Scale mixtures of gaussians and the statistics of natural images</article-title>. <source>In: Advances in Neural Information Processing Systems</source> <volume>12</volume>: <fpage>855</fpage>–<lpage>861</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-GuerreroColon1">
        <label>32</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guerrero-Colon</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Portilla</surname><given-names>J</given-names></name> (<year>2008</year>) <article-title>Image denoising using mixtures of gaussian scale mixtures</article-title>. <source>In: ICIP 15th IEEE International Conference on Image Processing</source> <fpage>565</fpage>–<lpage>568</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Bethge1">
        <label>33</label>
        <mixed-citation publication-type="other" xlink:type="simple">Bethge M, Hosseini R (2008). Method and device for image compression. Available: <ext-link ext-link-type="uri" xlink:href="https://register.epo.org/espacenet/application?number=EP08010343" xlink:type="simple">https://register.epo.org/espacenet/application?number=EP08010343</ext-link>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Julesz1">
        <label>34</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Julesz</surname><given-names>B</given-names></name> (<year>1962</year>) <article-title>Visual pattern discrimination</article-title>. <source>IRE Transactions on Information Theory</source> <volume>8</volume>: <fpage>84</fpage>–<lpage>92</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Wolpert1">
        <label>35</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wolpert</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Macready</surname><given-names>WG</given-names></name> (<year>1997</year>) <article-title>No free lunch theorems for optimization</article-title>. <source>IEEE Transactions on Evolutionary Computation</source> <volume>1</volume>: <fpage>67</fpage>–<lpage>82</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Chubb1">
        <label>36</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chubb</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Econopouly</surname><given-names>J</given-names></name> (<year>2004</year>) <article-title>A visual mechanism tuned to black</article-title>. <source>Vision Research</source> <volume>44</volume>: <fpage>3223</fpage>–<lpage>3232</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Julesz2">
        <label>37</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Julesz</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Gilbert</surname><given-names>EN</given-names></name>, <name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name> (<year>1978</year>) <article-title>Visual discrimination of textures with identical third-order statistics</article-title>. <source>Biological Cybernetics</source> <volume>31</volume>: <fpage>137</fpage>–<lpage>140</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Julesz3">
        <label>38</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Julesz</surname><given-names>B</given-names></name> (<year>1981</year>) <article-title>Textons, the elements of texture perception, and their interactions</article-title>. <source>Nature</source> <volume>290</volume>: <fpage>91</fpage>–<lpage>97</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Victor1">
        <label>39</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Conte</surname><given-names>MM</given-names></name> (<year>1991</year>) <article-title>Spatial organization of nonlinear interactions in form perception</article-title>. <source>Vision Research</source> <volume>31</volume>: <fpage>1457</fpage>–<lpage>1488</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Victor2">
        <label>40</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Chubb</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Conte</surname><given-names>MM</given-names></name> (<year>2005</year>) <article-title>Interaction of luminance and higher-order statistics in texture discrimination</article-title>. <source>Vision Research</source> <volume>45</volume>: <fpage>311</fpage>–<lpage>328</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-vanHateren1">
        <label>41</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>, <name name-style="western"><surname>van der Schaaf</surname><given-names>A</given-names></name> (<year>1998</year>) <article-title>Independent component filters of natural images compared with simple cells in primary visual cortex</article-title>. <source>Proceedings of the Royal Society B</source> <volume>265</volume>: <fpage>359</fpage>–<lpage>366</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Hyvrinen1">
        <label>42</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hurri</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Hoyer</surname><given-names>P</given-names></name> (<year>2009</year>) <article-title>Natural Image Statistics: A Probabilistic Approach to Early Computational Vision</article-title>. <source>Springer</source></mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Bethge2">
        <label>43</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Factorial coding of natural images: How effective are linear models in removing higher-order dependencies?</article-title> <source>Journal of the Optical Society of America A</source> <volume>23</volume>: <fpage>1253</fpage>–<lpage>1268</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Morgan1">
        <label>44</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morgan</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Hayes</surname><given-names>A</given-names></name> (<year>1991</year>) <article-title>The relative importance of local phase and local amplitude in patchwise image reconstruction</article-title>. <source>Biological Cybemetics</source> <volume>119</volume>: <fpage>113</fpage>–<lpage>119</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Frnd1">
        <label>45</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fründ</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Haenel</surname><given-names>NV</given-names></name>, <name name-style="western"><surname>Wichmann</surname><given-names>FA</given-names></name> (<year>2011</year>) <article-title>Inference for psychometric functions in the presence of nonstationary behavior</article-title>. <source>Journal of Vision</source> <volume>11 piii</volume>: <fpage>16</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Klein1">
        <label>46</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname><given-names>SA</given-names></name>, <name name-style="western"><surname>Tyler</surname><given-names>CW</given-names></name> (<year>1986</year>) <article-title>Phase discrimination of compound gratings: generalized autocorrelation analysis</article-title>. <source>Journal of the Optical Society of America A</source> <volume>3</volume>: <fpage>868</fpage>–<lpage>879</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Tyler1">
        <label>47</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tyler</surname><given-names>CW</given-names></name> (<year>2004</year>) <article-title>Beyond fourth-order texture discrimination: generation of extreme-order and statistically-balanced textures</article-title>. <source>Vision Research</source> <volume>44</volume>: <fpage>2187</fpage>–<lpage>99</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Tyler2">
        <label>48</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tyler</surname><given-names>CW</given-names></name> (<year>2004</year>) <article-title>Theory of texture discrimination of based on higher-order perturbations in individual texture samples</article-title>. <source>Vision Research</source> <volume>44</volume>: <fpage>2179</fpage>–<lpage>86</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Victor3">
        <label>49</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Conte</surname><given-names>MM</given-names></name> (<year>2012</year>) <article-title>Local image statistics: maximum-entropy constructions and perceptual salience</article-title>. <source>Journal of the Optical Society of America A</source> <volume>29</volume>: <fpage>1313</fpage>–<lpage>1345</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Tkacik1">
        <label>50</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tkacik</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Prentice</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Balasubramanian</surname><given-names>V</given-names></name> (<year>2010</year>) <article-title>Local statistics in natural scenes predict the saliency of synthetic textures</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>107</volume>: <fpage>18149</fpage>–<lpage>54</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Bethge3">
        <label>51</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wiecki</surname><given-names>TV</given-names></name>, <name name-style="western"><surname>Wichmann</surname><given-names>FA</given-names></name> (<year>2007</year>) <article-title>The independent components of natural images are perceptually dependent</article-title>. <source>In: Proceedings of SPIE Human Vision and Electronic Imaging XII (EI105)</source> <volume>6492</volume>: <fpage>1</fpage>–<lpage>12</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Elder1">
        <label>52</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elder</surname><given-names>JH</given-names></name> (<year>1999</year>) <article-title>Are edges incomplete?</article-title> <source>International Journal of Computer Vision</source> <volume>34</volume>: <fpage>97</fpage>–<lpage>122</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Girshick1">
        <label>53</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Girshick</surname><given-names>AR</given-names></name>, <name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2011</year>) <article-title>Cardinal rules: visual orientation perception reects knowledge of environmental statistics</article-title>. <source>Nature Neuroscience</source> <volume>14</volume>: <fpage>926</fpage>–<lpage>32</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Balas2">
        <label>54</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balas</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Nakano</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Rosenholtz</surname><given-names>R</given-names></name> (<year>2009</year>) <article-title>A summary-statistic representation in peripheral vision explains visual crowding</article-title>. <source>Journal of Vision</source> <volume>9</volume>: <fpage>13</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Rosenholtz1">
        <label>55</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosenholtz</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ehinger</surname><given-names>KA</given-names></name> (<year>2012</year>) <article-title>Rethinking the role of top-down attention in vision: effects attributable to a lossy representation in peripheral vision</article-title>. <source>Frontiers in Psychology</source> <volume>3</volume>: <fpage>13</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Freeman1">
        <label>56</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freeman</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2011</year>) <article-title>Metamers of the ventral stream</article-title>. <source>Nature Neuroscience</source> <volume>14</volume>: <fpage>1195</fpage>–<lpage>1201</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Brainard1">
        <label>57</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brainard</surname><given-names>DH</given-names></name> (<year>1997</year>) <article-title>The psychophysics toolbox</article-title>. <source>Spatial Vision</source> <volume>10</volume>: <fpage>433</fpage>–<lpage>436</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Kleiner1">
        <label>58</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kleiner</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Brainard</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Pelli</surname><given-names>D</given-names></name> (<year>2007</year>) <article-title>What's new in Psychtoolbox-3?</article-title> <source>Perception 36: ECVP Abstract Supplement</source></mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Sinz2">
        <label>59</label>
        <mixed-citation publication-type="other" xlink:type="simple">Sinz F, Hosseini R (2009). Natural image statistics density estimation toolbox (nisdet) for matlab. Available: <ext-link ext-link-type="uri" xlink:href="http://bethgelab.org/software/nisdet/" xlink:type="simple">http://bethgelab.org/software/nisdet/</ext-link>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Hyvarinen1">
        <label>60</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvarinen</surname><given-names>A</given-names></name> (<year>1999</year>) <article-title>Fast and robust fixed-point algorithms for independent component analysis</article-title>. <source>IEEE Transactions on Neural Networks</source> <volume>10</volume>: <fpage>626</fpage>–<lpage>634</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Jaekel1">
        <label>61</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jaekel</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Wichmann</surname><given-names>FA</given-names></name> (<year>2006</year>) <article-title>Spatial four-alternative forced-choice method is the preferred psychophysical method for naive observers</article-title>. <source>Journal of Vision</source> <volume>6</volume>: <fpage>1307</fpage>–<lpage>22</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002873-Sinz3">
        <label>62</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title><italic>l<sub>p</sub></italic>-nested symmetric distributions</article-title>. <source>Journal of Machine Learning Research</source> <volume>11</volume>: <fpage>3409</fpage>–<lpage>3451</lpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-01672</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002658</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Engineering</subject>
          <subj-group>
            <subject>Signal processing</subject>
            <subj-group>
              <subject>Image processing</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Software engineering</subject>
            <subj-group>
              <subject>Software tools</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computer Science</subject>
        </subj-group>
      </article-categories><title-group><article-title>High-throughput Computer Method for 3D Neuronal Structure Reconstruction from the Image Stack of the <italic>Drosophila</italic> Brain and Its Applications</article-title><alt-title alt-title-type="running-head">High-throughput Method for 3D Neuron Tracing</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Lee</surname>
            <given-names>Ping-Chang</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Chuang</surname>
            <given-names>Chao-Chun</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Chiang</surname>
            <given-names>Ann-Shyn</given-names>
          </name>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
          <xref ref-type="aff" rid="aff5">
            <sup>5</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Ching</surname>
            <given-names>Yu-Tai</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1">
        <label>1</label>
        <addr-line>Department of Computer Science, National Chiao Tung University, HsinChu, Taiwan</addr-line>
      </aff><aff id="aff2">
        <label>2</label>
        <addr-line>Institute of Bioinformatics and Systems Biology, National Chiao Tung University, HsinChu, Taiwan</addr-line>
      </aff><aff id="aff3">
        <label>3</label>
        <addr-line>National Center for High-Performance Computing, HsinChu, Taiwan</addr-line>
      </aff><aff id="aff4">
        <label>4</label>
        <addr-line>Institute of Biotechnology, National Tsing Hua University, HsinChu, Taiwan</addr-line>
      </aff><aff id="aff5">
        <label>5</label>
        <addr-line>Brain Research Center, National Tsing Hua University, HsinChu, Taiwan</addr-line>
      </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Ascoli</surname>
            <given-names>Giorgio A.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">
        <addr-line>George Mason University, United States of America</addr-line>
      </aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">ytc@cs.nctu.edu.tw</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: PCL YTC. Performed the experiments: PCL CCC. Analyzed the data: PCL CCC. Contributed reagents/materials/analysis tools: ASC. Wrote the paper: PCL YTC.</p>
        </fn>
      </author-notes><pub-date pub-type="collection">
        <month>9</month>
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>13</day>
        <month>9</month>
        <year>2012</year>
      </pub-date><volume>8</volume><issue>9</issue><elocation-id>e1002658</elocation-id><history>
        <date date-type="received">
          <day>8</day>
          <month>11</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>12</day>
          <month>7</month>
          <year>2012</year>
        </date>
      </history><permissions>
        
        <copyright-holder>Lee et al</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions><abstract>
        <p><italic>Drosophila melanogaster</italic> is a well-studied model organism, especially in the field of neurophysiology and neural circuits. The brain of the <italic>Drosophila</italic> is small but complex, and the image of a single neuron in the brain can be acquired using confocal microscopy. Analyzing the <italic>Drosophila</italic> brain is an ideal start to understanding the neural structure. The most fundamental task in studying the neural network of <italic>Drosophila</italic> is to reconstruct neuronal structures from image stacks. Although the fruit fly brain is small, it contains approximately 100 000 neurons. It is impossible to trace all the neurons manually. This study presents a high-throughput algorithm for reconstructing the neuronal structures from 3D image stacks collected by a laser scanning confocal microscope. The proposed method reconstructs the neuronal structure by applying the shortest path graph algorithm. The vertices in the graph are certain points on the 2D skeletons of the neuron in the slices. These points are close to the 3D centerlines of the neuron branches. The accuracy of the algorithm was verified using the DIADEM data set. This method has been adopted as part of the protocol of the <italic>FlyCircuit</italic> Database, and was successfully applied to process more than 16 000 neurons. This study also shows that further analysis based on the reconstruction results can be performed to gather more information on the neural network.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>It is now possible to image a single neuron in the fruit fly brain. However, manually reconstructing neuronal structures is tremendously time consuming. The proposed method avoids user interventions by first automatically identifying the end points and detecting the appropriate representative point of the soma, and then, by finding the shortest paths from the soma to the end points in an image stack. In the proposed algorithm, a tailor-made weighting function allows the resulting reconstruction to represent the neuron appropriately. Accuracy analysis and a robustness test demonstrated that the proposed method is accurate and robust to handle the noisy image data. Tract discovery is one of the most frequently mentioned potentials of reconstructed results. In addition to a method for neuronal structure reconstruction, this study presents a method for tract discovery and explores the tract-connecting olfactory neuropils using the reconstructed results. The discovered tracts are in agreement with the results of previous studies in the literature. Software for reconstructing the neuronal structures and the reconstruction results can be downloaded from the Web site <ext-link ext-link-type="uri" xlink:href="http://www.flycircuit.tw" xlink:type="simple">http://www.flycircuit.tw</ext-link>. More details on acquiring the software and the reconstruction results are provided in <xref ref-type="supplementary-material" rid="pcbi.1002658.s001">Text S1</xref>.</p>
      </abstract><funding-group>
        <funding-statement>This work was supported in part under the grant NSC-98-2221-E-009-118-MY3, National Science Council, Taiwan. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group><counts>
        <page-count count="12"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Neurons in a fruit fly brain form numerous distinct functional circuits as in the mammalian brain. These circuits mediate the fundamental processes of vision, olfaction, locomotion, flight navigation, and complex behaviors such as feeding, learning, and memory. The neurotransmitters and molecular mechanisms that mediate these behaviors and activities are very similar to those of higher organisms and humans. It is worth studying the fruit fly brain as the initial step in understanding the functions of the neural network.</p>
      <p>A single neuron in the <italic>Drosophila</italic> brain can be labeled by the Green Fluorescent Protein (GFP) <xref ref-type="bibr" rid="pcbi.1002658-Greenspan1">[1]</xref>. Using the focus clear technique <xref ref-type="bibr" rid="pcbi.1002658-Chiang1">[2]</xref> or the Scale technique <xref ref-type="bibr" rid="pcbi.1002658-Hama1">[3]</xref>, one can employ a confocal microscope to acquire a clear image stack of the entire brain, containing a labeled single neuron. This allows one to reconstruct the structure of neurons and study the neural network of the fruit fly brain. The <italic>Drosophila</italic> brain contains approximately 100 000 neurons in, and therefore, reconstructing all the neuronal structures by manually tracing every single neuron is impractical. A high-throughput computer method is required.</p>
      <p>Tracing neuron fibers is similar to tracking vasculature line structures in a 3D image volume. Previous studies on medical image processing presented related methods of tracking line structures. Bouix et al. proposed a method based on skeletonization and branch analysis <xref ref-type="bibr" rid="pcbi.1002658-Bouix1">[4]</xref>. Other approaches include a method based on enhancing line or edge properties and then chaining up the most likely pixels <xref ref-type="bibr" rid="pcbi.1002658-Sonka1">[5]</xref> and a method that attempts to find the minimal paths <xref ref-type="bibr" rid="pcbi.1002658-Deschamps1">[6]</xref>–<xref ref-type="bibr" rid="pcbi.1002658-Li1">[8]</xref>. Compared with medical images of blood vessels, neuron images often suffer from noise and uneven resolution in the <italic>x</italic>, <italic>y</italic>, and <italic>z</italic> directions, and a single neuron is usually discontinuous in the image stack. Directly applying the above methods to reconstruct the neuronal structures is therefore inadequate. Researchers have recently proposed methods to trace neurons or reconstruct the neuronal structure. Al-Kofahi et al. progressively fitted and matched the primitive template structures, spheres, ellipsoids, and cylinders in the image stack <xref ref-type="bibr" rid="pcbi.1002658-AlKofahi1">[9]</xref>. However, this method did not address the situation that a neuron is fragmented in an image space. Similarly, Zhao et al. investigated the morphological characteristics of neurons <xref ref-type="bibr" rid="pcbi.1002658-Zhao1">[10]</xref>. Both the Al-Kofahi and Zhao's methods assumed that neuron fibers are spherical, ellipsoidal, or cylindrical; however, neuron fibers in the image stack are usually not as regular as this assumption suggests. Zhang et al. assembled many skeleton structures as a single neuronal structure <xref ref-type="bibr" rid="pcbi.1002658-Zhang1">[11]</xref>. However, this method considered only 2D neuron images. Lee et al. proposed a semiautomatic method for 3D neuronal structure reconstruction <xref ref-type="bibr" rid="pcbi.1002658-Lee1">[12]</xref>. Peng et al. reduced the tracing problem as a variational problem by finding the geodesic shortest path <xref ref-type="bibr" rid="pcbi.1002658-Peng1">[13]</xref>. Türetken et al. proposed a method based on optimizing a carefully designed energy function <xref ref-type="bibr" rid="pcbi.1002658-Tretken1">[14]</xref>. However, none of these methods is specific for processing numerous sets of volume data automatically.</p>
      <p>This study presents a high-throughput computer method of reconstructing the neuronal structure of the fruit fly brain. The design philosophy of the proposed method differs from those of previous methods. We propose first to compute the 2D skeletons of a neuron in each slice of the image stack. The 3D neuronal structure is then constructed from the 2D skeletons. Biologists tend to use confocal microscopes for optimal images in a slice for human visualization; and images in two consecutive slices contain overlapped information. Consequently, a spherical object becomes oval in the image stack; that is, neurons in the image stack do not reflect the true shape of the neuron. This is the main reason we chose not to work directly on the 3D volume.</p>
      <p>The proposed method comprises two steps. The first is the image processing step, which involves computing a set of voxels that is a superset of the 3D centerlines of the neuron. The shortest path graph algorithm then computes the centerlines. The proposed method was applied to process more than 16 000 neurons. By using a large amount of reconstructions, this study also demonstrated a result derived from the reconstructed data using the clustering technique.</p>
      <p>The remainder of this paper is organized as follows: The <xref ref-type="sec" rid="s3">Methods</xref> section details the proposed method. The Results section presents the tracing results, reconstructed neuronal structures, and an application using the reconstruction results. In this study, we used the <italic>Olfactory Projection Fibers</italic> from the DIADEM test data set <xref ref-type="bibr" rid="pcbi.1002658-Brown1">[15]</xref> to evaluate the accuracy of the proposed method. Each image in the DIADEM test data set contains original image stacks and gold reconstructions created by experts. This study defines the distance between one reconstruction and the other, to evaluate the accuracy of the reconstruction. The accuracy analysis is also demonstrated in the Result section. The discussions are in the <xref ref-type="sec" rid="s4">Discussion</xref> section.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>The Reconstructed Structure of Olfactory Projection Neuron</title>
        <p>The neural network system of the olfactory system of <italic>Drosophila</italic> has received considerable attention from neural science researchers. The experiment in this study traced the axon of the olfactory projection neuron. Compared with other neurons, the axon of the olfactory projection neuron is relatively simple because it usually does not have a complex arborization structure.</p>
        <p>The datum used for the demonstration was the <italic>Olfactory Projection Fibers</italic> in the DIADEM dataset. For comparative purposes, the traced result and the original image were rendered in the same image, but with slight distancing (<xref ref-type="fig" rid="pcbi-1002658-g001">Fig. 1</xref>).</p>
        <fig id="pcbi-1002658-g001" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>The rendered traced result (<italic>red</italic>) of a neuron overlaps with the volume rendering of the original image stack.</title>
            <p>For the purpose of comparison, the result is translated a little from its original position.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g001" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2b">
        <title>Reconstructed Structure of Projection Neuron Connecting Optical Lobes</title>
        <p>The neuronal structure is usually more complex than the olfactory projection neuron. An example of this is the projection neuron connecting two optical lobes. In this experiment, the intensity of the neuron image spreads widely, and broken branches emerge. The proposed method performs corrections necessary for producing satisfactory results. <xref ref-type="fig" rid="pcbi-1002658-g002">Fig. 2</xref> shows the traced results.</p>
        <fig id="pcbi-1002658-g002" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Two reconstruction results of optical nerves were demonstrated.</title>
            <p>Both (a) and (b) show the neurons (top) and the traced results (bottom). The projection neuron connecting optical lobes has dense branches and complex morphology. In addition, the intensity of the neuron in (a) has a wide dynamic range. The proposed method can manage these situations and make necessary corrections. When the whole process is completed, the reconstructions of both neurons are complete with high fidelity.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g002" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2c">
        <title>Tract Discovery</title>
        <p>The traced results can be used to discover new information. An important application involves determining tracts in the fruit fly brain. Neuropils in the fruit fly brain are connected by neurons. The connection between two neuropils, the Antenna Lobe (AL) and the Lateral Horn (LH), were considered.</p>
        <p>Approximately 16 000 neurons were processed, and the reconstruction results were warped into a typical brain <xref ref-type="bibr" rid="pcbi.1002658-FlyCircuit1">[16]</xref>. Among the reconstructed neurons, 401 traced results were selected. Of the 401 neurons, 198 neurons innervate both the LH and the AL in the right hemisphere without innervating the LH or the AL in the left hemisphere. The remaining 203 neurons innervate only both the LH and the AL in the left hemisphere. The paths connecting the AL and the LH were then extracted. Every path was evenly sampled, and hierarchical cluster analysis was applied to the sampled paths. The hierarchical cluster function supported by <italic>R</italic> <xref ref-type="bibr" rid="pcbi.1002658-HClust1">[17]</xref> was used to complete this analysis. <xref ref-type="supplementary-material" rid="pcbi.1002658.s002">Text S2</xref> provides a schematic description of the different steps in the process and a specific example of how the clusters are discovered. The results show six clusters (<xref ref-type="fig" rid="pcbi-1002658-g003">Fig. 3</xref>), with three on each hemisphere.</p>
        <fig id="pcbi-1002658-g003" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>An illustration of olfactory PNs collection (left), the computed tract clusters (upper right) and the neuron image clusters overlapping the computed cluster (lower right).</title>
            <p>Totally 198 olfactory PNs in the right hemisphere and 203 olfactory PNs in the left hemisphere were selected.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g003" xlink:type="simple"/>
        </fig>
        <p>The projection neurons ascending from the antennal lobe (AL) to the lateral horn (LH) form three tracts: inner antennocerebral tract (iACT), medial antennocerebral tract (mACT), and outer antennocerebral tract (oACT) <xref ref-type="bibr" rid="pcbi.1002658-Stocker1">[18]</xref><xref ref-type="bibr" rid="pcbi.1002658-Stocker2">[19]</xref>. These three tracts are the major message channels from the AL to the LH. The computed six clusters (<xref ref-type="fig" rid="pcbi-1002658-g003">Fig. 3</xref>) show that there are three clusters on both the left and right hemisphere. A comparison of these clusters to the tracts previously observed in the image data shows that they are the same as the iACT, mACT, and oACT in both hemispheres.</p>
      </sec>
      <sec id="s2d">
        <title>Processing Time</title>
        <p><xref ref-type="table" rid="pcbi-1002658-t001">Table 1</xref> shows the processing time for every test datum chosen from the DIADEM test data. Except for the I/O time, it requires approximately 10 s for image preprocessing, tracing a single neuron, and the <italic>ε</italic>-approximation procedure. The experiments in this study were performed using a PC with an Intel Core i7 920 processor and 8 GB memory space. The actual memory usage was no more than 2 GB for all test data, including the optical nerves.</p>
        <table-wrap id="pcbi-1002658-t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.t001</object-id><label>Table 1</label><caption>
            <title>Reconstruction time and accuracy.</title>
          </caption><alternatives>
            <graphic id="pcbi-1002658-t001-1" mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.t001" xlink:type="simple"/>
            <table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Data</td>
                  <td align="left" colspan="1" rowspan="1">Size (voxel)</td>
                  <td align="left" colspan="1" rowspan="1">Time (sec.)</td>
                  <td align="left" colspan="1" rowspan="1">Dis(<italic>N</italic><sub>2</sub>, <italic>N</italic><sub>1</sub>)</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" colspan="1" rowspan="1">OP_1</td>
                  <td align="left" colspan="1" rowspan="1">512×512×60</td>
                  <td align="left" colspan="1" rowspan="1">11.297</td>
                  <td align="left" colspan="1" rowspan="1">1.41496</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">OP_6</td>
                  <td align="left" colspan="1" rowspan="1">512×512×60</td>
                  <td align="left" colspan="1" rowspan="1">5.234</td>
                  <td align="left" colspan="1" rowspan="1">1.87089</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">OP_7</td>
                  <td align="left" colspan="1" rowspan="1">512×512×60</td>
                  <td align="left" colspan="1" rowspan="1">6.359</td>
                  <td align="left" colspan="1" rowspan="1">1.75834</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">OP_9</td>
                  <td align="left" colspan="1" rowspan="1">512×512×60</td>
                  <td align="left" colspan="1" rowspan="1">10.39</td>
                  <td align="left" colspan="1" rowspan="1">1.65372</td>
                </tr>
              </tbody>
            </table>
          </alternatives></table-wrap>
      </sec>
      <sec id="s2e">
        <title>Accuracy Analysis</title>
        <p>Taking two reconstruction results, <italic>N</italic><sub>1</sub> and <italic>N</italic><sub>2</sub>, from a set of volume data containing a single neuron, we define the distance from one reconstruction to the other. The distance from <italic>N</italic><sub>1</sub> to <italic>N</italic><sub>2</sub> is defined as follows. Let <italic>p</italic> be a point in <italic>N</italic><sub>1</sub>. The distance from <italic>p</italic> to <italic>N</italic><sub>2</sub> is defined as<disp-formula id="pcbi.1002658.e001"><graphic orientation="portrait" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002658.e001" xlink:type="simple"/><label>(1)</label></disp-formula>In (1), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e002" xlink:type="simple"/></inline-formula> is the Euclidean distance in the image space. The distance from <italic>N</italic><sub>1</sub> to <italic>N</italic><sub>2</sub> is defined as<disp-formula id="pcbi.1002658.e003"><graphic orientation="portrait" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002658.e003" xlink:type="simple"/><label>(2)</label></disp-formula>This study computes the distance between the reconstruction and the ground truth to analyze the accuracy of the method. Four data sets in <italic>olfactory projection fibers</italic> in the DIADEM test data were used. Because the points on the neuron fibers of the ground truth are substantially denser than in the reconstruction, points on the neuron branches of the reconstruction were sampled to produce the same density of points on the neuron fibers. Let <italic>N</italic><sub>1</sub> and <italic>N</italic><sub>2</sub> be the ground truth and our reconstruction respectively. We computed <italic>Dis</italic>(<italic>N</italic><sub>2</sub>, <italic>N</italic><sub>1</sub>) for the four data sets; the distances ranged from 1.4 to 1.87. <xref ref-type="table" rid="pcbi-1002658-t001">Table 1</xref> shows a summary of the experimental results.</p>
        <p>This study also investigates the profile of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e004" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e005" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1002658-g004">Fig. 4</xref> shows the histograms. Most of the points are within three voxels of the reference reconstruction. The maximum difference is larger when the automatically reconstructed result is the reference. This is probably because there are large nodular structures in the projection neurons. Experts usually trace more points to the boundary of the nodular structure. However, the proposed method computes the centerline to represent the nodular structures using fewer points. Consequently, a branch in the reconstruction has a good chance of being shorter than the same branch in the ground truth. <xref ref-type="fig" rid="pcbi-1002658-g005">Fig. 5</xref> shows both the gold reconstruction in the DIADEM data set and our reconstructed result overlapped with the original neuron image. Large distances appear in the green rectangular boxes. In this experiment, the distance is measured in the number of voxels. Each voxel is considered a unit cube.</p>
        <fig id="pcbi-1002658-g004" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>These two histograms show the distribution of the distances between points on one reconstructed result and a reference reconstruction.</title>
            <p>The references are respectively our reconstruction (top) and the ground truth (bottom).</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g004" xlink:type="simple"/>
        </fig>
        <fig id="pcbi-1002658-g005" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Both the gold reconstruction (top) and our tracing result (bottom) overlap with the volume rendering of the original image stack are shown.</title>
            <p>The green rectangles indicate the regions where the large distances occur.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g005" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2f">
        <title>Robustness Test</title>
        <p>The robustness test was performed by first adding Gaussian random noise to the datum, and then applying the proposed method to compute the centerlines of the neuron. We tested five cases for different noise levels. The noise levels were determined by the standard deviation of the Gaussian distribution to be <italic>σ</italic> = 20, <italic>σ</italic> = 30, <italic>σ</italic> = 40, <italic>σ</italic> = 50, and <italic>σ</italic> = 60. The intensity value ranged from 0 to 255. <italic>σ</italic> increases in conjunction with the number of visible voxels, but the percentage of visible voxels on the neuron decreases (<xref ref-type="fig" rid="pcbi-1002658-g006">Fig. 6</xref>), making neuron tracing more difficult. Because the image is contaminated by noise, keeping 70% of the brightest visible voxels could lead to too many noisy voxels being included. The visible voxel is defined in the <xref ref-type="sec" rid="s3">Methods</xref> section. In the robustness test experiment, therefore, instead of keeping 70% of the brightest voxels, only 20% of the brightest voxels among the visible voxels were kept.</p>
        <fig id="pcbi-1002658-g006" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>The images were contaminated by different levels of Gaussian noise: (a) σ = 20, (b) σ = 30, (c) σ = 40, (d) σ = 50, and (e) σ = 60.</title>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g006" xlink:type="simple"/>
        </fig>
        <p>To evaluate the robustness of the proposed method quantitatively in noisy images, in this study we also calculated the distance between the reconstructed result and the gold reconstruction in the DIADEM data set. As <xref ref-type="fig" rid="pcbi-1002658-g007">Fig. 7</xref> shows, the distances between the reconstructions and the ground truth are still manageable, despite the noise level being at 60. <xref ref-type="fig" rid="pcbi-1002658-g008">Fig. 8</xref> shows the traced results. Although the current test demonstrated that the proposed method is able to handle image data contaminated by Gaussian random noise, the algorithm will not necessarily perform well in the face of staining artifacts, which are common in biological specimens.</p>
        <fig id="pcbi-1002658-g007" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>The histogram for all five different noise levels.</title>
            <p>We can find that the distributions of five noise levels are almost the same.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g007" xlink:type="simple"/>
        </fig>
        <fig id="pcbi-1002658-g008" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>The traced result (<italic>red</italic>) of the contaminated, σ = 60 image stack overlaps with the volume rendering of the image stack.</title>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g008" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3" sec-type="methods">
      <title>Methods</title>
      <sec id="s3a">
        <title>Image Acquisition</title>
        <p>This section briefly details the technique used to label a single neuron for observing neurons using confocal microscopy <xref ref-type="bibr" rid="pcbi.1002658-Chiang2">[20]</xref>. A tiling heat-shock protocol in MARCM labeling was adapted to cover most neurons born at different times. Animals were kept in a 37°C water bath for 3 min to 60 min, depending on the Gal4 driver used, with 50% overlapping periods throughout the entire development from embryo to adult eclosion. In each case, GFP expression was controlled by a specific Gal4 driver with the expression being dependent on the stochastic removal of a <italic>Gal80</italic> repressor by heat-shock-induced expression of a flippase protein during mitotic recombination at cell birth. The Gal4 lines were driven by the promoter of an essential protein for synthesis or processing of one of the following neurotransmitters: acetylcholine (<italic>Cha-Gal4</italic>), dopamine (<italic>TH-Gal4</italic>), GABA (<italic>Gad1-Gal4</italic>), glutamate (<italic>VGlut-Gal4</italic>), octopamine (<italic>Tdc2-Gal4</italic>), or serotonin (<italic>Trh-Gal4</italic>). Thus, an individual neuron of putative birth time and neurotransmitter type was labeled.</p>
        <p>Sample brains were imaged using a Zeiss LSM 510 confocal microscope with a 20× C-Apochromat water-immersion objective lens (N.A. value 1.2, working distance 220 µm). The following settings were used in image acquisition: scanning speed 7, resolution 1024×1024, line average four times, zoom 0.7, and optical slice 1 µm. The voxel size of <italic>x</italic>∶<italic>y</italic>∶<italic>z</italic> is 0∶33×0∶33×1 µm. The resolutions of the image stacks in the <italic>Olfactory Projection Fibers</italic> of the DIADEM data set were the same.</p>
        <p>All the data except those provided in the DIADEM data set were acquired by neural biologists in the Brain Research Center, National Tsing Hua University, Hsinchu, Taiwan. Every image of a single neuron in 3D was segmented out of background brain tissues semi-automatically with the help of software. Human aids were provided to visually identify and select the neuron structure in the image. There are cases that multiple single neuron images were labeled from one brain. If these neurons could be clearly discriminated in 3D with ease, the neuron images were also segmented semi-automatically. Mostly, it took just few minutes to complete this step but a small number of difficult cases need more than 10 minutes.</p>
      </sec>
      <sec id="s3b">
        <title>Image Preprocessing</title>
        <p>First, a heuristic method was used to binarize the volume data of an image stack containing a single neuron. The heuristic method was designed based on the observation that biologists tend to set up a confocal microscope for optimal human visualization of the neuron in a slice. The heuristic approach in this study segments the neuron by keeping 70% of the brightest “visible” voxels. An 8-bit grayscale voxel is “visible” if it has an intensity above 10. This method allows a sufficient number of voxels to be kept on the neuron, while maintaining a low noise level. Each row in <xref ref-type="fig" rid="pcbi-1002658-g009">Fig. 9</xref> shows the images of a neuron undergoing different levels of binarization. The first column shows the original images, and the fourth column shows the results obtained by the proposed heuristic. Because the segmented result could still contain sparse noise, we remove noise by eliminating small-sized connected components in the volume. First, the 2D connected component analysis was applied to each slice. All 2D 8-neighbor connected components consisting of less than 9 pixels were removed. The 3D 26-neighbor connected component analysis was then applied to the volume to remove all 3D 26-neighbor connected components consisting of less than 30 voxels. After removing the small connected components, the 2D morphological closing operator was applied to each slice in the image stack to smooth the boundary of the neuron. This step is necessary because without it, the step that computes the 2D skeletons produces unwanted small branches for rough boundary components.</p>
        <fig id="pcbi-1002658-g009" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g009</object-id>
          <label>Figure 9</label>
          <caption>
            <title>Three data of <italic>Olfactory Projection Neuron</italic> in the DIADEM data set are used to demonstrate the binarization method.</title>
            <p>The neurons are rendered by the maximum intensity projection (MIP) method. Every row shows a neuron undergoing different levels of binarization. From left to right, they are the original neuron image followed by the binarized results. From the second column to the last column, we kept 50%, 60%, 70%, and 80% of the brightest visible voxels where the visible voxels are voxels having a gray scale above 10. In the proposed method, we keep 70% of the brightest visible voxels, which are shown in column 4.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g009" xlink:type="simple"/>
        </fig>
        <p>The 2D skeletons of each slice were computed before reconstructing the 3D neuronal structure. Let <italic>B</italic> be the volume containing the binarized neuron, and denote the set of non-zero voxels by <italic>B<sub>N</sub></italic>. The 2D Euclidean distance transform was applied to each image slice in <italic>B</italic>, and the 2D skeletons for each connected component were computed based on the transformed result <xref ref-type="bibr" rid="pcbi.1002658-Niblack1">[21]</xref>. Let the set of points on the 2D skeletons be denoted by <italic>Q</italic>.</p>
      </sec>
      <sec id="s3c">
        <title>Fragmental Line Structures Assembling</title>
        <p>Because there is only one neuron, <italic>Q</italic> should form a single 3D connected component. If <italic>Q</italic> does not form a 3D connected component (i.e., broken branches exist), then the Minimum Spanning Tree (MST) technique is applied to compute the connected component. A weighted graph was constructed based on the 3D 26-neighbor connected components. Each vertex in this weighted graph represents a 3D connected component. There is an edge between a pair of vertices if the Euclidean distance in the image space between the closest points in two connected components is less than 5% of the largest image dimension. The edge weight is the distance between the pair of closest points. The MST of the graph was then computed using the Kruskal algorithm. Once an edge was selected during MST construction, points along the edge were sampled so that the distance between a pair of consecutive points was approximately 1. These sampled points were then added to the set <italic>Q</italic>. If there is more than one connected component when the process terminates, only the largest connected component is kept, and all the others are removed from <italic>Q</italic>. For each point in <italic>Q</italic>, we identify whether it is a candidate 3D end point by examining nine digital planes in the 26-neighborhood <xref ref-type="bibr" rid="pcbi.1002658-Pudney1">[22]</xref>. The set of candidate 3D end points is denoted by <italic>V<sub>E</sub></italic>. The next step reconstructs the 3D neuronal structure from <italic>Q</italic>.</p>
      </sec>
      <sec id="s3d">
        <title>Reconstruction of the Neuron Branches</title>
        <p>Another weighted graph was constructed from the point set <italic>Q</italic>. The shortest path algorithm employed in this study is the single-source shortest path algorithm. Because a source point in the graph should be given, this study defines the center of the soma as the source. In the image, the soma is a set of high-intensity voxels forming a spherical object. Geometrically, the Chebyshev center of a set is the point within the set that is the farthest from the boundary (<xref ref-type="bibr" rid="pcbi.1002658-Boyd1">[23]</xref> Ch. 8). An approximated Chebyshev center for the center of the soma served as the source vertex in the graph.</p>
        <p>A good approximation for the Chebyshev center of the soma is a point in <italic>Q</italic> that is farthest from the boundary. The approximate Chebyshev center is computed iteratively as follows. For each point <italic>p</italic> in <italic>Q</italic>, we iteratively increase the radius, <italic>r<sub>p</sub></italic>, of the sphere centered at <italic>p</italic> until the sphere cannot enclose points totally in <italic>B<sub>N</sub></italic>. The center of the soma is the point <italic>c</italic> in <italic>Q</italic> that admits the largest sphere enclosing points totally in <italic>B<sub>N</sub></italic> and the largest sum of the intensity. <xref ref-type="fig" rid="pcbi-1002658-g010">Fig. 10</xref> shows an example of soma detection.</p>
        <fig id="pcbi-1002658-g010" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g010</object-id>
          <label>Figure 10</label>
          <caption>
            <title>An example of the soma detection.</title>
            <p>(a) The MIP image of the original image stack. (b) Red dot indicates the center of the soma calculated by the soma detection procedure. (c) A close view of the detected soma position.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g010" xlink:type="simple"/>
        </fig>
        <p>To push the 3D centerline toward the true center of the neuron, it is important to identify the <italic>candidate branch points</italic>. A 2D skeleton point is a candidate branch point if it has four or five neighboring points in <italic>Q</italic> and the arrangement of four is isomorphic to one of the patterns shown in <xref ref-type="fig" rid="pcbi-1002658-g011">Fig. 11</xref>. The set of candidate branch points is denoted by <italic>Bps2D</italic>.</p>
        <fig id="pcbi-1002658-g011" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g011</object-id>
          <label>Figure 11</label>
          <caption>
            <title>The black nodes represent the points in Q.</title>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g011" xlink:type="simple"/>
        </fig>
        <p>A weighted graph <italic>G</italic> = (<italic>V,E</italic>) was constructed from <italic>Q</italic>. <italic>V</italic> is a set of vertices where each vertex is a point in <italic>Q</italic>. <italic>E</italic> is a set of edges (<italic>p, q</italic>), where <italic>p</italic> and <italic>q</italic> are in <italic>Q</italic> and neighboring to each other in the volume. The cost associated with the edge (<italic>p, q</italic>) is<disp-formula id="pcbi.1002658.e006"><graphic orientation="portrait" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002658.e006" xlink:type="simple"/><label>(3)</label></disp-formula>where <italic>w</italic>(<italic>p, q</italic>) is as shown in (4).<disp-formula id="pcbi.1002658.e007"><graphic orientation="portrait" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002658.e007" xlink:type="simple"/><label>(4)</label></disp-formula>In (4), <italic>w<sub>d</sub></italic> is the Euclidean distance between <italic>p</italic> and <italic>q</italic> in the image space. The traced branches should intersect at a single branch point where a visual bifurcation point is present. To meet this requirement, an edge close to a candidate branch point has a large value for <italic>w<sub>b</sub></italic>. Let <italic>b<sub>p</sub></italic> be a candidate branch point. Consider the sphere centered at <italic>b<sub>p</sub></italic> with a radius <italic>R</italic> = 1.0 µm. If (<italic>p, q</italic>) is enclosed in the sphere, then <italic>w<sub>b</sub></italic> of (<italic>p, q</italic>) is <italic>η−d</italic>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e008" xlink:type="simple"/></inline-formula>. Otherwise, <italic>w<sub>b</sub></italic> = 0. <italic>R</italic> is set to be 1.0 µm. This is because a sphere of the radius of 1.0 µm is usually totally enclosed in the neuron in the bifurcation region. Because the resolutions in the <italic>x</italic>-,<italic>y</italic>-, and <italic>z</italic>-directions are 0.33 µm, 0.33 µm, and 1.0 µm, respectively, a 6×6×2 box was used to approximate the sphere. To guarantee that <italic>w<sub>b</sub></italic> is positive, set <italic>η</italic> = 10.</p>
        <p>In (4), the edges close to a branching point have a large <italic>w<sub>b</sub></italic> = <italic>η−d</italic>. Thus, these edges have a heavy weight, <italic>w</italic>(<italic>p, q</italic>), and light cost, <italic>f</italic>(<italic>p, q</italic>). When the shortest path algorithm is applied, these edges tend to become a part of the shortest path; thus, the constructed shortest paths tend to keep the appropriate branch points of the neuron branches.</p>
        <p>Given the weighted graph and the source vertex <italic>c</italic>, the shortest paths from <italic>c</italic> to all the points in <italic>V<sub>E</sub></italic> can be computed by applying the Dijkstra algorithm. Each path from <italic>c</italic> to a vertex in <italic>V<sub>E</sub></italic> is called a branch. A branch should be removed if the ratio between its length and the length of the longest branch is less than 0.2. Such short branches are usually branches in the interior of the soma. These branches in the soma are not neuron fibers and they should be removed. <xref ref-type="fig" rid="pcbi-1002658-g012">Fig. 12</xref> shows the results of before and after removing short branches.</p>
        <fig id="pcbi-1002658-g012" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g012</object-id>
          <label>Figure 12</label>
          <caption>
            <title>The results of before (left) and after (right) removing short branches inside the soma are demonstrated.</title>
            <p>The green rectangles indicate the somas.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g012" xlink:type="simple"/>
        </fig>
        <p>The neuronal structure is reconstructed by iteratively selecting a branch obtained in the previous step, followed by post-processing as described in the following steps. Iterations stop when <italic>V<sub>E</sub></italic> is empty. A list (<italic>BpList</italic>) that stores the branch points formed during the reconstruction process is required.</p>
        <list list-type="order">
          <list-item>
            <p>Select the longest branch, <italic>P</italic>, which is a branch from <italic>c</italic> to a point <italic>p</italic> in <italic>V<sub>E</sub></italic>. Remove <italic>p</italic> from <italic>V<sub>E</sub></italic>. If <italic>BpList</italic> is not empty, compute the physical distances between the points on <italic>P</italic> and the points in <italic>BpList</italic>. Along the path from <italic>p</italic> to <italic>c</italic>, let <italic>b</italic> be the first point, such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e009" xlink:type="simple"/></inline-formula>1.0 µm. In this case, <italic>b</italic> is considered the same as <italic>q</italic>. Furthermore, <italic>P</italic> can be divided into two paths: from <italic>c</italic> to <italic>b</italic>, and from <italic>b</italic> to <italic>p</italic>. The path from <italic>c</italic> to <italic>q</italic> is a subpath of a previously reconstructed path, <italic>P′</italic>. In this case, the branch <italic>P</italic> is modified to be the path from <italic>c</italic> to <italic>q</italic> of <italic>P′</italic>, and <italic>b</italic> in the path from <italic>b</italic> to <italic>p</italic> is replaced by <italic>q</italic>. If no such pair exists, look for another pair (<italic>b′, q′</italic>), in which <italic>q′</italic> is from <italic>Bps2D</italic> and <italic>b′</italic> is from the path along <italic>p</italic> to <italic>c</italic>. Let <italic>b′</italic> be the first point, such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e010" xlink:type="simple"/></inline-formula>0.75 µm, and replace <italic>b′</italic> by <italic>q′</italic> on the branch.</p>
          </list-item>
          <list-item>
            <p>If <italic>P</italic> shares a common subpath from <italic>c</italic> to <italic>bp</italic> with a previously reconstructed branch and <italic>bp</italic> is not in <italic>BpList</italic>, then <italic>bp</italic> is inserted into <italic>BpList</italic>.</p>
          </list-item>
          <list-item>
            <p>Because the skeletons were computed in 2D slices, false candidate 3D end points exist. In this study, the candidate 3D end points close to <italic>P</italic> are considered to be false end points, and the branch is removed if the distance between its end points and <italic>P</italic> is less than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e011" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e012" xlink:type="simple"/></inline-formula> is the average of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e013" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e014" xlink:type="simple"/></inline-formula>.</p>
          </list-item>
        </list>
      </sec>
      <sec id="s3e">
        <title>Polygonal Path Approximation</title>
        <p>The 3D centerline obtained by applying the shortest path algorithm was not smooth because the graph is a grid graph (<xref ref-type="fig" rid="pcbi-1002658-g013">Fig. 13(a)</xref>). To construct smooth centerlines, an <italic>ε</italic>-approximated polygonal path was calculated to approximate the centerline computed by the shortest path algorithm. An <italic>ε</italic>-approximation of a polygonal path has fewer points on the path, within a small deviation, <italic>ε</italic>, from the original polygonal path (<xref ref-type="fig" rid="pcbi-1002658-g013">Fig. 13(b)</xref>). <xref ref-type="supplementary-material" rid="pcbi.1002658.s003">Text S3</xref> details the algorithm for computing the <italic>ε</italic>-approximation. All experiments in this study adopted a value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e015" xlink:type="simple"/></inline-formula> for <italic>ε</italic>.</p>
        <fig id="pcbi-1002658-g013" orientation="portrait" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.g013</object-id>
          <label>Figure 13</label>
          <caption>
            <title>A zoom-in view of the traced result. Red lines show the tracing results.</title>
            <p>The lines in (a) are zigzag shaped. However, they become smooth when the ε-approximation method is applied (b). The <italic>ε</italic> was <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e016" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.g013" xlink:type="simple"/>
        </fig>
        <p>For the convenience of reproducing our results, the parameters used in all these steps are summarized in <xref ref-type="table" rid="pcbi-1002658-t002">Table 2</xref>.</p>
        <table-wrap id="pcbi-1002658-t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1002658.t002</object-id><label>Table 2</label><caption>
            <title>Parameters for reconstruction.</title>
          </caption><alternatives>
            <graphic id="pcbi-1002658-t002-2" mimetype="image" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.t002" xlink:type="simple"/>
            <table>
              <colgroup span="1">
                <col align="left" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
                <col align="center" span="1"/>
              </colgroup>
              <thead>
                <tr>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">Image Preprocess</td>
                  <td align="left" colspan="1" rowspan="1">Fragmental line structures assembling</td>
                  <td align="left" colspan="1" rowspan="1">Reconstruct the 3D centerlines</td>
                  <td align="left" colspan="1" rowspan="1">Polygonal path approximation</td>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Initial threshold level</td>
                  <td align="left" colspan="1" rowspan="1">10, in a 256-gray scale image</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Threshold for the 2D 8-neighbor CC</td>
                  <td align="left" colspan="1" rowspan="1">9</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Threshold for the 3D 26-neighbor CC</td>
                  <td align="left" colspan="1" rowspan="1">30</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Maximum edge weight to connect two components</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">5% of the largest image dimension</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Radius <italic>R</italic></td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">1.0 µm</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">
                    <italic>η</italic>
                  </td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">10</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Ratio for determine branches in the soma</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">0.2</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Threshold for connecting to a point in BpList</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">1.0 µm</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">Threshold for connecting to a point in Bps2D</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                  <td align="left" colspan="1" rowspan="1">0.75 µm</td>
                  <td align="left" colspan="1" rowspan="1">_</td>
                </tr>
                <tr>
                  <td align="left" colspan="1" rowspan="1">ε for path approximation</td>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1"/>
                  <td align="left" colspan="1" rowspan="1">
                    <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002658.e017" xlink:type="simple"/></inline-formula>
                  </td>
                </tr>
              </tbody>
            </table>
          </alternatives></table-wrap>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <p>In this paper, we presented a computer method for reconstructing neuronal structure from an image stack. Based on the fact that biologists tend to use confocal microscopes for optimal images in a slice for human visualization, we proposed processing 2D slice images first. 3D neuronal structures were then constructed from the processed 2D images. Using this strategy, a high-throughput method was designed. More than 16 000 neurons were reconstructed and stored in the database <xref ref-type="bibr" rid="pcbi.1002658-FlyCircuit1">[16]</xref>. A few of the reconstructed neurons were incorrect, mainly because the resolution of the optical microscope is not sufficient to distinguish dense branches.</p>
      <p>The features used to design the weights of the edges (<xref ref-type="disp-formula" rid="pcbi.1002658.e007">Eq. 4</xref>) were extracted from the 2D skeletons. One of the features is the branch point; however, the proposed template matching method is unable to detect all branch points. When a slice passes through the branch point, and the two branches are respectively above and below the slice, we are not able to detect the branch point. This problem may cause errors in the location of the branch point.</p>
      <p>Another weakness of the proposed method is related to detecting delicate structures. The candidate 3D end points were obtained from the 2D end points, and the end points close to a branch were removed. Some small branches could therefore be considered as noise and ignored. Thus, the reconstruction by the proposed methods is inadequate for a study for which the details of a neuron are extremely important, e.g. the study of neuron dynamics <xref ref-type="bibr" rid="pcbi.1002658-He1">[24]</xref>.</p>
      <p>Currently, the DIADEM <xref ref-type="bibr" rid="pcbi.1002658-Brown1">[15]</xref> data set is widely used in the study of neuron reconstruction for accuracy evaluation. A scoring system is provided. We used the DIADEM data set as ground truth to evaluate the accuracy of the proposed method; however, reconstructions obtained by the proposed method did not achieve a good DIADEM score. The reasons are:</p>
      <list list-type="order">
        <list-item>
          <p>The neuron branches obtained were based on the 2D skeletons in each slice. Thus, neuron branches obtained by the proposed method are shorter than those traced by experts.</p>
        </list-item>
        <list-item>
          <p>Our approach tends to merge branch points in a small region to a single point. The proposed method could ignore some branch points in the ground truth. However, each branch point is highly weighted in the DIADEM metric so that our reconstructed neuron could receive a serious penalty.</p>
        </list-item>
        <list-item>
          <p>The DIADEM ground truth constructed by experts was obtained using NeuroLucida. The traced neurons were smoothed by spline interpolation. Coordinates of points on the neuron branches are real numbers. We used a polygonal line to approximate a neuron branch; coordinates of the points are integer numbers. Consequently, a large error could occur in estimating the radius of the neuron branches of our reconstruction.</p>
        </list-item>
      </list>
      <p>Although neurons constructed by the proposed method cannot achieve a good DIADEM score, nevertheless, as shown in the Results section, the reconstructed results are suitable for further studies. In conclusion, the reconstructed neurons are sufficiently reliable to support the analysis of the neural network.</p>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pcbi.1002658.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.s001" xlink:type="simple">
        <label>Text S1</label>
        <caption>
          <p>An introduction to the reconstructed data.</p>
          <p>(DOCX)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002658.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.s002" xlink:type="simple">
        <label>Text S2</label>
        <caption>
          <p>Steps for constructing neural tracts.</p>
          <p>(DOCX)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002658.s003" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" orientation="portrait" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002658.s003" xlink:type="simple">
        <label>Text S3</label>
        <caption>
          <p>Details of polygonal path approximation method.</p>
          <p>(DOCX)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors are grateful to Dr. HM. Chang for helping them clarify the presentation of this paper and for his precious suggestions. They would like to thank the National Center for High-Performance Computing (NCHC), Hsinchu, Taiwan, for their help with data maintenance.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002658-Greenspan1">
        <label>1</label>
        <mixed-citation publication-type="book" xlink:type="simple">Greenspan RJ (2004) Fly Pushing second edition. Cold Spring Harbor Laboratory Press.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Chiang1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chiang</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Liu</surname><given-names>YC</given-names></name>, <name name-style="western"><surname>Hu</surname><given-names>SH</given-names></name>, <name name-style="western"><surname>Huang</surname><given-names>CY</given-names></name>, <name name-style="western"><surname>Hsieh</surname><given-names>CH</given-names></name> (<year>2001</year>) <article-title>Three-dimensional mapping of brain neuropils in the cockroach <italic>Diploptera punctata</italic></article-title>. <source>J Comp Neurol</source> <volume>440</volume>: <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Hama1">
        <label>3</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hama</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Kurokawa</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Kawano</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Ando</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Shimogori</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Noda</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Fukami</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Sakaue-Sawano</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Miyawaki</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Scale: a chemical approach for fluorescence imaging and reconstruction of transparent mouse brain</article-title>. <source>Nat Neurosci</source> <volume>14</volume>: <fpage>1481</fpage>–<lpage>1488</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Bouix1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bouix</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Siddiqi</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Tannenbaum</surname><given-names>K</given-names></name> (<year>2005</year>) <article-title>Flux driven automatic centerline extraction</article-title>. <source>Med Image Anal</source> <volume>9</volume>: <fpage>209</fpage>–<lpage>221</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Sonka1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sonka</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Winniford</surname><given-names>MD</given-names></name>, <name name-style="western"><surname>Zhang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>SM</given-names></name> (<year>1994</year>) <article-title>Lumen centerline detection incomplex coronary angiogram</article-title>. <source>IEEE Tran Med Imaging</source> <volume>41</volume>: <fpage>520</fpage>–<lpage>528</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Deschamps1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Deschamps</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Cohen</surname><given-names>LD</given-names></name> (<year>2001</year>) <article-title>Fast extraction of minimal paths in 3D images and application to virtual endoscopy</article-title>. <source>Med Image Anal</source> <volume>5</volume>: <fpage>281</fpage>–<lpage>299</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Bitter1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bitter</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Kaufman</surname><given-names>AE</given-names></name>, <name name-style="western"><surname>Sato</surname><given-names>M</given-names></name> (<year>2001</year>) <article-title>Penalized-distance volumetric skeleton algorithm</article-title>. <source>IEEE T Vis Comput Gr</source> <volume>7</volume>: <fpage>195</fpage>–<lpage>205</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Li1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Yezzi</surname><given-names>A</given-names></name> (<year>2007</year>) <article-title>Vessels as 4-D curves: global minimal 4-D paths to extract 3-D tubular surfaces and centerlines</article-title>. <source>IEEE Tran Med Imaging</source> <volume>26</volume>: <fpage>1213</fpage>–<lpage>1223</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-AlKofahi1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Al-Kofahi</surname><given-names>KA</given-names></name>, <name name-style="western"><surname>Lasek</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Szarowski</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Pace</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Nagy</surname><given-names>G</given-names></name>, <etal>et al</etal>. (<year>2002</year>) <article-title>Rapid automated three-dimensional tracing of neurons from confocal image stacks</article-title>. <source>IEEE Tran Info Tech in Biomedicine</source> <volume>6</volume>: <fpage>171</fpage>–<lpage>187</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Zhao1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhao</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Amat</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Clack</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Ahammad</surname><given-names>P</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Automated reconstructions of neuronal morphology based on local geometrical and global structural models</article-title>. <source>NeuroInform</source> <volume>9</volume>: <fpage>247</fpage>–<lpage>261</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Zhang1">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Zhou</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Degterev</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Lipinski</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Adjeroh</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Automated neurite extraction using dynamic programming for high-throughput screening of neuron based assays</article-title>. <source>NeuroImage</source> <volume>35</volume>: <fpage>1502</fpage>–<lpage>1515</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Lee1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>PC</given-names></name>, <name name-style="western"><surname>Ching</surname><given-names>YT</given-names></name>, <name name-style="western"><surname>Chang</surname><given-names>HM</given-names></name>, <name name-style="western"><surname>Chiang</surname><given-names>AS</given-names></name> (<year>2008</year>) <article-title>A semi-automatic method for neuron centerline extraction in confocal microscopic image stack</article-title>. <source>Biomedical Imaging, IEEE Intl. Symposium, 2008</source> <fpage>959</fpage>–<lpage>962</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Peng1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Peng</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Ruan</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Atasoy</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sternson</surname><given-names>S</given-names></name> (<year>2010</year>) <article-title>Automatic reconstruction of 3D neuron structures using a graph-augmented deformable model</article-title>. <source>Bioinformatics</source> <volume>26</volume>: <fpage>i38</fpage>–<lpage>i46</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Tretken1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Türetken</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Gonzalez</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Blum</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Fau</surname><given-names>P</given-names></name> (<year>2011</year>) <article-title>Automated reconstruction of dendritic and axonal tress by global optimization with geometric priors</article-title>. <source>NeuroInform</source> <volume>9</volume>: <fpage>279</fpage>–<lpage>302</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Brown1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brown</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Barrionuevo</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Canty</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>De Paola</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Hirsch</surname><given-names>JA</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>The DIADEM data sets: representative light microscopy images of neuronal morphology to advance automation of digital reconstructions</article-title>. <source>Neuroinformatics</source> <volume>9</volume>: <fpage>143</fpage>–<lpage>57</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-FlyCircuit1">
        <label>16</label>
        <mixed-citation publication-type="other" xlink:type="simple">FlyCircuit Database. Available: <ext-link ext-link-type="uri" xlink:href="http://www.flycircuit.tw" xlink:type="simple">http://www.flycircuit.tw</ext-link> Accessed 2010.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-HClust1">
        <label>17</label>
        <mixed-citation publication-type="other" xlink:type="simple">HClust. Available: <ext-link ext-link-type="uri" xlink:href="http://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html" xlink:type="simple">http://stat.ethz.ch/R-manual/R-devel/library/stats/html/hclust.html</ext-link></mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Stocker1">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stocker</surname><given-names>RF</given-names></name>, <name name-style="western"><surname>Lienhard</surname><given-names>MC</given-names></name>, <name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Fischbach</surname><given-names>KF</given-names></name> (<year>1990</year>) <article-title>Neural architecture of the antennal lobe in Drosophila melanogaster</article-title>. <source>Cell Tissue Res</source> <volume>262</volume>: <fpage>9</fpage>–<lpage>34</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Stocker2">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stocker</surname><given-names>RF</given-names></name> (<year>1994</year>) <article-title>The organization of the chemosensory system in Drosophila melanogaster: a review</article-title>. <source>Cell Tissue Res</source> <volume>275</volume>: <fpage>3</fpage>–<lpage>26</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Chiang2">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chiang</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Lin</surname><given-names>CY</given-names></name>, <name name-style="western"><surname>Chuang</surname><given-names>CC</given-names></name>, <name name-style="western"><surname>Chang</surname><given-names>HM</given-names></name>, <name name-style="western"><surname>Hsieh</surname><given-names>CH</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Three-dimensional reconstruction of brainwide wiring networks in Drosophila at single cell resolution</article-title>. <source>Curr Biol</source> <volume>21</volume>: <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Niblack1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niblack</surname><given-names>CW</given-names></name>, <name name-style="western"><surname>Gibbsons</surname><given-names>PB</given-names></name>, <name name-style="western"><surname>Capson</surname><given-names>DW</given-names></name> (<year>1992</year>) <article-title>Generating skeletons and centerlines from the distance transform</article-title>. <source>CVGIP: Graphl Models Im Proc</source> <volume>54</volume>: <fpage>420</fpage>–<lpage>437</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Pudney1">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pudney</surname><given-names>C</given-names></name> (<year>1998</year>) <article-title>Distance-ordered homotopic thinning: a skeletonization algorithm for 3D digital images</article-title>. <source>Comput Vis Image Und</source> <volume>72</volume>: <fpage>404</fpage>–<lpage>413</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-Boyd1">
        <label>23</label>
        <mixed-citation publication-type="book" xlink:type="simple">Boyd S and Vandenberghe L (2004) Convex Optimization. Cambridge Univ. Press.</mixed-citation>
      </ref>
      <ref id="pcbi.1002658-He1">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>He</surname><given-names>HY</given-names></name>, <name name-style="western"><surname>Cline</surname><given-names>HT</given-names></name> (<year>2011</year>) <article-title>Diadem X: Automated 4 dimensional analysis of morphological data</article-title>. <source>Neuroinform</source> <volume>9</volume>: <fpage>109</fpage>–<lpage>112</lpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
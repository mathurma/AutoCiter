<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-02005</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006681</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Geometry</subject><subj-group><subject>Ellipses</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Monte Carlo method</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Monte Carlo method</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject><subj-group><subject>Human learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Human online adaptation to changes in prior probability</article-title>
<alt-title alt-title-type="running-head">Human online adaptation to changes in prior probability</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7645-7141</contrib-id>
<name name-style="western">
<surname>Norton</surname> <given-names>Elyse H.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7471-7336</contrib-id>
<name name-style="western">
<surname>Acerbi</surname> <given-names>Luigi</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="fn" rid="currentaff001"><sup>¤</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Ma</surname> <given-names>Wei Ji</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2079-4552</contrib-id>
<name name-style="western">
<surname>Landy</surname> <given-names>Michael S.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Psychology Department, New York University, New York, New York, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Center for Neural Science, New York University, New York, New York, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Beierholm</surname> <given-names>Ulrik R.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Durham University, UNITED KINGDOM</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="current-aff" id="currentaff001">
<p>¤Current Address: Département des neurosciences fondamentales, Université de Genève, CMU, Genève, Switzerland</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">landy@nyu.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>7</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="epub">
<day>8</day>
<month>7</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>7</issue>
<elocation-id>e1006681</elocation-id>
<history>
<date date-type="received">
<day>28</day>
<month>11</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>20</day>
<month>6</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Norton et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006681"/>
<abstract>
<p>Optimal sensory decision-making requires the combination of uncertain sensory signals with prior expectations. The effect of prior probability is often described as a shift in the decision criterion. Can observers track sudden changes in probability? To answer this question, we used a change-point detection paradigm that is frequently used to examine behavior in changing environments. In a pair of orientation-categorization tasks, we investigated the effects of changing probabilities on decision-making. In both tasks, category probability was updated using a sample-and-hold procedure: probability was held constant for a period of time before jumping to another probability state that was randomly selected from a predetermined set of probability states. We developed an ideal Bayesian change-point detection model in which the observer marginalizes over both the current run length (i.e., time since last change) and the current category probability. We compared this model to various alternative models that correspond to different strategies—from approximately Bayesian to simple heuristics—that the observers may have adopted to update their beliefs about probabilities. While a number of models provided decent fits to the data, model comparison favored a model in which probability is estimated following an exponential averaging model with a bias towards equal priors, consistent with a conservative bias, and a flexible variant of the Bayesian change-point detection model with incorrect beliefs. We interpret the former as a simpler, more biologically plausible explanation suggesting that the mechanism underlying change of decision criterion is a combination of on-line estimation of prior probability and a stable, long-term equal-probability prior, thus operating at two very different timescales.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>We demonstrate how people learn and adapt to changes to the probability of occurrence of one of two categories on decision-making under uncertainty. The study combined psychophysical behavioral tasks with computational modeling. We used two behavioral tasks: a typical forced-choice categorization task as well as one in which the observer specified the decision criterion to use on each trial before the stimulus was displayed. We formulated an ideal Bayesian change-point detection model and compared it to several alternative models. We found that the data are explained best by a model that estimates category probability based on recently observed exemplars with a bias towards equal probability. Our results suggest that the brain takes multiple relevant time scales into account when setting category expectations.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000053</institution-id>
<institution>National Eye Institute</institution>
</institution-wrap>
</funding-source>
<award-id>EY08266</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2079-4552</contrib-id>
<name name-style="western">
<surname>Landy</surname> <given-names>Michael S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000053</institution-id>
<institution>National Eye Institute</institution>
</institution-wrap>
</funding-source>
<award-id>EY020958 and EY026927</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Ma</surname> <given-names>Wei Ji</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by NIH grants EY08266 (to MSL) and EY020958 and EY026927 (to WJM). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="2"/>
<page-count count="26"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-07-18</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Code to perform the analyses described in this paper and all subjects’ data are available at the following link: <ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/ChangeProb" xlink:type="simple">https://github.com/lacerbi/ChangeProb</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Sensory decision-making involves making decisions under uncertainty. Furthermore, optimal sensory decision-making requires the combination of uncertain sensory signals with prior expectations. Perceptual models of decision-making often incorporate prior expectations to describe human behavior. In Bayesian models, priors are combined with likelihoods to compute a posterior [<xref ref-type="bibr" rid="pcbi.1006681.ref001">1</xref>]. In signal detection theory, the effect of unequal probabilities (signal present vs. absent) is a shift of the decision criterion [<xref ref-type="bibr" rid="pcbi.1006681.ref002">2</xref>].</p>
<p>The effects of prior probability on the decision criterion have been observed in detection [<xref ref-type="bibr" rid="pcbi.1006681.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref004">4</xref>], line tilt [<xref ref-type="bibr" rid="pcbi.1006681.ref005">5</xref>], numerosity estimation [<xref ref-type="bibr" rid="pcbi.1006681.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref007">7</xref>], recognition memory [<xref ref-type="bibr" rid="pcbi.1006681.ref008">8</xref>], and perceptual categorization [<xref ref-type="bibr" rid="pcbi.1006681.ref009">9</xref>] tasks, among others. These studies generally use explicit priors, assume a fixed effect, and treat learning as additional noise. However, there are many everyday tasks in which the probability of a set of alternatives needs to be assessed based on one’s past experience with the outcomes of the task. The importance of experience has been demonstrated in studies examining differences between experience-based and description-based decisions [<xref ref-type="bibr" rid="pcbi.1006681.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref011">11</xref>] and in perceptual-categorization tasks with unequal probability, in which response feedback leads to performance that is closer to optimal than observational feedback [<xref ref-type="bibr" rid="pcbi.1006681.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref013">13</xref>]. While these studies demonstrate the importance of experience on decision-making behavior, they do not describe how experience influences expectation formation. The influence of experience on the formation of expectations has been demonstrated for learning stimulus mean [<xref ref-type="bibr" rid="pcbi.1006681.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref017">17</xref>], variance [<xref ref-type="bibr" rid="pcbi.1006681.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref018">18</xref>], higher-order statistics [<xref ref-type="bibr" rid="pcbi.1006681.ref019">19</xref>], likelihood distributions [<xref ref-type="bibr" rid="pcbi.1006681.ref020">20</xref>], the rate of change of the environment [<xref ref-type="bibr" rid="pcbi.1006681.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref021">21</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref023">23</xref>], and prior probability [<xref ref-type="bibr" rid="pcbi.1006681.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref025">25</xref>]. Here, we add to previous work by investigating how one’s previous experience influences probability learning in a changing environment.</p>
<p>In the previous work on probability learning by Behrens et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref024">24</xref>], participants tracked the probability of a reward to learn the value of two alternatives. This is a classic decision-making task that involves combining prior probability and reward. In contrast, we are interested in perceptual decision-making under uncertainty, in which prior probability is combined with uncertain sensory signals. We might expect differences in strategy between cognitive and perceptual tasks, as cognitive tasks can be susceptible to additional biases. For example, participants often exhibit base-rate neglect (i.e., they ignore prior probability when evaluating evidence) in cognitive tasks [<xref ref-type="bibr" rid="pcbi.1006681.ref026">26</xref>] but not in perceptual tasks [<xref ref-type="bibr" rid="pcbi.1006681.ref002">2</xref>]. On the other hand, Behrens et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref024">24</xref>] found that participants’ behavior was well described by an optimal Bayesian model, in that observed learning rates quantitatively matched those of a Bayesian decision-maker carrying out the same task. A more recent study by Zylberberg et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref025">25</xref>] examined probability learning under uncertainty in a motion-discrimination task. In this study, probability was estimated from a confidence signal rather than explicit feedback. Additionally, probability was changed across blocks, allowing participants to infer a change had occurred. Here, we examine probability learning when feedback is explicit and changes are sudden.</p>
<p>To investigate probability learning in uncertain conditions, we designed a perceptual categorization task in which observers need to learn category probability through experience. Since our goal was to examine low-level perceptual and decision-making processes, we used a highly controlled experimental environment. To prevent the use of external cues (e.g., the start of a new block indicating a change in probability) probabilities were changed using a sample-and-hold procedure. This approach has been used in decision-making [<xref ref-type="bibr" rid="pcbi.1006681.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref024">24</xref>] and motor domains [<xref ref-type="bibr" rid="pcbi.1006681.ref018">18</xref>] to examine behavior in dynamic contexts. Observers completed both a covert- and overt-criterion task, in which the decision criterion was implicit or explicit, respectively. The overt task, previously developed by Norton et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref016">16</xref>], provided a richer dataset upon which to compare models of human behavior. We determined how observers tracked category probability in a changing environment by comparing human behavior to both Bayesian and alternative models. We find that a number of models qualitatively describe human behavior, but that, quantitatively, model comparison favored an exponential averaging model with a bias towards equal priors and a flexible variant of the Bayesian change-point detection model with incorrect beliefs about the generative model. Although model comparison did not distinguish between these models, we interpret the exponential model with a conservative bias as a simpler, more biologically plausible explanation. Our results suggest that changes in the decision criterion are the result of both probability estimates computed on-line and a more stable, long-term prior.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Experiment</title>
<p>During each session, observers completed one of two orientation-categorization tasks. On each trial in the <italic>covert-criterion</italic> task, observers categorized an ellipse as belonging to category A or B by key press (<xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1A</xref>). On each trial in the <italic>overt-criterion</italic> task, observers used the mouse to rotate a line to indicate their criterion prior to the presentation of an ellipse (<xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1B</xref>). The observer was correct if the ellipse belonged to category A and was clockwise of the criterion line or if the ellipse belonged to category B and was counter-clockwise of the criterion line. The overt-criterion task is an explicit version of the covert-criterion task developed by Norton et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref016">16</xref>]. The overt-criterion task provides a richer dataset than the covert-criterion task in that it affords a continuous measure and allows us to see trial by trial changes in the reported decision criterion, at the expense of being a more cognitive task. In both tasks, the categories were defined by normal distributions on orientation with different means (<italic>μ</italic><sub>B</sub> = <italic>μ</italic><sub>A</sub> + Δ<italic>θ</italic>) and equal standard deviation (<italic>σ</italic><sub><italic>C</italic></sub>); the mean of category A was set clockwise of the the mean of category B and a neutral criterion would be located halfway between the category means (<xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1C</xref>). The difficulty of the task was equated across participants by setting Δ<italic>θ</italic> to a value that predicted a <italic>d</italic>′ value of 1.5 based on the data from the initial measurement session (see <xref ref-type="sec" rid="sec030">Methods</xref>). All data are reported relative to the neutral criterion, <italic>z</italic><sub>neutral</sub> = (<italic>μ</italic><sub>A</sub> + <italic>μ</italic><sub>B</sub>)/2.</p>
<fig id="pcbi.1006681.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006681.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Experimental design.</title>
<p>(A) Trial sequence in the covert-criterion task. After stimulus offset, observers reported the category by key press and received auditory feedback indicating the correctness of their response. In addition, the fixation cross was displayed in the color of the generating category. (B) Trial sequence in the overt-criterion task. Prior to stimulus onset, observers rotated a line to indicate their criterion by sliding the mouse side-to-side. When the observer clicked the mouse, a stimulus was displayed under the criterion line and auditory feedback was provided. (C) Example stimulus distributions for category A (green) and category B (red). Note that numbers on the <italic>x</italic>-axis are relative to the neutral criterion (i.e., 0 is the neutral criterion). (D) Example of random stepwise changes in probability across a block of trials. Change points occurred every 80-120 trials and are depicted above by the black arrows. Category A probabilities <italic>π</italic><sub><italic>t</italic></sub> were sampled from a discrete set, <italic>S</italic><sub><italic>π</italic></sub> = {0.2, 0.35, 0.5, 0.65, 0.8}. (E) Generative model for the task in which category probability <italic>π</italic> is updated following a sample-and-hold procedure, a category <italic>C</italic> is selected based on the category probability, a stimulus <italic>s</italic> is drawn from the category distribution and is corrupted by visual noise resulting in the noisy measurement <italic>x</italic>. Note that this diagram omits the dependency that leads to change points every 80-120 trials.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006681.g001" xlink:type="simple"/>
</fig>
<p>Prior to testing, observers were trained on the categories. Only the covert-criterion task was used for training (see Section 6 in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>). During training, category probability was equal (<italic>π</italic> = 0.5) and observers received feedback on every trial that indicated both the correctness of the response (tone) and the generating category (visual). As a measure of category learning, we compute the probability of being correct in the training block and averaged across sessions. All observers learned the categories to the expected level of accuracy (<italic>p</italic>(correct) = 0.74 ± 0.01; mean ± SEM across observers), given that the expected fraction of correct responses for an ideal observer with <italic>d</italic>′ = 1.5 and equal priors over categories is 0.77. As an additional test of category learning, immediately following training observers estimated the mean orientation of each category by rotating an ellipse. Each category mean was estimated once and no feedback was provided. There was a significant correlation between the true and estimated means for each category (category A: <italic>r</italic> = 0.82, <italic>p</italic> &lt; 0.0001; category B: <italic>r</italic> = 0.97, <italic>p</italic> &lt; 0.0001), suggesting that categories were learned. However, on average mean estimates were repelled from the category boundary (average category A error of 11.3° ± 6.3° and average category B error of −8.0° ± 2.6°; mean ± SEM across observers) suggesting a systematic repulsive bias.</p>
<p>To determine how category probability affects decision-making, during testing category A probability <italic>π</italic><sub><italic>t</italic></sub> was determined using a sample-and-hold procedure (<xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1D</xref>; category B probability was 1 − <italic>π</italic><sub><italic>t</italic></sub>). For <italic>t</italic> = 1, category A probability was randomly chosen from a set of five probabilities <italic>S</italic><sub><italic>π</italic></sub> = {0.2, 0.35, 0.5, 0.65, 0.8}. On most trials, no change occurred (Δ<sub><italic>t</italic></sub> = 0), so that <italic>π</italic><sub><italic>t</italic>+1</sub> = <italic>π</italic><sub><italic>t</italic></sub>. Every 80-120 trials there was a change point (Δ<sub><italic>t</italic></sub> = 1), with change point sampled uniformly. At each change point, category probability was randomly selected from the <italic>S</italic><sub><italic>π</italic></sub> excluding the current probability. On each trial <italic>t</italic>, a category <italic>C</italic><sub><italic>t</italic></sub> was randomly selected (with <italic>P</italic>(category A) = <italic>π</italic><sub><italic>t</italic></sub>) and a stimulus <italic>s</italic><sub><italic>t</italic></sub> was drawn from the stimulus distribution corresponding to the selected category. We assume that the observer’s internal representation of the stimulus is a noisy measurement <italic>x</italic><sub><italic>t</italic></sub> drawn from a Gaussian distribution with mean <italic>s</italic><sub><italic>t</italic></sub> and standard deviation <italic>σ</italic><sub>v</sub>, which represents visual noise (v). The generative model of the task is summarized in <xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1E</xref>.</p>
</sec>
<sec id="sec004">
<title>Bayesian models</title>
<p>To understand how decision-making behavior is affected by changes in category probability, we compared observer performance to several Bayesian models. To compute the behavior of a Bayesian observer, we developed a Bayesian change-point detection algorithm, based on Adams and MacKay [<xref ref-type="bibr" rid="pcbi.1006681.ref027">27</xref>], but which also accounts for Markov dependencies in the transition distribution after a change. Specifically, the Bayesian observer estimates the posterior distribution over the current run length (time since the last change point), and the state (category probability) before the last change point, given the data so far observed (category labels until trial <italic>t</italic>, <bold><italic>C</italic></bold><sub><italic>t</italic></sub> = (<italic>C</italic><sub>1</sub>,…,<italic>C</italic><sub><italic>t</italic></sub>)). We denote the current run length at the end of trial <italic>t</italic> by <italic>r</italic><sub><italic>t</italic></sub>, the current state by <italic>π</italic><sub><italic>t</italic></sub>, and the state before the last change point by <italic>ξ</italic><sub><italic>t</italic></sub>, where both <italic>π</italic><sub><italic>t</italic></sub>,<italic>ξ</italic><sub><italic>t</italic></sub> ∈ <italic>S</italic><sub><italic>π</italic></sub>. That is, if a change point occurs after trial <italic>t</italic> (i.e., <italic>r</italic><sub><italic>t</italic></sub> = 0), then the new category A probability will be <italic>π</italic><sub><italic>t</italic></sub> and the previous run’s category probability <italic>ξ</italic><sub><italic>t</italic></sub> = <italic>π</italic><sub><italic>t</italic>−1</sub>. If no change point occurs, both <italic>π</italic> and <italic>ξ</italic> remain unchanged. We use the notation <inline-formula id="pcbi.1006681.e001"><alternatives><graphic id="pcbi.1006681.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msubsup><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mi>t</mml:mi> <mml:mrow><mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:mi>r</mml:mi> <mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> to indicate the set of observations (category labels) associated with the run <italic>r</italic><sub><italic>t</italic></sub>, which is <bold><italic>C</italic></bold><sub><italic>t</italic>−<italic>r</italic><sub><italic>t</italic></sub>+1:<italic>t</italic></sub> for <italic>r</italic><sub><italic>t</italic></sub> &gt; 0, and ∅ for <italic>r</italic><sub><italic>t</italic></sub> = 0. The range of times with a colon, e.g., <bold><italic>C</italic></bold><sub><italic>t</italic>′:<italic>t</italic></sub>, indicates the sub-vector of <bold><italic>C</italic></bold> with elements from <italic>t</italic>′ to <italic>t</italic> included.</p>
<p>Both of our tasks provide category feedback, so that at the end of trial <italic>t</italic> the observer has been informed of <bold><italic>C</italic></bold><sub>1:<italic>t</italic></sub>. In <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref> we derive the iterative Bayesian ideal-observer model. After each trial, the model calculates a posterior distribution over possible run lengths and previous probability states, <italic>P</italic>(<italic>r</italic><sub><italic>t</italic></sub>,<italic>ξ</italic><sub><italic>t</italic></sub>|<bold><italic>C</italic></bold><sub>1:<italic>t</italic></sub>). The generative model makes it easy to calculate the conditional probability of the current state for a given run length and previous state, <italic>P</italic>(<italic>π</italic><sub><italic>t</italic></sub>|<italic>r</italic><sub><italic>t</italic></sub>,<italic>ξ</italic><sub><italic>t</italic></sub>,<bold><italic>C</italic></bold><sub>1:<italic>t</italic></sub>). These two distributions may be combined, marginalizing (summing) across the unknown run length and previous states to yield the predictive probability distribution of the current state, <italic>P</italic>(<italic>π</italic><sub><italic>t</italic></sub>|<bold><italic>C</italic></bold><sub>1:<italic>t</italic></sub>). Given this distribution over states, in both tasks the observer needs to determine the probability of each category. In particular,
<disp-formula id="pcbi.1006681.e002"><alternatives><graphic id="pcbi.1006681.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mtext>A</mml:mtext> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>[</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>]</mml:mo> <mml:mo>=</mml:mo> <mml:munder><mml:mo mathvariant="bold">∑</mml:mo> <mml:mrow><mml:msub><mml:mi>π</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>∈</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mi>π</mml:mi></mml:msub></mml:mrow></mml:munder> <mml:msub><mml:mi>π</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula></p>
<p>In the overt task, the ideal observer sets the current criterion to the optimal value <inline-formula id="pcbi.1006681.e003"><alternatives><graphic id="pcbi.1006681.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:msubsup><mml:mi>z</mml:mi> <mml:mi>t</mml:mi> <mml:mtext mathvariant="normal">opt</mml:mtext></mml:msubsup></mml:math></alternatives></inline-formula> based on the known category orientation distributions and the current estimate of category probabilities. Further, in the ideal and all subsequent models of the overt task, in addition to early sensory noise (<italic>σ</italic><sub>v</sub>) we assume the actual setting is perturbed by adjustment noise <inline-formula id="pcbi.1006681.e004"><alternatives><graphic id="pcbi.1006681.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>z</mml:mi> <mml:mi>t</mml:mi> <mml:mtext mathvariant="normal">opt</mml:mtext></mml:msubsup> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ε</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1006681.e005"><alternatives><graphic id="pcbi.1006681.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:msub><mml:mi>ε</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>∼</mml:mo> <mml:mstyle mathvariant="script"><mml:mi>N</mml:mi></mml:mstyle> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">a</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo form="postfix" stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>In the covert task, the observer views a stimulus and makes a noisy measurement <italic>x</italic><sub><italic>t</italic></sub> of its true orientation <italic>s</italic><sub><italic>t</italic></sub> with noise variance <inline-formula id="pcbi.1006681.e006"><alternatives><graphic id="pcbi.1006681.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">v</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. The prior category probability is combined with the noisy measurement to compute category A’s posterior probability <italic>P</italic>(<bold><italic>C</italic></bold><sub><italic>t</italic>+1</sub> = A|<italic>x</italic><sub><italic>t</italic>+1</sub>, <bold><italic>C</italic></bold><sub>1:<italic>t</italic></sub>). The observer responds “A” if that probability is greater than 0.5.</p>
<p>We consider the ideal-observer model (Bayes<sub>ideal</sub>) and four (suboptimal) variants thereof, which deviate from the ideal observer in terms of their beliefs about specific features of the experiment (Bayes<sub><italic>r</italic></sub>, Bayes<sub><italic>π</italic></sub>, Bayes<sub><italic>β</italic></sub>, and Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub>). Two further variants of the Bayesian model (Bayes<sub>bias</sub> and Bayes<sub><italic>r</italic>,<italic>β</italic></sub>) are described in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>. Crucially, all these models are “Bayesian” in that they compute a posterior over run length and probability state, but they differ with respect to the observer’s assumptions about the generative model. Note that these models differ from the model provided by Gallistel and colleagues [<xref ref-type="bibr" rid="pcbi.1006681.ref028">28</xref>], which was used to model a task in which participants explicitly indicated perceived probability and change points.</p>
<sec id="sec005">
<title>Bayes<sub>ideal</sub></title>
<p>The ideal Bayesian observer uses knowledge of the generative model to maximize expected gain. This model assumes knowledge of sensory noise, the category distributions, the set of potential probability states, and the run length distribution. Because observers were trained on the categories prior to completing each categorization task, assuming knowledge of the category distributions seems reasonable. Further, it is reasonable to assume knowledge of sensory noise as this is a characteristic of the observer. However, since observers were not told how often probability would change, nor were they told the set of potential probability states, observers may have had incorrect beliefs about the generative model. Thus, we developed additional Bayesian models (described below), in which observers could have potentially incorrect beliefs about different aspects of the generative model.</p>
</sec>
<sec id="sec006">
<title>Bayes<sub><italic>r</italic></sub></title>
<p>The Bayes<sub><italic>r</italic></sub> model allows for an observer to have an incorrect belief about the run length distribution. For a given discrete <italic>r</italic>, the observer believes that the run length distribution is drawn from a discrete uniform distribution, <inline-formula id="pcbi.1006681.e007"><alternatives><graphic id="pcbi.1006681.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:mo>∼</mml:mo> <mml:mtext mathvariant="normal">Unif</mml:mtext> <mml:mrow><mml:mo form="prefix" stretchy="true">[</mml:mo> <mml:mrow><mml:mo form="prefix" stretchy="true">⌊</mml:mo> <mml:mfrac><mml:mn>2</mml:mn> <mml:mn>3</mml:mn></mml:mfrac> <mml:mi>r</mml:mi> <mml:mo form="postfix" stretchy="true">⌋</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi> <mml:mo form="postfix" stretchy="true">]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. We chose this particular interval rather than a more general one, because it is simple and includes the true generative distribution. For the ideal observer, <italic>r</italic> = 120.</p>
</sec>
<sec id="sec007">
<title>Bayes<sub><italic>π</italic></sub></title>
<p>The Bayes<sub><italic>π</italic></sub> model allows for an observer to have an incorrect belief about the set of probability states. The veridical set of experimental states is five values of <italic>π</italic> ranging from 0.2 to 0.8. The Bayes<sub><italic>π</italic></sub> model observer also assumes five possible values of <italic>π</italic> evenly spaced, but ranging from <italic>π</italic><sub>min</sub> to <italic>π</italic><sub>max</sub> = 1 − <italic>π</italic><sub>min</sub>, where <italic>π</italic><sub>min</sub> is a free parameter.</p>
</sec>
<sec id="sec008">
<title>Bayes<sub><italic>β</italic></sub></title>
<p>While incorrect assumptions about parameters of the generative model result in suboptimal behavior, suboptimality can also arise from prior biases (that is, incorrect hyper-parameters). The Bayes<sub><italic>β</italic></sub> model, like the Bayes<sub>ideal</sub> model, assumes knowledge of the generative model, but also includes a hyperprior Beta(<italic>β</italic>, <italic>β</italic>) that is applied after a change point. Thus, as <italic>β</italic> increases, the posterior belief over category probabilities is biased toward equal probability. For the ideal observer, <italic>β</italic> = 1 (a uniform distribution).</p>
</sec>
<sec id="sec009">
<title>Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub></title>
<p>The ‘incorrect-belief’ Bayesian models described above vary one assumption at a time, with at most a single additional free parameter. To get a sense of model performance when multiple assumptions are varied, the Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> model allows for incorrect beliefs about the run length and probability distributions and a prior bias towards equal probability. Specifically, the Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> model observer assumes that run length is drawn from the discrete distribution [<italic>r</italic>, <italic>r</italic> + Δ<italic>r</italic>] and that there are five possible values of <italic>π</italic> evenly spaced ranging from <italic>π</italic><sub>min</sub> to <italic>π</italic><sub>max</sub>, where <italic>r</italic> ∈ [1, 200], Δ<italic>r</italic> ∈ [1, 200], <italic>π</italic><sub>min</sub> ∈ (0, 0.5), and <italic>π</italic><sub>max</sub> ∈ (0.5, 1) are all free parameters. The model also includes the hyperprior Beta(<italic>β</italic>, <italic>β</italic>), with <italic>β</italic> ∈ (0, 100], that is applied after a change point. Because of the model’s complexity, excessive flexibility, and differences in the fitting procedure (see <xref ref-type="sec" rid="sec030">Methods</xref>), we only compared it to the best-fit model as determined by a separate model-comparison analysis. For the same reasons, note that this model is not included in the following figures or parameter tables. However, the results are summarized in Fig S1 in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>.</p>
</sec>
</sec>
<sec id="sec010">
<title>Alternative models</title>
<p>In addition to the Bayesian models described above, we tested the following alternative models that do not require the observer to compute a posterior over run length and probability state. In each of the following models, assumptions vary about whether and how probability is estimated. In the Fixed Criterion (Fixed) model the observer assumes fixed probabilities. In the Exponential-Averaging (Exp), Exponential-Averaging with Prior Bias (Exp<sub>bias</sub>), and the Wilson et al. (2013) models, probability is estimated based on the recent history of categories. In the Reinforcement-Learning (RL) model, the decision criterion is updated following an error-driven learning rule with no assumptions about probability. Finally, the Behrens et al. (2007) model is an alternative Bayesian model with fewer assumptions and restrictions than the Bayesian change-point detection model described above. We also tested three additional models that are described in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>.</p>
<p>Each of the following models, except for the RL model, computes an estimate of category probability <inline-formula id="pcbi.1006681.e008"><alternatives><graphic id="pcbi.1006681.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mo>(</mml:mo><mml:msub><mml:mover><mml:mi>π</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mrow><mml:mtext mathvariant="normal">A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>) on each trial and the estimated probability of the alternative is <inline-formula id="pcbi.1006681.e009"><alternatives><graphic id="pcbi.1006681.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:msub><mml:mover><mml:mi>π</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mrow><mml:mtext mathvariant="normal">B</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msub><mml:mover><mml:mi>π</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mrow><mml:mtext mathvariant="normal">A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. On each trial, the optimal criterion <italic>z</italic><sub>opt</sub> is computed based on these estimated probabilities in the identical manner as for the Bayesian models. To make a categorization decision in the covert-criterion task, the criterion is applied to the noisy observation of the stimulus. In the overt-criterion task, the observer reports the criterion, which we again assume is corrupted by adjustment noise.</p>
<sec id="sec011">
<title>Fixed</title>
<p>While incorporating category probability into the decision process maximizes expected gain, a simpler strategy is to ignore changes in probability and fix the decision criterion throughout the block. In the fixed-criterion model, we assume equal category probability and the criterion is set to the neutral criterion:
<disp-formula id="pcbi.1006681.e010"><alternatives><graphic id="pcbi.1006681.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>z</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mtext>B</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mtext>A</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula></p>
<p>This model is equivalent to a model in which the likelihood ratio, <inline-formula id="pcbi.1006681.e011"><alternatives><graphic id="pcbi.1006681.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mfrac><mml:mrow><mml:mi>P</mml:mi> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo form="prefix" stretchy="false">|</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mtext mathvariant="normal">A</mml:mtext> <mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow> <mml:mrow><mml:mi>P</mml:mi> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo form="prefix" stretchy="false">|</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mtext mathvariant="normal">B</mml:mtext> <mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, is used to make categorization decisions rather than the posterior odds ratio in the covert-criterion task. This is a reasonable strategy for an observer who wants to make an informed decision, but is unsure about the current probability state and its rate of change.</p>
</sec>
<sec id="sec012">
<title>Exp</title>
<p>The exponential-averaging model computes smoothed estimates of category probability by taking a weighted average of previously experienced category labels, giving more weight to recently experienced labels:
<disp-formula id="pcbi.1006681.e012"><alternatives><graphic id="pcbi.1006681.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mtext>Exp</mml:mtext></mml:msub> <mml:msub><mml:mi>C</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mtext>Exp</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where <italic>α</italic><sub>Exp</sub> is the smoothing factor, 0 &lt; <italic>α</italic><sub>Exp</sub> &lt; 1, and <italic>C</italic><sub><italic>t</italic></sub> = 1 if category A is observed on trial <italic>t</italic> and <italic>C</italic><sub><italic>t</italic></sub> = 0 otherwise. The time constant of memory decay for this model is <inline-formula id="pcbi.1006681.e013"><alternatives><graphic id="pcbi.1006681.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:mi>τ</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mo>−</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mtext>log</mml:mtext> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mtext mathvariant="normal">Exp</mml:mtext></mml:msub> <mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. Mathematically this model is equivalent to a delta-rule [<xref ref-type="bibr" rid="pcbi.1006681.ref029">29</xref>] model based on an “error” that is the difference between the current category and the current probability estimate: <inline-formula id="pcbi.1006681.e014"><alternatives><graphic id="pcbi.1006681.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:msub><mml:mover><mml:mi>π</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mrow><mml:mtext mathvariant="normal">A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mover><mml:mi>π</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mrow><mml:mtext mathvariant="normal">A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mtext mathvariant="normal">Exp</mml:mtext></mml:msub> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>−</mml:mo> <mml:msub><mml:mover><mml:mi>π</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mrow><mml:mtext mathvariant="normal">A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. The criterion <italic>z</italic> is then set to the optimal value based on this category-probability estimate.</p>
</sec>
<sec id="sec013">
<title>Exp<sub>bias</sub></title>
<p>The Exp<sub>bias</sub> model is identical to the Exp model, while also incorporating a common finding in the literature [<xref ref-type="bibr" rid="pcbi.1006681.ref002">2</xref>] known as conservatism (i.e., observers are biased towards the neutral criterion). On each trial an estimate of probability is computed as described in <xref ref-type="disp-formula" rid="pcbi.1006681.e012">Eq (3)</xref>, and averaged with a prior probability of 0.5:
<disp-formula id="pcbi.1006681.e015"><alternatives><graphic id="pcbi.1006681.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>w</mml:mi> <mml:msub><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
where <italic>w</italic> is the weight given to the probability estimate <inline-formula id="pcbi.1006681.e016"><alternatives><graphic id="pcbi.1006681.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:msub><mml:mover><mml:mi>π</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mrow><mml:mtext mathvariant="normal">A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and (1 − <italic>w</italic>) is the weight given to <italic>π</italic><sub>A</sub> = 0.5. The criterion <italic>z</italic> is also set to the optimal value based on this category-probability estimate.</p>
</sec>
<sec id="sec014">
<title>Wilson et al. (2013)</title>
<p>Due to the complexity of the full Bayesian change-point detection model, Wilson et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref030">30</xref>] developed an approximation to the full model using a mixture of delta rules. In their reduced model, the full run-length distribution is approximated by maintaining a subset of all possible run lengths. These are referred to as nodes {<italic>l</italic><sub>1</sub>,…,<italic>l</italic><sub><italic>i</italic></sub>}. On each trial, an estimate of probability is computed for each node,
<disp-formula id="pcbi.1006681.e017"><alternatives><graphic id="pcbi.1006681.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>l</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:msubsup><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>l</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msubsup></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:msub><mml:mi>l</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msubsup> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ν</mml:mi> <mml:mtext>p</mml:mtext></mml:msub></mml:mrow></mml:mfrac> <mml:mo>(</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:msub><mml:mi>l</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msubsup> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
where <italic>ν</italic><sub>p</sub> is a model parameter that represents the strength of the observer’s prior towards equal category probability (pseudocounts of a Beta prior; larger <italic>ν</italic><sub>p</sub> corresponds to stronger conservatism) and <italic>C</italic><sub><italic>t</italic></sub> is the category label. The learning rate for each node is thus <inline-formula id="pcbi.1006681.e018"><alternatives><graphic id="pcbi.1006681.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:msub><mml:mi>α</mml:mi> <mml:mrow><mml:mtext mathvariant="normal">Wilson</mml:mtext> <mml:mo>,</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msub><mml:mi>l</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ν</mml:mi> <mml:mtext mathvariant="normal">p</mml:mtext></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>. For a single-node model, this is identical to the Exp model described above <xref ref-type="disp-formula" rid="pcbi.1006681.e012">Eq (3)</xref>. To obtain an overall estimate of probability in a multiple-node model, estimates (<xref ref-type="disp-formula" rid="pcbi.1006681.e017">Eq (5)</xref>) are combined by taking a weighted average. The weights, <italic>p</italic>(<italic>l</italic><sub><italic>i</italic></sub>|<italic>C</italic><sub>1:<italic>t</italic></sub>), are updated on every trial. The update is dependent on an approximation to the change-point prior, which in turn depends on the hazard rate <italic>h</italic> (for details see Wilson et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref030">30</xref>], Eqs 25-31, along with the later correction [<xref ref-type="bibr" rid="pcbi.1006681.ref031">31</xref>]). In other words, when the probability of a change is high, more weight is given to <italic>l</italic><sub>1</sub>, which results in a greater change in the overall probability estimate. But when the probability of a change is low, more weight is given to nodes greater than <italic>l</italic><sub>1</sub> and the probability estimate is more stable. For a three-node model probability is estimated as
<disp-formula id="pcbi.1006681.e019"><alternatives><graphic id="pcbi.1006681.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e019" xlink:type="simple"/><mml:math display="block" id="M19"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>l</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:msubsup> <mml:mo>+</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>l</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:msubsup> <mml:mo>+</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>l</mml:mi> <mml:mn>3</mml:mn></mml:msub></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula></p>
<p>For the purpose of the current experiment, we used a three-node model in which the first node was fixed (<italic>l</italic><sub>1</sub> = 1) and <italic>l</italic><sub>2</sub> and <italic>l</italic><sub>3</sub> were allowed to vary. In addition, the prior strength parameter, <italic>ν</italic><sub>p</sub>, which modulates the learning rate, was also free. By allowing <italic>ν</italic><sub>p</sub> to vary, this model is equivalent to the three-node model described by Wilson and colleagues [<xref ref-type="bibr" rid="pcbi.1006681.ref030">30</xref>] in which all nodes were free and <italic>ν</italic><sub>p</sub> = 2 was fixed. The hazard rate was set to 0.01, corresponding to an expected block length of 100 trials (the experimental mean), and we assumed a change occurred at <italic>t</italic> = 1, so that all the weight was given to <italic>l</italic><sub>1</sub>. We also tested an alternative model with a fixed value of <italic>ν</italic><sub>p</sub> = 2, but it resulted in a worse fit.</p>
</sec>
<sec id="sec015">
<title>RL</title>
<p>While the models described above make assumptions about how probability is estimated, it is also possible that observers simply update the decision criterion without estimating the current probability state. A model-free reinforcement-learning approach assumes the observer does not use knowledge of the environmental structure. Instead, the decision criterion, rather than an estimate of category probability, is updated. The observer updates the internal criterion (<italic>z</italic>) on each trial according to the following delta rule:
<disp-formula id="pcbi.1006681.e020"><alternatives><graphic id="pcbi.1006681.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>correct</mml:mtext></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>α</mml:mi> <mml:mtext>RL</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>incorrect</mml:mtext> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula></p>
<p>Thus, the criterion is updated when negative feedback is received by taking a small step in the direction of the difference between the noisy observation (<italic>x</italic><sub><italic>t</italic></sub>) and current criterion (<italic>z</italic><sub><italic>t</italic></sub>), where the step size is scaled by the learning rate <italic>α</italic><sub>RL</sub>. Nothing is changed after a correct response. Assuming effective training, we initialize the RL model by setting <inline-formula id="pcbi.1006681.e021"><alternatives><graphic id="pcbi.1006681.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:msub><mml:mi>z</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mtext mathvariant="normal">B</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mtext mathvariant="normal">A</mml:mtext></mml:msub> <mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
</sec>
<sec id="sec016">
<title>Behrens et al. (2007)</title>
<p>Behrens and colleagues [<xref ref-type="bibr" rid="pcbi.1006681.ref024">24</xref>] developed a model that uses Bayesian learning to update one’s belief about the statistics of the environment to use on the next trial. Importantly, a Behrens et al. (2007) observer updates beliefs about the probability of category A (<italic>π</italic>), volatility (<italic>v</italic>) and the volatility’s rate of change (<italic>k</italic>) without having to store the entire history of outcomes (<italic>C</italic><sub>1:<italic>t</italic></sub>) and reward statistics. The posterior probability over <italic>π</italic>, <italic>v</italic>, and <italic>k</italic>, or current belief about the environmental statistics, is computed as follows:
<disp-formula id="pcbi.1006681.e022"><alternatives><graphic id="pcbi.1006681.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e022" xlink:type="simple"/><mml:math display="block" id="M22"><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>×</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="right"><mml:mtd columnalign="right"><mml:mspace width="7em"/><mml:mrow><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>∫</mml:mo><mml:mo stretchy="false">[</mml:mo></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true"><mml:mrow><mml:mo>∫</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>v</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>π</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
where <italic>p</italic>(<italic>π</italic><sub><italic>t</italic>+1</sub>|<italic>π</italic><sub><italic>t</italic></sub>, <italic>v</italic><sub><italic>t</italic>+1</sub>) ∼ <italic>β</italic>(<italic>π</italic><sub><italic>t</italic></sub>, exp(<italic>v</italic><sub><italic>t</italic>+1</sub>)) is the probability transition function, <inline-formula id="pcbi.1006681.e023"><alternatives><graphic id="pcbi.1006681.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mrow><mml:mi>p</mml:mi> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo form="prefix" stretchy="false">|</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>k</mml:mi> <mml:mo form="postfix" stretchy="false">)</mml:mo> <mml:mo>∼</mml:mo> <mml:mstyle mathvariant="script"><mml:mi>N</mml:mi></mml:mstyle> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>exp</mml:mtext> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:mi>k</mml:mi> <mml:mo form="postfix" stretchy="false">)</mml:mo> <mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the volatility transition function, and <italic>p</italic>(<italic>C</italic><sub><italic>t</italic>+1</sub>|<italic>π</italic><sub><italic>t</italic>+1</sub>) is the likelihood of the most recently observed category. The likelihood is equal to <italic>π</italic><sub><italic>t</italic>+1</sub> when <italic>C</italic><sub><italic>t</italic>+1</sub> = 1 and 1 − <italic>π</italic><sub><italic>t</italic>+1</sub> when <italic>C</italic><sub><italic>t</italic>+1</sub> = 0. Integration was done numerically over a five-dimensional grid (<italic>π</italic><sub><italic>t</italic></sub>, <italic>v</italic><sub><italic>t</italic></sub>, <italic>k</italic>, <italic>π</italic><sub><italic>t</italic>+1</sub>, <italic>v</italic><sub><italic>t</italic>+1</sub>). We assumed the observer adopted non-informative uniform priors over <italic>π</italic>, <italic>v</italic>, and <italic>k</italic>. Thus, each dimension was split into 30 equally spaced bins with <italic>v</italic> and <italic>k</italic> spaced evenly in log space (as per positive parameters of unknown scale). To obtain an estimate of the probability of category A, we marginalized over <italic>v</italic><sub><italic>t</italic>+1</sub> and <italic>k</italic> and computed the mean of the probability distribution,
<disp-formula id="pcbi.1006681.e024"><alternatives><graphic id="pcbi.1006681.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>π</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mtext>A</mml:mtext><mml:mo>,</mml:mo><mml:mtext>t</mml:mtext><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>π</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi>π</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula></p>
<p>Other than sensory or adjustment noise, this model has no additional free parameters. Assuming perfect category knowledge, the criterion <italic>z</italic> is set to the optimal value based on this category-probability estimate.</p>
</sec>
<sec id="sec017">
<title>Behrens et al. (2007) with bias</title>
<p>For the Behrens et al. (2007) model with a bias towards equal probability, category probability was estimated as in <xref ref-type="disp-formula" rid="pcbi.1006681.e024">Eq 9</xref> and a weighted average between <italic>π</italic><sub>A</sub> = 0.5 and the model estimate was computed as in <xref ref-type="disp-formula" rid="pcbi.1006681.e015">Eq 4</xref>. This model has one additional free parameter, <italic>w</italic>, which is the weight given to the probability estimate <inline-formula id="pcbi.1006681.e025"><alternatives><graphic id="pcbi.1006681.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:msub><mml:mover><mml:mi>π</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mrow><mml:mtext mathvariant="normal">A</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> as in the Exp<sub>bias</sub> model. The criterion <italic>z</italic> is then set to the optimal value based on the weighted category-probability estimate.</p>
</sec>
</sec>
<sec id="sec018">
<title>Raw data</title>
<p>
<xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2</xref> shows raw data for a single observer in the covert (<xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2A</xref>) and overt (<xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2C</xref>) tasks. For visualization in the covert task, the ‘excess’ number of A responses is plotted as a function of trial (gray line in <xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2A</xref>). To compute the ‘excess’ number of A responses, we subtracted <inline-formula id="pcbi.1006681.e026"><alternatives><graphic id="pcbi.1006681.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mfrac><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula> from the cumulative number of A responses. Thus, ‘excess’ A responses are constant for an observer who reported A and B equally often, increase when A is reported more, and decrease when A is reported less. To get a sense of how well the observer performed in the covert task, the number of ‘excess’ A trials (based on the actual category on each trial rather than the observer’s response) is shown in black (<xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2A</xref>, top). For reference, <italic>π</italic><sub>A</sub> is shown as a function of trial (<xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2A</xref>, bottom). From visual inspection, the observer reported A more often when <italic>π</italic><sub>A,<italic>t</italic></sub> &gt; 0.5 and B more often when <italic>π</italic><sub>A,<italic>t</italic></sub> &lt; 0.5. Results for all observers in the covert task can be found in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref> (gray line in Figs S6A-S17A).</p>
<fig id="pcbi.1006681.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006681.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Behavioral data and model fits.</title>
<p>(A) Behavioral data from a representative observer (CWG) in the covert-criterion task. Top: The number of ‘excess’ A responses (i.e., the cumulative number of A responses minus <inline-formula id="pcbi.1006681.e027"><alternatives><graphic id="pcbi.1006681.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mfrac><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>) across trials. Gray line: Observer data. Black line: The true number of ‘excess’ A’s. Bottom: The corresponding category probability. (B) Model fits (colored lines) for observer CWG in the covert-criterion task. Shaded regions: 68% CI for model fits. Gray: Observer data. (C) Behavioral data from a representative observer (GK) in the overt-criterion task. Top: The orientation of the criterion line relative to the neutral criterion as a function of trial number. Gray circles: raw settings. Gray line: running average over a 5-trial moving window. Black line: ideal criterion for an observer with perfect knowledge of the experimental parameters. Bottom: Category probability across trials. (D) Models fits (colored lines) for observer GK in the overt-criterion task. A running average was computed over a 5-trial window for visualization. Shaded regions: 68% CI on model fits. These are generally smaller than the model-fit line. Gray line: the running average computed from the observer’s data.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006681.g002" xlink:type="simple"/>
</fig>
<p>In the overt task, the orientation of the observer’s criterion setting, relative to the neutral criterion, is plotted as a function of trial (gray circles). For visualization, a running average was computed over a five-trial moving window (gray line). Here (<xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2C</xref>, top), the black line represents the criterion on each trial, given perfect knowledge of the categories, sensory uncertainty, and category probability. While this is impossible for an observer to attain, we can see that the observer’s criterion follows the general trend. This suggests that observers update their criterion appropriately in response to changes in probability. That is, the criterion is set counter-clockwise from the neutral criterion when <italic>π</italic><sub>A,<italic>t</italic></sub> &gt; 0.5, and clockwise of neutral when <italic>π</italic><sub>A,<italic>t</italic></sub> &lt; 0.5. <xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2C</xref> (bottom) shows <italic>π</italic><sub>A</sub> as a function of trial. Results for all observers in the overt task can be found in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref> (gray line in Figs S6B-S17B).</p>
</sec>
<sec id="sec019">
<title>Modeling results</title>
<sec id="sec020">
<title>Model predictions</title>
<p>A qualitative comparison of the behavioral data to the ground truth suggests that observers updated their criterion in response to changes in probability. However, it does not tell us how. To explore the mechanism underlying these changes, we compared the observers’ data to multiple models. For each task and model, the mean model response for a representative subject is plotted in <xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2B</xref> (covert task) and <xref ref-type="fig" rid="pcbi.1006681.g002">Fig 2D</xref> (overt task). Shaded regions indicate 68% CIs computed from the posterior over model parameters. Specifically, we sampled parameters from the posterior over model parameters and computed the model response for the given set of parameters. We then computed the standard deviation across model responses for a large sample (see Model visualization). Occasionally, shaded regions computed on fits are narrower than the data line. Qualitatively, most models captured observers’ changing criteria, with the fixed model being much worse. Differences across models are especially pronounced in the overt task. Specifically, we see that the Exp, Exp<sub>bias</sub>, Wilson et al. (2013), RL, and Behrens et al. (2007) models capture changes in criterion that occur between change points that the ideal Bayesian change-point model generally fails to capture. The MAP model fits for each observer, model, and task can be found in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref> (colored lines in Figs S6-S17).</p>
</sec>
<sec id="sec021">
<title>Model comparison</title>
<p>We quantitatively compared models by computing the log marginal likelihood (LML) for each subject, model, and task. The marginal likelihood is the probability of the data given the model, marginalized over model parameters (see <xref ref-type="sec" rid="sec030">Methods</xref>). Here, we report differences in log marginal likelihood (ΔLML, also known as log Bayes factor) from the best model, so that larger ΔLML correspond to worse models. We compare models both by looking at average performance across subjects (a fixed-effects analysis), and also via a Bayesian Model Selection approach (BMS; [<xref ref-type="bibr" rid="pcbi.1006681.ref032">32</xref>]) in which subjects are treated as random variables. With BMS, we estimate for each model its posterior frequency <italic>f</italic> in the population and its protected exceedance probability <italic>ϕ</italic>, which is the probability that a given model is the most frequent model in the population, above and beyond chance [<xref ref-type="bibr" rid="pcbi.1006681.ref033">33</xref>].</p>
<p>Model comparison (<xref ref-type="fig" rid="pcbi.1006681.g003">Fig 3</xref>) favored the Exp<sub>bias</sub> model, which outperformed the second best model Bayes<sub><italic>r</italic></sub> (covert task: ΔLML = 9.27 ± 2.86; overt task: ΔLML = 8.96 ± 4.01; mean and SEM across observers) in the two tasks (covert task: <italic>t</italic>(10) = 3.99, <italic>p</italic> = 0.003; overt task: <italic>t</italic>(10) = 2.37, <italic>p</italic> = 0.04). Similarly, Bayesian model comparison performed at the group level also favored the Exp<sub>bias</sub> model (covert task: <italic>f</italic> = 0.42 and <italic>ϕ</italic> = 0.96; overt task: <italic>f</italic> = 0.34 and <italic>ϕ</italic> = 0.86). These results suggest that observers estimate probability by taking a weighted average of recently experienced categories with a bias towards <italic>π</italic> = 0.5.</p>
<fig id="pcbi.1006681.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006681.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Model comparison.</title>
<p>(A) Average log marginal likelihood (LML) scores relative to the best-fitting model, Exp<sub>bias</sub> (top: covert task; bottom: overt task). Lower scores indicate a better fit. Error bars: 95% CI (bootstrapped). (B) Bayesian model selection at the group level. The protected exceedance probability (<italic>ϕ</italic>) is plotted for each model. Models are stacked in order of decreasing probability.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006681.g003" xlink:type="simple"/>
</fig>
<p>To evaluate the performance of the more complex Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> model, we computed both the Bayesian Information Criterion (BIC), obtained via maximum-likelihood estimation, and an approximate expected lower bound (ELBO) of the log marginal likelihood, obtained via Variational Bayesian Monte Carlo [<xref ref-type="bibr" rid="pcbi.1006681.ref034">34</xref>], a recent variational inference technique (see <xref ref-type="sec" rid="sec030">Methods</xref> for details). For a fair comparison, we also computed the same metrics for the best-fitting model from the analysis above (Exp<sub>bias</sub>), using the same fitting procedures. In this analysis, negative ΔBIC and positive ΔELBO correspond to evidence in favor of the Exp<sub>bias</sub> model. For the covert task, the two models were indistinguishable in terms of both BIC (ΔBIC = −2.75 ± 6.07; <italic>t</italic>(10) = −0.45, <italic>p</italic> = 0.66) and ELBO (ΔELBO = 0.93 ± 2.81; <italic>t</italic>(10) = 0.33, <italic>p</italic> = 0.75). The same finding held for the overt task, in that models performed comparably in terms of both BIC (ΔBIC = −2.14 ± 10.58; <italic>t</italic>(10) = −0.20, <italic>p</italic> = 0.84) and ELBO (ΔELBO = 1.54 ± 4.89; <italic>t</italic>(10) = 0.32, <italic>p</italic> = 0.76). In short, according to both metrics the Exp<sub>bias</sub> model describes the data at least as well as the much more complex Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> model. The model fits and results of this comparison can be found in Fig S1 in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>.</p>
<p>
<xref ref-type="fig" rid="pcbi.1006681.g004">Fig 4A</xref> shows the number of observers that were best fit by each model for each task. To compare LML scores across tasks, and for the purpose of this analysis only, we standardized model scores for each observer and task. Standardized LML scores in the overt task are plotted as a function of standardized LML scores in the covert task in <xref ref-type="fig" rid="pcbi.1006681.g004">Fig 4B</xref>. We found a significant positive correlation, <italic>r</italic> = 0.60, <italic>p</italic> &lt; 0.01, indicating that models with higher LML scores in the covert task were also higher in the overt task. This result suggests that strategy was fairly consistent across tasks at the group level. In addition, there was more variance in model scores for worse-fitting models.</p>
<fig id="pcbi.1006681.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006681.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Modeling results for individual observers.</title>
<p>(A) Model frequency. The number of observers best fit by each model plotted for each task. Models are stacked in order of decreasing frequency. (B) Comparison of LML scores across tasks. LML scores were standardized for each observer and task. Standardized LML scores in the overt task are plotted as a function of standardized LML scores in the covert task (colored data points). Black dashed line: identity line.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006681.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec022">
<title>Model parameters</title>
<p>We examine here the parameter estimates of the Exp<sub>bias</sub> model, recalling that the two model parameters <italic>α</italic><sub>Exp</sub> and <italic>w</italic> represent, respectively, the exponential smoothing factor and the degree to which observers exhibit conservatism. The <italic>maximum a posteriori</italic> (MAP) parameter estimates are plotted in <xref ref-type="fig" rid="pcbi.1006681.g005">Fig 5</xref>. Converting the smoothing factor to a time constant over trials, we found that the time constant in both tasks was well below the true rate of change (covert: <italic>τ</italic> = [4.24, 7.18]; overt: <italic>τ</italic> = [3.48, 4.75]; <italic>τ</italic><sub>true</sub> = 100 trials on average). We conducted paired-sample <italic>t</italic>-tests to compare the raw parameter estimates in the covert and overt tasks. We found a significant difference in <italic>w</italic> (<italic>t</italic>(10) = −2.55, <italic>p</italic> = 0.03), suggesting that observers were more conservative in the covert than the overt task. No significant difference was found for <italic>α</italic><sub>Exp</sub> (<italic>t</italic>(10) = −0.98, <italic>p</italic> = 0.35).</p>
<fig id="pcbi.1006681.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006681.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Parameter estimates for the Exp<sub>bias</sub> model.</title>
<p>(A) Mean <italic>α</italic><sub>exp</sub> (top) and <italic>w</italic> (bottom) MAP values across observers. The * denotes significance at the <italic>p</italic> &lt; 0.05 level. Error bars: ±SEM. (B) Individual <italic>α</italic><sub>exp</sub> (top) and <italic>w</italic> (bottom) MAP values from fits in the overt task as a function of MAP values from fits in the covert task. Black dashed lines: identity line.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006681.g005" xlink:type="simple"/>
</fig>
<p>To investigate whether there was bias in the parameter-estimation procedure when fitting the Exp<sub>bias</sub> model, we also conducted a parameter-recovery analysis. Most parameters could be recovered correctly, except for adjustment variability (<italic>σ</italic><sub>a</sub>) in the overt task, which we found to be overestimated on average (see Section 4 in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref> for details). Note that this bias in estimating <italic>σ</italic><sub>a</sub> in the overt task does not affect our model comparison, which is based on LMLs and not on point estimates.</p>
<p>While we might expect performance to be similar across tasks and observers (i.e., a correlation between the parameter fits in each task), no significant correlations were found (<italic>α</italic><sub>Exp</sub>: <italic>r</italic> = −0.14, <italic>p</italic> = 0.67; <italic>w</italic>: <italic>r</italic> = 0.16, <italic>p</italic> = 0.64). Parameter estimates for all models, except the Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> model, are shown in Tables <xref ref-type="table" rid="pcbi.1006681.t001">1</xref> and <xref ref-type="table" rid="pcbi.1006681.t002">2</xref>.</p>
<table-wrap id="pcbi.1006681.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006681.t001</object-id>
<label>Table 1</label>
<caption>
<title>Maximum a posteriori parameter estimates ±S.E. in the covert-criterion task.</title>
</caption>
<alternatives>
<graphic id="pcbi.1006681.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006681.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center"><italic>σ</italic><sub>v</sub></th>
<th align="center"><italic>r</italic></th>
<th align="center"><italic>π</italic></th>
<th align="center"><italic>β</italic></th>
<th align="center"><italic>α</italic></th>
<th align="center"><italic>w</italic></th>
<th align="center"><italic>l</italic><sub>2</sub></th>
<th align="center"><italic>l</italic><sub>3</sub></th>
<th align="center"><italic>ν</italic><sub>p</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Bayes<sub>ideal</sub></td>
<td align="center">9.7 ± 0.6</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Bayes<sub><italic>r</italic></sub></td>
<td align="center">9.9 ± 0.8</td>
<td align="center">51.5 ± 11.8</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Bayes<sub><italic>π</italic></sub></td>
<td align="center">10.5 ± 0.8</td>
<td align="center">-</td>
<td align="center">0.32 ± 0.02</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Bayes<sub><italic>β</italic></sub></td>
<td align="center">10.2 ± 0.7</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">18.4 ± 8.2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Fixed</td>
<td align="center">10.9 ± 0.8</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Exp</td>
<td align="center">9.4 ± 0.7</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">0.04 ± 0.01</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Exp<sub>bias</sub></td>
<td align="center">10.0 ± 0.8</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">0.17 ± 0.04</td>
<td align="center">0.58 ± 0.05</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Wilson et al. (2013)</td>
<td align="center">9.4 ± 0.7</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">12.2 ± 2.8</td>
<td align="center">118.5 ± 23.3</td>
<td align="center">43.3 ± 14.4</td>
</tr>
<tr>
<td align="left">RL</td>
<td align="center">9.2 ± 0.7</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">0.26 ± 0.03</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Behrens et al. (2007)</td>
<td align="center">8.5 ± 0.3</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Behrens et al. (2007) + bias</td>
<td align="center">10.4 ± 0.7</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">0.31 ± 0.04</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<table-wrap id="pcbi.1006681.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006681.t002</object-id>
<label>Table 2</label>
<caption>
<title>Maximum a posteriori parameter estimates ±S.E. in the overt-criterion task.</title>
</caption>
<alternatives>
<graphic id="pcbi.1006681.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006681.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Model</th>
<th align="center"><italic>σ</italic><sub>a</sub></th>
<th align="center"><italic>r</italic></th>
<th align="center"><italic>π</italic></th>
<th align="center"><italic>β</italic></th>
<th align="center"><italic>α</italic></th>
<th align="center"><italic>w</italic></th>
<th align="center"><italic>l</italic><sub>2</sub></th>
<th align="center"><italic>l</italic><sub>3</sub></th>
<th align="center"><italic>ν</italic><sub>p</sub></th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Bayes<sub>ideal</sub></td>
<td align="center">17.2 ± 1.1</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Bayes<sub><italic>r</italic></sub></td>
<td align="center">16.4 ± 1.1</td>
<td align="center">70 ± 15</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Bayes<sub><italic>π</italic></sub></td>
<td align="center">16.7 ± 1.1</td>
<td align="center">-</td>
<td align="center">0.17 ± 0.03</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Bayes<sub><italic>β</italic></sub></td>
<td align="center">17.0 ± 1.1</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">13.2 ± 8.2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Fixed</td>
<td align="center">19.4 ± 1.1</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Exp</td>
<td align="center">16.7 ± 1.1</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">0.09 ± 0.02</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Exp<sub>bias</sub></td>
<td align="center">16.0 ± 1.0</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">0.22 ± 0.03</td>
<td align="center">0.74 ± 0.06</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Wilson et al. (2013)</td>
<td align="center">16.4 ± 1.1</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">10.8 ± 2.0</td>
<td align="center">46.4 ± 18.4</td>
<td align="center">9.2 ± 5.1</td>
</tr>
<tr>
<td align="left">RL</td>
<td align="center">18.1 ± 1.2</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">0.21 ± 0.03</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Behrens et al. (2007)</td>
<td align="center">18.6 ± 1.0</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
<tr>
<td align="left">Behrens et al. (2007) + bias</td>
<td align="center">17.4 ± 1.0</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">0.66 ± 0.06</td>
<td align="center">-</td>
<td align="center">-</td>
<td align="center">-</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>As the Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> contained a number of parameters that were unique to the model, parameter estimates for this model were not included in the tables below (covert: <italic>σ</italic><sub>v</sub> = 9.6 ± 0.7, <italic>r</italic> = 56.9 ± 19.1, Δ<italic>r</italic> = 37.0 ± 14.8, <italic>π</italic> = .15 ± .04, Δ<italic>π</italic> = .35 ± .04, and <italic>β</italic> = 1.68 ± .6; overt: <italic>σ</italic><sub>a</sub> = 15.5 ± 1.1, <italic>r</italic> = 32.3 ± 10.2, Δ<italic>r</italic> = 30.7 ± 9.5, <italic>π</italic> = .13 ± .04, Δ<italic>π</italic> = .42 ± .03, and <italic>β</italic> = 0.42 ± .2).</p>
</sec>
</sec>
</sec>
<sec id="sec023" sec-type="conclusions">
<title>Discussion</title>
<p>Although we know that people update decision criteria in response to explicit changes in prior probability, the effects of implicit changes in prior probability on decision-making behavior are less well known. In the present study, we used model comparison to investigate the mechanisms underlying decision-making behavior in an orientation-categorization task as prior probability changed. We tested a set of models that varied in both computational and memory demands. Models were tested on data from both a covert- and overt-criterion task. A comprehensive approach, consisting of both qualitative and quantitative analysis, was performed to determine the best fitting model. We found that observers updated their decision criterion following changes in probability. Additionally, we observed systematic changes in the decision criterion during periods of stability, which was clearly evident in the overt-criterion data. While most models fit the data reasonably well qualitatively, model comparison slightly favored an exponential-averaging model with a bias towards equal probability, which was indistinguishable from a flexible variant of the Bayesian change-point detection model with incorrect beliefs and a bias towards equal probability. We can thus interpret the Exp<sub>bias</sub> model as a simpler explanation, in which observers update the decision criterion by combining on-line estimation of probability with an equal-probability prior. Ultimately, our results help explain decision-making behavior in situations in which people need to assess the probability of an outcome based on previous experience.</p>
<sec id="sec024">
<title>Criterion updates in response to implicit changes in category probability</title>
<p>To determine the influence of prior probability on decision-making behavior, we examined changes in the decision criterion. First, we found that no participant was best fit by a fixed-criterion model. This finding suggests that observers update decision criteria in response to implicit changes in probability. This result is consistent with previous studies in which prior probability was explicit [<xref ref-type="bibr" rid="pcbi.1006681.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref009">9</xref>]. Further, this finding complements recent studies suggesting that individuals can learn and adapt to statistical regularities in changing environments [<xref ref-type="bibr" rid="pcbi.1006681.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref036">36</xref>]. Although this finding suggests that observers dynamically adjust decision criteria in response to changes in prior probability, it does not tell us how they do this (e.g., do observers compute on-line estimates of probability?). To uncover the mechanisms underlying changes in decision-making behavior, we compared multiple models ranging from the full Bayesian change-point detection model to a model-free reinforcement-learning (RL) model.</p>
</sec>
<sec id="sec025">
<title>Systematic criterion fluctuations</title>
<p>How is the decision criterion set? Qualitatively, most models appear to fit the data reasonably well in the covert task. However, when we look at data from the overt task, while the Bayesian change-point detection models captured the overall trend, some variants failed to capture local fluctuations in the decision criterion observed during periods of stability (i.e., time intervals between change points). In other words, the criterion predicted by these models stabilized whereas the observers’ behavior did not. This was less true when the Bayesian change-point detection model was allowed to vary more freely. In contrast, the exponential-averaging models continually update the observer’s estimate of probability based on recently experienced categories. It can be difficult to discriminate a hierarchical model (e.g., the Bayesian change-point detection models) from flat models (e.g., our exponential models). For example, in a similar paradigm, Heilbron and Meyniel [<xref ref-type="bibr" rid="pcbi.1006681.ref037">37</xref>] found that predictions of change points could be similar for hierarchical and flat models. The addition of confidence judgments allowed them to discriminate the two model forms more readily.</p>
<p>How quickly observers updated this estimate is determined in the model by the decay-rate parameter. From our model fits, we found that observers had an average decay rate that was substantially smaller than the true run length distribution (on average 4.5 vs. 100 trials, respectively), leading to frequent, systematic fluctuations in decision criteria. Although we cannot directly observe these fluctuations in the covert task, because the estimated decay rate was not significantly different across tasks we can assume the fluctuations occurred in a similar manner. Like the exponential models, the RL model was also able to capture local fluctuations in the decision criterion. However, the amplitude of the changes in criterion predicted by the RL model was generally too low compared to the data. This discrepancy was especially clear in the overt task; no participant was best fit by the RL model. As a more fair comparison to the exponential models, we also fit the Bayesian model developed by Behrens and colleagues [<xref ref-type="bibr" rid="pcbi.1006681.ref024">24</xref>] with and without a bias towards equal probability. These models are more fair in that they do not require specifying a run-length distribution and allowed us to increase the number of possible probability states. While this allowed us to capture local fluctuations, model comparison favored the Exp<sub>bias</sub> model. These results have two important implications. (1) It is important to test alternatives to Bayesian models: observers’ behavior might be explained without requiring an internal representation of probability. (2) Using multiple tasks together with rigorous model comparison can provide additional insight into behavior (see also [<xref ref-type="bibr" rid="pcbi.1006681.ref038">38</xref>]). Here, the fluctuations in decision criteria between change points led to suboptimal behavior. Overall, our findings suggest that suboptimality arose from an incorrect, possibly heuristic inference process, that goes beyond mere sensory noise [<xref ref-type="bibr" rid="pcbi.1006681.ref039">39</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref041">41</xref>].</p>
</sec>
<sec id="sec026">
<title>A dual mechanism for criterion updating</title>
<p>While the Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> and Exp<sub>bias</sub> models fit the data equally well, the Exp<sub>bias</sub> model provides a simpler explanation—considering that our experiment did not necessarily require subjects to build a hierarchical model of the task (see [<xref ref-type="bibr" rid="pcbi.1006681.ref037">37</xref>]). This suggests that observers compute on-line estimates of category probability based on recent experience. Further, the bias component of the model suggests that observers are conservative, as reflected in a long-term prior that categories are equally likely. The degree to which observers weight this prior varied across individuals and tasks. Taken together, these results suggest a dual mechanism for learning and incorporating prior probability into decisions. That is, there are (at least) two components to decision making that are acquired and updated at very different timescales.</p>
<p>Multiple-mechanism models have been used to describe behavior in decision-making [<xref ref-type="bibr" rid="pcbi.1006681.ref030">30</xref>] and motor behavior [<xref ref-type="bibr" rid="pcbi.1006681.ref042">42</xref>]. A model that combines delta rules predicts motor behavior better than either delta rule alone [<xref ref-type="bibr" rid="pcbi.1006681.ref042">42</xref>]. Using a combination of delta rules [<xref ref-type="bibr" rid="pcbi.1006681.ref030">30</xref>], we were able to capture the local fluctuations in criterion that the ideal Bayesian model missed. However, we found that a constant weight on <italic>π</italic> = 0.5 fit better than the multiple-node model described by Wilson and colleagues [<xref ref-type="bibr" rid="pcbi.1006681.ref030">30</xref>]. Temporal differences between their task and ours might explain some of the differences we observed, as changes occurred much more slowly in our experiment. Additionally, while fitting Wilson et al.’s model we set the hazard rate to 0.01 (the average rate of change), but observers had to learn this value throughout the experiment and may have had incorrect assumptions about the rate of change [<xref ref-type="bibr" rid="pcbi.1006681.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref022">22</xref>].</p>
</sec>
<sec id="sec027">
<title>Explanations of conservatism</title>
<p>Conservatism was an important feature in our models, as it improved model fits each time it was incorporated. While we observed conservatism in both the covert- and overt-criterion tasks, we found that, on average, observers were significantly more conservative in the covert task. To understand why conservatism differs across tasks, we need to understand the differences between the tasks. While the generative model was identical across tasks, the observer’s response differed. In the covert task, observers chose between two alternatives. In the overt task, observers selected a decision criterion. This is an important difference because it allows us to potentially rule out previous explanations of conservatism, such as the use of subjective probability [<xref ref-type="bibr" rid="pcbi.1006681.ref004">4</xref>], misestimation of the relative frequency of events [<xref ref-type="bibr" rid="pcbi.1006681.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref044">44</xref>], and incorrect assumptions about the sensory distributions [<xref ref-type="bibr" rid="pcbi.1006681.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref046">46</xref>]; these explanations predict similar levels of conservatism across tasks. On the other hand, conservatism may be due to the use of suboptimal decision rules. Probability matching is a strategy in which participants select alternatives proportional to their probability, and has been used to explain suboptimal behavior in forced-choice tasks in which observers choose between two or more alternatives [<xref ref-type="bibr" rid="pcbi.1006681.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref047">47</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref050">50</xref>]. Thus, the higher levels of conservatism in the covert task may have been due to the use of a suboptimal decision rule like probability matching, which would effectively smooth the observer’s response probability across trials. Probability matching is not applicable to responses in the overt task. Thus, the use of different decision rules may result in different levels of conservatism. These differences may also arise from an increase in uncertainty in the covert task due to less explicit feedback. An observer with greater uncertainty will rely more on the prior. Thus, conservatism may be the result of having a prior over criteria that interacts with task uncertainty. This can be tested by manipulating uncertainty over the generative model and measuring changes in conservatism. It is also possible that our training protocol introduced a bias towards equal probability and, due to the greater similarity between the covert and training tasks, the bias was stronger in the covert task. Finally, it is also possible that conservatism is the result of both the use of suboptimal decision rules and one or more of the previously proposed explanations.</p>
</sec>
<sec id="sec028">
<title>Incorrect assumptions about the generative model</title>
<p>While we tested a number of Bayesian change-point detection models that explored an array of assumptions about the generative model, clearly one could propose even more variants (e.g., a model with incorrect assumptions about category means and variance). Here, we analyzed one such assumption at a time. A simple way to expand the model space is via a factorial comparison [<xref ref-type="bibr" rid="pcbi.1006681.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref051">51</xref>], which we did not consider here due to computational intractability and the combinatorial explosion of models. We did however, fit the Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> model, which simultaneously accounted for incorrect assumptions about the run length and probability-state distributions and a bias towards equal probability. We compared the fit to the Exp<sub>bias</sub> model. Notably these two models explained the data equally well, despite the higher flexibility of the Bayesian model. We can thus interpret the Exp<sub>bias</sub> model as a simpler explanation for Bayesian change-point detection behavior with largely erroneous beliefs. For all models except the RL model we assumed knowledge of the category distributions. However, Norton et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref016">16</xref>] found that for the same orientation-categorization task, category means were estimated dynamically, even after prolonged training. Similarly, Gifford et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref052">52</xref>] observed suboptimality in an auditory-categorization task and found that the data were best explained by a model with non-stationary categories and prior probability that was updated using the recent history of category exemplars. This occurred despite holding categories and probability constant within a block. In fact, similar effects of non-stationarity have been observed in several other studies [<xref ref-type="bibr" rid="pcbi.1006681.ref053">53</xref>–<xref ref-type="bibr" rid="pcbi.1006681.ref055">55</xref>]. In addition to non-stationary category means, observers may also have misestimated category variance [<xref ref-type="bibr" rid="pcbi.1006681.ref056">56</xref>], especially since learning category variance takes longer than learning category means [<xref ref-type="bibr" rid="pcbi.1006681.ref014">14</xref>].</p>
</sec>
</sec>
<sec id="sec029" sec-type="conclusions">
<title>Conclusion</title>
<p>In sum, our results provide a computational model for how decision-making behavior changes in response to implicit changes in prior probability. Specifically, they suggest a dual mechanism for learning and incorporating prior probability that operate at different timescales. Importantly, this helps explain behavior in situations in which assessment of probability is learned through experience. Further, our results demonstrate the need to compare multiple models and the benefit of using tasks that provide a richer, more informative dataset.</p>
</sec>
<sec id="sec030" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec031">
<title>Ethics statement</title>
<p>The Institutional Review Board at New York University approved the experimental procedure and observers gave written informed consent prior to participation.</p>
</sec>
<sec id="sec032">
<title>Participants</title>
<p>Eleven observers participated in the experiment (mean age 26.6, range 20-31, 8 females). All observers had normal or corrected-to-normal vision. One of the observers (EHN) was also an author.</p>
</sec>
<sec id="sec033">
<title>Apparatus and stimuli</title>
<p>Stimuli were presented on a gamma-corrected Dell Trinitron P780 CRT monitor with a 31.3 x 23.8° display, a resolution of 1024 x 768 pixels, a refresh rate of 85 Hz, and a mean luminance of 40 cd/m<sup>2</sup>. Observers viewed the display from a distance of 54.6 cm. The experiment was programmed in MATLAB [<xref ref-type="bibr" rid="pcbi.1006681.ref057">57</xref>] using the Psychophysics Toolbox [<xref ref-type="bibr" rid="pcbi.1006681.ref058">58</xref>, <xref ref-type="bibr" rid="pcbi.1006681.ref059">59</xref>].</p>
<p>Stimuli were 4.0 x 1.0° ellipses presented at the center of the display on a mid-gray background. In both the orientation-discrimination and covert-criterion tasks, trials began with a central white fixation cross (1.2°). In the overt-criterion task, a yellow line with random orientation was presented at the center of the display (5.0 x 0.5°).</p>
</sec>
<sec id="sec034">
<title>Procedure</title>
<sec id="sec035">
<title>Categories</title>
<p>In the ‘categorization’ sessions described below, stimulus orientations were drawn from one of two categories (A or B). Category distributions were Gaussian with different means (<italic>μ</italic><sub>B</sub> &gt; <italic>μ</italic><sub>A</sub>) and equal variance <inline-formula id="pcbi.1006681.e028"><alternatives><graphic id="pcbi.1006681.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">A</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">B</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">s</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>100</mml:mn> <mml:mspace width="0.167em"/><mml:msup><mml:mtext mathvariant="normal">deg</mml:mtext> <mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>. The mean of category A was chosen randomly from all possible orientations at the beginning of each session and the mean of category B was set so that <italic>d</italic>′ was approximately 1.5, which was determined for each observer based on the estimates of sensory uncertainty obtained during a ‘measurement session’ (<xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1C</xref>).</p>
</sec>
<sec id="sec036">
<title>Sessions</title>
<p>All observers participated in three 1-hour sessions. Observers completed a ‘measurement’ session first followed by two ‘categorization’ sessions. Observers completed the covert-criterion task in the first ‘categorization’ session followed by the overt-criterion task in the second, or vice versa (chosen randomly). At the beginning of each ‘categorization’ session, observers completed 200 trials of category training followed by 800 experimental trials. Prior to training, observers were provided with a detailed explanation of the category distributions and training task. After training, observers were provided with additional instructions about the subsequent ‘categorization’ task and told that the categories would remain constant for the remainder of the session but that category probability may change. Observers were not told how often category probability would change or the range of probability states.</p>
</sec>
</sec>
<sec id="sec037">
<title>Measurement task</title>
<p>During the ‘measurement’ session, sensory uncertainty (<italic>σ</italic><sub>v</sub>) was estimated using a two-interval, forced-choice, orientation-discrimination task in which two black ellipses were presented sequentially on a mid-gray background. The observer reported the interval containing the ellipse that was more clockwise by keypress. Once the response was recorded, auditory feedback was provided and the next trial began. An example trial sequence is shown in Fig S3A in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>.</p>
<p>The orientation of the ellipse in the first interval was chosen randomly on every trial from a uniform distribution ranging from -90 to 90°. The orientation of the second ellipse was randomly oriented clockwise or counter-clockwise of the first. The difference in orientation between the two ellipses was selected using an adaptive staircase procedure. The minimum step-size was 1° and the maximum step-size was 32°. Each observer ran two blocks. In each block, four staircases (65 trials each) were interleaved (two 1-up, 2-down and two 1-up, 3-down staircases) and randomly selected on each trial. For analyses and results see <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>.</p>
</sec>
<sec id="sec038">
<title>Category training</title>
<p>Each training trial was identical to a covert-criterion trial (<xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1A</xref>). During training there was an equal chance that a stimulus was drawn from either category. To assess learning of category distributions, observers were asked to estimate the mean orientation of each category following training. The mean of each category was estimated exactly once. The order in which category means were estimated was randomized. For estimation, a black ellipse with random orientation was displayed in the center of the display. Observers slid the mouse to the right and left to rotate the ellipse clockwise and counterclockwise, respectively and clicked the mouse to indicate they were satisfied with the setting. No feedback was provided. We computed the proportion correct for each observer to ensure category learning by comparing it to the expected proportion correct (<italic>p</italic>(correct) = 0.77) for <italic>d</italic>′ = 1.5. Mean estimates are plotted in Fig S4C in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref> as a function of the true category means. We computed the average estimation error for each category and observer by subtracting the estimate from the true mean. From visual inspection, it appears that training was effective with the exception of one outlier, which we assume was a lapse.</p>
</sec>
<sec id="sec039">
<title>Categorization tasks</title>
<sec id="sec040">
<title>Covert-criterion task</title>
<p>In the covert-criterion task, observers categorized ellipses based on their orientation. The start of each trial (<italic>N</italic><sub>trials</sub> = 800) was signaled by the appearance of a central white fixation cross (500 ms). A black oriented ellipse was then displayed at the center of the screen (300 ms). Observers categorized the ellipse as A or B by keypress. Observers received feedback as to whether they were correct on every trial. Observers received a point for every correct response and aggregate points were displayed at the top of the screen to motivate observers. In addition, the fixation cross was displayed at the center of the screen in the color corresponding to the true category (category A: green; category B: red). The next trial began immediately. An example trial sequence is depicted in <xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1A</xref>.</p>
</sec>
<sec id="sec041">
<title>Overt-criterion task</title>
<p>In the overt-criterion task, observers completed an explicit version of the categorization task described above that was developed by Norton et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref016">16</xref>]. At the beginning of each trial (<italic>N</italic><sub>trials</sub> = 800), a line was displayed at the center of the screen. The orientation of the line was randomly selected from a uniform distribution ranging from -90 to 90°. The observers’ task was to rotate the line to indicate the criterion for that trial. Observers were explicitly instructed to set the criterion so that a subsequent category A stimulus would fall clockwise of the line and category B stimuli would fall counter-clockwise of it. Observers rotated the line clockwise or counterclockwise by sliding the mouse to the right or left and clicked the mouse to indicate their setting. Next, an ellipse was displayed under the criterion line in the color corresponding to the true category for 300 ms. Auditory feedback indicated whether the set criterion correctly categorized the ellipse. That is, observers were correct when a category A stimulus was clockwise of the criterion line or a category B stimulus was counterclockwise of the line. Observers received a point for a correct response and aggregate points were displayed at the top of the screen. The next trial began immediately. An example trial sequence is depicted in <xref ref-type="fig" rid="pcbi.1006681.g001">Fig 1B</xref>.</p>
</sec>
</sec>
<sec id="sec042">
<title>Model fitting</title>
<p>For fitting, all models had one free noise parameter. In the covert-criterion task, this was sensory noise (<italic>σ</italic><sub>v</sub>). In the overt-criterion task, sensory noise was fixed and set to the value obtained in the ‘measurement’ session, but we included a noise parameter for the adjustment of the criterion line (<italic>σ</italic><sub>a</sub>). Fixing one noise parameter in the overt-criterion task ameliorated potential issues of lack of parameter identifiability [<xref ref-type="bibr" rid="pcbi.1006681.ref060">60</xref>], and ensured that models had the same complexity across tasks. The Bayes<sub>ideal</sub>, Fixed, and Behrens et al. (2007) models had no additional parameters. The following suboptimal Bayesian models had one additional parameter: Bayes<sub><italic>r</italic></sub> (<italic>r</italic>); Bayes<sub><italic>π</italic></sub> (<italic>π</italic><sub>min</sub>); Bayes<sub><italic>β</italic></sub> (<italic>β</italic>). The Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> model had 5 additional parameters (<italic>r</italic>, Δ<italic>r</italic>, <italic>π</italic><sub>min</sub>, Δ<italic>π</italic>, <italic>β</italic>). The Exp and RL models also only had one additional parameter (<italic>α</italic>), as did the Behrens et al. (2007) model with a bias towards equal probability (<italic>w</italic>). The Exp<sub>bias</sub> model had two additional parameters (<italic>α</italic><sub>exp</sub> and <italic>w</italic>), and the Wilson et al. (2013) model had three (<italic>l</italic><sub>2</sub>, <italic>l</italic><sub>3</sub>, and <italic>ν</italic><sub>p</sub>).</p>
<p>To fit each model, for each subject and task we computed the logarithm of the <italic>unnormalized</italic> posterior probability of the parameters,
<disp-formula id="pcbi.1006681.e029"><alternatives><graphic id="pcbi.1006681.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:msup><mml:mi>p</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>|</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>|</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
where data are category decisions in the covert-criterion task and criterion orientation in the overt-criterion task, M is a specific model, and <bold><italic>θ</italic></bold> represents the model parameters (generally, a vector). The first term of <xref ref-type="disp-formula" rid="pcbi.1006681.e029">Eq 10</xref> is the log likelihood, while the second term is the prior over parameters (see below).</p>
<p>For each model (except Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub>) we evaluated <xref ref-type="disp-formula" rid="pcbi.1006681.e029">Eq 10</xref> on a cubic grid, with bounds chosen to contain almost all posterior probability mass. The grid for all models, except Wilson et al. (2013), consisted of 100 equally spaced values for each parameter. Due to the computational demands of the Wilson et al. (2013) model, we reduced the grid to 50 equally spaced values. The grid allowed us to approximate the full posterior distribution over parameters, and also to evaluate the normalization constant for the posterior, which corresponds to the evidence or marginal likelihood, used as a metric of model comparison (see Model comparison). We reported as parameter estimates the best-fitting model parameters on the grid, that is the maximum-a-posteriori (MAP) values (see Tables <xref ref-type="table" rid="pcbi.1006681.t001">1</xref> and <xref ref-type="table" rid="pcbi.1006681.t002">2</xref>). We used the full posterior distributions to compute posterior predictive distributions, that is, model predictions for visualization (see Model visualization), and to generate plausible parameter values for our model-recovery analysis. The Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> model had too many parameters to compute the marginal likelihood via brute force on a grid, so we adopted a different procedure for model comparison (see Model comparison).</p>
<sec id="sec043">
<title>Priors over parameters</title>
<p>We chose all priors to be uninformative. For noise parameters, we used uniform priors over a reasonably large range ([1°, 30°]). For <italic>α</italic><sub>exp</sub>, <italic>α</italic><sub>RL</sub>, and <italic>w</italic> we used a uniform prior from 0 to 1. For <italic>r</italic> we used a uniform prior from 2 to 200 trials. For <italic>π</italic><sub>min</sub> we used a uniform prior from 0 to 0.5. For <italic>β</italic>, we used a uniform prior on the square root of the parameter value, ranging from 0 to 10. Instead of fitting the individual nodes in the Wilson et al. (2013) model, we fit the difference between nodes, i.e., <italic>δ</italic><sub>1</sub> = <italic>l</italic><sub>2</sub> − <italic>l</italic><sub>1</sub> and <italic>δ</italic><sub>2</sub> = <italic>l</italic><sub>3</sub> − <italic>l</italic><sub>2</sub>. We used a uniform prior on the square root of <italic>δ</italic><sub>1</sub> ranging from 1.01 to 5 and on the square root of <italic>δ</italic><sub>2</sub> ranging from 1.01 to 14. Finally, for <italic>ν</italic><sub>p</sub> we used a uniform prior in log space from 0 to 5.</p>
</sec>
</sec>
<sec id="sec044">
<title>Response probability</title>
<sec id="sec045">
<title>Covert-criterion task</title>
<p>For each model, parameter combination, observer, and trial in the covert-criterion task, we computed the probability of choosing category A on each trial given a stimulus, <italic>s</italic><sub><italic>t</italic></sub>, and all previously experienced categories, <bold><italic>C</italic></bold><sub>1:<italic>t</italic>−1</sub>. In all models, the observer’s current decision depends on the noisy measurement, <italic>x</italic><sub><italic>t</italic></sub>, so the probability of responding A for a given stimulus <italic>s</italic><sub><italic>t</italic></sub> is
<disp-formula id="pcbi.1006681.e030"><alternatives><graphic id="pcbi.1006681.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mtext>A</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mtext>A</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext>v</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula></p>
<p>Because the current criterion setting in the RL model depends on the vector of all previous stimulus measurements, <bold><italic>x</italic></bold><sub>1:<italic>t</italic></sub>, the probability could not be computed analytically for this model. As an approximation, we used Monte Carlo simulations with 5000 sample measurement vectors. For each measurement vector, we applied the model’s decision rule and approximated the probability by computing the proportion of times the model chose A out of all the simulations. For all models, we included a fixed lapse rate, λ = 10<sup>−4</sup>, that is the probability of a completely random response. The probability of choosing category A, <inline-formula id="pcbi.1006681.e031"><alternatives><graphic id="pcbi.1006681.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:msub><mml:mover><mml:mi>C</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mtext mathvariant="normal">A</mml:mtext></mml:msub></mml:math></alternatives></inline-formula>, in the presence of lapses was then
<disp-formula id="pcbi.1006681.e032"><alternatives><graphic id="pcbi.1006681.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mtext>A</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>λ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mtext>A</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula></p>
<p>Effectively, the lapse rate acts as a regularization term that avoids excessive penalties to the likelihood of a model for outlier trials.</p>
<p>Next, assuming conditional independence between trials, we computed the log likelihood across all of the observer’s choices, given each model and parameter combination
<disp-formula id="pcbi.1006681.e033"><alternatives><graphic id="pcbi.1006681.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munderover><mml:mo mathvariant="bold">∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>trials</mml:mtext></mml:msub></mml:munderover> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mtext>A</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
where <italic>t</italic> is the trial index and <italic>N</italic><sub>trials</sub> is the total number of trials.</p>
</sec>
<sec id="sec046">
<title>Overt-criterion task</title>
<p>For each model, parameter combination, observer, and trial in the overt-criterion task, we computed the decision criterion on each trial. For all models except the RL model, the criterion was computed as in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>. For the RL model, the criterion was computed as in <xref ref-type="disp-formula" rid="pcbi.1006681.e020">Eq 7</xref> for 5000 sample measurement vectors. For all models in the overt-criterion task, the criterion was corrupted by adjustment noise with variance <inline-formula id="pcbi.1006681.e034"><alternatives><graphic id="pcbi.1006681.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">a</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, so that <inline-formula id="pcbi.1006681.e035"><alternatives><graphic id="pcbi.1006681.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:msub><mml:mover><mml:mi>z</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>∼</mml:mo> <mml:mstyle mathvariant="script"><mml:mi>N</mml:mi></mml:mstyle> <mml:mo form="prefix" stretchy="false">(</mml:mo> <mml:msub><mml:mi>z</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mtext mathvariant="normal">a</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo form="postfix" stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>z</italic><sub><italic>t</italic></sub> was the observer’s chosen criterion at trial <italic>t</italic>, and <inline-formula id="pcbi.1006681.e036"><alternatives><graphic id="pcbi.1006681.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:msub><mml:mover><mml:mi>z</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula> was the actual reported criterion after adjustment noise. In addition, the observer had a chance of lapsing (e.g., a misclick), in which case the response was uniformly distributed in the range. Therefore, the probability that the observer reports the criterion <inline-formula id="pcbi.1006681.e037"><alternatives><graphic id="pcbi.1006681.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msub><mml:mover><mml:mi>z</mml:mi> <mml:mo accent="true">^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub></mml:math></alternatives></inline-formula> was
<disp-formula id="pcbi.1006681.e038"><alternatives><graphic id="pcbi.1006681.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e038" xlink:type="simple"/><mml:math display="block" id="M38"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mfrac><mml:mo>λ</mml:mo> <mml:mn>180</mml:mn></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
with λ = 5 × 10<sup>−5</sup>. As in the covert-criterion task, we computed the log likelihood across all trials by summing the log probability
<disp-formula id="pcbi.1006681.e039"><alternatives><graphic id="pcbi.1006681.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munderover><mml:mo mathvariant="bold">∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">C</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula></p>
</sec>
</sec>
<sec id="sec047">
<title>Model comparison</title>
<p>To obtain a quantitative measure of model fit, for each observer, model (except Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub>), and task we computed the log marginal likelihood (LML) by integrating over the parameters in <xref ref-type="disp-formula" rid="pcbi.1006681.e029">Eq 10</xref>,
<disp-formula id="pcbi.1006681.e040"><alternatives><graphic id="pcbi.1006681.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006681.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>|</mml:mo> <mml:mtext>M</mml:mtext> <mml:mo>)</mml:mo> <mml:mi>d</mml:mi> <mml:mi>θ</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula></p>
<p>To approximate the integral in <xref ref-type="disp-formula" rid="pcbi.1006681.e040">Eq 16</xref>, we marginalized across each parameter dimension using the trapezoidal method. Assuming equal probability across models, the marginal likelihood is proportional to the posterior probability of a given model and thus represents a principled metric for comparison that automatically accounts for both goodness of fit and model complexity via Bayesian Occam’s razor [<xref ref-type="bibr" rid="pcbi.1006681.ref061">61</xref>]. Penalizing for model complexity is a desirable feature of a model-comparison metric to reduce overfitting.</p>
<p>In addition to the Bayesian model-comparison metric described above, we computed the Akaike Information Criterion (AIC) [<xref ref-type="bibr" rid="pcbi.1006681.ref062">62</xref>] for each of our models. AIC is one of many information criteria that penalize the maximum log likelihood by a term that increases with the number of parameters. LML and AIC results were consistent (see <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>. for model comparison using AIC scores).</p>
<p>For comparison purposes, we report relative model-comparison scores, ΔLML and ΔAIC. We used bootstrapping to compute confidence intervals on the mean difference scores. Specifically, we simulated 10,000 sample data sets. For each simulated dataset we sampled, with replacement, 11 difference scores (the same number of difference scores as observers) and calculated the mean. To determine the 95% CI, we sorted the mean difference scores and determined the scores that corresponded to the 2.5 and 97.5 percentiles.</p>
<p>For an additional analysis at the group level, we used the random-effects Bayesian model selection analysis (BMS) developed by Stephan et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref032">32</xref>] and expanded on by Rigoux et al. [<xref ref-type="bibr" rid="pcbi.1006681.ref033">33</xref>]. Specifically, using observers’ LML scores we computed the protected exceedance probability <italic>ϕ</italic> and the posterior model frequency for each model. Exceedance probability represents the probability that one model is the most frequent decision-making strategy in the population, given the group data, above and beyond chance. This analysis was conducted using the open-source software package Statistical Parametric Mapping (SPM12; <ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm" xlink:type="simple">http://www.fil.ion.ucl.ac.uk/spm</ext-link>).</p>
<p>To compare the Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> and Exp<sub>bias</sub> models, we first fitted the data by maximum likelihood. For each of the two models, subject, and task we minimized the negative log likelihood of the data using Bayesian Adaptive Direct Search (BADS; <ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/bads" xlink:type="simple">https://github.com/lacerbi/bads</ext-link> [<xref ref-type="bibr" rid="pcbi.1006681.ref063">63</xref>]), taking the best result of 20 optimization runs with randomized starting points. Using the negative log likelihood from the fits, we computed the Bayesian Information Criterion (BIC), which penalizes the maximum log likelihood by a term that increases with the number of parameters in a similar way to AIC. We then estimated approximate lower bounds (ELBO) to the log marginal likelihood (and approximate posterior distibutions, unused in our current analysis) via Variational Bayesian Monte Carlo (VBMC; <ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/vbmc" xlink:type="simple">https://github.com/lacerbi/vbmc</ext-link> [<xref ref-type="bibr" rid="pcbi.1006681.ref034">34</xref>]), taking the ‘best’ out of 10 variational optimization runs. VBMC combines variational inference and active-sampling Bayesian quadrature to perform approximate Bayesian inference in a sample-efficient manner. We validated the technique on the Exp<sub>bias</sub> model, by comparing the ELBO obtained via VBMC and the log marginal likelihood calculated via numerical integration. For all subjects and task, the two metrics differed by &lt; 0.2 points. As a diagnostic of convergence for VBMC, for each problem instance we also verified that the majority of variational optimization runs returned an ELBO less than 1 point away from the ‘best’ solution we used in the analysis. For the few datasets that exhibited a slightly larger variability in the ELBOs across optimization runs, such variability was still much lower than the standard error across subjects of the ΔELBO, thus not affecting the results of the model comparison.</p>
</sec>
<sec id="sec048">
<title>Model visualization</title>
<p>For each model, observer, and task, we randomly sampled 1000 parameter combinations from the joint posterior distribution with replacement. For each parameter combination, we simulated model responses using the same stimuli that were presented to the observer. Because the model output in the covert task was the probability of reporting category A, for each trial in a simulated dataset we simulated 10,000 model responses (i.e., category decisions), calculated the cumulative number of A’s for each simulated dataset, and averaged the results. The mean and standard deviation were computed across all simulated datasets in both tasks. Model fit plots show the mean response (colored line) with shaded regions representing one standard deviation from the mean. Thus, shaded regions represent a 68% confidence interval on model fits.</p>
</sec>
<sec id="sec049">
<title>Model recovery</title>
<p>To ensure that our models were discriminable, we performed a model-recovery analysis, details of which can be found in <xref ref-type="supplementary-material" rid="pcbi.1006681.s001">S1 Appendix</xref>. In addition to the model-recovery analysis, we also performed a parameter-recovery analysis for the Exp<sub>bias</sub> model. This was done to determine whether our parameter estimation procedure was biased for each parameter and task.</p>
</sec>
</sec>
<sec id="sec050">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006681.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006681.s001" xlink:type="simple">
<label>S1 Appendix</label>
<caption>
<title>Supplementary information.</title>
<p>Ideal observer model derivation; additional models; comparison of the Bayes<sub><italic>r</italic>,<italic>π</italic>,<italic>β</italic></sub> and Exp<sub>bias</sub> models, model comparison with AIC; recovery analysis; measurement task; category training; individual model fits.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We would like to thank Chris Grimmick for helping with data collection. This work utilized the NYU IT High Performance Computing resources and services.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006681.ref001">
<label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bernardo</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>A</given-names></name>. <source>Bayesian theory</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1994</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref002">
<label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Green</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Swets</surname> <given-names>JA</given-names></name>. <source>Signal detection theory and psychophysics</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1966</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tanner</surname> <given-names>WP</given-names><suffix>Jr</suffix></name>. <article-title>Theory of recognition</article-title>. <source>J Acoust Soc Am</source>. <year>1956</year>;<volume>28</volume>:<fpage>882</fpage>–<lpage>888</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.1908504" xlink:type="simple">10.1121/1.1908504</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ackermann</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>. <article-title>Suboptimal decision criteria are predicted by subjectively weighted probabilities and rewards</article-title>. <source>Atten Percept Psychophys</source>. <year>2015</year>;<volume>77</volume>:<fpage>638</fpage>–<lpage>658</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13414-014-0779-z" xlink:type="simple">10.3758/s13414-014-0779-z</ext-link></comment> <object-id pub-id-type="pmid">25366822</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ulehla</surname> <given-names>ZJ</given-names></name>. <article-title>Optimality of perceptual decision criteria</article-title>. <source>J Exp Psychol</source>. <year>1966</year>;<volume>71</volume>:<fpage>564</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0023007" xlink:type="simple">10.1037/h0023007</ext-link></comment> <object-id pub-id-type="pmid">5909083</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Healy</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Kubovy</surname> <given-names>M</given-names></name>. <article-title>Probability matching and the formation of conservative decision rules in a numerical analog of signal detection</article-title>. <source>J Exp Psychol Hum Learn</source>. <year>1981</year>;<volume>7</volume>:<fpage>344</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0278-7393.7.5.344" xlink:type="simple">10.1037/0278-7393.7.5.344</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kubovy</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Healy</surname> <given-names>AF</given-names></name>. <article-title>The decision rule in probabilistic categorization: What it is and how it is learned</article-title>. <source>J Exp Psychol Gen</source>. <year>1977</year>;<volume>106</volume>:<fpage>427</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-3445.106.4.427" xlink:type="simple">10.1037/0096-3445.106.4.427</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Healy</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Kubovy</surname> <given-names>M</given-names></name>. <article-title>The effects of payoffs and prior probabilities on indices of performance and cutoff location in recognition memory</article-title>. <source>Mem Cognit</source>. <year>1978</year>;<volume>6</volume>:<fpage>544</fpage>–<lpage>553</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03198243" xlink:type="simple">10.3758/BF03198243</ext-link></comment> <object-id pub-id-type="pmid">24203388</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maddox</surname> <given-names>WT</given-names></name>. <article-title>Toward a unified theory of decision criterion learning in perceptual categorization</article-title>. <source>J Exp Anal Behav</source>. <year>2002</year>;<volume>78</volume>:<fpage>567</fpage>–<lpage>595</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1901/jeab.2002.78-567" xlink:type="simple">10.1901/jeab.2002.78-567</ext-link></comment> <object-id pub-id-type="pmid">12507020</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barron</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Erev</surname> <given-names>I</given-names></name>. <article-title>Small feedback-based decisions and their limited correspondence to description-based decisions</article-title>. <source>J Behav Decis Mak</source>. <year>2003</year>;<volume>16</volume>:<fpage>215</fpage>–<lpage>233</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/bdm.443" xlink:type="simple">10.1002/bdm.443</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hertwig</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Barron</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Weber</surname> <given-names>EU</given-names></name>, <name name-style="western"><surname>Erev</surname> <given-names>I</given-names></name>. <article-title>Decisions from experience and the effect of rare events in risky choice</article-title>. <source>Psychol Sci</source>. <year>2004</year>;<volume>15</volume>:<fpage>534</fpage>–<lpage>539</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.0956-7976.2004.00715.x" xlink:type="simple">10.1111/j.0956-7976.2004.00715.x</ext-link></comment> <object-id pub-id-type="pmid">15270998</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bohil</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Wismer</surname> <given-names>AJ</given-names></name>. <article-title>Implicit learning mediates base rate acquisition in perceptual categorization</article-title>. <source>Psychon Bull Rev</source>. <year>2015</year>;<volume>22</volume>:<fpage>586</fpage>–<lpage>593</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13423-014-0694-2" xlink:type="simple">10.3758/s13423-014-0694-2</ext-link></comment> <object-id pub-id-type="pmid">25037267</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wismer</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Bohil</surname> <given-names>CJ</given-names></name>. <article-title>Base-rate sensitivity through implicit learning</article-title>. <source>PLoS One</source>. <year>2017</year>;<volume>12</volume>(<issue>6</issue>):<fpage>e0179256</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0179256" xlink:type="simple">10.1371/journal.pone.0179256</ext-link></comment> <object-id pub-id-type="pmid">28632779</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berniker</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Voss</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Körding</surname> <given-names>K</given-names></name>. <article-title>Learning priors for Bayesian computations in the nervous system</article-title>. <source>PLoS One</source>. <year>2010</year>;<volume>5</volume>(<issue>9</issue>):<fpage>e12686</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0012686" xlink:type="simple">10.1371/journal.pone.0012686</ext-link></comment> <object-id pub-id-type="pmid">20844766</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name>. <article-title>Perceptual classification in a rapidly changing environment</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>71</volume>:<fpage>725</fpage>–<lpage>736</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.06.022" xlink:type="simple">10.1016/j.neuron.2011.06.022</ext-link></comment> <object-id pub-id-type="pmid">21867887</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Norton</surname> <given-names>EH</given-names></name>, <name name-style="western"><surname>Fleming</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>. <article-title>Suboptimal criterion learning in static and dynamic environments</article-title>. <source>PLoS Comput Biol</source>. <year>2017</year>;<volume>13</volume>(<issue>1</issue>):<fpage>e1005304</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005304" xlink:type="simple">10.1371/journal.pcbi.1005304</ext-link></comment> <object-id pub-id-type="pmid">28046006</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Heasly</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>:<fpage>12366</fpage>–<lpage>12378</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0822-10.2010" xlink:type="simple">10.1523/JNEUROSCI.0822-10.2010</ext-link></comment> <object-id pub-id-type="pmid">20844132</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Trommershäuser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>. <article-title>Dynamic estimation of task-relevant variance in movement under risk</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>:<fpage>12702</fpage>–<lpage>12711</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.6160-11.2012" xlink:type="simple">10.1523/JNEUROSCI.6160-11.2012</ext-link></comment> <object-id pub-id-type="pmid">22972994</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Vijayakumar</surname> <given-names>S</given-names></name>. <article-title>Internal representations of temporal statistics and feedback calibrate motor-sensory interval timing</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>(<issue>11</issue>):<fpage>e1002771</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002771" xlink:type="simple">10.1371/journal.pcbi.1002771</ext-link></comment> <object-id pub-id-type="pmid">23209386</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sato</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Körding</surname> <given-names>KP</given-names></name>. <article-title>How much to trust the senses: Likelihood learning</article-title>. <source>J Vis</source>. <year>2014</year>;<volume>14</volume>(<issue>13</issue>):<fpage>13</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/14.13.13" xlink:type="simple">10.1167/14.13.13</ext-link></comment> <object-id pub-id-type="pmid">25398975</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Glaze</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Kable</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>Normative evidence accumulation in unpredictable environments</article-title>. <source>eLife</source>. <year>2015</year>;<volume>4</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.08825" xlink:type="simple">10.7554/eLife.08825</ext-link></comment> <object-id pub-id-type="pmid">26322383</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>Bayesian online learning of the hazard rate in change-point problems</article-title>. <source>Neural Comput</source>. <year>2010</year>;<volume>22</volume>:<fpage>2452</fpage>–<lpage>2476</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/NECO_a_00007" xlink:type="simple">10.1162/NECO_a_00007</ext-link></comment> <object-id pub-id-type="pmid">20569174</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Meyniel</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Schlunegger</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>. <article-title>The sense of confidence during probabilistic learning: A normative account</article-title>. <source>PLoS Comput Biol</source>. <year>2015</year>;<volume>11</volume>(<issue>6</issue>):<fpage>e1004305</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004305" xlink:type="simple">10.1371/journal.pcbi.1004305</ext-link></comment> <object-id pub-id-type="pmid">26076466</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MF</given-names></name>. <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source>. <year>2007</year>;<volume>10</volume>:<fpage>1214</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1954" xlink:type="simple">10.1038/nn1954</ext-link></comment> <object-id pub-id-type="pmid">17676057</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zylberberg</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>. <article-title>Counterfactual reasoning underlies the learning of priors in decision making</article-title>. <source>Neuron</source>. <year>2018</year>;<volume>99</volume>(<issue>5</issue>):<fpage>1083</fpage>–<lpage>1097</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2018.07.035" xlink:type="simple">10.1016/j.neuron.2018.07.035</ext-link></comment> <object-id pub-id-type="pmid">30122376</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tversky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kahneman</surname> <given-names>D</given-names></name>. <article-title>Judgment under uncertainty: Heuristics and biases</article-title>. <source>Science</source>. <year>1974</year>;<volume>185</volume>:<fpage>1124</fpage>–<lpage>1131</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.185.4157.1124" xlink:type="simple">10.1126/science.185.4157.1124</ext-link></comment> <object-id pub-id-type="pmid">17835457</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref027">
<label>27</label>
<mixed-citation publication-type="other" xlink:type="simple">Adams RP, MacKay DJ. Bayesian online changepoint detection. arXiv preprint arXiv:07103742. 2007.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gallistel</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Krishan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>. <article-title>The perception of probability</article-title>. <source>Psychol Rev</source>. <year>2014</year>;<volume>121</volume>:<fpage>96</fpage>–<lpage>123</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0035232" xlink:type="simple">10.1037/a0035232</ext-link></comment> <object-id pub-id-type="pmid">24490790</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref029">
<label>29</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Rescorla</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AR</given-names></name>. <article-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</article-title>. In: <name name-style="western"><surname>Black</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Prokasy</surname> <given-names>WF</given-names></name>, editors. <source>Classical conditioning II: Current research and theory</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Appleton-Century-Crofts</publisher-name>; <year>1972</year>. p. <fpage>64</fpage>–<lpage>99</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>A mixture of delta-rules approximation to Bayesian inference in change-point problems</article-title>. <source>PLoS Comput Biol</source>. <year>2018</year>;<volume>14</volume>(<issue>6</issue>):<fpage>e1006210</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003150" xlink:type="simple">10.1371/journal.pcbi.1003150</ext-link></comment> <object-id pub-id-type="pmid">23935472</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Nassar</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>. <article-title>Correction: A mixture of delta-rules approximation to Bayesian inference in change-point problems</article-title>. <source>PLoS Comput Biol</source>. <year>2013</year>;<volume>9</volume>(<issue>7</issue>):<fpage>e1003150</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1006210" xlink:type="simple">10.1371/journal.pcbi.1006210</ext-link></comment> <object-id pub-id-type="pmid">29944654</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Penny</surname> <given-names>WD</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Moran</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Bayesian model selection for group studies</article-title>. <source>Neuroimage</source>. <year>2009</year>;<volume>46</volume>:<fpage>1004</fpage>–<lpage>1017</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.03.025" xlink:type="simple">10.1016/j.neuroimage.2009.03.025</ext-link></comment> <object-id pub-id-type="pmid">19306932</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rigoux</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>. <article-title>Bayesian model selection for group studies—revisited</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>84</volume>:<fpage>971</fpage>–<lpage>985</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.08.065" xlink:type="simple">10.1016/j.neuroimage.2013.08.065</ext-link></comment> <ext-link ext-link-type="uri" xlink:href="https://www.ncbi.nlm.nih.gov/pubmed/24018303" xlink:type="simple">https://www.ncbi.nlm.nih.gov/pubmed/24018303</ext-link></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>. <article-title>Variational Bayesian Monte Carlo</article-title>. In: <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 31</volume>; <year>2018</year>. p. <fpage>8213</fpage>–<lpage>8223</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Burge</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>The statistical determinants of adaptation rate in human reaching</article-title>. <source>J Vis</source>. <year>2008</year>;<volume>8</volume>(<issue>4</issue>):<fpage>20</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/8.4.20" xlink:type="simple">10.1167/8.4.20</ext-link></comment> <object-id pub-id-type="pmid">18484859</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Qamar</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Cotton</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>RG</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Prezhdo</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Laudano</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Trial-to-trial, uncertainty-based adjustment of decision boundaries in visual categorization</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2013</year>;<volume>110</volume>:<fpage>20332</fpage>–<lpage>20337</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1219756110" xlink:type="simple">10.1073/pnas.1219756110</ext-link></comment> <object-id pub-id-type="pmid">24272938</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Heilbron</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Meyniel</surname> <given-names>F</given-names></name>. <article-title>Confidence resets reveal hierarchical adaptive learning in humans</article-title>. <source>PLoS Comput Biol</source>. <year>2019</year>;<volume>15</volume>(<issue>4</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1006972" xlink:type="simple">10.1371/journal.pcbi.1006972</ext-link></comment> <object-id pub-id-type="pmid">30964861</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Dokka</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Bayesian comparison of explicit and implicit causal inference strategies in multisensory heading perception</article-title>. <source>PLoS Comput Biol</source>. <year>2018</year>;<volume>14</volume>(<issue>7</issue>):<fpage>e1006110</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1006110" xlink:type="simple">10.1371/journal.pcbi.1006110</ext-link></comment> <object-id pub-id-type="pmid">30052625</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Pitkow</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Not noisy, just wrong: The role of suboptimal inference in behavioral variability</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>74</volume>(<issue>1</issue>):<fpage>30</fpage>–<lpage>39</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.03.016" xlink:type="simple">10.1016/j.neuron.2012.03.016</ext-link></comment> <object-id pub-id-type="pmid">22500627</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Vijayakumar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>On the origins of suboptimality in human probabilistic inference</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>6</issue>):<fpage>e1003661</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003661" xlink:type="simple">10.1371/journal.pcbi.1003661</ext-link></comment> <object-id pub-id-type="pmid">24945142</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Drugowitsch</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Tuning the speed-accuracy trade-off to maximize reward rate in multisensory decision-making</article-title>. <source>eLife</source>. <year>2015</year>;<volume>4</volume>:<fpage>e06678</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.06678" xlink:type="simple">10.7554/eLife.06678</ext-link></comment> <object-id pub-id-type="pmid">26090907</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Izawa</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shadmehr</surname> <given-names>R</given-names></name>. <article-title>Learning from sensory and reward prediction errors during motor adaptation</article-title>. <source>PLoS Comput Biol</source>. <year>2011</year>;<volume>7</volume>(<issue>3</issue>):<fpage>e1002012</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002012" xlink:type="simple">10.1371/journal.pcbi.1002012</ext-link></comment> <object-id pub-id-type="pmid">21423711</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Attneave</surname> <given-names>F</given-names></name>. <article-title>Psychological probability as a function of experienced frequency</article-title>. <source>J Exp Psychol</source>. <year>1953</year>;<volume>46</volume>:<fpage>81</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0057955" xlink:type="simple">10.1037/h0057955</ext-link></comment> <object-id pub-id-type="pmid">13084849</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Varey</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Mellers</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Birnbaum</surname> <given-names>MH</given-names></name>. <article-title>Judgments of proportions</article-title>. <source>J Exp Psychol Hum Percept Perform</source>. <year>1990</year>;<volume>16</volume>:<fpage>613</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/0096-1523.16.3.613" xlink:type="simple">10.1037/0096-1523.16.3.613</ext-link></comment> <object-id pub-id-type="pmid">2144575</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Maloney</surname> <given-names>LT</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>EA</given-names></name>. <article-title>Distributional assumptions and observed conservatism in the theory of signal detectability</article-title>. <source>J Math Psychol</source>. <year>1991</year>;<volume>35</volume>:<fpage>443</fpage>–<lpage>470</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0022-2496(91)90043-S" xlink:type="simple">10.1016/0022-2496(91)90043-S</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kubovy</surname> <given-names>M</given-names></name>. <article-title>A possible basis for conservatism in signal detection and probabilistic categorization tasks</article-title>. <source>Percept Psychophys</source>. <year>1977</year>;<volume>22</volume>:<fpage>277</fpage>–<lpage>281</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/BF03199690" xlink:type="simple">10.3758/BF03199690</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lee</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Janke</surname> <given-names>M</given-names></name>. <article-title>Categorizing externally distributed stimulus samples for unequal molar probabilities</article-title>. <source>Psychol Rep</source>. <year>1965</year>;<volume>17</volume>:<fpage>79</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2466/pr0.1965.17.1.79" xlink:type="simple">10.2466/pr0.1965.17.1.79</ext-link></comment> <object-id pub-id-type="pmid">5826504</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Murray</surname> <given-names>RF</given-names></name>, <name name-style="western"><surname>Patel</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Yee</surname> <given-names>A</given-names></name>. <article-title>Posterior probability matching and human perceptual decision making</article-title>. <source>PLoS Comput Biol</source>. <year>2015</year>;<volume>11</volume>(<issue>6</issue>):<fpage>e1004342</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004342" xlink:type="simple">10.1371/journal.pcbi.1004342</ext-link></comment> <object-id pub-id-type="pmid">26079134</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thomas</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Legge</surname> <given-names>D</given-names></name>. <article-title>Probability matching as a basis for detection and recognition decisions</article-title>. <source>Psychol Rev</source>. <year>1970</year>;<volume>77</volume>:<fpage>65</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/h0028579" xlink:type="simple">10.1037/h0028579</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wozny</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>. <article-title>Probability matching as a computational strategy used in perception</article-title>. <source>PLoS Comput Biol</source>. <year>2010</year>;<volume>6</volume>(<issue>8</issue>):<fpage>e1000871</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000871" xlink:type="simple">10.1371/journal.pcbi.1000871</ext-link></comment> <object-id pub-id-type="pmid">20700493</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Awh</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Factorial comparison of working memory models</article-title>. <source>Psychol Rev</source>. <year>2014</year>;<volume>121</volume>:<fpage>124</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0035234" xlink:type="simple">10.1037/a0035234</ext-link></comment> <object-id pub-id-type="pmid">24490791</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gifford</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>YE</given-names></name>, <name name-style="western"><surname>Stocker</surname> <given-names>AA</given-names></name>. <article-title>Characterizing the impact of category uncertainty on human auditory categorization behavior</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>7</issue>):<fpage>e1003715</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003715" xlink:type="simple">10.1371/journal.pcbi.1003715</ext-link></comment> <object-id pub-id-type="pmid">25032683</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Petzschner</surname> <given-names>FH</given-names></name>, <name name-style="western"><surname>Glasauer</surname> <given-names>S</given-names></name>. <article-title>Iterative Bayesian estimation as an explanation for range and regression effects: A study on human path integration</article-title>. <source>J Neurosci</source>. <year>2011</year>;<volume>31</volume>:<fpage>17220</fpage>–<lpage>17229</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2028-11.2011" xlink:type="simple">10.1523/JNEUROSCI.2028-11.2011</ext-link></comment> <object-id pub-id-type="pmid">22114288</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Raviv</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Ahissar</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Loewenstein</surname> <given-names>Y</given-names></name>. <article-title>How recent history affects perception: The normative approach and its heuristic approximation</article-title>. <source>PLoS Comput Biol</source>. <year>2012</year>;<volume>8</volume>(<issue>10</issue>):<fpage>e1002731</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002731" xlink:type="simple">10.1371/journal.pcbi.1002731</ext-link></comment> <object-id pub-id-type="pmid">23133343</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fischer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Whitney</surname> <given-names>D</given-names></name>. <article-title>Serial dependence in visual perception</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>:<fpage>738</fpage>–<lpage>743</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3689" xlink:type="simple">10.1038/nn.3689</ext-link></comment> <object-id pub-id-type="pmid">24686785</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zylberberg</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Roelfsema</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Sigman</surname> <given-names>M</given-names></name>. <article-title>Variance misperception explains illusions of confidence in simple perceptual decisions</article-title>. <source>Conscious Cogn</source>. <year>2014</year>;<volume>27</volume>:<fpage>246</fpage>–<lpage>253</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.concog.2014.05.012" xlink:type="simple">10.1016/j.concog.2014.05.012</ext-link></comment> <object-id pub-id-type="pmid">24951943</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref057">
<label>57</label>
<mixed-citation publication-type="other" xlink:type="simple">MATLAB. version 7.10.0 (R2010a). Natick, Massachusetts: The MathWorks Inc.; 2010.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brainard</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Vision</surname> <given-names>S</given-names></name>. <article-title>The psychophysics toolbox</article-title>. <source>Spat Vis</source>. <year>1997</year>;<volume>10</volume>:<fpage>433</fpage>–<lpage>436</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1163/156856897X00357" xlink:type="simple">10.1163/156856897X00357</ext-link></comment> <object-id pub-id-type="pmid">9176952</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pelli</surname> <given-names>DG</given-names></name>. <article-title>The VideoToolbox software for visual psychophysics: Transforming numbers into movies</article-title>. <source>Spat Vis</source>. <year>1997</year>;<volume>10</volume>:<fpage>437</fpage>–<lpage>442</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1163/156856897X00366" xlink:type="simple">10.1163/156856897X00366</ext-link></comment> <object-id pub-id-type="pmid">9176953</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006681.ref060">
<label>60</label>
<mixed-citation publication-type="other" xlink:type="simple">Acerbi L, Ma WJ, Vijayakumar S. A framework for testing identifiability of Bayesian models of perception. In: Advances in Neural Information Processing Systems; 2014. p. 1026–1034.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref061">
<label>61</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>MacKay</surname> <given-names>DJ</given-names></name>. <source>Information Theory, Inference and Learning Algorithms</source>. <publisher-loc>Cambridge, England</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2003</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref062">
<label>62</label>
<mixed-citation publication-type="other" xlink:type="simple">Akaike H. Information theory and an extension of the maximum likelihood principle. In: Proceedings of the 2nd International Symposium on Information; 1973. p. 267–281.</mixed-citation>
</ref>
<ref id="pcbi.1006681.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Practical Bayesian optimization for model fitting with Bayesian Adaptive Direct Search</article-title>. In: <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 30</volume>; <year>2017</year>. p. <fpage>1836</fpage>–<lpage>1846</lpage>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
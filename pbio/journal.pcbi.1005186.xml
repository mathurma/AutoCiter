<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-02047</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005186</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Systems science</subject><subj-group><subject>Dynamical systems</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Systems science</subject><subj-group><subject>Dynamical systems</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Population biology</subject><subj-group><subject>Population dynamics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Random variables</subject><subj-group><subject>Covariance</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Potential energy</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>The Hamiltonian Brain: Efficient Probabilistic Inference with Excitatory-Inhibitory Neural Circuit Dynamics</article-title>
<alt-title alt-title-type="running-head">The Hamiltonian Brain</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3681-4607</contrib-id>
<name name-style="western">
<surname>Aitchison</surname> <given-names>Laurence</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lengyel</surname> <given-names>Máté</given-names></name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Gatsby Computational Neuroscience Unit, University College London, London, United Kingdom</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Computational &amp; Biological Learning Lab, Department of Engineering, University of Cambridge, Cambridge, United Kingdom</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Cognitive Science, Central European University, Budapest, Hungary</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Kording</surname> <given-names>Konrad P.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Northwestern University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p>
<list list-type="simple">
<list-item>
<p><bold>Conceived and designed the experiments:</bold> ML LA.</p>
</list-item>
<list-item>
<p><bold>Performed the experiments:</bold> LA.</p>
</list-item>
<list-item>
<p><bold>Analyzed the data:</bold> LA.</p>
</list-item>
<list-item>
<p><bold>Wrote the paper:</bold> LA ML.</p>
</list-item>
</list>
</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">laurence.aitchison@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>12</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="epub">
<day>27</day>
<month>12</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>12</issue>
<elocation-id>e1005186</elocation-id>
<history>
<date date-type="received">
<day>6</day>
<month>12</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>6</day>
<month>10</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Aitchison, Lengyel</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005186"/>
<abstract>
<p>Probabilistic inference offers a principled framework for understanding both behaviour and cortical computation. However, two basic and ubiquitous properties of cortical responses seem difficult to reconcile with probabilistic inference: neural activity displays prominent oscillations in response to constant input, and large transient changes in response to stimulus onset. Indeed, cortical models of probabilistic inference have typically either concentrated on tuning curve or receptive field properties and remained agnostic as to the underlying circuit dynamics, or had simplistic dynamics that gave neither oscillations nor transients. Here we show that these dynamical behaviours may in fact be understood as hallmarks of the specific representation and algorithm that the cortex employs to perform probabilistic inference. We demonstrate that a particular family of probabilistic inference algorithms, Hamiltonian Monte Carlo (HMC), naturally maps onto the dynamics of excitatory-inhibitory neural networks. Specifically, we constructed a model of an excitatory-inhibitory circuit in primary visual cortex that performed HMC inference, and thus inherently gave rise to oscillations and transients. These oscillations were not mere epiphenomena but served an important functional role: speeding up inference by rapidly spanning a large volume of state space. Inference thus became an order of magnitude more efficient than in a non-oscillatory variant of the model. In addition, the network matched two specific properties of observed neural dynamics that would otherwise be difficult to account for using probabilistic inference. First, the frequency of oscillations as well as the magnitude of transients increased with the contrast of the image stimulus. Second, excitation and inhibition were balanced, and inhibition lagged excitation. These results suggest a new functional role for the separation of cortical populations into excitatory and inhibitory neurons, and for the neural oscillations that emerge in such excitatory-inhibitory networks: enhancing the efficiency of cortical computations.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Our brain operates in the face of substantial uncertainty due to ambiguity in the inputs, and inherent unpredictability in the environment. Behavioural and neural evidence indicates that the brain often uses a close approximation of the optimal strategy, probabilistic inference, to interpret sensory inputs and make decisions under uncertainty. However, the circuit dynamics underlying such probabilistic computations are unknown. In particular, two fundamental properties of cortical responses, the presence of oscillations and transients, are difficult to reconcile with probabilistic inference. We show that excitatory-inhibitory neural networks are naturally suited to implement a particular inference algorithm, Hamiltonian Monte Carlo. Our network showed oscillations and transients like those found in the cortex and took advantage of these dynamical motifs to speed up inference by an order of magnitude. These results suggest a new functional role for the separation of cortical populations into excitatory and inhibitory neurons, and for the neural oscillations that emerge in such excitatory-inhibitory networks: enhancing the efficiency of cortical computations.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000324</institution-id>
<institution>Gatsby Charitable Foundation</institution>
</institution-wrap>
</funding-source>
<principal-award-recipient>
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3681-4607</contrib-id>
<name name-style="western">
<surname>Aitchison</surname> <given-names>Laurence</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100004963</institution-id>
<institution>Seventh Framework Programme</institution>
</institution-wrap>
</funding-source>
<award-id>FP7/2007–2013 269921</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Lengyel</surname> <given-names>Máté</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by the Wellcome Trust (ML), the Gatsby Charitable Foundation (LA), and the European Union Seventh Framework Programme (FP7/2007–2013) under grant agreement no. 269921 (BrainScaleS) (ML). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="1"/>
<page-count count="24"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All code is in the Supplementary Information file <xref ref-type="supplementary-material" rid="pcbi.1005186.s002">S1 Code</xref>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Uncertainty plagues neural computation. For instance, hearing the rustle of an animal at night, it may be impossible to ascertain the species, and thus whether or not it is dangerous. One approach in this scenario is to respond based on a point estimate, usually the single most probable explanation of our observations. However, this leads to a problem: if the probability of the animal being dangerous is below 50%, then the single most probable explanation is that the animal is harmless; and considering only this explanation, and thus failing to respond, could easily prove fatal. Instead, to respond appropriately, it is critical to take uncertainty into account by also considering the possibility of there being a dangerous animal, given the rustle and any other available clues.</p>
<p>The optimal way to perform computations and select actions under uncertainty is to represent a probability distribution that quantifies the probability with which each scenario may describe the actual state of the world, and update this probability distribution according to the laws of probability, i.e. by performing Bayesian inference. Human behaviour is consistent with Bayesian inference in many sensory [<xref ref-type="bibr" rid="pcbi.1005186.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1005186.ref004">4</xref>], motor [<xref ref-type="bibr" rid="pcbi.1005186.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref006">6</xref>] and cognitive [<xref ref-type="bibr" rid="pcbi.1005186.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1005186.ref009">9</xref>] tasks. There is also evidence that probabilistic inference is performed already in early sensory cortical areas [<xref ref-type="bibr" rid="pcbi.1005186.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref011">11</xref>]. In particular, simple cells in the primary visual cortex (V1) respond maximally to Gabor filter-like stimuli (i.e. edges), which have been shown to provide the most parsimonious explanation of natural images in probabilistic theories of visual processing [<xref ref-type="bibr" rid="pcbi.1005186.ref012">12</xref>] (or mathematically equivalent regularisation-based approaches [<xref ref-type="bibr" rid="pcbi.1005186.ref013">13</xref>]). Furthermore, more complex probabilistic models can account for contrast invariant tuning [<xref ref-type="bibr" rid="pcbi.1005186.ref014">14</xref>] and complex cell properties [<xref ref-type="bibr" rid="pcbi.1005186.ref015">15</xref>], as well as surround-suppression effects in neural data and behaviour [<xref ref-type="bibr" rid="pcbi.1005186.ref016">16</xref>].</p>
<p>The apparent success of probabilistic inference in accounting for a diverse set of experimental observations raises the question of how neural systems might represent and compute with uncertainty [<xref ref-type="bibr" rid="pcbi.1005186.ref017">17</xref>]. Nevertheless, traditional models of neural computation ignore uncertainty, and instead rely on circuit dynamics that find the single best explanation for their inputs [<xref ref-type="bibr" rid="pcbi.1005186.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref019">19</xref>]. More recent approaches do allow for the representation of uncertainty, including distributional [<xref ref-type="bibr" rid="pcbi.1005186.ref020">20</xref>], doubly distributed [<xref ref-type="bibr" rid="pcbi.1005186.ref021">21</xref>], and probabilistic population codes [<xref ref-type="bibr" rid="pcbi.1005186.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1005186.ref024">24</xref>], or sampling-based network dynamics [<xref ref-type="bibr" rid="pcbi.1005186.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref026">26</xref>]. However, none of these previous models capture the rich dynamics of cortical responses. In particular, neural activities in the cortex show prominent intrinsic oscillations [<xref ref-type="bibr" rid="pcbi.1005186.ref027">27</xref>], and large transient changes in response to stimulus onset, which are observed in V1 [<xref ref-type="bibr" rid="pcbi.1005186.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>], and other cortical areas [<xref ref-type="bibr" rid="pcbi.1005186.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref032">32</xref>]. In contrast, existing neural models of probabilistic inference either have no dynamics and so predict stationary responses to a fixed stimulus, or they have gradient ascent-like dynamics that display neither oscillations nor transients, and eventually also converge to a steady-state response for a fixed input. Moreover, these models typically violate Dale’s law, by having neurons with both excitatory and inhibitory outputs. While there have been excitatory-inhibitory (EI) network models that did capture some of these aspects of cortical dynamics, these have rarely been linked to any particular computation (but see [<xref ref-type="bibr" rid="pcbi.1005186.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref034">34</xref>]), let alone probabilistic inference.</p>
<p>Here, we present an EI neural network model of V1 that performs probabilistic inference such that it retains a computationally useful representation of uncertainty, and has rich, cortex-like dynamics, including oscillations and transients. In particular, our network uses a sampling-based representation of uncertainty [<xref ref-type="bibr" rid="pcbi.1005186.ref011">11</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref035">35</xref>], such that at any time it represents a single plausible interpretation of the input, and as time passes it sequentially samples many different interpretations. In other words, the network represents the probability of different scenarios implicitly, by the frequency with which it visits their representations via its dynamics. For instance, in the example above, neural activity at one moment would represent “dangerous”, then “not dangerous” at some later time, and then “dangerous” again, such that a decision about how to behave can then be made based on the proportion of the time neural activity represents “dangerous” vs. “not dangerous”. Thus, a fundamental consequence of a sampling-based representation for neural dynamics is that whenever there is uncertainty, neural activity will not settle down to a single fixed point but instead, it will continue to move between patterns representing the different possible states of the world. More specifically, an <italic>efficient</italic> sampling-based representation requires this continuous movement across state space to be such that the rate at which (statistically independent) samples are generated by the dynamics is as high as possible. We show that EI networks are ideally suited to achieve efficient sampling by implementing a powerful family of probabilistic inference algorithms, Hamiltonian Monte Carlo (HMC) [<xref ref-type="bibr" rid="pcbi.1005186.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref037">37</xref>].</p>
<p>HMC is based on the idea that it is possible to sample from a probability distribution by setting up a dynamical system whose dynamics is Hamiltonian (<xref ref-type="fig" rid="pcbi.1005186.g001">Fig 1A</xref>). The state of such a system behaves as a particle moving on a (high dimensional) surface, frictionless but with momentum. The surface determines the potential energy of the particle, corresponding to the negative logarithm of the probability distribution that needs to be sampled (such that high probability states correspond to low potential energy). These dynamics speed up inference because the momentum of the system prevents the random walk behaviour plaguing many other sampling-based inference schemes. In particular, the particle will accelerate as it heads towards the minimum of the potential energy landscape, but once it reaches that point, it will have a large momentum, so it will keep moving out the other side (<xref ref-type="fig" rid="pcbi.1005186.g001">Fig 1A–1D</xref>). Our key insight is that HMC dynamics are naturally implemented by the interactions of recurrently coupled excitatory and inhibitory populations in cortical circuits. Due to these interactions, our network possessed inherently oscillatory dynamics. Crucially, these oscillations were ideal for speeding up inference, as they moved rapidly across the state space and hence represented a whole range of plausible interpretations efficiently.</p>
<fig id="pcbi.1005186.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005186.g001</object-id>
<label>Fig 1</label>
<caption>
<title>An example of Hamiltonian dynamics.</title>
<p><bold>A.</bold> Movement of a particle under Hamiltonian dynamics (i.e. with momentum) on a two-dimensional quadratic potential energy landscape (greyscale, darker means lower energy) corresponding to a multivariate Gaussian probability density. The red arrows show the trajectory, with each arrow representing an equal time interval. Note that the particle does not just go to the lowest potential energy location: it picks up momentum (kinetic energy) as it moves, leading it to oscillate around the energy well. <bold>B.</bold> A plot of position (red) and velocity (blue, the derivative of position) along one dimension. <bold>C.</bold> Plotting velocity and position directly against each other reveals explicitly that the dynamics of the system is similar to that of a harmonic oscillator. <bold>D.</bold> Plotting kinetic energy (KE) against potential energy (PE) reveals an exchange between kinetic energy and potential energy that contributes to the system’s oscillatory behaviour.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.g001" xlink:type="simple"/>
</fig>
<p>In the following, we first define the statistical model of natural visual scenes that served as the testbed for our simulations of V1 dynamics. We then describe the HMC-based neural network that implemented sampling under this statistical model. We demonstrate that our dynamics sample more rapidly than noisy gradient ascent (also known as Langevin dynamics), and therefore that the presence of oscillations and transients in our network speeds up inference. Next, we show by both theoretical analysis and simulation that our sampler reproduces three properties of experimentally observed cortical dynamics. First, our sampler has balanced excitation and inhibition, with inhibition lagging excitation [<xref ref-type="bibr" rid="pcbi.1005186.ref038">38</xref>]. Second, our sampler oscillates, and the oscillation frequency increases with stimulus contrast [<xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref039">39</xref>]. Third, there is a transient increase in firing rates upon stimulus onset, and the magnitude of this transient is also modulated by stimulus contrast [<xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>]. Thus, our work provides a principled unifying account of these dynamical motifs by relating them to a fundamental class of cortical computations: probabilistic inference.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>The Gaussian scale mixture model and V1 responses</title>
<p>In order to model the dynamics of V1 responses, we adopted a statistical model that has been widely used to capture the statistics of natural images and consequently to account for the <italic>stationary</italic> responses of V1 neurons in terms of probabilistic inference. We extended this model to account for the <italic>dynamics</italic> of V1 responses.</p>
<p>The Gaussian scale mixture (GSM) model is relatively simple, yet captures some fundamental higher-order statistical properties of natural image patches by introducing latent variables, <bold>u</bold>, coordinating the linear superposition of simple edge features and an additional latent variable, <italic>z</italic>, determining the overall contrast level of the image patch [<xref ref-type="bibr" rid="pcbi.1005186.ref040">40</xref>] (<xref ref-type="fig" rid="pcbi.1005186.g002">Fig 2A</xref>). Formally, the probabilistic generative model can be written as
<disp-formula id="pcbi.1005186.e001"><alternatives><graphic id="pcbi.1005186.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mrow><mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="("><mml:mi mathvariant="bold">u</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close="" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>;</mml:mo> <mml:mn mathvariant="bold">0</mml:mn> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">C</mml:mi> <mml:mo>)</mml:mo></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
<disp-formula id="pcbi.1005186.e002"><alternatives><graphic id="pcbi.1005186.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mrow><mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="("><mml:mi>z</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">T</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi>z</mml:mi> <mml:mo>;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
<disp-formula id="pcbi.1005186.e003"><alternatives><graphic id="pcbi.1005186.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mrow><mml:mi>P</mml:mi> <mml:mtext> </mml:mtext><mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>;</mml:mo> <mml:mi>z</mml:mi> <mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mi mathvariant="bold">I</mml:mi></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
where <inline-formula id="pcbi.1005186.e004"><alternatives><graphic id="pcbi.1005186.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mo>(</mml:mo> <mml:mo>·</mml:mo> <mml:mo>;</mml:mo> <mml:mi mathvariant="bold-italic">μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is a multivariate distribution with mean <bold><italic>μ</italic></bold> and covariance <bold>Σ</bold>, <inline-formula id="pcbi.1005186.e005"><alternatives><graphic id="pcbi.1005186.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:mi mathvariant="script">T</mml:mi> <mml:mtext> </mml:mtext><mml:mo>(</mml:mo> <mml:mo>·</mml:mo> <mml:mo>;</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is a truncated (univariate) normal distribution with mean <italic>μ</italic> and variance <italic>σ</italic><sup>2</sup> truncated below threshold <italic>θ</italic> (so that, in our case, <italic>z</italic> is non-negative), <bold>x</bold> is the grey levels of pixels in an image patch, the columns of <bold>A</bold> include the edge-like features whose combinations are used to explain images (<xref ref-type="fig" rid="pcbi.1005186.g002">Fig 2B</xref>), <bold>C</bold> describes their prior covariance (which is fitted to whitened data), and <inline-formula id="pcbi.1005186.e006"><alternatives><graphic id="pcbi.1005186.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msubsup><mml:mo>σ</mml:mo> <mml:mtext>x</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>1</mml:mn></mml:math></alternatives></inline-formula> is the level of noise present in the images. (See <xref ref-type="table" rid="pcbi.1005186.t001">Table 1</xref> for all parameters in the model, and <xref ref-type="sec" rid="sec010">Methods</xref> for details of the procedure used to set them.)</p>
<fig id="pcbi.1005186.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005186.g002</object-id>
<label>Fig 2</label>
<caption>
<title/>
<p><bold>A.</bold> The graphical model representation of the Gaussian scale mixture model. The distribution over the observations (images), <bold>x</bold>, depends on two latent variables, <italic>z</italic> and <bold>u</bold>. The vector <bold>u</bold> represents the intensity of edge-like features (see panel B) in the images. The positive scalar <italic>z</italic> represents the overall contrast level in the image. <bold>B.</bold> The basis functions represented by <bold>u</bold> were 15 Gabor filters centred at five different locations, and with three different orientations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.g002" xlink:type="simple"/>
</fig>
<table-wrap id="pcbi.1005186.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005186.t001</object-id>
<label>Table 1</label>
<caption>
<title>Values of the parameters used in our simulations.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005186.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="left">Value</th>
<th align="left">Role</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><bold>C</bold></td>
<td align="left">
<inline-formula id="pcbi.1005186.e007">
<alternatives>
<graphic id="pcbi.1005186.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e007" xlink:type="simple"/>
<mml:math display="inline" id="M7">
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mn>1</mml:mn>
<mml:mo>-</mml:mo>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi mathvariant="bold">x</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
<mml:mo>)</mml:mo>
<mml:msup>
<mml:mrow><mml:mo>(</mml:mo>
<mml:msup>
<mml:mi mathvariant="bold">A</mml:mi>
<mml:mi>T</mml:mi>
</mml:msup>
<mml:mi mathvariant="bold">A</mml:mi>
<mml:mo>)</mml:mo></mml:mrow>
<mml:mrow>
<mml:mo>-</mml:mo>
<mml:mn>1</mml:mn>
</mml:mrow>
</mml:msup>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">prior covariance of <bold>u</bold></td>
</tr>
<tr>
<td align="left"><bold>A</bold></td>
<td align="left">See <xref ref-type="fig" rid="pcbi.1005186.g002">Fig 2B</xref> and <xref ref-type="sec" rid="sec010">Methods</xref></td>
<td align="left">edge-detecting filters represented by model neurons</td>
</tr>
<tr>
<td align="left">
<inline-formula id="pcbi.1005186.e008">
<alternatives>
<graphic id="pcbi.1005186.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e008" xlink:type="simple"/>
<mml:math display="inline" id="M8">
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi mathvariant="normal">x</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">0.1</td>
<td align="left">variance of observation noise</td>
</tr>
<tr>
<td align="left"><italic>τ</italic></td>
<td align="left">10 ms</td>
<td align="left">membrane time constant</td>
</tr>
<tr>
<td align="left"><italic>ρ</italic><sup>2</sup></td>
<td align="left">13 s<sup>−1</sup></td>
<td align="left">rate at which stochastic vesicle release injects noise</td>
</tr>
<tr>
<td align="left"><bold>W</bold><sub>uu</sub>, <bold>W</bold><sub>uv</sub>, etc.</td>
<td align="left">See <xref ref-type="sec" rid="sec010">Methods</xref></td>
<td align="left">recurrent connection weights in the network</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001"><p>See <xref ref-type="sec" rid="sec010">Methods</xref> for details of the procedure used to determine the parameters. Oscillation frequency in the network was jointly determined by several of these parameters (see <xref ref-type="disp-formula" rid="pcbi.1005186.e014">Eq 8</xref>), the timescale of transients was mainly determined by <italic>ρ</italic> (see <xref ref-type="supplementary-material" rid="pcbi.1005186.s001">S1 Fig</xref>).</p></fn>
</table-wrap-foot>
</table-wrap>
<p>Crucially, assuming that V1 simple cell activities represent values of <bold>u</bold> sampled from the posterior over <bold>u</bold> given an input <bold>x</bold> under the GSM, <italic>P</italic> (<bold>u</bold>|<bold>x</bold>), provides a natural account for a number of empirical observations. (Conversely, inference of <italic>z</italic> may provide an account of complex-cell activations [<xref ref-type="bibr" rid="pcbi.1005186.ref041">41</xref>–<xref ref-type="bibr" rid="pcbi.1005186.ref043">43</xref>], which we did not study in further detail here.) In particular, the posterior mean of <bold>u</bold>, represented by the mean of model neuron activities, matches the across-trial average responses of simple cells in V1 [<xref ref-type="bibr" rid="pcbi.1005186.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref044">44</xref>]. Moreover, it can also be shown that the posterior variance of <bold>u</bold>, represented by the variance of model neuron activities, captures important aspects of the across-trial variance of V1 responses [<xref ref-type="bibr" rid="pcbi.1005186.ref011">11</xref>], namely the quenching of neural variability with stimulus onset [<xref ref-type="bibr" rid="pcbi.1005186.ref045">45</xref>]. This is because, in the no-stimulus condition, we have a blank image, <bold>x</bold> = <bold>0</bold>. Under the GSM, <bold>x</bold> ≈ <italic>z</italic><bold>A</bold><bold>u</bold>, so while it is possible to explain a blank image by setting every single element of <bold>u</bold> very close to 0 (or, more generally, tuning <bold>u</bold> to be in the nullspace of <bold>A</bold>), a far more parsimonious, and probable, explanation is that <italic>z</italic> (a single scalar) is close to 0. Importantly, if <italic>z</italic> is close to 0, then <bold>x</bold> does not constrain <bold>u</bold>. Plausible values for <bold>u</bold> therefore cover a broad range (defined by the prior over <bold>u</bold>), so <bold>u</bold> and hence neural activity, can be highly variable. In contrast, if there is a stimulus, <bold>x</bold> ≉ <bold>0</bold>, we must also have <italic>z</italic> ≉ 0, in which case <bold>x</bold> tightly constrains the range of plausible values of <bold>u</bold> (as <bold>x</bold> ≈ <italic>z</italic><bold>A</bold><bold>u</bold>), leading to lower variability. Moreover, the model naturally implements a form of divisive gain control: a very large <bold>x</bold> can be accounted for by making <italic>z</italic>, rather than <bold>u</bold>, large [<xref ref-type="bibr" rid="pcbi.1005186.ref046">46</xref>]. This agreement between the probabilistic model and empirically observed patterns of neural activity is our key motivation for choosing to use the GSM model as our testbed and asking what plausible neural network dynamics may be appropriate for sampling from its posterior distribution.</p>
</sec>
<sec id="sec004">
<title>Hamiltonian Monte Carlo in an EI network</title>
<p>To ensure efficient sampling from the posterior, we constructed network dynamics based on the core principles of HMC sampling. The efficiency of HMC stems from its ability to speed up inference by preventing the random walk behaviour plaguing other sampling-based inference schemes. In particular, it introduces auxiliary variables to complement the ‘principal’ variables whose value needs to be inferred (<bold>u</bold> in the case of the GSM). Although this extension of the state space seemingly makes computations more challenging, it allows inference to be substantially more efficient when dynamical interactions between the two groups of variables are set up appropriately.</p>
<p>We noted that the particular interaction between principal and auxiliary variables required by HMC dynamics is naturally implemented by the recurrently connected excitatory and inhibitory populations of cortical circuits. Thus, the dynamics of our two-population neural network that sampled from the GSM posterior were (<xref ref-type="fig" rid="pcbi.1005186.g003">Fig 3</xref>, see <xref ref-type="sec" rid="sec010">Methods</xref> for a full derivation):
<disp-formula id="pcbi.1005186.e009"><alternatives><graphic id="pcbi.1005186.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e009" xlink:type="simple"/><mml:math display="block" id="M9"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfenced close="]" open="[" separators=""><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>uu</mml:mtext></mml:msub> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>uv</mml:mtext></mml:msub> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>+</mml:mo> <mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac></mml:mstyle> <mml:mi>τ</mml:mi> <mml:msup><mml:mi>ρ</mml:mi> <mml:mn>2</mml:mn></mml:msup><mml:mtext> </mml:mtext> <mml:msub><mml:mi mathvariant="bold">I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub></mml:mfenced> <mml:mo>+</mml:mo> <mml:mi>ρ</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
<disp-formula id="pcbi.1005186.e010"><alternatives><graphic id="pcbi.1005186.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfenced close="]" open="[" separators=""><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>vu</mml:mtext></mml:msub> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>vv</mml:mtext></mml:msub> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub></mml:mfenced> <mml:mo>+</mml:mo> <mml:mi>ρ</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
where <bold><italic>η</italic></bold><sub>u</sub> and <bold><italic>η</italic></bold><sub>v</sub> denotes standard normal white noise (or, more precisely, the differential of a Wiener processes), the <bold>W</bold> matrices are the recurrent synaptic weight matrices between the two populations of cells (defined in the <xref ref-type="sec" rid="sec010">Methods</xref>), such that all their elements are positive, and
<disp-formula id="pcbi.1005186.e011"><alternatives><graphic id="pcbi.1005186.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mrow><mml:msub><mml:mi mathvariant="bold">I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>z</mml:mi> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mspace width="0.166667em"/><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>-</mml:mo> <mml:mi>z</mml:mi> <mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced> <mml:mo>-</mml:mo> <mml:mrow><mml:msup><mml:mi mathvariant="bold">C</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:math></alternatives> <label>(6)</label></disp-formula>
is an input current. Under these dynamics, the principal <italic>u</italic><sub><italic>i</italic></sub> and auxiliary variables <italic>v</italic><sub><italic>i</italic></sub> corresponded to the membrane potentials of individual neurons (or the average membrane potential of small populations of cells), and for any input <bold>x</bold>, the stationary distribution of <bold>u</bold> was guaranteed to be identical to the corresponding posterior distribution under the GSM.</p>
<fig id="pcbi.1005186.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005186.g003</object-id>
<label>Fig 3</label>
<caption>
<title>The architecture of the Hamiltonian network.</title>
<p>The network consists of two populations of neurons, excitatory neurons with membrane potential <bold>u</bold>, and inhibitory neurons <bold>v</bold>, driven by external input <bold>I</bold><sub>input</sub>. Neurons in the network are recurrently coupled by synaptic weights, <bold>W</bold><sub>uu</sub>, <bold>W</bold><sub>uv</sub>, <bold>W</bold><sub>vu</sub> and <bold>W</bold><sub>vv</sub>. Red arrows represent excitation; blue bars represent inhibition.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.g003" xlink:type="simple"/>
</fig>
<p>Network dynamics consisted of three components. First, recurrent dynamics implementing HMC was specified by the first two terms in Eqs (<xref ref-type="disp-formula" rid="pcbi.1005186.e009">4</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005186.e010">5</xref>), <bold>W</bold><sub>uu</sub> <bold>u</bold> − <bold>W</bold><sub>uv</sub> <bold>v</bold> and <bold>W</bold><sub>vu</sub> <bold>u</bold> − <bold>W</bold><sub>vv</sub> <bold>v</bold>. As the elements of the <bold>W</bold> matrices were all positive (see above), the recurrent circuit implied by these dynamics had an EI structure, with <bold>u</bold> corresponding to excitatory cells and <bold>v</bold> to inhibitory cells.</p>
<p>Second, there was an input current <bold>I</bold><sub>input</sub>, whose strength was scaled by the (inferred) level of contrast, <italic>z</italic> (<xref ref-type="disp-formula" rid="pcbi.1005186.e011">Eq 6</xref>). Note again that while this signal might increase with <italic>z</italic>, it is a prediction error, so it has a highly non-trivial relationship with the resulting response. In fact, it can be shown that the response actually saturates as contrast increases (and results in tuning curves with contrast invariant width) [<xref ref-type="bibr" rid="pcbi.1005186.ref011">11</xref>]. This input current specified the probabilistic model by conveying a prediction error, i.e. the difference between the input image, <bold>x</bold>, and the image predicted by the current activities of the excitatory neurons, <italic>z</italic><bold>A</bold><bold>u</bold>, plus a term penalizing the violation of prior expectations about <bold>u</bold>. While the key focus of our paper is the EI circuit implementing HMC, rather than the specific form for the input (of which the details depend on the underlying probabilistic model, here the admittedly simplified GSM model), we suggest a potential implementation of <bold>I</bold><sub>input</sub> by a separate population of neurons directly representing the prediction error (<bold>x</bold> − <italic>z</italic><bold>A</bold><bold>u</bold>) as in theories of predictive coding [<xref ref-type="bibr" rid="pcbi.1005186.ref018">18</xref>]. Such cells (perhaps in the lateral geniculate nucleus, LGN) would have an excitatory connection from upstream areas (the retina), representing the data, and an inhibitory disynaptic connection from the excitatory cells, <bold>u</bold>. The output from these cells needs to excite the excitatory cells and inhibit the inhibitory cells of our circuit, which can again be implemented via disynaptic inhibition. This form of input is particularly well-suited to give strong, long-lasting activation of the EI circuit, as the increase in excitation reinforces the decrease in inhibition.</p>
<p>Finally, the last term in Eqs (<xref ref-type="disp-formula" rid="pcbi.1005186.e009">4</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1005186.e010">5</xref>) represented noise. Although these dynamics were clearly simplified in that they were fundamentally linear, such dynamical systems have been used to model a wide variety of neural processes [<xref ref-type="bibr" rid="pcbi.1005186.ref047">47</xref>–<xref ref-type="bibr" rid="pcbi.1005186.ref049">49</xref>]. Previous work has also shown that neurons combining firing-rate nonlinearities with short-term synaptic plasticity and dendritic nonlinearities can implement such effectively linear membrane potential dynamics [<xref ref-type="bibr" rid="pcbi.1005186.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref051">51</xref>]. Moreover, such models have been found to provide a good match to the dynamics of cortical populations at the level of field potentials [<xref ref-type="bibr" rid="pcbi.1005186.ref052">52</xref>], calcium signals [<xref ref-type="bibr" rid="pcbi.1005186.ref053">53</xref>], and firing rate trajectories [<xref ref-type="bibr" rid="pcbi.1005186.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref054">54</xref>]. We set the parameters of the network to lie in a biologically realistic regime (<xref ref-type="table" rid="pcbi.1005186.t001">Table 1</xref>, <xref ref-type="sec" rid="sec010">Methods</xref>).</p>
</sec>
<sec id="sec005">
<title>Oscillations contribute to efficient sampling</title>
<p>When given an input image, our network exhibited oscillatory dynamics due to its intrinsic excitatory-inhibitory interactions (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4A</xref>). Intuitively, these oscillations were useful for inference as they allowed the network to cover a broad range of plausible interpretations of its input within each oscillation cycle. In order to assess more rigorously the computational use of these oscillations, we compared our network to a non-oscillatory counterpart, called Langevin sampling [<xref ref-type="bibr" rid="pcbi.1005186.ref055">55</xref>] (<xref ref-type="sec" rid="sec010">Methods</xref>). For a fair comparison of the two samplers, we set them up to sample from the same posterior, and we kept the noise level <italic>ρ</italic> the same in them.</p>
<fig id="pcbi.1005186.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005186.g004</object-id>
<label>Fig 4</label>
<caption>
<title>The Hamiltonian sampler is more efficient than a Langevin sampler.</title>
<p><bold>A, B.</bold> Example membrane potential traces for a randomly selected neuron in the Hamiltonian network (<bold>A</bold>) and the Langevin network (<bold>B</bold>). <bold>C.</bold> Solid lines: the autocorrelation of membrane potential traces in <bold>A</bold> and <bold>B</bold>, for Hamiltonian (red) and Langevin samplers (blue). Dashed lines: the autocorrelation of the joint (log) probability for Hamiltonian (red) and Langevin samplers (blue). Note that for the Hamiltonian sampler, the joint probability is over both <bold>u</bold> and <bold>v</bold>. <bold>D, E.</bold> Joint membrane potential traces from two randomly selected neurons in the Hamiltonian network (<bold>D</bold>) and the Langevin network (<bold>E</bold>), colour indicates time (from red to green, spanning 25 ms), grey scale map shows the (logarithm of the) underlying posterior (its marginal over the two dimensions shown). <bold>F.</bold> Normalised mean square error (MSE) between the true mean and the mean estimate from samples taken over a time <italic>t</italic> for the Langevin (blue) and Hamiltonian dynamics (red), with 100 repetitions (mean ± 2 s.e.m.).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.g004" xlink:type="simple"/>
</fig>
<p>The Langevin sampler was constructed by setting the recurrent weights in our network (<bold>W</bold> matrices) to zero. Although, in general, a Langevin sampler can still have recurrent connectivity, at least among the principal cells (by interpreting the dependence of <bold>I</bold><sub>input</sub> on <bold>u</bold> as recurrent connections [<xref ref-type="bibr" rid="pcbi.1005186.ref056">56</xref>]), these recurrent connections are necessarily symmetric and therefore fundamentally different in nature from the EI interactions that we consider here. As a consequence, Langevin dynamics showed prominent random walk-like behaviour without oscillations (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4B</xref>). Comparing the autocorrelation functions for the Hamiltonian and Langevin samplers revealed that while their autocorrelation functions decayed at similar rates (controlled by the timescale of the stochastic, Langevin component), the HMC had an additional, oscillating component, allowing it to rapidly explore the state space (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4C</xref>).</p>
<p>The oscillatory behaviour of our HMC sampler allowed it to explore a larger volume of state space in a fixed time interval than Langevin sampling (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4D and 4E</xref>). To compare the sampling performance of HMC and Langevin dynamics rigorously, we measured for both of them the error between a sample-based estimate of the posterior mean and the true mean of the posterior. The samples from the Hamiltonian sampler took very little time to give a good estimate of the mean (73 ms to get the mean square error to the level obtainable by a single statistically fair sample), whereas samples from the Langevin model took ∼4 times longer (273 ms, <xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4F</xref>). This difference indicated that our HMC-inspired sampler used limited noise far more efficiently than Langevin dynamics.</p>
<p>The efficiency of HMC is typically attributed to the suppression of the random walk behaviour of Langevin dynamics [<xref ref-type="bibr" rid="pcbi.1005186.ref037">37</xref>]. In our network, we were able to relate this effect more specifically to the appearance of oscillations. HMC dynamics had both an oscillatory and a stochastic component (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4A and 4C</xref> red), whereas Langevin dynamics had only the stochastic component, so that it performed simple noisy gradient ascent, without apparent oscillations (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4B and 4C</xref> blue). In particular, oscillations in the HMC sampler had a time scale that was a factor of 15 faster than that of the stochastic component shared with Langevin dynamics. This fast time constant of the HMC sampler, <italic>τ</italic>, governed the effects of recurrent EI interactions, which were mediated by the <bold>W</bold> matrices that the Langevin sampler lacked (<xref ref-type="disp-formula" rid="pcbi.1005186.e042">Eq 32</xref>). These architectural and dynamical differences implied a fundamentally different strategy for exploring the state space of these networks. The fast oscillations in the HMC sampler deterministically explored states in (<bold>u</bold>, <bold>v</bold>)-space that lay on an equiprobability manifold, while the slow time scale implied by the input noise served to change this manifold stochastically (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4D</xref>). Indeed, the autocorrelogram of the energy (log posterior probability) in the HMC sampler (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4C</xref>, red dashed curve) was identical to the Langevin envelope of the autocorrelogram of states (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4C</xref>, red solid curve), indicating that energy only changed on the slow time scale governed by this stochastic component and not on the fast time scale of oscillations. (Note that while moving along equiprobability contours in the full joint (<bold>u</bold>, <bold>v</bold>) space, HMC dynamics may still cross probability contours when projected to a low dimensional marginal, as shown in <xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4D</xref>.) In contrast, Langevin dynamics could only rely on this slow stochastic component resulting in slow movement across energy levels (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4C</xref>, blue dashed curve) and the state space (<xref ref-type="fig" rid="pcbi.1005186.g004">Fig 4C</xref>, blue solid curve).</p>
</sec>
<sec id="sec006">
<title>Balance between excitation and inhibition</title>
<p>As we saw above, the advantage of HMC over Langevin dynamics could be attributed to the contribution of the recurrent connections, i.e. the <bold>W</bold><sub>uu</sub> <bold>u</bold> − <bold>W</bold><sub>uv</sub> <bold>v</bold> and <bold>W</bold><sub>vu</sub> <bold>u</bold> − <bold>W</bold><sub>vv</sub> <bold>v</bold> terms in the dynamics (Eqs <xref ref-type="disp-formula" rid="pcbi.1005186.e009">4</xref> and <xref ref-type="disp-formula" rid="pcbi.1005186.e010">5</xref>), which respectively expressed the difference between net excitation and inhibition received by each excitatory and inhibitory neuron. (Note that this difference was not affected by <bold>I</bold><sub>input</sub> as the prediction error conveyed by the input is zero on average for any input, by definition.) Importantly, for HMC to sample from the correct posterior, the dynamics of excitatory cells needed to track the prediction error conveyed by <bold>I</bold><sub>input</sub>, for which the recurrent term needed to be zero on average, which in turn suggests that excitation and inhibition needed to track each other across different stimuli (<xref ref-type="fig" rid="pcbi.1005186.g005">Fig 5A</xref>). Indeed, the only way we could obtain Hamiltonian dynamics that complied with Dale’s law was if the activity of inhibitory cells tracked that of excitatory cells, i.e. if the network was balanced. As Langevin is equivalent to having these terms set to zero, for HMC to realize its advantage over Langevin, the variance of the recurrent term needed to be sufficiently large, which implied that the magnitudes of net excitation and net inhibition each needed to be large and momentarily imbalanced (<xref ref-type="fig" rid="pcbi.1005186.g005">Fig 5B</xref>). These features, large excitatory and inhibitory currents that are tracking each other with momentary perturbations, are thought to be fundamental properties of the dynamical regime in which the cortex operates [<xref ref-type="bibr" rid="pcbi.1005186.ref038">38</xref>], and thus arise naturally from HMC dynamics in our EI network. Furthermore, as expected in a network with an EI architecture, excitation led inhibition in our network (<xref ref-type="fig" rid="pcbi.1005186.g005">Fig 5C</xref>).</p>
<fig id="pcbi.1005186.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005186.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Excitation and inhibition are balanced in the Hamiltonian network.</title>
<p><bold>A.</bold> Trial-average excitatory input vs. trial-average inhibitory input across trials (dots) for a randomly selected individual cell in the network. <bold>B.</bold> Total inhibitory input to a single cell (blue) closely tracks but slightly lags total excitatory input (red) over the course of a trial. <bold>C.</bold> The cross-correlation between the average excitatory and average inhibitory membrane potentials shows a peak that is offset from 0 time.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>Stimulus-dependent oscillations</title>
<p>Oscillations are a ubiquitous property of cortical dynamics [<xref ref-type="bibr" rid="pcbi.1005186.ref057">57</xref>], and we have shown above that efficient sampling in HMC necessarily leads to oscillatory dynamics in general (Figs <xref ref-type="fig" rid="pcbi.1005186.g004">4</xref> and <xref ref-type="fig" rid="pcbi.1005186.g005">5</xref>). However, when applied specifically to perform inference based on visual images (<xref ref-type="fig" rid="pcbi.1005186.g002">Fig 2</xref>), our model also reproduced some more specific and robust properties of gamma-band oscillations in V1, namely that the precise frequency of these oscillations increases with stimulus contrast [<xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref039">39</xref>] (<xref ref-type="fig" rid="pcbi.1005186.g006">Fig 6</xref>).</p>
<fig id="pcbi.1005186.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005186.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Oscillation frequency depends on stimulus contrast.</title>
<p><bold>A.</bold> The membrane potential response of one neuron to stimulus onset across 4 trials (coloured curves) shows that the variability decreases and the frequency increases as stimulus contrast increases. The true contrast of the underlying image increases left to right (<italic>z</italic><sub>gen</sub> = 0.5, 1, and 2). <bold>B.</bold> Power spectrum of the LFP (average membrane potentials) at different contrasts (coloured lines), showing that dominant oscillation frequency increases with contrast. Note that we plot power × frequency on the y-axis, in order to account for the fact that noise from a “scale-free” process has 1/f frequency dependence [<xref ref-type="bibr" rid="pcbi.1005186.ref059">59</xref>]. <bold>C.</bold> Time-dependent spectrum (Gaussian window, width 100 ms) of the LFP (contrast levels as in <bold>A</bold>). <bold>D.</bold> The simplified dynamics (x-axis, <xref ref-type="disp-formula" rid="pcbi.1005186.e014">Eq 8</xref>) accurately predicted the dependence of oscillation frequencies on contrast (colour code as in B) in the full network (y-axis).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.g006" xlink:type="simple"/>
</fig>
<p>In order to extract an LFP from our model, in line with previous approaches (e.g. [<xref ref-type="bibr" rid="pcbi.1005186.ref058">58</xref>]), we computed the sum of membrane potentials of all cells. (Using the sum of input currents instead would have yielded qualitatively similar results.) The fact that LFP oscillations in our model were in the gamma band, i.e. around 40 Hz, was simply due to our choice of a realistic single neuron time constant, <italic>τ</italic> = 10ms. However, within this band, the modulation of the oscillation frequency by the contrast of the input image was a more specific characteristic of the dynamics of our network. As contrast increased, the amount of evidence to pin down <bold>u</bold> increased, and so the GSM posterior from which the dynamics needed to sample became tighter [<xref ref-type="bibr" rid="pcbi.1005186.ref011">11</xref>]. At the same time, the recurrent EI interactions of the HMC dynamics which gave rise to oscillations had a fixed time scale independent of the input (Eqs <xref ref-type="disp-formula" rid="pcbi.1005186.e009">4</xref> and <xref ref-type="disp-formula" rid="pcbi.1005186.e010">5</xref>). Using the same speed to traverse an equiprobability manifold of an increasingly tight posterior thus naturally led to increasing oscillation frequencies.</p>
<p>To further quantify this intuition, we simplified the dynamics of our network by incorporating the effects of inhibition directly into the equations describing the dynamics of the excitatory cells (see <xref ref-type="sec" rid="sec010">Methods</xref>):
<disp-formula id="pcbi.1005186.e012"><alternatives><graphic id="pcbi.1005186.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¨</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mfrac> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msup><mml:mi>z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mfenced> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(7)</label></disp-formula>
where <inline-formula id="pcbi.1005186.e013"><alternatives><graphic id="pcbi.1005186.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mtext>E </mml:mtext> <mml:mo>[</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the (stimulus-dependent) mean of the posterior over <bold>u</bold>. This form explicitly exposes that our sampler (in the limit studied here) underwent regular harmonic oscillations, whose frequency increased with stimulus contrast, <italic>z</italic><sub>gen</sub> (assuming that the inferred value of <italic>z</italic> was sufficiently close to the actual stimulus contrast, i.e. <italic>z</italic> ≃ <italic>z</italic><sub>gen</sub>), as
<disp-formula id="pcbi.1005186.e014"><alternatives><graphic id="pcbi.1005186.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e014" xlink:type="simple"/><mml:math display="block" id="M14"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:mi>τ</mml:mi></mml:mrow></mml:mfrac> <mml:msqrt><mml:mrow><mml:mfrac><mml:msubsup><mml:mi>z</mml:mi> <mml:mtext>gen</mml:mtext> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:msqrt></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula></p>
<p>Indeed, as predicted by these arguments, the network exhibited contrast-dependent oscillation frequencies both in its membrane potentials (<xref ref-type="fig" rid="pcbi.1005186.g006">Fig 6A</xref>) and LFPs (<xref ref-type="fig" rid="pcbi.1005186.g006">Fig 6B and 6C</xref>; note that in B, we account for the fact that a “scale-free” noise process has 1/<italic>f</italic> frequency dependence [<xref ref-type="bibr" rid="pcbi.1005186.ref059">59</xref>] by plotting power × frequency on the y-axis). Furthermore, the quantitative predictions made by <xref ref-type="disp-formula" rid="pcbi.1005186.e014">Eq 8</xref> were in close agreement with the results of numerical simulations in the the full model, where <italic>z</italic> is not fixed, but is inferred simultaneously with <bold>u</bold> (<xref ref-type="fig" rid="pcbi.1005186.g006">Fig 6D</xref>).</p>
</sec>
<sec id="sec008">
<title>Stimulus-dependent transients</title>
<p>When we computed firing rates in the model by applying a threshold to membrane potentials (<xref ref-type="disp-formula" rid="pcbi.1005186.e081">Eq 60</xref>), our simulations showed large, contrast-dependent transient increases in population firing rate at stimulus onset (<xref ref-type="fig" rid="pcbi.1005186.g007">Fig 7A</xref>). (Were we to consider the average membrane potential, this would not display such a large transient, because some neurons undergo positive transients, and others undergo negative transients, which cancel overall.) Such transients are also a widely observed characteristic of responses in V1 [<xref ref-type="bibr" rid="pcbi.1005186.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>] (as well as other sensory cortices [<xref ref-type="bibr" rid="pcbi.1005186.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref060">60</xref>]). These transients were also inherent to the dynamics of our network and were not trivially predicted by simpler variants. For example, Langevin sampling did not give rise to any transient increase in firing rates—rates simply rose or fell towards their new steady state (<xref ref-type="fig" rid="pcbi.1005186.g007">Fig 7B</xref>, most obvious for <italic>z</italic><sub>gen</sub> = 0.5). Even Hamiltonian dynamics did not necessarily yield transients. In particular, the full dynamics of our network inferred contrast, <italic>z</italic>, online together with the basis function intensities <bold>u</bold>. Assuming instead that the brain knows <italic>z</italic> = <italic>z</italic><sub>gen</sub>, or uses a fixed value of <italic>z</italic> sampled from <italic>P</italic> (<italic>z</italic>|<bold>x</bold>), the dynamics became simple noisy harmonic motion. Although harmonic motion can lead to transients when initialised properly, the transients yielded by these dynamics were much smaller in magnitude which were near-impossible to detect in simulated population firing rates (<xref ref-type="fig" rid="pcbi.1005186.g007">Fig 7C</xref>).</p>
<fig id="pcbi.1005186.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005186.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Large, contrast-dependent firing rate transients in the model.</title>
<p><bold>A-C.</bold> Transients (or lack thereof) at different contrast levels (colour) under the full dynamics (<bold>A</bold>), using Langevin dynamics (<bold>B</bold>), and under the full dynamics when the value of <italic>z</italic> is fixed, <italic>z</italic> = <italic>z</italic><sub>gen</sub> (<bold>C</bold>). Note different scales for firing rates in the three panels to better show the full range of firing rate fluctuations in each case. <bold>D.</bold> Dependence of the inferred value of contrast, <italic>z</italic>, on the currently inferred magnitude of basis function intensities, <italic>u</italic>, under the simplified dynamics (blue). For reference, red shows the value of <italic>z</italic> when set to be fixed at <italic>z</italic> = <italic>z</italic><sub>gen</sub>. <bold>E.</bold> There is asymmetry in <inline-formula id="pcbi.1005186.e015"><alternatives><graphic id="pcbi.1005186.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mover accent="true"><mml:mi>u</mml:mi> <mml:mo>¨</mml:mo></mml:mover></mml:math></alternatives></inline-formula> as a function of <italic>u</italic>, around the value of <italic>u</italic> = <inline-formula id="pcbi.1005186.e082"><alternatives><graphic id="pcbi.1005186.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e082" xlink:type="simple"/><mml:math display="inline" id="M82"><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula> = 1, in the simplified model when <italic>z</italic> is inferred (blue) but not when it is fixed (red). <bold>F.</bold> Transients predicted by the simplified dynamics (<xref ref-type="disp-formula" rid="pcbi.1005186.e018">Eq 9</xref>, with parameters as in <xref ref-type="fig" rid="pcbi.1005186.g006">Fig 6D</xref>, and initial conditions <italic>u</italic>(0) = 0.1 and <inline-formula id="pcbi.1005186.e016"><alternatives><graphic id="pcbi.1005186.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>) are similar to transients under the full dynamics.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.g007" xlink:type="simple"/>
</fig>
<p>In order to understand how transients emerged in the full Hamiltonian dynamics of our network, sampling <bold>u</bold> and <italic>z</italic> jointly, we focussed on the interaction between the dynamics of <bold>u</bold> and the inferred value of <italic>z</italic>. For analyzing the asymptotic behaviour in the previous section, we assumed that <italic>z</italic> was constant (and equal to <italic>z</italic><sub>gen</sub>). However, in general, <italic>z</italic> depended on the network’s currently inferred value of <bold>u</bold>. In particular, <italic>z</italic> and <bold>u</bold> jointly accounted for the total contrast content of the input image <bold>x</bold> (<xref ref-type="disp-formula" rid="pcbi.1005186.e003">Eq 3</xref>), and thus there was an inverse scaling between their magnitudes. Using the 1D variant of <xref ref-type="disp-formula" rid="pcbi.1005186.e012">Eq 7</xref>, <italic>x</italic> ≈ <italic>zAu</italic>, so <italic>z</italic> ≈ <italic>x</italic>/<italic>Au</italic> (<xref ref-type="fig" rid="pcbi.1005186.g007">Fig 7D</xref>). Here, we make use of a separation of time scales between the dynamics of <italic>z</italic> and <bold>u</bold>, specifically that <italic>z</italic> will attain its stationary value (distribution) much faster than <bold>u</bold>. This is because while the basis functions of <italic>u</italic><sub><italic>i</italic></sub>’s are localised Gabor filters, <italic>z</italic> depends on the whole image patch (or, conversely, on all the <italic>u</italic><sub><italic>i</italic></sub>’s), which means that the sensory evidence for <italic>z</italic> is much stronger than for <bold>u</bold>, and consequently its distribution is much narrower, giving strong prediction error signals which rapidly drive it to equilibrium. As <italic>z</italic> effectively set the stiffness of the ‘spring’ underlying harmonic motions in our dynamics (<xref ref-type="disp-formula" rid="pcbi.1005186.e012">Eq 7</xref>), the system had high (restoring) acceleration for low values of |<italic>u</italic>| and low accelerations for high values of |<italic>u</italic>|, resulting in high magnitude excursions in <italic>u</italic> (<xref ref-type="fig" rid="pcbi.1005186.g007">Fig 7E</xref>). Therefore, just after stimulus onset, <italic>u</italic> was small, so there was a large force in the positive direction (due to the large stiffness), causing a large acceleration. Eventually, <italic>u</italic> exceeded <inline-formula id="pcbi.1005186.e017"><alternatives><graphic id="pcbi.1005186.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mover accent="true"><mml:mi>u</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, but by that point the stiffness, and hence the restoring force had fallen, so the system’s momentum allowed it to move a long distance, certainly further than if the spring constant had been fixed. This asymmetry in preferring upward to downward changes in |<italic>u</italic>| was only relevant during initial transients as asymptotically the evidence in the image was sufficient to determine <italic>z</italic> with high precision and so the dynamics of <italic>u</italic> became approximately linear (as in <xref ref-type="disp-formula" rid="pcbi.1005186.e012">Eq 7</xref>). Thus, the timescale of the transient was determined by the timescale at which inferences about <italic>z</italic> attained their stationary distribution, which in turn scaled with <italic>ρ</italic> (<xref ref-type="supplementary-material" rid="pcbi.1005186.s001">S1 Fig</xref>).</p>
<p>More formally, taking the 1D version of the simplified dynamics (<xref ref-type="disp-formula" rid="pcbi.1005186.e012">Eq 7</xref>), and substituting <italic>z</italic> ≈ <italic>x</italic>/<italic>Au</italic> gives
<disp-formula id="pcbi.1005186.e018"><alternatives><graphic id="pcbi.1005186.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mrow><mml:mover accent="true"><mml:mi>u</mml:mi> <mml:mo>¨</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mfrac> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msup><mml:mi>x</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msup><mml:mi>A</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msup><mml:mi>u</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mfenced> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>u</mml:mi> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>u</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula></p>
<p>Simulating this simplified dynamical system did indeed yield large transients (<xref ref-type="fig" rid="pcbi.1005186.g007">Fig 7F</xref>) which matched full simulations (<xref ref-type="fig" rid="pcbi.1005186.g007">Fig 7A</xref>) and recordings in macaque V1 [<xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>] both in terms of the transient timescale (∼30 ms) and the dependence of transient magnitude on contrast level (values of <italic>z</italic><sub>gen</sub>). The fact that these large transients were retained in the model after such severe approximations indicated that they were robust to the exact method used for determining <italic>z</italic>, as long as it ensured that <italic>z</italic> was consistent with both <bold>x</bold> and <bold>u</bold>.</p>
</sec>
</sec>
<sec id="sec009" sec-type="conclusions">
<title>Discussion</title>
<p>Previously proposed mechanisms by which the cortex could either represent and manipulate uncertainty or just find the most probable explanation for sensory data failed to explain the richness of cortical dynamics. In particular, these models either had no dynamics or only gradient ascent-like dynamics, whereas neural activity displays oscillations in response to a fixed stimulus, and large transients in response to stimulus onset. Moreover, these models typically violated Dale’s law, by having neurons whose outputs were both excitatory and inhibitory. We demonstrated that it was, in fact, possible to perform probabilistic inference in an EI network that displayed oscillations and transients. Moreover, having oscillations actually improved the network, in that it was able to perform inference faster than networks that did not have oscillations. Our model displayed four further dynamical properties that did not appear, at first, to be compatible with probabilistic inference: excitation and inhibition were balanced at the level of individual cells [<xref ref-type="bibr" rid="pcbi.1005186.ref038">38</xref>], inhibition lagged excitation [<xref ref-type="bibr" rid="pcbi.1005186.ref038">38</xref>], oscillation frequency increased with stimulus contrast [<xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>], and there were large transients upon stimulus onset which also scaled with contrast [<xref ref-type="bibr" rid="pcbi.1005186.ref028">28</xref>–<xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>]. In sum, we have given an approach by which successful, inference-based models of stationary activity distributions in V1 (e.g. [<xref ref-type="bibr" rid="pcbi.1005186.ref011">11</xref>]) can be extended to match the dynamics of neural activity.</p>
<p>Our work suggests a new functional role for cortical oscillations, and for inhibitory neurons that are involved in their generation: speeding up inference. We have demonstrated this role in the specific context of V1, but our formalism is readily applicable to other cortical areas in which probabilistic inference is supposed to take place, and similar stimulus-controlled transients and oscillations can be observed [<xref ref-type="bibr" rid="pcbi.1005186.ref061">61</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref062">62</xref>]. Neural oscillations and probabilistic inference have been linked previously, albeit in the hippocampus rather than sensory cortices [<xref ref-type="bibr" rid="pcbi.1005186.ref063">63</xref>]. The main differences between the two approaches are that in previous work, oscillations were controlled entirely externally, and implemented (approximately) an augmented sampling scheme known as tempered transitions [<xref ref-type="bibr" rid="pcbi.1005186.ref064">64</xref>], whereas our work builds on the theory of Hamiltonian Monte Carlo [<xref ref-type="bibr" rid="pcbi.1005186.ref037">37</xref>] to construct network dynamics that are intrinsically oscillating. This allowed us to study the effects of the stimulus on these oscillations that previous approaches could not address. Computationally, Hamiltonian Monte Carlo and annealing-based techniques, such as tempered transitions, have complementary advantages in allowing network dynamics to respectively explore a given posterior mode or traverse different modes efficiently. Thus, a combination of these different approaches may account for concurrent cortical oscillations at different frequencies.</p>
<p>While the statistical model of images underlying our network was able to capture some interesting properties of the statistics of natural images, it was nevertheless clearly simplified, in that e.g. it did not capture any notion of objects, or occlusion. Once such higher-order features are incorporated into the model, we expect a variety of interesting new dynamical properties to emerge. For example, there should be strong statistical relationships between low-level variables describing a single object, and hence strong dynamical relationships, including synchronisation, between neurons representing different parts of the same object [<xref ref-type="bibr" rid="pcbi.1005186.ref065">65</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref066">66</xref>]. In the extreme, we might expect to see coherent oscillations between neurons representing the same object, providing a principled unifying perspective of bottom-up (e.g. contrast) and top-down influences (e.g. “binding by synchrony”) on cortical oscillations [<xref ref-type="bibr" rid="pcbi.1005186.ref067">67</xref>].</p>
<p>It will also be important to understand how local learning rules, modelling synaptic plasticity, may be able to set up the weight matrices that we found were necessary for implementing efficient Hamiltonian dynamics. For example, there might be two sets of learning rules operating in parallel, one set of rules which learns that statistical structure of the input, perhaps mainly through the plasticity of excitatory-to-excitatory connections [<xref ref-type="bibr" rid="pcbi.1005186.ref068">68</xref>], and another which tunes network dynamics, perhaps primarily by inhibitory plasticity mechanisms, to speed up the inference process, without altering the sampled distribution [<xref ref-type="bibr" rid="pcbi.1005186.ref069">69</xref>].</p>
<p>Finally, while the type of linear membrane potential dynamics we used in our network could be implemented using firing rate non-linearities in combination with synaptic and dendritic nonlinearities [<xref ref-type="bibr" rid="pcbi.1005186.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref051">51</xref>], it will nevertheless be important to understand whether it is possible to perform inference in networks with more realistic non-linearities.</p>
</sec>
<sec id="sec010" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec011">
<title>Sampler derivation</title>
<p>The sampler was derived by combining an HMC step, and a Langevin step to add noise and ensure ergodicity. The most general equations describing HMC are given by
<disp-formula id="pcbi.1005186.e019"><alternatives><graphic id="pcbi.1005186.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e019" xlink:type="simple"/><mml:math display="block" id="M19"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
<disp-formula id="pcbi.1005186.e020"><alternatives><graphic id="pcbi.1005186.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(11)</label></disp-formula></p>
<p>For the HMC step, there is freedom to specify the distribution of the auxiliary variable, <italic>P</italic> (<bold>v</bold>|<bold>u</bold>, <bold>x</bold>), and freedom to set the noise distribution. Typically, the distribution of the auxilliary variable is set to have <bold>0</bold> mean and be totally independent of <bold>u</bold>, so that <inline-formula id="pcbi.1005186.e021"><alternatives><graphic id="pcbi.1005186.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>;</mml:mo> <mml:mn mathvariant="bold">0</mml:mn> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. However, we know that inhibitory cells do, in fact, respond to input. We therefore chose to use
<disp-formula id="pcbi.1005186.e022"><alternatives><graphic id="pcbi.1005186.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e022" xlink:type="simple"/><mml:math display="block" id="M22"><mml:mrow><mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>;</mml:mo> <mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula>
with a free choice for <bold>B</bold> and <bold>M</bold>, which we will discuss below (Setting the parameters). This allowed us to split up these probability distributions into terms that are dependent, and independent, of the data, <bold>x</bold>:
<disp-formula id="pcbi.1005186.e023"><alternatives><graphic id="pcbi.1005186.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(13)</label></disp-formula>
<disp-formula id="pcbi.1005186.e024"><alternatives><graphic id="pcbi.1005186.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(14)</label></disp-formula></p>
<p>In order to add noise without perturbing the stationary distribution, we perform a Langevin step, that is, we simultaneously add noise and take a step along the gradient of the log-probability. Notably, this introduces a new time constant <italic>τ</italic><sub><italic>L</italic></sub>, that simply controls the rate at which noise is injected into the system. As such, <italic>τ</italic><sub><italic>L</italic></sub> is directly related to <italic>ρ</italic>,
<disp-formula id="pcbi.1005186.e025"><alternatives><graphic id="pcbi.1005186.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mrow><mml:mi>ρ</mml:mi> <mml:mo>=</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt></mml:mrow></mml:math></alternatives> <label>(15)</label></disp-formula></p>
<p>The dynamics therefore become
<disp-formula id="pcbi.1005186.e026"><alternatives><graphic id="pcbi.1005186.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e026" xlink:type="simple"/><mml:math display="block" id="M26"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(16)</label></disp-formula>
<disp-formula id="pcbi.1005186.e027"><alternatives><graphic id="pcbi.1005186.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e027" xlink:type="simple"/><mml:math display="block" id="M27"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(17)</label></disp-formula></p>
<p>Again, we can break up the <italic>P</italic> (<bold>u</bold>, <bold>v</bold>|<bold>x</bold>, <italic>z</italic>) terms into terms that are dependent, and independent, of <bold>v</bold>:
<disp-formula id="pcbi.1005186.e028"><alternatives><graphic id="pcbi.1005186.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e028" xlink:type="simple"/><mml:math display="block" id="M28"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(18)</label></disp-formula>
<disp-formula id="pcbi.1005186.e029"><alternatives><graphic id="pcbi.1005186.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfrac> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(19)</label></disp-formula></p>
<p>Now, we compute these gradients, and convert them into a neural-network (see <xref ref-type="supplementary-material" rid="pcbi.1005186.s002">S1 Code</xref>)
<disp-formula id="pcbi.1005186.e030"><alternatives><graphic id="pcbi.1005186.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">v</mml:mi></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(20)</label></disp-formula>
<disp-formula id="pcbi.1005186.e031"><alternatives><graphic id="pcbi.1005186.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">B</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">M</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">B</mml:mi> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">v</mml:mi></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(21)</label></disp-formula>
where the gradient of the posterior is the external input
<disp-formula id="pcbi.1005186.e032"><alternatives><graphic id="pcbi.1005186.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mrow><mml:msub><mml:mi mathvariant="bold">I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mi>z</mml:mi> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mtext> </mml:mtext><mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>-</mml:mo> <mml:mi>z</mml:mi> <mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">C</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:math></alternatives> <label>(22)</label></disp-formula></p>
<p>We can thus write the dynamics of our neural network as
<disp-formula id="pcbi.1005186.e033"><alternatives><graphic id="pcbi.1005186.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mtext> </mml:mtext><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>uu</mml:mtext></mml:msub> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>uv</mml:mtext></mml:msub> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>τ</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:msub><mml:mi mathvariant="bold">I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub></mml:mfenced> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>u</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(23)</label></disp-formula>
<disp-formula id="pcbi.1005186.e034"><alternatives><graphic id="pcbi.1005186.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>vu</mml:mtext></mml:msub> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>vv</mml:mtext></mml:msub> <mml:mi mathvariant="bold">v</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub></mml:mfenced> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(24)</label></disp-formula>
where
<disp-formula id="pcbi.1005186.e035"><alternatives><graphic id="pcbi.1005186.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e035" xlink:type="simple"/><mml:math display="block" id="M35"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>uu</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">B</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">M</mml:mi> <mml:mi mathvariant="bold">B</mml:mi> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>τ</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:mi mathvariant="bold">M</mml:mi> <mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:math></alternatives> <label>(25)</label></disp-formula>
<disp-formula id="pcbi.1005186.e036"><alternatives><graphic id="pcbi.1005186.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e036" xlink:type="simple"/><mml:math display="block" id="M36"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>uv</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">B</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">M</mml:mi> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>τ</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:mi mathvariant="bold">M</mml:mi></mml:mrow></mml:math></alternatives> <label>(26)</label></disp-formula>
<disp-formula id="pcbi.1005186.e037"><alternatives><graphic id="pcbi.1005186.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e037" xlink:type="simple"/><mml:math display="block" id="M37"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>vu</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mi mathvariant="bold">B</mml:mi> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>τ</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">B</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">M</mml:mi> <mml:mi mathvariant="bold">B</mml:mi></mml:mrow></mml:math></alternatives> <label>(27)</label></disp-formula>
<disp-formula id="pcbi.1005186.e038"><alternatives><graphic id="pcbi.1005186.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e038" xlink:type="simple"/><mml:math display="block" id="M38"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mtext>vv</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">M</mml:mi> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>τ</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">B</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">M</mml:mi></mml:mrow></mml:math></alternatives> <label>(28)</label></disp-formula></p>
<p>Finally, we substitute <italic>τ</italic><sub><italic>L</italic></sub> = 2/<italic>ρ</italic><sup>2</sup>.</p>
</sec>
<sec id="sec012">
<title>Sampling <italic>z</italic></title>
<p>The brain does not know <italic>z</italic><sub>gen</sub>, so it must infer <italic>z</italic> together with <bold>u</bold>. We therefore inferred <italic>z</italic> and <bold>u</bold> in parallel, using an additional HMC sampler for <italic>z</italic>.</p>
<p>In particular, we simply extended the dynamics with an additional element for <italic>z</italic>:
<disp-formula id="pcbi.1005186.e039"><alternatives><graphic id="pcbi.1005186.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>z</mml:mi> <mml:mi>z</mml:mi></mml:mrow></mml:msub> <mml:mi>z</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>z</mml:mi> <mml:mi>v</mml:mi></mml:mrow></mml:msub> <mml:mi>v</mml:mi> <mml:mo>+</mml:mo> <mml:mfrac><mml:mi>τ</mml:mi> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:msub><mml:mi>I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub></mml:mfenced> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi>η</mml:mi> <mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(29)</label></disp-formula>
<disp-formula id="pcbi.1005186.e040"><alternatives><graphic id="pcbi.1005186.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>v</mml:mi> <mml:mi>z</mml:mi></mml:mrow></mml:msub> <mml:mi>z</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>v</mml:mi> <mml:mi>v</mml:mi></mml:mrow></mml:msub> <mml:mi>v</mml:mi> <mml:mo>-</mml:mo> <mml:msub><mml:mi>I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub></mml:mfenced> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi>η</mml:mi> <mml:mi>v</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(30)</label></disp-formula>
where <italic>W</italic> is defined as above, with <italic>B</italic> = <italic>M</italic> = 1, and
<disp-formula id="pcbi.1005186.e041"><alternatives><graphic id="pcbi.1005186.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e041" xlink:type="simple"/><mml:math display="block" id="M41"><mml:mrow><mml:msub><mml:mi>I</mml:mi> <mml:mtext>intput</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">x</mml:mi></mml:mfenced></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:mi>z</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced> <mml:mi>T</mml:mi></mml:msup><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>-</mml:mo> <mml:mi>z</mml:mi> <mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:mfenced> <mml:mo>-</mml:mo> <mml:mi>z</mml:mi></mml:mrow></mml:math></alternatives> <label>(31)</label></disp-formula></p>
</sec>
<sec id="sec013">
<title>Langevin sampler</title>
<p>By setting the weight matrices implementing HMC, <bold>W</bold>, to <bold>0</bold>, we obtain the Langevin step:
<disp-formula id="pcbi.1005186.e042"><alternatives><graphic id="pcbi.1005186.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac> <mml:msub><mml:mi mathvariant="bold">I</mml:mi> <mml:mtext>input</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:msqrt><mml:mfrac><mml:mn>2</mml:mn> <mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub></mml:mfrac></mml:msqrt> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi mathvariant="bold">u</mml:mi></mml:msub></mml:mrow></mml:math></alternatives> <label>(32)</label></disp-formula></p>
</sec>
<sec id="sec014">
<title>Setting the parameters</title>
<p>The GSM model has three parameters, the Gabor features, <bold>A</bold>, the covariance matrix, <bold>C</bold>, and the observation noise, <inline-formula id="pcbi.1005186.e043"><alternatives><graphic id="pcbi.1005186.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. We set <bold>A</bold> using known properties of the visual system: the Gabor filters-like receptive fields of V1 simple cells. In particular, we define <bold>A</bold> as a bank of Gabor filters at three orientations (0, <italic>π</italic>/3 and 2<italic>π</italic>/3), five locations (the centre, and corners, 1/6 image-widths from the edge, where all measurements are in units of image height = image width). The Gaussian envelope of the Gabors had minor axis 0.1, and major axis uniformly distributed from 0.1 to 0.5 (where these measurements are in units of image width, and give the standard deviation along the relevant axis), and the sinusoid had wavelength 0.13 image-widths.</p>
<p>We can set <bold>C</bold> using the value for <bold>A</bold>, and the fact that retina and LGN are known to whiten visual input [<xref ref-type="bibr" rid="pcbi.1005186.ref070">70</xref>]. For a particular image, <bold>x</bold>, and inferred contrast level, <italic>z</italic>, the posterior is
<disp-formula id="pcbi.1005186.e044"><alternatives><graphic id="pcbi.1005186.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e044" xlink:type="simple"/><mml:math display="block" id="M44"><mml:mrow><mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>;</mml:mo> <mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:mi>z</mml:mi> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mstyle> <mml:mtext> </mml:mtext><mml:mi mathvariant="bold">Σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mtext> </mml:mtext><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(33)</label></disp-formula>
where
<disp-formula id="pcbi.1005186.e045"><alternatives><graphic id="pcbi.1005186.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e045" xlink:type="simple"/><mml:math display="block" id="M45"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msup><mml:mi mathvariant="bold">C</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi>z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mstyle> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mfenced> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives> <label>(34)</label></disp-formula></p>
<p>We know that the average posterior equals the prior [<xref ref-type="bibr" rid="pcbi.1005186.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1005186.ref071">71</xref>], and so the prior covariance <bold>C</bold> should match the average posterior covariance (averaging over data, <bold>x</bold>, and other latent variables, <italic>z</italic>), i.e.
<disp-formula id="pcbi.1005186.e046"><alternatives><graphic id="pcbi.1005186.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e046" xlink:type="simple"/><mml:math display="block" id="M46"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>=</mml:mo> <mml:mrow><mml:mtext>E </mml:mtext> <mml:mfenced close="]" open="[" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>T</mml:mi></mml:msup></mml:mfenced> <mml:mo>=</mml:mo> <mml:mtext>E </mml:mtext> <mml:mfenced close="]" open="[" separators=""><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi>z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>4</mml:mn></mml:msubsup></mml:mfrac></mml:mstyle> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup><mml:mtext> </mml:mtext> <mml:mi mathvariant="bold">x</mml:mi> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(35)</label></disp-formula></p>
<p>We make the ansatz that
<disp-formula id="pcbi.1005186.e047"><alternatives><graphic id="pcbi.1005186.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e047" xlink:type="simple"/><mml:math display="block" id="M47"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>=</mml:mo> <mml:mrow><mml:mi>K</mml:mi><mml:mtext> </mml:mtext> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mfenced> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives> <label>(36)</label></disp-formula>
where <italic>K</italic> is an unknown constant. Substituting this guess into <xref ref-type="disp-formula" rid="pcbi.1005186.e045">Eq (34)</xref>, we see that <bold>Σ</bold>(<italic>z</italic>) simplifies considerably:
<disp-formula id="pcbi.1005186.e048"><alternatives><graphic id="pcbi.1005186.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e048" xlink:type="simple"/><mml:math display="block" id="M48"><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>z</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msup><mml:mi>K</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>+</mml:mo> <mml:mstyle displaystyle="false" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi>z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mstyle></mml:mfenced> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mfenced> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives> <label>(37)</label></disp-formula>
and as the data are whitened (assuming this is true at any contrast level, i.e. E<sub><bold>x</bold>|<italic>z</italic></sub> [<bold>x</bold><bold>x</bold><sup><italic>T</italic></sup>] = <italic>c</italic>(<italic>z</italic>) <bold>I</bold>, with some <italic>c</italic>(<italic>z</italic>)), we indeed have
<disp-formula id="pcbi.1005186.e049"><alternatives><graphic id="pcbi.1005186.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e049" xlink:type="simple"/><mml:math display="block" id="M49"><mml:mrow><mml:msub><mml:mtext>E</mml:mtext> <mml:mi mathvariant="bold">u</mml:mi></mml:msub> <mml:mtext> </mml:mtext><mml:mfenced close="]" open="[" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:msup><mml:mi mathvariant="bold">u</mml:mi> <mml:mi>T</mml:mi></mml:msup></mml:mfenced> <mml:mo>∝</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mfenced> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives> <label>(38)</label></disp-formula>
confirming our ansatz.</p>
<p>In principle, we could find <italic>K</italic> by solving <xref ref-type="disp-formula" rid="pcbi.1005186.e046">Eq (35)</xref> (by substituting <xref ref-type="disp-formula" rid="pcbi.1005186.e047">Eq 36</xref> to its l.h.s., and <xref ref-type="disp-formula" rid="pcbi.1005186.e048">Eq 37</xref> to its r.h.s.), however, in practice, we cannot because we do not know <italic>c</italic>(<italic>z</italic>) in E<sub><bold>x</bold>|<italic>z</italic></sub> [<bold>x</bold><bold>x</bold><sup><italic>T</italic></sup>] = <italic>c</italic>(<italic>z</italic>) <bold>I</bold>. Instead, we set <italic>K</italic> to ensure that the inputs, <bold>A</bold><sup><italic>T</italic></sup> <bold>x</bold>, have the right covariance (note that it is only possible to match the covariance of <bold>A</bold><sup><italic>T</italic></sup> <bold>x</bold>, and not of <bold>x</bold> directly, because we are using an undercomplete basis). As the data is whitened, we expect
<disp-formula id="pcbi.1005186.e050"><alternatives><graphic id="pcbi.1005186.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e050" xlink:type="simple"/><mml:math display="block" id="M50"><mml:mrow><mml:mtext>E </mml:mtext> <mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup><mml:mtext> </mml:mtext> <mml:mi mathvariant="bold">x</mml:mi> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:math></alternatives> <label>(39)</label></disp-formula>
while the predictive distribution of the GSM results in
<disp-formula id="pcbi.1005186.e051"><alternatives><graphic id="pcbi.1005186.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e051" xlink:type="simple"/><mml:math display="block" id="M51"><mml:mrow><mml:mtext>E </mml:mtext> <mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup><mml:mtext> </mml:mtext> <mml:mi mathvariant="bold">x</mml:mi> <mml:msup><mml:mi mathvariant="bold">x</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mtext>E</mml:mtext> <mml:mrow/></mml:msub> <mml:mfenced close="]" open="[" separators=""><mml:msup><mml:mi>z</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mfenced><mml:mtext> </mml:mtext> <mml:mi mathvariant="bold">A</mml:mi> <mml:mi mathvariant="bold">C</mml:mi> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mi mathvariant="bold">I</mml:mi></mml:mfenced><mml:mtext> </mml:mtext> <mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:math></alternatives> <label>(40)</label></disp-formula></p>
<p>Setting these expressions equal, substituting for <bold>C</bold> using our ansatz (<xref ref-type="disp-formula" rid="pcbi.1005186.e047">Eq 36</xref>), and using E [<italic>z</italic><sup>2</sup>] = 1 gives
<disp-formula id="pcbi.1005186.e052"><alternatives><graphic id="pcbi.1005186.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e052" xlink:type="simple"/><mml:math display="block" id="M52"><mml:mrow><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:mo>=</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mi>K</mml:mi> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfenced><mml:mtext> </mml:mtext> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:math></alternatives> <label>(41)</label></disp-formula>
yielding the solution
<disp-formula id="pcbi.1005186.e053"><alternatives><graphic id="pcbi.1005186.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e053" xlink:type="simple"/><mml:math display="block" id="M53"><mml:mrow><mml:mi>K</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives> <label>(42)</label></disp-formula></p>
<p>(Note that while this derivation is valid for the complete and undercomplete case, a more complex analysis would be necessary for the overcomplete case.)</p>
<p>With these choices, the dynamics only depend on the probabilistic model through the product (<bold>A</bold><sup><italic>T</italic></sup><bold>A</bold>)<sup>−1</sup>. This product controls the frequency spectrum: if (<bold>A</bold><sup><italic>T</italic></sup><bold>A</bold>)<sup>−1</sup> has a very broad eigenspectrum (e.g. multiple orders of magnitude), then the system will sample at different rates along different directions. This is not desirable: we want sampling to take place as fast as possible in every direction, not to be fast in some directions, and slow in others. If we were able to set <bold>M</bold> to (<bold>A</bold><sup><italic>T</italic></sup><bold>A</bold>)<sup>−1</sup>, then we would indeed sample at the same rate in every direction [<xref ref-type="bibr" rid="pcbi.1005186.ref037">37</xref>], no matter how broad the spectrum of (<bold>A</bold><sup><italic>T</italic></sup><bold>A</bold>)<sup>−1</sup> (see “Deriving the 1D approximate model”, below). However, to ensure that Dale’s law is obeyed, we need the elements of <bold>M</bold> to be non-negative, so we set
<disp-formula id="pcbi.1005186.e054"><alternatives><graphic id="pcbi.1005186.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e054" xlink:type="simple"/><mml:math display="block" id="M54"><mml:mrow><mml:mi mathvariant="bold">B</mml:mi> <mml:mo>=</mml:mo> <mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:math></alternatives> <label>(43)</label></disp-formula>
and
<disp-formula id="pcbi.1005186.e055"><alternatives><graphic id="pcbi.1005186.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e055" xlink:type="simple"/><mml:math display="block" id="M55"><mml:mrow><mml:msub><mml:mi>M</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mtext>max </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msubsup><mml:mfenced close=")" open="(" separators=""><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mfenced> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(44)</label></disp-formula></p>
<p>For the dynamics to be correct, we need this matrix to be positive definite. While this is not guaranteed, we found that in practice the matrix turns out to satisfy this constraint. As <bold>M</bold> is close to, but not exactly, (<bold>A</bold><sup><italic>T</italic></sup><bold>A</bold>)<sup>−1</sup>, the eigenspectrum of <bold>A</bold><sup><italic>T</italic></sup><bold>A</bold> will have some effect on our sampler. In practice, our eigenvalues range over a factor of 5 without weakening our results. Again, this is valid for the undercomplete and complete cases, and a more complex analysis would be necessary for the overcomplete case.</p>
<p>Next, we consider the observation noise level, <italic>σ</italic><sub><italic>x</italic></sub>, which describes the noise-to-signal ratio for neurons in the visual cortex. In particular, we take the input to be <bold>A</bold><sup><italic>T</italic></sup> <bold>x</bold>. This input is made up of two components, signal from the mean of <italic>P</italic> (<bold>A</bold><sup><italic>T</italic></sup> <bold>x</bold>|<bold>u</bold>, <italic>z</italic>), and noise from its covariance, (given by transforming <xref ref-type="disp-formula" rid="pcbi.1005186.e003">Eq (3)</xref>). The covariance of this input (<xref ref-type="disp-formula" rid="pcbi.1005186.e051">Eq 40</xref>) also breaks up into signal, <inline-formula id="pcbi.1005186.e056"><alternatives><graphic id="pcbi.1005186.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo><mml:mtext> </mml:mtext> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, and noise, <inline-formula id="pcbi.1005186.e057"><alternatives><graphic id="pcbi.1005186.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e057" xlink:type="simple"/><mml:math display="inline" id="M57"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>, terms, giving the signal to noise ratio as <inline-formula id="pcbi.1005186.e058"><alternatives><graphic id="pcbi.1005186.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:mrow><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>/</mml:mo> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:msqrt> <mml:mo>≈</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. To obtain a value for <italic>σ</italic><sub>x</sub> we perform a simple estimation. We take a V1 simple cell that integrates <italic>N</italic> inputs from retinal ganglion cells (RGCs) (indirectly, via the LGN), each firing a Poisson spike train of average rate <italic>r</italic>, with a temporal integration window of Δ<italic>t</italic>. In this case, the c.v. (which corresponds to <italic>σ</italic><sub>x</sub>) is
<disp-formula id="pcbi.1005186.e059"><alternatives><graphic id="pcbi.1005186.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e059" xlink:type="simple"/><mml:math display="block" id="M59"><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mtext>s.d.</mml:mtext> <mml:mtext>mean</mml:mtext></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:msqrt><mml:mrow><mml:mi>N</mml:mi> <mml:mi>r</mml:mi> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msqrt> <mml:mrow><mml:mi>N</mml:mi> <mml:mi>r</mml:mi> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mrow><mml:mi>N</mml:mi> <mml:mi>r</mml:mi> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(45)</label></disp-formula></p>
<p>Based on the literature, we set the values of the relevant constants as
<disp-formula id="pcbi.1005186.e060"><alternatives><graphic id="pcbi.1005186.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e060" xlink:type="simple"/><mml:math display="block" id="M60"><mml:mrow><mml:mi>r</mml:mi> <mml:mo>∼</mml:mo> <mml:mn>1</mml:mn> <mml:mspace width="4.pt"/><mml:msup><mml:mtext>s</mml:mtext> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives> <label>(46)</label></disp-formula>
[<xref ref-type="bibr" rid="pcbi.1005186.ref072">72</xref>],
<disp-formula id="pcbi.1005186.e061"><alternatives><graphic id="pcbi.1005186.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e061" xlink:type="simple"/><mml:math display="block" id="M61"><mml:mrow><mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>∼</mml:mo> <mml:mn>10</mml:mn> <mml:mspace width="4.pt"/><mml:mtext>to</mml:mtext> <mml:mspace width="4.pt"/><mml:mn>100</mml:mn> <mml:mspace width="4.pt"/><mml:mtext>ms</mml:mtext></mml:mrow></mml:math></alternatives> <label>(47)</label></disp-formula>
[<xref ref-type="bibr" rid="pcbi.1005186.ref073">73</xref>],
<disp-formula id="pcbi.1005186.e062"><alternatives><graphic id="pcbi.1005186.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e062" xlink:type="simple"/><mml:math display="block" id="M62"><mml:mrow><mml:mi>N</mml:mi> <mml:mo>∼</mml:mo> <mml:mn>100</mml:mn> <mml:mspace width="4.pt"/><mml:mtext>to</mml:mtext> <mml:mspace width="4.pt"/><mml:mn>1000</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(48)</label></disp-formula></p>
<p>To obtain this range for <italic>N</italic>, we note that there are around 1000 RGCs in the stimulated region in [<xref ref-type="bibr" rid="pcbi.1005186.ref030">30</xref>]. (This can be computed knowing the dependency of RGC density on eccentricity [<xref ref-type="bibr" rid="pcbi.1005186.ref074">74</xref>], and that the stimulus has s.d. 0.5 degrees, so the total area is around 1 degree<sup>2</sup>, and is 3 to 5 degrees from the fovea, and then discounting, to account for the fact that not all of these cells will be connected [<xref ref-type="bibr" rid="pcbi.1005186.ref075">75</xref>]). Thus, we obtain the interval
<disp-formula id="pcbi.1005186.e063"><alternatives><graphic id="pcbi.1005186.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e063" xlink:type="simple"/><mml:math display="block" id="M63"><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mn>1</mml:mn></mml:msqrt></mml:mfrac> <mml:mspace width="4.pt"/><mml:mtext>to</mml:mtext> <mml:mspace width="4.pt"/><mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mn>100</mml:mn></mml:msqrt></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(49)</label></disp-formula>
of which we use the geometric mean:
<disp-formula id="pcbi.1005186.e064"><alternatives><graphic id="pcbi.1005186.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e064" xlink:type="simple"/><mml:math display="block" id="M64"><mml:mrow><mml:msub><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msqrt><mml:mn>10</mml:mn></mml:msqrt></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(50)</label></disp-formula></p>
<p>To choose values for <italic>τ</italic><sub><italic>L</italic></sub>, <italic>τ</italic> and <inline-formula id="pcbi.1005186.e065"><alternatives><graphic id="pcbi.1005186.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="bold">v</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>, we considered biological constraints. The external input to the inhibitory cells is governed entirely by <italic>τ</italic>, suggesting that a biologically plausible value for <italic>τ</italic> is 10 ms [<xref ref-type="bibr" rid="pcbi.1005186.ref076">76</xref>]. The scale of the recurrent input terms are governed by the product <inline-formula id="pcbi.1005186.e066"><alternatives><graphic id="pcbi.1005186.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">M</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, suggesting that, to ensure the recurrent input has a biologically plausible timescale of 10 ms, we should set <bold>M</bold><sup>−1</sup> to be O(1) (see <xref ref-type="disp-formula" rid="pcbi.1005186.e055">Eq (44)</xref>).</p>
<p>Finally, we estimated <italic>τ</italic><sub><italic>L</italic></sub>, or equivalently the amount of noise per unit time, by comparing the rate at which membrane potential variance increases in our equations, 2<italic>σ</italic><sup>2</sup>/<italic>τ</italic><sub><italic>L</italic></sub>, to the rate of increase given by stochastic vesicle release, the primary source of ‘noise’ in cortical circuits. If a neuron is connected to <italic>s</italic> presynaptic neurons, firing with average rate <italic>r</italic>, and the variance of a unitary EPSP is <italic>v</italic>, then stochastic vesicle release introduces variance at the rate <italic>srv</italic>. Setting <italic>srv</italic> = 2<italic>σ</italic><sup>2</sup>/<italic>τ</italic><sub><italic>L</italic></sub> allows us to find the Langevin timescale
<disp-formula id="pcbi.1005186.e067"><alternatives><graphic id="pcbi.1005186.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e067" xlink:type="simple"/><mml:math display="block" id="M67"><mml:mrow><mml:msub><mml:mi>τ</mml:mi> <mml:mi>L</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mrow><mml:mi>s</mml:mi> <mml:mi>r</mml:mi> <mml:mi>v</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives> <label>(51)</label></disp-formula></p>
<p>However, estimating <italic>τ</italic><sub><italic>L</italic></sub> is difficult, because there are huge uncertainties in <italic>σ</italic>, <italic>s</italic>, <italic>r</italic> and <italic>v</italic>. We therefore wrote our uncertainty about each parameter as a log-normal distribution, <inline-formula id="pcbi.1005186.e068"><alternatives><graphic id="pcbi.1005186.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:mrow><mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mo>(</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mo>(</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mi>x</mml:mi> <mml:mo>;</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mi>x</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> where <italic>x</italic> is one of <italic>σ</italic>, <italic>s</italic>, <italic>r</italic>, or <italic>v</italic>, and computed the induced distribution on <italic>τ</italic><sub><italic>L</italic></sub>. To specify the distributions, we wrote a range, from <italic>x</italic><sub>l</sub> to <italic>x</italic><sub>h</sub>, that, we believed contained around 95% of the probability mass, taking the boundaries of the range to be two standard-deviations from the mean in the log-domain, log <italic>x</italic><sub>l</sub> = <italic>μ</italic><sub>x</sub> − 2<italic>σ</italic><sub>x</sub> and log <italic>x</italic><sub>h</sub> = <italic>μ</italic><sub>x</sub> + 2<italic>σ</italic><sub>x</sub>.</p>
<p>To estimate the required ranges, we took values from the neuroscience literature. First, estimates of firing rates vary widely, from around 0.5 Hz [<xref ref-type="bibr" rid="pcbi.1005186.ref077">77</xref>] to around 10 Hz [<xref ref-type="bibr" rid="pcbi.1005186.ref078">78</xref>]. Second, the number of synapses per cell is usually taken to be around 10000. However, it is likely that there are multiple synapses per connection [<xref ref-type="bibr" rid="pcbi.1005186.ref079">79</xref>], so there could be anywhere from 1000 to 10000 input cells for a single downstream neuron. Third, the average variance per spike is relatively easy to measure, data from Song <italic>et al.</italic> [<xref ref-type="bibr" rid="pcbi.1005186.ref080">80</xref>] put the value at 0.076 mV<sup>2</sup>. As other measurements seem roughly consistent [<xref ref-type="bibr" rid="pcbi.1005186.ref081">81</xref>], we use a relatively narrow range for <italic>v</italic>, from 0.05 mV<sup>2</sup> to 0.1 mV<sup>2</sup>. Finally, the scaling factor, <italic>σ</italic>, could plausibly range from 2.5 mV to 7.5 mV, giving a full (2 standard deviations, and both sides of the mean) range of membrane potential fluctuations of 10 mV to 30 mV [<xref ref-type="bibr" rid="pcbi.1005186.ref082">82</xref>].</p>
<p>These ranges give a central estimate of <italic>τ</italic><sub><italic>L</italic></sub> = 150 ms, which we used in our simulations. In agreement with this back-of-the-envelope calculation, we find that our sampler’s dynamics match neural dynamics when <italic>τ</italic><sub><italic>L</italic></sub> lies in a broad range, from around 60 ms to around 400 ms (see <xref ref-type="supplementary-material" rid="pcbi.1005186.s001">S1 Fig</xref>). While <italic>τ</italic><sub><italic>L</italic></sub> appears relatively large in comparison with typical neural timescales, which are often around 10 ms, it should be remembered that <italic>τ</italic><sub><italic>L</italic></sub> parameterises the amount of noise injected into the network at every time step, and as such, does not therefore have any necessary link to other neural time constants.</p>
</sec>
<sec id="sec015">
<title>Altering the model so that <italic>u</italic><sub><italic>i</italic></sub> and <italic>v</italic><sub><italic>i</italic></sub> are always positive</title>
<p>One might worry that it is possible for <italic>u</italic><sub><italic>i</italic></sub> (or <italic>v</italic><sub><italic>i</italic></sub>) to go negative, meaning that they have their influence on downstream neurons will have the wrong sign. However, it is straightforward to offset <bold>u</bold> (and hence <bold>v</bold>, through <xref ref-type="disp-formula" rid="pcbi.1005186.e022">Eq (12)</xref>), so that they rarely, if ever become negative. Moreover, if we introduce the offset as
<disp-formula id="pcbi.1005186.e069"><alternatives><graphic id="pcbi.1005186.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e069" xlink:type="simple"/><mml:math display="block" id="M69"><mml:mrow><mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="("><mml:mi mathvariant="bold">u</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close="" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>;</mml:mo> <mml:mi mathvariant="bold">b</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">C</mml:mi> <mml:mo>)</mml:mo></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(52)</label></disp-formula>
<disp-formula id="pcbi.1005186.e070"><alternatives><graphic id="pcbi.1005186.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e070" xlink:type="simple"/><mml:math display="block" id="M70"><mml:mrow><mml:mi>P</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">u</mml:mi> <mml:mo>,</mml:mo> <mml:mi>z</mml:mi></mml:mfenced> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close="" open="(" separators=""><mml:mi mathvariant="bold">x</mml:mi> <mml:mo>;</mml:mo> <mml:mi mathvariant="bold">A</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:mi mathvariant="bold">b</mml:mi></mml:mfenced> <mml:mrow><mml:mo>,</mml:mo> <mml:mi mathvariant="bold">C</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(53)</label></disp-formula>
then this leaves the data distribution <italic>P</italic> (<bold>x</bold>), and hence the dynamics intact.</p>
</sec>
<sec id="sec016">
<title>Deriving the 1D approximate model</title>
<p>
<disp-formula id="pcbi.1005186.e071">
<alternatives>
<graphic id="pcbi.1005186.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e071" xlink:type="simple"/>
<mml:math display="block" id="M71">
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="bold">u</mml:mi>
<mml:mo>˙</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mi>τ</mml:mi>
</mml:mfrac>
<mml:mi mathvariant="bold">M</mml:mi>
<mml:mfenced close=")" open="(" separators="">
<mml:mi mathvariant="bold">u</mml:mi>
<mml:mo>-</mml:mo>
<mml:mi mathvariant="bold">v</mml:mi>
</mml:mfenced>
</mml:mrow>
</mml:math>
</alternatives>
<label>(54)</label>
</disp-formula>
<disp-formula id="pcbi.1005186.e072">
<alternatives>
<graphic id="pcbi.1005186.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e072" xlink:type="simple"/>
<mml:math display="block" id="M72">
<mml:mrow>
<mml:mover accent="true">
<mml:mi mathvariant="bold">v</mml:mi>
<mml:mo>˙</mml:mo>
</mml:mover>
<mml:mo>=</mml:mo>
<mml:mfrac>
<mml:mn>1</mml:mn>
<mml:mi>τ</mml:mi>
</mml:mfrac>
<mml:mi mathvariant="bold">M</mml:mi>
<mml:mfenced close=")" open="(" separators="">
<mml:mi mathvariant="bold">u</mml:mi>
<mml:mo>-</mml:mo>
<mml:mi mathvariant="bold">v</mml:mi>
</mml:mfenced>
<mml:mo>-</mml:mo>
<mml:mfrac>
<mml:mi>z</mml:mi>
<mml:msubsup>
<mml:mi>σ</mml:mi>
<mml:mi mathvariant="normal">x</mml:mi>
<mml:mn>2</mml:mn>
</mml:msubsup>
</mml:mfrac>
<mml:msup>
<mml:mi mathvariant="bold">A</mml:mi>
<mml:mi>T</mml:mi>
</mml:msup>
<mml:mtext> </mml:mtext>
<mml:mfenced close=")" open="(" separators="">
<mml:mi mathvariant="bold">x</mml:mi>
<mml:mo>-</mml:mo>
<mml:mi>z</mml:mi>
<mml:mi mathvariant="bold">A</mml:mi>
<mml:mi mathvariant="bold">u</mml:mi>
</mml:mfenced>
<mml:mo>-</mml:mo>
<mml:mi mathvariant="bold">C</mml:mi>
<mml:mi mathvariant="bold">u</mml:mi>
</mml:mrow>
</mml:math>
</alternatives>
<label>(55)</label>
</disp-formula>
</p>
<p>Differentiating again yields
<disp-formula id="pcbi.1005186.e073"><alternatives><graphic id="pcbi.1005186.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e073" xlink:type="simple"/><mml:math display="block" id="M73"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¨</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mi mathvariant="bold">M</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>˙</mml:mo></mml:mover></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(56)</label></disp-formula>
substituting for <inline-formula id="pcbi.1005186.e074"><alternatives><graphic id="pcbi.1005186.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e074" xlink:type="simple"/><mml:math display="inline" id="M74"><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>˙</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005186.e075"><alternatives><graphic id="pcbi.1005186.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e075" xlink:type="simple"/><mml:math display="inline" id="M75"><mml:mover accent="true"><mml:mi mathvariant="bold">v</mml:mi> <mml:mo>˙</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, and collecting the terms that depend on <bold>u</bold>, we obtain
<disp-formula id="pcbi.1005186.e076"><alternatives><graphic id="pcbi.1005186.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e076" xlink:type="simple"/><mml:math display="block" id="M76"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¨</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mfrac> <mml:mi mathvariant="bold">M</mml:mi><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msup><mml:mi>z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi mathvariant="bold">C</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mfenced> <mml:mtext> </mml:mtext><mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(57)</label></disp-formula>
where <inline-formula id="pcbi.1005186.e077"><alternatives><graphic id="pcbi.1005186.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e077" xlink:type="simple"/><mml:math display="inline" id="M77"><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the posterior mean of <bold>u</bold> with fixed <italic>z</italic> (see Eqs <xref ref-type="disp-formula" rid="pcbi.1005186.e044">33</xref>, <xref ref-type="disp-formula" rid="pcbi.1005186.e048">37</xref> and <xref ref-type="disp-formula" rid="pcbi.1005186.e053">42</xref>)
<disp-formula id="pcbi.1005186.e078"><alternatives><graphic id="pcbi.1005186.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e078" xlink:type="simple"/><mml:math display="block" id="M78"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>z</mml:mi> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msup><mml:mi>z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mfenced> <mml:mtext> </mml:mtext><mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi></mml:mfenced> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mtext> </mml:mtext><mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mtext> </mml:mtext><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:math></alternatives> <label>(58)</label></disp-formula>
substituting <bold>M</bold> = (<bold>A</bold><sup><italic>T</italic></sup> <bold>A</bold>)<sup>−1</sup> (i.e. the ideal value for <bold>M</bold>), and <inline-formula id="pcbi.1005186.e079"><alternatives><graphic id="pcbi.1005186.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e079" xlink:type="simple"/><mml:math display="inline" id="M79"><mml:mi mathvariant="bold">C</mml:mi> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo><mml:mtext> </mml:mtext> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mi mathvariant="bold">A</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1005186.e047">Eq (36)</xref>), gives
<disp-formula id="pcbi.1005186.e080"><alternatives><graphic id="pcbi.1005186.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e080" xlink:type="simple"/><mml:math display="block" id="M80"><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¨</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:msup><mml:mi>τ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mfrac><mml:mtext> </mml:mtext> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msup><mml:mi>z</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mi mathvariant="normal">x</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mfenced> <mml:mfenced close=")" open="(" separators=""><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi mathvariant="bold">u</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(59)</label></disp-formula></p>
<p>Thus, for fixed <italic>z</italic>, each component of <bold>u</bold> evolves independently.</p>
</sec>
<sec id="sec017">
<title>Simulation protocol</title>
<p>We simulated stimulus onset by first running the sampler until it reached equilibrium with no stimulus, then turning on the stimulus. To represent no stimulus we sampled <bold>x</bold> from <italic>P</italic> (<bold>x</bold>|<italic>z</italic> = 0), and to represent stimulus, we sampled <bold>x</bold> from <italic>P</italic> (<bold>x</bold>|<italic>z</italic> = <italic>z</italic><sub>gen</sub>), where <italic>z</italic><sub>gen</sub> ∈ {0.5, 1, 2}.</p>
</sec>
<sec id="sec018">
<title>Computing LFPs and firing rates</title>
<p>To make contact with experimental data, we also computed local field potentials (LFPs), and firing rates. There are many methods for computing LFPs, we chose the simplest, averaging the membrane potentials across neurons, as it gave similar results to the other methods, without tuneable parameters. To compute firing rates, we used a rectified linear function of the membrane potential:
<disp-formula id="pcbi.1005186.e081"><alternatives><graphic id="pcbi.1005186.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005186.e081" xlink:type="simple"/><mml:math display="block" id="M81"><mml:mrow><mml:msub><mml:mi>f</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfenced close="" open="{" separators=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>u</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:msub><mml:mi>u</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd> <mml:mtd columnalign="left"><mml:mtext>otherwise</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:math></alternatives> <label>(60)</label></disp-formula></p>
</sec>
</sec>
<sec id="sec019">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1005186.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Our main results are robust to a range of <italic>ρ</italic> or equivalently <italic>τ</italic><sub><italic>L</italic></sub>.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005186.s002" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005186.s002" xlink:type="simple">
<label>S1 Code</label>
<caption>
<title>The code used to generate our simulations.</title>
<p>See readme for further details.</p>
<p>(ZIP)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank G. Orbán for useful discussions and suggestions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005186.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>. <article-title>Surface orientation from texture: ideal observers, generic observers and the information content of texture cues</article-title>. <source>Vision Research</source>. <year>1998</year>;<volume>38</volume>:<fpage>1655</fpage>–<lpage>1682</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0042-6989(97)00324-6" xlink:type="simple">10.1016/S0042-6989(97)00324-6</ext-link></comment> <object-id pub-id-type="pmid">9747502</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jacobs</surname> <given-names>RA</given-names></name>. <article-title>Optimal integration of texture and motion cues to depth</article-title>. <source>Vision Research</source>. <year>1999</year>;<volume>39</volume>:<fpage>3621</fpage>–<lpage>3629</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0042-6989(99)00088-7" xlink:type="simple">10.1016/S0042-6989(99)00088-7</ext-link></comment> <object-id pub-id-type="pmid">10746132</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Beers</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Sittig</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>van der Gon</surname> <given-names>JJD</given-names></name>. <article-title>Integration of proprioceptive and visual position-information: An experimentally supported model</article-title>. <source>Journal of Neurophysiology</source>. <year>1999</year>;<volume>81</volume>:<fpage>1355</fpage>–<lpage>1364</lpage>. <object-id pub-id-type="pmid">10085361</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source>. <year>2002</year>;<volume>415</volume>:<fpage>429</fpage>–<lpage>433</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/415429a" xlink:type="simple">10.1038/415429a</ext-link></comment> <object-id pub-id-type="pmid">11807554</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Ghahramani</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Jordan</surname> <given-names>MI</given-names></name>. <article-title>An internal model for sensorimotor integration</article-title>. <source>Science</source>. <year>1995</year>;<volume>269</volume>:<fpage>1880</fpage>–<lpage>1880</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.7569931" xlink:type="simple">10.1126/science.7569931</ext-link></comment> <object-id pub-id-type="pmid">7569931</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Körding</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>Bayesian integration in sensorimotor learning</article-title>. <source>Nature</source>. <year>2004</year>;<volume>427</volume>:<fpage>244</fpage>–<lpage>247</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gopnik</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Glymour</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sobel</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Schulz</surname> <given-names>LE</given-names></name>, <name name-style="western"><surname>Kushnir</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Danks</surname> <given-names>D</given-names></name>. <article-title>A theory of causal learning in children: causal maps and Bayes nets</article-title>. <source>Psychological review</source>. <year>2004</year>;<volume>111</volume>:<fpage>3</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.111.1.3" xlink:type="simple">10.1037/0033-295X.111.1.3</ext-link></comment> <object-id pub-id-type="pmid">14756583</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chater</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Yuille</surname> <given-names>A</given-names></name>. <article-title>Probabilistic models of cognition: Conceptual foundations</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2006</year>;<volume>10</volume>:<fpage>287</fpage>–<lpage>291</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2006.05.007" xlink:type="simple">10.1016/j.tics.2006.05.007</ext-link></comment> <object-id pub-id-type="pmid">16807064</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Kemp</surname> <given-names>C</given-names></name>. <article-title>Theory-based Bayesian models of inductive learning and reasoning</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2006</year>;<volume>10</volume>:<fpage>309</fpage>–<lpage>318</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2006.05.009" xlink:type="simple">10.1016/j.tics.2006.05.009</ext-link></comment> <object-id pub-id-type="pmid">16797219</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Orbán</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>. <article-title>Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment</article-title>. <source>Science</source>. <year>2011</year>;<volume>331</volume>:<fpage>83</fpage>–<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1195870" xlink:type="simple">10.1126/science.1195870</ext-link></comment> <object-id pub-id-type="pmid">21212356</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Orbán</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Neural variability and sampling-based probabilistic representations in the visual cortex</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>92</volume>:<fpage>530</fpage>–<lpage>543</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2016.09.038" xlink:type="simple">10.1016/j.neuron.2016.09.038</ext-link></comment> <object-id pub-id-type="pmid">27764674</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hyvärinen</surname> <given-names>A</given-names></name>. <article-title>Statistical models of natural images and cortical visual representation</article-title>. <source>Topics in Cognitive Science</source>. <year>2010</year>;<volume>2</volume>:<fpage>251</fpage>–<lpage>264</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1756-8765.2009.01057.x" xlink:type="simple">10.1111/j.1756-8765.2009.01057.x</ext-link></comment> <object-id pub-id-type="pmid">25163788</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name>. <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source>. <year>1996</year>;<volume>381</volume>:<fpage>607</fpage>–<lpage>609</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/381607a0" xlink:type="simple">10.1038/381607a0</ext-link></comment> <object-id pub-id-type="pmid">8637596</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>Natural signal statistics and sensory gain control</article-title>. <source>Nature Neuroscience</source>. <year>2001</year>;<volume>4</volume>:<fpage>819</fpage>–<lpage>825</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/90526" xlink:type="simple">10.1038/90526</ext-link></comment> <object-id pub-id-type="pmid">11477428</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Karklin</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Lewicki</surname> <given-names>MS</given-names></name>. <article-title>Emergence of complex cell properties by learning to generalize in natural scenes</article-title>. <source>Nature</source>. <year>2009</year>;<volume>457</volume>:<fpage>83</fpage>–<lpage>86</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07481" xlink:type="simple">10.1038/nature07481</ext-link></comment> <object-id pub-id-type="pmid">19020501</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Coen-Cagli</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>. <article-title>Cortical surround interactions and perceptual salience via natural scene statistics</article-title>. <source>PLoS Computational Biology</source>. <year>2012</year>;<volume>8</volume>:<fpage>e1002405</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002405" xlink:type="simple">10.1371/journal.pcbi.1002405</ext-link></comment> <object-id pub-id-type="pmid">22396635</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>. <article-title>Probabilistic brains: knowns and unknowns</article-title>. <source>Nature Neuroscience</source>. <year>2013</year>;<volume>16</volume>:<fpage>1170</fpage>–<lpage>1178</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3495" xlink:type="simple">10.1038/nn.3495</ext-link></comment> <object-id pub-id-type="pmid">23955561</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rao</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Ballard</surname> <given-names>DH</given-names></name>. <article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title>. <source>Nature Neuroscience</source>. <year>1999</year>;<volume>2</volume>:<fpage>79</fpage>–<lpage>87</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/4580" xlink:type="simple">10.1038/4580</ext-link></comment> <object-id pub-id-type="pmid">10195184</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Reading population codes: a neural implementation of ideal observers</article-title>. <source>Nature Neuroscience</source>. <year>1999</year>;<volume>2</volume>:<fpage>740</fpage>–<lpage>745</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/11205" xlink:type="simple">10.1038/11205</ext-link></comment> <object-id pub-id-type="pmid">10412064</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zemel</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Probabilistic interpretation of population codes</article-title>. <source>Neural Computation</source>. <year>1998</year>;<volume>10</volume>:<fpage>403</fpage>–<lpage>430</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976698300017818" xlink:type="simple">10.1162/089976698300017818</ext-link></comment> <object-id pub-id-type="pmid">9472488</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Doubly distributional population codes: simultaneous representation of uncertainty and multiplicity</article-title>. <source>Neural Computation</source>. <year>2003</year>;<volume>15</volume>:<fpage>2255</fpage>–<lpage>2279</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976603322362356" xlink:type="simple">10.1162/089976603322362356</ext-link></comment> <object-id pub-id-type="pmid">14511521</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Bayesian inference with probabilistic population codes</article-title>. <source>Nature Neuroscience</source>. <year>2006</year>;<volume>9</volume>:<fpage>1432</fpage>–<lpage>1438</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1790" xlink:type="simple">10.1038/nn1790</ext-link></comment> <object-id pub-id-type="pmid">17057707</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hanks</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Churchland</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Roitman</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Probabilistic Population Codes for Bayesian Decision Making</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>60</volume>:<fpage>1142</fpage>–<lpage>1152</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2008.09.021" xlink:type="simple">10.1016/j.neuron.2008.09.021</ext-link></comment> <object-id pub-id-type="pmid">19109917</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Marginalization in neural circuits with divisive normalization</article-title>. <source>The Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>:<fpage>15310</fpage>–<lpage>15319</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1706-11.2011" xlink:type="simple">10.1523/JNEUROSCI.1706-11.2011</ext-link></comment> <object-id pub-id-type="pmid">22031877</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref025">
<label>25</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hoyer</surname> <given-names>PO</given-names></name>, <name name-style="western"><surname>Hyvarinen</surname> <given-names>A</given-names></name>. <source>Interpreting neural response variability as Monte Carlo sampling of the posterior</source>. <year>2003</year>;p. <fpage>293</fpage>–<lpage>300</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Bill</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Nessler</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name>. <article-title>Neural dynamics as sampling: A model for stochastic computation in recurrent networks of spiking neurons</article-title>. <source>PLoS Computational Biology</source>. <year>2011</year>;<volume>7</volume>:<fpage>e1002211</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002211" xlink:type="simple">10.1371/journal.pcbi.1002211</ext-link></comment> <object-id pub-id-type="pmid">22096452</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Basar</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Guntekin</surname> <given-names>B</given-names></name>. <article-title>A review of brain oscillations in cognitive disorders and the role of neurotransmitters</article-title>. <source>Brain Research</source>. <year>2008</year>;<volume>1235</volume>:<fpage>172</fpage>–<lpage>193</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.brainres.2008.06.103" xlink:type="simple">10.1016/j.brainres.2008.06.103</ext-link></comment> <object-id pub-id-type="pmid">18640103</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Müller</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Metha</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Krauskopf</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lennie</surname> <given-names>P</given-names></name>. <article-title>Rapid adaptation in visual cortex to the structure of images</article-title>. <source>Science</source>. <year>1999</year>;<volume>285</volume>:<fpage>1405</fpage>–<lpage>1408</lpage>. <object-id pub-id-type="pmid">10464100</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Müller</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Metha</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Krauskopf</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lennie</surname> <given-names>P</given-names></name>. <article-title>Information conveyed by onset transients in responses of striate cortical neurons</article-title>. <source>The Journal of Neuroscience</source>. <year>2001</year>;<volume>21</volume>:<fpage>6978</fpage>–<lpage>6990</lpage>. <object-id pub-id-type="pmid">11517285</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ray</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JHR</given-names></name>. <article-title>Differences in gamma frequencies across visual cortex restrict their possible use in computation</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>67</volume>:<fpage>885</fpage>–<lpage>896</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.08.004" xlink:type="simple">10.1016/j.neuron.2010.08.004</ext-link></comment> <object-id pub-id-type="pmid">20826318</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Armstrong</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>T</given-names></name>. <article-title>Rapid enhancement of visual cortical response discriminability by microstimulation of the frontal eye field</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2007</year>;<volume>104</volume>:<fpage>9499</fpage>–<lpage>9504</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0701104104" xlink:type="simple">10.1073/pnas.0701104104</ext-link></comment> <object-id pub-id-type="pmid">17517599</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Luczak</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bartho</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>KD</given-names></name>. <article-title>Gating of sensory input by spontaneous cortical activity</article-title>. <source>The Journal of Neuroscience</source>. <year>2013</year>;<volume>33</volume>:<fpage>1684</fpage>–<lpage>1695</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2928-12.2013" xlink:type="simple">10.1523/JNEUROSCI.2928-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23345241</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Li</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Computational differences between asymmetrical and symmetrical networks</article-title>. <source>Network</source>. <year>1999</year>;<volume>10</volume>:<fpage>59</fpage>–<lpage>77</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/0954-898X_10_1_004" xlink:type="simple">10.1088/0954-898X_10_1_004</ext-link></comment> <object-id pub-id-type="pmid">10372762</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Van Hooser</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KD</given-names></name>. <article-title>The stabilized supralinear network: a unifying circuit motif underlying multi-input integration in sensory cortex</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>85</volume>:<fpage>402</fpage>–<lpage>417</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.12.026" xlink:type="simple">10.1016/j.neuron.2014.12.026</ext-link></comment> <object-id pub-id-type="pmid">25611511</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Orbán</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2010</year>;<volume>14</volume>:<fpage>119</fpage>–<lpage>130</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2010.01.003" xlink:type="simple">10.1016/j.tics.2010.01.003</ext-link></comment> <object-id pub-id-type="pmid">20153683</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Duane</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kennedy</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Pendleton</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Roweth</surname> <given-names>D</given-names></name>. <article-title>Hybrid monte carlo</article-title>. <source>Physics letters B</source>. <year>1987</year>;<volume>195</volume>:<fpage>216</fpage>–<lpage>222</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0370-2693(87)91197-X" xlink:type="simple">10.1016/0370-2693(87)91197-X</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref037">
<label>37</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Neal</surname> <given-names>R</given-names></name>. <chapter-title>MCMC using Hamiltonian dynamics</chapter-title>. In: <name name-style="western"><surname>Brooks</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gelman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Meng</surname> <given-names>XL</given-names></name>, editors. <source>Handbook of Markov Chain Monte Carlo</source>. <publisher-name>Chapman &amp; Hall/CRC</publisher-name>; <year>2011</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1201/b10905-6" xlink:type="simple">10.1201/b10905-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Okun</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lampl</surname> <given-names>I</given-names></name>. <article-title>Instantaneous correlation of excitation and inhibition during ongoing and sensory-evoked activities</article-title>. <source>Nature Neuroscience</source>. <year>2008</year>;<volume>11</volume>:<fpage>535</fpage>–<lpage>537</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2105" xlink:type="simple">10.1038/nn.2105</ext-link></comment> <object-id pub-id-type="pmid">18376400</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roberts</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Lowet</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Brunet</surname> <given-names>NM</given-names></name>, <name name-style="western"><surname>Ter Wal</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tiesinga</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Robust gamma coherence between macaque V1 and V2 by dynamic frequency matching</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>78</volume>:<fpage>523</fpage>–<lpage>536</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.03.003" xlink:type="simple">10.1016/j.neuron.2013.03.003</ext-link></comment> <object-id pub-id-type="pmid">23664617</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wainwright</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>Scale mixtures of Gaussians and the statistics of natural images</article-title>. <source>Neural Information Processing Systems</source> <volume>12</volume>. <year>1999</year>;p. <fpage>855</fpage>–<lpage>861</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Assignment of multiplicative mixtures in natural images</article-title>. In: <source>Advances in Neural Information Processing Systems</source> <volume>17</volume>; <year>2004</year>. p. <fpage>1217</fpage>–<lpage>1224</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Karklin</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Lewicki</surname> <given-names>MS</given-names></name>. <article-title>Emergence of complex cell properties by learning to generalize in natural scenes</article-title>. <source>Nature</source>. <year>2009</year>;<volume>457</volume>:<fpage>83</fpage>–<lpage>86</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07481" xlink:type="simple">10.1038/nature07481</ext-link></comment> <object-id pub-id-type="pmid">19020501</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <article-title>A structured model of video reproduces primary visual cortical organisation</article-title>. <source>PLoS Computational Biology</source>. <year>2009</year>;<volume>5</volume>:<fpage>e1000495</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000495" xlink:type="simple">10.1371/journal.pcbi.1000495</ext-link></comment> <object-id pub-id-type="pmid">19730679</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Coen-Cagli</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>. <article-title>Statistical models of linear and nonlinear contextual interactions in early visual processing</article-title>. In: <source>Advances in Neural Information Processing Systems</source> <volume>22</volume>; <year>2009</year>. p. <fpage>369</fpage>–<lpage>377</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Churchland</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Yu</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Sugrue</surname> <given-names>LP</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>MR</given-names></name>, <etal>et al</etal>. <article-title>Stimulus onset quenches neural variability: a widespread cortical phenomenon</article-title>. <source>Nature Neuroscience</source>. <year>2010</year>;<volume>13</volume>:<fpage>369</fpage>–<lpage>378</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2501" xlink:type="simple">10.1038/nn.2501</ext-link></comment> <object-id pub-id-type="pmid">20173745</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Perceptual organization in the tilt illusion</article-title>. <source>Journal of Vision</source>. <year>2009</year>;<volume>9</volume>:<fpage>19</fpage>–<lpage>19</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/9.4.19" xlink:type="simple">10.1167/9.4.19</ext-link></comment> <object-id pub-id-type="pmid">19757928</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tsodyks</surname> <given-names>MV</given-names></name>, <name name-style="western"><surname>Skaggs</surname> <given-names>WE</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>. <article-title>Paradoxical effects of external modulation of inhibitory interneurons</article-title>. <source>The Journal of Neuroscience</source>. <year>1997</year>;<volume>17</volume>:<fpage>4382</fpage>–<lpage>4388</lpage>. <object-id pub-id-type="pmid">9151754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Murphy</surname> <given-names>BK</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KD</given-names></name>. <article-title>Balanced amplification: a new mechanism of selective amplification of neural activity patterns</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>61</volume>:<fpage>635</fpage>–<lpage>648</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.02.005" xlink:type="simple">10.1016/j.neuron.2009.02.005</ext-link></comment> <object-id pub-id-type="pmid">19249282</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hennequin</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Vogels</surname> <given-names>TP</given-names></name>, <name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>. <article-title>Optimal control of transient dynamics in balanced networks supports generation of complex movements</article-title>. <source>Neuron</source>. <year>2014</year>;<volume>82</volume>:<fpage>1394</fpage>–<lpage>1406</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.04.045" xlink:type="simple">10.1016/j.neuron.2014.04.045</ext-link></comment> <object-id pub-id-type="pmid">24945778</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pfister</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Synapses with short-term plasticity are optimal estimators of presynaptic membrane potentials</article-title>. <source>Nature Neuroscience</source>. <year>2010</year>;<volume>13</volume>:<fpage>1271</fpage>–<lpage>1275</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2640" xlink:type="simple">10.1038/nn.2640</ext-link></comment> <object-id pub-id-type="pmid">20852625</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ujfalussy</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Makara</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Branco</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Dendritic nonlinearities are tuned for efficient spike-based computations in cortical circuits</article-title>. <source>eLife</source>. <year>2015</year>;<volume>4</volume>:<fpage>e10056</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.7554/eLife.10056" xlink:type="simple">10.7554/eLife.10056</ext-link></comment> <object-id pub-id-type="pmid">26705334</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Loebel</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Nelken</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>. <article-title>Processing of sounds by population spikes in a model of primary auditory cortex</article-title>. <source>Frontiers in Neuroscience</source>. <year>2007</year>;<volume>1</volume>:<fpage>197</fpage>–<lpage>207</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.01.1.1.015.2007" xlink:type="simple">10.3389/neuro.01.1.1.015.2007</ext-link></comment> <object-id pub-id-type="pmid">18982129</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref053">
<label>53</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Turaga</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Packer</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Dalgleish</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Pettit</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Hausser</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <chapter-title>Inferring neural population dynamics from multiple partial recordings of the same neural circuit</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>; <year>2013</year>. p. <fpage>539</fpage>–<lpage>547</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Macke</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Buesing</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Byron</surname> <given-names>MY</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <article-title>Empirical models of spiking in neural populations</article-title>. In: <source>Advances in Neural Information Processing Systems</source> <volume>11</volume>; <year>2011</year>. p. <fpage>1350</fpage>–<lpage>1358</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roberts</surname> <given-names>GO</given-names></name>, <name name-style="western"><surname>Tweedie</surname> <given-names>RL</given-names></name>. <article-title>Exponential convergence of Langevin distributions and their discrete approximations</article-title>. <source>Bernoulli</source>. <year>1996</year>;<volume>2</volume>:<fpage>341</fpage>–<lpage>363</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hennequin</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Aitchison</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Fast sampling-based inference in balanced neuronal networks</article-title>. In: <source>Advances in Neural Information Processing Systems</source> <volume>27</volume>; <year>2014</year>. p. <fpage>2240</fpage>–<lpage>2248</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref057">
<label>57</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Buzsaki</surname> <given-names>G</given-names></name>. <source>Rhythms of the Brain</source>. <publisher-name>Oxford University Press</publisher-name>; <year>2006</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/acprof:oso/9780195301069.001.0001" xlink:type="simple">10.1093/acprof:oso/9780195301069.001.0001</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>HR</given-names></name>, <name name-style="western"><surname>Cowan</surname> <given-names>JD</given-names></name>. <article-title>Excitatory and inhibitory interactions in localized populations of model neurons</article-title>. <source>Biophysical Journal</source>. <year>1972</year>;<volume>12</volume>:<fpage>1</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0006-3495(72)86068-5" xlink:type="simple">10.1016/S0006-3495(72)86068-5</ext-link></comment> <object-id pub-id-type="pmid">4332108</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Milotti</surname> <given-names>E</given-names></name>. <article-title>1/f noise: a pedagogical review</article-title>. <source>arXiv preprint</source>. <year>2002</year>;p. <fpage>0204033</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bermudez Contreras</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Schjetnan</surname> <given-names>AGP</given-names></name>, <name name-style="western"><surname>Muhammad</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bartho</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>McNaughton</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Kolb</surname> <given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Formation and reverberation of sequential neural activity patterns evoked by sensory stimulation are enhanced during cortical desynchronization</article-title>. <source>Neuron</source>. <year>2013</year>;<volume>79</volume>:<fpage>555</fpage>–<lpage>566</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.06.013" xlink:type="simple">10.1016/j.neuron.2013.06.013</ext-link></comment> <object-id pub-id-type="pmid">23932001</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Lu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Snider</surname> <given-names>RK</given-names></name>, <name name-style="western"><surname>Liang</surname> <given-names>L</given-names></name>. <article-title>Sustained firing in auditory cortex evoked by preferred stimuli</article-title>. <source>Nature</source>. <year>2005</year>;<volume>435</volume>:<fpage>341</fpage>–<lpage>346</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature03565" xlink:type="simple">10.1038/nature03565</ext-link></comment> <object-id pub-id-type="pmid">15902257</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Buzsáki</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Watson</surname> <given-names>BO</given-names></name>. <article-title>Brain rhythms and neural syntax: implications for efficient coding of cognitive content and neuropsychiatric disease</article-title>. <source>Dialogues in Clinical Neuroscience</source>. <year>2012</year>;<volume>14</volume>:<fpage>345</fpage>. <object-id pub-id-type="pmid">23393413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Savin</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Peter</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Optimal recall from bounded metaplastic synapses: predicting functional adaptations in hippocampal area CA3</article-title>. <source>PLoS Computational Biology</source>. <year>2014</year>;<volume>10</volume>:<fpage>e1003489</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003489" xlink:type="simple">10.1371/journal.pcbi.1003489</ext-link></comment> <object-id pub-id-type="pmid">24586137</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Neal</surname> <given-names>RM</given-names></name>. <article-title>Sampling from multimodal distributions using tempered transitions</article-title>. <source>Statistics and computing</source>. <year>1996</year>;<volume>6</volume>:<fpage>353</fpage>–<lpage>366</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00143556" xlink:type="simple">10.1007/BF00143556</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Womelsdorf</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Schoffelen</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Oostenveld</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Desimone</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>AK</given-names></name>, <etal>et al</etal>. <article-title>Modulation of Neuronal Interactions Through Neuronal Synchronization</article-title>. <source>Science</source>. <year>2007</year>;<volume>316</volume>:<fpage>1609</fpage>–<lpage>1612</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1139597" xlink:type="simple">10.1126/science.1139597</ext-link></comment> <object-id pub-id-type="pmid">17569862</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fries</surname> <given-names>P</given-names></name>. <article-title>Neuronal gamma-band synchronization as a fundamental process in cortical computation</article-title>. <source>Annual Review of Neuroscience</source>. <year>2009</year>;<volume>32</volume>:<fpage>209</fpage>–<lpage>224</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.051508.135603" xlink:type="simple">10.1146/annurev.neuro.051508.135603</ext-link></comment> <object-id pub-id-type="pmid">19400723</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Singer</surname> <given-names>W</given-names></name>. <article-title>Neuronal synchrony: a versatile code for the definition of relations?</article-title> <source>Neuron</source>. <year>1999</year>;<volume>24</volume>:<fpage>49</fpage>–<lpage>65</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(00)80821-1" xlink:type="simple">10.1016/S0896-6273(00)80821-1</ext-link></comment> <object-id pub-id-type="pmid">10677026</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Markram</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Sjöström</surname> <given-names>PJ</given-names></name>. <article-title>Spike-timing-dependent plasticity: A comprehensive overview</article-title>. <source>Frontiers in Synaptic Neuroscience</source>. <year>2012</year>;<volume>4</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnsyn.2012.00002" xlink:type="simple">10.3389/fnsyn.2012.00002</ext-link></comment> <object-id pub-id-type="pmid">22807913</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kullmann</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Moreau</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Bakiri</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Nicholson</surname> <given-names>E</given-names></name>. <article-title>Plasticity of inhibition</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>75</volume>:<fpage>951</fpage>–<lpage>962</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.07.030" xlink:type="simple">10.1016/j.neuron.2012.07.030</ext-link></comment> <object-id pub-id-type="pmid">22998865</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref070">
<label>70</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>. <source>Theoretical Neuroscience</source>. <publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>; <year>2001</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dempster</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Laird</surname> <given-names>NM</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <article-title>Maximum likelihood from incomplete data via the EM algorithm</article-title>. <source>Journal of the Royal Statistical Society Series B (Methodological)</source>. <year>1977</year>;p. <fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref072">
<label>72</label>
<mixed-citation publication-type="other" xlink:type="simple">
Zhang YY, Li Y, Gong HQ, Liang PJ. Temporal and Spatial Properties of the Retinal Ganglion Cells’ Response to Natural Stimuli Described by Treves-Rolls Sparsity. In: 2009 3rd International Conference on Bioinformatics and Biomedical Engineering; 2009. p. 1–4.</mixed-citation>
</ref>
<ref id="pcbi.1005186.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tripathy</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Burton</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Geramita</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gerkin</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Urban</surname> <given-names>NN</given-names></name>. <article-title>Brain-wide analysis of electrophysiological diversity yields novel categorization of mammalian neuron types</article-title>. <source>Journal of Neurophysiology</source>. <year>2015</year>;<volume>113</volume>:<fpage>3474</fpage>–<lpage>3489</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00237.2015" xlink:type="simple">10.1152/jn.00237.2015</ext-link></comment> <object-id pub-id-type="pmid">25810482</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Watson</surname> <given-names>AB</given-names></name>. <article-title>A formula for human retinal ganglion cell receptive field density as a function of visual field location</article-title>. <source>Journal of Vision</source>. <year>2014</year>;<volume>14</volume>:<fpage>1</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1167/14.7.15" xlink:type="simple">10.1167/14.7.15</ext-link></comment> <object-id pub-id-type="pmid">24982468</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reid</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Alonso</surname> <given-names>JM</given-names></name>, <etal>et al</etal>. <article-title>Specificity of monosynaptic connections from thalamus to visual cortex</article-title>. <source>Nature</source>. <year>1995</year>;<volume>378</volume>:<fpage>281</fpage>–<lpage>283</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/378281a0" xlink:type="simple">10.1038/378281a0</ext-link></comment> <object-id pub-id-type="pmid">7477347</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tripathy</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Savitskaya</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Burton</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Urban</surname> <given-names>NN</given-names></name>, <name name-style="western"><surname>Gerkin</surname> <given-names>RC</given-names></name>. <article-title>NeuroElectro: a window to the world’s neuron electrophysiology data</article-title>. <source>Frontiers in Neuroinformatics</source>. <year>2014</year>;<volume>8</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fninf.2014.00040" xlink:type="simple">10.3389/fninf.2014.00040</ext-link></comment> <object-id pub-id-type="pmid">24808858</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref077">
<label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mizuseki</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Buzsáki</surname> <given-names>G</given-names></name>. <article-title>Preconfigured, skewed distribution of firing rates in the hippocampus and entorhinal cortex</article-title>. <source>Cell Reports</source>. <year>2013</year>;<volume>4</volume>:<fpage>1010</fpage>–<lpage>1021</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.celrep.2013.07.039" xlink:type="simple">10.1016/j.celrep.2013.07.039</ext-link></comment> <object-id pub-id-type="pmid">23994479</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref078">
<label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>O’Connor</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Peron</surname> <given-names>SP</given-names></name>, <name name-style="western"><surname>Huber</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Svoboda</surname> <given-names>K</given-names></name>. <article-title>Neural activity in barrel cortex underlying vibrissa-based object localization in mice</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>67</volume>:<fpage>1048</fpage>–<lpage>1061</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.08.026" xlink:type="simple">10.1016/j.neuron.2010.08.026</ext-link></comment> <object-id pub-id-type="pmid">20869600</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Branco</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Staras</surname> <given-names>K</given-names></name>. <article-title>The probability of neurotransmitter release: variability and feedback control at single synapses</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2009</year>;<volume>10</volume>:<fpage>373</fpage>–<lpage>383</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2634" xlink:type="simple">10.1038/nrn2634</ext-link></comment> <object-id pub-id-type="pmid">19377502</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref080">
<label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Song</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sjöström</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Reigl</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Chklovskii</surname> <given-names>DB</given-names></name>. <article-title>Highly nonrandom features of synaptic connectivity in local cortical circuits</article-title>. <source>PLoS Biology</source>. <year>2005</year>;<volume>3:</volume> <fpage>e68</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0030068" xlink:type="simple">10.1371/journal.pbio.0030068</ext-link></comment> <object-id pub-id-type="pmid">15737062</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref081">
<label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bremaud</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>West</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Thomson</surname> <given-names>AM</given-names></name>. <article-title>Binomial parameters differ across neocortical layers and with different classes of connections in adult rat and cat neocortex</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2007</year>;<volume>104</volume>:<fpage>14134</fpage>–<lpage>14139</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0705661104" xlink:type="simple">10.1073/pnas.0705661104</ext-link></comment> <object-id pub-id-type="pmid">17702864</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005186.ref082">
<label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stern</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Kincaid</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>CJ</given-names></name>. <article-title>Spontaneous subthreshold membrane potential fluctuations and action potential variability of rat corticostriatal and striatal neurons in vivo</article-title>. <source>Journal of Neurophysiology</source>. <year>1997</year>;<volume>77</volume>:<fpage>1697</fpage>–<lpage>1715</lpage>. <object-id pub-id-type="pmid">9114230</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
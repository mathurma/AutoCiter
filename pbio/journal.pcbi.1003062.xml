<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-00026</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003062</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject><subject>Sensory systems</subject></subj-group></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Mathematics</subject><subj-group><subject>Probability theory</subject></subj-group><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Are V1 Simple Cells Optimized for Visual Occlusions? A Comparative Study</article-title>
<alt-title alt-title-type="running-head">Are V1 Simple Cells Optimized for Occlusions?</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bornschein</surname><given-names>Jörg</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Henniges</surname><given-names>Marc</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Lücke</surname><given-names>Jörg</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Frankfurt Institute for Advanced Studies, Goethe-Universität Frankfurt, Frankfurt, Germany</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Department of Physics, Goethe-Universität Frankfurt, Frankfurt, Germany</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">luecke@fias.uni-frankfurt.de</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: JL JB. Performed the experiments: JB MH JL. Analyzed the data: JB. Wrote the paper: JL JB. Algorithms' implementation and parallelization: JB MH.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>6</month><year>2013</year></pub-date>
<pub-date pub-type="epub"><day>6</day><month>6</month><year>2013</year></pub-date>
<volume>9</volume>
<issue>6</issue>
<elocation-id>e1003062</elocation-id>
<history>
<date date-type="received"><day>2</day><month>1</month><year>2013</year></date>
<date date-type="accepted"><day>21</day><month>3</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2013</copyright-year>
<copyright-holder>Bornschein et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Simple cells in primary visual cortex were famously found to respond to low-level image components such as edges. Sparse coding and independent component analysis (ICA) emerged as the standard computational models for simple cell coding because they linked their receptive fields to the statistics of visual stimuli. However, a salient feature of image statistics, occlusions of image components, is not considered by these models. Here we ask if occlusions have an effect on the predicted shapes of simple cell receptive fields. We use a comparative approach to answer this question and investigate two models for simple cells: a standard linear model and an occlusive model. For both models we simultaneously estimate optimal receptive fields, sparsity and stimulus noise. The two models are identical except for their component superposition assumption. We find the image encoding and receptive fields predicted by the models to differ significantly. While both models predict many Gabor-like fields, the occlusive model predicts a much sparser encoding and high percentages of ‘globular’ receptive fields. This relatively new center-surround type of simple cell response is observed since reverse correlation is used in experimental studies. While high percentages of ‘globular’ fields can be obtained using specific choices of sparsity and overcompleteness in linear sparse coding, no or only low proportions are reported in the vast majority of studies on linear models (including all ICA models). Likewise, for the here investigated linear model and optimal sparsity, only low proportions of ‘globular’ fields are observed. In comparison, the occlusive model robustly infers high proportions and can match the experimentally observed high proportions of ‘globular’ fields well. Our computational study, therefore, suggests that ‘globular’ fields may be evidence for an optimal encoding of visual occlusions in primary visual cortex.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>The statistics of our visual world is dominated by occlusions. Almost every image processed by our brain consists of mutually occluding objects, animals and plants. Our visual cortex is optimized through evolution and throughout our lifespan for such stimuli. Yet, the standard computational models of primary visual processing do not consider occlusions. In this study, we ask what effects visual occlusions may have on predicted response properties of simple cells which are the first cortical processing units for images. Our results suggest that recently observed differences between experiments and predictions of the standard simple cell models can be attributed to occlusions. The most significant consequence of occlusions is the prediction of many cells sensitive to center-surround stimuli. Experimentally, large quantities of such cells are observed since new techniques (reverse correlation) are used. Without occlusions, they are only obtained for specific settings and none of the seminal studies (sparse coding, ICA) predicted such fields. In contrast, the new type of response naturally emerges as soon as occlusions are considered. In comparison with recent <italic>in vivo</italic> experiments we find that occlusive models are consistent with the high percentages of center-surround simple cells observed in macaque monkeys, ferrets and mice.</p>
</abstract>
<funding-group><funding-statement>The work was funded by the German Research Foundation (DFG) grant LU 1196/4-2, by the German Ministry of Research and Education (BMBF) grant 01GQ0840 (BFNT Frankfurt), and by the Honda Research Institute Europe. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="16"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Evolution and synaptic plasticity optimize the visual cortex for the processing of visual stimuli. The quantification of the degree of optimization has long been subject of theoretical and physiological studies. Among the most influential contributions are models such as independent component analysis <xref ref-type="bibr" rid="pcbi.1003062-Comon1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen1">[3]</xref> (ICA) and sparse coding <xref ref-type="bibr" rid="pcbi.1003062-Olshausen1">[4]</xref> which became popular because they linked response properties of simple cells in primary visual cortex to the view of sensory systems as optimal information encoders <xref ref-type="bibr" rid="pcbi.1003062-Attneave1">[5]</xref>–. Since they were first introduced, many different versions of sparse coding and ICA have been investigated. While many technical studies focused on different ways to efficiently infer the model parameters <xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lee1">[9]</xref>, many others investigated the assumptions used in the underlying stimulus model itself such as the sparsity prior or the assumed stimulus noise <xref ref-type="bibr" rid="pcbi.1003062-Berkes1">[10]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen2">[13]</xref>. An assumption that has been investigated very little in the context of sparse coding models is the assumption of linear superposition of basis functions. For many types of data, linear superposition can be motivated by the actual combination of stimulus components (e.g., sound waveforms combine linearly). However, for image patches an assumption of linear superposition implies that component occlusions are not considered.</p>
<p>But does neglecting or including occlusions have an impact on receptive fields predicted by sparse coding? If so, what is the main difference if occlusions are considered and how do model predictions compare with experimental measurements? A critical inspection of standard sparse coding as a model for simple cell responses has recently been motivated by increasingly detailed experimental studies of simple cell responses. Using reverse correlation, a broad variety of receptive field shapes has been recorded, e.g., for macaque monkeys <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>, ferrets <xref ref-type="bibr" rid="pcbi.1003062-Usrey1">[15]</xref> or mice <xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref>. In general, the distribution of receptive field shapes was found to be more diverse than the distributions predicted, e.g., by sparse coding or ICA <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>. The most significant qualitative difference from modeling predictions was the experimental finding of large numbers of simple cells with globular instead of Gabor-like receptive fields <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref>. None of the seminal papers on simple cell coding <xref ref-type="bibr" rid="pcbi.1003062-Bell1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Olshausen2">[17]</xref> had predicted such fields. Experimentally, globular fields were presumably not prominently reported earlier because of previously used estimation and/or cell selection methods. If oriented stimuli (often Gabors or light-bars) with different orientations and positions are used, cells with globular or center-surround fields are difficult to detect.</p>
<p>After the discrepancy of diverse receptive field shapes and standard encoding models was pointed out <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>, further studies did show that large numbers of globular fields can be obtained in computational models <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke1">[18]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Olshausen3">[20]</xref>. Notably, two of these models <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Olshausen3">[20]</xref> are sparse coding versions based on a linear superposition assumption. One uses a specific sparse prior and a specific hand-set sparsity <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>. The other <xref ref-type="bibr" rid="pcbi.1003062-Olshausen3">[20]</xref> reports large numbers of globular fields for specific combinations of overcompleteness and sparsity. For the very large number of other studies on models with linear superposition (including all ICA models), no or only low proportions of globular fields were observed (compare, e.g., <xref ref-type="bibr" rid="pcbi.1003062-Lee1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Berkes1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Saxe1">[21]</xref>).</p>
<p>In this study we, for the first time, provide a systematic investigation of the impact of occlusion-like non-linearities on predicted simple cell responses. In order to quantify the differences to the neglection of occlusions, we study two sparse coding models: one assuming standard linear superposition <xref ref-type="bibr" rid="pcbi.1003062-Bell1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Olshausen2">[17]</xref> and the other approximating occlusions with strongly non-linear superpositions of components <xref ref-type="bibr" rid="pcbi.1003062-Lcke3">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Puertas1">[23]</xref>. <xref ref-type="fig" rid="pcbi-1003062-g001">Fig. 1A,B</xref> illustrates the difference between the linear and the non-linear superposition used. By comparing the two combination rules with the actual combination of components in images, we can observe a better match of the non-linear superposition rule to the actual combination of components. If all components had the same intensity (i.e., the same color for the illustration in <xref ref-type="fig" rid="pcbi-1003062-g001">Fig. 1A,B</xref>), the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e001" xlink:type="simple"/></inline-formula>-combination rule would represent the correct model for component occlusions <xref ref-type="bibr" rid="pcbi.1003062-Lcke3">[22]</xref> (also see <xref ref-type="fig" rid="pcbi-1003062-g002">Fig. 2</xref>). For components with different intensities, the non-linear combination is an approximation of the actual combination rule. However, the much weaker interferences resulting from the non-linear rule are a significantly closer match to occlusion non-linearities (see <xref ref-type="fig" rid="pcbi-1003062-g001">Fig. 1B</xref>).</p>
<fig id="pcbi-1003062-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003062.g001</object-id><label>Figure 1</label><caption>
<title>Illustration of the combination of image components, comparison with computational models of component combinations, and receptive field comparison.</title>
<p><bold>A</bold> Image patch (bottom left) showing an intersection of two branches extracted from a grey-level natural scene image (adapted from the van Hateren natural image database <xref ref-type="bibr" rid="pcbi.1003062-vanHateren1">[58]</xref> with permission from J. H. van Hateren). Preprocessed version of the image patch (bottom right) obtained by using a center-surround filter to model the preprocessing by the lateral geniculate nucleus. <bold>B</bold> Left: Two image patches manually generated from the grey-level patch in <bold>A</bold>. Each patch is dominated by one of the two crossing branches of the original patch. Middle: The preprocessed versions of the two patches (central parts). Right: Combination of the two preprocessed patches using an occlusive combination (top) and a standard linear combination (bottom). <bold>C</bold> Examples of globular and Gabor-like receptive fields measured in V1 of macaque monkeys (courtesy of D. Ringach), and examples of the two receptive field types predicted by the occlusive encoding model. <bold>D</bold> Percentages of globular receptive fields predicted by different models for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e002" xlink:type="simple"/></inline-formula> hidden units compared to percentages of globular fields of <italic>in vivo</italic> recordings.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003062.g001" position="float" xlink:type="simple"/></fig><fig id="pcbi-1003062-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003062.g002</object-id><label>Figure 2</label><caption>
<title>Example of the non-linear and the linear generative model.</title>
<p>Suppose all hidden units are zero except of units <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e025" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e026" xlink:type="simple"/></inline-formula>. In this case the patch is generated using the basis functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e027" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e028" xlink:type="simple"/></inline-formula>. If the two basis functions have the form as displayed on the right-hand-side, the non-linear and the linear model generate the patches on the left-hand-side. Given a pixel <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e029" xlink:type="simple"/></inline-formula>, the non-linear model chooses the basis function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e030" xlink:type="simple"/></inline-formula> with the maximal absolute value (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e031" xlink:type="simple"/></inline-formula>) to set the value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e032" xlink:type="simple"/></inline-formula> of the patch, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e033" xlink:type="simple"/></inline-formula>. For the example pixel (red box), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e034" xlink:type="simple"/></inline-formula> is chosen but for other pixels <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e035" xlink:type="simple"/></inline-formula> may be chosen. Note that the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e036" xlink:type="simple"/></inline-formula>-superposition models the exclusiveness of occlusion without considering object or edge depths. The linear model always sums the basis function values, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e037" xlink:type="simple"/></inline-formula>. After the generation of the noiseless patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e038" xlink:type="simple"/></inline-formula> both models assume the addition of Gaussian noise for the generation of patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e039" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003062.e006">Eqns. 2</xref> and <xref ref-type="disp-formula" rid="pcbi.1003062.e008">4</xref> but not shown in the figure). The color scale is defined as in <xref ref-type="fig" rid="pcbi-1003062-g001">Fig. 1</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003062.g002" position="float" xlink:type="simple"/></fig>
<p>Although the only difference between the two sparse coding models investigated is the rule for component combination, non-linear sparse coding versions have been investigated much less than linear versions because parameter optimization becomes more challenging. To model image patches for instance, large-scale applications of non-linear models with large numbers of observed and hidden variables have not yet been reported. By applying novel training methods <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref> it is possible to overcome computational tractability limitations, e.g., for the strongly non-linear model illustrated in <xref ref-type="fig" rid="pcbi-1003062-g001">Fig. 1</xref>. Consequently, we can systematically study the effect of the combination rule on receptive fields predicted by sparse coding. The models' predictions will allow us to answer the question if and how occlusions can impact simple cell coding. Comparison of the model predictions to <italic>in vivo</italic> recordings then provides experimental evidence for the impact of occlusions on simple cell coding.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Models for the encoding of image patches</title>
<p>We compare two generative sparse coding models for the encoding of image patches by simple cells. Both models have the same set of parameters and both assume, like standard sparse coding, independent visual components and Gaussian noise in the data. The distinguishing feature of the non-linear model is the use of a point-wise maximum to describe the combination of visual components. The maximum combination is illustrated and contrasted with the standard linear combination in <xref ref-type="fig" rid="pcbi-1003062-g002">Fig. 2</xref>. If we denote by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e003" xlink:type="simple"/></inline-formula> an observed image patch and by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e004" xlink:type="simple"/></inline-formula> the hidden units encoding presence or absence of components, the full generative formulation of the non-linear model is given by:<disp-formula id="pcbi.1003062.e005"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e005" xlink:type="simple"/><label>(1)</label></disp-formula><disp-formula id="pcbi.1003062.e006"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e006" xlink:type="simple"/><label>(2)</label></disp-formula>This model is compared to one assuming the standard linear superposition:<disp-formula id="pcbi.1003062.e007"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e007" xlink:type="simple"/><label>(3)</label></disp-formula><disp-formula id="pcbi.1003062.e008"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e008" xlink:type="simple"/><label>(4)</label></disp-formula>The parameters of both models are the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e009" xlink:type="simple"/></inline-formula> basis functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e010" xlink:type="simple"/></inline-formula> (which will later be related to receptive fields), the noise variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e011" xlink:type="simple"/></inline-formula>, and the sparsity parameterized by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e012" xlink:type="simple"/></inline-formula>. We define <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e013" xlink:type="simple"/></inline-formula> to be the matrix containing all basis functions (columns of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e014" xlink:type="simple"/></inline-formula>) and for brevity denote <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e015" xlink:type="simple"/></inline-formula> to be the set of all model parameters. The non-linear superposition in <xref ref-type="disp-formula" rid="pcbi.1003062.e006">equation 2</xref> is given by the function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e016" xlink:type="simple"/></inline-formula> (compare <xref ref-type="fig" rid="pcbi-1003062-g002">Fig. 2</xref>). Instead of linearly summing basis function entries at pixel <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e017" xlink:type="simple"/></inline-formula> like in the linear model (<xref ref-type="disp-formula" rid="pcbi.1003062.e008">Eqn. 4</xref>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e018" xlink:type="simple"/></inline-formula>), the mean value of the Gaussian, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e019" xlink:type="simple"/></inline-formula>, is set by the (active) basis function entry with maximal magnitude: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e020" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e021" xlink:type="simple"/></inline-formula>. The function in (2) is the vector valued version defined by applying the maximum magnitude function for each entry. By using a point-wise maximum, the model is a variant of <italic>maximal causes analysis</italic> (MCA) <xref ref-type="bibr" rid="pcbi.1003062-Lcke3">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Puertas1">[23]</xref> and will be referred to accordingly. For the generation of image patches, both models assume a basis function to be either part of the patch or not (binary hidden variables). Such an assumption is consistent with objects or edges being either present or absent in a given patch. However, binary hidden units are different from conventional sparse coding in which continuous hidden variables are used. For later comparison, we therefore also study conventional sparse coding based on the generative model given by:<disp-formula id="pcbi.1003062.e022"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e022" xlink:type="simple"/><label>(5)</label></disp-formula><disp-formula id="pcbi.1003062.e023"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e023" xlink:type="simple"/><label>(6)</label></disp-formula>where a Laplace prior is used to model continuous sparse values (instead of the Bernoulli prior used in the other two considered models). This model is the generative analogue of the objective function formulation of sparse coding with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e024" xlink:type="simple"/></inline-formula> regularization. We will refer to the model of <xref ref-type="disp-formula" rid="pcbi.1003062.e022">Eqn. 5</xref> and <xref ref-type="disp-formula" rid="pcbi.1003062.e023">Eqn. 6</xref> as <italic>standard sparse coding</italic> (SC) and to the linear model with Bernoulli prior (<xref ref-type="disp-formula" rid="pcbi.1003062.e007">Eqns. 3</xref> and <xref ref-type="disp-formula" rid="pcbi.1003062.e008">4</xref>) as <italic>binary sparse coding</italic> (BSC) <xref ref-type="bibr" rid="pcbi.1003062-Haft1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Henniges1">[26]</xref>.</p>
<p>For each model above we now seek the parameters that optimally model the statistics of image patches. As a result, each model predicts a set of basis functions which can be compared to each other and to <italic>in vivo</italic> recordings of simple cell receptive fields. To find optimal parameters, we apply maximum likelihood learning on the same set of preprocessed image patches (see <xref ref-type="sec" rid="s4">Methods</xref>). For maximal causes analysis (MCA) and binary sparse coding (BSC) we applied a variational EM approach <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref>, while parameter optimization for standard sparse coding (SC) applied a maximum a-posteriori approach <xref ref-type="bibr" rid="pcbi.1003062-Olshausen1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lee1">[9]</xref>. All optimization approaches used allow for the inference of parameters for large numbers of input and hidden units. While large-scale applicability of linear sparse coding models has been demonstrated repeatedly in the past <xref ref-type="bibr" rid="pcbi.1003062-Lee1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Olshausen2">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Olshausen4">[27]</xref>, comparatively efficient optimization of strongly non-linear models has only been demonstrated very recently <xref ref-type="bibr" rid="pcbi.1003062-Puertas1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref>. The optimization procedure applied to MCA and BSC furthermore allows the inference of all model parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e040" xlink:type="simple"/></inline-formula> including stimulus noise and sparsity. The only remaining parameters are the size of image patches and the number of basis functions (with the degree of over-completeness given by the ratio of the two).</p>
</sec><sec id="s2b">
<title>Comparison of predicted receptive fields</title>
<p>For the generative models above, we optimized the model parameters for a set of natural image patches. First, natural image patches were preprocessed using an array of linear center-surround filters to model preprocessing by the lateral geniculate nucleus (LGN). Details are given in the <xref ref-type="sec" rid="s4">Methods</xref> section. Given a fixed set of preprocessed stimuli, we optimized the parameters for the non-linear model (MCA), for binary sparse coding (BSC), and for standard sparse coding (see <xref ref-type="sec" rid="s4">Methods</xref> and Supporting Information). All models were applied to the same set of preprocessed patches (no independent ON-/OFF-channels). After optimization, all models predicted a large number of Gabor-like receptive fields (compare <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 A,B</xref>). However, we found significant quantitative differences in the statistics of receptive field shapes. Most saliently, the different models showed different fractions of globular fields, i.e., fields that are not Gabor-like but are best described as center-surround (difference-of-Gaussians) fields <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>. In the primary visual cortices of different species, significant proportions of simple cells with such receptive fields have been reported <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref> (see <xref ref-type="fig" rid="pcbi-1003062-g001">Fig. 1 C</xref> for examples of such cells in macaque monkeys). However, globular fields are either not observed or only done so in relatively small numbers when standard sparse coding or ICA are applied to image patches. We observed globular fields for both linear and non-linear models. However, the predicted proportions of such fields were very different. <xref ref-type="fig" rid="pcbi-1003062-g001">Fig. 1 D</xref> shows the proportions of globular cells for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e041" xlink:type="simple"/></inline-formula> hidden units for the different models and <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3</xref> C shows the proportions for each model for different numbers hidden units (different degrees of overcompleteness). For standard sparse coding <xref ref-type="bibr" rid="pcbi.1003062-Lee1">[9]</xref>, the percentage of globular fields tends to increase corresponding to an increase in overcompleteness <xref ref-type="bibr" rid="pcbi.1003062-Olshausen4">[27]</xref> but stays low in relative comparison (below <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e042" xlink:type="simple"/></inline-formula>).</p>
<fig id="pcbi-1003062-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003062.g003</object-id><label>Figure 3</label><caption>
<title>Percentages of globular receptive fields predicted by the computational models in comparison to <italic>in vivo</italic> measurements.</title>
<p><bold>A</bold> Receptive fields predicted if occlusion-like superposition is assumed (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e043" xlink:type="simple"/></inline-formula> out of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e044" xlink:type="simple"/></inline-formula> receptive fields are shown). <bold>B</bold> Receptive fields predicted if standard linear superposition is assumed (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e045" xlink:type="simple"/></inline-formula> out of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e046" xlink:type="simple"/></inline-formula> receptive fields are shown). <bold>C</bold> Percentages of globular fields predicted by the occlusive model (MCA) and by the linear model (BSC) versus number of hidden units. The experiments for MCA (blue line) and BSC (green line) on DoG preprocessed image patches were repeated five times and the error bars extend two empirical standard deviations. Standard sparse coding (yellow line) on DoG processed data shows the lowest fraction of globular fields. To control for the influence of preprocssing, additional experiments were performed on ZCA whitened data (dashed blue and dashed green lines). The bold red line (and its error bar) shows the fraction of globular fields computed based on <italic>in vivo</italic> measurements of macaque monkeys <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>. Dashed red lines show the fractions reported for ferrets <xref ref-type="bibr" rid="pcbi.1003062-Usrey1">[15]</xref> and mice <xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003062.g003" position="float" xlink:type="simple"/></fig>
<p>Sparse coding with binary latents as in BSC results in a consistently higher percentage of globular fields ranging from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e047" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e048" xlink:type="simple"/></inline-formula> units to about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e049" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e050" xlink:type="simple"/></inline-formula>. By far however, the highest percentages of globular fields were observed in applications of the non-linear model (MCA). Relatively independent of the number of latents, fractions between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e051" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e052" xlink:type="simple"/></inline-formula> of globular receptive fields were obtained. For comparison, the fraction of globular fields in macaque monkeys <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref> is estimated to be about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e053" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Methods</xref> and SI), in ferrets about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e054" xlink:type="simple"/></inline-formula> of the fields were reported to be globular <xref ref-type="bibr" rid="pcbi.1003062-Usrey1">[15]</xref>, and in mice about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e055" xlink:type="simple"/></inline-formula> globular fields were measured <xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref>. For ferrets and mice the percentages were reported in the corresponding studies <xref ref-type="bibr" rid="pcbi.1003062-Usrey1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref>, and for macaque monkeys we used original receptive field recordings (courtesy of D. Ringach) and applied the same classification procedure as for the predictions computed by the models (see <xref ref-type="sec" rid="s4">Methods</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003062.s006">Fig. S6</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003062.s007">S7</xref>). The percentages of globular fields estimated on the grounds of the three experimental studies <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref> are given as horizontal red lines in <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 C</xref>.</p>
<p>Of all remaining non-globular fields predicted by the models, almost all have a Gabor-like shape (with few fields having unspecific shapes; see <xref ref-type="sec" rid="s4">Methods</xref> and compare <xref ref-type="supplementary-material" rid="pcbi.1003062.s003">Figs. S3</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003062.s007">S7</xref>.). To analyze remaining differences between these Gabor-like fields, we followed an approach suggested by an earlier experimental study <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>, i.e., we matched the fields with Gabor functions and plotted Gabor shape parameters (Gaussian envelope parameters and frequency) using dimensionless <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e056" xlink:type="simple"/></inline-formula>-plots (see <xref ref-type="sec" rid="s4">Methods</xref> and SI for details). <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e057" xlink:type="simple"/></inline-formula> is proportional to the width of the Gaussian envelope in wave-vector direction; <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e058" xlink:type="simple"/></inline-formula> is proportional to its width orthogonal to the wave-vector. The widths are measured in multiples of the spatial wavelength. As we have separated out the globular fields first, we avoided having to match center-surround fields with Gabor functions, which removes a problem of earlier applications of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e059" xlink:type="simple"/></inline-formula> analysis. <xref ref-type="fig" rid="pcbi-1003062-g004">Fig. 4</xref> A shows the obtained distributions for the non-linear and the linear model (for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e060" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e061" xlink:type="simple"/></inline-formula>), respectively. As can be observed, both distributions are relatively broadly shaped but differ. The distribution predicted by the non-linear model is shaped upwards starting from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e062" xlink:type="simple"/></inline-formula> while the distribution predicted by the linear model is more elliptical. Furthermore, the receptive fields of the non-linear model tend to lie closer to the origin with a center-of-mass at about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e063" xlink:type="simple"/></inline-formula> compared to a center-of-mass at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e064" xlink:type="simple"/></inline-formula> for the linear model. For comparison, we applied the same analysis of receptive field shapes to <italic>in vivo</italic> recordings of macaque simple cells <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref> (data provided by D. Ringach, see <xref ref-type="sec" rid="s4">Methods</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003062.s007">Fig. S7</xref>). The resulting shape distributions are overlaid with the model predictions in <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 A</xref>. The center-of-mass of the experimental recordings lies at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e065" xlink:type="simple"/></inline-formula> and is much closer to the center-of-mass of the non-linear model. In general, the distributions predicted by both models show a large diversity of Gabor shapes and a relatively large overlap with macaque recordings, however.</p>
<fig id="pcbi-1003062-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003062.g004</object-id><label>Figure 4</label><caption>
<title>Comparison of Gabor shape statistics with <italic>in vivo</italic> recordings and predicted sparsity.</title>
<p><bold>A</bold> Analysis of learned Gabor-like receptive fields for experiments with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e066" xlink:type="simple"/></inline-formula> hidden units (and patch size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e067" xlink:type="simple"/></inline-formula>): <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e068" xlink:type="simple"/></inline-formula> distribution of Gabor shaped receptive fields learned by occlusion-like (MCA) and linear sparse coding (BSC). The red triangles in both plots depict the distribution computed based on <italic>in vivo</italic> measurements of macaque monkeys <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>. <bold>B</bold> Average number of active units accross image patches as a function of the number of hidden units <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e069" xlink:type="simple"/></inline-formula> (note that error bars are very small; experiments on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e070" xlink:type="simple"/></inline-formula> pixel sized DoG preporcessed patches).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003062.g004" position="float" xlink:type="simple"/></fig>
<p>Other than investigating different models for image patch encoding, we explored different preprocessing methods prior to the application of the encoding models. We used a neurally plausible preprocessing by modeling LGN input to the cortex using center-surround (difference-of-Gaussians) filtered patches. Another (and related) method of preprocessing popular for functional modeling is zero-phase PCA whitening <xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen3">[28]</xref>. To control for the influence of the preprocessing method (i.e., the model for LGN input to the cortex), we applied the linear and non-linear models also to image patches preprocessed using zero-phase PCA whitening (ZCA). We found that preprocessing has a significant influence on the shapes of predicted receptive fields. A change in preprocessing both changes the percentages of globular fields (see <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 C</xref>, ZCA curves) and the shape distribution of Gabor fields (see <xref ref-type="sec" rid="s4">Methods</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003062.s004">Fig. S4</xref>). The main difference between the linear and non-linear receptive fields remains the consistently much higher percentage of globular fields for the non-linear model, however. Similarly, the degree to which center-ON and center-OFF cells are assumed to convey input independently from one-another <xref ref-type="bibr" rid="pcbi.1003062-Jin1">[29]</xref> has an impact on the shapes of receptive fields. Controls with ON- and OFF-cells treated independently of each other again reproduce the same qualitative results, with the non-linear model showing a much higher percentage of globular fields than the linear model (see <xref ref-type="supplementary-material" rid="pcbi.1003062.s005">Fig. S5</xref>). Finally, also controls with sparsity levels fixed to the same values for both models always resulted in a much higher percentage of globular fields for the non-linear model. This much higher percentage was, without exception, observed in all of the experiments and controls of this study.</p>
</sec><sec id="s2c">
<title>Sparsity and inference</title>
<p>Unlike standard sparse coding <xref ref-type="bibr" rid="pcbi.1003062-Olshausen1">[4]</xref> and most of its variants <xref ref-type="bibr" rid="pcbi.1003062-Lee1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref>, the non-linear MCA model and the linear BSC model both do not only infer parameters for the basis functions but also parameters for sparsity and stimulus noise. Consequently, these parameters do not have to be hand-set or inferred by cross-validation in numerical experiments. More importantly, however, we can directly ask if the degrees of inferred sparsity differ between the non-linear and linear model. Sparsity is of high interest for understanding neural coding <xref ref-type="bibr" rid="pcbi.1003062-Fiser1">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Willmore1">[33]</xref>. Theoretical predictions of sparsity levels have, so far, only been studied for linear models. Here we can study sparsity for the non-linear and linear model very directly. Because of binary hidden variables described by a Bernoulli prior, we use the number <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e071" xlink:type="simple"/></inline-formula> as sparsity measure. This number is simply the average number of active units across all image patches. Or in other words, the average number of basis functions a model needs to combine for the generation or reconstruction of an image patch. Note that the value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e072" xlink:type="simple"/></inline-formula> corresponds to an inverse sparsity (however, we will refer to this value as <italic>sparsity measure</italic> or simply <italic>sparsity</italic> if the meaning is clear from the context).</p>
<p>In analogy to <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 C</xref>, inferred degrees of sparsity are plotted in <xref ref-type="fig" rid="pcbi-1003062-g004">Fig. 4 B</xref> for different numbers of basis functions. For both models, MCA and BSC, the average number of active hidden units decreases (sparsity increases) with increasing number of basis functions (i.e., with increasing over-completeness). However, while both models converge to increasingly sparse solutions, the non-linear model was found to be consistently and very significantly sparser. On <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e073" xlink:type="simple"/></inline-formula> patches and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e074" xlink:type="simple"/></inline-formula> hidden variables the non-linear model estimates a patch to consists of on average four to five components (basis functions) compared to seven to eight as estimated by the linear model. <xref ref-type="fig" rid="pcbi-1003062-g005">Fig. 5</xref> illustrates the different encodings of the two models for different example patches. For the simple example patch showing an oriented ‘branch’ (<xref ref-type="fig" rid="pcbi-1003062-g005">Fig. 5</xref>, top), both models combine basis functions of similar orientation. However, MCA uses fewer ‘line segments’ to re-construct the patch while BSC uses more basis functions. For patches with more complex structures (<xref ref-type="fig" rid="pcbi-1003062-g005">Fig. 5</xref>, examples in the middle), the differences become still more salient. Again, MCA uses fewer basis functions and usually reconstructs a patch from components which correspond to actual components in a patch. The final example (<xref ref-type="fig" rid="pcbi-1003062-g005">Fig. 5</xref>, bottom) illustrates inference with Gabor-like and globular components. The MCA model uses a globular field to reconstruct a two dimensional end-stopping structure. In the example, BSC reconstructs the patch by exclusively using Gabors. Some of them are very localized but clearly Gabor-like fields (the two right-hand-side fields). Often the BSC fields are not closely aligned with true image components. Sometimes we also observed BSC to use a globular field for an end-stopping structure but it does so much more rarely than MCA. We have never observed standard sparse coding to use a globular field for the examples investigated. In general, BSC and (much more so) standard sparse coding use more basis functions (reflecting the lower sparsity) and usually combine components which do not directly correspond to actual image components. In control experiments using different preprocessing approaches, we found that concrete sparsity levels do depend on the type of preprocessing. However, as was the case for the percentage of globular fields, in all experiments sparsity levels were consistently much higher for the non-linear model than for the linear one (see <xref ref-type="sec" rid="s4">Methods</xref> and SI).</p>
<fig id="pcbi-1003062-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003062.g005</object-id><label>Figure 5</label><caption>
<title>Decomposition of image patches into basic components for four example patches.</title>
<p>For each example the figure shows: the original patch (left), its DoG preprocessed version (second to left), and the decomposition of the preprocessed patch by the three models. For better comparison with the original patches, basis functions are shown in grey-scale. The displayed functions correspond to the active units of the most likely hidden state given the patch. In the case of standard sparse coding, the basis functions are displayed in the order of their contributions. Standard sparse coding (SC) uses many basis functions for reconstruction but many of them contribute very little. BSC uses a much smaller subset of the basis functions for reconstruction. MCA typically uses the smallest subset. The basis functions of MCA usually correspond directly to edges or to two dimensional structures of the image while basis functions of BSC and (to a greater degree) of SC are more loosely associated with the true components of the respective patch. The bottom most example illustrates that the globular fields are usually associated with structures such as end-stopping or corners. For the displayed examples, the normalized root-mean-square reconstruction errors (nrmse) allow to quantify the reconstruction quality. For standard sparse coding the errors are (from top to bottom) given by 0.09, 0.08, 0.10 and 0.12, respectively. For the two models with Bernoulli prior they are larger with 0.51, 0.63, 0.53, and 0.42 for MCA, and 0.37, 0.47, 0.44 and 0.39 for BSC. We give reconstruction errors for completeness but note that they are for all models based on their most likely hidden states (MAP estimates). For MCA and BSC the MAP was chosen for illustrative purposes while for most tasks these models can make use of their more elaborate posterior approximations.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003062.g005" position="float" xlink:type="simple"/></fig></sec></sec><sec id="s3">
<title>Discussion</title>
<p>In this work we have investigated the impact of occlusion non-linearities in visual stimuli on simple cell coding. Specifically, we compared optimal coding of a linear sparse coding model to a sparse coding model taking strong occlusion-like non-linearities into account. The comparison of the two (otherwise identical) sparse coding models showed significant differences in the predicted receptive fields as well as in predicted levels of sparsity.</p>
<sec id="s3a">
<title>Comparison of model predictions and <italic>in vivo</italic> recordings</title>
<p>The non-linear model consistently predicted a high percentage of globular receptive fields (<xref ref-type="fig" rid="pcbi-1003062-g001">Figs. 1 D</xref> and <xref ref-type="fig" rid="pcbi-1003062-g003">3 C</xref>) which was relatively independent of the degree of overcompleteness (i.e., number of fields). The linear model and standard sparse coding showed much lower percentages. For comparison with <italic>in vivo</italic> recordings of simple cells, we used data from macaques <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>, ferrets <xref ref-type="bibr" rid="pcbi.1003062-Usrey1">[15]</xref> and mice <xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref>. Notably, high percentages of globular fields were found in all these experimental studies. The percentage of globular fields in macaques was estimated here based on data provided by D. Ringach. By applying the same classification procedure as for the theoretical predictions, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e075" xlink:type="simple"/></inline-formula> of the original receptive field recordings were classified as globular fields. For ferrets, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e076" xlink:type="simple"/></inline-formula> globular or <italic>center-surround</italic> receptive fields were reported <xref ref-type="bibr" rid="pcbi.1003062-Usrey1">[15]</xref>. For mice, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e077" xlink:type="simple"/></inline-formula> of recorded cells consisted of just one subfield <xref ref-type="bibr" rid="pcbi.1003062-Niell1">[16]</xref>, which is a close match to globular fields as defined in this work. It should be pointed out that none of the experimental studies had a focus on globular fields. These fields have been observed while general properties of V1 receptive fields were investigated.</p>
<p>For comparison, the experimentally measured percentages of globular fields (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e078" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e079" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e080" xlink:type="simple"/></inline-formula>) tend to be lower than the percentages predicted by the non-linear model (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e081" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e082" xlink:type="simple"/></inline-formula>) but they are much higher than the low percentages (below <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e083" xlink:type="simple"/></inline-formula>) of the linear models. <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 C</xref> visualizes the predictions of the models for different degrees of overcompleteness with experimental results shown as horizontal lines. For the measurements and for the models, the percentages of globular fields can depend on different experimental or model settings. On the experimental side, receptive field measurements can depend, e.g., on the type of stimuli used for reverse correlation. On the modelling side, the percentage of globular fields can change, e.g., by changing sparsity levels or overcompleteness. For our comparative study we removed the arbitrariness in sparsity levels by applying an optimization procedure which automatically infers the level of sparsity. To study the influence of overcompleteness, we screened through different values for the number of hidden units. Considering all numerical experiments, the type of component superposition emerged as having by far the most significant influence on percentages of globular fields, with the non-linear model showing robustly very high percentages. Neither standard sparse coding with the usual parameter settings nor a range of other standard models predict such high percentages: For sparse coding, globular fields only emerge with specific priors and/or specifically chosen sparsity levels <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Olshausen3">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref>. For independent component analysis, k-means, sparse auto-encoders or restricted Boltzmann Machines no globular fields were observed <xref ref-type="bibr" rid="pcbi.1003062-Saxe1">[21]</xref>. The high percentages of globular fields for the occlusive model studied here and the high percentages observed in <italic>in vivo</italic> recordings suggest a strong impact of visual occlusions on simple cell encoding.</p>
<p>Furthermore, the reported results suggest direct experiments to verify or falsify the models studied here: Suppose different simple cells with receptive fields at the same location in the visual field were identified, then the linear and non-linear models could be used to predict the responses if complex stimuli are presented at the same location. For a crossing of two edges the linear model would for instance predict responses less aligned with responses to the individual edges than the non-linear model (compare <xref ref-type="fig" rid="pcbi-1003062-g005">Fig. 5</xref>). This is because the linear model combines less specific components (and more of them) as they can be added and subtracted more freely than those of the non-linear model. The linear model would thus predict a higher difference between the response to overlapping line segments and the responses to the individual segments. Measuring the difference of a response to a crossing and to the individual lines would thus allow to verify or falsify the linear or non-linear model more directly. Also predictions of different sparsity levels could be verified or falsified but such experiments are more difficult because it is challenging to accurately measure sparsity levels <italic>in vivo</italic>. The consistently much sparser encoding predicted by a non-linear sparse coding model has, however, a significant potential impact on the ongoing debate on sparse encodings and recent experimental results <xref ref-type="bibr" rid="pcbi.1003062-Berkes2">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Willmore1">[33]</xref>.</p>
<p>In contrast to differences in sparsity and in the percentage of globular receptive fields, we found the differences of Gabor-shape distributions (<xref ref-type="fig" rid="pcbi-1003062-g004">Fig. 4</xref>) less instructive for distinguishing image encoding based on linear or occlusion-like models. For both superposition assumptions we obtained a large diversity of Gabor shapes. Notably, both distributions are broader and have a larger overlap with macaque receptive fields than ICA and standard sparse coding <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>. As the non-linear and linear model studied here use binary hidden units, the higher overlap of both models with experimental results may, instead, be taken as evidence for a more discrete neural encoding of components than assumed, e.g., by a standard continuous Laplace prior <xref ref-type="bibr" rid="pcbi.1003062-Olshausen2">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Olshausen4">[27]</xref>.</p>
</sec><sec id="s3b">
<title>Comparison to other computational models</title>
<p>Since the diversity of receptive field shapes was suggested as a means for comparison of models to experimental data <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Jones1">[34]</xref>, different modeling approaches have been shown to result in broad distributions of Gabor shapes. Consistent with our observation that more discrete priors result in a large diversity of shapes, recent studies <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref> reported a large diversity based on more discrete values for the hidden units. Two studies <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Olshausen3">[20]</xref> notably obtained high percentages of globular fields by simultaneously assuming a linear combination of components. However, parameter optimization of both studies focused on the basis functions themselves, sparsity was hand-set and not inferred from data. One of the studies <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref> specifically chose the sparsity level which resulted in the highest similarity between model and experimental distribution of receptive fields. The hand-set sparsities of these two linear models are, consequently, unlikely to be the optimal sparsity values for the data. It therefore remains an open question what percentages the models would predict for (approximately) optimal values of sparsity and data noise. For sparse coding with standard parameter settings (e.g., SC in <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 C</xref>), for novel linear sparse coding models (e.g., <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref>) or for other models <xref ref-type="bibr" rid="pcbi.1003062-Saxe1">[21]</xref> no or only relatively few globular fields were observed. For the non-linear model investigated here, high percentages of globular fields robustly emerged in all experiments with sparsity levels (and data noise) always automatically estimated from the used set of image patches.</p>
<p>In addition to functional and probabilistic approaches to model simple cell coding, other computational investigations are based on models of neural circuits. While many studies directly relate to linear sparse coding <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Rozell1">[35]</xref>, other contributions are not directly linked to an underlying functional model and, notably, often point out that non-linearly overlapping components can be learned well <xref ref-type="bibr" rid="pcbi.1003062-Lcke2">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Fldik1">[36]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Savin1">[39]</xref>. The non-linear generative model studied in this paper can be seen as a functional correlate to neural circuit models that do well in learning non-linearly combining components. Consequently, a neural model for non-linear component extraction <xref ref-type="bibr" rid="pcbi.1003062-Lcke2">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke5">[38]</xref> was among the first modelling approaches to report and discuss globular receptive fields <xref ref-type="bibr" rid="pcbi.1003062-Lcke1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke2">[19]</xref>. Such microcircuit models suggest that, on the one hand, a neural implementation of the non-linear model may have some advantages over the linear model because the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e084" xlink:type="simple"/></inline-formula>-superposition is closely related to a (soft) k-winner-take-all competition or rank-coding among computational units <xref ref-type="bibr" rid="pcbi.1003062-Lcke2">[19]</xref>. On the other hand, standard linear models with appropriate sparse priors can be shown to result in mono-modal posteriors <xref ref-type="bibr" rid="pcbi.1003062-Olshausen2">[17]</xref>. Such modes can efficiently be found using gradient-based neural dynamics which may represent a computational advantage of such models. In the case of ICA, activities of hidden units can directly be computed via filter responses.</p>
<p>In general there may, therefore, be relevant aspects other than the theoretical optimality of the generative model itself. To obtain as optimal as possible results, an encoding model has to fulfill two requirements: (A) it has to reflect the data generation process well and (B) it has to provide an efficient procedure to learn optimal parameters. A simpler model may in practice have the advantage of a more efficient learning procedure while learning based on a non-linear model may be harder. There may, for instance, be higher computational costs associated with a non-linear model or convergence to local optima may represent a problem. It has, therefore, been argued in the literature <xref ref-type="bibr" rid="pcbi.1003062-Graham1">[40]</xref> that discussions about coding efficiency should contain learning efficiency as an integral part. In controls with our models using ground-truth stimuli, we indeed found a higher tendency of the non-linear model to converge to local optima compared to the linear model (see <xref ref-type="sec" rid="s4">Methods</xref>, Numerical experiments). Learning still frequently converged to a global optimum, though, and could easily be improved using annealing. For natural image patches, we did not observe differences between runs with and without annealing (<xref ref-type="sec" rid="s4">Methods</xref>). All experiments resulted in the same percentages of globular fields (within the limits of the error bars in <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3C</xref>), for instance. Based on the used learning approach, finding optimal parameters therefore does not seem much more challenging for the non-linear model than for the linear one. Also the computational cost is about the same (compare <xref ref-type="sec" rid="s4">Methods</xref> and <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref>). Furthermore, both models face essentially the same challenges regarding neural implementability. Because of discrete hidden variables, a standard MAP estimation can not be applied and would be prohibitive for a direct inference of the optimal sparsity and stimulus noise. An implementation in neural microcircuits would consequently have to focus on how the posterior could be represented efficiently. This may be realized through population codes (e.g., <xref ref-type="bibr" rid="pcbi.1003062-Zemel1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Ma1">[42]</xref>) or through a sampling based representation (e.g., <xref ref-type="bibr" rid="pcbi.1003062-Berkes2">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Buesing1">[43]</xref>). The latter can be related to the approximation used here <xref ref-type="bibr" rid="pcbi.1003062-Shelton1">[44]</xref>. Accuracy and response times would then depend on the concrete realization of such a neural implementation. Functionally, sensory coding efficiency is very task dependent (see <xref ref-type="bibr" rid="pcbi.1003062-Graham1">[40]</xref> for a discussion). Regarding metabolic coding efficiency, a sparser code is preferable over a less sparse code, which would favor the non-linear model. For image reconstruction, linear models may remain well suited (compare, e.g., reconstructions in <xref ref-type="fig" rid="pcbi-1003062-g005">Fig. 5</xref>), and a reduced sparsity can help for this task. However, best results for general tasks and for further processing in the visual pathway are presumably achieved for the best stimulus model, i.e., for a model which well approximates the actual stimulus generation process.</p>
<p>Note, that the maximum non-linearity and standard linear superposition as studied here are only two possible models for the combination of components. In the literature, other non-linearities such as noisy-OR combinations <xref ref-type="bibr" rid="pcbi.1003062-Saund1">[45]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-ingliar1">[47]</xref> or non-linear ICA <xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen4">[48]</xref> have been investigated before. Neither these non-linearities nor the maximum non-linearity have, so far, been shown to predict simple cell receptive fields, however. The reason is that non-linear models could, so far, not be scaled-up to the problem size required to study optimal codes on image patches. This is, again, due to the requirement of learning approaches that go significantly beyond MAP-based approximations.</p>
<p>Although sparse coding and its variants represent the standard model for simple cell coding, other computational models have been suggested. More recently, for instance, the suitability of mixture model approaches has been discussed <xref ref-type="bibr" rid="pcbi.1003062-Saxe1">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Theis1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zoran1">[50]</xref>. While such models emphasize fitting model to data distributions, approaches such as ICA, sparse coding or MCA aim at learning a distributed encoding based on a combination of components. Still another functional approach to model visual stimuli is a line of research referred to as <italic>dead leaves</italic> approaches <xref ref-type="bibr" rid="pcbi.1003062-Zoran1">[50]</xref>–<xref ref-type="bibr" rid="pcbi.1003062-Pitkow1">[53]</xref>. These statistical models of visual stimuli have long emphasized the importance of occlusions, and they were shown to reproduce many statistical properties of visual stimuli <xref ref-type="bibr" rid="pcbi.1003062-Mumford1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Pitkow1">[53]</xref>. So far, this prominent line of statistical image models was incompatible with sparse coding and simple cell models, though. The incorporation of occlusion non-linearities into sparse coding offers a way to reconcile these lines of research. Again it should be noted, however, that the non-linear model studied here accounts for occlusions by assuming strongly non-linear superpositions of low-level image components. A more explicit encoding of occlusion would result in a more accurate functional model but involves a larger set of parameters and further increases computational requirements <xref ref-type="bibr" rid="pcbi.1003062-Lcke6">[54]</xref>. Furthermore, explicit occlusion models are presumably more relevant for mid- and high-level vision (with objects and object parts as components) than they are for low-level image statistics.</p>
</sec><sec id="s3c">
<title>Why globular fields?</title>
<p>While different recent models report that globular receptive fields do emerge in applications to image patches <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke2">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref>, they offer no explanation <italic>why</italic> this is the case. In this context, our comparative study allows for an explanation that is closely linked to discrete hidden units and the superposition model. First consider the selection of typical DoG preprocessed image patches as displayed in <xref ref-type="fig" rid="pcbi-1003062-g006">Fig. 6 A</xref>. As can be observed, the patches contain Gabor-like components as well as globular components. Also note that the maximal intensities of Gabor and globular components are similar. Now suppose that a sparse coding model has already represented Gabor-like fields such as those shown in <xref ref-type="fig" rid="pcbi-1003062-g006">Fig. 6 B</xref> (left-hand-side). If these two Gabor fields are linearly superimposed and then rescaled by a factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e085" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1003062-g006">Fig. 6 B</xref>), an (approximately) globular field is generated. If the two Gabors are linearly superimposed but can not be rescaled (<xref ref-type="fig" rid="pcbi-1003062-g006">Fig. 6 C</xref>), then the intensity of the globular field becomes higher than the intensity of typical globular structures in the data. For the non-linear superposition (<xref ref-type="fig" rid="pcbi-1003062-g006">Fig. 6 D</xref>) no globular structures can be generated by superimposing Gabors. <xref ref-type="fig" rid="pcbi-1003062-g006">Fig. 6</xref> illustrates that globular structures in image patches can be explained by linearly superimposing Gabors. For linear sparse coding approaches with continuous values for hidden variables, globular structures do, consequently, not have to be represented explicitly. This may explain why almost all versions of sparse coding or ICA do not predict globular fields or only very low percentages thereof <xref ref-type="bibr" rid="pcbi.1003062-Bell1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lee1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Berkes1">[10]</xref>. If hidden units are prevented from taking on continuous values <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Henniges1">[26]</xref>, a stronger incentive is generated to explicitly represent globular fields. This can explain the observation of larger numbers of globular fields for models with more discrete priors <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Henniges1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref>. A strongly non-linear superposition of Gabors can not generate globular fields. Consequently, such components have to be represented explicitly. This may explain the high percentages of globular fields in the non-linear model and, presumably, the high percentages of globular fields in the experimental measurements. Also note that the generation of globular structures in the linear models requires more fields than in the non-linear model, which is consistent with the sparser encoding in the non-linear case.</p>
<fig id="pcbi-1003062-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003062.g006</object-id><label>Figure 6</label><caption>
<title>Illustration of different superposition models and globular fields.</title>
<p><bold>A</bold> Selection of typical preprocessed image patches. <bold>B</bold> Superposition of two Gabor fields as assumed by standard sparse coding with continuous priors (along with additive Gaussian noise after superposition). <bold>C</bold> Superposition of the same two Gabor fields if hidden units (prefactors) are binary. <bold>D</bold> Superposition of the Gabor fields if a point-wise maximum is used as superposition model.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003062.g006" position="float" xlink:type="simple"/></fig>
<p>Both Gabor-like and globular fields are useful for image encoding. While Gabors are closely associated with edges, we observed globular fields to be more closely associated with two dimensional structures (see <xref ref-type="fig" rid="pcbi-1003062-g005">Fig. 5</xref>) such as corners or ends of branches (also compare <xref ref-type="bibr" rid="pcbi.1003062-Olshausen3">[20]</xref> for a discussion). Furthermore, both component types may be useful for texture encoding. Both types are certainly observed in preprocessed stimuli (<xref ref-type="fig" rid="pcbi-1003062-g006">Fig. 6 A</xref>) and they are both measured <italic>in vivo</italic>. On the functional side, many tasks seem to work well with approaches <italic>not</italic> resulting in globular fields, as a large body of literature, e.g., on image processing with linear models shows. Also inference examples, e.g. those of <xref ref-type="fig" rid="pcbi-1003062-g005">Fig. 5</xref>, show that linear models (with low percentages of globular fields) can perform well, e.g., in terms of image reconstruction (mainly because they use a large number of components which they can add and subtract). For data with non-linearly combining components, non-linear models are naturally performing better if inference of the true components is the task <xref ref-type="bibr" rid="pcbi.1003062-Lcke3">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke5">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Spratling2">[55]</xref>. The functional capabilities of non-linear models and globular fields will, therefore, be very task dependent. The observation that globular fields are observed in <italic>in vivo</italic> recordings may, however, be interpreted as evidence for them being functionally very useful for the typical tasks animals and humans have to accomplish.</p>
</sec><sec id="s3d">
<title>Conclusion</title>
<p>Our study answers whether occlusions can have an impact on theoretical predictions of simple cell models. Based on a direct comparison of superposition assumptions we have observed very significant differences between the receptive fields and sparsity levels predicted by the linear and the occlusive model. Both models represent approximations of the exact model for local visual component combinations. However, we have observed that a non-linear superposition results in both a closer match to the true combination rule of visual components and a closer match of predicted receptive fields to <italic>in vivo</italic> measurements. This higher consistency between predicted receptive fields and <italic>in vivo</italic> recordings suggests that stimulus encoding in V1 is optimized by taking visual occlusions into account. Most significantly, high quantities of a new type of simple cells with center-surround fields, reliably and robustly emerge if visual occlusions are considered.</p>
</sec></sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Optimization of model parameters</title>
<p>In this study we compared the predictions of two sparse coding models, MCA and BSC, when trained on natural image patches. Given the generative models (<xref ref-type="disp-formula" rid="pcbi.1003062.e005">Eqns. 1</xref> and <xref ref-type="disp-formula" rid="pcbi.1003062.e006">2</xref> for MCA; <xref ref-type="disp-formula" rid="pcbi.1003062.e007">Eqns. 3</xref> and <xref ref-type="disp-formula" rid="pcbi.1003062.e008">4</xref> for BSC) and a set of preprocessed image patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e086" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e087" xlink:type="simple"/></inline-formula> we sought for each model the parameter values <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e088" xlink:type="simple"/></inline-formula> that maximize the data likelihood. In its logarithmic form the likelihood function is given by:<disp-formula id="pcbi.1003062.e089"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e089" xlink:type="simple"/><label>(7)</label></disp-formula>For all models considered here (MCA, BSC and conventional SC), the optimization of the likelihood function represents a computationally intractable problem for higher dimensional hidden spaces. We therefore require approaches that approximately but efficiently optimize the likelihood. For MCA and BSC we apply variational expectation maximization <xref ref-type="bibr" rid="pcbi.1003062-Neal1">[56]</xref> (variational EM). That is, instead of maximizing the likelihood directly, we maximize the so-called free-energy:<disp-formula id="pcbi.1003062.e090"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e090" xlink:type="simple"/><label>(8)</label></disp-formula>where the sum <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e091" xlink:type="simple"/></inline-formula> runs over all binary vectors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e092" xlink:type="simple"/></inline-formula> and where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e093" xlink:type="simple"/></inline-formula> is an entropy term. The free-energy function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e094" xlink:type="simple"/></inline-formula> is a lower bound of the log-likelihood. By applying variational EM, the function is maximized alternately with respect to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e095" xlink:type="simple"/></inline-formula> in the E-step (while <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e096" xlink:type="simple"/></inline-formula> is kept fixed) and with respect to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e097" xlink:type="simple"/></inline-formula> in the M-step (while <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e098" xlink:type="simple"/></inline-formula> is kept fixed). For the M-step, expectation values of functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e099" xlink:type="simple"/></inline-formula> with respect to distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e100" xlink:type="simple"/></inline-formula> have to be computed. The optimal choice for these distributions in the E-step are the posterior probabilities given the stimulus, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e101" xlink:type="simple"/></inline-formula>. Sparse coding models are computationally intractable because these exact posterior distributions and their expectation values are intractable.</p>
<p><italic>E-step</italic>. To efficiently optimize the models' parameters, we apply a variational EM approach by choosing distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e102" xlink:type="simple"/></inline-formula> which are truncated approximations to the exact posteriors <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref>:<disp-formula id="pcbi.1003062.e103"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e103" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e104" xlink:type="simple"/></inline-formula> is an indicator function (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e105" xlink:type="simple"/></inline-formula> if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e106" xlink:type="simple"/></inline-formula> and zero otherwise) and where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e107" xlink:type="simple"/></inline-formula> is a data point dependent subset of the hidden space. By choosing the variational distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e108" xlink:type="simple"/></inline-formula> as in <xref ref-type="disp-formula" rid="pcbi.1003062.e103">Eqn. 9</xref>, we obtain the following approximations for expectation values with respect to the exact posteriors:<disp-formula id="pcbi.1003062.e109"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e109" xlink:type="simple"/><label>(10)</label></disp-formula>The sums for the approximate expectation values now run over <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e110" xlink:type="simple"/></inline-formula> instead of the entire hidden space. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e111" xlink:type="simple"/></inline-formula> is chosen to be small but to contain the states with most posterior probability mass, the computation of the expectations in <xref ref-type="disp-formula" rid="pcbi.1003062.e109">Eqn. 10</xref> becomes tractable while a high accuracy of the approximations is maintained <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref>. The set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e112" xlink:type="simple"/></inline-formula> is, therefore, chosen to consider the subset of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e113" xlink:type="simple"/></inline-formula> most relevant hidden units for a patch <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e114" xlink:type="simple"/></inline-formula>. Furthermore, at most <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e115" xlink:type="simple"/></inline-formula> of these <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e116" xlink:type="simple"/></inline-formula> units are assumed to be active simultaneously <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e117" xlink:type="simple"/></inline-formula>. More formally we define:<disp-formula id="pcbi.1003062.e118"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e118" xlink:type="simple"/><label>(11)</label></disp-formula>where the index set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e119" xlink:type="simple"/></inline-formula> contains those <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e120" xlink:type="simple"/></inline-formula> hidden units that are the most likely to have generated data point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e121" xlink:type="simple"/></inline-formula> (while the last term in <xref ref-type="disp-formula" rid="pcbi.1003062.e118">Eqn. 11</xref> assures that all states <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e122" xlink:type="simple"/></inline-formula> with just one non-zero entry are also considered). To determine the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e123" xlink:type="simple"/></inline-formula> hidden variables for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e124" xlink:type="simple"/></inline-formula>, we use those units <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e125" xlink:type="simple"/></inline-formula> with the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e126" xlink:type="simple"/></inline-formula> largest values of a <italic>selection function</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e127" xlink:type="simple"/></inline-formula> given by:<disp-formula id="pcbi.1003062.e128"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e128" xlink:type="simple"/><label>(12)</label></disp-formula>Through the selection of states with high posterior mass, the function resulted in a high accuracy for parameter recovery on data with ground-truth (see numerical experiments further below). Parameters of the approximation are the maximal number of components considered, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e129" xlink:type="simple"/></inline-formula>, and the maximal number of simultaneously active components <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e130" xlink:type="simple"/></inline-formula>. They can be chosen such that a high approximation accuracy is achieved with simultaneously high efficiency (see numerical experiments).</p>
<p><italic>M-step</italic>. If the variational distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e131" xlink:type="simple"/></inline-formula> of the free-energy are chosen as in <xref ref-type="disp-formula" rid="pcbi.1003062.e103">Eqn. 9</xref>, then M-step equations for parameter updates follow from the optimization of a truncated free-energy <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref> which is given by:<disp-formula id="pcbi.1003062.e132"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e132" xlink:type="simple"/><label>(13)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e133" xlink:type="simple"/></inline-formula> is the set of all states with less than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e134" xlink:type="simple"/></inline-formula> active hidden units. The set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e135" xlink:type="simple"/></inline-formula> is a subset of those data points with less or equal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e136" xlink:type="simple"/></inline-formula> components. Data points with more than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e137" xlink:type="simple"/></inline-formula> components are not well approximated and are therefore not considered for learning. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e138" xlink:type="simple"/></inline-formula> is defined to contain the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e139" xlink:type="simple"/></inline-formula> data points with smallest values for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e140" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e141" xlink:type="simple"/></inline-formula> is the expected number of well approximated data points <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref> given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e142" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e143" xlink:type="simple"/></inline-formula> defined as in <xref ref-type="disp-formula" rid="pcbi.1003062.e171">Eqn. 20</xref> below.</p>
<sec id="s4a1">
<title>MCA update equations</title>
<p>The M-step equation for the generative fields <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e144" xlink:type="simple"/></inline-formula> for MCA is derived along the same lines as for the original MCA model <xref ref-type="bibr" rid="pcbi.1003062-Lcke3">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref>. However, the scalable algorithm in <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref> did not infer data noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e145" xlink:type="simple"/></inline-formula> nor data sparsity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e146" xlink:type="simple"/></inline-formula>. Furthermore, note that the MCA model used in this work applies a point-wise maximum <italic>magnitude</italic> function. Instead of being aimed at positive data as the original MCA algorithm, the maximum magnitude version developed for this work is directly applicable to data with positive and negative values, and it treats (like sparse coding) these values equally. The model is, therefore, directly applicable to the same data as standard sparse coding or BSC. Additional channel separation <xref ref-type="bibr" rid="pcbi.1003062-Puertas1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Hoyer1">[57]</xref> to convert preprocessed stimuli to positive values is consequently not required, which reduces the difference between MCA and BSC to the component combination rule alone.</p>
<p>To derive update equations for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e147" xlink:type="simple"/></inline-formula> we first replace the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e148" xlink:type="simple"/></inline-formula> operation by a smooth approximation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e149" xlink:type="simple"/></inline-formula><disp-formula id="pcbi.1003062.e150"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e150" xlink:type="simple"/><label>(14)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e151" xlink:type="simple"/></inline-formula> is a large and odd positive integer. Note that in the limit of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e152" xlink:type="simple"/></inline-formula> approchaing infinity, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e153" xlink:type="simple"/></inline-formula> becomes the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e154" xlink:type="simple"/></inline-formula> operation we replaced it for:<disp-formula id="pcbi.1003062.e155"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e155" xlink:type="simple"/><label>(15)</label></disp-formula>To maximize the truncated free-energy <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e156" xlink:type="simple"/></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1003062.e132">Eqn. 13</xref>) with respect to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e157" xlink:type="simple"/></inline-formula>, we use <xref ref-type="disp-formula" rid="pcbi.1003062.e150">equation 14</xref> and obtain:<disp-formula id="pcbi.1003062.e158"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e158" xlink:type="simple"/><label>(16)</label></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e159" xlink:type="simple"/></inline-formula>. Now, for any well-behaved function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e160" xlink:type="simple"/></inline-formula> and for large values <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e161" xlink:type="simple"/></inline-formula> we can write<disp-formula id="pcbi.1003062.e162"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e162" xlink:type="simple"/><label>(17)</label></disp-formula>because <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e163" xlink:type="simple"/></inline-formula> whenever <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e164" xlink:type="simple"/></inline-formula>. Hence it follows from <xref ref-type="disp-formula" rid="pcbi.1003062.e158">Eqn. 16</xref> that:<disp-formula id="pcbi.1003062.e165"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e165" xlink:type="simple"/><label>(18)</label></disp-formula>Rearranging terms of (18) results in the update equation for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e166" xlink:type="simple"/></inline-formula> (see <xref ref-type="disp-formula" rid="pcbi.1003062.e176">Eqn. 23</xref> below).</p>
<p>The derivation of the M-step update for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e167" xlink:type="simple"/></inline-formula> is straight-forward. The derivation of the M-step for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e168" xlink:type="simple"/></inline-formula> involves a term that corrects for discounting the data points with more than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e169" xlink:type="simple"/></inline-formula> components. This term is a consequence of the additional prior term in the truncated free-energy (<xref ref-type="disp-formula" rid="pcbi.1003062.e132">Eqn. 13</xref>). For the derivation we used<disp-formula id="pcbi.1003062.e170"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e170" xlink:type="simple"/><label>(19)</label></disp-formula>with<disp-formula id="pcbi.1003062.e171"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e171" xlink:type="simple"/><label>(20)</label></disp-formula><disp-formula id="pcbi.1003062.e172"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e172" xlink:type="simple"/><label>(21)</label></disp-formula>By taking the derivative of the truncated free-energy (<xref ref-type="disp-formula" rid="pcbi.1003062.e132">Eqn. 13</xref>) with respect to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e173" xlink:type="simple"/></inline-formula> we then obtain:<disp-formula id="pcbi.1003062.e174"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e174" xlink:type="simple"/><label>(22)</label></disp-formula>Applying this equation in the fix-point sense (compare <xref ref-type="disp-formula" rid="pcbi.1003062.e178">Eqn. 25</xref>) results in a convergence to values <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e175" xlink:type="simple"/></inline-formula> that represent solutions of <xref ref-type="disp-formula" rid="pcbi.1003062.e174">Eqn. 22</xref>.</p>
<p>To summarize, the M-step equations for the MCA model are given by:<disp-formula id="pcbi.1003062.e176"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e176" xlink:type="simple"/><label>(23)</label></disp-formula><disp-formula id="pcbi.1003062.e177"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e177" xlink:type="simple"/><label>(24)</label></disp-formula><disp-formula id="pcbi.1003062.e178"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e178" xlink:type="simple"/><label>(25)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e179" xlink:type="simple"/></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1003062.e177">Eqn. 24</xref> denotes the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e180" xlink:type="simple"/></inline-formula>-norm. <xref ref-type="disp-formula" rid="pcbi.1003062.e176">Eqns. 23</xref> to <xref ref-type="disp-formula" rid="pcbi.1003062.e178">25</xref> with expectation values as given in <xref ref-type="disp-formula" rid="pcbi.1003062.e109">Eqn. 10</xref> represent the learning algorithm of the MCA generative model.</p>
<p>One important property of the max-function of the MCA model is that only the largest value of its arguments determines the function's value. In the case of a finite dataset for optimization, this has the effect that those elements of the matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e181" xlink:type="simple"/></inline-formula> with small absolute values, have an influence on only very few of the supplied data points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e182" xlink:type="simple"/></inline-formula>. In these cases the updated values for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e183" xlink:type="simple"/></inline-formula> (<xref ref-type="disp-formula" rid="pcbi.1003062.e176">Eqn. 23</xref>) are, therefore, based on very low evidence from the data. At the same time, with the maximum-function, even small changes to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e184" xlink:type="simple"/></inline-formula> can change which basis function is responsible for a given data point element <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e185" xlink:type="simple"/></inline-formula>. As a result, many close-to-zeros elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e186" xlink:type="simple"/></inline-formula> frequently change their value in an EM iteration. While their values stay close to zero, the exact values irregularly vary with each EM iteration due to the finite size of the dataset. To address this effect, we introduced a learning rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e187" xlink:type="simple"/></inline-formula>, which slows down the learning for those basis functions that only have low evidence:<disp-formula id="pcbi.1003062.e188"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e188" xlink:type="simple"/></disp-formula>where we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e189" xlink:type="simple"/></inline-formula> to be a monotonous function between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e190" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e191" xlink:type="simple"/></inline-formula> based on the amount of evidence that was available for each of the matrix elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e192" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1003062.e193"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e193" xlink:type="simple"/></disp-formula>The reasoning behind this choice is that for each data point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e194" xlink:type="simple"/></inline-formula> the expectation value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e195" xlink:type="simple"/></inline-formula> quantifies the responsibility of elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e196" xlink:type="simple"/></inline-formula> for explaining the data point. With this choice, the learning rate is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e197" xlink:type="simple"/></inline-formula> when a matrix element is responsible to explain only two data points, while it rapidly approaches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e198" xlink:type="simple"/></inline-formula> when it is responsible for explaining more than 10 data points. This modification insures numerical stability due to finite sample sizes without biasing the optimization result.</p>
<p>The computational complexity of the MCA learning algorithm is dominated by the number of states that have to be evaluated for each E-step. The scaling of this number can be estimated to be (compare <xref ref-type="bibr" rid="pcbi.1003062-Lcke4">[24]</xref>):<disp-formula id="pcbi.1003062.e199"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e199" xlink:type="simple"/><label>(26)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e200" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e201" xlink:type="simple"/></inline-formula> are the approximation constants introduced earlier. The first term is associated with the preprocessing step, the second with the combinatorics of the selected units. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e202" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e203" xlink:type="simple"/></inline-formula> are scaling constants. They depend on the computational costs of the concrete functions for preselection and state evaluation.</p>
</sec><sec id="s4a2">
<title>BSC update equations</title>
<p>For the BSC model, the derivation of the M-step for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e204" xlink:type="simple"/></inline-formula> is analogous to the derviation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e205" xlink:type="simple"/></inline-formula> for standard sparse coding (and other linear models). The M-step for the data noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e206" xlink:type="simple"/></inline-formula> is straight-forward, and the derivation for the M-step for the sparsity parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e207" xlink:type="simple"/></inline-formula> is analogous to the corresponding derivation of the MCA model. The resulting M-step equations are given by:<disp-formula id="pcbi.1003062.e208"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e208" xlink:type="simple"/><label>(27)</label></disp-formula><disp-formula id="pcbi.1003062.e209"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e209" xlink:type="simple"/><label>(28)</label></disp-formula><disp-formula id="pcbi.1003062.e210"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e210" xlink:type="simple"/><label>(29)</label></disp-formula>where the set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e211" xlink:type="simple"/></inline-formula> is defined as above. Because of the standard linear superposition used by the BSC model, the update equation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e212" xlink:type="simple"/></inline-formula> has the same form as for standard sparse coding (or principal component analysis). The only difference is the summation over the subset <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e213" xlink:type="simple"/></inline-formula> instead of the whole set of data points. The update equation for the data noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e214" xlink:type="simple"/></inline-formula> is the same as for MCA except of the combination rule, while the M-step equation for the sparsity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e215" xlink:type="simple"/></inline-formula> is identical to the one for MCA (but note that the distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e216" xlink:type="simple"/></inline-formula> are different due to the different generative models). Likewise, the computation of the expectation values is analogous to MCA and uses the same definition of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e217" xlink:type="simple"/></inline-formula>, the same selection function, and the same values for approximation parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e218" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e219" xlink:type="simple"/></inline-formula>. Accordingly, the computational complexity of the BSC learning algorithm is essentially the same, with the difference of a smaller scaling factor <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e220" xlink:type="simple"/></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1003062.e199">Eqn. 26</xref>.</p>
</sec><sec id="s4a3">
<title>Parameter initialisation</title>
<p>For all numerical experiments with MCA and BSC the model parameters needed to be initialized. We used the same initialization procedure for both models and set the basis functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e221" xlink:type="simple"/></inline-formula> to the data mean plus Gaussian noise (unit variance), the sparsity parameter to correspond to one active component on average (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e222" xlink:type="simple"/></inline-formula>) and the data noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e223" xlink:type="simple"/></inline-formula> was set to the variance of the data:<disp-formula id="pcbi.1003062.e224"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e224" xlink:type="simple"/><label>(30)</label></disp-formula><disp-formula id="pcbi.1003062.e225"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e225" xlink:type="simple"/><label>(31)</label></disp-formula>All the source code and the datasets to rerun our experiments are publically available at: <ext-link ext-link-type="uri" xlink:href="http://fias.uni-frankfurt.de/~bornschein/NonLinSC" xlink:type="simple">http://fias.uni-frankfurt.de/~bornschein/NonLinSC</ext-link></p>
</sec><sec id="s4a4">
<title>Parameter optimization for conventional SC</title>
<p>For standard sparse coding we applied a MAP based approximation to optimize the parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e226" xlink:type="simple"/></inline-formula>. All experiments were run using a publically available implementation which is based on an earlier publication <xref ref-type="bibr" rid="pcbi.1003062-Lee1">[9]</xref>. We used the standard <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e227" xlink:type="simple"/></inline-formula> sparsity function and set the batch size to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e228" xlink:type="simple"/></inline-formula>. The number of bases <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e229" xlink:type="simple"/></inline-formula> was set according to the experiment while parameters in the code (e.g., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e230" xlink:type="simple"/></inline-formula>) were left unchanged. For alle experiments, the algorithm detected to have reached an optimum after about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e231" xlink:type="simple"/></inline-formula> iterations. For small <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e232" xlink:type="simple"/></inline-formula> we performed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e233" xlink:type="simple"/></inline-formula> iterations but did not encounter any more changes after an optimum was detected. For <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e234" xlink:type="simple"/></inline-formula> we thus only ran <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e235" xlink:type="simple"/></inline-formula> iterations. Computational demand became impractically large for experiments exceeding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e236" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s4b">
<title>Numerical experiments - artificial data</title>
<p>To verify that the learning algorithms for MCA and BSC correctly recover data components at least approximately, we first applied them to artificial stimuli where ground-truth is available. For each model, a dataset of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e237" xlink:type="simple"/></inline-formula> stimuli <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e238" xlink:type="simple"/></inline-formula> was generated. The generation followed the MCA and BSC model, respectively, using the same set of generating parameters for the basis functions, stimulus noise and sparsity. The used stimuli consisted of patches with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e239" xlink:type="simple"/></inline-formula> pixels generated from ten basis functions in the form of horizontal and vertical bars (five bars for each orientation). The parameter values of each bar were defined to be either <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e240" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e241" xlink:type="simple"/></inline-formula> (with small amounts of additive Gaussian noise). The generating sparsity was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e242" xlink:type="simple"/></inline-formula> (two bars on average), and the stimulus noise was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e243" xlink:type="simple"/></inline-formula>. Examples of the generated patches are shown in <xref ref-type="supplementary-material" rid="pcbi.1003062.s001">Fig. S1</xref> A for the MCA model, and in <xref ref-type="supplementary-material" rid="pcbi.1003062.s002">Fig. S2</xref> A for the BSC model. The stimuli represent forms of a standard ground-truth stimulus set <xref ref-type="bibr" rid="pcbi.1003062-Fldik1">[36]</xref>. For MCA experiments the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e244" xlink:type="simple"/></inline-formula> softening parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e245" xlink:type="simple"/></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1003062.e150">equation 14</xref> was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e246" xlink:type="simple"/></inline-formula> (a large odd integer). The MCA and BSC algorithms were run on the respective data using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e247" xlink:type="simple"/></inline-formula> EM iterations each. For both algorithms the first third of the iterations (up to EM step <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e248" xlink:type="simple"/></inline-formula>) were performed on the full dataset with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e249" xlink:type="simple"/></inline-formula>. For iterations <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e250" xlink:type="simple"/></inline-formula> upto <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e251" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e252" xlink:type="simple"/></inline-formula> was linearly decreased to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e253" xlink:type="simple"/></inline-formula>. After <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e254" xlink:type="simple"/></inline-formula> EM iterations, both models recovered the generating parameters of the data with high accuracy. The recovered generative fields after <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e255" xlink:type="simple"/></inline-formula> iterations and the time courses of data noise and sparsity are shown in <xref ref-type="supplementary-material" rid="pcbi.1003062.s001">Fig. S1</xref> B–D for the MCA model, and in <xref ref-type="supplementary-material" rid="pcbi.1003062.s002">Fig. S2</xref> B–D for the BSC model. Parameter optimization for both models is non-convex but, after convergence, we observed the parameters to represent the ground-truth basis functions for both models in most of the trials. MCA we observed to converge more frequently to local optima. By applying annealing, MCA and BSC both more efficiently avoided local optima. The bars stimuli have very pronounced local optima because the stimulus values are not continuously distributed. For stimuli with more continuous distributions of observed values such as images, we observed no significant differences between runs with and without annealing. In particular, no significant differences in the numbers of globular fields were observed. Both algorithms were, therefore, run without annealing for all the experiments on image patches.</p>
</sec><sec id="s4c">
<title>Numerical experiments - natural image patches</title>
<p>To optimize the model parameters on natural image stimuli, we extracted a set of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e256" xlink:type="simple"/></inline-formula> patches of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e257" xlink:type="simple"/></inline-formula> pixels for one set of experiments, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e258" xlink:type="simple"/></inline-formula> patches of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e259" xlink:type="simple"/></inline-formula> for another set of experiments. Patches were extracted at random positions from the van Hateren natural image database <xref ref-type="bibr" rid="pcbi.1003062-vanHateren1">[58]</xref>. In mammals, visual information is transferred to the visual cortex via center-ON and center-OFF cells in the lateral geniculus nucleus (LGN). The sensitivity of these neurons can be modeled by a difference-of-Gaussians (DoG) filter. We therefore preprocessed all patches by convoluting them with a difference-of-Gaussians kernel. Following experimental results <xref ref-type="bibr" rid="pcbi.1003062-Somers1">[59]</xref>, the ratio between the standard deviation of the positive and the negative Gaussian was chosen to be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e260" xlink:type="simple"/></inline-formula> and the amplitudes were chosen to obtain a mean-free center-surround filter <xref ref-type="bibr" rid="pcbi.1003062-Lcke2">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Puertas1">[23]</xref>. After DoG filtering, values were scaled to fill the interval [−10,10] which provides a form of divisive contrast normalization <xref ref-type="bibr" rid="pcbi.1003062-Carandini1">[60]</xref>. Control experiments with divisive variance normalization <xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen3">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Carandini1">[60]</xref> (which serves the same purpose) produced closely matching results. To control for the influence of the DoG convolution filtering, we ran further experiments using zero-phase PCA whitening (ZCA) which represents a standard preprocessing procedure often used with functional models <xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen3">[28]</xref>. Furthermore, we controlled for the influence of separating positive and negative channels.</p>
<p>For each experiment, the same set of stimuli was used to train the three models under consideration. Those experiments, where we screened through different degrees of overcompleteness (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e261" xlink:type="simple"/></inline-formula> overcomplete with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e262" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e263" xlink:type="simple"/></inline-formula> overcomplete with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e264" xlink:type="simple"/></inline-formula>) were performed on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e265" xlink:type="simple"/></inline-formula> stimuli of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e266" xlink:type="simple"/></inline-formula> pixels (<xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 C</xref> and <xref ref-type="fig" rid="pcbi-1003062-g004">Fig. 4 B</xref>). Each experiment was repeated five times to obtain empirical error bars on the recovered sparseness and the predicted percentage of globular fields (we show twice the standard deviations in <xref ref-type="fig" rid="pcbi-1003062-g003">Figs. 3 C</xref> and <xref ref-type="fig" rid="pcbi-1003062-g004">4 B</xref>). All other experiments, including those investigating the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e267" xlink:type="simple"/></inline-formula> shape statistics (<xref ref-type="fig" rid="pcbi-1003062-g004">Fig. 4 A</xref>) were performed on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e268" xlink:type="simple"/></inline-formula> stimuli of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e269" xlink:type="simple"/></inline-formula>. In total, results of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e270" xlink:type="simple"/></inline-formula> experiments were gathered to create <xref ref-type="fig" rid="pcbi-1003062-g003">Figs. 3 C</xref> and <xref ref-type="fig" rid="pcbi-1003062-g004">4 B</xref>; additionally, about <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e271" xlink:type="simple"/></inline-formula> experiments were performed for various <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e272" xlink:type="simple"/></inline-formula>-plots and for additional controls on differently preprocessed sets of image patches (see below). For each experiment on image patches we performed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e273" xlink:type="simple"/></inline-formula> EM iterations. Analogously to the verification experiments on artificial data, the first <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e274" xlink:type="simple"/></inline-formula> of the EM steps (1 up to 33) were run on the full dataset. For iterations 34 to 66, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e275" xlink:type="simple"/></inline-formula> was again linearly decreased to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e276" xlink:type="simple"/></inline-formula> and kept at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e277" xlink:type="simple"/></inline-formula> for the last 34 EM steps. The smoothing parameter for the non-linearity of the MCA algorithm was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e278" xlink:type="simple"/></inline-formula> as for the artificial data. The approximation parameters for the non-linear and the linear model were both set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e279" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e280" xlink:type="simple"/></inline-formula>. Each experiment to find optimal parameters was typically run on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e281" xlink:type="simple"/></inline-formula> CPU cores using a parallelized implementation.</p>
<sec id="s4c1">
<title>Controls for different LGN models</title>
<p>To control for changes of receptive field shapes depending on different types of preprocessing, we applied MCA and BSC to zero-phase PCA (ZCA) whitened patches <xref ref-type="bibr" rid="pcbi.1003062-Hyvrinen3">[28]</xref> and to DoG preprocessed patches with an independent treatment of center-ON and center-OFF fields.</p>
<p>ZCA: Zero-phase PCA (ZCA) preprocessing is common in more technical applications of sparse coding or ICA. We replaced the DoG convolution by ZCA and normalized the patches as for DoG preprocessing. When MCA and BSC are applied to ZCA whitened data, the globular field percentages change with a lower percentage of globular fields for MCA as one consequence. Also for ZCA whitened data, globular field percentages for MCA remain consistently and significantly higher than for BSC (with at least <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e282" xlink:type="simple"/></inline-formula> more globular fields for MCA; compare <xref ref-type="fig" rid="pcbi-1003062-g003">Fig. 3 C</xref>, dashed blue and green lines). Also the shape distribution of Gabor-like receptive fields changes: we observed for both models more fields elongated along the wave-front, i.e., higher <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e283" xlink:type="simple"/></inline-formula> values (compare <xref ref-type="supplementary-material" rid="pcbi.1003062.s004">Fig. S4</xref> B). This increase in elongation is somewhat more pronounced for the BSC model than for MCA.</p>
<p>Independent ON-/OFF-channels: In mammals, visual information is transferred to the cortex via two types of neurons in the lateral geniculus nucleus (LGN): center-ON and center-OFF cells. ON- and OFF-cells project to the primary visual cortex (mainly layer 4). Pairs of center-ON and center-OFF cells can be combined to provide a net center-surround input to cortical cells. Such ‘push-pull’ inputs are suggested by strongly overlapping receptive fields of LGN cells connecting to the same cortical column (see, e.g., a recent study <xref ref-type="bibr" rid="pcbi.1003062-Jin1">[29]</xref> for discussions and references). We modeled such inputs by using DoG preprocessed patches for numerical experiments. However, center-ON and center-OFF inputs to the cortex may also be assumed to be entirely independent a-priori. The model for this latter situation would correspond to a separation of negative and positive inputs after DoG preprocessing. To control for the effect of independent ON and OFF inputs, we considered experiments on patches that are DoG preprocessed and normalized as above except of a subsequent separation into inputs for positive and negative parts. More formally, we used the same DoG filter and preprocessing to generate patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e284" xlink:type="simple"/></inline-formula> as previously but then converted them into patches <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e285" xlink:type="simple"/></inline-formula> of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e286" xlink:type="simple"/></inline-formula> by assigning: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e287" xlink:type="simple"/></inline-formula> (for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e288" xlink:type="simple"/></inline-formula>) where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e289" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e290" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e291" xlink:type="simple"/></inline-formula> otherwise (see <xref ref-type="supplementary-material" rid="pcbi.1003062.s005">Fig. S5A</xref> for an illustration). Note that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e292" xlink:type="simple"/></inline-formula> holds after separation. As a consequence the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e293" xlink:type="simple"/></inline-formula> for the MCA model (<xref ref-type="disp-formula" rid="pcbi.1003062.e006">Eqn. 2</xref>) reduces to the conventional <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e294" xlink:type="simple"/></inline-formula> function. The applications of MCA and BSC to DoG preprossed image patches assuming independent ON- and OFF-cells essentially reproduced the results for the previous DoG preprocessed patches. Exemplarily, using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e295" xlink:type="simple"/></inline-formula> fields, we find that (1) BSC used, on average, more active units to encode a given image patch than MCA (<xref ref-type="supplementary-material" rid="pcbi.1003062.s005">Fig. S5C</xref>); (2) MCA inferred a much higher fraction of globular receptive fields than BSC (<xref ref-type="supplementary-material" rid="pcbi.1003062.s005">Fig. S5C</xref>); (3) MCA and BSC resulted in different distributions of Gabor field shapes (<xref ref-type="supplementary-material" rid="pcbi.1003062.s005">Fig. S5D</xref>). The differences in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e296" xlink:type="simple"/></inline-formula>-distributions is again not very pronounced, however.</p>
<p>In general, the type of preprocessing has an impact on the shapes of predicted receptive fields - affecting both percentages of globular fields and Gabor shape statistics. However, the difference in the percentages of globular fields with a consistently much higher percentage for the non-linear model is a very stable observation for all used preprocessing models. Also the sparsity of the non-linear model has always been observed to be much higher. Differences between the non-linear and linear model were much less pronounced if the shape distributions of Gabor-like fields were considered. While we found differences between the models for different preprocessing types, they were small compared to differences in sparsity and globular field percentages. At the same time, all distributions using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e297" xlink:type="simple"/></inline-formula>-plots show a large diversity of fields with relatively large overlap with <italic>in vivo</italic> recordings. The analysis of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e298" xlink:type="simple"/></inline-formula>-distributions has by now frequently been applied to analyse the quality of simple cell models <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke2">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Osindero1">[61]</xref> but for the purposes of this study we found <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e299" xlink:type="simple"/></inline-formula>-distributions much less instructive than percentages of globular fields and sparsity levels.</p>
</sec></sec><sec id="s4d">
<title>Analysis of receptive fields</title>
<p>After parameter optimization we computed an estimate of the predicted receptive fields by convolving the learned basis functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e300" xlink:type="simple"/></inline-formula> with the same DoG filter as used for preprocessing. Subsequently, we matched both the predicted receptive fields and the <italic>in vivo</italic> data with Gabor-wavelets and difference-of-Gaussians to gather the statistics of shapes.</p>
<p>The convolution with the DoG filter is an estimate of the receptive field assuming a linear mapping: If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e301" xlink:type="simple"/></inline-formula> denotes a patch (with pixel values as vector entries) and if <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e302" xlink:type="simple"/></inline-formula> parameterizes the mapping, the linear response is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e303" xlink:type="simple"/></inline-formula>. The original response of a unit to a patch consists of two steps: a linear preprocessing and a non-linear response to the preprocessed patch, where the non-linear response is described by the corresponding sparse coding model. We therefore rewrite the mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e304" xlink:type="simple"/></inline-formula> as a two-step mapping. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e305" xlink:type="simple"/></inline-formula> denotes a preprocessed patch (as in the main text), it is given by:<disp-formula id="pcbi.1003062.e306"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e306" xlink:type="simple"/><label>(32)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e307" xlink:type="simple"/></inline-formula> is the DoG kernel for the convolution and where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e308" xlink:type="simple"/></inline-formula> parameterizes a linear mapping from preprocessed patches to hidden units. The mapping <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e309" xlink:type="simple"/></inline-formula> can be estimated by reverse correlation <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref> using the models' approximate posteriors as responses. If we denote such an estimate by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e310" xlink:type="simple"/></inline-formula>, the total linear response is given by:<disp-formula id="pcbi.1003062.e311"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e311" xlink:type="simple"/><label>(33)</label></disp-formula>This means the receptive field estimate is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e312" xlink:type="simple"/></inline-formula> convoluted with the same kernel as used for preprocessing. <xref ref-type="supplementary-material" rid="pcbi.1003062.s006">Fig. S6</xref> (top row) shows examples of estimates obtained in this way. Alternatively, note that the basis functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e313" xlink:type="simple"/></inline-formula> are already similar to stimuli that best drive the hidden units. A direct estimate of the parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e314" xlink:type="simple"/></inline-formula> is therefore given by the basis function parameters themselves (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e315" xlink:type="simple"/></inline-formula>), and the corresponding receptive field estimate is given by convoluted basis functions: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e316" xlink:type="simple"/></inline-formula>. In numerical experiments, both estimates resulted in very similar receptive fields, and some representative examples are shown in <xref ref-type="supplementary-material" rid="pcbi.1003062.s006">Fig. S6</xref>. Because of this high similarity we used the convoluted basis functions as receptive field estimates, which reduced the otherwise extensive computational costs of reverse correlation for the very large number of receptive fields that were analysed in this study.</p>
<p>To analyse the shape statistics of the estimated receptive fields resulting from our numerical experiments and from experimental recordings <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>, receptive fields were matched against Gabor-wavelets <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e317" xlink:type="simple"/></inline-formula> and difference-of-Gaussians <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e318" xlink:type="simple"/></inline-formula>. Note that for notational purposes we replace the index <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e319" xlink:type="simple"/></inline-formula> denoting the input units by two-dimensional coordinates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e320" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e321" xlink:type="simple"/></inline-formula> denoting the actual planar position in the two-dimensional field. The <italic>in vivo</italic> data analysed for comparison was obtained in experiments on macaque monkeys in an earlier study <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>. These receptive fields were recorded from neurons in the primary visual cortex using reverse correlation, and were matched with Gabor and DoG functions in the same way as the receptive fields predicted by the models. Representative examples are shown in <xref ref-type="supplementary-material" rid="pcbi.1003062.s007">Fig. S7</xref> A. For each receptive field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e322" xlink:type="simple"/></inline-formula>, we sought the eight parameters which minimized the mean squared error between the field and the Gabor-wavelet <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e323" xlink:type="simple"/></inline-formula>. Where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e324" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e325" xlink:type="simple"/></inline-formula> are the center coordinates of the Gabor-wavelet, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e326" xlink:type="simple"/></inline-formula> is its spatial rotation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e327" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e328" xlink:type="simple"/></inline-formula> parameterize the shape of the Gaussian envelope, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e329" xlink:type="simple"/></inline-formula> is a measure of the frequency of the planar wave component, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e330" xlink:type="simple"/></inline-formula> is its phase shift and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e331" xlink:type="simple"/></inline-formula> is the overall amplitude of the Gabor-wavelet:<disp-formula id="pcbi.1003062.e332"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e332" xlink:type="simple"/><label>(34)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e333" xlink:type="simple"/></inline-formula> are the translated and rotated coordinates of the function.</p>
<p>Similarly, again for each receptive field <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e334" xlink:type="simple"/></inline-formula>, we sought the eight parameters of the difference-of-Gaussians kernel <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e335" xlink:type="simple"/></inline-formula> which minimized the squared distance to each field. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e336" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e337" xlink:type="simple"/></inline-formula> are the center coordinates of the DoG kernel, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e338" xlink:type="simple"/></inline-formula> its spatial rotation. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e339" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e340" xlink:type="simple"/></inline-formula> parameterize the shape of the inner Gaussian, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e341" xlink:type="simple"/></inline-formula> parameterizes the size difference between the Gaussians and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e342" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e343" xlink:type="simple"/></inline-formula> specify the amplitudes of the Gaussians:<disp-formula id="pcbi.1003062.e344"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003062.e344" xlink:type="simple"/></disp-formula>We classified a receptive field as being globular if the reconstruction error of the best matching DoG function was smaller then the reconstruction error of the best matching Gabor wavelet and if the aspect ratio of the DoG was smaller than 2.0 (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e345" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e346" xlink:type="simple"/></inline-formula> is the parameter for the more elongated axis). A small difference between the errors of a match with DoG and a match with a Gabor function means that the receptive field is neither clearly center-surround nor clearly Gabor-like. In such cases we call the field <italic>ambiguous</italic>. Using a standard least-square optimization method <xref ref-type="bibr" rid="pcbi.1003062-Powell1">[62]</xref>, we got robust result for fitting and classification for almost all receptive fields. We applied matching and classification to the results of each of our numerical experiments as well as to the experimental data <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref> provided by D. Ringach. The experimental data consisted of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e347" xlink:type="simple"/></inline-formula> fields of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e348" xlink:type="simple"/></inline-formula> pixels, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e349" xlink:type="simple"/></inline-formula> fields of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e350" xlink:type="simple"/></inline-formula> pixels, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e351" xlink:type="simple"/></inline-formula> fields of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e352" xlink:type="simple"/></inline-formula> pixels. Our procedure classified <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e353" xlink:type="simple"/></inline-formula> fields as clearly globular and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e354" xlink:type="simple"/></inline-formula> as clearly Gabor-like (see <xref ref-type="supplementary-material" rid="pcbi.1003062.s007">Fig. S7</xref> A for some examples). As the experimental data is less smooth than the theoretical receptive field predictions, a relatively large number of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e355" xlink:type="simple"/></inline-formula> (out of 250) fields were ambiguous in this case (see <xref ref-type="supplementary-material" rid="pcbi.1003062.s007">Fig. S7</xref> B for some examples). By considering half of these fields as globular, we obtained <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e356" xlink:type="simple"/></inline-formula> globular fields (a percentage of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e357" xlink:type="simple"/></inline-formula>); considering all of them as globular corresponds to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e358" xlink:type="simple"/></inline-formula> globular fields; and considering all ambiguous fields as Gabor-like results in a percentage of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e359" xlink:type="simple"/></inline-formula> globular fields. In <xref ref-type="fig" rid="pcbi-1003062-g002">Fig. 2</xref> C we used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e360" xlink:type="simple"/></inline-formula> as mean with the higher and the lower percentages defining the limits of the corresponding error bar.</p>
<p>To analyse the shape distribution of receptive fields, the shape relevant parameters can be visualized as an <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e361" xlink:type="simple"/></inline-formula>-plot. That is, for each receptive field (predicted or measured) the dimensionless values given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e362" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e363" xlink:type="simple"/></inline-formula> were computed, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e364" xlink:type="simple"/></inline-formula> is the spatial frequency of the fitted Gabor function, and where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e365" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e366" xlink:type="simple"/></inline-formula> are the standard deviations of its Gaussian envelope in wavevector direction and orthogonal to it <xref ref-type="bibr" rid="pcbi.1003062-Rehn1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Ringach1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Lcke2">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1003062-Zylberberg1">[30]</xref>. For our analysis, we first removed the globular fields from the sets of experimentally measured fields as well as from the sets of predicted receptive fields before visualizing the corresponding <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e367" xlink:type="simple"/></inline-formula> distributions. This procedure removed the otherwise ill-posed problem of having to match center-surround fields with Gabor wavelets.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003062.s001" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003062.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p><bold>Experiments with MCA on artificial data.</bold> <bold>A</bold> Random selection of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e368" xlink:type="simple"/></inline-formula> artificially generated data points with basis functions in the form of bars. Each data point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e369" xlink:type="simple"/></inline-formula> is composed of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e370" xlink:type="simple"/></inline-formula> pixels. <bold>B</bold> Learned basis functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e371" xlink:type="simple"/></inline-formula>. <bold>C, D</bold> Evolution of the inferred sparsity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e372" xlink:type="simple"/></inline-formula> and the noise parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e373" xlink:type="simple"/></inline-formula> over a course of 50 EM steps (dashed lines indicate ground-truth).</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003062.s002" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003062.s002" position="float" xlink:type="simple"><label>Figure S2</label><caption>
<p><bold>Experiments with BSC on artificial data.</bold> <bold>A</bold> Random selection of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e374" xlink:type="simple"/></inline-formula> artificially generated data points with basis functions in the form of bars. Each data point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e375" xlink:type="simple"/></inline-formula> is composed of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e376" xlink:type="simple"/></inline-formula> pixels. <bold>B</bold> Learned basis functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e377" xlink:type="simple"/></inline-formula>. <bold>C, D</bold> Evolution of the inferred sparsity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e378" xlink:type="simple"/></inline-formula> and the noise parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e379" xlink:type="simple"/></inline-formula> over a course of 50 EM steps (dashed lines indicate ground-truth).</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003062.s003" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003062.s003" position="float" xlink:type="simple"><label>Figure S3</label><caption>
<p><bold>Example results when applying MCA and BSC to DoG preprocessed images.</bold> <bold>A</bold> Predicted basis functions for MCA (left) and BSC (right) with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e380" xlink:type="simple"/></inline-formula> hidden units each. <bold>B</bold> Predicted basis functions for MCA (top) and BSC (bottom) with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e381" xlink:type="simple"/></inline-formula> hidden units each.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003062.s004" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003062.s004" position="float" xlink:type="simple"><label>Figure S4</label><caption>
<p><bold>Results when applying MCA and BSC to zero-phase whitened data (ZCA).</bold> <bold>A</bold> Full set of learned basis functions when applied with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e382" xlink:type="simple"/></inline-formula> hidden units. <bold>B</bold> Distribution of shapes for the Gabor-like fields in <bold>A</bold>.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003062.s005" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003062.s005" position="float" xlink:type="simple"><label>Figure S5</label><caption>
<p><bold>Results when MCA and BSC are applied to DoG preprocessed data with independent ON- and OFF-center channels.</bold> <bold>A</bold> Visualization of the doublication of input dimensions for independent ON and OFF channels. <bold>B, C, D</bold> <xref ref-type="sec" rid="s2">Results</xref> for MCA and BSC after running on <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e383" xlink:type="simple"/></inline-formula> patches (size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e384" xlink:type="simple"/></inline-formula> pixels) with independent ON and OFF channels. The number of hidden variables was set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e385" xlink:type="simple"/></inline-formula>.</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003062.s006" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003062.s006" position="float" xlink:type="simple"><label>Figure S6</label><caption>
<p><bold>Comparison of receptive field estimates.</bold> Representative examples of receptive fields estimated from basis functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003062.e386" xlink:type="simple"/></inline-formula> are shown. Estimates based on reverse correlation (top row) are shown together with their corresponding estimates based on direct convolution of the basis function (bottom row).</p>
<p>(TIFF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003062.s007" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003062.s007" position="float" xlink:type="simple"><label>Figure S7</label><caption>
<p><bold>Fitting of learned and </bold><bold><italic>in vivo</italic></bold><bold> receptive fields with Gabor functions and DoGs.</bold> <bold>A</bold> Selection of 16 of the 250 receptive fields measured in macaque monkeys <xref ref-type="bibr" rid="pcbi.1003062-Usrey1">[15]</xref> using reverse correlation together with their resulting matches. <bold>A</bold> The upper row shows original recordings that were classified as globular, and the second row shows the corresponding DoG matches. The third row shows original recordings that were classified as Gabor-like, and the forth row shows their corresponding matches. <bold>B</bold> Examples of original receptive fields that were ambiguous, i.e., neither clearly difference-of-Gaussian nor Gabor-like. Note the Gaussian fields can be well matched by DoG and Gabor functions and are therefore inherently ambiguous. <bold>C</bold> A selection of 16 receptive field estimates resulting from numerical experiments. The fields and their matches are shown as in <bold>A</bold>.</p>
<p>(TIFF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Dario Ringach for providing original receptive field recordings of macaque monkeys.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003062-Comon1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Comon</surname><given-names>P</given-names></name> (<year>1994</year>) <article-title>Independent component analysis, a new concept?</article-title> <source>Signal Process</source> <volume>36</volume>: <fpage>287</fpage>–<lpage>314</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Bell1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1997</year>) <article-title>The “independent components” of natural scenes are edge filters</article-title>. <source>Vis Res</source> <volume>37</volume>: <fpage>3327</fpage>–<lpage>38</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Hyvrinen1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Oja</surname><given-names>E</given-names></name> (<year>1997</year>) <article-title>A fast fixed-point algorithm for independent component analysis</article-title>. <source>Neural Comp</source> <volume>9</volume>: <fpage>1483</fpage>–<lpage>92</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Olshausen1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>D</given-names></name> (<year>1996</year>) <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source> <volume>381</volume>: <fpage>607</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Attneave1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Attneave</surname><given-names>F</given-names></name> (<year>1954</year>) <article-title>Some informational aspects of visual perception</article-title>. <source>Psychol Rev</source> <volume>61</volume>: <fpage>183</fpage>–<lpage>193</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Barlow1"><label>6</label>
<mixed-citation publication-type="other" xlink:type="simple">Barlow H (1961) Possible principles underlying the transformation of sensory messages. In: Rosenbilth W, editor. Sensory Communication, Chapter 13: pp. 217–234.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Marr1"><label>7</label>
<mixed-citation publication-type="other" xlink:type="simple">Marr D (1982) Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. San Francisco: WH Freeman and Company.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Simoncelli1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simoncelli</surname><given-names>E</given-names></name> (<year>2003</year>) <article-title>Vision and the statistics of the visual environment</article-title>. <source>Curr Opin Neurobiol</source> <volume>13</volume>: <fpage>144</fpage>–<lpage>149</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Lee1"><label>9</label>
<mixed-citation publication-type="other" xlink:type="simple">Lee H, Battle A, Raina R, Ng A (2007) Efficient sparse coding algorithms. In: Proc NIPS. Volume 20, pp. 801–808. Source code available at <ext-link ext-link-type="uri" xlink:href="http://ai.stanford.edu/~hllee/softwares/nips06-sparsecoding.htm" xlink:type="simple">http://ai.stanford.edu/~hllee/softwares/nips06-sparsecoding.htm</ext-link>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Berkes1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Turner</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>On sparsity and overcompleteness in image models</article-title>. <source>Proc NIPS</source> <volume>21</volume>: <fpage>89</fpage>–<lpage>96</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Rehn1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rehn</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sommer</surname><given-names>FT</given-names></name> (<year>2007</year>) <article-title>A network that uses few active neurones to code visual input predicts the diverse shapes of cortical receptive fields</article-title>. <source>J Comput Neurosci</source> <volume>22</volume>: <fpage>135</fpage>–<lpage>46</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Dayan1"><label>12</label>
<mixed-citation publication-type="other" xlink:type="simple">Dayan P, Abbott LF (2001) Theoretical Neuroscience. Cambridge: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Hyvrinen2"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hoyer</surname><given-names>P</given-names></name> (<year>2000</year>) <article-title>Emergence of phase- and shift-invariant features by decomposition of natural images into independent feature subspaces</article-title>. <source>Neural Comp</source> <volume>12</volume>: <fpage>1705</fpage>–<lpage>20</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Ringach1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ringach</surname><given-names>DL</given-names></name> (<year>2002</year>) <article-title>Spatial structure and symmetry of simple-cell receptive fields in macaque primary visual cortex</article-title>. <source>J Neurophys</source> <volume>88</volume>: <fpage>455</fpage>–<lpage>63</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Usrey1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Usrey</surname><given-names>WM</given-names></name>, <name name-style="western"><surname>Sceniak</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Chapman</surname><given-names>B</given-names></name> (<year>2003</year>) <article-title>Receptive fields and response properties of neurons in layer 4 of ferret visual cortex</article-title>. <source>J Neurophys</source> <volume>89</volume>: <fpage>1003</fpage>–<lpage>1015</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Niell1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niell</surname><given-names>CM</given-names></name>, <name name-style="western"><surname>Stryker</surname><given-names>MP</given-names></name> (<year>2008</year>) <article-title>Highly selective receptive fields in mouse visual cortex</article-title>. <source>J Neurosci</source> <volume>28</volume>: <fpage>7520</fpage>–<lpage>7536</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Olshausen2"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1997</year>) <article-title>Sparse coding with an overcomplete basis set: A strategy employed by V1?</article-title> <source>Vis Res</source> <volume>37</volume>: <fpage>3311</fpage>–<lpage>3325</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Lcke1"><label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Lücke J (2007) A dynamical model for receptive field self-organization in V1 cortical columns. In: Proc ICANN. Springer, LNCS 4669, pp. 389–398.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Lcke2"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name> (<year>2009</year>) <article-title>Receptive field self-organization in a model of the fine-structure in V1 cortical columns</article-title>. <source>Neural Comp</source> <volume>21</volume>: <fpage>2805</fpage>–<lpage>45</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Olshausen3"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Cadieu</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Warland</surname><given-names>DK</given-names></name> (<year>2009</year>) <article-title>Learning real and complex overcomplete representations from the statistics of natural images</article-title>. <source>Proc SPIE</source> <volume>7446</volume>: <fpage>744060S</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Saxe1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saxe</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Bhand</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Mudur</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Suresh</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Ng</surname><given-names>AY</given-names></name> (<year>2011</year>) <article-title>Unsupervised learning models of primary cortical receptive fields and receptive field plasticity</article-title>. <source>Proc NIPS</source> <volume>24</volume>: <fpage>1971</fpage>–<lpage>1979</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Lcke3"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name> (<year>2008</year>) <article-title>Maximal causes for non-linear component extraction</article-title>. <source>J Mach Learn Res</source> <volume>9</volume>: <fpage>1227</fpage>–<lpage>67</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Puertas1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Puertas</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Bornschein</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>The maximal causes of natural scenes are edge filters</article-title>. <source>Proc NIPS</source> <volume>23</volume>: <fpage>1939</fpage>–<lpage>47</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Lcke4"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Eggert</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>Expectation truncation and the benefits of preselection in training generative models</article-title>. <source>J Mach Learn Res</source> <volume>11</volume>: <fpage>2855</fpage>–<lpage>900</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Haft1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haft</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hofman</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Tresp</surname><given-names>V</given-names></name> (<year>2004</year>) <article-title>Generative binary codes</article-title>. <source>Pattern Anal Appl</source> <volume>6</volume>: <fpage>269</fpage>–<lpage>84</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Henniges1"><label>26</label>
<mixed-citation publication-type="other" xlink:type="simple">Henniges M, Puertas G, Bornschein J, Eggert J, Lücke J (2010) Binary sparse coding. In: Proc LVA/ICA, LNCS <volume>6365</volume>: : 450–57.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Olshausen4"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name> (<year>2002</year>) <article-title>Sparse Codes and Spikes. MIT Press</article-title>. <source>Probabilistic Models of the Brain: Perception and Neural Function, Chapter</source> <volume>13</volume>: <fpage>257</fpage>–<lpage>272</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Hyvrinen3"><label>28</label>
<mixed-citation publication-type="other" xlink:type="simple">Hyvärinen A, Hurri J, Hoyer PO (2009) Natural Image Statistics. Springer, 1st edition.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Jin1"><label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jin</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Swadlow</surname><given-names>HA</given-names></name>, <name name-style="western"><surname>Alonso</surname><given-names>JM</given-names></name> (<year>2011</year>) <article-title>Population receptive fields of ON and OFF thalamic inputs to an orientation column in visual cortex</article-title>. <source>Nat Neurosci</source> <fpage>232</fpage>–<lpage>238</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Zylberberg1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zylberberg</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Murphy</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>DeWeese</surname><given-names>MR</given-names></name> (<year>2011</year>) <article-title>A Sparse Coding Model with Synaptically Local Plasticity and Spiking Neurons Can Account for the Diverse Shapes of V1 Simple Cell Receptive Fields</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002250</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Fiser1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fiser</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Orban</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source>Trends in Cognitive Science</source> <volume>14</volume>: <fpage>119</fpage>–<lpage>130</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Berkes2"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Orban</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Fiser</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment</article-title>. <source>Science</source> <volume>331</volume>: <fpage>83</fpage>–<lpage>87</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Willmore1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willmore</surname><given-names>BDB</given-names></name>, <name name-style="western"><surname>Mazer</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2011</year>) <article-title>Sparse coding in striate and extrastriate visual cortex</article-title>. <source>J Neurophys</source> <volume>105</volume>: <fpage>2907</fpage>–<lpage>2919</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Jones1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jones</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Palmer</surname><given-names>LA</given-names></name> (<year>1987</year>) <article-title>An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex</article-title>. <source>J Neurophys</source> <volume>58</volume>: <fpage>1233</fpage>–<lpage>58</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Rozell1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rozell</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Baraniuk</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Olshausen</surname><given-names>B</given-names></name> (<year>2008</year>) <article-title>Sparse coding via thresholding and local competition in neural circuits</article-title>. <source>Neural Comp</source> <volume>20</volume>: <fpage>2526</fpage>–<lpage>2563</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Fldik1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Földiák</surname><given-names>P</given-names></name> (<year>1990</year>) <article-title>Forming sparse representations by local anti-Hebbian learning</article-title>. <source>Biol Cybern</source> <volume>64</volume>: <fpage>165</fpage>–<lpage>170</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Spratling1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Spratling</surname><given-names>MW</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>MH</given-names></name> (<year>2002</year>) <article-title>Preintegration lateral inhibition enhances unsupervised learning</article-title>. <source>Neural Comp</source> <volume>14</volume>: <fpage>2157</fpage>–<lpage>2179</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Lcke5"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Malsburg</surname><given-names>C</given-names></name> (<year>2004</year>) <article-title>Rapid processing and unsupervised learning in a model of the cortical macrocolumn</article-title>. <source>Neural Comp</source> <volume>16</volume>: <fpage>501</fpage>–<lpage>33</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Savin1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Savin</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Joshi</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Triesch</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>Independent component analysis in spiking neurons</article-title>. <source>PLoS Comput Biol</source> <volume>6</volume>: <fpage>e1000757</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Graham1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graham</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>2009</year>) <article-title>Natural images: Coding efficiency</article-title>. <source>Encyclopedia of Neuroscience</source> <volume>6</volume>: <fpage>19</fpage>–<lpage>27</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Zemel1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zemel</surname><given-names>RS</given-names></name>, <name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name> (<year>1998</year>) <article-title>Probabilistic interpretation of population codes</article-title>. <source>Neural Comp</source> <volume>10</volume>: <fpage>403</fpage>–<lpage>430</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Ma1"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ma</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>Beck</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name>, <name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name> (<year>2006</year>) <article-title>Bayesian inference with probabilistic population codes</article-title>. <source>Nature Neuroscience</source> <volume>9</volume>: <fpage>1432</fpage>–<lpage>1438</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Buesing1"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buesing</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Bill</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Nessler</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2011</year>) <article-title>Neural dynamics as sampling: A model for stochastic computation in recurrent networks of spiking neurons</article-title>. <source>PLoS Computational Biology</source> <volume>7</volume>: <fpage>e1002211</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Shelton1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shelton</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Bornschein</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sheikh</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Select and sample - a model of efficient neural inference and learning</article-title>. <source>Proc NIPS</source> <volume>24</volume>: <fpage>2618</fpage>–<lpage>2626</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Saund1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Saund</surname><given-names>E</given-names></name> (<year>1995</year>) <article-title>A multiple cause mixture model for unsupervised learning</article-title>. <source>Neural Comp</source> <volume>7</volume>: <fpage>51</fpage>–<lpage>71</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Dayan2"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Zemel</surname><given-names>RS</given-names></name> (<year>1995</year>) <article-title>Competition and multiple cause models</article-title>. <source>Neural Comp</source> <volume>7</volume>: <fpage>565</fpage>–<lpage>579</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-ingliar1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Šingliar</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Hauskrecht</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Noisy-OR component analysis and its application to link analysis</article-title>. <source>J Mach Learn Res</source> <volume>7</volume>: <fpage>2189</fpage>–<lpage>2213</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Hyvrinen4"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Pajunen</surname><given-names>P</given-names></name> (<year>1999</year>) <article-title>Nonlinear Independent Component Analysis: Existence and uniqueness results</article-title>. <source>Neural Networks</source> <volume>12</volume>: <fpage>429</fpage>–<lpage>439</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Theis1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Theis</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Gerwinn</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>In all likelihood, deep belief is not enough</article-title>. <source>J Mach Learn Res</source> <volume>12</volume>: <fpage>3071</fpage>–<lpage>96</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Zoran1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zoran</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Weiss</surname><given-names>Y</given-names></name> (<year>2012</year>) <article-title>Natural images, Gaussian mixtures and dead leaves</article-title>. <source>Proc NIPS</source> <volume>25</volume>: <fpage>1745</fpage>–<lpage>1753</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Matheron1"><label>51</label>
<mixed-citation publication-type="other" xlink:type="simple">Matheron G (1975) Random sets and integral geometry. New York: Wiley.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Mumford1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mumford</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Gidas</surname><given-names>B</given-names></name> (<year>2001</year>) <article-title>Stochastic models for generic images</article-title>. <source>Q Appl Math</source> <volume>59</volume>: <fpage>85</fpage>–<lpage>111</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Pitkow1"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pitkow</surname><given-names>X</given-names></name> (<year>2010</year>) <article-title>Exact feature probabilities in images with occlusion</article-title>. <source>J Vision</source> <volume>10</volume>: <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Lcke6"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lücke</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Turner</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Sahani</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Henniges</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Occlusive Components Analysis</article-title>. <source>Proc NIPS</source> <volume>22</volume>: <fpage>1069</fpage>–<lpage>77</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Spratling2"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Spratling</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Learning image components for object recognition</article-title>. <source>J Mach Learn Res</source> <volume>7</volume>: <fpage>793</fpage>–<lpage>815</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Neal1"><label>56</label>
<mixed-citation publication-type="other" xlink:type="simple">Neal R, Hinton G (1998) A view of the EM algorithm that justifies incremental, sparse, and other variants. In: Jordan MI, editor, Nato Adv Sci I D-beh. Kluwer.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Hoyer1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hoyer</surname><given-names>PO</given-names></name> (<year>2004</year>) <article-title>Non-negative matrix factorization with sparseness constraints</article-title>. <source>J Mach Learn Res</source> <volume>5</volume>: <fpage>1457</fpage>–<lpage>69</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-vanHateren1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name>, <name name-style="western"><surname>van der Schaaf</surname><given-names>A</given-names></name> (<year>1998</year>) <article-title>Independent component filters of natural images compared with simple cells in primary visual cortex</article-title>. <source>Proc R Soc Lond B</source> <volume>265</volume>: <fpage>359</fpage>–<lpage>66</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Somers1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Somers</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Nelson</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sur</surname><given-names>M</given-names></name> (<year>1995</year>) <article-title>An emergent model of orientation selectivity in cat visual cortical simple cells</article-title>. <source>The Journal of Neuroscience</source> <volume>15</volume>: <fpage>5448</fpage>–<lpage>5465</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Carandini1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Heeger</surname><given-names>DJ</given-names></name> (<year>2012</year>) <article-title>Normalization as a canonical neural computation</article-title>. <source>Nat Rev Neurosci</source> <volume>13</volume>: <fpage>51</fpage>–<lpage>62</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Osindero1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Osindero</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Welling</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hinton</surname><given-names>GE</given-names></name> (<year>2006</year>) <article-title>Topographic product models applied to natural scene statistics</article-title>. <source>Neural Comp</source> <volume>18</volume>: <fpage>381</fpage>–<lpage>414</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003062-Powell1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Powell</surname><given-names>M</given-names></name> (<year>1964</year>) <article-title>An efficient method for finding the minimum of a function of several variables without calculating derivatives</article-title>. <source>The Computer Journal</source> <volume>7</volume>: <fpage>155</fpage>–<lpage>162</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
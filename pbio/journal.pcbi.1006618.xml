<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006618</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-01873</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Infectious diseases</subject><subj-group><subject>Bacterial diseases</subject><subj-group><subject>Hemolytic-uremic syndrome</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Amniotes</subject><subj-group><subject>Mammals</subject><subj-group><subject>Ferrets</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular structures and organelles</subject><subj-group><subject>Cell membranes</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A dynamic network model of temporal receptive fields in primary auditory cortex</article-title>
<alt-title alt-title-type="running-head">Dynamic network model of temporal receptive fields in auditory cortex</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0057-5248</contrib-id>
<name name-style="western">
<surname>Rahman</surname>
<given-names>Monzilur</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Willmore</surname>
<given-names>Ben D. B.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5180-7179</contrib-id>
<name name-style="western">
<surname>King</surname>
<given-names>Andrew J.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7851-4840</contrib-id>
<name name-style="western">
<surname>Harper</surname>
<given-names>Nicol S.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Department of Physiology, Anatomy and Genetics, University of Oxford, Oxford, United Kingdom</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Theunissen</surname>
<given-names>Frédéric E.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of California at Berkeley, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">monzilur.rahman@dpag.ox.ac.uk</email> (MR); <email xlink:type="simple">nicol.harper@dpag.ox.ac.uk</email> (NSH)</corresp>
</author-notes>
<pub-date pub-type="epub">
<day>6</day>
<month>5</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>5</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>5</issue>
<elocation-id>e1006618</elocation-id>
<history>
<date date-type="received">
<day>4</day>
<month>11</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>13</day>
<month>4</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Rahman et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006618"/>
<abstract>
<p>Auditory neurons encode stimulus history, which is often modelled using a span of time-delays in a spectro-temporal receptive field (STRF). We propose an alternative model for the encoding of stimulus history, which we apply to extracellular recordings of neurons in the primary auditory cortex of anaesthetized ferrets. For a linear-non-linear STRF model (LN model) to achieve a high level of performance in predicting single unit neural responses to natural sounds in the primary auditory cortex, we found that it is necessary to include time delays going back at least 200 ms in the past. This is an unrealistic time span for biological delay lines. We therefore asked how much of this dependence on stimulus history can instead be explained by dynamical aspects of neurons. We constructed a neural-network model whose output is the weighted sum of units whose responses are determined by a dynamic firing-rate equation. The dynamic aspect performs low-pass filtering on each unit’s response, providing an exponentially decaying memory whose time constant is individual to each unit. We find that this dynamic network (DNet) model, when fitted to the neural data using STRFs of only 25 ms duration, can achieve prediction performance on a held-out dataset comparable to the best performing LN model with STRFs of 200 ms duration. These findings suggest that integration due to the membrane time constants or other exponentially-decaying memory processes may underlie linear temporal receptive fields of neurons beyond 25 ms.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The responses of neurons in the primary auditory cortex depend on the recent history of sounds over seconds or less. Typically, this dependence on the past has been modelled by applying a wide span of time delays to the input, although this is likely to be biologically unrealistic. Real neurons integrate the history of their activity due to the dynamical properties of their cell membranes and other components. We show that a network with a realistically narrow span of delays and with units having dynamic characteristics like those found in neurons, succinctly models neural responses recorded from ferret primary auditory cortex. Because these integrative properties are widespread, our dynamic network provides a basis for modelling responses in other neural systems.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>WT108369/Z/2015/Z</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5180-7179</contrib-id>
<name name-style="western">
<surname>King</surname>
<given-names>Andrew J.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>BDBW, NSH, and AJK were supported by Wellcome Trust funding (WT108369/Z/2015/Z). MR was supported by the Clarendon Fund Scholarship. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="0"/>
<page-count count="24"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-05-24</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The experimental data underlying the results presented in the study were previously published by Harper et al. (2016) and are available from <ext-link ext-link-type="uri" xlink:href="https://osf.io/ayw2p/" xlink:type="simple">https://osf.io/ayw2p/</ext-link>. All codes are available from <ext-link ext-link-type="uri" xlink:href="https://github.com/monzilur/DNet" xlink:type="simple">https://github.com/monzilur/DNet</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The tuning properties of auditory neurons are commonly described by a spectro-temporal receptive field (STRF) model, which characterizes the linear dependence of the neural response on the sound spectrum at a range of latencies [<xref ref-type="bibr" rid="pcbi.1006618.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006618.ref014">14</xref>]. A static non-linearity is often applied to the output from the linear STRF—this linear non-linear (LN) model estimates the responses of neurons significantly better than the linear estimate [<xref ref-type="bibr" rid="pcbi.1006618.ref015">15</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref016">16</xref>]. While STRF models are somewhat successful in explaining the dependence of neural responses on the past few hundred milliseconds of stimulus history [<xref ref-type="bibr" rid="pcbi.1006618.ref017">17</xref>], these models do not show how this temporal aspect of receptive fields might be implemented biologically. The most direct biological interpretation of the STRF model would involve auditory cortical neurons receiving inputs at a range of simple delays spanning out to 200 ms; however, this is biologically unrealistic. The onset latencies of neurons in the ventral division of the medial geniculate body (vMGB), which provides the primary ascending input to primary auditory cortex (A1), are typically less than ~14 ms in the ferret [<xref ref-type="bibr" rid="pcbi.1006618.ref018">18</xref>], the animal species that provided the data that were modelled in this study. In the cat vMGB response latencies are typically less than ~20 ms [<xref ref-type="bibr" rid="pcbi.1006618.ref019">19</xref>], in the mouse less than ~10 ms [<xref ref-type="bibr" rid="pcbi.1006618.ref020">20</xref>], and in the marmoset less than ~40 ms [<xref ref-type="bibr" rid="pcbi.1006618.ref021">21</xref>]. These values are far less than the duration of stimulus history which influences the responses of A1 neurons. Although a few vMGB units do show onset latencies beyond this range (in cat up to 70 ms [<xref ref-type="bibr" rid="pcbi.1006618.ref019">19</xref>], in mouse up to 60 ms [<xref ref-type="bibr" rid="pcbi.1006618.ref020">20</xref>], and in marmoset up to 300 ms [<xref ref-type="bibr" rid="pcbi.1006618.ref021">21</xref>]), this small fraction is unlikely to be the main determinant of the dependence of the neural response in primary auditory cortex on stimulus history beyond a few tens of milliseconds. This is because there are other plausible mechanisms, such as the dynamic temporally-integrative properties intrinsic to neurons.</p>
<p>In this study, using recordings from anesthetised ferrets, we asked how much of the dependence on recent stimulus history—the temporal receptive fields, of primary auditory cortical neurons can instead be explained by certain of these simple dynamical aspects of neurons–an approach more consistent with the known biology. To model a neuron’s response, we constructed a neural network model whose output is the weighted sum of the responses of multiple units, each of which resembles an LN model. However, the response of each unit of the network was modified in accordance with a dynamic firing-rate equation. This low-pass filters the unit’s response (by convolving with an exponential decay impulse response), providing a simple exponentially decaying memory. This integrative characteristic can be related to the capacitance and resistance of nerve cell membranes, and the individual time constant of each unit can be related to the membrane time constant of real neurons [<xref ref-type="bibr" rid="pcbi.1006618.ref022">22</xref>]. The dynamic aspect of our network can alternatively be interpreted in terms of other neurobiological dynamical phenomena, such as channel-based neural adaptation, short term synaptic plasticity, or recurrent network properties. We found that our biologically-motivated dynamical model can accurately capture the temporal receptive fields of neurons without the need for a wide span of latencies of input.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec003">
<title>Ethics statement</title>
<p>In vivo electrophysiological recordings in ferrets were performed under ketamine (5 mg/kg/h) and medetomidine (0.022 mg/kg/h) anaesthesia. All animal procedures were performed under license from the UK Home Office and were approved by the University of Oxford Committee on Animal Care and Ethical Review.</p>
</sec>
<sec id="sec004">
<title>Stimuli</title>
<p>Models were fitted to single-unit neural responses of anesthetized ferrets to natural sound stimuli. Altogether, 20 sound clips were presented containing human speech in different languages, other animal vocalizations (e.g. ferret) and environmental sounds (e.g. wind and water). All clips were 5 s long with a sampling rate of 48,828.125 Hz and with root mean square intensity ranging from 75 to 82 dB SPL.</p>
</sec>
<sec id="sec005">
<title>Experimental setup and neural responses</title>
<p>The electrophysiological data used in this study were taken from a series of experiments used in a previous study by Harper et al. [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>]. Briefly, recordings were made from the primary auditory cortical areas, A1 and the anterior auditory field (AAF) of 6 adult pigmented ferrets (5 females and 1 male) under ketamine (5 mg/kg/h) and medetomidine (0.022 mg/kg/h) anaesthesia for 20 repeats of the 20 natural sound clips played in random order. All animal procedures were performed under license from the United Kingdom Home Office and were approved by the local ethical review committee. In total, 56 penetrations resulted in 549 single and multi-units, of which 284 were single units. A single unit was taken for analysis only if its activity was driven by the stimulus according to the noise ratio (see below). For each unit, the number of spikes was counted in each 5 ms time bin and averaged over repeats, to provide a response profile <italic>y</italic><sub><italic>n</italic></sub>(<italic>t</italic>), where <italic>t</italic> is time, and <italic>n</italic> is the clip number. The total number of time bins in a clip is <italic>T</italic>. For simpler notation, we will drop the subscript <italic>n</italic>, unless we note otherwise.</p>
</sec>
<sec id="sec006">
<title>Noise ratio</title>
<p>The noise ratio was calculated as a measure of how much the response of each unit is dependent on the stimuli [<xref ref-type="bibr" rid="pcbi.1006618.ref009">9</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref024">24</xref>]. The noise ratio was measured over all 20 stimuli and 20 repeats. Any unit with a noise ratio &gt; 40 were excluded from the study. Also, only putative single units were used. This resulted in 73 neurons for the study.</p>
</sec>
<sec id="sec007">
<title>Cochleagrams</title>
<p>The models receive the input as a cochleagram, a spectrogram-like transformation of the sound waveform. The cochleagram approximates the spectral filtering performed by the auditory periphery and was calculated as follows [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref025">25</xref>]. For each sound clip, the amplitude spectrum was measured using 10-ms Hanning windows, overlapping by 5ms. The number of frequency channels was then reduced by weighted summation using overlapping triangular windows to provide 34 log-spaced channels (500 Hz to 22,627 Hz center frequencies, adapted from melbank.m (<ext-link ext-link-type="uri" xlink:href="http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html" xlink:type="simple">http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html</ext-link>)). Next, a log function was applied to the value in each time-frequency bin, and any values below a low threshold was set to the threshold. The cochleagram was normalized to zero mean and unit variance over the training set (see Cross-validation and model testing). The input <italic>x</italic><sub><italic>fq</italic></sub>(<italic>t</italic>) at time <italic>t</italic> was the chunk of cochleagram preceding <italic>t</italic>, given by <italic>x</italic><sub><italic>fq</italic></sub>(<italic>t</italic>) = <italic>K</italic><sub><italic>f</italic></sub>(<italic>t</italic>−<italic>q</italic>+1), where <italic>f</italic> is the frequency channel and q is the latency and <italic>K</italic><sub><italic>f</italic></sub>(<italic>t</italic>) is the cochleagram.</p>
</sec>
<sec id="sec008">
<title>The LN model</title>
<p>The two stage LN model consists of a linear model followed by a sigmoid output nonlinearity.</p>
<p><italic>Linear stage</italic>:
<disp-formula id="pcbi.1006618.e001">
<alternatives>
<graphic id="pcbi.1006618.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where <italic>a(t)</italic> is the model neuron's activation, <italic>w</italic><sub><italic>fq</italic></sub> is the input weight and <italic>b</italic> is the baseline activation. Both <italic>w</italic> and <italic>b</italic> are free parameters of the model and were estimated by regressing neural response <italic>y(t)</italic> against input <italic>x</italic>(<italic>t</italic>) using glmnet [<xref ref-type="bibr" rid="pcbi.1006618.ref026">26</xref>]. To overcome overfitting, the weights were regularized using an L1-norm (LASSO regularization). Thus <italic>a(t)</italic> can be seen as the best linear estimate of <italic>y</italic>(<italic>t</italic>) from <italic>x</italic>(<italic>t</italic>). The regularization hyperparameter <italic>λ</italic> controlled the strength of the regularization. To select <italic>λ</italic>, the model was subjected to k-fold cross-validation (see Cross-validation and model testing).</p>
<p><italic>Nonlinear stage</italic>: The nonlinear stage of the model was a parameterized sigmoid nonlinearity:
<disp-formula id="pcbi.1006618.e002">
<alternatives>
<graphic id="pcbi.1006618.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mi>ν</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula></p>
<p>The four parameters <italic>ρ</italic><sub><italic>i</italic></sub> of the function were fitted by minimizing the squared error between <italic>v(t)</italic> and <italic>y(t)</italic>.</p>
</sec>
<sec id="sec009">
<title>The network receptive field (NRF) model</title>
<p>The NRF model is an artificial neural network with a single hidden layer of 20 hidden units (HU) which converge onto an output unit (OU). Each unit of the model is similar to a single LN model. The activation of the <italic>j</italic>-th HU, <italic>a</italic><sub><italic>j</italic></sub>(<italic>t</italic>) is,
<disp-formula id="pcbi.1006618.e003">
<alternatives>
<graphic id="pcbi.1006618.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>The output of the <italic>j</italic>-th HU, <italic>v</italic><sub><italic>j</italic></sub>(<italic>t</italic>) is,
<disp-formula id="pcbi.1006618.e004">
<alternatives>
<graphic id="pcbi.1006618.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where g(<italic>a</italic><sub><italic>j</italic></sub>(<italic>t</italic>)) is a sigmoid non-linear activation function, 1/(1+exp(−<italic>a</italic><sub><italic>j</italic></sub>(<italic>t</italic>))). The HUs feed these outputs to the OU. The activation function of the OU <italic>a</italic><sub><italic>o</italic></sub>(<italic>t</italic>) is,
<disp-formula id="pcbi.1006618.e005">
<alternatives>
<graphic id="pcbi.1006618.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula></p>
<p>The output <italic>v</italic><sub><italic>o</italic></sub>(<italic>t</italic>) of the OU is,
<disp-formula id="pcbi.1006618.e006">
<alternatives>
<graphic id="pcbi.1006618.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
which is the model’s estimate of the neuron’s response at time <italic>t</italic>.</p>
</sec>
<sec id="sec010">
<title>The dynamic network (DNet) model</title>
<p>A neuron’s response depends on the activity of its presynaptic neurons through the total synaptic current they evoke. However, a neuron’s membrane potential, and consequently its firing rate, is not an instantaneous function of this current. Due to the capacitance and resistance of the neural cell membrane, the membrane potential and hence the firing rate is approximately a low-pass filtered version of the synaptic current. A common simple dynamic model of neurons that captures this phenomenon is the differential equation (<xref ref-type="disp-formula" rid="pcbi.1006618.e007">Eq 7</xref>) known as the firing-rate equation [<xref ref-type="bibr" rid="pcbi.1006618.ref022">22</xref>].</p>
<disp-formula id="pcbi.1006618.e007">
<alternatives>
<graphic id="pcbi.1006618.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:msup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">cont</mml:mi></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">cont</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">cont</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
<p>Here, <italic>τ</italic><sup>cont</sup> is the membrane time constant, <italic>v</italic> is post-synaptic firing rate, <italic>I</italic>(<italic>t</italic><sup>cont</sup>) is the synaptic current at time <italic>t</italic><sup>cont</sup>,F() is a nonlinear function that relates synaptic current to the post-synaptic firing rate, and <italic>t</italic><sup>cont</sup> is time. Here we use <italic>t</italic><sup>cont</sup> and <italic>τ</italic><sup>cont</sup> with the superscript ‘cont’ to denote that for this equation these variables operate in continuous time rather than discrete time. <italic>τ</italic><sup>cont</sup> determines how rapidly firing rate approaches steady state for a constant synaptic current, and can be related to the membrane time constant [<xref ref-type="bibr" rid="pcbi.1006618.ref022">22</xref>]. Although the relationship is not strict, we shall call <italic>τ</italic><sup>cont</sup> the membrane time constant. This is equivalent to convolving the instantaneous output of function F() with an exponential decay impulse response.</p>
<p><xref ref-type="disp-formula" rid="pcbi.1006618.e007">Eq 7</xref> can be discretized by the Euler method, where <italic>c</italic> = 1 time-bin = 5 ms. We redefine <italic>v</italic> and <italic>I</italic> to depend on time-bin number, <italic>t</italic>, rather than continuous time (<italic>t</italic> = <italic>t<sup>cont</sup> / c</italic>, where <italic>t</italic> is an integer). Hence, the discretized form of the firing rate equation is:
<disp-formula id="pcbi.1006618.e008">
<alternatives>
<graphic id="pcbi.1006618.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mi>v</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>v</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">F</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula></p>
<p>The dynamic network model incorporates units that behave like <xref ref-type="disp-formula" rid="pcbi.1006618.e008">Eq 8</xref>. In recognition that the characteristics of units in our model may not exactly correspond to biophysical properties of neurons described by the firing rate equation, and to be consistent with the NRF model, we replace F() with g() and the current <italic>I</italic>(<italic>t</italic>−1) with activation <italic>a</italic>(<italic>t</italic>).</p>
<p>As a result, activation <italic>a</italic><sub><italic>j</italic></sub>(<italic>t</italic>) of the <italic>j</italic>-th HU of the DNet model is the same as the NRF model,
<disp-formula id="pcbi.1006618.e009">
<alternatives>
<graphic id="pcbi.1006618.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula></p>
<p>However, the output <italic>v</italic><sub><italic>j</italic></sub>(<italic>t</italic>) is different from that of the NRF model, incorporating the discretized firing-rate equation.</p>
<disp-formula id="pcbi.1006618.e010">
<alternatives>
<graphic id="pcbi.1006618.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula>
<p>Similarly, the activation <italic>a</italic><sub><italic>o</italic></sub>(<italic>t</italic>) of the OU is,
<disp-formula id="pcbi.1006618.e011">
<alternatives>
<graphic id="pcbi.1006618.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula>
and the output v<sub><italic>o</italic></sub>(<italic>t</italic>) of the OU is,
<disp-formula id="pcbi.1006618.e012">
<alternatives>
<graphic id="pcbi.1006618.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:msub><mml:mrow><mml:mi mathvariant="normal">v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula></p>
<p>Here, <italic>τ</italic><sub><italic>j</italic></sub> and <italic>τ</italic><sub><italic>o</italic></sub> are the membrane time constants of <italic>j</italic>-th hidden unit and output unit respectively.</p>
</sec>
<sec id="sec011">
<title>The sDNet model</title>
<p>The firing-rate equation (<xref ref-type="disp-formula" rid="pcbi.1006618.e007">Eq 7</xref>) assumes that the time constant that governs the relationship between the current and the firing rate is substantially larger than the time constant that governs the decay of post-synaptic potentials. However, if we assume the reverse, i.e., that the synaptic time constant is substantially larger, a different simple model of the relationship between the firing rate and the current becomes appropriate [<xref ref-type="bibr" rid="pcbi.1006618.ref022">22</xref>]. This model is given by:
<disp-formula id="pcbi.1006618.e013">
<alternatives>
<graphic id="pcbi.1006618.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:msubsup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">cont</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">cont</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mi>z</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mi mathvariant="normal">cont</mml:mi></mml:msup><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(13)</label>
</disp-formula>
<disp-formula id="pcbi.1006618.e014">
<alternatives>
<graphic id="pcbi.1006618.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mo>(</mml:mo><mml:mi>I</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(14)</label>
</disp-formula></p>
<p>Here, <italic>I</italic> is synaptic current and <italic>v</italic> is post-synaptic firing rate, <italic>z</italic>(<italic>t</italic><sup>cont</sup>) is the immediate influence of the presynaptic spikes on the synaptic current, F() is the nonlinear function of synaptic current to post-synaptic firing rate, <inline-formula id="pcbi.1006618.e015"><alternatives><graphic id="pcbi.1006618.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:msubsup><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">cont</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is synaptic time constant, and <italic>t</italic><sup>cont</sup> is time.</p>
<p>Similar discretization, like that used for the DNet model (see above), can be used for <xref ref-type="disp-formula" rid="pcbi.1006618.e013">Eq 13</xref> to use this for the units of a neural network model. Again, replacing the synaptic current, <italic>I</italic>, with the activation a, the activation of hidden units of the sDNet model can be modelled as the following:
<disp-formula id="pcbi.1006618.e016">
<alternatives>
<graphic id="pcbi.1006618.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mi>Q</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(15)</label>
</disp-formula></p>
<p>And the hidden unit output, replacing F() with g(), is given by:
<disp-formula id="pcbi.1006618.e017">
<alternatives>
<graphic id="pcbi.1006618.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(16)</label>
</disp-formula></p>
<p>Hence, in the sDNet model, the activation of each HU, rather than the output of the nonlinearity, is convolved with an exponential decay impulse response.</p>
<p>Similarly, for the output units,
<disp-formula id="pcbi.1006618.e018">
<alternatives>
<graphic id="pcbi.1006618.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e018" xlink:type="simple"/>
<mml:math display="block" id="M18">
<mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(17)</label>
</disp-formula></p>
<p>And the output,
<disp-formula id="pcbi.1006618.e019">
<alternatives>
<graphic id="pcbi.1006618.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e019" xlink:type="simple"/>
<mml:math display="block" id="M19">
<mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
<label>(18)</label>
</disp-formula></p>
<p>Here, <italic>τ</italic><sub><italic>sj</italic></sub> and <italic>τ</italic><sub><italic>so</italic></sub> are the synaptic time constants of <italic>j</italic>-th hidden unit and output unit respectively.</p>
</sec>
<sec id="sec012">
<title>Objective function of the NRF and DNet models</title>
<p>The free parameters <italic>w</italic><sub><italic>jfq</italic></sub>, <italic>w</italic><sub><italic>j</italic></sub>, <italic>b</italic><sub><italic>j</italic></sub>, and <italic>b</italic><sub><italic>o</italic></sub> (also <italic>τ</italic><sub><italic>j</italic></sub> and <italic>τ</italic><sub><italic>o</italic></sub> for the DNet and <italic>τ</italic><sub><italic>sj</italic></sub> and <italic>τ</italic><sub><italic>so</italic></sub> for the sDNet) were optimized by minimizing the squared error between <italic>v</italic><sub><italic>o</italic></sub>(<italic>t</italic>) and <italic>y(t)</italic> subject to L1-regularization of the weights. Thus, the objective function is given by,
<disp-formula id="pcbi.1006618.e020">
<alternatives>
<graphic id="pcbi.1006618.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e020" xlink:type="simple"/>
<mml:math display="block" id="M20">
<mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>N</mml:mi><mml:mi>T</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(19)</label>
</disp-formula></p>
<p>Here, <italic>n</italic> is included to indicate clip number, but was left out of other equations for simplicity. <italic>N</italic> is the number of clips used in training.</p>
</sec>
<sec id="sec013">
<title>Parameter estimation</title>
<p>All models except for the LN model are fitted by minimizing the objective function with respect to the free parameters using the sum-of-function optimizer algorithm [<xref ref-type="bibr" rid="pcbi.1006618.ref027">27</xref>]. In using this algorithm, we take one clip to be one minibatch. The optimization algorithm requires calculation of the error gradients in respect to each of the parameters. For the NRF model, error gradients are calculated using standard chain rule (backpropagation). For the dynamic models, the process is similar (see below).</p>
<p>For the network models, before training, the weights were initialized by modified Glorot initialization from a uniform distribution ranging from—<inline-formula id="pcbi.1006618.e021"><alternatives><graphic id="pcbi.1006618.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mi>f</mml:mi><mml:mi>q</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> to + <inline-formula id="pcbi.1006618.e022"><alternatives><graphic id="pcbi.1006618.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mi>f</mml:mi><mml:mi>q</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, where <italic>fq</italic> is the number of input weights to a HU and <italic>l</italic> = 1 is the number of output weights from a HU. The biases were initialized similarly [<xref ref-type="bibr" rid="pcbi.1006618.ref028">28</xref>].</p>
<p>For the DNet model, to prevent the <inline-formula id="pcbi.1006618.e023"><alternatives><graphic id="pcbi.1006618.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> term running into mathematical error (when <italic>τ</italic> = 0), we substitute <inline-formula id="pcbi.1006618.e024"><alternatives><graphic id="pcbi.1006618.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> with <inline-formula id="pcbi.1006618.e025"><alternatives><graphic id="pcbi.1006618.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mi mathvariant="normal">h</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>. Parameters, <italic>d</italic><sub><italic>j</italic></sub> and <italic>d</italic><sub><italic>o</italic></sub> (for hidden and output units) were each independently initialized with the square root of a random variable from an exponential distribution with a mean of 1. Similar, substitution is used for the sDNet model.</p>
</sec>
<sec id="sec014">
<title>Error-gradient calculation for the DNet model</title>
<p>To estimate the parameters, the gradients of the error with respect to various parameters are calculated using a method similar to the one used for real time recurrent learning [<xref ref-type="bibr" rid="pcbi.1006618.ref029">29</xref>].</p>
<p>Substituting <inline-formula id="pcbi.1006618.e026"><alternatives><graphic id="pcbi.1006618.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>τ</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula>, the dynamic equations for HUs (<xref ref-type="disp-formula" rid="pcbi.1006618.e010">Eq 10</xref>) and OU (<xref ref-type="disp-formula" rid="pcbi.1006618.e012">Eq 12</xref>) of the DNet model become respectively:
<disp-formula id="pcbi.1006618.e027">
<alternatives>
<graphic id="pcbi.1006618.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e027" xlink:type="simple"/>
<mml:math display="block" id="M27">
<mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(20)</label>
</disp-formula>
<disp-formula id="pcbi.1006618.e028">
<alternatives>
<graphic id="pcbi.1006618.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e028" xlink:type="simple"/>
<mml:math display="block" id="M28">
<mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(21)</label>
</disp-formula></p>
<p>Using the chain rule, the gradient of the error term, E(<italic>t</italic>) at time <italic>t</italic> in respect to the weights of the output layer, <italic>w</italic><sub><italic>j</italic></sub>,
<disp-formula id="pcbi.1006618.e029">
<alternatives>
<graphic id="pcbi.1006618.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e029" xlink:type="simple"/>
<mml:math display="block" id="M29">
<mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi mathvariant="normal">E</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi mathvariant="normal">E</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(22)</label>
</disp-formula>
<disp-formula id="pcbi.1006618.e030">
<alternatives>
<graphic id="pcbi.1006618.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e030" xlink:type="simple"/>
<mml:math display="block" id="M30">
<mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mo>′</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi>ν</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo>
</mml:math>
</alternatives>
<label>(23)</label>
</disp-formula></p>
<p>The prime denotes the derivative of the function. Similarly, the gradient of the error term, E(<italic>t</italic>) in respect to the bias of the output layer, <italic>b</italic><sub><italic>o</italic></sub>,
<disp-formula id="pcbi.1006618.e031">
<alternatives>
<graphic id="pcbi.1006618.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e031" xlink:type="simple"/>
<mml:math display="block" id="M31">
<mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi mathvariant="normal">E</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi mathvariant="normal">E</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(24)</label>
</disp-formula>
<disp-formula id="pcbi.1006618.e032">
<alternatives>
<graphic id="pcbi.1006618.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e032" xlink:type="simple"/>
<mml:math display="block" id="M32">
<mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mo>′</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(25)</label>
</disp-formula></p>
<p>Finally, the gradient of the error term, E(<italic>t</italic>) with respect to the parameter, <italic>d</italic><sub><italic>o</italic></sub>,
<disp-formula id="pcbi.1006618.e033">
<alternatives>
<graphic id="pcbi.1006618.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e033" xlink:type="simple"/>
<mml:math display="block" id="M33">
<mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>E</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>E</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(26)</label>
</disp-formula>
<disp-formula id="pcbi.1006618.e034">
<alternatives>
<graphic id="pcbi.1006618.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e034" xlink:type="simple"/>
<mml:math display="block" id="M34">
<mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo>′</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi mathvariant="normal">h</mml:mi><mml:mo>′</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="normal">g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(27)</label>
</disp-formula></p>
<p>Hence, the gradient is passed forward from the current time step to the next time step to be used in calculation of the gradient at that new time step. At <italic>t</italic> = 1, the values of <inline-formula id="pcbi.1006618.e035"><alternatives><graphic id="pcbi.1006618.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006618.e036"><alternatives><graphic id="pcbi.1006618.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> are undetermined. So, at time <italic>t</italic> = 1, the values of these terms are set to zero.</p>
<p>The gradients of the error term, E(<italic>t</italic>), with respect to the rest of the parameters of the DNet model and the sDNet model are obtained similarly.</p>
</sec>
<sec id="sec015">
<title>Cross-validation and model testing</title>
<p>From the data for the 20 sound stimuli, 4 were chosen as a test set which was not used during training and cross-validation. The cross-validation set (the remaining 16 stimuli) was used to fit the models using <italic>k</italic>-fold cross validation, where <italic>k</italic> = 8. The cross-validation set was randomly divided into a training set of 14 stimuli and a validation set of 2 stimuli. The model was trained on the training set for 18 different values of the hyperparameter λ. A log spaced range of lambda values was used, but with a somewhat lower density at the extremes. For the LN model, the exact values of λ used were: 1.00 x 10<sup>−1</sup>, 2.00 x 10<sup>−2</sup>, 1.17 x 10<sup>−2</sup>, 6.84 x 10<sup>−3</sup>, 4.00 x 10<sup>−3</sup>, 2.34 x 10<sup>−3</sup>, 1.37 x 10<sup>−3</sup>, 8.00 x 10<sup>−4</sup>, 4.68 x 10<sup>−4</sup>, 2.74 x 10<sup>−4</sup>, 1.60 x 10<sup>−4</sup>, 9.36 x 10<sup>−5</sup>, 5.41 x 10<sup>−5</sup>, 3.20 x 10<sup>−5</sup>, 6.40 x 10<sup>−6</sup>, 1.28 x 10<sup>−6</sup>, 2.56 x 10<sup>−7</sup>, and 5.12 x 10<sup>−8</sup>. For the rest of the models, the values of λ used were: 1.00 x 10<sup>−3</sup>, 2.00 x 10<sup>−4</sup>, 1.17 x 10<sup>−4</sup>, 6.84 x 10<sup>−5</sup>, 4.00 x 10<sup>−5</sup>, 2.34 x 10<sup>−5</sup>, 1.37 x 10<sup>−5</sup>, 8.00 x 10<sup>−6</sup>, 4.68 x 10<sup>−6</sup>, 2.74 x 10<sup>−6</sup>, 1.60 x 10<sup>−6</sup>, 9.36 x 10<sup>−7</sup>, 5.41 x 10<sup>−7</sup>, 3.20 x 10<sup>−7</sup>, 6.40 x 10<sup>−8</sup>, 1.28 x 10<sup>−8</sup>, 2.56 x 10<sup>−9</sup>, and 5.12 x 10<sup>−10</sup>. For each of the fitted models, neural responses were then predicted for the validation set, and the correlation coefficient between the actual neural responses and the prediction was measured. This process was repeated 8 times for different non-overlapping validation sets. The model was then retrained with the whole cross-validation set using the λ value that provided the highest mean correlation coefficient over all 8 folds. Next, the retrained network was used to predict the neural responses to the test set. All the correlation coefficients and normalized correlation coefficients shown are for this held out test set, and all the model parameters shown are for the retrained network.</p>
<p>To ensure that all models receive the same amount of training data, models with different latency spans of STRFs are provided with exactly the same durations of neural response. This was done by clipping the necessary number of time points from the beginning of the neural response data.</p>
</sec>
<sec id="sec016">
<title>Effective hidden units</title>
<p>The hidden layer of each of the networks contained 20 HUs, but because their weights were L1-regularized, they tended to develop substantive weights only if they explained aspects of the neural response that were not explained by any other units. As a result, many HUs developed weights close to zero, and thus the network models tended to have only a small number of effective HUs. The ‘effectiveness’ of each unit <italic>j</italic> was calculated [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>] as the variance over time of the unit’s weighted output <italic>w</italic><sub><italic>o</italic></sub><italic>v</italic><sub><italic>j</italic></sub>(<italic>t</italic>). Any HU with variance greater than 5% of the sum of the variances of all 20 HUs is considered effective.</p>
</sec>
<sec id="sec017">
<title>IE score</title>
<p>The IE score [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>] measures whether the degree to which a HU is excitatory or inhibitory, on a scale between -1 and 1. Most inhibitory is IE = -1, when all of the input weights are negative or zero, and the output weight is positive, or when all of the input weights are positive or zero and the output weight is negative. Most excitatory is IE = 1, when all of the input weights are positive or zero, and the output weight is positive, or when all of the input weights are negative or zero and the output weight is negative.</p>
<disp-formula id="pcbi.1006618.e037">
<alternatives>
<graphic id="pcbi.1006618.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006618.e037" xlink:type="simple"/>
<mml:math display="block" id="M37">
<mml:mi mathvariant="normal">IE</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">sign</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mi>f</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(28)</label>
</disp-formula>
</sec>
<sec id="sec018">
<title>Membrane time constant</title>
<p>Because the membrane time constant is modelled as 1+<italic>d</italic><sup>2</sup> and the duration of each time step is 5 ms, the value of membrane time constant in ms is 5 (1+<italic>d</italic><sup>2</sup>).</p>
</sec>
<sec id="sec019">
<title>Knocking out large time constants of the DNet model</title>
<p>After fitting a network model, HUs with time constant greater than the length of the STRF are selected. The output weights connecting these units to the output unit are then set to zero. As a result, HUs with large time constants become inactive during the test process. Everything else in the model remained unchanged.</p>
</sec>
</sec>
<sec id="sec020" sec-type="results">
<title>Results</title>
<p>The neural response dataset used in this study was recorded from the primary auditory cortical areas, A1 and AAF, of anesthetized ferrets in response to a diverse selection of natural sounds (20 stimuli of 5 s duration), including speech, animal vocalizations and environmental sounds [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref025">25</xref>]. In total, 73 single-unit neural recordings showed sensitivity to the sound stimuli (see <xref ref-type="sec" rid="sec002">Methods</xref>), as measured by their noise ratios, and these were analysed in this study.</p>
<p>To probe the computations underlying stimulus encoding, models were fitted to estimate the neural firing rate (averaged over stimulus repeats) of each neuron as a function of the preceding sound stimulation (<xref ref-type="fig" rid="pcbi.1006618.g001">Fig 1</xref>). First, for all models, the sound stimuli were pre-processed to generate a spectrogram-like representation (a cochleagram) that approximates the processing that occurs in the cochlea and auditory nerve. Second, using responses to 16 of the natural stimuli, a parameterized model was trained to estimate the firing rate as a function of the preceding cochleagram. After parameters of the models were fitted to the data, their fit quality was tested on a held-out test set composed of the responses to the remaining 4 natural stimuli.</p>
<fig id="pcbi.1006618.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006618.g001</object-id>
<label>Fig 1</label>
<caption>
<title>The models have two-stages.</title>
<p>A. The first stage involves pre-processing that mimics the auditory periphery, where the sound waveform is converted into a time-frequency representation (cochleagram). B. The output of the first stage is then used as input to a model that is fitted to the neural responses of auditory cortical neurons. C. After parameter estimation, the model was used to predict neural responses to arbitrary stimuli.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006618.g001" xlink:type="simple"/>
</fig>
<sec id="sec021">
<title>Using standard models, access to 200 ms of recent stimulus history is needed to achieve best prediction</title>
<p>For each neuron, an LN model was fitted to estimate its firing rate as a function of the preceding cochleagram. The LN model consists of an STRF, followed by a sigmoid nonlinearity (<xref ref-type="fig" rid="pcbi.1006618.g002">Fig 2A</xref>). As mentioned in the Methods, the STRF is the weighted sum of the cochleagram over frequency components at a span of latencies. The effect of different spans of latencies (lengths) of the STRF was investigated. For the held-out test set, and averaged over the 73 neurons, the mean normalized correlation coefficient, mean CC<sub>norm</sub> [<xref ref-type="bibr" rid="pcbi.1006618.ref030">30</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref031">31</xref>], between the actual neural responses and the prediction of LN models with 25, 50, 100, 200, and 400 ms long STRFs are respectively 0.51, 0.64, 0.69, 0.71, and 0.71 (<xref ref-type="fig" rid="pcbi.1006618.g002">Fig 2B</xref>), where 1.0 is the maximum achievable prediction given the estimated neuronal noise and 0.0 indicates that there is no correlation between actual and predicted neural responses. The means of non-normalized Pearson correlation coefficients (CC) are 0.40, 0.50, 0.54, 0.55, and 0.55 respectively. <xref ref-type="fig" rid="pcbi.1006618.g002">Fig 2C</xref> shows STRFs of some example neurons estimated by the LN model.</p>
<fig id="pcbi.1006618.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006618.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Prediction of neural responses by the linear non-linear (LN) model.</title>
<p>A. The LN model, which consists of a spectrotemporal receptive field (STRF) followed by a sigmoid nonlinearity. B. Normalized correlation coefficients (CC<sub>norm</sub>) between neural responses and the prediction of the LN model with different latency spans. Each black dot represents a neuron, the curve indicates the mean over 73 neurons and error bars indicate standard error of the mean. C. STRFs of some example neurons, for LN models with different latency spans. Red, excitatory fields, blue, inhibitory. Excitatory and inhibitory fields extend up to 100 ms in most cases and up to 200 ms in some cases.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006618.g002" xlink:type="simple"/>
</fig>
<p>A network receptive field model (the NRF model) was also developed and fitted to each neuron. This model consisted of the weighted sum of multiple LN-like units. This model is the same as a previously published version [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>], except that it uses sigmoid nonlinearities instead of scaled tanh non-linearities. A sigmoid non-linearity was used to be consistent with the dynamic network model that we will come to, which requires non-negative outputs and hence also uses sigmoid non-linearities. The NRF model we use here is essentially an artificial neural network with a single hidden layer, using a sigmoid non-linearity in its hidden units and its single output unit (<xref ref-type="fig" rid="pcbi.1006618.g003">Fig 3A</xref>). The NRF model makes use of multiple component STRFs, which allows modelling of neuronal sensitivity to non-linear interactions of multiple features [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>]. STRFs of at least 400 ms are needed for best performance in predicting neural responses (<xref ref-type="fig" rid="pcbi.1006618.g003">Fig 3B</xref>). For the test set, the mean CC<sub>norm</sub> between neural responses and the model predictions made by NRF models with 25, 50, 100, 200 and 400 ms long component STRFs are 0.51, 0.64, 0.70, 0.72 and 0.73, respectively (mean CC 0.40, 0.50, 0.54, 0.55 and 0.56, respectively). The NRF model predicts the neural responses equal to or better than the LN model over all durations examined, although by a more modest amount than seen in an earlier study [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>]. This may be because the NRF model in this study uses a sigmoid rather than tanh nonlinearity, or because the earlier study [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>] used a different way of selecting the test set. <xref ref-type="fig" rid="pcbi.1006618.g003">Fig 3C</xref> shows the input weights (analogous to STRFs) for the ‘effective’ HUs (see <xref ref-type="sec" rid="sec002">Methods</xref>) of the model-fit for one example neuron, obtained using the NRF model. <xref ref-type="fig" rid="pcbi.1006618.g003">Fig 3D</xref> and <xref ref-type="fig" rid="pcbi.1006618.g003">Fig 3E</xref> show the ‘effectiveness’ (see <xref ref-type="sec" rid="sec002">Methods</xref>) and IE score (see <xref ref-type="sec" rid="sec002">Methods</xref>) of the units shown in <xref ref-type="fig" rid="pcbi.1006618.g003">Fig 3C</xref>.</p>
<fig id="pcbi.1006618.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006618.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Prediction of neural responses by the network receptive field (NRF) model.</title>
<p>A. The NRF model, which involves a weighted sum of multiple LN-model like units, each with an STRF. B. Normalized correlation coefficients (CC<sub>norm</sub>) between neural responses and the prediction of the NRF model with different latency spans. Each black dot represents a neuron, the curve indicates the mean over 73 neurons and error bars indicate standard error of the mean. C. Component STRFs of an example neuron (Neuron #1). Each column represents an NRF model with different latency spans. D. ‘Effectiveness’ (see <xref ref-type="sec" rid="sec002">Methods</xref>) and E. IE score (see <xref ref-type="sec" rid="sec002">Methods</xref>) of the components STRFs shown in panel C.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006618.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec022">
<title>The DNet model can characterize neural responses using very short duration STRFs</title>
<p>Although both the LN and NRF models can capture dependence on stimulus history using a span of input latencies extending up to at least 200 ms, there is little biological evidence for such a wide span of latencies in the auditory thalamic neurons that feed to auditory cortex (see <xref ref-type="sec" rid="sec001">Introduction</xref>). With the aim of better understanding the biological underpinnings of stimulus history dependence in auditory cortical responses, a model with a dynamic aspect was developed that integrates the output of its component units over time in a manner similar to those of real neurons (see <xref ref-type="sec" rid="sec002">Methods</xref>). Each unit in the DNet model includes exponentially-decaying response integration, motivated by the integrative properties of real neuronal membranes (<xref ref-type="fig" rid="pcbi.1006618.g004">Fig 4A</xref>). This model is in essence the NRF model but with dynamic units, each modelled by the dynamic firing-rate differential equation (<xref ref-type="disp-formula" rid="pcbi.1006618.e007">Eq 7</xref>) [<xref ref-type="bibr" rid="pcbi.1006618.ref022">22</xref>]. That is, each unit of the model applies an exponentially decaying impulse response to the output of their non-linear activation function. Each unit’s decay rate is governed by its individually fitted time constant, <italic>τ</italic> (see <xref ref-type="sec" rid="sec002">Methods</xref>).</p>
<fig id="pcbi.1006618.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006618.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Prediction of neural responses using a dynamic network (DNet) model.</title>
<p>A. The DNet model. The cochleagram is passed through a set of linear-nonlinear filters, whose response is then integrated over time using an exponentially-decaying impulse response to produce the hidden units’ outputs. A weighted sum of these outputs is passed through a similar output unit to make a prediction of the neural response. B. CC<sub>norm</sub> for the DNet model with different latency spans. Each black dot is a neuron, the curve indicates the mean over 73 neurons and error bars are standard error of the mean. C. The input weights (STRFs) for the ‘effective’ hidden units (see <xref ref-type="sec" rid="sec002">Methods</xref>) of 8 example neurons (each column is a different neuron) for the DNet model. D. ‘Effectiveness’ (see <xref ref-type="sec" rid="sec002">Methods</xref>) and E. IE score (see <xref ref-type="sec" rid="sec002">Methods</xref>) of the hidden units shown in panel C.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006618.g004" xlink:type="simple"/>
</fig>
<p>We found that the mean CC<sub>norm</sub> between the actual neural responses and the predictions of the DNet model with 25, 50, 100, 200 and 400 ms STRFs are respectively 0.71, 0.71, 0.70, 0.68 and 0.68 (<xref ref-type="fig" rid="pcbi.1006618.g004">Fig 4B</xref>) (mean CC 0.55, 0.55, 0.54, 0.52 and 0.52, respectively). Because the 25-ms model performs the best and the biological range of latencies are typically less than 30 ms[<xref ref-type="bibr" rid="pcbi.1006618.ref032">32</xref>], we focused on the 25-ms DNet model for further analysis. <xref ref-type="fig" rid="pcbi.1006618.g004">Fig 4C</xref> shows the input weights (analogous to STRFs) for the ‘effective’ hidden units (see <xref ref-type="sec" rid="sec002">Methods</xref>) of the model fits for 8 example neurons, using a DNet model with 25-ms long STRFs. <xref ref-type="fig" rid="pcbi.1006618.g004">Fig 4D and 4E</xref> show the ‘effectiveness’ (see <xref ref-type="sec" rid="sec002">Methods</xref>) and IE score (see <xref ref-type="sec" rid="sec002">Methods</xref>) of the units shown in <xref ref-type="fig" rid="pcbi.1006618.g004">Fig 4C</xref>.</p>
<p>The 25-ms DNet model out performs the DNet with longer (200 ms and 400 ms) STRFs, as measured by prediction of neural responses on a held-out test set averaged over all 73 neurons (<xref ref-type="fig" rid="pcbi.1006618.g005">Fig 5A</xref>). It also achieves performance similar to the best performing LN model, but performs a little worse than the best performing NRF model (<xref ref-type="fig" rid="pcbi.1006618.g005">Fig 5A</xref>). This can be seen qualitatively in the time course of the prediction for an example neuron and stimulus in <xref ref-type="fig" rid="pcbi.1006618.g005">Fig 5B</xref>. A neuron by neuron comparison shows that this result is consistent for most neurons (<xref ref-type="fig" rid="pcbi.1006618.g005">Fig 5C and 5D</xref>). Also, the 25-ms LN and NRF models are outperformed by a large margin by the 25-ms DNet model (<xref ref-type="fig" rid="pcbi.1006618.g005">Fig 5A</xref>). A neuron by neuron comparison shows that this result is also consistent for almost all neurons (<xref ref-type="fig" rid="pcbi.1006618.g005">Fig 5E and 5F</xref>).</p>
<fig id="pcbi.1006618.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006618.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Comparison of the performance of the DNet model with other models.</title>
<p>A. Mean CC<sub>norm</sub> of linear-nonlinear (LN), network receptive field (NRF) and dynamic network (DNet) models. B. Time course of predictions by best performing versions of each of the LN, NRF and DNet models, compared with real neural responses for an example neuron and stimulus. C. Neuron by neuron comparison of CC<sub>norm</sub> values between the 25-ms DNet model and 200-ms LN model. Each red dot is a neuron. D. Neuron by neuron comparison of CC<sub>norm</sub> values between the 25-ms DNet model and 400-ms NRF model. E. Neuron by neuron comparison of CC<sub>norm</sub> values between the 25-ms DNet model and 25-ms LN model. F. Neuron by neuron comparison of CC<sub>norm</sub> values between the 25-ms DNet model and 25-ms NRF model.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006618.g005" xlink:type="simple"/>
</fig>
<p>Note that the DNet model is equivalent to the NRF model when the discretized time constant for every DNet model unit is at the smallest possible value (<italic>τ</italic> = 1, <italic>d</italic> = 0). Hence, because all possible NRF models are a subset of all possible DNet models, the DNet should in theory always equal or outperform the NRF model. The fact that this is not the case suggests that, at least in some cases, the very best fits are not being found for the DNet model, perhaps as a consequence of some overfitting. That the DNet model performs worse for large latency spans, where there are more variables, is again probably due to challenges in fitting the DNet model, likely due to some overfitting to the training set.</p>
</sec>
<sec id="sec023">
<title>Network structure and response integration are both required for an effective DNet</title>
<p>To understand how much of an effect HUs of the DNet model with long time constants have on the model’s predictions, the fitted model was modified by ‘knocking out’ (see <xref ref-type="sec" rid="sec002">Methods</xref>) HUs with time constants longer than the duration of their STRFs. This was achieved by setting the output weights of those units to zero, while keeping all other parameters intact. We found that the 25-ms DNet model is the DNet whose CC<sub>norm</sub> is most reduced by this alteration (<xref ref-type="fig" rid="pcbi.1006618.g006">Fig 6A</xref>).</p>
<fig id="pcbi.1006618.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006618.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Multiple time constants in a network architecture are required to capture the dependence of neural response on stimulus history.</title>
<p>A. DNet model performance when large time constants are knocked out. B. Performance of the single-unit dynamic model. C. Number of effective hidden units (HUs) used to model each of the 73 neurons using the DNet model. D. Distribution of time constants of HUs of the DNet model. E. Distribution of time constants of the output units (OUs) of the DNet model. F. Relationship between time constant and HU effectiveness for the DNet model.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006618.g006" xlink:type="simple"/>
</fig>
<p>A single-unit dynamic model was also developed to examine the effect of a time constant in an LN-like single STRF model. Prediction performance of this model was found to be worse than the LN model (<xref ref-type="fig" rid="pcbi.1006618.g006">Fig 6B</xref>). This indicates that both long time constants and a network architecture are needed for the 25-ms DNet model to achieve prediction performance similar to that of standard models.</p>
<p>Although the DNet model had 20 hidden units, the L1 regularization eliminated unnecessary units. Hence there were fewer effective HUs, and for the 25-ms DNet model this number was found to be between 2 and 8 (<xref ref-type="fig" rid="pcbi.1006618.g006">Fig 6C</xref>). We defined an effective HU as one whose effectiveness (variance of weighted output, see <xref ref-type="sec" rid="sec002">Methods</xref>) exceeded a certain threshold.</p>
<p>In the 25-ms DNet model, the time constants of the effective HUs ranged between 5 and 475 ms, often far greater than the duration of the STRFs (<xref ref-type="fig" rid="pcbi.1006618.g006">Fig 6D</xref>). The time constants of the OUs of the DNet model ranged from 5 to 130 ms (<xref ref-type="fig" rid="pcbi.1006618.g006">Fig 6E</xref>). To investigate whether long time constants are associated with effective HUs, for each neuron HUs were ranked in order of effectiveness and the mean of the time constants of all HUs in the same rank (over all neurons) were calculated. This showed that high-ranked HUs tend to have long time constants (<xref ref-type="fig" rid="pcbi.1006618.g006">Fig 6F</xref>).</p>
</sec>
<sec id="sec024">
<title>Hidden units with long time constants tend to be more inhibitory</title>
<p>To test whether a relationship exists between the time constant and unit’s inhibitory/excitatory nature, we classified the effective HUs of the 25-ms DNet model into excitatory or inhibitory using an IE score (see <xref ref-type="sec" rid="sec002">Methods</xref>). If the output weight is positive, an IE score of 1 means a unit with entirely excitatory influence and an IE score of -1 means a unit with entirely inhibitory influence. We found that almost all units having large time constants are inhibitory in nature (<xref ref-type="fig" rid="pcbi.1006618.g007">Fig 7</xref>).</p>
<fig id="pcbi.1006618.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006618.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Relationship between inhibitory/excitatory (IE) score and time constant.</title>
<p>Almost all the HUs of the DNet model with time constants greater than the duration of the STRFs (units right of the vertical dotted line, the duration of the 25 ms STRFs) are inhibitory in nature. IE score = inhibitory/excitatory score.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006618.g007" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec025">
<title>Membrane time constant versus synaptic time constant</title>
<p>In the DNet model, the integration governed by the time constant occurs after each unit’s nonlinearity. Although the time constant is conceived and implemented in a manner consistent with a membrane constant, within the network it may capture other dynamic neural phenomena such as synaptic time constants, forms of a channel-based or synaptic adaptation, or certain forms of network recurrency. An alternative network model places the integration just before the nonlinearity, which is more consistent with the time constant being synaptic in nature [<xref ref-type="bibr" rid="pcbi.1006618.ref022">22</xref>]. To investigate how much of the neural activity can be explained by such a model, we modified the DNet model to form the sDNet model (synaptic DNet model), with each unit governed by Eqs <xref ref-type="disp-formula" rid="pcbi.1006618.e013">13</xref> and <xref ref-type="disp-formula" rid="pcbi.1006618.e014">14</xref> [<xref ref-type="bibr" rid="pcbi.1006618.ref022">22</xref>].</p>
<p>The sDNet model achieves best performance in predicting neural responses when the duration of the STRFs is 200 ms (CC<sub>norm</sub> = 0.71) (<xref ref-type="fig" rid="pcbi.1006618.g008">Fig 8A</xref>). Although the sDNet with 25-ms STRFs predicts neural responses better (CC<sub>norm</sub> = 0.67) than the 25-ms LN model (CC<sub>norm</sub> = 0.51) and the 25-ms NRF model (CC<sub>norm</sub> = 0.51), it is worse than the 25-ms DNet model (CC<sub>norm</sub> = 0.71). This suggests that a large percentage of the variance of neural responses can be explained by a time constant before non-linearity, but that having a time constant after the non-linearity further improves prediction.</p>
<fig id="pcbi.1006618.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006618.g008</object-id>
<label>Fig 8</label>
<caption>
<title>A modified DNet model with synaptic time constants (sDNet model).</title>
<p>A. Performance of the sDNet model. B. Distribution of the values of time constants of hidden units (HUs) in the sDNet and DNet model C. Distribution of the values of time constants of the output units (OUs) of the sDNet and DNet model. D. Relationship between a HU’s time constant and its effectiveness for the sDNet model. E. Relationship between a HU’s inhibitory/excitatory (IE) score and its time constant for the sDNet model. Most of the HUs with time constants greater than the duration of the STRFs (units right of the vertical dotted line) are inhibitory in nature.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006618.g008" xlink:type="simple"/>
</fig>
<p>While the largest time constants of the effective HUs of the sDNet model can be as large as ~470 ms (<xref ref-type="fig" rid="pcbi.1006618.g008">Fig 8B</xref>), the distribution of time constants of output units have smaller values compared to the DNet model (<xref ref-type="fig" rid="pcbi.1006618.g008">Fig 8C</xref>). As with the DNet model the more effective HUs of the sDNet model tend to have longer time constants (<xref ref-type="fig" rid="pcbi.1006618.g008">Fig 8D</xref>) and units with long time constants tend to be inhibitory in nature (<xref ref-type="fig" rid="pcbi.1006618.g008">Fig 8E</xref>).</p>
</sec>
</sec>
<sec id="sec026" sec-type="conclusions">
<title>Discussion</title>
<p>We find that a model of primary auditory cortical neurons which incorporates exponentially-decaying memory processes–the DNet model–can capture some of the temporal aspects of the receptive field using very short (25 ms) component STRFs in a network. Standard models such as the LN model (and the NRF model) represent temporal receptive fields of neurons using delay lines whose latencies extend up to a few hundred milliseconds. Our results suggest that, beyond 25ms, the temporal receptive field can be modelled more succinctly by exponentially-decaying memory processes than by delay lines.</p>
<p>When auditory neurons are fitted using a standard LN model, the resulting STRFs often contain narrowband inhibitory fields that decay over approximately 200 ms. In contrast, we find that the STRFs of the DNet model have short inhibitory fields with long time constants. This suggests that these temporally extended inhibitory fields in STRFs may reflect neural mechanisms that can be approximated by exponentially-decaying memory processes.</p>
<p>Although they have not been described in the ferret, a few vMGB units do show onset latencies beyond a few tens of milliseconds: in cat latencies up to 70 ms have been described [<xref ref-type="bibr" rid="pcbi.1006618.ref019">19</xref>], in mouse up to 60 ms [<xref ref-type="bibr" rid="pcbi.1006618.ref020">20</xref>], and in marmoset up to 300 ms [<xref ref-type="bibr" rid="pcbi.1006618.ref021">21</xref>]. Areas other than vMGB that project to cortex may also include long latency responses. Hence, we cannot rule out the possibility that long-latency inputs at least partially explain the dependence of auditory cortical neurons on stimulus history–indeed it is likely that they do to some extent. However, these long-latency responses are relatively rare and we show that it is possible to explain a lot of the dependence of the neural response in primary auditory cortex by exponentially-decaying memory properties consistent with those properties intrinsic to neurons, such as membrane dynamics.</p>
<p>There are many biological mechanisms which may underlie exponentially-decaying memory processes. Neurons have various intrinsic dynamic integrative and adaptive characteristics originating from basic membrane dynamics, channel-based adaptation, post-synaptic potentials and short-term synaptic plasticity [<xref ref-type="bibr" rid="pcbi.1006618.ref022">22</xref>]. Recurrent network effects could also underlie such memory processes. In a previous study, a model with synaptic depression has been shown to partially capture the integration of stimulus history in A1 [<xref ref-type="bibr" rid="pcbi.1006618.ref033">33</xref>]. Here, we found that a better prediction of neural responses can be achieved by a model based on the integrative properties of neural membranes (the DNet model) than by the one based on the dynamics of synaptic potentials (the sDNet model). We note, however, that although the DNet model was developed with membrane dynamics in mind, aspects of all the above listed dynamic processes could be captured by the same exponentially-decaying memory in the DNet. These different processes are not exclusive of each other, and combinations of them may contribute to the effects we find.</p>
<p>The firing rate of A1 neurons has been demonstrated to depend on stimulus history up to ~4 s in the past [<xref ref-type="bibr" rid="pcbi.1006618.ref017">17</xref>]. This dependence cannot be fully captured by linear models such as STRFs (17). This indicates that there are some nonlinear dynamic processes that provide history dependence which cannot be captured either by a linear or LN models, nor by the DNet model. Perhaps this is because the DNet model has limited capacity to capture temporal dynamics that are not exponential in nature.</p>
<p>Much of the relationship between stimulus and neural responses results from neurons being embedded in a network structure and from the nonlinear properties of the units in this network. From the auditory periphery to the A1, there are numerous feedforward, feedback and lateral connections. Many previous models of auditory cortical neurons have not explicitly represented this network character. However, some recent models have incorporated non-linear contextual effects [<xref ref-type="bibr" rid="pcbi.1006618.ref014">14</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref025">25</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref034">34</xref>–<xref ref-type="bibr" rid="pcbi.1006618.ref036">36</xref>]. Furthermore, a few models do explicitly incorporate multiple receptive fields [<xref ref-type="bibr" rid="pcbi.1006618.ref037">37</xref>–<xref ref-type="bibr" rid="pcbi.1006618.ref043">43</xref>] or more extensive network structure [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>], which perform better in predicting neural responses of A1/AAF neurons than STRF models [<xref ref-type="bibr" rid="pcbi.1006618.ref023">23</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref037">37</xref>].</p>
<p>When modelling the dependence of neural responses on stimulus history, one approach is to include the history of a neuron’s spikes and those of its recorded neighbours in a generalized linear model (GLM) model [<xref ref-type="bibr" rid="pcbi.1006618.ref035">35</xref>,<xref ref-type="bibr" rid="pcbi.1006618.ref044">44</xref>]. However, unlike the DNet model, this approach does not model multi-layer network structure with hidden units that are inferred but not recorded. Modelling hidden network structure has been applied to the salamander retina, where in vitro responses to simple artificial stimuli are well predicted by a network model (LNFDSNF) with various non-linearities and response delays mimicking the retinal pathway [<xref ref-type="bibr" rid="pcbi.1006618.ref045">45</xref>]. The LNFDSNF model is particularly relevant to our study because it is a network model whose units have some memory of their past activity, though the form of this memory differs from that of the DNet model. The LNFDSNF model units have a feedback kernel that acts before the nonlinearity—in contrast, the DNet model units integrate their activity after the nonlinearity using an infinite impulse response that decays exponentially.</p>
<p>The succinct and biologically-motivated description of neural responses provided by the DNet model provides a basis from which to develop further models to account for the ~30% of the CC<sub>norm</sub> that remains to be explained. One variant of the model that can be developed involves a network with multiple hidden layers where the units each have just a single latency (i.e. each unit in the first hidden layer uses just a spectral receptive field at a single delay). This approach provides an opportunity to build deeper neural-network-like models with fewer parameters, potentially overcoming overfitting problems for deep network models of neural responses [<xref ref-type="bibr" rid="pcbi.1006618.ref046">46</xref>]. This network can provide a basis for new network models that incorporate a greater range of intrinsic dynamic processes more explicitly, for example modelling in each unit its basic membrane dynamics, synaptic depression and channel-based adaptation together, with different appropriate time constants in each case. Such models may show more predictive power.</p>
<p>Neurons are intrinsically dynamic systems, each with memory of past events. Furthermore, neurons are embedded in networks. We show that models incorporating both these characteristics can be valuable for explaining moment to moment <italic>in vivo</italic> responses of neurons in the auditory cortex. This is an arguably more biologically plausible way of capturing the history dependence of neural responses than a set of delay lines. In artificial neural networks, memory is usually implemented through recurrent connections between units. However, real biological neurons also have intrinsic memory processes with particular characteristics. Including such single-unit memory has potential advantages for explaining the <italic>in vivo</italic> responses of biological neurons and may also be useful in artificial neural networks. In summary, the dynamic network model we present here provides a biologically-plausible alternative encoding model to the classic LN model, as well as a basis for further development of encoding models with hidden units with diverse intrinsic dynamic processes.</p>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006618.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aertsen AMHJ</surname> <given-names>Johannesma PIM</given-names></name>, <name name-style="western"><surname>Hermes</surname> <given-names>DJ</given-names></name>. <article-title>Spectro-temporal receptive fields of auditory neurons in the grassfrog</article-title>. <source>Biol Cybern</source>. <year>1980</year>;<volume>38</volume>: <fpage>235</fpage>–<lpage>248</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aertsen AMHJ</surname> <given-names>Johannesma PIM</given-names></name>. <article-title>A comparison of the spectro-temporal sensitivity of auditory neurons to tonal and natural stimuli</article-title>. <source>Biol Cybern</source>. <year>1981</year>;<volume>42</volume>: <fpage>145</fpage>–<lpage>156</lpage>. <object-id pub-id-type="pmid">6976799</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>deCharms</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Blake</surname> <given-names>DT</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Optimizing sound features for cortical neurons</article-title>. <source>Science</source>. <year>1998</year>;<volume>280</volume>: <fpage>1439</fpage>–<lpage>1444</lpage>. <object-id pub-id-type="pmid">9603734</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Depireux</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Simon</surname> <given-names>JZ</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Robust spectrotemporal reverse correlation for the auditory system: optimizing stimulus design</article-title>. <source>J Comput Neurosci</source>. <year>2000</year>;<volume>9</volume>: <fpage>85</fpage>–<lpage>111</lpage>. <object-id pub-id-type="pmid">10946994</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Theunissen</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Sen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Doupe</surname> <given-names>AJ</given-names></name>. <article-title>Spectral-temporal receptive fields of nonlinear auditory neurons</article-title>. <source>J Neurosci</source>. <year>2000</year>;<volume>20</volume>: <fpage>2315</fpage>–<lpage>2331</lpage>. <object-id pub-id-type="pmid">10704507</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Linear processing of spatial cues in primary auditory cortex</article-title>. <source>Nature</source>. <year>2001</year>;<volume>414</volume>: <fpage>200</fpage>–<lpage>204</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/35102568" xlink:type="simple">10.1038/35102568</ext-link></comment> <object-id pub-id-type="pmid">11700557</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Escabí</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Nonlinear spectrotemporal sound analysis by neurons in the auditory midbrain</article-title>. <source>J Neurosci</source>. <year>2002</year>;<volume>22</volume>: <fpage>4114</fpage>–<lpage>4131</lpage>. <object-id pub-id-type="pmid">12019330</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Escabí</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Read</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Spectrotemporal receptive fields in the lemniscal auditory thalamus and cortex</article-title>. <source>J Neurophysiol</source>. <year>2002</year>;<volume>87</volume>: <fpage>516</fpage>–<lpage>527</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00395.2001" xlink:type="simple">10.1152/jn.00395.2001</ext-link></comment> <object-id pub-id-type="pmid">11784767</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Spectrotemporal structure of receptive fields in areas AI and AAF of mouse auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>2003</year>;<volume>90</volume>: <fpage>2660</fpage>–<lpage>2675</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00751.2002" xlink:type="simple">10.1152/jn.00751.2002</ext-link></comment> <object-id pub-id-type="pmid">12815016</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fritz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>D</given-names></name>. <article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title>. <source>Nat Neurosci</source>. <year>2003</year>;<volume>6</volume>: <fpage>1216</fpage>–<lpage>1223</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1141" xlink:type="simple">10.1038/nn1141</ext-link></comment> <object-id pub-id-type="pmid">14583754</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gill</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Woolley</surname> <given-names>SMN</given-names></name>, <name name-style="western"><surname>Fremouw</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>Sound representation methods for spectro-temporal receptive field estimation</article-title>. <source>J Comput Neurosci</source>. <year>2006</year>;<volume>21</volume>: <fpage>5</fpage>–<lpage>20</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10827-006-7059-4" xlink:type="simple">10.1007/s10827-006-7059-4</ext-link></comment> <object-id pub-id-type="pmid">16633939</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Christianson</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>. <article-title>The consequences of response nonlinearities for interpretation of spectrotemporal receptive fields</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>: <fpage>446</fpage>–<lpage>455</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1775-07.2007" xlink:type="simple">10.1523/JNEUROSCI.1775-07.2007</ext-link></comment> <object-id pub-id-type="pmid">18184787</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gourévitch</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Noreña</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Shaw</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Eggermont</surname> <given-names>JJ</given-names></name>. <article-title>Spectrotemporal receptive fields in anesthetized cat primary auditory cortex are context dependent</article-title>. <source>Cereb Cortex</source>. <year>2009</year>;<volume>19</volume>: <fpage>1448</fpage>–<lpage>1461</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhn184" xlink:type="simple">10.1093/cercor/bhn184</ext-link></comment> <object-id pub-id-type="pmid">18854580</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>David S</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Mesgarani</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Fritz</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Rapid synaptic depression explains nonlinear modulation of spectro-temporal tuning in primary auditory cortex by natural stimuli</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>: <fpage>3374</fpage>–<lpage>3386</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.5249-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5249-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19295144</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Machens</surname> <given-names>CK</given-names></name>, <name name-style="western"><surname>Wehr</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Zador</surname> <given-names>AM</given-names></name>. <article-title>Linearity of cortical receptive fields measured with natural sounds</article-title>. <source>J Neurosci</source>. <year>2004</year>;<volume>24</volume>: <fpage>1089</fpage>–<lpage>1100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4445-03.2004" xlink:type="simple">10.1523/JNEUROSCI.4445-03.2004</ext-link></comment> <object-id pub-id-type="pmid">14762127</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref016"><label>16</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>O</given-names></name>. <chapter-title>Characterization of neural responses with stochastic stimuli</chapter-title>. In: <name name-style="western"><surname>Gazzaniga</surname> <given-names>M</given-names></name>, editor. <source>The New Cognitive Neurosciences</source>. <edition>3rd ed</edition>. <publisher-name>MIT Press</publisher-name>; <year>2004</year>. pp. <fpage>327</fpage>–<lpage>338</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Asari</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Zador</surname> <given-names>AM</given-names></name>. <article-title>Long-lasting context dependence constrains neural encoding models in rodent auditory cortex</article-title>. <source>J Neurophysiol</source>. <year>2009</year>;<volume>102</volume>: <fpage>2638</fpage>–<lpage>2656</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00577.2009" xlink:type="simple">10.1152/jn.00577.2009</ext-link></comment> <object-id pub-id-type="pmid">19675288</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Homma</surname> <given-names>NY</given-names></name>, <name name-style="western"><surname>Happel</surname> <given-names>MFK</given-names></name>, <name name-style="western"><surname>Nodal</surname> <given-names>FR</given-names></name>, <name name-style="western"><surname>Ohl</surname> <given-names>FW</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Bajo</surname> <given-names>VM</given-names></name>. <article-title>A Role for Auditory Corticothalamic Feedback in the Perception of Complex Sounds</article-title>. <source>J Neurosci. Society for Neuroscience</source>; <year>2017</year>;<volume>37</volume>: <fpage>6149</fpage>–<lpage>6161</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calford</surname> <given-names>MB</given-names></name>. <article-title>The parcellation of the medial geniculate body of the cat defined by the auditory response properties of single units</article-title>. <source>J Neurosci</source>. <year>1983</year>;<volume>3</volume>: <fpage>2350</fpage>–<lpage>2364</lpage>. <object-id pub-id-type="pmid">6631485</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname> <given-names>LA</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>. <article-title>Physiological differences between histologically defined subdivisions in the mouse auditory thalamus</article-title>. <source>Hear Res. Elsevier</source>; <year>2011</year>;<volume>274</volume>: <fpage>48</fpage>–<lpage>60</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bartlett</surname> <given-names>EL</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name>. <article-title>Correlation of neural response properties with auditory thalamus subdivisions in the awake marmoset</article-title>. <source>J Neurophysiol</source>. American Physiological Society Bethesda, MD; <year>2011</year>;<volume>105</volume>: <fpage>2647</fpage>–<lpage>2667</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00238.2010" xlink:type="simple">10.1152/jn.00238.2010</ext-link></comment> <object-id pub-id-type="pmid">21411564</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref022"><label>22</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Abbott</surname> <given-names>LF</given-names></name>. <source>Theoretical neuroscience: computational and mathematical modeling of neural systems</source>. <publisher-name>Massachusetts Institute of Technology Press</publisher-name>; <year>2001</year>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Schoppe</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>Cui</surname> <given-names>ZF</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Network receptive field modeling reveals extensive integration and multi-feature selectivity in auditory cortical neurons</article-title>. <source>PLoS Comput Biol</source>. <year>2016</year>;<volume>12</volume>: <fpage>e1005113</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005113" xlink:type="simple">10.1371/journal.pcbi.1005113</ext-link></comment> <object-id pub-id-type="pmid">27835647</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabinowitz</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Contrast gain control in auditory cortex</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>70</volume>: <fpage>1178</fpage>–<lpage>1191</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.04.030" xlink:type="simple">10.1016/j.neuron.2011.04.030</ext-link></comment> <object-id pub-id-type="pmid">21689603</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>Schoppe</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>. <article-title>Incorporating midbrain adaptation to mean sound level improves models of auditory cortical processing</article-title>. <source>J Neurosci</source>. <year>2016</year>;<volume>36</volume>: <fpage>280</fpage>–<lpage>289</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2441-15.2016" xlink:type="simple">10.1523/JNEUROSCI.2441-15.2016</ext-link></comment> <object-id pub-id-type="pmid">26758822</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friedman</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hastie</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <article-title>Regularization paths for generalized linear models</article-title>. <source>J Stat Softw</source>. <year>2010</year>;<volume>33</volume>: <fpage>1</fpage>–<lpage>3</lpage>. <object-id pub-id-type="pmid">20808728</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sohl-Dickstein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Poole</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Ganguli</surname> <given-names>S</given-names></name>. <article-title>Fast large-scale optimization by unifying stochastic gradient and quasi-Newton methods</article-title>. <source>arXiv Prepr</source> arXiv<fpage>13112115</fpage>. <year>2013</year>;</mixed-citation></ref>
<ref id="pcbi.1006618.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Glorot</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>. <article-title>Understanding the difficulty of training deep feedforward neural networks</article-title>. <source>Proc AISTATS</source>. <year>2010</year>. pp. <fpage>249</fpage>–<lpage>256</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Williams</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Zipser</surname> <given-names>D</given-names></name>. <article-title>A Learning Algorithm for Continually Running Fully Recurrent Neural Networks</article-title>. <source>Neural Comput</source>. <year>1989</year>;<volume>1</volume>: <fpage>270</fpage>–<lpage>280</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hsu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Borst</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>F</given-names></name>. <article-title>Quantifying variability in neural responses and its application for the validation of model predictions</article-title>. <source>Netw Comput Neural Syst</source>. <year>2004</year>;<volume>15</volume>: <fpage>91</fpage>–<lpage>109</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schoppe</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>. <article-title>Measuring the performance of neural models</article-title>. <source>Front Comput Neurosci</source>. <year>2016</year>;<volume>10</volume>: <fpage>1</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncom.2016.00001" xlink:type="simple">10.3389/fncom.2016.00001</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1006618.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bizley</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Nodal</surname> <given-names>FR</given-names></name>, <name name-style="western"><surname>Nelken</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Functional organization of ferret auditory cortex</article-title>. <source>Cereb Cortex</source>. <year>2005</year>;<volume>15</volume>: <fpage>1637</fpage>–<lpage>1653</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhi042" xlink:type="simple">10.1093/cercor/bhi042</ext-link></comment> <object-id pub-id-type="pmid">15703254</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>David S</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Integration over multiple timescales in primary auditory cortex</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>: <fpage>19154</fpage>–<lpage>19166</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2270-13.2013" xlink:type="simple">10.1523/JNEUROSCI.2270-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24305812</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ahrens</surname> <given-names>MB</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <article-title>Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>: <fpage>1929</fpage>–<lpage>1942</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3377-07.2008" xlink:type="simple">10.1523/JNEUROSCI.3377-07.2008</ext-link></comment> <object-id pub-id-type="pmid">18287509</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calabrese</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schumacher</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Woolley</surname> <given-names>SMN</given-names></name>. <article-title>A generalized linear model for estimating spectrotemporal receptive fields from responses to natural sounds</article-title>. <source>PLoS One</source>. <year>2011</year>;<volume>6</volume>: <fpage>e16104</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0016104" xlink:type="simple">10.1371/journal.pone.0016104</ext-link></comment> <object-id pub-id-type="pmid">21264310</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rabinowitz</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BDB</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JWH</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Spectrotemporal contrast kernels for neurons in primary auditory cortex</article-title>. <source>J Neurosci</source>. <year>2012</year>;<volume>32</volume>: <fpage>11271</fpage>–<lpage>11284</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1715-12.2012" xlink:type="simple">10.1523/JNEUROSCI.1715-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22895711</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Cooperative nonlinearities in auditory cortical neurons</article-title>. <source>Neuron</source>. <year>2008</year>;<volume>58</volume>: <fpage>956</fpage>–<lpage>966</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2008.04.026" xlink:type="simple">10.1016/j.neuron.2008.04.026</ext-link></comment> <object-id pub-id-type="pmid">18579084</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Hierarchical computation in the canonical auditory cortical circuit</article-title>. <source>Proc Natl Acad Sci</source>. <year>2009</year>;<volume>106</volume>: <fpage>21894</fpage>–<lpage>21899</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0908383106" xlink:type="simple">10.1073/pnas.0908383106</ext-link></comment> <object-id pub-id-type="pmid">19918079</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>. <article-title>Computational Identification of Receptive Fields</article-title>. <source>Annu Rev Neurosci</source>. <year>2013</year>;<volume>36</volume>: <fpage>103</fpage>–<lpage>120</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-neuro-062012-170253" xlink:type="simple">10.1146/annurev-neuro-062012-170253</ext-link></comment> <object-id pub-id-type="pmid">23841838</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname> <given-names>TO</given-names></name>, <name name-style="western"><surname>Atencio</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Hierarchical representations in the auditory cortex</article-title>. <source>Curr Opin Neurobiol</source>. Elsevier Ltd; <year>2011</year>;<volume>21</volume>: <fpage>761</fpage>–<lpage>767</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2011.05.027" xlink:type="simple">10.1016/j.conb.2011.05.027</ext-link></comment> <object-id pub-id-type="pmid">21704508</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Rust</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Analyzing neural responses to natural signals: maximally informative dimensions</article-title>. <source>Neural Comput</source>. <year>2004</year>;<volume>16</volume>: <fpage>223</fpage>–<lpage>250</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976604322742010" xlink:type="simple">10.1162/089976604322742010</ext-link></comment> <object-id pub-id-type="pmid">15006095</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kozlov</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Gentner</surname> <given-names>TQ</given-names></name>. <article-title>Central auditory neurons have composite receptive fields</article-title>. <source>Proc Natl Acad Sci</source>. <year>2016</year>;<volume>113</volume>: <fpage>1441</fpage>–<lpage>1446</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1506903113" xlink:type="simple">10.1073/pnas.1506903113</ext-link></comment> <object-id pub-id-type="pmid">26787894</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McFarland</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Cui</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Butts</surname> <given-names>DA</given-names></name>. <article-title>Inferring nonlinear neuronal computation based on physiologically plausible inputs. Bethge M, editor</article-title>. <source>PLoS Comput Biol. Public Library of Science</source>; <year>2013</year>;<volume>9</volume>: <fpage>e1003143</fpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Litke</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname> <given-names>EJ</given-names></name>, <etal>et al</etal>. <article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title>. <source>Nature</source>. <year>2008</year>;<volume>454</volume>: <fpage>995</fpage>–<lpage>999</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature07140" xlink:type="simple">10.1038/nature07140</ext-link></comment> <object-id pub-id-type="pmid">18650810</object-id></mixed-citation></ref>
<ref id="pcbi.1006618.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Real</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Asari</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Gollisch</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>. <article-title>Neural circuit inference from function to structure</article-title>. <source>Curr Biol. Elsevier Ltd.</source>; <year>2017</year>;<volume>27</volume>: <fpage>189</fpage>–<lpage>198</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006618.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meyer</surname> <given-names>AF</given-names></name>, <name name-style="western"><surname>Williamson</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <article-title>Models of neuronal stimulus-response functions: elaboration, estimation, and evaluation</article-title>. <source>Front Syst Neurosci</source>. <year>2017</year>;<volume>10</volume>: <fpage>109</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnsys.2016.00109" xlink:type="simple">10.3389/fnsys.2016.00109</ext-link></comment> <object-id pub-id-type="pmid">28127278</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
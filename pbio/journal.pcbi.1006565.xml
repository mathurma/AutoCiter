<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00190</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006565</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Data management</subject><subj-group><subject>Ontologies</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject><subj-group><subject>Face recognition</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Cognitive neurology</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive neuroscience</subject><subj-group><subject>Cognitive neurology</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Neurology</subject><subj-group><subject>Cognitive neurology</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Atlases of cognition with large-scale human brain mapping</article-title>
<alt-title alt-title-type="running-head">Atlases of cognition with large-scale brain mapping</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Varoquaux</surname> <given-names>Gaël</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="fn" rid="currentaff001"><sup>¤</sup></xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Schwartz</surname> <given-names>Yannick</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6755-0259</contrib-id>
<name name-style="western">
<surname>Poldrack</surname> <given-names>Russell A.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Gauthier</surname> <given-names>Baptiste</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3466-6620</contrib-id>
<name name-style="western">
<surname>Bzdok</surname> <given-names>Danilo</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
<xref ref-type="aff" rid="aff007"><sup>7</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9794-749X</contrib-id>
<name name-style="western">
<surname>Poline</surname> <given-names>Jean-Baptiste</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff008"><sup>8</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5018-7895</contrib-id>
<name name-style="western">
<surname>Thirion</surname> <given-names>Bertrand</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Parietal, Inria, Saclay, France</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Neurospin, CEA, Gif sur Yvette, France</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>STIC department, Université Paris-Saclay, Saclay, France</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Psychology department, Stanford University, Stanford, CA 94305, USA</addr-line>
</aff>
<aff id="aff005">
<label>5</label>
<addr-line>Cognitive Neuroimaging Unit, INSERM, Gif sur Yvette, France</addr-line>
</aff>
<aff id="aff006">
<label>6</label>
<addr-line>JARA-BRAIN, Jülich-Aachen Research Alliance, Aachen, Germany</addr-line>
</aff>
<aff id="aff007">
<label>7</label>
<addr-line>Department of Psychiatry, Psychotherapy and Psychosomatics, RWTH Aachen University, 52072 Aachen, Germany</addr-line>
</aff>
<aff id="aff008">
<label>8</label>
<addr-line>Montreal neurological Institute and Hospital, McGill University, Montreal, Canada</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Diedrichsen</surname> <given-names>Jörn</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Western University, CANADA</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist regarding the content of the manuscript.</p>
</fn>
<fn fn-type="current-aff" id="currentaff001">
<label>¤</label>
<p>Current address: Neurospin, CEA Saclay, 91191 Gif sur Yvette, France</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">bertrand.thirion@inria.fr</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>11</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>29</day>
<month>11</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>11</issue>
<elocation-id>e1006565</elocation-id>
<history>
<date date-type="received">
<day>2</day>
<month>2</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>15</day>
<month>10</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Varoquaux et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006565"/>
<abstract>
<p>To map the neural substrate of mental function, cognitive neuroimaging relies on controlled psychological manipulations that engage brain systems associated with specific cognitive processes. In order to build comprehensive atlases of cognitive function in the brain, it must assemble maps for many different cognitive processes, which often evoke overlapping patterns of activation. Such data aggregation faces contrasting goals: on the one hand finding correspondences across vastly different cognitive experiments, while on the other hand precisely describing the function of any given brain region. Here we introduce a new analysis framework that tackles these difficulties and thereby enables the generation of brain atlases for cognitive function. The approach leverages ontologies of cognitive concepts and multi-label brain decoding to map the neural substrate of these concepts. We demonstrate the approach by building an atlas of functional brain organization based on 30 diverse functional neuroimaging studies, totaling 196 different experimental conditions. Unlike conventional brain mapping, this functional atlas supports robust <italic>reverse inference</italic>: predicting the mental processes from brain activity in the regions delineated by the atlas. To establish that this reverse inference is indeed governed by the corresponding concepts, and not idiosyncrasies of experimental designs, we show that it can accurately decode the cognitive concepts recruited in new tasks. These results demonstrate that aggregating independent task-fMRI studies can provide a more precise global atlas of selective associations between brain and cognition.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Cognitive neuroscience uses neuroimaging to identify brain systems engaged in specific cognitive tasks. However, linking unequivocally brain systems with cognitive functions is difficult: each task probes only a small number of facets of cognition, while brain systems are often engaged in many tasks. We develop a new approach to generate a functional atlas of cognition, demonstrating brain systems selectively associated with specific cognitive functions. This approach relies upon an ontology that defines specific cognitive functions and the relations between them, along with an analysis scheme tailored to this ontology. Using a database of thirty neuroimaging studies, we show that this approach provides a highly-specific atlas of mental functions, and that it can decode the mental processes engaged in new tasks.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Agence natioanle de la recherche</institution>
</funding-source>
<award-id>ANR-10-JCJC 1408-01</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5018-7895</contrib-id>
<name name-style="western">
<surname>Thirion</surname> <given-names>Bertrand</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100010661</institution-id>
<institution>Horizon 2020 Framework Programme</institution>
</institution-wrap>
</funding-source>
<award-id>720270</award-id>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000001</institution-id>
<institution>National Science Foundation</institution>
</institution-wrap>
</funding-source>
<award-id>OCI-1131441</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-6755-0259</contrib-id>
<name name-style="western">
<surname>Poldrack</surname> <given-names>Russell A</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution>Inria</institution>
</funding-source>
<award-id>Associate team MetaMRI</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5018-7895</contrib-id>
<name name-style="western">
<surname>Thirion</surname> <given-names>Bertrand</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>The authors acknowledge support from the following contracts: NSF OCI-113144 1, ANR ANR-10-JCJC 1408-01, ANR 2017 "DirtyData" ANR 2017 "FastBig", EU H2020 Framework Programme for Research and Innovation, Grant Agreement No 720270 (Human Brain Project SGA1), and 785907 (Human brain project SGA2), the Deutsche Forschungsgemeinschaft (DFG, BZ2/2-1, BZ2/3-1, and BZ2/4-1; International Research Training Group IRTG2150), Amazon AWS Research Grant (2016 and 2017), the German National Merit Foundation, as well as the START-Program of the Faculty of Medicine (126/16) and Exploratory Research Space (OPSF449), RWTH Aachen, ERC-2010-StG_20091209 MindTime, ANR-10-JCJC-1904 BrainTime and the Inria MetaMRI associate team. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="1"/>
<page-count count="18"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-12-11</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The data used are available in the following public NeuroVault collection: <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/1952" xlink:type="simple">https://neurovault.org/collections/1952</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>A major challenge to reaching a global understanding of the functional organization of the human brain is that each neuroimaging experiment only probes a small number of cognitive processes. Cognitive neuroscience is faced with a profusion of findings relating specific psychological functions to brain activity. These are like a collection of anecdotes that the field must assemble into a comprehensive description of the neural basis of mental functions, akin to “playing twenty questions with nature” [<xref ref-type="bibr" rid="pcbi.1006565.ref001">1</xref>]. However, maps from individual studies are not easily assembled into a functional atlas. On the one hand, the brain recruits similar neural territories to solve very different cognitive problems. For instance, the intra-parietal sulcus is often studied in the context of spatial attention; however, it is also activated in response to mathematical processing [<xref ref-type="bibr" rid="pcbi.1006565.ref002">2</xref>], cognitive control [<xref ref-type="bibr" rid="pcbi.1006565.ref003">3</xref>], and social cognition and language processing [<xref ref-type="bibr" rid="pcbi.1006565.ref004">4</xref>]. On the other hand, aggregating brain responses across studies to refine descriptions of the function of brain regions faces two challenges: First, experiments are often quite disparate and each one is crafted to single out a specific psychological mechanism, often suppressing other mechanisms. Second, standard brain-mapping analyses enable conclusions on responses to tasks or stimuli, and not on the function of given brain regions.</p>
<p>Cognitive subtraction, via the opposition of carefully-crafted stimuli or tasks, is used to isolate differential responses to a cognitive effect. However, scaling this approach to many studies and cognitive effects leads to neural activity maps with little functional specificity, hard to assemble in an atlas of cognitive function. Indeed, any particular task recruits many mental processes; while it may sometimes be possible to cancel out all but one process across tasks (e.g. through the use of conjunction analysis [<xref ref-type="bibr" rid="pcbi.1006565.ref005">5</xref>]), it is not feasible to do this on a large scale. Furthermore, it can be difficult to eliminate all possible confounds between tasks and mental processes. An additional challenge to the selectivity of this approach is that, with sufficient statistical power, nearly all regions in the brain will respond in a statistically significant way to an experimental manipulation [<xref ref-type="bibr" rid="pcbi.1006565.ref006">6</xref>].</p>
<p>The standard approach to the analysis of functional brain images maps the response of brain regions to a known psychological manipulation [<xref ref-type="bibr" rid="pcbi.1006565.ref007">7</xref>]. However, this is most often not the question that we actually wish to answer. Rather, we want to understand the mapping between brain regions/networks and psychological functions (i.e. “what function does the fronto-parietal network implement?”). If we understood these mappings, then in theory we could predict the mental state of an individual based solely on patterns of activation; this is often referred to as <italic>reverse inference</italic> [<xref ref-type="bibr" rid="pcbi.1006565.ref008">8</xref>], because it reverses the usual pattern of inference from mental state to brain activation. Whereas informal reverse inference (e.g. based on a selective review of the literature) can be highly biased, it is increasingly common to use meta-analytic tools such as Neurosynth [<xref ref-type="bibr" rid="pcbi.1006565.ref009">9</xref>] to perform formal reverse inference analyses (also know as <italic>decoding</italic>). However, these inferences remain challenging to interpret due to the trade-off between breadth and specificity that is necessary to create a sufficiently large database (e.g. see discussion in [<xref ref-type="bibr" rid="pcbi.1006565.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1006565.ref011">11</xref>]).</p>
<p>The optimal basis for brain decoding would be a large database of task fMRI datasets spanning a broad range of mental functions. Previous work has demonstrated that it is possible to decode the task being performed by an individual, in a way that generalizes across individuals [<xref ref-type="bibr" rid="pcbi.1006565.ref012">12</xref>], but this does not provide insight into the specific cognitive functions being engaged, which is necessary if we wish to infer mental functions associated with novel tasks. The goal of decoding cognitive functions rather than tasks requires that the data are annotated using an ontology of cognitive functions [<xref ref-type="bibr" rid="pcbi.1006565.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1006565.ref015">15</xref>], which can then become the target for decoding. Some recent work has used a similar approach in restricted domains, such as pain [<xref ref-type="bibr" rid="pcbi.1006565.ref016">16</xref>], and was able to isolate brain networks selective to physical pain. Extending this success to the entire scope of cognition requires modeling a broad range of experiments with sufficient annotations to serve as the basis for decoding.</p>
<p>To date, the construction of human functional brain atlases has primarily relied upon the combination of resting-state fMRI and coordinate-based meta-analyses. This approach is attractive because of the widespread availability of resting-state fMRI data (from which brain functional networks can be inferred through statistical approaches [<xref ref-type="bibr" rid="pcbi.1006565.ref017">17</xref>]), and the ability to link function to structure through the use of annotated coordinate-based data (such as those in the BrainMap [<xref ref-type="bibr" rid="pcbi.1006565.ref018">18</xref>] and Neurosynth [<xref ref-type="bibr" rid="pcbi.1006565.ref009">9</xref>] databases). This approach has identified a set of large-scale networks that are consistently related to specific sets of cognitive functions [<xref ref-type="bibr" rid="pcbi.1006565.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1006565.ref020">20</xref>], and provides decompositions of specific regions [<xref ref-type="bibr" rid="pcbi.1006565.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006565.ref022">22</xref>]. However, resting-state analysis is limited in the set of functional states that it can identify [<xref ref-type="bibr" rid="pcbi.1006565.ref023">23</xref>], and meta-analytic databases are limited in the specificity of their annotation of task data, as well as in the quality of the data, given that it is reconstructed merely from activation coordinates reported in published papers.</p>
<p>A comprehensive functional brain atlas should link brain structures and cognitive functions in both forward and reverse inferences [<xref ref-type="bibr" rid="pcbi.1006565.ref007">7</xref>]. To build such a bilateral mapping, we introduce the concept of “ontology-based decoding,”, in which the targets of decoding are specific cognitive features annotated according to an ontology. This idea was already present in [<xref ref-type="bibr" rid="pcbi.1006565.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006565.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1006565.ref024">24</xref>]; here we show how an ontology enables scaling it to many cognitive features, to increase breadth. In the present case, we use the Cognitive Paradigm Ontology (CogPO) [<xref ref-type="bibr" rid="pcbi.1006565.ref015">15</xref>], that provides a common vocabulary of concepts related to psychological tasks and their relationships (see <xref ref-type="supplementary-material" rid="pcbi.1006565.s001">S1 Text</xref> Distribution of terms in our database). Forward inference then relies on ontology-defined contrasts across experiments, while reverse inference is performed using an ontology-informed decoder to leverage this specific set of oppositions (see <xref ref-type="fig" rid="pcbi.1006565.g001">Fig 1</xref> and methodological details). We apply these forward and reverse inferences to the individual activation maps of a large task-fMRI database: 30 studies, 837 subjects, 196 experimental conditions, and almost 7000 activation maps (see <xref ref-type="supplementary-material" rid="pcbi.1006565.s001">S1 Text</xref> Distribution of terms in our database). We use studies from different laboratories, that cover various cognitive domains such as language, vision, decision making, and arithmetics. We start from the raw data to produce statistical brain maps, as this enables homogeneous preprocessing and thorough quality control. The results of this approach demonstrate that it is possible to decode specific cognitive functions from brain activity, even if the subject is performing a task not included in the database.</p>
<fig id="pcbi.1006565.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006565.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Brain mapping with a cognitive ontology.</title>
<p>Our approach characterizes the task conditions that correspond to each brain image with terms from a cognitive ontology. <italic>Forward inference</italic> maps differences between brain responses for a given term and its neighbors in the ontology, i.e. closely related psychological notions. <italic>Reverse inference</italic> is achieved by predicting the terms associated with the task from brain activity. The figure depicts the analysis of visual object perception tasks with motor response. A forward inference captures brain responses in motor, primary visual and high-level visual areas. Reverse inference captures which regions or <italic>neural substrate</italic> are predictive of different terms, discarding common response to different tasks, here in the primary visual cortex.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.g001" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec003">
<title>An ontology to describe cognitive neuroimaging studies</title>
<p>The main challenge to accumulate task fMRI is to account for the disparity in experimental paradigms. One solution is the use of cognitive ontologies that define terms describing the cognitive tasks at hand and enable to relate them. The choice of the ontology must meet two opposite goals: have a good coverage of the cognitive space, and document overlap between studies. In practice, each cognitive term describing mental processes must be expressed in several studies of our database to ensure the generalizability of our inference.</p>
<sec id="sec004">
<title>Terms</title>
<p>The cognitive ontologies currently being developed in the neuroimaging community follow two directions. The Cognitive Paradigm Ontology (CogPO) [<xref ref-type="bibr" rid="pcbi.1006565.ref015">15</xref>], which is derived from the BrainMap taxonomy [<xref ref-type="bibr" rid="pcbi.1006565.ref018">18</xref>], concentrates on the description of the experimental conditions that characterize an experimental paradigm. A taxonomy is a special case of ontology in which links between concepts are captured in categories: high-level concepts from categories that encompass lower-level concepts. In CogPO, experimental tasks are described via different categories that represent the stimuli, the expected responses, and the instructions given to the subjects, <italic>e.g</italic>., “stimulus modality”, “explicit stimulus”, “explicit response”. The CogPO terms are rather broad, but enable to find common task descriptors regardless of the original intent of the study. More tailored towards cognitive processes, the Cognitive Atlas [<xref ref-type="bibr" rid="pcbi.1006565.ref014">14</xref>] lists a large number of cognitive tasks and concepts, and increasingly links them together. We decide to mainly use terms from CogPO, and extend it where our database can benefit from more precise or high-level descriptions. Not all terms of CogPO in our database are present over multiple studies, and thus we only use a subset of CogPO. Similarly, with the limited number of studies in our database, there is only little overlap in high-level cognition. We added only the “language” label from the Cognitive Atlas.</p>
<p>It should be noted that the ontology does not have a full hierarchical structure, as <italic>stimulus modality</italic>, <italic>explicit stimulus</italic> and <italic>explicit response</italic> convey different level of information. Further work with growing databases will however need to add more and more terms. Finding a consistent structure underlying all these terms is a hard task.</p>
</sec>
<sec id="sec005">
<title>Categories</title>
<p>Functional MRI experiments are carefully designed to balance conditions of interest with control conditions to cancel out effects related to the stimulation. As we do not want to ignore the designs, but rather leverage them in the context of a large-scale inference, we introduce an additional category level for our terms, that groups together terms –or conditions– that are typically contrasted in individual studies. These new categories strongly relate to the paradigm classes from BrainMap and the tasks from the Cognitive Atlas. The categories we choose are relevant to our database, and reflect the contrasts found in the studies. They nonetheless could be modified or extended further to test other hypotheses. This hierarchy of terms enables to co-analyze heterogeneous studies. <xref ref-type="supplementary-material" rid="pcbi.1006565.s019">S4 Table</xref> references the categories and associated terms used in this paper.</p>
</sec>
</sec>
<sec id="sec006">
<title>Forward inference</title>
<p>Standard forward inference in functional neuroimaging uses the GLM (general linear model), which models brain responses as linear combinations of multiple effects. We use a <italic>one-hot-encoding</italic> of the concepts, <italic>i.e</italic>. we represent their presence in the tasks by a binary design matrix. We test for response induced by each concept with a second-level analysis using cross-studies contrasts.</p>
<p>To disentangle various experimental factors, brain mapping uses contrasts. Individual studies are crafted to isolate cognitive processes with control conditions, e.g. a face-recognition study would rely on a “face versus place” or a “face versus scrambled picture” contrast. To separate cognitive factors without a strong prior on control conditions, the alternative is to contrast a term against all related terms, e.g., “face versus place and scrambled picture”.</p>
<p>We use the categories of our ontology to define such contrasts in a systematic way for the wide array of cognitive concepts touched in our database. This approach yields groups of terms within the task categories, as described in <xref ref-type="table" rid="pcbi.1006565.t001">Table 1</xref>: the task categories are used to define the conditions and their controls. Inside each group, we perform a GLM analysis with all the “one versus others” contrasts. We denote these <italic>ontology contrasts</italic>. Compared to a standard group analysis, the benefit of this GLM is that the control conditions for each effect studied span a much wider range of stimuli than typical studies.</p>
<table-wrap id="pcbi.1006565.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006565.t001</object-id>
<label>Table 1</label>
<caption>
<title>Contrasts used to characterize tasks effects in our database.</title>
<p>We used CogPO categories for task-related description, and add necessary terms from Cognitive Atlas to describe higher-level cognitive aspect. Here we report only terms that were present in more than one study –aside from the “left foot”, which maps in the analysis as maps in “feet” task category, but not “right foot”. The task categories group terms typically used as conditions and their controls to test a hypothesis. The <italic>stimulus modality</italic> category stands for CogPO and task categories. Some terms do not belong to any task category and are referred to as such. The <italic>arithmetics</italic> task category spans across the <italic>response modality</italic> and <italic>instructions</italic> CogPO categories.</p>
</caption>
<alternatives>
<graphic id="pcbi.1006565.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">CogPO Categories</th>
<th align="left">Task Categories</th>
<th align="left">Terms</th>
<th align="left">contrasts</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="2">Stimulus modality</td>
<td align="left" rowspan="2">-</td>
<td align="left">visual</td>
<td align="left">visual—auditory</td>
</tr>
<tr>
<td align="left">auditory</td>
<td align="left">auditory—visual</td>
</tr>
<tr>
<td align="left" rowspan="10">Explicit stimulus</td>
<td align="left" rowspan="2">Sounds</td>
<td align="left">human voice</td>
<td align="left">human voice—sound</td>
</tr>
<tr>
<td align="left">sound</td>
<td align="left">sound—human voice</td>
</tr>
<tr>
<td align="left" rowspan="2">Retinotopy</td>
<td align="left">vertical checkerboard</td>
<td align="left">vertical checkerboard—horizontal checkerboard</td>
</tr>
<tr>
<td align="left">horizontal checkerboard</td>
<td align="left">horizontal checkerboard—vertical checkerboard</td>
</tr>
<tr>
<td align="left" rowspan="4">Object recognition</td>
<td align="left">faces</td>
<td align="left">faces—<inline-formula id="pcbi.1006565.e001"><alternatives><graphic id="pcbi.1006565.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006565.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>3</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>(places + object + scramble)</td>
</tr>
<tr>
<td align="left">places</td>
<td align="left">places—<inline-formula id="pcbi.1006565.e002"><alternatives><graphic id="pcbi.1006565.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006565.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>3</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>(faces + object + scramble)</td>
</tr>
<tr>
<td align="left">objects</td>
<td align="left">object—<inline-formula id="pcbi.1006565.e003"><alternatives><graphic id="pcbi.1006565.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006565.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>3</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>(faces + places + scramble)</td>
</tr>
<tr>
<td align="left">scramble</td>
<td align="left">scramble—<inline-formula id="pcbi.1006565.e004"><alternatives><graphic id="pcbi.1006565.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006565.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>3</mml:mn></mml:mfrac></mml:math></alternatives></inline-formula>(faces + places + object)</td>
</tr>
<tr>
<td align="left" rowspan="2">Symbol recognition</td>
<td align="left">words</td>
<td align="left">words—digits</td>
</tr>
<tr>
<td align="left">digits</td>
<td align="left">digits—words</td>
</tr>
<tr>
<td align="left" rowspan="5">Response modality</td>
<td align="left" rowspan="2">Motor—hands</td>
<td align="left">left hand</td>
<td align="left">left hand—right hand</td>
</tr>
<tr>
<td align="left">right hand</td>
<td align="left">right hand—left hand</td>
</tr>
<tr>
<td align="left" rowspan="2">Motor—feet</td>
<td align="left">left foot</td>
<td align="left">left foot—right foot</td>
</tr>
<tr>
<td align="left">right foot</td>
<td align="left">right foot—left foot</td>
</tr>
<tr>
<td align="left">Arithmetics</td>
<td align="left">saccades</td>
<td align="left">saccades</td>
</tr>
<tr>
<td align="left">Instructions</td>
<td align="left">Arithmetics</td>
<td align="left">calculation</td>
<td align="left">calculation</td>
</tr>
<tr>
<td align="left">Cognitive Atlas term</td>
<td align="left">No category</td>
<td align="left">language</td>
<td align="left">language</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec007">
<title>Reverse inference</title>
<p>For reverse inference, we rely on large-scale decoding [<xref ref-type="bibr" rid="pcbi.1006565.ref012">12</xref>]. Prior work [<xref ref-type="bibr" rid="pcbi.1006565.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1006565.ref024">24</xref>] tackles this question using a multi-class predictive model, the targets of the classification being separate cognitive labels. Our formulation is different as our goal is to predict the presence or absence of a term, effectively inverting the inference of our forward model based on one-hot-encoding. This implies that each image is associated with more than a single label, which corresponds to multi-label classification in a decoding setting.</p>
<sec id="sec008">
<title>A hierarchical decoder</title>
<p>Linear models are widely used for decoding as they give good prediction and their parameters form brain maps. However, in a multi-label setting, they give rise to a profusion of separate one-versus-all (OvA) problems and cannot exploit the shared information between each label. We use a method based on stacked regressions [<xref ref-type="bibr" rid="pcbi.1006565.ref025">25</xref>]: two layers of linear models (logistic regressions) discriminating different cognitive terms. The first layer is tuned to specific oppositions between terms related in the ontology, while the second is tuned to predict which specific term is most relevant. This peculiar classifier architecture is tailored to the ontology that defines the structure of the targeted cognitive information. In the future, more complex cognitive ontologies may entail further refinements of the classifier.</p>
</sec>
<sec id="sec009">
<title>First layer</title>
<p>First, we stack the decisions of the OvA classifiers, that capture specific activation patterns across all tasks. This allows to relate cognitive processes across independent cognitive disciplines. Second, we build one-versus-one (OvO) classifiers by opposing terms that belong to the same task category (see <xref ref-type="supplementary-material" rid="pcbi.1006565.s019">S4 Table</xref>). This enables to generalize the notion of contrasts and subtraction-logic that is implicit to the majority of fMRI experiments. Finally, we build classifiers predicting the actual task categories from <xref ref-type="supplementary-material" rid="pcbi.1006565.s019">S4 Table</xref>. It enables to build a hierarchical decoding framework, that combines the decisions of simpler problems, namely classifying the task categories, and more subtle, within-category problems: the OvO classifiers. There may be better choices of classifiers, but the final predictor weights them, and therefore mitigates the introduction of unnecessary or sub-optimal classifiers. We list in <xref ref-type="supplementary-material" rid="pcbi.1006565.s017">S2 Table</xref> all the classifiers that we use in the first level to learn the feature space capturing the ontology.</p>
</sec>
<sec id="sec010">
<title>Second layer</title>
<p>In a second layer, we learn the terms on the reduced representation with an OvA scheme, which also uses <italic>ℓ</italic><sub>1</sub>-penalized logistic regression. The final output of this method is one linear classifier per term, that can be recovered by the linear combination of the coefficients of the base classifiers, with the coefficients of the final classifiers. The resulting ontology-informed decoder combines fined-grain information captured by opposing matching conditions in the first level with more universal decisions in the second level that outputs the presence or absence of a term. This combination is itself a linear classifier per label, and thus yields discriminant brain patterns for each term. <xref ref-type="fig" rid="pcbi.1006565.g002">Fig 2</xref> summarizes this decoding procedure and <xref ref-type="supplementary-material" rid="pcbi.1006565.s004">S4 Text</xref> Reverse inference: Decoding with cognitive ontologies gives more specific details.</p>
<fig id="pcbi.1006565.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006565.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Ontology informed decoding.</title>
<p>The hierarchical decoding procedure reduces the dimensionality by stacking the decision functions of several simple binary classifiers, which mimic study-level contrasts by opposing each term to matching ones. A second level of one-versus-all (OvA) classifiers predicts the presence of terms using the output of the first level. The first layer may be seen as capturing whether a given brain activity map looks more like face or place recognition, objects or scrambled images, visual or motor stimuli. The second layer combines this information to conclude on what cognitive terms best describe the given activity. Final linear classifiers may be recovered by combining the coefficients of the first and second level classifiers.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.g002" xlink:type="simple"/>
</fig>
<p>Such a two-step classification is important because binary classifiers opposing one term to another exhibit undesirable properties in rich output settings: for instance a binary classifier that would detect occurrences of <italic>right hand</italic> task would typically classify all <italic>left hand</italic> task occurrence as <italic>right hand</italic>, given that the negative class for this problem typically involved mostly non-manual tasks. Leveraging a two- instead of one-layer classification architecture creates the possibility to capture more subtle effects, a trick systematically used in recent deep learning models.</p>
</sec>
<sec id="sec011">
<title>Cross validation</title>
<p>To evaluate the procedure, we perform the classification in randomized leave-3-study-out cross validation scheme. Cross-study prediction ensures that the representation of the cognitive labels generalizes across paradigms. We run 100 iterations of the cross validation to get a good estimate of the classifier’s performance.</p>
</sec>
</sec>
</sec>
<sec id="sec012" sec-type="results">
<title>Results</title>
<sec id="sec013">
<title>An atlas of areas linked to function</title>
<p>Using a database of 30 studies, we demonstrate that our approach captures a rich mapping of the brain, identifying networks with a specific link to cognitive concepts. Prediction of cognitive components in new paradigms validates this claim.</p>
</sec>
<sec id="sec014">
<title>Linking brain networks and cognitive concepts</title>
<p>We combine forward and reverse inference to construct a one-to-one mapping between brain structures and cognitive concepts. Forward inference across studies requires adapting brain mapping analysis to leverage the ontology. Mapping the brain response to the presence of a concept in tasks selects unspecific regions, as it captures other related effects, <italic>e.g</italic>. selecting the primary visual cortex for any visual task (<xref ref-type="fig" rid="pcbi.1006565.g003">Fig 3</xref>). To obtain a more focal mapping, we remove these effects by opposing the concept of interest to related concepts in the ontology. Reverse inference narrows down to regions specific to the term. However, as we use a multivariate procedure, some of its variables may model sources of noise [<xref ref-type="bibr" rid="pcbi.1006565.ref026">26</xref>]. For instance, when using visual n-back tasks with a motor response to map the visual system, the motor response creates confounding signals. A multivariate procedure could use signal from regions that capture these confounds to subtract them from vision-specific activity, leading to better prediction. As such regions are not directly related to the task, they are well filtered with a standard GLM (General Linear Model) used in forward inference. For this reason, our final maps combine statistics from forward and reverse inference: functional regions are composed of voxels that are both recruited by the cognitive process of interest <italic>and</italic> predictive of this process; see <xref ref-type="supplementary-material" rid="pcbi.1006565.s005">S5 Text</xref> Consensus between forward and reverse inference for statistical arguments and [<xref ref-type="bibr" rid="pcbi.1006565.ref027">27</xref>] for more fundamental motivations regarding causal inference. <xref ref-type="fig" rid="pcbi.1006565.g003">Fig 3a–3d</xref> shows how the neural-activity patterns for the “places” label progressively narrow on the PPA with the different approaches. Thus we link each cognitive concept to a set of focal regions, resulting in a brain-wide functional atlas.</p>
<fig id="pcbi.1006565.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006565.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Maps for the different inference types.</title>
<p>Left (<bold>a</bold>–<bold>d</bold>): maps of the different inferences on our database for the “place” concept. The consensus between reverse inference and forward inference based on contrasts defined from the ontology singles out the “parahippocampal place area” (PPA) for the “place” concept. Right (<bold>d</bold>): the NeuroSynth reverse-inference map for this concept. Reverse inference with Neurosynth also narrows well on the PPA, but is more noisy.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec015">
<title>Atlases with various mapping approaches</title>
<p>To build functional atlases, it is important to clearly identify the regions associated with different cognitive concepts. <xref ref-type="fig" rid="pcbi.1006565.g003">Fig 3e</xref> shows that reverse-inference meta-analysis with Neurosynth also associates the PPA with the “place” term, but the region is not as well delineated as with our approach. <xref ref-type="fig" rid="pcbi.1006565.g004">Fig 4</xref> shows functional atlases of auditory and visual regions extracted with various mapping strategies. The relative position and overlap of the various maps is clearly visible. Forward-inference mapping of the effect of each term versus baseline on our database gives regions that strongly overlap (<xref ref-type="fig" rid="pcbi.1006565.g004">Fig 4a</xref>). Indeed, the maps are not functionally specific and are dominated by low-level visual mechanisms in the occipital cortex and language in the temporal cortex. Using contrasts helps decreasing this overlap (<xref ref-type="fig" rid="pcbi.1006565.g004">Fig 4b</xref>), and hence reveals some of the functional segregation of the visual system. However, as the stimuli are not perfectly balanced across experiments, contrasts also capture unspecific regions, such as responses in the lateral occipital cortex (LOC) for faces or places. Reverse inference with a logistic-regression decoder gives well separated regions, albeit small and scattered (<xref ref-type="fig" rid="pcbi.1006565.g004">Fig 4c</xref>). The ontology-informed approach identifies well-separated regions that are consistent with current knowledge of brain functional organization (<xref ref-type="fig" rid="pcbi.1006565.g004">Fig 4d</xref>). Finally, meta analysis with NeuroSynth separates maps related to the various terms better than forward analysis on our database of studies (<xref ref-type="fig" rid="pcbi.1006565.g004">Fig 4e</xref>). Yet some overlap remains, for instance in the LOC for maps related to visual concepts. In addition, the outline of regions is ragged, as the corresponding maps are noisy (<xref ref-type="fig" rid="pcbi.1006565.g003">Fig 3e</xref>), probably because they are reconstructed from peak coordinates. Note that overlaps across term-specific topographies are ultimately expected to remain, especially in associative cortices. In the following, we first discuss quantitative validation of the reverse-inference atlases, and then study in detail the atlas obtained with the ontology-informed approach.</p>
<fig id="pcbi.1006565.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006565.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Different functional atlases.</title>
<p>Regions outlined using different functional mapping approaches, from left to right: a. forward term mapping; b. forward inference with ontology contrasts (standard analysis); c. reverse inference with logistic regression; d. NeuroSynth reverse inference; and e. our approach, mapping with decoding and an ontology. The top part shows visual regions, and the lower one auditory regions in the left hemisphere. Forward term mapping outlines overlapping regions, as brain responses capture side effects such as the stimulus modality: for visual and auditory regions every cognitive term is represented in the corresponding primary cortex. Forward mapping using contrasts removes the overlap in primary regions, but a large overlap persists in mid-level regions, as control conditions are not well matched across studies. Standard reverse inference, specific to a term, creates overly sparse regions though with little overlap. Reverse inference with Neurosynth also displays large overlap in mid-level regions. Finally, ontology-based decoding maps recover known functional areas the visual and auditory cortices.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec016">
<title>Decoding cognition validates the atlas</title>
<p>Upon qualitative inspection, the regions extracted by our mapping approach provide a good functional segmentation of the brain. For an objective test of this atlas, we quantify how well these regions support reverse inference. For this, we use the ontology-informed decoder to predict cognitive concepts describing tasks in new paradigms and measure the quality of the prediction. This approach was tested using a cross-validation scheme in which 3 studies were held out of each training fold for subsequent testing. <xref ref-type="fig" rid="pcbi.1006565.g005">Fig 5</xref> shows the corresponding scores: ontology-informed decoding accurately predicts cognitive concepts in unseen tasks. It predicts these concepts better than other commonly used decoders (logistic regression and naive Bayes, see also <xref ref-type="supplementary-material" rid="pcbi.1006565.s006">S6 Text</xref> Evaluating prediction accuracy: cross-validation) and NeuroSynth decoding based on meta-analysis. This confirms that the corresponding atlas captures areas specialized in cognitive functions better than conventional approaches.</p>
<fig id="pcbi.1006565.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006565.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Prediction scores for different methods.</title>
<p>Area under the ROC curve (1 is perfect prediction, while chance is at 0.5); <bold>a</bold> score for each term; <bold>b</bold> score relative to the average per term for each decoding approach. As the terms in NeuroSynth do not fully overlap with the terms used in our database, not every term has a prediction score with NeuroSynth. The ontology-informed decoder is almost always able to assign the right cognitive concepts to an unknown task and clearly out-performs standards decoders: logistic regression and naive Bayes classifier trained on our database. It also outperforms the NeuroSynth decoding based on meta-analysis.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.g005" xlink:type="simple"/>
</fig>
<p>Very general labels such a “visual” are found in most studies, and therefore easy to predict. However, higher-level or more specialized cognitive concepts such as viewing digits or moving the left foot are seldom present (see <xref ref-type="supplementary-material" rid="pcbi.1006565.s001">S1 Text</xref> Distribution of terms in our database). For these rare labels, the fraction of prediction errors is not a useful measure. Indeed, simply assigning them to zero images would lead to a small fraction of errors. For this reason, <xref ref-type="fig" rid="pcbi.1006565.g005">Fig 5</xref> reports the area under the receiver operating characteristic (ROC) curve. This is a standard metric that summarizes both false positives and false negatives and is not biased for rare labels. This analysis showed that even for relatively rare concepts, successful decoding was possible.</p>
</sec>
<sec id="sec017">
<title>Regions in our functional atlas</title>
<p>Our approach links different cognitive terms to functionally-specialized brain regions:</p>
<sec id="sec018">
<title>Visual regions</title>
<p>(<xref ref-type="fig" rid="pcbi.1006565.g006">Fig 6a</xref>) Visual object recognition is linked to the ventral stream of specialized regions: primary visual areas associated with vertical and horizontal checkerboards in a basic but accurate retinotopic mapping; regions in the LOC linked to objects and scrambled objects; the Fusiform Face Area (FFA) and parahippocampal place area (PPA) associated respectively with “faces” and “places” terms; the region called visual word form area (VWFA) [<xref ref-type="bibr" rid="pcbi.1006565.ref028">28</xref>] linked to word recognition. Interestingly, both amygdalas also appear related to faces, which could be due to emotional effects of face processing not modeled in the ontology. Digit-viewing does not outline meaningful regions. Corresponding decoding scores are poor (<xref ref-type="fig" rid="pcbi.1006565.g005">Fig 5</xref>): our database is not suited to cross-study mapping of digit viewing. This example confirms that decoding scores can serve as Occam’s razor, validating or falsifying functional regions.</p>
<fig id="pcbi.1006565.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006565.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Functional atlases with decoding in an ontology.</title>
<p>Regions linked to the various cognitive terms by our mapping approach. They are displayed in 5 different panels depending on their location in the brain: a. visual regions; b. auditory regions; c. motor regions; d. parietal regions; e.cerebellum regions.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec019">
<title>Auditory regions</title>
<p>(<xref ref-type="fig" rid="pcbi.1006565.g006">Fig 6b</xref>) Four cognitive terms are represented in the temporal lobe: “auditory”, “sounds”, “language”, and “human voice”. These correspond to increasingly specific concepts in our ontology, and map increasingly focal regions: The “auditory” label denotes the stimulus modality, a fairly general concept, and is linked to the entire auditory cortex. The more precise “sounds” label is associated with Heschl’s gyrus. The “language” label highlights a prototypical left-lateralized language network: anterior and posterior superior temporal sulcus (STS), temporal lobe, supramarginal gyrus, and Broca’s area. The “human voice” label reveals regions in the upper bank of the STS that were previous identified as voice-selective regions by contrasting human voices with closely-matched scrambled voices control conditions [<xref ref-type="bibr" rid="pcbi.1006565.ref029">29</xref>]. That the mapping singles out such regions from the data is an impressive feat given that only one study in our database [<xref ref-type="bibr" rid="pcbi.1006565.ref030">30</xref>] features both human voices and non-voice auditory conditions.</p>
</sec>
<sec id="sec020">
<title>Motor regions</title>
<p>(<xref ref-type="fig" rid="pcbi.1006565.g006">Fig 6c</xref>) Motor labels reveal the lateralized hands and feet representations in the primary motor cortex, as well as in the cerebellum.</p>
</sec>
<sec id="sec021">
<title>Parietal regions</title>
<p>(<xref ref-type="fig" rid="pcbi.1006565.g006">Fig 6d</xref>) Saccadic eye movements and mental arithmetic are known to recruit almost overlapping parietal areas [<xref ref-type="bibr" rid="pcbi.1006565.ref002">2</xref>], which are difficult to separate with standard analysis. In the IPS (intra-parietal sulcus), we find bilateral regions for saccades but calculation appears left lateralized, consistent with previous reports [<xref ref-type="bibr" rid="pcbi.1006565.ref031">31</xref>]. Cross-study analysis of activation maps is important to study such nearly-colocalized functions from different cognitive domains. Indeed, meta-analysis based on coordinates suffers a loss of spatial resolution (<xref ref-type="fig" rid="pcbi.1006565.g003">Fig 3e</xref>).</p>
</sec>
<sec id="sec022">
<title>Cerebellar regions</title>
<p>While the cerebellum is involved in a variety of mental processes, there are very few systematic mapping results. Previous work [<xref ref-type="bibr" rid="pcbi.1006565.ref032">32</xref>] studied the somatotopic organization of the cerebellum visible on <xref ref-type="fig" rid="pcbi.1006565.g006">Fig 6c</xref>, with an inverted laterality of functional areas with respect to cortical somatotopy. Other higher-level cognitive functions are represented in the cerebellum with the same inversion. Notably our analysis links the “language” term to a right-lateralized cerebellum region in Crus II (<xref ref-type="fig" rid="pcbi.1006565.g006">Fig 6e</xref>), consistent with language studies [<xref ref-type="bibr" rid="pcbi.1006565.ref033">33</xref>]. Finally, the “calculation” term is also represented in the right cerebellar cortex, in the superior medial section of the lobule VI. This location has been linked to working memory [<xref ref-type="bibr" rid="pcbi.1006565.ref034">34</xref>]. It appears here linked to calculation, consistent with the fact that mental arithmetic has a strong working-memory component [<xref ref-type="bibr" rid="pcbi.1006565.ref035">35</xref>], and our cognitive ontology does not explicitly model working memory.</p>
</sec>
</sec>
</sec>
<sec id="sec023" sec-type="conclusions">
<title>Discussion</title>
<p>The inference framework introduced here represents a new approach to developing functional atlases of the human brain. It formally characterizes representations for various cognitive processes that evoke overlapping brain responses, and makes it possible to pool many task-fMRI experiments probing different cognitive domains. Existing meta-analysis approaches face the risk of being unspecific, as demonstrated by our standard analysis results on our database (Figs <xref ref-type="fig" rid="pcbi.1006565.g003">3</xref> and <xref ref-type="fig" rid="pcbi.1006565.g004">4</xref>). Databases of coordinates, such as NeuroSynth, can more easily accumulate data on many different cognitive concepts and support formal reverse inference. This data accumulation is promising, but existing reverse-inference approaches do not suffice to fully remove the overlap in functional regions (<xref ref-type="fig" rid="pcbi.1006565.g006">Fig 6</xref>). Our approach gives more differentiated maps for cognitive concepts by analyzing them in a way that leverages the cognitive ontology. They are also sharper, presumably because they are derived from images rather than coordinates. In a multi-modal framework [<xref ref-type="bibr" rid="pcbi.1006565.ref017">17</xref>], these maps could be combined with resting-state and anatomical data to provide cognitive resolution to brain parcellations. Note that our framework is meant to be used at the population level and does not address individual brain mapping or decoding.</p>
<sec id="sec024">
<title>Reverse inference mapping</title>
<p>Our analysis framework overcomes the loss in specificity typical of data aggregation. As a result, it enables analyzing jointly more cognitive processes. These richer models can map qualitatively different information. Analyzing more diverse databases of brain functional images can bring together two central brain-mapping questions: <italic>where</italic> is a given cognitive process implemented, and <italic>what</italic> cognitive processes are represented by a given brain structure. Answers to the “what” question have traditionally been provided by invasive studies or neurological lesion reports. Indeed, in a given fMRI study, brain activity results from the task. Concluding on what processes are implied by the observed activity risks merely capturing this task. Decoding across studies can answer this question, by demonstrating the ability to perform accurate inference from brain activity to cognitive function [<xref ref-type="bibr" rid="pcbi.1006565.ref036">36</xref>].</p>
<p>Reverse-inference maps are essential to functional brain mapping. A key insight comes from the analysis in NeuroSynth [<xref ref-type="bibr" rid="pcbi.1006565.ref009">9</xref>]: some brain structures are activated in many tasks. Hence, a standard analysis –forward inference– showing such a structure as activated does not provide much information about what function is being engaged. Reverse inference puts the observed brain activity in a wider context by characterizing the behavior that it implies. The analysis performed in NeuroSynth accounts for the multiple tasks that activate a given structure, performing a Bayesian inversion with the so-called <italic>Naive Bayes</italic> model; however, it does not account for other activation foci in the brain that characterize the function. Put differently, our approach departs from the model used by NeuroSynth for reverse inference by what it conditions upon: NeuroSynth’s model asserts functional specialization <italic>conditional to</italic> other terms, while we condition on other brain locations when predicting concept occurrence. This difference should be kept in mind when interpreting differences between the two types of approaches. The Inferior Temporal Gyrus (ITG), for instance, is more active in object-recognition tasks than in other paradigms. However, observing activity in the ITG does not help deciding whether the subject is recognizing faces or other types of objects: the information is in the Fusiform gyrus. An important difference between reverse-inference maps with a Naive Bayes –as in Neurosynth– and using a linear model –as in our approach– is that the Naive Bayes maps do no capture dependencies across voxels. On the opposite, linear models map how brain activity in a voxel relates to behavior <italic>conditionally</italic> on other voxels. Technically, this is the reason why Neurosynth reverse-inference maps related to object recognition overlap in the IT cortex (<xref ref-type="fig" rid="pcbi.1006565.g003">Fig 3e</xref>) while maps produced by our approach separate the representations of the various terms in the ventral mosaic (<xref ref-type="fig" rid="pcbi.1006565.g003">Fig 3d</xref>).</p>
<p>Another, more subtle, benefit of the two-layer model over more classical multi-label approaches is that it combines the decisions of classifiers based on subsets of the data, such as the OvO classifiers, which helps learning relevant local discriminative information.</p>
<p>In sum, our mapping approach provides a different type of brain maps: They quantify how much observing activity in a given brain location, as opposed to other brain locations, informs on whether the subject was engaged in a cognitive operation.</p>
</sec>
<sec id="sec025">
<title>Generalizing beyond single studies</title>
<p>Brain functional atlases are hard to falsify: is a functional atlas specific to the experimental paradigms employed to build it, or is it more generally characteristic of human brain organization? The success of statistically-grounded reverse inference, which generalizes to new paradigms from unseen studies, suggests that there must be some degree of generality in the present atlas. In demonstrating this generalization, the present work goes beyond previous work that had shown generalization to new subjects under known task conditions [<xref ref-type="bibr" rid="pcbi.1006565.ref012">12</xref>], but not to unknown protocols. However, it is worth noting that here too we found that it was easier to predict on held-out subjects (from one of the training studies) than on held-out studies (see <xref ref-type="supplementary-material" rid="pcbi.1006565.s006">S6 Text</xref> Evaluating prediction accuracy: cross-validation), consistent with a substantial effect of the specific task (see <xref ref-type="supplementary-material" rid="pcbi.1006565.s002">S2 Text</xref> Similarities of activations across the database). Despite this, our ontology-enabled approach was able to successfully predict cognitive processes for new tasks. Interestingly, it opens the possibility to perform prospective decoding analyses on novel data, hence makes it easier to grasp the added information of incoming data.</p>
<p>To enable this generalization across paradigms, we characterize each task by the multiple cognitive concepts that it recruits, that are specified in the ontology. Departing from the subtractions often used in brain mapping, our framework relies on quantifying full descriptions of the tasks. In the context of decoding, this approach leads to <italic>multi-label prediction</italic>, predicting multiple terms for an activation map, as opposed to <italic>multi-class prediction</italic>, used in prior works [<xref ref-type="bibr" rid="pcbi.1006565.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1006565.ref016">16</xref>], that assigns each new map to a single class. The use of the multi-label approach combined with an ontology capturing the relationships between terms provides a principled way of modeling the multiple components of cognition and thus avoids the need for hand-crafted oppositions that are customarily used in subtraction studies. Defining good ontologies is yet another challenge for the community, but it is not unlikely that brain imaging will become part of that process [<xref ref-type="bibr" rid="pcbi.1006565.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1006565.ref037">37</xref>]. Providing a methodological approach founded on an explicit hierarchy of cognitive concepts would allow to test for different cognitive ontologies, and, provided with a comparison metric, select the best ontology according to the available data. Although the present analysis is limited to a relatively small set of cognitive functions, such an approach will be essential as the field attempts to scale such analyses to the breadth of human cognition.</p>
</sec>
<sec id="sec026">
<title>Conclusion</title>
<p>To build brain functional atlases that map many cognitive processes, we have found that reverse inference and an ontology relating these processes were key ingredients. Indeed, because of the experimental devices used in cognitive neuroimaging, some regions –e.g. attentional or sensory regions– tend to be overly represented in forward inferences. An ontology encodes the related cognitive processes that must be studied together to best establish forward or reverse inferences.</p>
<p>Using a relatively small number of independent task fMRI datasets, our brain-mapping approach reconciles the conundrum of multiple cognitive processes/labels mapping to often overlapping brain regions in activation studies. More data will enable even more fine-grained process-region mappings. In particular higher-level cognitive processes elude the present work, limited by the amount and the diversity of the studies in our database. Indeed, high-level terms form very rare classes in the datasets employed here (see <xref ref-type="supplementary-material" rid="pcbi.1006565.s001">S1 Text</xref> Distribution of terms in our database). With increased data sharing in the neuroimaging community [<xref ref-type="bibr" rid="pcbi.1006565.ref038">38</xref>], there is a growing opportunity to perform this kind of analysis on a much larger scale, ultimately providing a comprehensive atlas of neurocognitive organization. A major challenge to such analyses is the need for detailed task annotation; whereas annotation of task features such as the response effector is relatively straightforward, annotation of complex cognitive processes (e.g., whether a task involves attentional selection or working memory maintenance) is challenging and often contentious. The utility of the ontology in the present work suggests that this effort is worthwhile, and that the increased utilization of ontologies in cognitive neuroscience may be an essential component to solving the problem of how cognitive function is organized in the brain.</p>
</sec>
</sec>
<sec id="sec027">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006565.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Distribution of terms in our database.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Similarities of activations across the database.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s003" xlink:type="simple">
<label>S3 Text</label>
<caption>
<title>Forward analysis: Ontology-based design across studies.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s004" xlink:type="simple">
<label>S4 Text</label>
<caption>
<title>Reverse inference: Decoding with cognitive ontologies.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s005" xlink:type="simple">
<label>S5 Text</label>
<caption>
<title>Consensus between forward and reverse inference.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s006" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s006" xlink:type="simple">
<label>S6 Text</label>
<caption>
<title>Evaluating prediction accuracy: Cross-validation.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s007" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s007" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Term distribution.</title>
<p>The number of times a term appears in our database, per map, subject, or study.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s008" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s008" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Terms distribution in studies.</title>
<p>Percentage of term occurrence in each study.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s009" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s009" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Histograms of the distances between brain activity images.</title>
<p>Pairwise distances across all the images of our 30-study database: comparing all images, images sharing a cognitive label, in the same study, or in the same exact contrast.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s010" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s010" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Term effect for the “place” term.</title>
<p>The “place” term denotes visual place recognition tasks. As such a task involves viewing images, it recruits also the low-level and mid-level visual areas.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s011" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s011" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Terms correlations.</title>
<p>Correlation matrix between terms across images.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s012" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s012" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>Ontology contrasts for the “place” term.</title>
<p>We contrast the “place” with other visual recognition tasks as defined in <xref ref-type="supplementary-material" rid="pcbi.1006565.s019">S4 Table</xref>: recognizing faces, objects, and scrambled images. The contrast is efficient at suppressing low-level visual areas, but does not completely remove mid-level visual areas. Indeed, mid-level features are probably not balanced across studies, as some objects with no background, some full pictures of objects, and some cropped pictures.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s013" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s013" xlink:type="simple">
<label>S7 Fig</label>
<caption>
<title>Maps for consensus between forward and reverse.</title>
<p>Left: maps for the different inferences on the “place” concept. Right: the overlaid inferences for this concept. The consensus singles out the PPA for the “place” concept.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s014" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s014" xlink:type="simple">
<label>S8 Fig</label>
<caption>
<title>Distributions of the z-scores for forward and reverse inference.</title>
<p>For the maps related to the <italic>place</italic> concept. <bold>Right</bold>: raw p-values. <bold>Left</bold>: after normalization.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s015" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s015" xlink:type="simple">
<label>S9 Fig</label>
<caption>
<title>Prediction scores for different methods.</title>
<p>AUC (area under the curve) of the ROC. OD: ontology decoding, LOG: logistic, NB: Naive Bayes. Left: leave-subject-out cross-validation, Right: leave-study-out cross-validation.</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s016" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s016" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Studies in the database.</title>
<p>The subject-level maps output by our preprocessing and first-level analysis have been uploaded to NeuroVault, for reproducibility of the analysis. These maps form the input of our analytic scheme. All the subject-level statistical maps that we computed as part of our preprocessing are available on <ext-link ext-link-type="uri" xlink:href="http://neurovault.org/collections/1952" xlink:type="simple">http://neurovault.org/collections/1952</ext-link>.</p>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s017" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s017" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>First-level classifiers used.</title>
<p>We train three types of classifier to learn the hierarchy of terms: category classifiers (with a OvA approach), and terms classifiers (both with OvA and OvO approaches). The classifiers’ decision functions span an intermediate feature space tailored to our ontology, upon which we perform a standard OvA approach to predict our labels.</p>
<p>(XLSX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s018" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s018" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>Prediction scores for different methods.</title>
<p>AUC (area under the curve) of the ROC curve. OD: ontology decoding, LOG: logistic regression, NB: Naive Bayes, NS: NeuroSynth. The OD (ontology decoding) method performs very well (chance is at .5), including when predicting to new studies. Leave-subject-out cross-validation scheme tend to display a higher prediction score than with a leave-study-out cross-validation. This higher prediction accuracy corroborates the observation that activations in the same study are more similar than activations related to the same cognitive term (<xref ref-type="supplementary-material" rid="pcbi.1006565.s009">S3 Fig</xref>).</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006565.s019" mimetype="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006565.s019" xlink:type="simple">
<label>S4 Table</label>
<caption>
<title>Terms and categories we use to characterize tasks associated with images in our database.</title>
<p>We used CogPO categories for task-related description, and add necessary terms from Cognitive Atlas to describe higher-level cognitive aspect. Here we report only terms that were present in more than one study—aside from the “left foot”, which maps in the analysis as maps in “feet” task category, but not “right foot”. The task categories group terms typically used as conditions and their controls to test a hypothesis. The <italic>stimulus modality</italic> category stands for CogPO and task categories. Some terms do not belong to any task category and are referred as such. The <italic>arithmetics</italic> task category spans across the <italic>response modality</italic> and <italic>instructions</italic> CogPO categories.</p>
<p>(XLSX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006565.ref001">
<label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Newell A. You can’t play 20 questions with nature and win: Projective comments on the papers of this symposium. In: Visual information processing; 1973.</mixed-citation>
</ref>
<ref id="pcbi.1006565.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Knops</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Thirion</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Hubbard</surname> <given-names>EM</given-names></name>, <name name-style="western"><surname>Michel</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>. <article-title>Recruitment of an area involved in eye movements during mental arithmetic</article-title>. <source>Science</source>. <year>2009</year>;<volume>324</volume>:<fpage>1583</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1171599" xlink:type="simple">10.1126/science.1171599</ext-link></comment> <object-id pub-id-type="pmid">19423779</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dosenbach</surname> <given-names>NU</given-names></name>, <name name-style="western"><surname>Fair</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Miezin</surname> <given-names>FM</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Wenger</surname> <given-names>KK</given-names></name>, <name name-style="western"><surname>Dosenbach</surname> <given-names>RA</given-names></name>, <etal>et al</etal>. <article-title>Distinct brain networks for adaptive and stable task control in humans</article-title>. <source>P Natl Acad Sci Usa</source>. <year>2007</year>;<volume>104</volume>:<fpage>11073</fpage>–<lpage>11078</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0704320104" xlink:type="simple">10.1073/pnas.0704320104</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bzdok</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hartwigsen</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Reid</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Laird</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PT</given-names></name>, <name name-style="western"><surname>Eickhoff</surname> <given-names>SB</given-names></name>. <article-title>Left inferior parietal lobe engagement in social cognition and language</article-title>. <source>Neurosci &amp; Biobehav Rev</source>. <year>2016</year>;. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neubiorev.2016.02.024" xlink:type="simple">10.1016/j.neubiorev.2016.02.024</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Price</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Cognitive conjunction: a new approach to brain activation experiments</article-title>. <source>Neuroimage</source>. <year>1997</year>;<volume>5</volume>:<fpage>261</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.1997.0269" xlink:type="simple">10.1006/nimg.1997.0269</ext-link></comment> <object-id pub-id-type="pmid">9345555</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thyreau</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Schwartz</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Thirion</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Frouin</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Loth</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Vollstädt-Klein</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Very large fMRI study using the IMAGEN database: Sensitivity—specificity and population effect modeling in relation to the underlying anatomy</article-title>. <source>NeuroImage</source>. <year>2012</year>;<volume>61</volume>:<fpage>295</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2012.02.083" xlink:type="simple">10.1016/j.neuroimage.2012.02.083</ext-link></comment> <object-id pub-id-type="pmid">22425669</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Henson</surname> <given-names>R</given-names></name>. <article-title>Forward inference using functional neuroimaging: Dissociations versus associations</article-title>. <source>Trends Cogn Sci</source>. <year>2006</year>;<volume>10</volume>:<fpage>64</fpage>–<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2005.12.005" xlink:type="simple">10.1016/j.tics.2005.12.005</ext-link></comment> <object-id pub-id-type="pmid">16406759</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Poldrack</surname> <given-names>R</given-names></name>. <article-title>Can cognitive processes be inferred from neuroimaging data?</article-title> <source>Trends Cogn Sci</source>. <year>2006</year>;<volume>10</volume>:<fpage>59</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2005.12.004" xlink:type="simple">10.1016/j.tics.2005.12.004</ext-link></comment> <object-id pub-id-type="pmid">16406760</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yarkoni</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Poldrack</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Nichols</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Essen</surname> <given-names>DV</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>T</given-names></name>. <article-title>Large-scale automated synthesis of human functional neuroimaging data</article-title>. <source>Nat Methods</source>. <year>2011</year>;<volume>8</volume>:<fpage>665</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nmeth.1635" xlink:type="simple">10.1038/nmeth.1635</ext-link></comment> <object-id pub-id-type="pmid">21706013</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Atlas</surname> <given-names>LY</given-names></name>, <name name-style="western"><surname>Botvinick</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Chang</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Coghill</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>KD</given-names></name>, <etal>et al</etal>. <article-title>Pain in the ACC?</article-title> <source>Proc Natl Acad Sci USA</source>. <year>2016</year>;<volume>113</volume>:<fpage>E2474</fpage>–<lpage>E2475</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1600282113" xlink:type="simple">10.1073/pnas.1600282113</ext-link></comment> <object-id pub-id-type="pmid">27095849</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lieberman</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Burns</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Torre</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Eisenberger</surname> <given-names>NI</given-names></name>. <article-title>Reply to Wager et al.: Pain and the dACC: The importance of hit rate-adjusted effects and posterior probabilities with fair priors</article-title>. <source>Proc Natl Acad Sci USA</source>. <year>2016</year>; p. 201603186. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1603186113" xlink:type="simple">10.1073/pnas.1603186113</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Halchenko</surname> <given-names>YO</given-names></name>, <name name-style="western"><surname>Hanson</surname> <given-names>SJ</given-names></name>. <article-title>Decoding the large-scale structure of brain function by classifying mental states across individuals</article-title>. <source>Psychol Sci</source>. <year>2009</year>;<volume>20</volume>:<fpage>1364</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1467-9280.2009.02460.x" xlink:type="simple">10.1111/j.1467-9280.2009.02460.x</ext-link></comment> <object-id pub-id-type="pmid">19883493</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Price</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Functional ontologies for cognition: The systematic definition of structure and function</article-title>. <source>Cognitive Neuropsychology</source>. <year>2005</year>;<volume>22</volume>:<fpage>262</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/02643290442000095" xlink:type="simple">10.1080/02643290442000095</ext-link></comment> <object-id pub-id-type="pmid">21038249</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Kittur</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kalar</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Seppa</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Gil</surname> <given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>The cognitive atlas: toward a knowledge foundation for cognitive neuroscience</article-title>. <source>Front neuroinform</source>. <year>2011</year>;<volume>5</volume>:<fpage>17</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fninf.2011.00017" xlink:type="simple">10.3389/fninf.2011.00017</ext-link></comment> <object-id pub-id-type="pmid">21922006</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Turner</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Laird</surname> <given-names>A</given-names></name>. <article-title>The cognitive paradigm ontology: design and application</article-title>. <source>Neuroinformatics</source>. <year>2012</year>;<volume>10</volume>:<fpage>57</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s12021-011-9126-x" xlink:type="simple">10.1007/s12021-011-9126-x</ext-link></comment> <object-id pub-id-type="pmid">21643732</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Atlas</surname> <given-names>LY</given-names></name>, <name name-style="western"><surname>Lindquist</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Roy</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Woo</surname> <given-names>CW</given-names></name>, <name name-style="western"><surname>Kross</surname> <given-names>E</given-names></name>. <article-title>An fMRI-based neurologic signature of physical pain</article-title>. <source>N Engl J Med</source>. <year>2013</year>;<volume>368</volume>:<fpage>1388</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1056/NEJMoa1204471" xlink:type="simple">10.1056/NEJMoa1204471</ext-link></comment> <object-id pub-id-type="pmid">23574118</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Glasser</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Coalson</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hacker</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Harwell</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Yacoub</surname> <given-names>E</given-names></name>, <etal>et al</etal>. <article-title>A Multi-modal parcellation of human cerebral cortex</article-title>. <source>Nature</source>. <year>2016</year>;<volume>536</volume>:<fpage>171</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature18933" xlink:type="simple">10.1038/nature18933</ext-link></comment> <object-id pub-id-type="pmid">27437579</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laird</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Lancaster</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>P</given-names></name>. <article-title>Brainmap</article-title>. <source>Neuroinformatics</source>. <year>2005</year>;<volume>3</volume>:<fpage>65</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1385/NI:3:1:065" xlink:type="simple">10.1385/NI:3:1:065</ext-link></comment> <object-id pub-id-type="pmid">15897617</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PT</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Glahn</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Mackay</surname> <given-names>CE</given-names></name>, <etal>et al</etal>. <article-title>Correspondence of the brain’s functional architecture during activation and rest</article-title>. <source>Proc Natl Acad Sci</source>. <year>2009</year>;<volume>106</volume>:<fpage>13040</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.0905267106" xlink:type="simple">10.1073/pnas.0905267106</ext-link></comment> <object-id pub-id-type="pmid">19620724</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Laird</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Eickhoff</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Ray</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>McKay</surname> <given-names>DR</given-names></name>, <etal>et al</etal>. <article-title>Behavioral interpretations of intrinsic connectivity networks</article-title>. <source>J cog neurosci</source>. <year>2011</year>;<volume>23</volume>:<fpage>4022</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/jocn_a_00077" xlink:type="simple">10.1162/jocn_a_00077</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chang</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Yarkoni</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Khaw</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Sanfey</surname> <given-names>AG</given-names></name>. <article-title>Decoding the role of the insula in human cognition: functional parcellation and large-scale reverse inference</article-title>. <source>Cereb Cortex</source>. <year>2012</year>; p. bhs065.</mixed-citation>
</ref>
<ref id="pcbi.1006565.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bzdok</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Langner</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Laird</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Fox</surname> <given-names>PT</given-names></name>, <name name-style="western"><surname>Palomero-Gallagher</surname> <given-names>N</given-names></name>, <etal>et al</etal>. <article-title>Subspecialization in the human posterior medial cortex</article-title>. <source>Neuroimage</source>. <year>2015</year>;<volume>106</volume>:<fpage>55</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2014.11.009" xlink:type="simple">10.1016/j.neuroimage.2014.11.009</ext-link></comment> <object-id pub-id-type="pmid">25462801</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cole</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Bassett</surname> <given-names>DS</given-names></name>, <name name-style="western"><surname>Power</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Braver</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Petersen</surname> <given-names>SE</given-names></name>. <article-title>Intrinsic and task-evoked network architectures of the human brain</article-title>. <source>Neuron</source>. <year>2014</year>;<volume>83</volume>:<fpage>238</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2014.05.014" xlink:type="simple">10.1016/j.neuron.2014.05.014</ext-link></comment> <object-id pub-id-type="pmid">24991964</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Barch</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Mitchell</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wager</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Devlin</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Towards open sharing of task-based fMRI data: The OpenfMRI project</article-title>. <source>Front Neuroinform</source>. <year>2013</year>;<volume>7</volume>:<fpage>12</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fninf.2013.00012" xlink:type="simple">10.3389/fninf.2013.00012</ext-link></comment> <object-id pub-id-type="pmid">23847528</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Breiman</surname> <given-names>L</given-names></name>. <article-title>Stacked regressions</article-title>. <source>Machine learning</source>. <year>1996</year>;<volume>24</volume>:<fpage>49</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF00117832" xlink:type="simple">10.1007/BF00117832</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haufe</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Meinecke</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Görgen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dähne</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Haynes</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Blankertz</surname> <given-names>B</given-names></name>, <etal>et al</etal>. <article-title>On the interpretation of weight vectors of linear models in multivariate neuroimaging</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>87</volume>:<fpage>96</fpage>–<lpage>110</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.10.067" xlink:type="simple">10.1016/j.neuroimage.2013.10.067</ext-link></comment> <object-id pub-id-type="pmid">24239590</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Weichwald</surname> <given-names>Sebastian</given-names></name>, <name name-style="western"><surname>Meyer</surname> <given-names>Timm</given-names></name>, <name name-style="western"><surname>Özdenizci</surname> <given-names>Ozan</given-names></name>, <name name-style="western"><surname>Schölkopf</surname> <given-names>Bernhard</given-names></name>, <name name-style="western"><surname>Ball</surname> <given-names>Tonio</given-names></name>, and <name name-style="western"><surname>Grosse-Wentrup</surname> <given-names>Moritz</given-names></name>. <article-title>Causal interpretation rules for encoding and decoding models in neuroimaging</article-title>. <source><italic>NeuroImage</italic></source>, <volume>110</volume>:<fpage>48</fpage>–<lpage>59</lpage>, <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2015.01.036" xlink:type="simple">10.1016/j.neuroimage.2015.01.036</ext-link></comment> <object-id pub-id-type="pmid">25623501</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cohen</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>. <article-title>Specialization within the ventral stream: the case for the visual word form area</article-title>. <source>NeuroImage</source>. <year>2004</year>;<volume>22</volume>:<fpage>466</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2003.12.049" xlink:type="simple">10.1016/j.neuroimage.2003.12.049</ext-link></comment> <object-id pub-id-type="pmid">15110040</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Belin</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Zatorre</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Lafaille</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ahad</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Pike</surname> <given-names>B</given-names></name>. <article-title>Voice-selective areas in human auditory cortex</article-title>. <source>Nature</source>. <year>2000</year>;<volume>403</volume>:<fpage>309</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/35002078" xlink:type="simple">10.1038/35002078</ext-link></comment> <object-id pub-id-type="pmid">10659849</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pinel</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>. <article-title>Genetic and environmental contributions to brain activation during calculation</article-title>. <source>NeuroImage</source>. <year>2013</year>;<volume>81</volume>:<fpage>306</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.04.118" xlink:type="simple">10.1016/j.neuroimage.2013.04.118</ext-link></comment> <object-id pub-id-type="pmid">23664947</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Andres</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Seron</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Olivier</surname> <given-names>E</given-names></name>. <article-title>Hemispheric lateralization of number comparison</article-title>. <source>Cognitive Brain Research</source>. <year>2005</year>;<volume>25</volume>:<fpage>283</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cogbrainres.2005.06.002" xlink:type="simple">10.1016/j.cogbrainres.2005.06.002</ext-link></comment> <object-id pub-id-type="pmid">16005617</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Grodd</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Hulsmann</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Lotze</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wildgruber</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Erb</surname> <given-names>M</given-names></name>. <article-title>Sensorimotor mapping of the human cerebellum: fMRI evidence of somatotopic organization</article-title>. <source>Hum brain mapp</source>. <year>2001</year>;<volume>13</volume>:<fpage>55</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/hbm.1025" xlink:type="simple">10.1002/hbm.1025</ext-link></comment> <object-id pub-id-type="pmid">11346886</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stoodley</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Schmahmann</surname> <given-names>JD</given-names></name>. <article-title>Functional topography in the human cerebellum: a meta-analysis of neuroimaging studies</article-title>. <source>Neuroimage</source>. <year>2009</year>;<volume>44</volume>:<fpage>489</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2008.08.039" xlink:type="simple">10.1016/j.neuroimage.2008.08.039</ext-link></comment> <object-id pub-id-type="pmid">18835452</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Durisko</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fiez</surname> <given-names>JA</given-names></name>. <article-title>Functional activation in the cerebellum during working memory and simple speech tasks</article-title>. <source>Cortex</source>. <year>2010</year>;<volume>46</volume>:<fpage>896</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cortex.2009.09.009" xlink:type="simple">10.1016/j.cortex.2009.09.009</ext-link></comment> <object-id pub-id-type="pmid">19853247</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zago</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Pesenti</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mellet</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Crivello</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Mazoyer</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Tzourio-Mazoyer</surname> <given-names>N</given-names></name>. <article-title>Neural correlates of simple and complex mental calculation</article-title>. <source>Neuroimage</source>. <year>2001</year>;<volume>13</volume>:<fpage>314</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.2000.0697" xlink:type="simple">10.1006/nimg.2000.0697</ext-link></comment> <object-id pub-id-type="pmid">11162272</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Yarkoni</surname> <given-names>T</given-names></name>. <article-title>From brain maps to cognitive ontologies: Informatics and the search for mental structure</article-title>. <source>Annual review of psychology</source>. <year>2016</year>;<volume>67</volume>:<fpage>587</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-psych-122414-033729" xlink:type="simple">10.1146/annurev-psych-122414-033729</ext-link></comment> <object-id pub-id-type="pmid">26393866</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bzdok</surname> <given-names>Danilo</given-names></name>, <name name-style="western"><surname>Yeo</surname> <given-names>Thomas B T</given-names></name>. <article-title>Inference in the age of big data: Future perspectives on neuroscience</article-title>. <source><italic>NeuroImage</italic></source>, <volume>155</volume>:<fpage>549</fpage>–<lpage>564</lpage>, <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2017.04.061" xlink:type="simple">10.1016/j.neuroimage.2017.04.061</ext-link></comment> <object-id pub-id-type="pmid">28456584</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006565.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Gorgolewski</surname> <given-names>KJ</given-names></name>. <article-title>Making big data open: data sharing in neuroimaging</article-title>. <source>Nat neurosci</source>. <year>2014</year>;<volume>17</volume>:<fpage>1510</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3818" xlink:type="simple">10.1038/nn.3818</ext-link></comment> <object-id pub-id-type="pmid">25349916</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
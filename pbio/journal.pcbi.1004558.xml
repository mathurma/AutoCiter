<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004558</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-02258</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Modeling the Evolution of Beliefs Using an Attentional Focus Mechanism</article-title>
<alt-title alt-title-type="running-head">Updating Beliefs Using an Attention-Like Mechanism</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Marković</surname>
<given-names>Dimitrije</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
<xref rid="cor001" ref-type="corresp">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Gläscher</surname>
<given-names>Jan</given-names>
</name>
<xref rid="aff003" ref-type="aff"><sup>3</sup></xref>
<xref rid="aff004" ref-type="aff"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Bossaerts</surname>
<given-names>Peter</given-names>
</name>
<xref rid="aff004" ref-type="aff"><sup>4</sup></xref>
<xref rid="aff005" ref-type="aff"><sup>5</sup></xref>
<xref rid="aff006" ref-type="aff"><sup>6</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>O’Doherty</surname>
<given-names>John</given-names>
</name>
<xref rid="aff004" ref-type="aff"><sup>4</sup></xref>
<xref rid="aff006" ref-type="aff"><sup>6</sup></xref>
<xref rid="aff007" ref-type="aff"><sup>7</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Kiebel</surname>
<given-names>Stefan J.</given-names>
</name>
<xref rid="aff001" ref-type="aff"><sup>1</sup></xref>
<xref rid="aff002" ref-type="aff"><sup>2</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Psychology, Technical University Dresden, Dresden, Germany</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Institute for Systems Neuroscience, University Medical Center Hamburg-Eppendorf, Hamburg, Germany</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>Division of Humanities and Social Sciences, California Institute of Technology, Pasadena, California, United States of America</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Department of Finance, University of Utah, Salt Lake City, United States of America</addr-line></aff>
<aff id="aff006"><label>6</label> <addr-line>Computation and Neural Systems, California Institute of Technology, Pasadena, California, United States of America</addr-line></aff>
<aff id="aff007"><label>7</label> <addr-line>Trinity College Institute of Neuroscience, Trinity College Dublin, Dublin, Ireland</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Einhäuser</surname>
<given-names>Wolfgang</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Technische Universitat Chemnitz, GERMANY</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: JG JO PB. Performed the experiments: JG. Analyzed the data: DM SJK. Wrote the paper: DM SJK.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">dimitrije.markovic@tu-dresden.de</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>23</day>
<month>10</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>10</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>10</issue>
<elocation-id>e1004558</elocation-id>
<history>
<date date-type="received">
<day>16</day>
<month>12</month>
<year>2014</year>
</date>
<date date-type="accepted">
<day>1</day>
<month>9</month>
<year>2015</year>
</date>
</history>
<permissions>
<license xlink:href="https://creativecommons.org/publicdomain/zero/1.0/" xlink:type="simple">
<license-p>This is an open access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/publicdomain/zero/1.0/" xlink:type="simple">Creative Commons CC0</ext-link> public domain dedication</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004558" xlink:type="simple"/>
<abstract>
<p>For making decisions in everyday life we often have first to infer the set of environmental features that are relevant for the current task. Here we investigated the computational mechanisms underlying the evolution of beliefs about the relevance of environmental features in a dynamical and noisy environment. For this purpose we designed a probabilistic Wisconsin card sorting task (WCST) with belief solicitation, in which subjects were presented with stimuli composed of multiple visual features. At each moment in time a particular feature was relevant for obtaining reward, and participants had to infer which feature was relevant and report their beliefs accordingly. To test the hypothesis that attentional focus modulates the belief update process, we derived and fitted several probabilistic and non-probabilistic behavioral models, which either incorporate a dynamical model of attentional focus, in the form of a hierarchical winner-take-all neuronal network, or a diffusive model, without attention-like features. We used Bayesian model selection to identify the most likely generative model of subjects’ behavior and found that attention-like features in the behavioral model are essential for explaining subjects’ responses. Furthermore, we demonstrate a method for integrating both connectionist and Bayesian models of decision making within a single framework that allowed us to infer hidden belief processes of human subjects.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>When making decisions in our everyday life (<italic>e</italic>.<italic>g</italic>. where to eat) we first have to identify a set of environmental features that are relevant for the decision (e.g. the distance to the place, current time or the price). Although we are able to make such inferences almost effortlessly, this type of problems is computationally challenging, as we live in a complex environment that constantly changes and contains an immense number of features. Here we investigated the question of how the human brain solves this computational challenge. In particular, we designed a new experimental paradigm and derived novel behavioral models to test the hypothesis that attention modulates the formation of beliefs about the relevance of several environmental features. As each behavioral model accounted for a different hypothesis about the underlying computational mechanism we compared them in their ability to explain the measured behavior of human subjects performing the experimental task. The model comparison indicates that an attentional-focus mechanism is a key feature of behavioral models that accurately replicate subjects’ behavior. These findings suggest that the evolution of beliefs is modulated by a competitive attractor dynamics that forms prior expectation about future outcomes. Hence, the findings provide interesting and novel insights into the computational mechanisms underlying human behavior when making decisions in complex environments.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by the US-German Collaboration in Computational Neuroscience of NSF (1207573, to JO) and BMBF (Förderkennzeichen: 01GQ1205, to SJK). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="10"/>
<table-count count="0"/>
<page-count count="34"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability" xlink:type="simple">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>A typical problem that humans encounter, in our complex environment, is to identify those environmental features that are relevant for achieving a desired outcome in a given task. This is computationally difficult because the real-world environment displays a large number of environmental features. In addition, the relevance of the features can change over time and the observations do not always reflect the relevance of specific features. For example, to increase the chance of catching a fish, a fisherman has to consider various features (<italic>e</italic>.<italic>g</italic>. time of the day, lightening conditions, water transparency, <italic>etc</italic>.). Depending on the fishing place (<italic>e</italic>.<italic>g</italic>. pond, lake, or river) only some of these features will be relevant. To perfectly solve such tasks all possible features should be taken into account simultaneously. However, due to an apparent limitation in their cognitive resources, humans dynamically attend only to the most relevant environmental features when deciding what action to pursue [<xref rid="pcbi.1004558.ref001" ref-type="bibr">1</xref>,<xref rid="pcbi.1004558.ref002" ref-type="bibr">2</xref>]. Our goal here is to develop a computational model to analyze behavioral data and understand better how attention modulates the update of beliefs about the relevance of features in such complex environments.</p>
<p>An ideal test bed to address these questions is the Wisconsin card sorting task (WCST), as it provides an experimental environment with multiple visual features, in which at any moment of time only a single feature is relevant for correctly solving the task. The WCST was originally designed to test for the damage or dysfunction of the prefrontal cortex, which regulates executive functions [<xref rid="pcbi.1004558.ref003" ref-type="bibr">3</xref>–<xref rid="pcbi.1004558.ref006" ref-type="bibr">6</xref>]. More recently it was employed in various behavioral models as a paradigm with which one can investigate computational mechanisms of higher cognitive functions [<xref rid="pcbi.1004558.ref007" ref-type="bibr">7</xref>].</p>
<p>Here we will focus on the computational mechanisms that underlie update of beliefs about the relevance of various visual features. However, inferring the hidden belief states of subjects performing the standard WCST is difficult, as the only expression of an internal, multidimensional belief space are the behavioral choices [<xref rid="pcbi.1004558.ref001" ref-type="bibr">1</xref>,<xref rid="pcbi.1004558.ref008" ref-type="bibr">8</xref>–<xref rid="pcbi.1004558.ref010" ref-type="bibr">10</xref>]. To address this issue we designed a probabilistic variant of WCST in which we solicited subjects’ beliefs [<xref rid="pcbi.1004558.ref011" ref-type="bibr">11</xref>], that is, we requested from subjects to bet an amount of money proportionally to their beliefs about the relevance of each visual feature. Importantly, various sources of uncertainty made the environment of WCST probabilistic and made the task more difficult, thus allowing us to measure smooth belief trajectories that evolve over single trials. This fine-grained measure provides more direct access to subjects’ hidden belief states and thus allowed for improved inference, compared to the standard WCST. Using this novel variant of the WCST, we were able to develop a probabilistic model for the analysis of behavioral data to provide novel insights into the hidden learning mechanism, which drives human behavior [<xref rid="pcbi.1004558.ref012" ref-type="bibr">12</xref>–<xref rid="pcbi.1004558.ref014" ref-type="bibr">14</xref>].</p>
<p>Previous computational models for the WCST can be divided into three groups based on the assumed computational principle that were used to capture human behavior and cognition: (i) functional cognitive models [<xref rid="pcbi.1004558.ref010" ref-type="bibr">10</xref>], which are motivated by algorithmic properties of the task; (ii) connectionist models [<xref rid="pcbi.1004558.ref009" ref-type="bibr">9</xref>,<xref rid="pcbi.1004558.ref015" ref-type="bibr">15</xref>–<xref rid="pcbi.1004558.ref019" ref-type="bibr">19</xref>], which are motivated by the evidence that the brain is an active and distributed system that constantly generates hypotheses about its environment and tests for their validity [<xref rid="pcbi.1004558.ref020" ref-type="bibr">20</xref>–<xref rid="pcbi.1004558.ref025" ref-type="bibr">25</xref>]; and probabilistic Bayesian models [<xref rid="pcbi.1004558.ref001" ref-type="bibr">1</xref>], which further assume that the brain combines prior knowledge and present sensory information based on their relative precision, that is, in a Bayes-optimal manner [<xref rid="pcbi.1004558.ref026" ref-type="bibr">26</xref>–<xref rid="pcbi.1004558.ref032" ref-type="bibr">32</xref>].</p>
<p>The classical connectionist approach provides an elegant framework for defining attention formation in a distributed and dynamical manner. A potential limitation is that one requires additional and rather ad-hoc assumptions to describe the interaction of prediction errors with internal dynamics of beliefs. This issue can be addressed by the Bayesian approach which provides a framework for defining optimal interaction between prediction errors and current belief states. Furthermore, the Bayesian framework provides a computational account of attention [<xref rid="pcbi.1004558.ref033" ref-type="bibr">33</xref>–<xref rid="pcbi.1004558.ref036" ref-type="bibr">36</xref>], which the connectionist approach lacks. Here we build upon these past views of attention within the Bayesian framework, with an attentional focus mechanism that relies on competitive and self-organized dynamical principles that guide spontaneous formation of attention. We will fuse the winner-take-all (WTA) dynamics [<xref rid="pcbi.1004558.ref037" ref-type="bibr">37</xref>–<xref rid="pcbi.1004558.ref043" ref-type="bibr">43</xref>] with a Bayesian formalism of decision making.</p>
<p>With this combined approach we can investigate, at the same time, the influence of attention and the influence of probabilistic aspects of the environment on the evolution of beliefs during decision making. In addition, this framework allows us to relate our investigation to previous findings of a presumed hierarchical representation in the brain [<xref rid="pcbi.1004558.ref012" ref-type="bibr">12</xref>,<xref rid="pcbi.1004558.ref014" ref-type="bibr">14</xref>,<xref rid="pcbi.1004558.ref044" ref-type="bibr">44</xref>–<xref rid="pcbi.1004558.ref048" ref-type="bibr">48</xref>]. Importantly, the introduction of such an attentional focus mechanism within a Bayesian framework takes the model away from the rational Bayesian observer that is fully informed about the structure of the probabilistic WCST and which updates beliefs about all features independent of their relevance. However, we expect an attentional focus mechanism to provide a better account for experimentally observed human behavior.</p>
<p>To test whether subjects’ behavior reflects the assumption that the update of beliefs is modulated by attentional focus we compared multiple variants of the behavioral models, both with and without an attentional focus mechanism, in their ability to generate behavioral data. In particular, we used a recently described meta-Bayesian approach, the so-called ‘Observing the observer’ (OTO) framework to infer the hidden belief states and their influence on behavioral responses of human subjects [<xref rid="pcbi.1004558.ref049" ref-type="bibr">49</xref>,<xref rid="pcbi.1004558.ref050" ref-type="bibr">50</xref>]. Importantly, using the OTO framework enabled us to put perception and action (i.e., subjects’ responses) into a single behavioral model and to compare various variants of both perceptual and response models. Each variant of the perceptual model tested for different assumptions about the mechanisms that underlie the update of beliefs. Similarly different variants of the response model tested for evidence regarding sub-optimality in human decision making, caused by a potentially stochastic representation of posterior beliefs in the brain [<xref rid="pcbi.1004558.ref051" ref-type="bibr">51</xref>–<xref rid="pcbi.1004558.ref053" ref-type="bibr">53</xref>].</p>
<p>In what follows, we will first describe the experimental paradigm, briefly introduce the OTO framework, and derive the update equations of several variants of the behavioral models. Then we will describe the data analysis technique that relies on Bayesian model selection using a random effects metric [<xref rid="pcbi.1004558.ref054" ref-type="bibr">54</xref>,<xref rid="pcbi.1004558.ref055" ref-type="bibr">55</xref>], and present the results of the analysis that we performed on a behavioral, multi-subject, data set obtained from a probabilistic WCST paradigm. In the last section of the article we discuss the relevance of the proposed attentional-focus mechanism and its relation to past works.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<p>In this section we will first describe the experimental task, a probabilistic Wisconsin card sorting task with belief solicitation. Afterwards, we will give a brief description of the OTO framework ‘Observing the observer’ [<xref rid="pcbi.1004558.ref049" ref-type="bibr">49</xref>] and we will introduce the variants of perceptual and response models that we used to model the update of the hidden belief states and the corresponding solicited responses. Finally, we will outline the methods that we applied to estimate the posterior distribution of model parameters and the corresponding model evidence, which we used to perform Bayesian model comparison.</p>
<sec id="sec003">
<title>Ethics statement</title>
<p>The experiment was approved by the Caltech Institutional Review Board and all subjects gave informed consent before participating in the study.</p>
</sec>
<sec id="sec004">
<title>Probabilistic Wisconsin card sorting task</title>
<p>We designed the experimental task with the aim to access the hidden belief states of the subjects. For this purpose we instructed the subjects to infer, by observing a series of an experimenter's choices, which one of the three different visual features is relevant for the current choice, and to report their beliefs about the relevance of each of the features. Participants in the experiment were all healthy volunteers recruited from the Caltech student population.</p>
<p>The visual stimuli that we presented to subjects consisted of a pair of cards (top and bottom), where each card contained three visual features (color, motion, shape). In turn, each visual feature was represented by one of the two possible exemplars (red-green, left-right, circle-square). As each card had to contain a distinct exemplar, there were eight distinct configurations of card pairs. Thus at each experimental trial the visual stimulus was randomly selected from one of the eight configurations (e.g., a red right-moving circle and green left-moving square; see <xref rid="pcbi.1004558.g001" ref-type="fig">Fig 1A</xref>).</p>
<fig id="pcbi.1004558.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Experimental design.</title>
<p>A trial consists of three subsequent steps: (A) The visual stimuli shown in a single trial as two cards. Note that each of the three visual features (color, shape, and motion) has two exemplars (e.g red and green for color) which are assigned either to the top or to the bottom card. (B) The experimenter selects one of the cards, here shown as a blue rectangle. (C) The subject distributes 20$ over three visual features by moving a cursor (red circle) within a triangle. The closer the cursor was to one of the corners of the triangle, the more money was assigned to the corresponding visual feature.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g001" position="float" xlink:type="simple"/>
</fig>
<p>Each out of <italic>n</italic> = 22 pre-trained subjects (14 male and 8 female) was exposed to an experimental session divided into six blocks consisting of <italic>T</italic> = 40 trials each. In three randomly selected blocks the relevant feature remained fixed (no-switch condition), whereas in the other three blocks the relevant feature would change with a probability <italic>p</italic> = 0.35 (switch condition). After each switch the relevant feature would remain constant for 8 trials before another switch could occur. Importantly, to make the otherwise quite simple task more difficult for healthy subjects we introduced observation uncertainty: the experimenter would select a wrong card (a card not containing the relevant exemplar) with probability <italic>ε</italic> = 0.2 in the no-switch condition, and with probability <italic>ε</italic> = 0.3 in the switch condition. The error rate <italic>ε</italic> was set to values that induced the most distinct behavioral responses between two experimental conditions, while rendering the switch condition informative enough to induce betting responses in subjects.</p>
<p>At the beginning of each experimental block we informed the subjects about the block type, but we did not inform them about the exact values of the error rates ε or switch probabilities; they had to infer these probabilities during the training phase. Each subject went through three training sessions, where each subsequent session slightly increased the difficulty of the task in the following manner: In the first session subjects were exposed to a no switch environment with error rate of experimenters choices set to zero. In the second session the switches in the selection rule where announced with error rate still being set at zero. The third session consisted of the no-switch environment with <italic>ε</italic> = 0.2. Afterwards, we explained to subjects the condition in the final switch environment with non-zero error rate.</p>
<p>During a single trial subjects were first exposed to one of the eight possible visual stimuli (see <xref rid="pcbi.1004558.g001" ref-type="fig">Fig 1A</xref>). After one second the presentation program would select a card containing the relevant exemplar with probability 1 − <italic>ε</italic> (see <xref rid="pcbi.1004558.g001" ref-type="fig">Fig 1B</xref>). After observing the selected choice for 5 seconds subjects had a 4 second period to respond by distributing 20$ on the three visual features depending on their belief about the relevance of each feature for the selection process. The response was generated by moving a cursor within a triangle presented on the screen (see <xref rid="pcbi.1004558.g001" ref-type="fig">Fig 1C</xref>). The closer the cursor was to one of the corners of the triangle the more money was assigned to the corresponding visual feature. Importantly, subjects were told that at the end of the experiment a single trial will be randomly selected and that subjects will gain the amount of money that they assigned to the relevant feature in that trial. This ensured that participants were motivated to provide an accurate rendering of their beliefs over the features.</p>
<p>For clarification of the task we present at this point some of the key behavioral results (see <xref rid="pcbi.1004558.g002" ref-type="fig">Fig 2</xref>). We quantified the performance of subjects as the median amount of their money bets on a truly relevant visual feature over an experimental block. The maximal performance would correspond to betting the full amount of 20$ to the truly relevant feature at each trial. As expected, the median of subjects’ performance was higher during the no-switch condition (Kruskal-Wallis test, <italic>p</italic> &lt;10<sup>−14</sup>), whereas the median reaction times were lower (Kruskal-Wallis test, <italic>p</italic> &lt;10<sup>−12</sup>) during the same experimental condition which reflects the increased difficulty of the switch condition.</p>
<fig id="pcbi.1004558.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Reaction times and task performance.</title>
<p>Median reaction time plotted against median performance of 22 subjects for each of three experimental blocks of the switch (orange circles) and no-switch condition (green circles). The two large circles denote the median values across all experimental blocks within the two experimental conditions. We defined the median performance as the median money gain within an experimental block, that is, the median amount of money assigned to the truly relevant visual feature within an experimental block.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g002" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>‘Observing the Observer’ framework</title>
<p>Our goal is to infer, from the behavioral data, the hidden belief states of each subject that are conditioned on the past sequence of visual stimuli and experimenter choices. By deriving an adequate mapping of observations onto internal belief states (the perceptual model) and the mapping of the internal belief states onto desired responses (response model), we can define a generative model of the whole observation-response process [<xref rid="pcbi.1004558.ref049" ref-type="bibr">49</xref>,<xref rid="pcbi.1004558.ref050" ref-type="bibr">50</xref>] as (see <xref rid="pcbi.1004558.g003" ref-type="fig">Fig 3</xref> for a graphical representation):
<disp-formula id="pcbi.1004558.e001">
<alternatives>
<graphic id="pcbi.1004558.e001g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e001" xlink:type="simple"/>
<mml:math display="block" id="M1" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>|</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where <inline-formula id="pcbi.1004558.e002"><alternatives><graphic id="pcbi.1004558.e002g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e002" xlink:type="simple"/><mml:math display="inline" id="M2" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> denotes the probability of observing a response <inline-formula id="pcbi.1004558.e003"><alternatives><graphic id="pcbi.1004558.e003g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e003" xlink:type="simple"/><mml:math display="inline" id="M3" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> given the hidden belief states <italic>b</italic><sub><italic>t</italic></sub> (that depend on past beliefs, current sensory observations <inline-formula id="pcbi.1004558.e004"><alternatives><graphic id="pcbi.1004558.e004g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e004" xlink:type="simple"/><mml:math display="inline" id="M4" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and a set <italic>γ</italic> of free parameters of the perceptual model <italic>m</italic><sup>(<italic>p</italic>)</sup>) and a set <italic>θ</italic> of free parameters of the response model <italic>m</italic><sup>(r)</sup>. The last term <italic>p</italic>(<italic>γ</italic>, <italic>θ</italic>|<italic>m</italic><sup>(r)</sup>, <italic>m</italic><sup>(<italic>p</italic>)</sup>) in <xref rid="pcbi.1004558.e001" ref-type="disp-formula">Eq (1)</xref> denotes a prior distribution over the space of free parameters.</p>
<fig id="pcbi.1004558.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Schematic of implicit generative model as formulated under the Observing-the-observer framework.</title>
<p>The full generative model consists of a combined perceptual (orange box) and response model (blue box). The perceptual part of the generative model defines the mapping from current observations <inline-formula id="pcbi.1004558.e005"><alternatives><graphic id="pcbi.1004558.e005g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e005" xlink:type="simple"/><mml:math display="inline" id="M5" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, past beliefs <italic>b</italic><sub><italic>t</italic>−1</sub>, and a set of model parameters <italic>γ</italic>, onto current beliefs <italic>b</italic><sub><italic>t</italic></sub>. The response part of the generative model defines the mapping from current beliefs <italic>b</italic><sub><italic>t</italic></sub> and a set of model parameters <italic>θ</italic>, onto responses <inline-formula id="pcbi.1004558.e006"><alternatives><graphic id="pcbi.1004558.e006g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e006" xlink:type="simple"/><mml:math display="inline" id="M6" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Figure adapted from [<xref rid="pcbi.1004558.ref049" ref-type="bibr">49</xref>].</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g003" position="float" xlink:type="simple"/>
</fig>
<p>Thus, to infer the hidden belief states of a subject we have to invert the generative model (<xref rid="pcbi.1004558.e001" ref-type="disp-formula">Eq (1)</xref>) for the given set of behavioral responses <italic>r</italic><sub>1…<italic>t</italic></sub> and sensory stimuli <italic>e</italic><sub>1…<italic>t</italic></sub>, and compute the posterior distribution over the model parameters
<disp-formula id="pcbi.1004558.e007">
<alternatives>
<graphic id="pcbi.1004558.e007g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e007" xlink:type="simple"/>
<mml:math display="block" id="M7" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
where we omitted <italic>m</italic><sup>(<italic>r</italic>)</sup>, <italic>m</italic><sup>(<italic>p</italic>)</sup> for better readability. Knowing the posterior distribution one can either compute the most likely belief state at trial <italic>t</italic> as <inline-formula id="pcbi.1004558.e008"><alternatives><graphic id="pcbi.1004558.e008g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e008" xlink:type="simple"/><mml:math display="inline" id="M8" overflow="scroll"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>—</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> where <inline-formula id="pcbi.1004558.e009"><alternatives><graphic id="pcbi.1004558.e009g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e009" xlink:type="simple"/><mml:math display="inline" id="M9" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>γ</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> denotes the mode of the posterior—or an expected belief state at trial t, as <inline-formula id="pcbi.1004558.e010"><alternatives><graphic id="pcbi.1004558.e010g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e010" xlink:type="simple"/><mml:math display="inline" id="M10" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo> </mml:mo><mml:mi>γ</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>To test the hypothesis that subjects focus their attention on a subset of environmental features when updating their beliefs about the features' relevance, it is essential to compare multiple models in their ability to replicate the behavioral data and select the most appropriate model. Bayesian model comparison uses model evidence, that is, marginal likelihood <italic>p</italic>(<italic>r</italic><sub>1…<italic>t</italic></sub>|<italic>e</italic><sub>1…<italic>t</italic></sub>), to estimate the probability that a specific model has generated the data. The advantage of such a procedure, compared to standard goodness of fit approaches, is that more complex models are penalized automatically. The model evidence, for any pair of perceptual and response models, is given as
<disp-formula id="pcbi.1004558.e011">
<alternatives>
<graphic id="pcbi.1004558.e011g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e011" xlink:type="simple"/>
<mml:math display="block" id="M11" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mo>∫</mml:mo><mml:mtext>​</mml:mtext></mml:msup><mml:mi>d</mml:mi><mml:mi>γ</mml:mi><mml:mi>d</mml:mi><mml:mi>θ</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mi>γ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>m</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula></p>
<p>To estimate the model evidence and obtain the posterior distribution over model parameters <italic>p</italic>(<italic>γ</italic>,<italic>θ</italic>|<italic>e</italic><sub>1…<italic>t</italic></sub>, <italic>r</italic><sub>1…<italic>t</italic></sub>) any approximate inference scheme can be applied. In particular, Daunizeau <italic>et</italic>. <italic>al</italic>. [<xref rid="pcbi.1004558.ref049" ref-type="bibr">49</xref>,<xref rid="pcbi.1004558.ref050" ref-type="bibr">50</xref>] proposed the use of a variational scheme where the model log-evidence is approximated with the variational free-energy and the posterior distribution over the model parameters is selected as the maximizer of the free-energy obtained through variational calculus. However, this method requires the computation of the gradients of the log-joint probability distributions (natural logarithm of the joint probability distribution given in <xref rid="pcbi.1004558.e001" ref-type="disp-formula">Eq (1)</xref>), which in our case are not obtainable analytically as the derivatives affect the parameters of the non-linear equations of the belief process. Furthermore, a small change in the parameters of the update equations of beliefs (<xref rid="pcbi.1004558.e081" ref-type="disp-formula">Eq (11)</xref>, see below) can have a large influence on the shape of the trajectory, thus the log-joint probability distribution can be ill-conditioned with respect to model parameters. Therefore, even if the gradient, with respect to model parameters, would be computable at every point of the trajectory, a gradient ascent method would have difficulties to converge to a global mode of the joint probability distribution, as the underlying landscape might have a multimodal, non-linear, and non-convex structure.</p>
<p>Thus, we use a numerical gradient-free scheme to find the mode of the log-joint probability distribution and apply a numerical method to compute the Hessian matrix at that mode [<xref rid="pcbi.1004558.ref056" ref-type="bibr">56</xref>–<xref rid="pcbi.1004558.ref058" ref-type="bibr">58</xref>]. With the obtained values of the mode and the Hessian we compute the Laplace approximation to the model evidence [<xref rid="pcbi.1004558.ref059" ref-type="bibr">59</xref>]. We will discuss the specifics of the numerical estimates in the final subsection of the methods. In what follows we will first introduce the behavioral models.</p>
<sec id="sec006">
<title>Perceptual model</title>
<p>To derive the perceptual model, which maps sensory cues onto beliefs we followed previous accounts in making three important assumptions [<xref rid="pcbi.1004558.ref060" ref-type="bibr">60</xref>–<xref rid="pcbi.1004558.ref062" ref-type="bibr">62</xref>]. First, we will assume that subjects combine prior beliefs and sensory information in a Bayes optimal fashion (Bayesian observer assumption). Note that this assumption will later be relaxed to obtain a non-Bayesian approximation to the update equations. Second, we assume that the update of beliefs can be represented as a Markov process, that is, future belief states depend only on the present beliefs. Third, we will assume that subjects perform counterfactual inference [<xref rid="pcbi.1004558.ref035" ref-type="bibr">35</xref>], that is, they try to infer which of the several hypothesis (explanations of experimenter’s choices) is currently correct. A single hypothesis would correspond to saying that the experimenter selects cards containing a specific exemplar (e.g. color red). As each visual feature has two exemplars (red-green color, leftward-rightward motion, and round-square shape), there are in total six hypotheses.</p>
<p>Starting with these three assumptions we will define a generative model of the sensory observations in the form of a hierarchical state space model [<xref rid="pcbi.1004558.ref063" ref-type="bibr">63</xref>], that captures the dynamics of the transient probability that one of the six possible selection rules is currently active. Inversion of the generative model will provide us with the required mapping from sensory cues onto posterior probability about the correctness of each hypothesis, that is, the posterior beliefs about the relevance of different visual features and exemplars.</p>
<p>However, to specify the structure of the hierarchical generative model, a few additional assumptions are required. First, we can assume that the probability <italic>p</italic>(<italic>H</italic><sub><italic>t</italic></sub>) of hypothesis <italic>H</italic><sub><italic>t</italic></sub> being correct is represented in a factorized from, that is, <italic>p</italic>(<italic>H</italic><sub><italic>t</italic></sub>) equals to the product of the probability <italic>p</italic>(<italic>F</italic><sub><italic>t</italic></sub>) that one of the visual features <italic>F</italic><sub><italic>t</italic></sub> is currently relevant and of the conditional probability <italic>P</italic>(<italic>E</italic><sub><italic>t</italic></sub>|<italic>F</italic><sub><italic>t</italic></sub>) that one of the two exemplars <italic>E</italic><sub><italic>t</italic></sub> is currently relevant (given the fact that the corresponding visual feature <italic>F</italic><sub><italic>t</italic></sub> is relevant for the selection process). Alternatively, we can assume that only the probability <italic>p</italic>(<italic>H</italic><sub><italic>t</italic></sub>) of hypothesis <italic>H</italic><sub><italic>t</italic></sub> being correct is explicitly represented and that the marginal probability <italic>p</italic>(<italic>F</italic><sub><italic>t</italic></sub>) is computed only implicitly via the integration of corresponding beliefs.</p>
<p>Depending on the starting assumption one will end up with slightly different structure of the corresponding hierarchical generative model. Here we will describe in detail only the generative model based on the assumption that only the joint hypothesis probability <italic>p</italic>(<italic>H</italic><sub><italic>t</italic></sub>) is explicitly represented and actively updated within the belief space. The reason for this is that model comparisons (see below) suggest that such representation better captures subject behavior. Nevertheless, the detailed derivation and the analysis of the behavioral data based on the alternative assumption, mentioned above, are provided in the supplementary material (<xref rid="pcbi.1004558.s001" ref-type="supplementary-material">S1 Text</xref>).</p>
<p>Here we will define the generative model as a three-level hierarchy (see <xref rid="pcbi.1004558.g004" ref-type="fig">Fig 4</xref> for graphical representation): (i) the 1<sup>st</sup> level of the hierarchy encodes the hidden selection rule, that is, the currently correct hypothesis <italic>H</italic><sub><italic>t</italic></sub> (see <xref rid="pcbi.1004558.e024" ref-type="disp-formula">Eq (5)</xref>); (ii) the 2<sup>nd</sup> level of the hierarchy encodes the probability, in the form of a state space vector <inline-formula id="pcbi.1004558.e012"><alternatives><graphic id="pcbi.1004558.e012g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e012" xlink:type="simple"/><mml:math display="inline" id="M12" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, that each of the possible exemplar-feature pairs is currently relevant for the experimenter’s choices (see <xref rid="pcbi.1004558.e031" ref-type="disp-formula">Eq (6)</xref>), and (iii) the 3<sup>rd</sup> level of the hierarchy encodes the probability, in the form of the state space vector <inline-formula id="pcbi.1004558.e013"><alternatives><graphic id="pcbi.1004558.e013g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e013" xlink:type="simple"/><mml:math display="inline" id="M13" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> that each visual feature is currently relevant for the experimenter’s choices (see <xref rid="pcbi.1004558.e039" ref-type="disp-formula">Eq (7)</xref>).</p>
<fig id="pcbi.1004558.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g004</object-id>
<label>Fig 4</label>
<caption>
<title>A graphical representation of the hierarchical generative model of percepts.</title>
<p>The highest 3<sup>rd</sup> level hierarchy describes the dynamics of the three dimensional state space vector <inline-formula id="pcbi.1004558.e014"><alternatives><graphic id="pcbi.1004558.e014g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e014" xlink:type="simple"/><mml:math display="inline" id="M14" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> that encodes the relevance of the three visual features. Similarly, the 2<sup>nd</sup> level of the hierarchy describes the dynamics of the six dimensional state space vector <inline-formula id="pcbi.1004558.e015"><alternatives><graphic id="pcbi.1004558.e015g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e015" xlink:type="simple"/><mml:math display="inline" id="M15" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> that encodes the relevance for the selection process of the six exemplar-feature pairs. The functional form of the state transition probability <inline-formula id="pcbi.1004558.e016"><alternatives><graphic id="pcbi.1004558.e016g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e016" xlink:type="simple"/><mml:math display="inline" id="M16" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is shown on the right hand side of the plot. The 1<sup>st</sup> level of the hierarchy encodes the currently active selection rule, that is, a currently correct hypothesis <italic>H</italic><sub><italic>t</italic></sub>, where the currently correct hypothesis is drawn from a conditional probability <inline-formula id="pcbi.1004558.e017"><alternatives><graphic id="pcbi.1004558.e017g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e017" xlink:type="simple"/><mml:math display="inline" id="M17" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> shown on the right hand side of the plot. Finally, the observable states are denoted with the six dimensional vector <inline-formula id="pcbi.1004558.e018"><alternatives><graphic id="pcbi.1004558.e018g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e018" xlink:type="simple"/><mml:math display="inline" id="M18" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, that encodes currently selected exemplars. On the right hand side of the plot we show the conditional probability <inline-formula id="pcbi.1004558.e019"><alternatives><graphic id="pcbi.1004558.e019g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e019" xlink:type="simple"/><mml:math display="inline" id="M19" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> of selecting the <italic>k</italic> th exemplar given the active selection rule <italic>H</italic><sub><italic>t</italic></sub>. For details, see the Eqs (<xref rid="pcbi.1004558.e021" ref-type="disp-formula">4</xref>) to (<xref rid="pcbi.1004558.e039" ref-type="disp-formula">7</xref>) and the accompanying text.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g004" position="float" xlink:type="simple"/>
</fig>
<p>Assuming that the <italic>k</italic> th hypothesis is the correct one (<italic>k</italic> ∈ {1,…,6}), the corresponding exemplar will be selected with probability 1 − <italic>ε</italic>, where <italic>ε</italic> denotes the error rate of experimenter’s choices. We will encode the experimenter’s choice with a binary vector <inline-formula id="pcbi.1004558.e020"><alternatives><graphic id="pcbi.1004558.e020g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e020" xlink:type="simple"/><mml:math display="inline" id="M20" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mn>6</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> whose elements are set to 1 or 0 depending on the presence or absence of the corresponding exemplar on the selected card. Thus, we can write the observation likelihood as
<disp-formula id="pcbi.1004558.e021">
<alternatives>
<graphic id="pcbi.1004558.e021g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e021" xlink:type="simple"/>
<mml:math display="block" id="M21" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:mi>p</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>ε</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>ε</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ε</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mi>ε</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where <inline-formula id="pcbi.1004558.e022"><alternatives><graphic id="pcbi.1004558.e022g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e022" xlink:type="simple"/><mml:math display="inline" id="M22" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes Kronecker's delta and <italic>e</italic><sub><italic>k</italic></sub>,<sub><italic>t</italic></sub> denotes the <italic>k</italic>th component of <inline-formula id="pcbi.1004558.e023"><alternatives><graphic id="pcbi.1004558.e023g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e023" xlink:type="simple"/><mml:math display="inline" id="M23" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></p>
<p>At the 1<sup>st</sup> (lowest) level of the hierarchy, we defined the probability that a hypothesis <italic>H</italic><sub><italic>t</italic></sub> ∈ {1,…,6} is the correct one as a categorical probability distribution
<disp-formula id="pcbi.1004558.e024">
<alternatives>
<graphic id="pcbi.1004558.e024g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e024" xlink:type="simple"/>
<mml:math display="block" id="M24" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
where the <inline-formula id="pcbi.1004558.e025"><alternatives><graphic id="pcbi.1004558.e025g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e025" xlink:type="simple"/><mml:math display="inline" id="M25" overflow="scroll"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> denotes the probability of the <italic>k</italic> th hypothesis. These probabilities are encoded at the 2<sup>nd</sup> level of the hierarchy (see <xref rid="pcbi.1004558.g004" ref-type="fig">Fig 4</xref>) with the real valued vector <inline-formula id="pcbi.1004558.e026"><alternatives><graphic id="pcbi.1004558.e026g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e026" xlink:type="simple"/><mml:math display="inline" id="M26" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mn>6</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, where we defined the mapping to the space of categorical probabilities as the softmax transform
<disp-formula id="pcbi.1004558.e027">
<alternatives>
<graphic id="pcbi.1004558.e027g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e027" xlink:type="simple"/>
<mml:math display="block" id="M27" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msubsup><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>To incorporate an attention-like mechanism within the perceptual model, we make the state transition of <inline-formula id="pcbi.1004558.e028"><alternatives><graphic id="pcbi.1004558.e028g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e028" xlink:type="simple"/><mml:math display="inline" id="M28" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> to follow a winner-take all (WTA) dynamics. We used this type of dynamics for three reasons:</p>
<list list-type="order">
<list-item><p>The WTA dynamics is characterized by a set of stable fixed points that can be arranged in such a way that at each fixed point only one component of <inline-formula id="pcbi.1004558.e029"><alternatives><graphic id="pcbi.1004558.e029g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e029" xlink:type="simple"/><mml:math display="inline" id="M29" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is set to a high value (which encodes a high relevance of the corresponding exemplar), while all other components have low values. Such attractor state captures the structure of the WCST environment, in which at any moment in time only one exemplar-feature pair can be relevant.</p></list-item>
<list-item><p>Adding uncorrelated noise to the WTA dynamics mediates the switching between stable attractors. The larger the noise term the more probable is the transition between attractors. Thus, we can use a single parameter that defines the level of noise in the WTA dynamics to capture different experimental conditions.</p></list-item>
<list-item><p>WTA networks were successfully used before as a hierarchical neural model of higher cognitive functions [<xref rid="pcbi.1004558.ref008" ref-type="bibr">8</xref>,<xref rid="pcbi.1004558.ref015" ref-type="bibr">15</xref>,<xref rid="pcbi.1004558.ref016" ref-type="bibr">16</xref>,<xref rid="pcbi.1004558.ref018" ref-type="bibr">18</xref>,<xref rid="pcbi.1004558.ref021" ref-type="bibr">21</xref>,<xref rid="pcbi.1004558.ref025" ref-type="bibr">25</xref>,<xref rid="pcbi.1004558.ref064" ref-type="bibr">64</xref>,<xref rid="pcbi.1004558.ref065" ref-type="bibr">65</xref>], and as a model of attention spontaneously emerging from competitive neural dynamics [<xref rid="pcbi.1004558.ref066" ref-type="bibr">66</xref>].</p></list-item>
</list>
<p>Thus, assuming the WTA dynamics, the time evolution of <inline-formula id="pcbi.1004558.e030"><alternatives><graphic id="pcbi.1004558.e030g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e030" xlink:type="simple"/><mml:math display="inline" id="M30" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> becomes
<disp-formula id="pcbi.1004558.e031">
<alternatives>
<graphic id="pcbi.1004558.e031g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e031" xlink:type="simple"/>
<mml:math display="block" id="M31" overflow="scroll">
<mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula></p>
<p>Here <inline-formula id="pcbi.1004558.e032"><alternatives><graphic id="pcbi.1004558.e032g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e032" xlink:type="simple"/><mml:math display="inline" id="M32" overflow="scroll"><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004558.e033"><alternatives><graphic id="pcbi.1004558.e033g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e033" xlink:type="simple"/><mml:math display="inline" id="M33" overflow="scroll"><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>⋯</mml:mo><mml:mo>,</mml:mo><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>;</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> <inline-formula id="pcbi.1004558.e034"><alternatives><graphic id="pcbi.1004558.e034g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e034" xlink:type="simple"/><mml:math display="inline" id="M34" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> denotes a vector of i.i.d. random variables drawn from normal distribution <inline-formula id="pcbi.1004558.e035"><alternatives><graphic id="pcbi.1004558.e035g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e035" xlink:type="simple"/><mml:math display="inline" id="M35" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> with zero mean and variance <italic>q</italic><sub><italic>e</italic></sub>; <italic>τ</italic><sub><italic>e</italic></sub> denotes the time scale of the update equations, and <italic>κ</italic><sub><italic>e</italic></sub> an additive constant. Importantly, the dynamics of the <inline-formula id="pcbi.1004558.e036"><alternatives><graphic id="pcbi.1004558.e036g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e036" xlink:type="simple"/><mml:math display="inline" id="M36" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is influenced by the state vector <inline-formula id="pcbi.1004558.e037"><alternatives><graphic id="pcbi.1004558.e037g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e037" xlink:type="simple"/><mml:math display="inline" id="M37" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> at the 3<sup>rd</sup> level of hierarchy, which encodes the relevance of the three visual features (see <xref rid="pcbi.1004558.g004" ref-type="fig">Fig 4</xref>). The time evolution of <inline-formula id="pcbi.1004558.e038"><alternatives><graphic id="pcbi.1004558.e038g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e038" xlink:type="simple"/><mml:math display="inline" id="M38" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is defined by an analogous set of equations
<disp-formula id="pcbi.1004558.e039">
<alternatives>
<graphic id="pcbi.1004558.e039g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e039" xlink:type="simple"/>
<mml:math display="block" id="M39" overflow="scroll">
<mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>ω</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula></p>
<p>Importantly, the connectivity matrices <inline-formula id="pcbi.1004558.e040"><alternatives><graphic id="pcbi.1004558.e040g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e040" xlink:type="simple"/><mml:math display="inline" id="M40" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> denote the inhibitory interactions within levels, which are essential for the realization of attractor dynamics and <inline-formula id="pcbi.1004558.e041"><alternatives><graphic id="pcbi.1004558.e041g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e041" xlink:type="simple"/><mml:math display="inline" id="M41" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> denote the excitatory interactions between the levels of the hierarchy. This allows for integrating the beliefs about hypothesis relevance into beliefs about feature relevance.</p>
<p>In what follows, to simplify the notation, we will merge the state vectors <inline-formula id="pcbi.1004558.e042"><alternatives><graphic id="pcbi.1004558.e042g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e042" xlink:type="simple"/><mml:math display="inline" id="M42" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004558.e043"><alternatives><graphic id="pcbi.1004558.e043g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e043" xlink:type="simple"/><mml:math display="inline" id="M43" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> into a single state vector <inline-formula id="pcbi.1004558.e044"><alternatives><graphic id="pcbi.1004558.e044g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e044" xlink:type="simple"/><mml:math display="inline" id="M44" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> whose update equation is denoted by <inline-formula id="pcbi.1004558.e045"><alternatives><graphic id="pcbi.1004558.e045g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e045" xlink:type="simple"/><mml:math display="inline" id="M45" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, that is,
<disp-formula id="pcbi.1004558.e046">
<alternatives>
<graphic id="pcbi.1004558.e046g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e046" xlink:type="simple"/>
<mml:math display="block" id="M46" overflow="scroll">
<mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>  </mml:mtext><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
</sec>
<sec id="sec007">
<title>Bayesian inference</title>
<p>Given the observation likelihood <xref rid="pcbi.1004558.e021" ref-type="disp-formula">Eq (4)</xref>, hypothesis probability <xref rid="pcbi.1004558.e024" ref-type="disp-formula">Eq (5)</xref> and the transition probabilities Eqs (<xref rid="pcbi.1004558.e031" ref-type="disp-formula">6</xref>) and (<xref rid="pcbi.1004558.e039" ref-type="disp-formula">7</xref>) we write the full generative model as
<disp-formula id="pcbi.1004558.e047">
<alternatives>
<graphic id="pcbi.1004558.e047g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e047" xlink:type="simple"/>
<mml:math display="block" id="M47" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mtext>)</mml:mtext><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula>
where <inline-formula id="pcbi.1004558.e048"><alternatives><graphic id="pcbi.1004558.e048g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e048" xlink:type="simple"/><mml:math display="inline" id="M48" overflow="scroll"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> denotes all past observations. As we are interested in obtaining the posterior probability of the hidden states <inline-formula id="pcbi.1004558.e049"><alternatives><graphic id="pcbi.1004558.e049g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e049" xlink:type="simple"/><mml:math display="inline" id="M49" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, we require a compact form of the generative model
<disp-formula id="pcbi.1004558.e050">
<alternatives>
<graphic id="pcbi.1004558.e050g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e050" xlink:type="simple"/>
<mml:math display="block" id="M50" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>∞</mml:mi></mml:munderover><mml:mo>…</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>∞</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>To obtain this compact form it is necessary to calculate the following integral
<disp-formula id="pcbi.1004558.e051">
<alternatives>
<graphic id="pcbi.1004558.e051g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e051" xlink:type="simple"/>
<mml:math display="block" id="M51" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mtext>)</mml:mtext><mml:mo>,</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>∞</mml:mi></mml:munderover><mml:mo>…</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>∞</mml:mi></mml:munderover><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Assuming that <inline-formula id="pcbi.1004558.e052"><alternatives><graphic id="pcbi.1004558.e052g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e052" xlink:type="simple"/><mml:math display="inline" id="M52" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is a normal distribution with mean <inline-formula id="pcbi.1004558.e053"><alternatives><graphic id="pcbi.1004558.e053g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e053" xlink:type="simple"/><mml:math display="inline" id="M53" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and covariance matrix Σ<sub><italic>t</italic>−1</sub>, we can approximate the integral on the right hand side as
<disp-formula id="pcbi.1004558.e054">
<alternatives>
<graphic id="pcbi.1004558.e054g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e054" xlink:type="simple"/>
<mml:math display="block" id="M54" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:mo>Σ</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:msub><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mi>Q</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:mo>⊕</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1004558.e055">
<alternatives>
<graphic id="pcbi.1004558.e055g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e055" xlink:type="simple"/>
<mml:math display="block" id="M55" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:mo>Σ</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>e</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> and </mml:mtext><mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:mo>Σ</mml:mo></mml:mrow><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>σ</mml:mo><mml:mi>e</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:msub><mml:mi>I</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:mo>⊕</mml:mo><mml:msubsup><mml:mo>σ</mml:mo><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:msub><mml:mi>I</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where the approximate predictive distribution <inline-formula id="pcbi.1004558.e056"><alternatives><graphic id="pcbi.1004558.e056g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e056" xlink:type="simple"/><mml:math display="inline" id="M56" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is obtained by linearizing <inline-formula id="pcbi.1004558.e057"><alternatives><graphic id="pcbi.1004558.e057g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e057" xlink:type="simple"/><mml:math display="inline" id="M57" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> around the currently known mean <inline-formula id="pcbi.1004558.e058"><alternatives><graphic id="pcbi.1004558.e058g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e058" xlink:type="simple"/><mml:math display="inline" id="M58" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, and where ⊕ denotes direct sum of matrices which constructs a block diagonal matrix from the elements of the sum.</p>
<p>To invert the generative model we apply the variational Bayesian method and the mean-field approximation in which the posterior distribution is approximated by a variational distribution. Thus, we write the posterior probability over the hidden states as a product of approximate posterior distributions, that is
<disp-formula id="pcbi.1004558.e059">
<alternatives>
<graphic id="pcbi.1004558.e059g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e059" xlink:type="simple"/>
<mml:math display="block" id="M59" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mtext>(</mml:mtext><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where we chose the functional forms of the approximate posteriors as the distribution with maximum entropy given the specified mean and variance. This procedure allows for minimal assumptions about the form of the approximate posterior [<xref rid="pcbi.1004558.ref046" ref-type="bibr">46</xref>]. Hence, for the posterior probability over the discrete space of hypotheses we selected again a categorical probability
<disp-formula id="pcbi.1004558.e060">
<alternatives>
<graphic id="pcbi.1004558.e060g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e060" xlink:type="simple"/>
<mml:math display="block" id="M60" overflow="scroll">
<mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∏</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:munderover><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mo> </mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
whereas for the posterior beliefs about the relevance of exemplars and visual features we selected a multivariate normal distribution
<disp-formula id="pcbi.1004558.e061">
<alternatives>
<graphic id="pcbi.1004558.e061g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e061" xlink:type="simple"/>
<mml:math display="block" id="M61" overflow="scroll">
<mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mo>Σ</mml:mo><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Note that in this formulations the posterior belief is fully defined by the tuple of the posterior expectations and the posterior covariance, that is, posterior uncertainty; hence we will denote beliefs as a set <inline-formula id="pcbi.1004558.e062"><alternatives><graphic id="pcbi.1004558.e062g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e062" xlink:type="simple"/><mml:math display="inline" id="M62" overflow="scroll"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mo>Σ</mml:mo><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>Following variational calculus, the approximate posterior, given the mean-field approximation, is proportional to the exponential of the variational energy [<xref rid="pcbi.1004558.ref067" ref-type="bibr">67</xref>]. The variational energies for the given generative model and the above mentioned factorization of approximate posterior are defined as
<disp-formula id="pcbi.1004558.e063">
<alternatives>
<graphic id="pcbi.1004558.e063g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e063" xlink:type="simple"/>
<mml:math display="block" id="M63" overflow="scroll">
<mml:mtable><mml:mtr><mml:mtd><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>∞</mml:mi></mml:munderover><mml:mo>…</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∫</mml:mo></mml:mstyle><mml:mrow><mml:mo>−</mml:mo><mml:mi>∞</mml:mi></mml:mrow><mml:mi>∞</mml:mi></mml:munderover><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>ln</mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mn>6</mml:mn></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>ln</mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
</disp-formula></p>
<p>To find the dependency of current beliefs <italic>b</italic><sub><italic>t</italic></sub> on prior beliefs <italic>b</italic><sub>t-1</sub> and current observation <inline-formula id="pcbi.1004558.e064"><alternatives><graphic id="pcbi.1004558.e064g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e064" xlink:type="simple"/><mml:math display="inline" id="M64" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> we used a series of approximations previously described in [<xref rid="pcbi.1004558.ref046" ref-type="bibr">46</xref>], which we extended to the multidimensional case.</p>
<p>First, to compute <italic>I</italic>(<italic>H</italic><sub><italic>t</italic></sub>), we need to know the beliefs <italic>b</italic><sub><italic>t</italic></sub>, whose computations require knowing <inline-formula id="pcbi.1004558.e065"><alternatives><graphic id="pcbi.1004558.e065g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e065" xlink:type="simple"/><mml:math display="inline" id="M65" overflow="scroll"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, which is a functional of <italic>q</italic>(<italic>H</italic><sub><italic>t</italic></sub>), thus leading to a circular problem. We break the circularity by computing <italic>I</italic>(<italic>H</italic><sub><italic>t</italic></sub>) with the expected beliefs <inline-formula id="pcbi.1004558.e066"><alternatives><graphic id="pcbi.1004558.e066g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e066" xlink:type="simple"/><mml:math display="inline" id="M66" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:msub><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:msub><mml:mrow><mml:mtext> Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:msub><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:mi>Q</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>; hence, we assume that the information about the observation <inline-formula id="pcbi.1004558.e067"><alternatives><graphic id="pcbi.1004558.e067g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e067" xlink:type="simple"/><mml:math display="inline" id="M67" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> first changes the 1<sup>st</sup> level of the model’s hierarchy and then propagates to the 2<sup>nd</sup> and 3<sup>rd</sup> level. As the exponential of the <italic>I</italic>(<italic>H</italic><sub><italic>t</italic></sub>) has the form of a categorical distribution, one can show with simple algebraic manipulations that
<disp-formula id="pcbi.1004558.e068">
<alternatives>
<graphic id="pcbi.1004558.e068g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e068" xlink:type="simple"/>
<mml:math display="block" id="M68" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>ε</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi>ε</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo> </mml:mo><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula></p>
<p>With the known <inline-formula id="pcbi.1004558.e069"><alternatives><graphic id="pcbi.1004558.e069g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e069" xlink:type="simple"/><mml:math display="inline" id="M69" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> one can compute the <inline-formula id="pcbi.1004558.e070"><alternatives><graphic id="pcbi.1004558.e070g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e070" xlink:type="simple"/><mml:math display="inline" id="M70" overflow="scroll"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where the difficulty is that the variational energy does not have a quadratic form, that is, the exponential of <inline-formula id="pcbi.1004558.e071"><alternatives><graphic id="pcbi.1004558.e071g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e071" xlink:type="simple"/><mml:math display="inline" id="M71" overflow="scroll"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is not a Gaussian distribution. Thus, to obtain a Gaussian form of the approximate posterior we need an additional quadratic approximation to the variational energy
<disp-formula id="pcbi.1004558.e072">
<alternatives>
<graphic id="pcbi.1004558.e072g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e072" xlink:type="simple"/>
<mml:math display="block" id="M72" overflow="scroll">
<mml:mtable><mml:mtr><mml:mtd><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mo>∂</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mo>∂</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
</disp-formula>
where we made a second order Taylor expansion of <inline-formula id="pcbi.1004558.e073"><alternatives><graphic id="pcbi.1004558.e073g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e073" xlink:type="simple"/><mml:math display="inline" id="M73" overflow="scroll"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> around the predictive mean <inline-formula id="pcbi.1004558.e074"><alternatives><graphic id="pcbi.1004558.e074g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e074" xlink:type="simple"/><mml:math display="inline" id="M74" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, that is, the anticipated position of the posterior expectation. Finally, having the quadratic form we get the posterior mean <inline-formula id="pcbi.1004558.e075"><alternatives><graphic id="pcbi.1004558.e075g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e075" xlink:type="simple"/><mml:math display="inline" id="M75" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> as the argument of the maximum of <inline-formula id="pcbi.1004558.e076"><alternatives><graphic id="pcbi.1004558.e076g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e076" xlink:type="simple"/><mml:math display="inline" id="M76" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> The maximum is obtained with the Newton’s method
<disp-formula id="pcbi.1004558.e077">
<alternatives>
<graphic id="pcbi.1004558.e077g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e077" xlink:type="simple"/>
<mml:math display="block" id="M77" overflow="scroll">
<mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mtext>argmax </mml:mtext><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mo>∂</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mo>∂</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo> </mml:mo><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula></p>
<p>As <xref rid="pcbi.1004558.e077" ref-type="disp-formula">Eq (10)</xref> is valid for any point <inline-formula id="pcbi.1004558.e078"><alternatives><graphic id="pcbi.1004558.e078g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e078" xlink:type="simple"/><mml:math display="inline" id="M78" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> of the quadratic function <inline-formula id="pcbi.1004558.e079"><alternatives><graphic id="pcbi.1004558.e079g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e079" xlink:type="simple"/><mml:math display="inline" id="M79" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>I</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, we can select again the expansion point <inline-formula id="pcbi.1004558.e080"><alternatives><graphic id="pcbi.1004558.e080g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e080" xlink:type="simple"/><mml:math display="inline" id="M80" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> as the starting value. In this way we obtain the following update equations for the expected relevance of the hidden states
<disp-formula id="pcbi.1004558.e081">
<alternatives>
<graphic id="pcbi.1004558.e081g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e081" xlink:type="simple"/>
<mml:math display="block" id="M81" overflow="scroll">
<mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mo>Σ</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>δ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mover accent="true"><mml:mi>δ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>π</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mn>0</mml:mn><mml:mo>→</mml:mo></mml:mover><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula>
where <inline-formula id="pcbi.1004558.e082"><alternatives><graphic id="pcbi.1004558.e082g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e082" xlink:type="simple"/><mml:math display="inline" id="M82" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mn>0</mml:mn><mml:mo>→</mml:mo></mml:mover><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes the three-dimensional zero vector and where the posterior covariance Σ<sub><italic>t</italic></sub> is given as the inverse of the negative Hessian at the expansion point <inline-formula id="pcbi.1004558.e083"><alternatives><graphic id="pcbi.1004558.e083g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e083" xlink:type="simple"/><mml:math display="inline" id="M83" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, that is,
<disp-formula id="pcbi.1004558.e084">
<alternatives>
<graphic id="pcbi.1004558.e084g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e084" xlink:type="simple"/>
<mml:math display="block" id="M84" overflow="scroll">
<mml:mrow><mml:msub><mml:mo>Σ</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mo>∂</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>The posterior covariance is updated as
<disp-formula id="pcbi.1004558.e085">
<alternatives>
<graphic id="pcbi.1004558.e085g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e085" xlink:type="simple"/>
<mml:math display="block" id="M85" overflow="scroll">
<mml:mrow><mml:msub><mml:mo>Σ</mml:mo><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo>Σ</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo>Σ</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mo>Σ</mml:mo><mml:mo stretchy="true">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:msub><mml:mrow/><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mtext> Σ</mml:mtext></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:msub><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>Q</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1004558.e086">
<alternatives>
<graphic id="pcbi.1004558.e086g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e086" xlink:type="simple"/>
<mml:math display="block" id="M86" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mo>⊕</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:msubsup><mml:msub><mml:mi>π</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>π</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>π</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⊕</mml:mo><mml:msub><mml:mn>0</mml:mn><mml:mrow><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula>
where 0<sub>3,3</sub> denotes squared null matrix and <inline-formula id="pcbi.1004558.e087"><alternatives><graphic id="pcbi.1004558.e087g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e087" xlink:type="simple"/><mml:math display="inline" id="M87" overflow="scroll"><mml:mrow><mml:msub><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> denotes the Jacobian matrix of <inline-formula id="pcbi.1004558.e088"><alternatives><graphic id="pcbi.1004558.e088g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e088" xlink:type="simple"/><mml:math display="inline" id="M88" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> computed at prior expectations <inline-formula id="pcbi.1004558.e089"><alternatives><graphic id="pcbi.1004558.e089g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e089" xlink:type="simple"/><mml:math display="inline" id="M89" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></inline-formula></p>
<p>There are two interesting features of these update equations:</p>
<list list-type="bullet">
<list-item><p>The update equation for the posterior expectation <xref rid="pcbi.1004558.e081" ref-type="disp-formula">Eq (11)</xref> have the form of a WTA neural network, with the key feature that the external input is proportional to the prediction error. This is similar to the hierarchical neuronal network models used in [<xref rid="pcbi.1004558.ref015" ref-type="bibr">15</xref>,<xref rid="pcbi.1004558.ref025" ref-type="bibr">25</xref>] to model behavioral planning in prefrontal cortex. The important difference is that in our model the update equations are derived from a probabilistic generative model (see <xref rid="pcbi.1004558.e047" ref-type="disp-formula">Eq (8)</xref>), and therefore there is an adaptive influence of prediction errors on the internal dynamics of the WTA network; as expected from the Bayesian observer assumption.</p></list-item>
<list-item><p>The hypothesis evidence <inline-formula id="pcbi.1004558.e090"><alternatives><graphic id="pcbi.1004558.e090g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e090" xlink:type="simple"/><mml:math display="inline" id="M90" overflow="scroll"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>H</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is modulated by the predicted relevance of that hypothesis <inline-formula id="pcbi.1004558.e091"><alternatives><graphic id="pcbi.1004558.e091g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e091" xlink:type="simple"/><mml:math display="inline" id="M91" overflow="scroll"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> when the posterior hypothesis probability <inline-formula id="pcbi.1004558.e092"><alternatives><graphic id="pcbi.1004558.e092g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e092" xlink:type="simple"/><mml:math display="inline" id="M92" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is computed (see <xref rid="pcbi.1004558.e068" ref-type="disp-formula">Eq (9)</xref>). Effectively, the evidence in favor of a hypothesis is neglected if the expectation about its relevance is low. This is similar to the effect that attention has on the processing of sensory information, as only the currently relevant features of the stimuli are being processed at any moment of time. Importantly, in the presence of competitive inhibitory dynamics the expectations of all but the most likely hypothesis will be suppressed. In other words, internal dynamics of beliefs leads to selection of prior expectation [<xref rid="pcbi.1004558.ref034" ref-type="bibr">34</xref>].</p></list-item>
</list>
<p>As the derivation of the perceptual model required multiple assumptions, which are not directly motivated by the behavioral data, it is important to test which of the assumption is actually essential for describing and predicting behavioral responses. Thus, in what follows we will describe several variants of the perceptual model that are obtained by relaxing some of the assumption made in the derivations presented above.</p>
</sec>
<sec id="sec008">
<title>Structured models</title>
<p>To reduce the number of free parameters in the perceptual model described above we will assume that between the 2<sup>nd</sup> and the 3<sup>rd</sup> level there are only symmetric excitatory connections with equal values and that these connections exist only between components encoding the relevance of exemplars and corresponding visual features, thus
<disp-formula id="pcbi.1004558.e093">
<alternatives>
<graphic id="pcbi.1004558.e093g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e093" xlink:type="simple"/>
<mml:math display="block" id="M93" overflow="scroll">
<mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext>   for </mml:mtext><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>  for </mml:mtext><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>,</mml:mo></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>v</italic>(<italic>i</italic>) maps the <italic>i</italic> th exemplar to the corresponding visual feature. Furthermore, we will assume that within the 2<sup>nd</sup> and the 3<sup>rd</sup> level there are only symmetric inhibitory connections with equal values, thus
<disp-formula id="pcbi.1004558.e094">
<alternatives>
<graphic id="pcbi.1004558.e094g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e094" xlink:type="simple"/>
<mml:math display="block" id="M94" overflow="scroll">
<mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mtext>  for  </mml:mtext><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mtext>   for  </mml:mtext><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Importantly, we will constrain the WTA dynamics to attractor states in which only single component of <inline-formula id="pcbi.1004558.e095"><alternatives><graphic id="pcbi.1004558.e095g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e095" xlink:type="simple"/><mml:math display="inline" id="M95" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004558.e096"><alternatives><graphic id="pcbi.1004558.e096g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e096" xlink:type="simple"/><mml:math display="inline" id="M96" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> have high values while all other components are set to zero or lower values. This is achieved by setting <inline-formula id="pcbi.1004558.e097"><alternatives><graphic id="pcbi.1004558.e097g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e097" xlink:type="simple"/><mml:math display="inline" id="M97" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>κ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, as suggested in [<xref rid="pcbi.1004558.ref041" ref-type="bibr">41</xref>].</p>
<p>However, removing the lateral inhibition form either the 2<sup>nd</sup> or the 3<sup>rd</sup> level would not disrupt completely the attractor dynamics as long as there are excitatory connections between levels. Thus, we will also consider two additional variants of the structured model in which we set either <italic>κ</italic><sub><italic>e</italic></sub> or <italic>κ</italic><sub><italic>f</italic></sub> to zero.</p>
<p>Therefore, the full set of parameters of the structured perceptual models is given by <inline-formula id="pcbi.1004558.e098"><alternatives><graphic id="pcbi.1004558.e098g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e098" xlink:type="simple"/><mml:math display="inline" id="M98" overflow="scroll"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mo>σ</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where in the first variant, denoted by <italic>w</italic><sub>1</sub>, we have that <italic>κ</italic><sub><italic>e</italic>,<italic>f</italic></sub> ≠ 0, in the second variant, <italic>w</italic><sub>2</sub>, we set <italic>κ</italic><sub><italic>e</italic></sub> = 0, and in the third variant, <italic>w</italic><sub>3</sub>, we set <italic>κ</italic><sub><italic>f</italic></sub> = 0. The graphical representation of all structured model variants is shown in <xref rid="pcbi.1004558.g005" ref-type="fig">Fig 5A–5C</xref>.</p>
<fig id="pcbi.1004558.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Visualization of six different model structures.</title>
<p>Graphical representations of the connectivity matrix <italic>W</italic> of all variants of the perceptual model: the three variants of the structured model denoted with (A) <italic>w</italic><sub>1</sub>, (B) <italic>w</italic><sub>2</sub>, and (C) <italic>w</italic><sub>3</sub>; (D) the structure-free model variant denoted with <italic>d</italic>; and the two reduced variants of the perceptual model denoted with (E) <italic>rw</italic>, and (F) <italic>rd</italic> (for formal definition please see the accompanying text). The relevance of visual features and exemplars encoded by the vector <inline-formula id="pcbi.1004558.e099"><alternatives><graphic id="pcbi.1004558.e099g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e099" xlink:type="simple"/><mml:math display="inline" id="M99" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> (see <xref rid="pcbi.1004558.g004" ref-type="fig">Fig 4</xref>) corresponds to the activity levels at the nine nodes of the neural network. The orange nodes encode the relevance of three visual features <inline-formula id="pcbi.1004558.e100"><alternatives><graphic id="pcbi.1004558.e100g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e100" xlink:type="simple"/><mml:math display="inline" id="M100" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>(color, motion, and shape). The purple nodes encode the relevance of six exemplar-feature pairs <inline-formula id="pcbi.1004558.e101"><alternatives><graphic id="pcbi.1004558.e101g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e101" xlink:type="simple"/><mml:math display="inline" id="M101" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (red-color, green-color, leftward-motion, rightward-motion, circle-shape and square-shape). The structured models incorporate symmetrical lateral inhibition <inline-formula id="pcbi.1004558.e102"><alternatives><graphic id="pcbi.1004558.e102g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e102" xlink:type="simple"/><mml:math display="inline" id="M102" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (depicted with blue lines) that implements a winner-take-all dynamics (see <xref rid="pcbi.1004558.e031" ref-type="disp-formula">Eq (6)</xref> and <xref rid="pcbi.1004558.e039" ref-type="disp-formula">Eq (7)</xref>) and symmetrical excitation between levels <italic>w</italic><sub><italic>dist</italic></sub> (depicted with red lines), that implement integration of relevance between levels of hierarchy. Note that the structure-free model has only symmetrical excitation <italic>w</italic><sub><italic>dist</italic></sub> (red lines) from the level of exemplar-feature pairs to the level of visual features. In the case of the reduced perceptual models, the level of visual features is removed.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g005" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec009">
<title>Structure-free model</title>
<p>To explicitly test whether a complex attractor dynamics is necessary to describe subjects’ behavior, that is, to test whether an attention-like mechanism modulates the update of beliefs, we require an alternative model without such an attentional focus mechanism. Hence, by setting both <italic>κ</italic><sub><italic>e</italic></sub> and <italic>κ</italic><sub><italic>f</italic></sub> to zero we obtain a structure-free model, denoted by <italic>d</italic>, in which the state transition of <inline-formula id="pcbi.1004558.e103"><alternatives><graphic id="pcbi.1004558.e103g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e103" xlink:type="simple"/><mml:math display="inline" id="M103" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> is described with a diffusive dynamics (<xref rid="pcbi.1004558.g005" ref-type="fig">Fig 5D</xref>). The effect of removing the lateral inhibition is that a feature considered relevant will not inhibit other features, that is, there is no attentional focus effect. Note that setting <italic>κ</italic><sub><italic>e</italic>,<italic>f</italic></sub> = 0 also reduces the number of free parameters, thus the model complexity. Critically, by employing a model with lower complexity enables us to test whether the attentional focus model may be too complex for the behavioral data.</p>
<p>Note that both the structured and the structure-free models are able to capture the transient relevance of visual features. However, one expected difference is that the structured model, as it encodes a key constraint of the task environment, requires less evidence to form strong beliefs about relevance of visual features.</p>
</sec>
<sec id="sec010">
<title>Reduced structured and structure-free models</title>
<p>To further simplify both structured and structure-free models note that the 3<sup>rd</sup> level of the hierarchy encodes the beliefs about the relevance of a visual feature. The importance of the 3<sup>rd</sup> level is to provide, as a dynamical implementation, the integration of the beliefs from the 2<sup>nd</sup> level of the hierarchy. The expectations at the 3<sup>rd</sup> level of the hierarchy are then used to generate responses, as described in the text below. In addition, one can also generate responses by using directly the expectations provided at the 2<sup>nd</sup> level of the hierarchy. In such a case the 3<sup>rd</sup> level of hierarchy is obsolete and can be removed.</p>
<p>In this way we obtain two reduced variants of the perceptual model defined by the following set of the free parameters <inline-formula id="pcbi.1004558.e104"><alternatives><graphic id="pcbi.1004558.e104g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e104" xlink:type="simple"/><mml:math display="inline" id="M104" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>e</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mo>σ</mml:mo><mml:mi>e</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. For the reduced structured model, denoted by <italic>rw</italic>, <italic>κ</italic><sub><italic>e</italic></sub> is a free parameter (<xref rid="pcbi.1004558.g005" ref-type="fig">Fig 5E</xref>), while for the reduced structure-free model, denoted by <italic>rd</italic>, <italic>κ</italic><sub><italic>e</italic></sub> is fixed to zero (<xref rid="pcbi.1004558.g005" ref-type="fig">Fig 5F</xref>).</p>
<p>Non-Bayesian perceptual models. All the previous variants of the perceptual model were based on the same form of the update equations as provided in Eqs (<xref rid="pcbi.1004558.e081" ref-type="disp-formula">11</xref>) and (<xref rid="pcbi.1004558.e086" ref-type="disp-formula">12</xref>). The only difference so far between them is that certain parameters were removed, that is, fixed to zero. Importantly, these update equations are based on the assumption that subjects combine prior beliefs and sensory information in a Bayes optimal fashion. This requires the representation of both the expectations about the true state of the world and the uncertainties about these expectations. This assumption might not be correct in our case, and potentially the only relevant quantity, both for update of beliefs and for generating responses, might be the expectations about the relevance of exemplars and visual features. Thus, to test for this possibility we considered a non-Bayesian variant of the perceptual model described above, in which we fix the values of prior and posterior uncertainty on all levels of the hierarchy. This effectively makes the perceptual model non-Bayesian, as the sensory observations are not combined with the prior knowledge in a Bayes-optimal fashion. Thus, in the non-Bayesian variant of the perceptual model, we will set the posterior covariance matrix to a fixed value, Σ<sub><italic>t</italic></sub> = <italic>αI</italic><sub>9</sub>, which leads to the following update equations of expectations
<disp-formula id="pcbi.1004558.e105">
<alternatives>
<graphic id="pcbi.1004558.e105g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e105" xlink:type="simple"/>
<mml:math display="block" id="M105" overflow="scroll">
<mml:mtable><mml:mtr><mml:mtd><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ρ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mi>π</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>e</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable>
</mml:math>
</alternatives>
<label>(13)</label>
</disp-formula></p>
<p>Furthermore, in this formulation the evidence <italic>ρ</italic><sub><italic>t</italic>,<italic>k</italic></sub> = 1 − <italic>ϵ</italic> if the exemplar supporting <italic>k</italic>th hypothesis was selected and <italic>ρ</italic><sub><italic>t</italic>,<italic>k</italic></sub> = <italic>ϵ</italic> otherwise, where <inline-formula id="pcbi.1004558.e106"><alternatives><graphic id="pcbi.1004558.e106g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e106" xlink:type="simple"/><mml:math display="inline" id="M106" overflow="scroll"><mml:mrow><mml:mi>ϵ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> denotes a free parameter which is not equivalent to the experimenters error rate <italic>ε</italic>, but only related to it. Note that the update equations shown in <xref rid="pcbi.1004558.e105" ref-type="disp-formula">Eq (13)</xref> have a functional form similar to the Rescorla-Wagner model which is often used in reinforcement learning models [<xref rid="pcbi.1004558.ref068" ref-type="bibr">68</xref>,<xref rid="pcbi.1004558.ref069" ref-type="bibr">69</xref>].</p>
</sec>
<sec id="sec011">
<title>Response model</title>
<p>Having obtained the update equation for the hidden belief states, the next step is to define an appropriate response model (see <xref rid="pcbi.1004558.g003" ref-type="fig">Fig 3</xref>). Thus, the question we will answer here is what would be an optimal response in an experimental trial <italic>t</italic> given the hidden beliefs <italic>b</italic><sub><italic>t</italic></sub>? Note first that the posterior probability that the <italic>i</italic>th visual feature is currently relevant is defined as
<disp-formula id="pcbi.1004558.e107">
<alternatives>
<graphic id="pcbi.1004558.e107g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e107" xlink:type="simple"/>
<mml:math display="block" id="M107" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
in the case of the perceptual model variants with the 3<sup>rd</sup> level of hierarchy, and
<disp-formula id="pcbi.1004558.e108">
<alternatives>
<graphic id="pcbi.1004558.e108g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e108" xlink:type="simple"/>
<mml:math display="block" id="M108" overflow="scroll">
<mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>6</mml:mn></mml:msubsup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
in the case of the reduced perceptual model variants without the 3<sup>rd</sup> level (where <italic>i</italic><sub>1</sub> and <italic>i</italic><sub>2</sub> denote the positions of the exemplars of the corresponding <italic>i</italic>th visual feature).</p>
<p>Importantly, as described above, we have instructed the subjects that at the end of the experiment one of the experimental trials will be randomly selected and the subject will receive as a reward the money that they have assigned to the truly relevant visual feature. Thus, we will assume that the subject’s responses depend on the subject’s risk attitude. As various studies have demonstrated that humans exhibit variable risk tendencies [<xref rid="pcbi.1004558.ref070" ref-type="bibr">70</xref>–<xref rid="pcbi.1004558.ref073" ref-type="bibr">73</xref>], we will parametrize the subject’s individual levels of risk aversion with an inverse risk factor <italic>θ</italic><sub>1</sub>. Using the formalism of the Bayesian decision theory (BDT) and under the assumption that a subject’s absolute risk aversion is inversely related to the outcome of the bet, we have derived theoretical evidence that the optimal response (for more details see <xref rid="pcbi.1004558.s002" ref-type="supplementary-material">S2 Text</xref>) is defined as
<disp-formula id="pcbi.1004558.e109">
<alternatives>
<graphic id="pcbi.1004558.e109g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e109" xlink:type="simple"/>
<mml:math display="block" id="M109" overflow="scroll">
<mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:msubsup><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(14)</label>
</disp-formula>
where the elements of the response vector <inline-formula id="pcbi.1004558.e110"><alternatives><graphic id="pcbi.1004558.e110g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e110" xlink:type="simple"/><mml:math display="inline" id="M110" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denote the fraction of money assigned to the corresponding visual feature. Note that the higher the <italic>θ</italic><sub>1</sub> is the more money will be assigned to the visual feature with highest posterior probability <italic>p</italic><sub><italic>t</italic>,<italic>j</italic></sub>, hence the higher the <italic>θ</italic><sub>1</sub> the riskier is the subject’s behavior. In the limit of <italic>θ</italic><sub>1</sub>→0, the responses become independent of the posterior beliefs and the same amount of money is always assigned to all visual features, thus reflecting infinite risk aversion.</p>
<p>However, using the optimal response function to model subjects’ behavior may be too restrictive, as the behavioral responses might deviate from the optimal responses for at least two reasons: First, the perceptual models proposed might not fully capture the hidden perceptual processes of human subject, thus there might be an unknown influences on the decision process. Second, recent findings suggest that human brain maintains only stochastic representation of posterior beliefs [<xref rid="pcbi.1004558.ref051" ref-type="bibr">51</xref>]. In other words, an exact representation of posterior expectations is not internally available to the subject. Thus, under an assumption that the posterior expectations are sampled stochastically, one expects that the deviation of the response from the optimal one is proportional to the posterior uncertainty [<xref rid="pcbi.1004558.ref051" ref-type="bibr">51</xref>].</p>
<p>To account for potential deviation from optimal response we will define the behavioral responses as
<disp-formula id="pcbi.1004558.e111">
<alternatives>
<graphic id="pcbi.1004558.e111g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e111" xlink:type="simple"/>
<mml:math display="block" id="M111" overflow="scroll">
<mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:msubsup><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msup><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(15)</label>
</disp-formula>
where <inline-formula id="pcbi.1004558.e112"><alternatives><graphic id="pcbi.1004558.e112g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e112" xlink:type="simple"/><mml:math display="inline" id="M112" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes a vector of i.i.d. random variables representing perturbations to the optimal response. We will assume here that the perturbation term <inline-formula id="pcbi.1004558.e113"><alternatives><graphic id="pcbi.1004558.e113g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e113" xlink:type="simple"/><mml:math display="inline" id="M113" overflow="scroll"><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> has two components expressed as separate components of the covariance matrix of a zero-mean Gaussian distribution:
<disp-formula id="pcbi.1004558.e114">
<alternatives>
<graphic id="pcbi.1004558.e114g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e114" xlink:type="simple"/>
<mml:math display="block" id="M114" overflow="scroll">
<mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>ξ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>;</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:msub><mml:mi>I</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:msubsup><mml:mo>Σ</mml:mo><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(16)</label>
</disp-formula></p>
<p>The first noise source represents unknown influences on the decision process, which we assume to be i.i.d. The second noise source, which represents the above stochastic sampling assumption, is proportional to the uncertainty about the expected relevance of the visual features. Note that the second component is only relevant for the probabilistic variants of the perceptual model with full hierarchical representation, as only in those cases is the posterior uncertainty about the feature relevance a dynamic quantity. Consequently, the full set of the parameters for the response model <italic>m</italic><sup>(<italic>r</italic>)</sup> becomes <italic>θ</italic> = {<italic>θ</italic><sub>1</sub>,<italic>θ</italic><sub>2</sub>,<italic>θ</italic><sub>3</sub>}.</p>
<p>Finally, for the above defined response model the response likelihood is defined as the multivariate logistic-normal distribution, that is,
<disp-formula id="pcbi.1004558.e115">
<alternatives>
<graphic id="pcbi.1004558.e115g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e115" xlink:type="simple"/>
<mml:math display="block" id="M115" overflow="scroll">
<mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>3</mml:mn><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Here <inline-formula id="pcbi.1004558.e116"><alternatives><graphic id="pcbi.1004558.e116g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e116" xlink:type="simple"/><mml:math display="inline" id="M116" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> denotes the centered log-ratio transform
<disp-formula id="pcbi.1004558.e117">
<alternatives>
<graphic id="pcbi.1004558.e117g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e117" xlink:type="simple"/>
<mml:math display="block" id="M117" overflow="scroll">
<mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mroot><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow><mml:mn>3</mml:mn></mml:mroot></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<inline-formula id="pcbi.1004558.e118"><alternatives><graphic id="pcbi.1004558.e118g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e118" xlink:type="simple"/><mml:math display="inline" id="M118" overflow="scroll"><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> denotes a normalization constant, and <inline-formula id="pcbi.1004558.e119"><alternatives><graphic id="pcbi.1004558.e119g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e119" xlink:type="simple"/><mml:math display="inline" id="M119" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> in the case of the full perceptual model or <inline-formula id="pcbi.1004558.e120"><alternatives><graphic id="pcbi.1004558.e120g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e120" xlink:type="simple"/><mml:math display="inline" id="M120" overflow="scroll"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>p</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> in the case of the reduced perceptual model.</p>
<p>The normalization constant is computed as
<disp-formula id="pcbi.1004558.e121">
<alternatives>
<graphic id="pcbi.1004558.e121g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e121" xlink:type="simple"/>
<mml:math display="block" id="M121" overflow="scroll">
<mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munder><mml:mo>∭</mml:mo><mml:mi>ℝ</mml:mi></mml:munder><mml:mrow><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:mo>⋅</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mstyle><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where the projection vector <inline-formula id="pcbi.1004558.e122"><alternatives><graphic id="pcbi.1004558.e122g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e122" xlink:type="simple"/><mml:math display="inline" id="M122" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>a</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. The normalization constant is required because of the mapping of the space of posterior expectations <inline-formula id="pcbi.1004558.e123"><alternatives><graphic id="pcbi.1004558.e123g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e123" xlink:type="simple"/><mml:math display="inline" id="M123" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> onto a 2D simplex, which is the space of responses <inline-formula id="pcbi.1004558.e124"><alternatives><graphic id="pcbi.1004558.e124g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e124" xlink:type="simple"/><mml:math display="inline" id="M124" overflow="scroll"><mml:mrow><mml:msup><mml:mo>Δ</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>|</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext>  </mml:mtext><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mtext> for </mml:mtext><mml:mo>∀</mml:mo><mml:mtext> </mml:mtext><mml:mi>i</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mtext> </mml:mtext></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>For model comparisons, we will consider two response models. For both models, all the equations in this section apply, but the critical difference is that we only allow <italic>θ</italic><sub>3</sub> as a free parameter in the so-called full response model, while in the reduced response model we fix <italic>θ</italic><sub>3</sub> at 0. The effect of this difference is that the reduced model assumes a constant response variability of subjects, while the full response model allows for response variability to be dependent on the internal uncertainty about feature relevance. Note that having the inverse risk factor <italic>θ</italic><sub>1</sub> as a free parameter in all variants of the response model is a result of a preliminary analysis (not presented here) which showed that response model variants with fixed risk factor have substantially lower model evidence compared to the considered variants of the response model.</p>
</sec>
</sec>
<sec id="sec012">
<title>List of models and model evidence computation</title>
<p>For the model comparison, we have paired all the full variants of the Bayesian perceptual models with the two variants of the response model; the reduced variants of the Bayesian models and all the variants of the non-Bayesian perceptual models were paired only with the reduced response model, as the posterior uncertainty about the visual features <inline-formula id="pcbi.1004558.e125"><alternatives><graphic id="pcbi.1004558.e125g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e125" xlink:type="simple"/><mml:math display="inline" id="M125" overflow="scroll"><mml:mrow><mml:msubsup><mml:mo>Σ</mml:mo><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> is set to constant values in this cases. In addition, we have defined a simple baseline model. Hence in total we consider 17 behavioral models denoted as:</p>
<list list-type="order">
<list-item><p><italic>BM</italic>—Baseline model in which the beliefs and the uncertainties about the beliefs are assumed to be constant over time. Thus, all the parameters of the perceptual model are set to zero, except <inline-formula id="pcbi.1004558.e126"><alternatives><graphic id="pcbi.1004558.e126g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e126" xlink:type="simple"/><mml:math display="inline" id="M126" overflow="scroll"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. Similarly, we fixed <italic>θ</italic><sub>1</sub> = <italic>θ</italic><sub>2</sub> = 1 as they are redundant for this case and leave only <italic>θ</italic><sub>3</sub> as the free parameters of the response model. The role of the baseline model here is to provide for a trivial explanation to the behavioral data: subjects generated random responses around a fixed mean independent from the sensory cues.</p></list-item>
<list-item><p><inline-formula id="pcbi.1004558.e127"><alternatives><graphic id="pcbi.1004558.e127g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e127" xlink:type="simple"/><mml:math display="inline" id="M127" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>—Twelve different Bayesian perceptual models, where the superscript denotes the variant of the response model (<italic>f</italic>→<italic>θ</italic><sub>2</sub>&gt; 0, <italic>r</italic>→<italic>θ</italic><sub>2</sub> = 0), and the subscript denotes the variants of the perceptual model (<italic>rw</italic>→ reduced perceptual model with lateral inhibition, <italic>rd</italic>→ reduced perceptual model without lateral inhibition, <italic>d</italic>→ full perceptual model without inhibition at all levels, <italic>w</italic><sub>1</sub>→ full model with lateral inhibition on all levels, <italic>w</italic><sub>2</sub>→ full model with lateral inhibition only at the 2<sup>nd</sup> level, <italic>w</italic><sub>3</sub>→ full model with lateral inhibition only at the 3<sup>rd</sup> level), see <xref rid="pcbi.1004558.g005" ref-type="fig">Fig 5</xref>.</p></list-item>
<list-item><p><inline-formula id="pcbi.1004558.e128"><alternatives><graphic id="pcbi.1004558.e128g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e128" xlink:type="simple"/><mml:math display="inline" id="M128" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mo> </mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>—Six different non-Bayesian perceptual models, where the superscript denotes the only possible variant of the response model, the reduced response model, and the subscripts denote the variants of the perceptual model, with the same notation as above.</p></list-item>
</list>
<p>To summarize the motivation for these different variants of the perceptual model (see <xref rid="sec002" ref-type="sec">Methods</xref> above for details): the structure-free model variants test for the possibility that the structured representation is not required for describing the behavioral data; the model variants without the final level of the hierarchy (<italic>rw</italic>,<italic>rd</italic>) test for the possibility that the final level of hierarchy is redundant for describing the behavior; the non-Bayesian variants of the perceptual test for the possibility that the Bayesian observer assumption is not required for describing the behavior.</p>
<p>Each model variant is defined using a set of free parameters {<italic>γ</italic>,<italic>θ</italic>} for the perceptual and response models. To be able to define prior and posterior distributions in the same functional form of multivariate normal distributions, we transform all parameters so that they have the same domain of real numbers. Note that such a transformation does not change the value of model evidences, as to compute the model evidence one integrates over all the free parameters of a generative model. Let us denote by <inline-formula id="pcbi.1004558.e129"><alternatives><graphic id="pcbi.1004558.e129g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e129" xlink:type="simple"/><mml:math display="inline" id="M129" overflow="scroll"><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> the vector of perceptual and response parameters transformed to real space, then <inline-formula id="pcbi.1004558.e130"><alternatives><graphic id="pcbi.1004558.e130g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e130" xlink:type="simple"/><mml:math display="inline" id="M130" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϑ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>γ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>ϑ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where
<disp-formula id="pcbi.1004558.e131">
<alternatives>
<graphic id="pcbi.1004558.e131g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e131" xlink:type="simple"/>
<mml:math display="block" id="M131" overflow="scroll">
<mml:mrow><mml:mi>ϑ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:mi>z</mml:mi><mml:mo> </mml:mo><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msubsup><mml:mo>σ</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>z</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mi>ε</mml:mi><mml:mo> </mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>z</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo> </mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mo> </mml:mo><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mo> </mml:mo><mml:mi>z</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>e</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>μ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Thus, we can define the prior distribution over model parameters as a multivariate normal distribution <inline-formula id="pcbi.1004558.e132"><alternatives><graphic id="pcbi.1004558.e132g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e132" xlink:type="simple"/><mml:math display="inline" id="M132" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>The log-joint probability distribution can then be written as
<disp-formula id="pcbi.1004558.e133">
<alternatives>
<graphic id="pcbi.1004558.e133g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e133" xlink:type="simple"/>
<mml:math display="block" id="M133" overflow="scroll">
<mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mtext>ln</mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>r</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>γ</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>ϑ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>θ</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mtext>ln</mml:mtext><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>;</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>η</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(17)</label>
</disp-formula>
where <italic>T</italic> denotes the number of trials within a single experimental block. The Laplace approximation to the log-evidence is obtained as
<disp-formula id="pcbi.1004558.e134">
<alternatives>
<graphic id="pcbi.1004558.e134g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e134" xlink:type="simple"/>
<mml:math display="block" id="M134" overflow="scroll">
<mml:mrow><mml:mtext>ln</mml:mtext><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>e</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mn>1</mml:mn><mml:mo>…</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mtext>ln</mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(18)</label>
</disp-formula>
where <inline-formula id="pcbi.1004558.e135"><alternatives><graphic id="pcbi.1004558.e135g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e135" xlink:type="simple"/><mml:math display="inline" id="M135" overflow="scroll"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> denotes the mode of <inline-formula id="pcbi.1004558.e136"><alternatives><graphic id="pcbi.1004558.e136g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e136" xlink:type="simple"/><mml:math display="inline" id="M136" overflow="scroll"><mml:mrow><mml:mo> </mml:mo><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004558.e137"><alternatives><graphic id="pcbi.1004558.e137g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e137" xlink:type="simple"/><mml:math display="inline" id="M137" overflow="scroll"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mo>∂</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:msub><mml:mi>l</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mo>|</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo stretchy="true">→</mml:mo></mml:mover></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, <italic>i</italic>.<italic>e</italic>. S is the negative inverse of the Hessian matrix at the mode <inline-formula id="pcbi.1004558.e138"><alternatives><graphic id="pcbi.1004558.e138g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e138" xlink:type="simple"/><mml:math display="inline" id="M138" overflow="scroll"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula>.</p>
<p>To find the mode of <inline-formula id="pcbi.1004558.e139"><alternatives><graphic id="pcbi.1004558.e139g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e139" xlink:type="simple"/><mml:math display="inline" id="M139" overflow="scroll"><mml:mrow><mml:mi>l</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> we applied the so-called Covariance Matrix Adaptation Evolution Strategy (CMA-ES). CMA-ES is a numerical optimization method, which has been applied successfully in various research areas [<xref rid="pcbi.1004558.ref074" ref-type="bibr">74</xref>–<xref rid="pcbi.1004558.ref077" ref-type="bibr">77</xref>] and is particularly useful for ill-conditioned and multimodal objective functions. In short, CMA-ES is a stochastic derivative-free method for numerical optimization of non-linear optimization problems [<xref rid="pcbi.1004558.ref056" ref-type="bibr">56</xref>,<xref rid="pcbi.1004558.ref057" ref-type="bibr">57</xref>]. We used a freely available Matlab toolbox that implements the algorithm [Hansen, Nikolaus (2004). (<ext-link ext-link-type="uri" xlink:href="https://www.lri.fr/~hansen/cmaes_inmatlab.html#matlab" xlink:type="simple">https://www.lri.fr/~hansen/cmaes_inmatlab.html#matlab</ext-link>), Version 3.61].</p>
<p>Once the mode of the log-joint probability distribution (<xref rid="pcbi.1004558.e133" ref-type="disp-formula">Eq (17)</xref>) is found, we have to estimate the curvature at the mode, that is, the Hessian matrix. We estimated the Hessian matrix by numerical differentiation [<xref rid="pcbi.1004558.ref058" ref-type="bibr">58</xref>], where we used the following toolbox [D’Errico, John (2006). (<ext-link ext-link-type="uri" xlink:href="http://www.mathworks.de/matlabcentral/fileexchange/13490" xlink:type="simple">http://www.mathworks.de/matlabcentral/fileexchange/13490</ext-link>), MATLAB Central File Exchange. Retrieved 10. November 2013].</p>
<p>Because of the stochastic nature of the CMA-ES algorithm we repeated the stochastic search <italic>N</italic> = 50 times per experimental block for each model. For each of the <italic>N</italic> solutions we estimated the Hessian matrix and computed the Laplace approximation to the log-evidence. Finally, we kept the solution with the largest log-evidence, therefore increasing the probability of finding the maximal lower bound to the log-evidence and thus the most likely model of a subject’s behavior. The numerically obtained <inline-formula id="pcbi.1004558.e140"><alternatives><graphic id="pcbi.1004558.e140g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e140" xlink:type="simple"/><mml:math display="inline" id="M140" overflow="scroll"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and <italic>S</italic> are used as the mean and the covariance matrix of the approximate posterior distribution <inline-formula id="pcbi.1004558.e141"><alternatives><graphic id="pcbi.1004558.e141g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e141" xlink:type="simple"/><mml:math display="inline" id="M141" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>χ</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>;</mml:mo><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Note that in this way we obtain the full covariance matrix without the need for a mean field approximation, which would neglect any existing correlations between parameters. All data processing was performed using MATLAB [version 8.1, The MathWorks Inc., Natick, Massachusetts].</p>
</sec>
<sec id="sec013">
<title>Bayesian model selection</title>
<p>We first estimated the log model evidence of the 17 generative models described above for each experimental block. To obtain a total per-subject log-evidence for each experimental condition, we summed the estimated log-evidences over experimental blocks of a single experimental condition. This gives us the log model evidence of each generative model for each subject per experimental condition. We used the obtained log-evidences to apply the hierarchical Bayesian model selection approach described in [<xref rid="pcbi.1004558.ref054" ref-type="bibr">54</xref>,<xref rid="pcbi.1004558.ref055" ref-type="bibr">55</xref>]. By using hierarchical Bayesian model selection we assumed that the identity of the best-fitting model may vary across subjects. This requires treating the posterior model probability (the posterior belief that a given model has generated the data) as a random variable.</p>
<p>Thus, the two computed quantities of interest are the expected probability (EP) and the exceedance probability (XP) of each model: The EP is defined as the probability that a given model generated the behavioral data of a randomly selected subject (see [<xref rid="pcbi.1004558.ref055" ref-type="bibr">55</xref>] for a detailed mathematical description); The exceedance probability XP tells how likely it is that a given model will have the largest probability in a random sample from the posterior distribution. Importantly, the XP can be seen as a degree of confidence in the difference between posterior model probabilities [<xref rid="pcbi.1004558.ref055" ref-type="bibr">55</xref>]. Thus, when presenting the results of a model comparison we will only report the XP of the corresponding model or model family, as large XP at the same time implies significantly larger EP. Importantly, we will only consider recently proposed “protected” exceedance probability, which takes into account the null hypothesis that assumes that all the models are equally likely (see [<xref rid="pcbi.1004558.ref055" ref-type="bibr">55</xref>] for details). We will consider that the EP of a single generative model is significantly larger than the EP of other generative models, if the model’s XP is above threshold value set at 0.95. Although, this threshold value was selected in the analogy to classical statistical tests that rely on p-values, its relation to the statistical power is not equivalent (see [<xref rid="pcbi.1004558.ref055" ref-type="bibr">55</xref>]).</p>
<p>We used the MATLAB implementation of the random-effect Bayesian model selection [(<ext-link ext-link-type="uri" xlink:href="https://sites.google.com/site/jeandaunizeauswebsite/code/rfx-bms" xlink:type="simple">https://sites.google.com/site/jeandaunizeauswebsite/code/rfx-bms</ext-link>), retrieved January 2014]. In what follows we will describe the results obtained by applying the Bayesian model selection to the set of behavioral models that we used to approximate subjects’ behavior in the probabilistic WCST.</p>
</sec>
</sec>
<sec id="sec014" sec-type="results">
<title>Results</title>
<p>In Figs <xref rid="pcbi.1004558.g006" ref-type="fig">6</xref> and <xref rid="pcbi.1004558.g007" ref-type="fig">7</xref> we present the results of the random-effects Bayesian model comparison at the group-level. We have separated the model comparison between the two experimental conditions, switch and no-switch. We estimated the per-subject log-evidence for each experimental condition as the sum of log-evidences across the three corresponding experimental blocks. The top graph in both Figs <xref rid="pcbi.1004558.g006" ref-type="fig">6</xref> and <xref rid="pcbi.1004558.g007" ref-type="fig">7</xref> depicts the model attributions to the behavioral responses of each subject, that is, the posterior probability that a given model has generated the behavioral responses of each subject, for each condition separately. The bottom graphs show the corresponding XP for each of the 17 models. The direct comparison of behavioral models is inconclusive, as the highest XP is in both cases below the threshold value. Note that this is a typical issue when the model comparison set contains groups of closely related models [<xref rid="pcbi.1004558.ref078" ref-type="bibr">78</xref>].</p>
<fig id="pcbi.1004558.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Random-effects model comparison for the no-switch condition.</title>
<p>(top) Posterior model probability (see color bar) for each subject. For an exact description of each of the 17 models see main text. (bottom) Exceedance probability (XP) that a given model is more likely to generate the data than any other model. The dashed orange line denotes the confidence threshold level set at 0.95.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g006" position="float" xlink:type="simple"/>
</fig>
<fig id="pcbi.1004558.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Random-effects model comparison for the switch condition.</title>
<p>(top) Posterior model probability (see color bar) for each subject. For the exact description of each of the 17 models see main text. (bottom) Exceedance probability (XP) that a given model is more likely to generate the data than any other model. The dashed orange line denotes the confidence threshold level set at 0.95.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g007" position="float" xlink:type="simple"/>
</fig>
<p>The solution here is that instead of trying to answer which of the models provides the best description of behavioral data, we should ask which of the features of the perceptual and the response model are the most relevant for generating the data [<xref rid="pcbi.1004558.ref078" ref-type="bibr">78</xref>]. Note that in both figures we observe clustering of high model probabilities (top graphs) within closely related perceptual models (e.g. <inline-formula id="pcbi.1004558.e142"><alternatives><graphic id="pcbi.1004558.e142g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e142" xlink:type="simple"/><mml:math display="inline" id="M142" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mi>f</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>) which only differ in the type of the connectivity matrix (see subsection Structured models in <xref rid="sec002" ref-type="sec">Methods</xref>). Thus, to determine which of the features of the perceptual and the response model are the most relevant for generating the behavioral data, we have performed four so-called family-wise model comparisons [<xref rid="pcbi.1004558.ref078" ref-type="bibr">78</xref>]. To test whether non-Bayesian or Bayesian model variants better describe the behavioral data, we grouped all models into baseline (BM = {<italic>BM</italic>}), non-Bayesian <inline-formula id="pcbi.1004558.e143"><alternatives><graphic id="pcbi.1004558.e143g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e143" xlink:type="simple"/><mml:math display="inline" id="M143" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>NB</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and Bayesian <inline-formula id="pcbi.1004558.e144"><alternatives><graphic id="pcbi.1004558.e144g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e144" xlink:type="simple"/><mml:math display="inline" id="M144" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>B</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> model families. Similarly, to test whether a hierarchical representation of feature relevance is truly necessary we have grouped the models into BM, reduced perceptual <inline-formula id="pcbi.1004558.e145"><alternatives><graphic id="pcbi.1004558.e145g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e145" xlink:type="simple"/><mml:math display="inline" id="M145" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>RP</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and full perceptual <inline-formula id="pcbi.1004558.e146"><alternatives><graphic id="pcbi.1004558.e146g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e146" xlink:type="simple"/><mml:math display="inline" id="M146" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>FP</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> model families. Finally, to test whether the attractor dynamics contributes to an explanation of the behavioral data, we have grouped models into the BM, structure-free <inline-formula id="pcbi.1004558.e147"><alternatives><graphic id="pcbi.1004558.e147g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e147" xlink:type="simple"/><mml:math display="inline" id="M147" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>SFM</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and structured <inline-formula id="pcbi.1004558.e148"><alternatives><graphic id="pcbi.1004558.e148g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e148" xlink:type="simple"/><mml:math display="inline" id="M148" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>SM</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>f</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> model families. In addition to separating behavioral models based on the features of perceptual model, we have grouped them based on the features of the response model, for which we considered only two model families, a model family with the reduced response model <inline-formula id="pcbi.1004558.e149"><alternatives><graphic id="pcbi.1004558.e149g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e149" xlink:type="simple"/><mml:math display="inline" id="M149" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>RR</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mi>M</mml:mi><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and a family with the full response model <inline-formula id="pcbi.1004558.e150"><alternatives><graphic id="pcbi.1004558.e150g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e150" xlink:type="simple"/><mml:math display="inline" id="M150" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>FR</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mi>f</mml:mi></mml:msubsup></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>From the results of the four family-wise model comparisons, shown in <xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8</xref>, we can conclude with high confidence (XP above the threshold level of 0.95) that the Bayesian formulation of the perceptual model is essential for generating behavioral data in both experimental conditions (see <xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8A and 8B</xref>). To understand the difference between NB and B model families in their ability to predict subjects’ behavior we tested how well the behavioral models within each of these families predict subjects’ performance. We computed the mean model performance by first estimating the expected performance per trial. To do this, we fixed model parameters to the mode <inline-formula id="pcbi.1004558.e151"><alternatives><graphic id="pcbi.1004558.e151g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e151" xlink:type="simple"/><mml:math display="inline" id="M151" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> of the posterior parameter distribution and computed the expected model response; hence the expected performance per trial corresponds to the mean fraction of money assigned to the truly relevant visual feature at that trial. We averaged the per-trial expected model performance over a whole experimental block to obtain the mean model performance per experimental block. We then estimated the Pearson correlation coefficient between the mean model performance and mean subjects’ performance across blocks and both experimental conditions. In <xref rid="pcbi.1004558.g009" ref-type="fig">Fig 9</xref> we illustrate, with a box plot, the distribution of the estimated correlation within NB and B model families. The correlation coefficient shows that, on average, the NB model family has significantly lower correlation with subjects’ performance, or in other words, the NB model family provides a worse fit to subjects’ behavior compared to the Bayesian model family. Interestingly, within the NB family the models with consistently low correlation, in both conditions, are the structure-free model variants <inline-formula id="pcbi.1004558.e152"><alternatives><graphic id="pcbi.1004558.e152g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e152" xlink:type="simple"/><mml:math display="inline" id="M152" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004558.e153"><alternatives><graphic id="pcbi.1004558.e153g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e153" xlink:type="simple"/><mml:math display="inline" id="M153" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (see <xref rid="pcbi.1004558.s004" ref-type="supplementary-material">S1 Fig</xref>), whose update equation correspond to what is typically used in classical reinforcement learning models. On the other hand, the non-Bayesian model variants with attractor dynamics, namely <inline-formula id="pcbi.1004558.e154"><alternatives><graphic id="pcbi.1004558.e154g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e154" xlink:type="simple"/><mml:math display="inline" id="M154" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, show consistently high correlation with subjects’ performance in both conditions (with one exception being model <inline-formula id="pcbi.1004558.e155"><alternatives><graphic id="pcbi.1004558.e155g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e155" xlink:type="simple"/><mml:math display="inline" id="M155" overflow="scroll"><mml:mrow><mml:mi>N</mml:mi><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>). This indicates that even only within the NB model family the attentional focus mechanism plays a critical role in replicating subjects’ behavior.</p>
<fig id="pcbi.1004558.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Family-wise model comparisons.</title>
<p>(A-B) Exceedance probability (XP) of the baseline model (BM) non-Bayesian (NB) and Bayesian (B) model families. (C-D) XP of the BM, reduced perceptual (RP) and full perceptual (FP) model families. (E-F) XP of the BM, structure-free (SFM) and structured (SM) model families. (G-H) XP of the reduced response (RR) and full response (RR) model families. The top graphs (A,C,E,G) show the exceedance probability of model families for the switch condition, whereas the bottom graphs (B, D, F, H) show the exceedance probability of the model families for the no-switch condition. The dashed orange lines denote the confidence threshold level set at 0.95.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g008" position="float" xlink:type="simple"/>
</fig>
<fig id="pcbi.1004558.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Distribution of the correlations between the mean model performance and the mean subjects’ performance across two model families.</title>
<p>Boxplot of the Pearson correlation coefficient <italic>r</italic><sub><italic>corr</italic></sub> estimated for each model within the non-Bayesian (NB) and the Bayesian (B) model families in the no-switch and switch condition. For each model within each family we have computed the Pearson correlation coefficient between the mean model performance and mean subjects’ performance. In both conditions the non-Bayesian model family has a significantly lower median correlation (denoted by a dark horizontal line within the boxes) with <italic>p</italic>&lt;0.005 (Kruskal-Wallis test).</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g009" position="float" xlink:type="simple"/>
</fig>
<p>Importantly, from the results of the family-wise model comparison we can also conclude with high confidence that the full variant of the perceptual model (including both the 2<sup>nd</sup> and 3<sup>rd</sup> level of the hierarchy, see Reduced structured and structure-free models for details) is an essential feature in both experimental conditions (see <xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8C and 8D</xref>). The structured family of the perceptual model shows an XP above the threshold level only in the no-switch condition (<xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8F</xref>), whereas in the switch condition the XP is slightly below the confidence threshold level (<xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8E</xref>), but still high enough to be considered a trend. One possible explanation for the slightly reduced confidence in the structured model family (<xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8E</xref>) is that in the switch condition one expects high levels of posterior uncertainty about the relevance of visual features. This is due to an increased difficulty in assigning contradicting evidence either to an experimenter’s error or a change in the selection rule. Thus, in such an environment one does not expect that a subject can form strong beliefs about the relevance of each visual feature. Hence the attractor dynamics would not show strong advantages in generating the data, when compared to the structure-free model family.</p>
<p>Finally, when comparing model families with the full against the reduced variant of the response model we get mixed results across conditions. The full response model seems to be relevant for generating behavioral data only in the no-switch condition (<xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8H</xref>), whereas in the switch condition the evidence is inconclusive (<xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8G</xref>). This discrepancy between the confidence levels in the two experimental conditions may be caused by the increased difficulty of the switch task, which effectively introduced a higher variability in subjects’ responses. Most of this variability may be explained simply by a high but constant level of response noise as formulated in the reduced response model.</p>
<p>To illustrate the dynamics encountered under the most likely types of behavioral model (<inline-formula id="pcbi.1004558.e156"><alternatives><graphic id="pcbi.1004558.e156g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e156" xlink:type="simple"/><mml:math display="inline" id="M156" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mi>f</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> in the no-switch condition and <inline-formula id="pcbi.1004558.e157"><alternatives><graphic id="pcbi.1004558.e157g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e157" xlink:type="simple"/><mml:math display="inline" id="M157" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> in the switch condition) we have plotted the measured and modeled responses of a representative subject (#9), see <xref rid="pcbi.1004558.g010" ref-type="fig">Fig 10</xref>. The modeled response was averaged over posterior model probability (see top graphs of Figs <xref rid="pcbi.1004558.g006" ref-type="fig">6</xref> and <xref rid="pcbi.1004558.g007" ref-type="fig">7</xref>). Note that for the selected subject only the <inline-formula id="pcbi.1004558.e160"><alternatives><graphic id="pcbi.1004558.e160g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e160" xlink:type="simple"/><mml:math display="inline" id="M160" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:mo> </mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mi>f</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (in the no-switch condition) and <inline-formula id="pcbi.1004558.e158"><alternatives><graphic id="pcbi.1004558.e158g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e158" xlink:type="simple"/><mml:math display="inline" id="M158" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (in the switch condition) have posterior model probabilities close to one and therefore contributed to the shown modeled responses. Importantly, one can see that the expected model responses appropriately track the subject’s responses in all six experimental blocks, and that the deviations of the subject’s responses from the expected response are mostly explained by the response variability, as indicated by the shaded area.</p>
<fig id="pcbi.1004558.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004558.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Behavioral responses and modeled responses for a representative single subject.</title>
<p>(left) The three no-switch blocks, and (right) the three switch blocks. Colored circles denote the behavioral responses of subject #9 obtained as the fraction of money assigned to each of the three visual features on single trials. Solid lines denote the expected model response computed at the mode <inline-formula id="pcbi.1004558.e159"><alternatives><graphic id="pcbi.1004558.e159g" position="anchor" mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.e159" xlink:type="simple"/><mml:math display="inline" id="M159" overflow="scroll"><mml:mrow><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> of the posterior distribution over model parameters and averaged over posterior model probabilities for subject #9 (see Figs <xref rid="pcbi.1004558.g006" ref-type="fig">6</xref> and <xref rid="pcbi.1004558.g007" ref-type="fig">7</xref>). The shaded area corresponds to the 95% probability interval. Each color corresponds to one of the three visual features (red—color, yellow—motion, blue—shape). The dotted colored line at the top of each plot denotes the relevant visual feature during each experimental trial, where the black diamond marks on the dotted line denote trials in which the experimenter selected the wrong card.</p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1004558.g010" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>Discussion</title>
<p>We have used a probabilistic variant of the Wisconsin card sorting task (WCST) with belief solicitation to show that, in a rather complex environment, update of beliefs is modulated by an attentional focus mechanism. We analyzed behavioral data of 22 subjects using a meta-Bayesian framework [<xref rid="pcbi.1004558.ref049" ref-type="bibr">49</xref>,<xref rid="pcbi.1004558.ref050" ref-type="bibr">50</xref>]. This framework allowed us to compare multiple behavioral models, each implementing different assumptions about the underlying mechanisms that govern update of beliefs. We found evidence that incorporating an attentional focus mechanism within the behavioral model is the essential feature for modeling behavior. Specifically, we demonstrated that the attentional focus mechanism modulates subjects’ expectations about the relevance of each visual feature and consequently influences the update of beliefs when new visual evidence is provided. In addition, we found that introducing a deviation from optimal responses (as predicted by Bayesian decision theory), during belief solicitation, further increased model evidence in one experimental condition.</p>
<sec id="sec016">
<title>WCST and belief solicitation</title>
<p>The variant of the WCST used here can be seen as a simple but representative task to which humans are often exposed, namely making decisions in situations where the relevant features of the environment are not obvious but need to be inferred first. What makes the WCST simpler when compared to natural environment is the reduced number of possible pre-learned hypotheses. However, the dynamic complexity is comparable to real world situations: (i) the rules of the environment can change, and (ii) in the specific WCST used here the experimenter occasionally ‘makes a mistake’ just as in the natural environment one often cannot know something with certainty. For the WCST task, these two naturally occurring sources of uncertainties make the necessary inference sufficiently complex to compute the subject’s uncertainty about the relevance of visual features. To better infer the hidden internal beliefs and uncertainties of subjects, we used belief solicitation in a form of a betting assignment, which reflect a subject’s hidden beliefs over the space of possible hypotheses. To our knowledge, such belief solicitation was not previously used in a WCST task, although similar experimental designs were used for simpler tasks [<xref rid="pcbi.1004558.ref011" ref-type="bibr">11</xref>,<xref rid="pcbi.1004558.ref079" ref-type="bibr">79</xref>].</p>
</sec>
<sec id="sec017">
<title>Modeling effects of attention on evolution of beliefs</title>
<p>To incorporate attentional-focus within the perceptual part of the behavioral model we modeled the dynamics of the hidden states of a probabilistic generative model with a winner-take-all (WTA) dynamics. This is a well-known type of dynamics applied to artificial neural networks [<xref rid="pcbi.1004558.ref037" ref-type="bibr">37</xref>–<xref rid="pcbi.1004558.ref040" ref-type="bibr">40</xref>,<xref rid="pcbi.1004558.ref080" ref-type="bibr">80</xref>–<xref rid="pcbi.1004558.ref082" ref-type="bibr">82</xref>] and used as a part of connectionist models of decision making and planning [<xref rid="pcbi.1004558.ref019" ref-type="bibr">19</xref>,<xref rid="pcbi.1004558.ref025" ref-type="bibr">25</xref>]. In addition, WTA network dynamics have been reported to capture a wide range of experimental findings [<xref rid="pcbi.1004558.ref048" ref-type="bibr">48</xref>,<xref rid="pcbi.1004558.ref083" ref-type="bibr">83</xref>–<xref rid="pcbi.1004558.ref086" ref-type="bibr">86</xref>].</p>
<p>For our purposes, the WTA neuronal network implemented a dynamic and self-regulated attention formation at the top level of a hierarchical representation of environmental features.</p>
<p>In comparison to the classical connectionist approach, e.g. [<xref rid="pcbi.1004558.ref025" ref-type="bibr">25</xref>], the main advantage of using the WTA dynamics within a Bayesian framework is that the adaptive coupling between the intrinsic network dynamics and external input (see Eqs (<xref rid="pcbi.1004558.e081" ref-type="disp-formula">11</xref>) and (<xref rid="pcbi.1004558.e086" ref-type="disp-formula">12</xref>)) is derived automatically as part of the update equations. These update equations provide Bayes-optimal behavior of the model by setting the connection weights to their optimal value. Although the optimization technique used by the brain may be different, such weight optimization may be assumed as a guiding computational principle of information processing in the brain.</p>
<p>Our finding—that competitive inhibitory WTA dynamics as a model of attentional focus is required for describing the hidden update process of subjects’ beliefs—is in agreement with previous findings of Wilson and Niv [<xref rid="pcbi.1004558.ref001" ref-type="bibr">1</xref>]. This suggests that in a WCST task humans actively track only the evidence corresponding to features they pay attention to, that is, the ones they found potentially relevant for the current task. Importantly, as a safe-guard against over-fitting the data with a complex WTA dynamics, we employed simpler (with a reduced number of free parameters) variants of the perceptual model. The fact that the less complex behavioral models have lower model evidence suggests that the WTA dynamics has indeed adequate complexity to describe the behavioral data.</p>
</sec>
<sec id="sec018">
<title>Predicting effects on behavior</title>
<p>The WTA dynamics introduces the following features in the evolution of beliefs: (i) faster convergence of beliefs to the working hypothesis; (ii) the beliefs are more inert to frequent changes in the environment, that is, to switch between the hypotheses sufficient amount of contradicting evidence has to accumulate. (iii) The beliefs change faster if the changes in the environment are rare, as after the fixed point is reached beliefs do not evolve further. In contrast, the diffusive dynamics of the SFM variants of the perceptual model is not bounded within finite volume of the belief space. Hence, as the posterior beliefs about a hypothesis’ relevance can be strongly separated if the environment is stable for a long period of time and, once the switch occurs it would take a very long time to adjust the beliefs as nothing constrains the separation of the posterior expectations.</p>
<p>Consequently, as our results suggest, the proposed attractor dynamics modulate expectations. This would predict the following effects on behavior: (i) Even small amount of evidence can have a big impact on beliefs, (ii) if changes in the environment are too frequent they will have smaller impact on beliefs than expected from the diffusive dynamics, and (iii) if changes in the environment are rare it will take less contradicting evidence to change the working hypothesis than predicted by the diffusive and unconstrained dynamics.</p>
</sec>
<sec id="sec019">
<title>Sub-optimality in human behavior</title>
<p>Although various studies have demonstrated that human behavior can approximate a Bayesian observer [<xref rid="pcbi.1004558.ref026" ref-type="bibr">26</xref>–<xref rid="pcbi.1004558.ref028" ref-type="bibr">28</xref>,<xref rid="pcbi.1004558.ref060" ref-type="bibr">60</xref>–<xref rid="pcbi.1004558.ref062" ref-type="bibr">62</xref>,<xref rid="pcbi.1004558.ref087" ref-type="bibr">87</xref>], human subjects can also behave sub-optimally when exposed to sufficiently complex tasks [<xref rid="pcbi.1004558.ref028" ref-type="bibr">28</xref>].</p>
<p>In recent work Acerbi et al. [<xref rid="pcbi.1004558.ref051" ref-type="bibr">51</xref>] have demonstrated that the response variability (deviation from expected response) is proportional to posterior uncertainty. Such a deviation from optimal responses can be explained if one assumes a stochastic representation of the posterior beliefs by the human brain [<xref rid="pcbi.1004558.ref052" ref-type="bibr">52</xref>,<xref rid="pcbi.1004558.ref053" ref-type="bibr">53</xref>].</p>
<p>Thus, to account for potential dependence of response variability on posterior uncertainty we considered two variants of the response model. In the first variant we assume that the response variability is constant over an experimental block. In the second variant we additionally allow for the variability of the modeled responses proportional to the posterior uncertainty (see Eqs (<xref rid="pcbi.1004558.e111" ref-type="disp-formula">15</xref>) and (<xref rid="pcbi.1004558.e114" ref-type="disp-formula">16</xref>)), which accounts for the potential stochastic representation of posterior beliefs.</p>
<p>Depending on the experimental condition both variants of the response model provide good accounts for the deviation of subjects’ responses from the optimal response. In the no-switch condition (the relevance of visual feature is unchanged during the block, see <xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8H</xref>) we found that the response variability is indeed proportional to the posterior uncertainty; in the switch condition (<xref rid="pcbi.1004558.g008" ref-type="fig">Fig 8G</xref>) the evidence is inconclusive although in favor of the assumption that the response variability is fixed and independent of the posterior uncertainty. A reason for this inconclusive result may be the increased difficulty of the experimental task in the switch condition. An increased difficulty makes the behavioral responses noisier (responses deviate more from the optimal response compared to the no-switch condition, see <xref rid="pcbi.1004558.g010" ref-type="fig">Fig 10</xref>). As the average response variability increases, there is less information about the dependency of response variability on experimental trials. Hence, most of this additional variability may be explained simply by a rather high but constant level of response noise as formulated in the reduced response model.</p>
</sec>
<sec id="sec020">
<title>Related work on the computational role of attentional processes</title>
<p>Earlier work on the computational role of attention in the processing of sensory information suggested that attention can be understood as prior expectations about the sensory stimuli [<xref rid="pcbi.1004558.ref088" ref-type="bibr">88</xref>,<xref rid="pcbi.1004558.ref089" ref-type="bibr">89</xref>]. This rather simple view of attention as a prior has recently been extended to account for both selective and integrative attentional phenomena [<xref rid="pcbi.1004558.ref034" ref-type="bibr">34</xref>–<xref rid="pcbi.1004558.ref036" ref-type="bibr">36</xref>]. This extended view suggests that due to the computational complexity of the exact probabilistic inference and the limited amount of available cognitive resources, the human brain has to rely on approximations to efficiently solve perceptual tasks. In other words, the role of attention is to assign limited cognitive resources to the relevant part of the sensory stimuli, which provides local refinement of the internal representation of the hidden states of the environment.</p>
<p>However, this view on attention as an approximation to the exact Bayesian inference has been recently challenged. Under the free-energy principle [<xref rid="pcbi.1004558.ref090" ref-type="bibr">90</xref>]—which suggests that perception, attention, and action are all aimed toward suppressing the perceptual surprise about future sensory stimuli—attention is viewed as a sampling of only those parts of sensory stimuli that have high-precision in relation to the predictions of the internal model of the world [<xref rid="pcbi.1004558.ref033" ref-type="bibr">33</xref>]. Importantly, if the model of the world also predicts the precision of different parts of sensory stimuli, then that prediction is what Friston and colleagues propose to be associated with attention.</p>
<p>Our work presented here can be related to both assumptions about the computational role of attention, and as such cannot reconcile this dispute. Note, that the competitive attractor dynamics can be seen both as an approximation to the exact inference (the attractor dynamics regulates the update of beliefs by assigning the computational resources only to the most relevant hypothesis) and as a suppressor of the perceptual surprise (the attractor dynamics actively reduces the uncertainty about future sensory stimuli by predicting both the future expectation and precision of a categorical probability of hypothesis relevance; see <xref rid="pcbi.1004558.e068" ref-type="disp-formula">Eq (9)</xref>).</p>
</sec>
<sec id="sec021">
<title>Potential limitations of the experimental design</title>
<p>We believe that the probabilistic WCST provides a promising experimental paradigm for investigating complex behavioral models. However, one can probably improve on the current design using two changes. Firstly, in spite of the initial training, several subjects exhibit rather poor performance in the no-switch condition (see <xref rid="pcbi.1004558.g002" ref-type="fig">Fig 2</xref>). Ten out of twenty two subjects show poor performance in at least one experimental block of the no-switch condition. Importantly, we have included these subjects in our analysis, because the model comparison did not show any correlation between subjects’ performance and the best fitting behavioral model. Also note that a key strength of the proposed model is that it can explain this poor performance well, see for example <xref rid="pcbi.1004558.g010" ref-type="fig">Fig 10</xref>; insofar a potentially suboptimal performance does not pose a limitation to the proposed modelling approach. However, the obtained results may be even more compelling if subjects practiced the task until a stable performance is reached for both conditions. Secondly, as mentioned in the Methods section, the error rate <italic>ε</italic> was set to values that induced the most distinct behavioral responses between two experimental conditions, while rendering the switch condition informative enough to induce betting responses in subjects. However, these led to a partially imbalanced manipulation between conditions. Thus, a potential improvement would be to introduce a fractal design, such that both the error rate and the switch probability are incrementally increased. Such a fractal design would provide further insights into how each environmental parameter influences behavior and what effects, if any, each parameter might have on the model comparison.</p>
</sec>
<sec id="sec022">
<title>Limitations of the analytical method</title>
<p>Similar to the experimental design, the analytical approach presented here may also be potentially improved upon. Firstly, as mentioned in the Methods section, the behavioral model proposed here is not the only possible formulation. Depending on how one defines the observation likelihood (<xref rid="pcbi.1004558.e021" ref-type="disp-formula">Eq (4)</xref>) and the parametrization of the hypothesis probability (<xref rid="pcbi.1004558.e024" ref-type="disp-formula">Eq (5)</xref>), one can obtain different variants of the perceptual model. Although we have tested a couple of them (one additional, alternative formulation is described in <xref rid="pcbi.1004558.s001" ref-type="supplementary-material">S1 Text</xref>), there is a large number of possible perceptual models. We anticipate that more studies are required to come to a general conclusion which of the models or model families is the most useful for describing behavioral data of studies similar to the one presented here. Secondly, the model comparison presented here relies solely on the Bayesian model selection that is useful for inferring which of the given models is most likely to generate the data. However, it cannot be directly used to answer the question whether a given model is a good predictor of behavior. To address this question one has to rely on cross-validation strategies, that is, on model testing [<xref rid="pcbi.1004558.ref091" ref-type="bibr">91</xref>]. Still, one important prior assumption of model testing is that the behavior can be described by parameters which are stable over blocks. We do not assume that this is the case for our experimental data as subjects were not over-trained which would motivate the assumption that subjects performed the task in some stable parameter regime. Thus, it is plausible that the experience in previous experimental blocks influences, at least slightly, the behavior in subsequent blocks. For this reason model testing may not be usefully applicable to our study. Nevertheless, for future studies changes to the training procedure may stabilize behavior across experimental blocks and would allow one to also apply model testing methods to predict behavior.</p>
</sec>
<sec id="sec023">
<title>Neuroimaging application</title>
<p>Although the presented analysis has been applied to behavioral data only, it would be potentially useful and feasible to extend the behavioral analysis to the investigation of neuroimaging data. The inferred belief trajectories would be used as regressors [<xref rid="pcbi.1004558.ref013" ref-type="bibr">13</xref>], and thus can provide insights into the functional aspects of specific brain areas involved in the decision making process during the ongoing task.</p>
</sec>
<sec id="sec024">
<title>Conclusion</title>
<p>We found strong evidence that an attention-like mechanism modulates the update of beliefs in human subjects who had to infer the relevance of various features in a dynamic and noisy environment. Effectively, this attentional focus facilitates the increase of expectations about the relevant feature and inhibits the expectations about irrelevant features. Subsequently, these modulated expectations affect update of beliefs. We expect that the same computational mechanism can be applied to modelling other complex tasks that impose high cognitive load on subjects, thus require the attentional focus strategies for decision making.</p>
</sec>
</sec>
<sec id="sec025">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004558.s001" xlink:href="info:doi/10.1371/journal.pcbi.1004558.s001" mimetype="application/pdf" position="float" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>An alternative formulation of the perceptual model.</title>
<p>Contains derivations of an alternative perceptual model (and reduced model variants) and also contains the results of the model comparison.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004558.s002" xlink:href="info:doi/10.1371/journal.pcbi.1004558.s002" mimetype="application/pdf" position="float" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Response model derivation.</title>
<p>Contains detailed derivation of the response model within the framework of Bayesian decision theory.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004558.s003" xlink:href="info:doi/10.1371/journal.pcbi.1004558.s003" mimetype="application/x-compressed" position="float" xlink:type="simple">
<label>S1 Data</label>
<caption>
<title>Collection of data files.</title>
<p>Contains behavioral data, posterior and prior expectation (and covariance matrix) of the free model parameters, estimated log-model evidence for each behavioral model, and the model comparison results.</p>
<p>(GZ)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004558.s004" xlink:href="info:doi/10.1371/journal.pcbi.1004558.s004" mimetype="image/tiff" position="float" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Correlations between the expected model performance and the measured subjects’ performance.</title>
<p>Pearson correlation coefficient <italic>r</italic><sub><italic>corr</italic></sub> between the mean subject performance and the mean model performance, for each behavioral model in the switch (top) and no-switch condition (bottom).</p>
<p>(TIFF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Sebastian Bitzer and Daniel McNamee for helpful discussions and comments on earlier versions of the manuscript. We also thank the Center of Information Services and High Performance Computing (ZIH) at Technische Universität Dresden for providing the computer resources.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004558.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilson</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name> (<year>2011</year>) <article-title>Inferring relevance in a changing world</article-title>. <source>Frontiers in human neuroscience</source> <volume>5</volume>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref002"><label>2</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Roberts</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Robbins</surname> <given-names>TW</given-names></name>, <name name-style="western"><surname>Weiskrantz</surname> <given-names>LE</given-names></name> (<year>1998</year>) <source>The prefrontal cortex: Executive and cognitive functions</source>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Milner</surname> <given-names>B</given-names></name> (<year>1963</year>) <article-title>Effects of different brain lesions on card sorting: The role of the frontal lobes</article-title>. <source>Archives of Neurology</source> <volume>9</volume>: <fpage>90</fpage>–<lpage>00</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Drewe</surname> <given-names>E</given-names></name> (<year>1974</year>) <article-title>The effect of type and area of brain lesion on Wisconsin Card Sorting Test performance</article-title>. <source>Cortex</source> <volume>10</volume>: <fpage>159</fpage>–<lpage>170</lpage>. <object-id pub-id-type="pmid">4844468</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nelson</surname> <given-names>HE</given-names></name> (<year>1976</year>) <article-title>A modified card sorting test sensitive to frontal lobe defects</article-title>. <source>Cortex</source> <volume>12</volume>: <fpage>313</fpage>–<lpage>324</lpage>. <object-id pub-id-type="pmid">1009768</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Robinson</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Heaton</surname> <given-names>RK</given-names></name>, <name name-style="western"><surname>Lehman</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Stilson</surname> <given-names>DW</given-names></name> (<year>1980</year>) <article-title>The utility of the Wisconsin Card Sorting Test in detecting and localizing frontal lobe lesions</article-title>. <source>Journal of consulting and clinical psychology</source> <volume>48</volume>: <fpage>605</fpage>. <object-id pub-id-type="pmid">7410659</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Robbins</surname> <given-names>TW</given-names></name>, <name name-style="western"><surname>Weinberger</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Morris</surname> <given-names>R</given-names></name> (<year>1996</year>) <article-title>Dissociating executive functions of the prefrontal cortex [and discussion]</article-title>. <source>Philosophical Transactions of the Royal Society of London Series B: Biological Sciences</source> <volume>351</volume>: <fpage>1463</fpage>–<lpage>1471</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rougier</surname> <given-names>NP</given-names></name>, <name name-style="western"><surname>O’Reilly</surname> <given-names>RC</given-names></name> (<year>2002</year>) <article-title>Learning representations in a gated prefrontal cortex model of dynamic task switching</article-title>. <source>Cognitive Science</source> <volume>26</volume>: <fpage>503</fpage>–<lpage>520</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaplan</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Şengör</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Gürvit</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Genç</surname> <given-names>İ</given-names></name>, <name name-style="western"><surname>Güzeliş</surname> <given-names>C</given-names></name> (<year>2006</year>) <article-title>A composite neural network model for perseveration and distractibility in the Wisconsin card sorting test</article-title>. <source>Neural Networks</source> <volume>19</volume>: <fpage>375</fpage>–<lpage>387</lpage>. <object-id pub-id-type="pmid">16343846</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bishara</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Kruschke</surname> <given-names>JK</given-names></name>, <name name-style="western"><surname>Stout</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Bechara</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>McCabe</surname> <given-names>DP</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Sequential learning models for the Wisconsin card sort task: Assessing processes in substance dependent individuals</article-title>. <source>Journal of mathematical psychology</source> <volume>54</volume>: <fpage>5</fpage>–<lpage>13</lpage>. <object-id pub-id-type="pmid">20495607</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stern</surname> <given-names>ER</given-names></name>, <name name-style="western"><surname>Gonzalez</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Welsh</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>SF</given-names></name> (<year>2010</year>) <article-title>Updating beliefs for a decision: neural correlates of uncertainty and underconfidence</article-title>. <source>The Journal of neuroscience</source> <volume>30</volume>: <fpage>8032</fpage>–<lpage>8041</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4729-09.2010" xlink:type="simple">10.1523/JNEUROSCI.4729-09.2010</ext-link></comment> <object-id pub-id-type="pmid">20534851</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Behrens</surname> <given-names>TEJ</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Walton</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MFS</given-names></name> (<year>2007</year>) <article-title>Learning the value of information in an uncertain world</article-title>. <source>Nat Neurosci</source> <volume>10</volume>: <fpage>1214</fpage>–<lpage>1221</lpage>. <object-id pub-id-type="pmid">17676057</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gläscher</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O'Doherty</surname> <given-names>JP</given-names></name> (<year>2010</year>) <article-title>States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>585</fpage>–<lpage>595</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.04.016" xlink:type="simple">10.1016/j.neuron.2010.04.016</ext-link></comment> <object-id pub-id-type="pmid">20510862</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Iglesias</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Brodersen</surname> <given-names>KH</given-names></name>, <name name-style="western"><surname>Kasper</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Piccirelli</surname> <given-names>M</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Hierarchical Prediction Errors in Midbrain and Basal Forebrain during Sensory Learning</article-title>. <source>Neuron</source> <volume>80</volume>: <fpage>519</fpage>–<lpage>530</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2013.09.009" xlink:type="simple">10.1016/j.neuron.2013.09.009</ext-link></comment> <object-id pub-id-type="pmid">24139048</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Changeux</surname> <given-names>J-P</given-names></name> (<year>1991</year>) <article-title>The Wisconsin Card Sorting Test: Theoretical analysis and modeling in a neuronal network</article-title>. <source>Cerebral cortex</source> <volume>1</volume>: <fpage>62</fpage>–<lpage>79</lpage>. <object-id pub-id-type="pmid">1822726</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berdia</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Metz</surname> <given-names>J</given-names></name> (<year>1998</year>) <article-title>An artificial neural network stimulating performance of normal subjects and schizophrenics on the Wisconsin card sorting test</article-title>. <source>Artificial intelligence in medicine</source> <volume>13</volume>: <fpage>123</fpage>–<lpage>138</lpage>. <object-id pub-id-type="pmid">9654382</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Morton</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Munakata</surname> <given-names>Y</given-names></name> (<year>2002</year>) <article-title>Active versus latent representations: A neural network model of perseveration, dissociation, and decalage</article-title>. <source>Developmental psychobiology</source> <volume>40</volume>: <fpage>255</fpage>–<lpage>265</lpage>. <object-id pub-id-type="pmid">11891637</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rougier</surname> <given-names>NP</given-names></name>, <name name-style="western"><surname>Noelle</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Braver</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>O'Reilly</surname> <given-names>RC</given-names></name> (<year>2005</year>) <article-title>Prefrontal cortex and flexible cognitive control: Rules without symbols</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>102</volume>: <fpage>7338</fpage>–<lpage>7343</lpage>. <object-id pub-id-type="pmid">15883365</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stemme</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Busch</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>WX</given-names></name> (<year>2005</year>) <article-title>Neurons and the synaptic basis of the fMRI signal associated with cognitive flexibility</article-title>. <source>Neuroimage</source> <volume>26</volume>: <fpage>454</fpage>–<lpage>470</lpage>. <object-id pub-id-type="pmid">15907303</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guigon</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dorizzi</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Burnod</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name> (<year>1995</year>) <article-title>Neural correlates of learning in the prefrontal cortex of the monkey: a predictive model</article-title>. <source>Cerebral Cortex</source> <volume>5</volume>: <fpage>135</fpage>–<lpage>147</lpage>. <object-id pub-id-type="pmid">7620290</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Changeux</surname> <given-names>JP</given-names></name> (<year>1995</year>) <article-title>Neuronal models of prefrontal cortical functions</article-title>. <source>Annals of the New York Academy of Sciences</source> <volume>769</volume>: <fpage>305</fpage>–<lpage>320</lpage>. <object-id pub-id-type="pmid">8595034</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref022"><label>22</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Houghton</surname> <given-names>G</given-names></name> (<year>2005</year>) <source>Connectionist models in cognitive psychology</source>: <publisher-name>Psychology Press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref023"><label>23</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Thomas</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>McClelland</surname> <given-names>JL</given-names></name> (<year>2008</year>) <chapter-title>Connectionist models of cognition</chapter-title>. <source>The Cambridge handbook of computational psychology</source>: <fpage>23</fpage>–<lpage>58</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Reilly</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Herd</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Pauli</surname> <given-names>WM</given-names></name> (<year>2010</year>) <article-title>Computational models of cognitive control</article-title>. <source>Current opinion in neurobiology</source> <volume>20</volume>: <fpage>257</fpage>–<lpage>261</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.conb.2010.01.008" xlink:type="simple">10.1016/j.conb.2010.01.008</ext-link></comment> <object-id pub-id-type="pmid">20185294</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Changeux</surname> <given-names>J-P</given-names></name> (<year>1997</year>) <article-title>A hierarchical neuronal network for planning behavior</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>94</volume>: <fpage>13293</fpage>–<lpage>13298</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weiss</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>, <name name-style="western"><surname>Adelson</surname> <given-names>EH</given-names></name> (<year>2002</year>) <article-title>Motion illusions as optimal percepts</article-title>. <source>Nat Neurosci</source> <volume>5</volume>: <fpage>598</fpage>–<lpage>604</lpage>. <object-id pub-id-type="pmid">12021763</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name> (<year>2004</year>) <article-title>The Bayesian brain: the role of uncertainty in neural coding and computation</article-title>. <source>Trends in Neurosciences</source> <volume>27</volume>: <fpage>712</fpage>–<lpage>719</lpage>. <object-id pub-id-type="pmid">15541511</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Körding</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name> (<year>2006</year>) <article-title>Bayesian decision theory in sensorimotor control</article-title>. <source>Trends in cognitive sciences</source> <volume>10</volume>: <fpage>319</fpage>–<lpage>326</lpage>. <object-id pub-id-type="pmid">16807063</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Norris</surname> <given-names>D</given-names></name> (<year>2006</year>) <article-title>The Bayesian Reader: Explaining word recognition as an optimal Bayesian decision process</article-title>. <source>Psychological Review</source> <volume>113</volume>: <fpage>327</fpage>. <object-id pub-id-type="pmid">16637764</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Körding</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Quartz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Causal inference in multisensory perception</article-title>. <source>PLoS one</source> <volume>2</volume>: <fpage>e943</fpage>. <object-id pub-id-type="pmid">17895984</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Orbán</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Aslin</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name> (<year>2008</year>) <article-title>Bayesian learning of visual chunks by human observers</article-title>. <source>Proceedings of the National Academy of Sciences</source> <volume>105</volume>: <fpage>2745</fpage>–<lpage>2750</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vossel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bauer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Driver</surname> <given-names>J</given-names></name>, et al. (<year>2013</year>) <article-title>Spatial attention, precision, and bayesian inference: A study of saccadic response speed</article-title>. <source>Cerebral Cortex</source>: bhs418.</mixed-citation></ref>
<ref id="pcbi.1004558.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Feldman</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name> (<year>2010</year>) <article-title>Attention, uncertainty, and free-energy</article-title>. <source>Frontiers in human neuroscience</source> <volume>4</volume>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Whiteley</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name> (<year>2012</year>) <article-title>Attention in a Bayesian framework</article-title>. <source>Frontiers in human neuroscience</source> <volume>6</volume>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name> (<year>2014</year>) <article-title>An evolutionary computational theory of prefrontal executive function in decision-making</article-title>. <source>Philosophical Transactions of the Royal Society of London B: Biological Sciences</source> <volume>369</volume>: <fpage>20130474</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rstb.2013.0474" xlink:type="simple">10.1098/rstb.2013.0474</ext-link></comment> <object-id pub-id-type="pmid">25267817</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chikkerur</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Serre</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Tan</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Poggio</surname> <given-names>T</given-names></name> (<year>2010</year>) <article-title>What and where: A Bayesian inference theory of attention</article-title>. <source>Vision research</source> <volume>50</volume>: <fpage>2233</fpage>–<lpage>2247</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.visres.2010.05.013" xlink:type="simple">10.1016/j.visres.2010.05.013</ext-link></comment> <object-id pub-id-type="pmid">20493206</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Kincaid</surname> <given-names>TG</given-names></name> (<year>1996</year>) <article-title>Dynamics of a winner-take-all neural network</article-title>. <source>Neural Networks</source> <volume>9</volume>: <fpage>1141</fpage>–<lpage>1154</lpage>. <object-id pub-id-type="pmid">12662589</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gros</surname> <given-names>C</given-names></name> (<year>2009</year>) <article-title>Cognitive computation with autonomously active neural networks: an emerging field</article-title>. <source>Cognitive Computation</source> <volume>1</volume>: <fpage>77</fpage>–<lpage>90</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaski</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kohonen</surname> <given-names>T</given-names></name> (<year>1994</year>) <article-title>Winner-take-all networks for physiological models of competitive learning</article-title>. <source>Neural Networks</source> <volume>7</volume>: <fpage>973</fpage>–<lpage>984</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maass</surname> <given-names>W</given-names></name> (<year>2000</year>) <article-title>On the computational power of winner-take-all</article-title>. <source>Neural computation</source> <volume>12</volume>: <fpage>2519</fpage>–<lpage>2535</lpage>. <object-id pub-id-type="pmid">11110125</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref041"><label>41</label><mixed-citation publication-type="other" xlink:type="simple">Bitzer S, Yildiz IB, Kiebel SJ (2012) Online Discrimination of Nonlinear Dynamics with Switching Differential Equations. arXiv preprint arXiv:12110947.</mixed-citation></ref>
<ref id="pcbi.1004558.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Usher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>McClelland</surname> <given-names>JL</given-names></name> (<year>2001</year>) <article-title>The time course of perceptual choice: the leaky, competing accumulator model</article-title>. <source>Psychological review</source> <volume>108</volume>: <fpage>550</fpage>. <object-id pub-id-type="pmid">11488378</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hopfield</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Tank</surname> <given-names>DW</given-names></name> (<year>1985</year>) <article-title>“Neural” computation of decisions in optimization problems</article-title>. <source>Biological cybernetics</source> <volume>52</volume>: <fpage>141</fpage>–<lpage>152</lpage>. <object-id pub-id-type="pmid">4027280</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Summerfield</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Behrens</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Koechlin</surname> <given-names>E</given-names></name> (<year>2011</year>) <article-title>Perceptual classification in a rapidly changing environment</article-title>. <source>Neuron</source> <volume>71</volume>: <fpage>725</fpage>–<lpage>736</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2011.06.022" xlink:type="simple">10.1016/j.neuron.2011.06.022</ext-link></comment> <object-id pub-id-type="pmid">21867887</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref045"><label>45</label><mixed-citation publication-type="other" xlink:type="simple">Payzan-LeNestour E (2010) Bayesian learning in unstable settings: Experimental evidence based on the bandit problem. Swiss Finance Institute Research Paper: 1–41.</mixed-citation></ref>
<ref id="pcbi.1004558.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name> (<year>2011</year>) <article-title>A Bayesian foundation for individual learning under uncertainty</article-title>. <source>Frontiers in Human Neuroscience</source> <volume>5</volume>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mathys</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Iglesias</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Diaconescu</surname> <given-names>AO</given-names></name>, <name name-style="western"><surname>Weber</surname> <given-names>LAE</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Computational modeling of perceptual inference: A hierarchical Bayesian approach that allows for individual and contextual differences in weighting of input</article-title>. <source>Int J Psychophysiol</source> <volume>85</volume>: <fpage>317</fpage>–<lpage>318</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kiebel</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name> (<year>2008</year>) <article-title>A hierarchy of time-scales and the brain</article-title>. <source>PLoS computational biology</source> <volume>4</volume>: <fpage>e1000209</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000209" xlink:type="simple">10.1371/journal.pcbi.1000209</ext-link></comment> <object-id pub-id-type="pmid">19008936</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Den Ouden</surname> <given-names>HE</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kiebel</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Observing the observer (I): meta-Bayesian models of learning and decision-making</article-title>. <source>PLoS One</source> <volume>5</volume>: <fpage>e15554</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0015554" xlink:type="simple">10.1371/journal.pone.0015554</ext-link></comment> <object-id pub-id-type="pmid">21179480</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Den Ouden</surname> <given-names>HE</given-names></name>, <name name-style="western"><surname>Pessiglione</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kiebel</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Observing the observer (II): deciding when to decide</article-title>. <source>PLoS one</source> <volume>5</volume>: <fpage>e15555</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0015555" xlink:type="simple">10.1371/journal.pone.0015555</ext-link></comment> <object-id pub-id-type="pmid">21179484</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Vijayakumar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name> (<year>2014</year>) <article-title>On the Origins of Suboptimality in Human Probabilistic Inference</article-title>. <source>PLOS Computational Biology</source> <volume>10</volume>: <fpage>e1003661</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003661" xlink:type="simple">10.1371/journal.pcbi.1003661</ext-link></comment> <object-id pub-id-type="pmid">24945142</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vul</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Goodman</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Griffiths</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>. <article-title>One and done?</article-title> <source>Optimal decisions from very few samples</source>; <year>2009</year>. pp. <fpage>66</fpage>–<lpage>72</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vul</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Pashler</surname> <given-names>H</given-names></name> (<year>2008</year>) <article-title>Measuring the crowd within probabilistic representations within individuals</article-title>. <source>Psychological Science</source> <volume>19</volume>: <fpage>645</fpage>–<lpage>647</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1467-9280.2008.02136.x" xlink:type="simple">10.1111/j.1467-9280.2008.02136.x</ext-link></comment> <object-id pub-id-type="pmid">18727777</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Penny</surname> <given-names>WD</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Moran</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name> (<year>2009</year>) <article-title>Bayesian model selection for group studies</article-title>. <source>Neuroimage</source> <volume>46</volume>: <fpage>1004</fpage>–<lpage>1017</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2009.03.025" xlink:type="simple">10.1016/j.neuroimage.2009.03.025</ext-link></comment> <object-id pub-id-type="pmid">19306932</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rigoux</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name> (<year>2014</year>) <article-title>Bayesian model selection for group studies—revisited</article-title>. <source>Neuroimage</source> <volume>84</volume>: <fpage>971</fpage>–<lpage>985</lpage>. <object-id pub-id-type="pmid">24018303</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hansen</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Müller</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Koumoutsakos</surname> <given-names>P</given-names></name> (<year>2003</year>) <article-title>Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES)</article-title>. <source>Evolutionary Computation</source> <volume>11</volume>: <fpage>1</fpage>–<lpage>18</lpage>. <object-id pub-id-type="pmid">12804094</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref057"><label>57</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Hansen</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Kern</surname> <given-names>S</given-names></name>. <source>Evaluating the CMA evolution strategy on multimodal test functions</source>; <year>2004</year>. <publisher-name>Springer</publisher-name>. pp. <fpage>282</fpage>–<lpage>291</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lyness</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Moler</surname> <given-names>C</given-names></name> (<year>1966</year>) <article-title>van der Monde systems and numerical differentiation</article-title>. <source>Numerische Mathematik</source> <volume>8</volume>: <fpage>458</fpage>–<lpage>464</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friel</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Wyse</surname> <given-names>J</given-names></name> (<year>2012</year>) <article-title>Estimating the evidence–a review</article-title>. <source>Statistica Neerlandica</source> <volume>66</volume>: <fpage>288</fpage>–<lpage>308</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Geisler</surname> <given-names>WS</given-names></name>, <name name-style="western"><surname>Kersten</surname> <given-names>D</given-names></name> (<year>2002</year>) <article-title>Illusions, perception and Bayes</article-title>. <source>Nat Neurosci</source> <volume>5</volume>: <fpage>508</fpage>–<lpage>510</lpage>. <object-id pub-id-type="pmid">12037517</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kersten</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Mamassian</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Yuille</surname> <given-names>A</given-names></name> (<year>2004</year>) <article-title>Object perception as Bayesian inference</article-title>. <source>Annu Rev Psychol</source> <volume>55</volume>: <fpage>271</fpage>–<lpage>304</lpage>. <object-id pub-id-type="pmid">14744217</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref062"><label>62</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Richards</surname> <given-names>W</given-names></name> (<year>1996</year>) <source>Perception as Bayesian inference</source>: <publisher-name>Cambridge University Press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref063"><label>63</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Durbin</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Koopman</surname> <given-names>SJ</given-names></name> (<year>2012</year>) <source>Time series analysis by state space methods</source>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Changeux</surname> <given-names>J-P</given-names></name>, <name name-style="western"><surname>Dehaene</surname> <given-names>S</given-names></name> (<year>2000</year>) <article-title>Hierarchical neuronal modeling of cognitive functions: from synaptic transmission to the Tower of London</article-title>. <source>Int J Psychophysiol</source> <volume>35</volume>: <fpage>179</fpage>–<lpage>187</lpage>. <object-id pub-id-type="pmid">10677646</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goela</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Pullara</surname> <given-names>SD</given-names></name>, <name name-style="western"><surname>Grafman</surname> <given-names>J</given-names></name> (<year>2001</year>) <article-title>A computational model of frontal lobe dysfunction: Working memory and the Tower of Hanoi task</article-title>. <source>Cognitive Science</source> <volume>25</volume>: <fpage>287</fpage>–<lpage>313</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Standage</surname> <given-names>DI</given-names></name>, <name name-style="western"><surname>Trappenberg</surname> <given-names>TP</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>RM</given-names></name> (<year>2005</year>) <article-title>Modelling divided visual attention with a winner-take-all network</article-title>. <source>Neural networks</source> <volume>18</volume>: <fpage>620</fpage>–<lpage>627</lpage>. <object-id pub-id-type="pmid">16087317</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref067"><label>67</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Beal</surname> <given-names>MJ</given-names></name> (<year>2003</year>) <source>Variational algorithms for approximate Bayesian inference</source>: <publisher-name>University of London</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref068"><label>68</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Barnet</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Grahame</surname> <given-names>NJ</given-names></name> (<year>1995</year>) <article-title>Assessment of the Rescorla-Wagner model</article-title>. <source>Psychological bulletin</source> <volume>117</volume>: <fpage>363</fpage>. <object-id pub-id-type="pmid">7777644</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Siegel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Allan</surname> <given-names>LG</given-names></name> (<year>1996</year>) <article-title>The widespread influence of the Rescorla-Wagner model</article-title>. <source>Psychonomic Bulletin &amp; Review</source> <volume>3</volume>: <fpage>314</fpage>–<lpage>321</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref070"><label>70</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bland</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Schaefer</surname> <given-names>A</given-names></name> (<year>2012</year>) <article-title>Different varieties of uncertainty in human decision-making</article-title>. <source>Frontiers in neuroscience</source> <volume>6</volume>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref071"><label>71</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Palma</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ben-Akiva</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Brownstone</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Holt</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Magnac</surname> <given-names>T</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Risk, uncertainty and discrete choice models</article-title>. <source>Marketing Letters</source> <volume>19</volume>: <fpage>269</fpage>–<lpage>285</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref072"><label>72</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kolling</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Wittmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rushworth</surname> <given-names>MF</given-names></name> (<year>2014</year>) <article-title>Multiple neural mechanisms of decision making and their competition under changing risk pressure</article-title>. <source>Neuron</source> <volume>81</volume>: <fpage>1190</fpage>–<lpage>1202</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2014.01.033" xlink:type="simple">10.1016/j.neuron.2014.01.033</ext-link></comment> <object-id pub-id-type="pmid">24607236</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref073"><label>73</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Platt</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Huettel</surname> <given-names>SA</given-names></name> (<year>2008</year>) <article-title>Risky business: the neuroeconomics of decision making under uncertainty</article-title>. <source>Nat Neurosci</source> <volume>11</volume>: <fpage>398</fpage>–<lpage>403</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn2062" xlink:type="simple">10.1038/nn2062</ext-link></comment> <object-id pub-id-type="pmid">18368046</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref074"><label>74</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Heidrich-Meisner</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Igel</surname> <given-names>C</given-names></name> (<year>2008</year>) <chapter-title>Evolution strategies for direct policy search</chapter-title>. <source>Parallel Problem Solving from Nature–PPSN X</source>: <publisher-name>Springer</publisher-name>. pp. <fpage>428</fpage>–<lpage>437</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref075"><label>75</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Heidrich-Meisner</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Igel</surname> <given-names>C</given-names></name> (<year>2009</year>) <article-title>Neuroevolution strategies for episodic reinforcement learning</article-title>. <source>Journal of Algorithms</source> <volume>64</volume>: <fpage>152</fpage>–<lpage>168</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref076"><label>76</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hou</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>Y</given-names></name> (<year>2009</year>) <article-title>Short-term fault prediction based on support vector machines with parameter optimization by evolution strategy</article-title>. <source>Expert Systems with Applications</source> <volume>36</volume>: <fpage>12383</fpage>–<lpage>12391</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref077"><label>77</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Meng</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Jin</surname> <given-names>Y</given-names></name> (<year>2011</year>) <article-title>Autonomous self-reconfiguration of modular robots by evolving a hierarchical mechanochemical model</article-title>. <source>Computational Intelligence Magazine, IEEE</source> <volume>6</volume>: <fpage>43</fpage>–<lpage>54</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref078"><label>78</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Penny</surname> <given-names>WD</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rosa</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Comparing families of dynamic causal models</article-title>. <source>PLoS computational biology</source> <volume>6</volume>: <fpage>e1000709</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000709" xlink:type="simple">10.1371/journal.pcbi.1000709</ext-link></comment> <object-id pub-id-type="pmid">20300649</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref079"><label>79</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kepecs</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Mainen</surname> <given-names>ZF</given-names></name> (<year>2012</year>) <article-title>A computational framework for the study of confidence in humans and animals</article-title>. <source>Philosophical Transactions of the Royal Society B: Biological Sciences</source> <volume>367</volume>: <fpage>1322</fpage>–<lpage>1337</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref080"><label>80</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Choi</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sheu</surname> <given-names>BJ</given-names></name> (<year>1993</year>) <article-title>A high-precision VLSI winner-take-all circuit for self-organizing neural networks</article-title>. <source>Solid-State Circuits, IEEE Journal of</source> <volume>28</volume>: <fpage>576</fpage>–<lpage>584</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref081"><label>81</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Coultrip</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Granger</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Lynch</surname> <given-names>G</given-names></name> (<year>1992</year>) <article-title>A cortical model of winner-take-all competition via lateral inhibition</article-title>. <source>Neural networks</source> <volume>5</volume>: <fpage>47</fpage>–<lpage>54</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref082"><label>82</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ermentrout</surname> <given-names>B</given-names></name> (<year>1992</year>) <article-title>Complex dynamics in winner-take-all neural nets with slow inhibition</article-title>. <source>Neural networks</source> <volume>5</volume>: <fpage>415</fpage>–<lpage>431</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref083"><label>83</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Ullman</surname> <given-names>S</given-names></name> (<year>1987</year>) <chapter-title>Shifts in selective visual attention: towards the underlying neural circuitry</chapter-title>. <source>Matters of Intelligence</source>: <collab xlink:type="simple">Springer</collab>. pp. <fpage>115</fpage>–<lpage>141</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref084"><label>84</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>DK</given-names></name>, <name name-style="western"><surname>Itti</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Braun</surname> <given-names>J</given-names></name> (<year>1999</year>) <article-title>Attention activates winner-take-all competition among visual filters</article-title>. <source>Nat Neurosci</source> <volume>2</volume>: <fpage>375</fpage>–<lpage>381</lpage>. <object-id pub-id-type="pmid">10204546</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref085"><label>85</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bodegård</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Geyer</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Grefkes</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Zilles</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Roland</surname> <given-names>PE</given-names></name> (<year>2001</year>) <article-title>Hierarchical processing of tactile shape in the human brain</article-title>. <source>Neuron</source> <volume>31</volume>: <fpage>317</fpage>–<lpage>328</lpage>. <object-id pub-id-type="pmid">11502261</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref086"><label>86</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wessinger</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>VanMeter</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Tian</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Van Lare</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pekar</surname> <given-names>J</given-names></name>, <etal>et al</etal>. (<year>2001</year>) <article-title>Hierarchical organization of the human auditory cortex revealed by functional magnetic resonance imaging</article-title>. <source>Journal of Cognitive Neuroscience</source> <volume>13</volume>: <fpage>1</fpage>–<lpage>7</lpage>. <object-id pub-id-type="pmid">11224904</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref087"><label>87</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kilner</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Kiebel</surname> <given-names>SJ</given-names></name> (<year>2010</year>) <article-title>Action and behavior: a free-energy formulation</article-title>. <source>Biological cybernetics</source> <volume>102</volume>: <fpage>227</fpage>–<lpage>260</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-010-0364-z" xlink:type="simple">10.1007/s00422-010-0364-z</ext-link></comment> <object-id pub-id-type="pmid">20148260</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref088"><label>88</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Angela</surname> <given-names>JY</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <source>Inference, attention, and decision in a Bayesian neural architecture</source>; <year>2004</year>. pp. <fpage>1577</fpage>–<lpage>1584</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004558.ref089"><label>89</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rao</surname> <given-names>RP</given-names></name> (<year>2005</year>) <article-title>Bayesian inference and attentional modulation in the visual cortex</article-title>. <source>Neuroreport</source> <volume>16</volume>: <fpage>1843</fpage>–<lpage>1848</lpage>. <object-id pub-id-type="pmid">16237339</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref090"><label>90</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name> (<year>2010</year>) <article-title>The free-energy principle: a unified brain theory?</article-title> <source>Nature Reviews Neuroscience</source> <volume>11</volume>: <fpage>127</fpage>–<lpage>138</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn2787" xlink:type="simple">10.1038/nrn2787</ext-link></comment> <object-id pub-id-type="pmid">20068583</object-id></mixed-citation></ref>
<ref id="pcbi.1004558.ref091"><label>91</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arlot</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Celisse</surname> <given-names>A</given-names></name> (<year>2010</year>) <article-title>A survey of cross-validation procedures for model selection</article-title>. <source>Statistics surveys</source> <volume>4</volume>: <fpage>40</fpage>–<lpage>79</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PBIOLOGY-D-11-03803</article-id><article-id pub-id-type="doi">10.1371/journal.pbio.1001319</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Sensory systems</subject>
              <subj-group>
                <subject>Auditory system</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Sensory perception</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Competing Sound Sources Reveal Spatial Effects in Cortical Processing</article-title><alt-title alt-title-type="running-head">Competing Sound Sources Reveal Spatial Effects</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Maddox</surname>
            <given-names>Ross K.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Billimoria</surname>
            <given-names>Cyrus P.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Perrone</surname>
            <given-names>Ben P.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Shinn-Cunningham</surname>
            <given-names>Barbara G.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Sen</surname>
            <given-names>Kamal</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Hearing Research Center, Department of Biomedical Engineering, Boston University, Boston, Massachusetts, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Center for Biodynamics, Boston University, Boston, Massachusetts, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Center for Computational Neuroscience and Neural Technology, Boston University, Boston, Massachusetts, United States of America</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Zador</surname>
            <given-names>Anthony M.</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Cold Spring Harbor, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">rkmaddox@uw.edu</email></corresp>
        <fn fn-type="con">
          <p>The author(s) have made the following declarations about their contributions: Conceived and designed the experiments: RKM CPB BGS-C KS. Performed the experiments: RKM BPP. Analyzed the data: RKM. Wrote the paper: RKM CPB BGS-C KS.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>5</month>
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>1</day>
        <month>5</month>
        <year>2012</year>
      </pub-date><volume>10</volume><issue>5</issue><elocation-id>e1001319</elocation-id><history>
        <date date-type="received">
          <day>20</day>
          <month>9</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>20</day>
          <month>3</month>
          <year>2012</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2012</copyright-year><copyright-holder>Maddox et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract abstract-type="toc">
        <p>Neurons in the avian auditory forebrain show strong sensitivity to the spatial configuration of two competing sources, even though there is only weak spatial dependence for any single source.</p>
      </abstract><abstract>
        <p>Why is spatial tuning in auditory cortex weak, even though location is important to object recognition in natural settings? This question continues to vex neuroscientists focused on linking physiological results to auditory perception. Here we show that the spatial locations of simultaneous, competing sound sources dramatically influence how well neural spike trains recorded from the zebra finch field L (an analog of mammalian primary auditory cortex) encode source identity. We find that the location of a birdsong played in quiet has little effect on the fidelity of the neural encoding of the song. However, when the song is presented along with a masker, spatial effects are pronounced. For each spatial configuration, a subset of neurons encodes song identity more robustly than others. As a result, competing sources from different locations dominate responses of different neural subpopulations, helping to separate neural responses into independent representations. These results help elucidate how cortical processing exploits spatial information to provide a substrate for selective spatial auditory attention.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>When a listener is presented with many sound sources at once, it is easier to understand a particular source when it comes from a different spatial location than the other competing sources. However, past studies of auditory cortex generally find that in response to a single sound source, there is not a precise representation of spatial location in the cortex, which makes this effect of spatial location hard to understand. Here, we presented zebra finches with two simultaneous sounds (a birdsong target and a noise masking sound) from distinct spatial locations and recorded neural responses in field L, which is analogous to primary auditory cortex in mammals. When the target sound was presented by itself, the location of the source had little effect on the ability to identify the target song based on neural activity in field L. However, when the target was presented with a masker sound, the location of both sources strongly affected neural discrimination performance. Moreover, different subpopulations of neurons preferentially encoded either target or masker, providing a potential substrate for spatial selective attention. Thus, even though location is not well coded in cortical neurons, spatial information strongly modulates cortical responses.</p>
      </abstract><funding-group><funding-statement>This work was supported by a National Institute of Deafness and Communication Disorders grant (R01 DC007610), and by CELEST, a National Science Foundation Science of Learning Center (NSF SMA-0835976). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="9"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Past studies of spatial effects in auditory cortex have focused on how spatial location is encoded. These studies typically find that single-unit spatial tuning in cortex is weak <xref ref-type="bibr" rid="pbio.1001319-Middlebrooks1">[1]</xref>–<xref ref-type="bibr" rid="pbio.1001319-Recanzone1">[4]</xref>, not topographically organized <xref ref-type="bibr" rid="pbio.1001319-Mickey1">[5]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Stecker1">[6]</xref>, and not encoded independently of other perceptually important features <xref ref-type="bibr" rid="pbio.1001319-Bizley1">[7]</xref>. There is good evidence for a specialized “where” pathway in auditory cortex, in which spatial information plays a larger role than in other cortical areas <xref ref-type="bibr" rid="pbio.1001319-Lomber1">[8]</xref>. However, although we know of no single study that directly compares spatial tuning in cortex to that of lower stages of the auditory pathway, spatial tuning of cortical neurons is generally broad compared to both behavioral sensitivity <xref ref-type="bibr" rid="pbio.1001319-Recanzone1">[4]</xref> and spatial encoding in the midbrain <xref ref-type="bibr" rid="pbio.1001319-Devore1">[9]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Lee1">[10]</xref>. One hint for how to resolve these apparent discrepancies is that in an awake animal performing a spatial task, spatial information in cortical responses is enhanced <xref ref-type="bibr" rid="pbio.1001319-Lee1">[10]</xref>. Together, these results suggest that although spatial information is available, it is not the primary feature represented in the cortical auditory regions. Instead, spatial information may modulate neural responses in a way that depends on task demands, thus enabling analysis of sound sources in realistic auditory scenes <xref ref-type="bibr" rid="pbio.1001319-Nelken1">[11]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Nelken2">[12]</xref>.</p>
      <p>It may be that spatial effects are not best revealed by looking at how well source location is encoded by neural responses, but rather by examining how source location affects other aspects of information in cortical spike trains. In everyday perception, source location matters most in auditory scenes in which sounds compete with each other. Although listeners can localize a sound source in quiet, this ability is degraded in more typical, real-world settings containing reverberant energy or competing sources <xref ref-type="bibr" rid="pbio.1001319-Rakerd1">[13]</xref>. In contrast, in exactly those kinds of realistic situations where there are competing sources, spatial separation helps listeners segregate sounds and enables them to focus selective attention, a critical skill for understanding a source of interest <xref ref-type="bibr" rid="pbio.1001319-Ruggles1">[14]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Kidd1">[15]</xref>. In this sense, behavioral results support the idea that the locations of competing sources strongly influence auditory perception, regardless of whether the listener can effectively localize in such a setting.</p>
      <p>Motivated by these observations, we hypothesized that the effects of spatial location on cortical processing would best be revealed by a study that uses competing sound sources. Rather than focusing on how accurately spatial location of a source was encoded, we explored how competing source locations influenced the ability to encode the identity of a target communication signal (in this case, birdsong). We found that, consistent with our hypothesis, source location of a target song presented in isolation had little effect on how well neurons in avian field L (the analog of mammalian primary auditory cortex <xref ref-type="bibr" rid="pbio.1001319-Wang1">[16]</xref>) encoded song identity; however, in the presence of a competing noise masker, both target and masker locations strongly influenced encoding of song identity. Moreover, depending on the location of target and masker, different neurons were “best” at encoding identity. Such a coding scheme may provide a substrate for spatial auditory attention, as top-down modulatory control signals could selectively suppress responses of neurons favoring a masker in order to reduce competition and allow more precise analysis of a target from a desired location.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Neural Responses Are Sensitive to the Locations of Competing Sources</title>
        <p>We recorded neural responses from male zebra finches in the auditory forebrain (field L, based on stereotactic coordinates <xref ref-type="bibr" rid="pbio.1001319-Narayan1">[17]</xref>–<xref ref-type="bibr" rid="pbio.1001319-Billimoria1">[19]</xref>) to stimuli from four azimuthal locations in the frontal hemifield. Target stimuli were two conspecific songs, presented either in quiet (“clean”; <xref ref-type="fig" rid="pbio-1001319-g001">Figure 1A</xref>) or in the presence of a spectrally similar noise masker coming from the same or a different location as the target song (<xref ref-type="fig" rid="pbio-1001319-g001">Figure 1B</xref>). We assessed neural performance using a single-trial spike-distance-based <xref ref-type="bibr" rid="pbio.1001319-vanRossum1">[20]</xref> nearest-neighbor classification scheme <xref ref-type="bibr" rid="pbio.1001319-Machens1">[21]</xref>, calculating a percent correct score that indicates how well neural responses coded stimulus identity. Chance performance was 50%. Consistent with prior studies <xref ref-type="bibr" rid="pbio.1001319-Narayan1">[17]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Schneider1">[22]</xref>–<xref ref-type="bibr" rid="pbio.1001319-Wang2">[24]</xref>, rate coding alone was insufficient to allow reliable stimulus discrimination; mean performance when no masker was present was only 54%, averaged across recording sites.</p>
        <fig id="pbio-1001319-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001319.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Masking sounds increase spatial sensitivity.</title>
            <p>(A) Two target song spectrograms (frequency range 500 Hz to 8 kHz), and the response of an example field L recording site to those two songs (10 trials each) as rasters. There is one set of rasters at each of the four azimuths for the two target songs; the effects of changing the location are minimal. (B) The same, with the addition of a song-shaped noise masker (whose spectrogram is shown below those of the targets), played from −90° for all target locations, at the same RMS amplitude as the target (represented by the black box with an “M” on it). The masker sound affects the responses at all target locations, but the effect is stronger (primarily as deleted spikes) when the target is at −90°. (C) Discrimination performance of the same example site. Discrimination of clean targets is reliable for all target locations. However, masked performance is worse when the target is ipsilateral to the site than when it is contralateral. (D) The effect of adding a masker (black bars: means ± 1 SEM, gray lines: individual sites, <italic>n</italic> = 33). The spatial sensitivity is much higher for the masked stimuli, succinctly demonstrating that the addition of masker to a stimulus increases the dependence of performance on location. (E) Average spike rates in response to clean songs (black line: mean ± 1 SEM, gray lines: individual sites).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001319.g001" xlink:type="simple"/>
        </fig>
        <p>In each experimental session, there were four loudspeaker locations, leading to 16 target-masker spatial configurations. If the recording electrode was in the left hemisphere, loudspeaker locations were on the left side (−90°, ipsilateral to the electrode), in front (0°), halfway between front and right (+45°), and on the right (+90°, contralateral). These locations were flipped about the midline when recording in the right hemisphere. Henceforth, coordinates are referenced to the recording electrode, so that ipsilateral azimuths have negative signs and contralateral azimuths have positive signs. Discrimination performance was calculated for all 16 configurations and three signal-to-noise ratios (SNR; −6 dB, 0 dB, +6 dB). To assess the extent to which the head created an acoustical obstruction (“head shadow”) to the ear opposite the sound source, we measured sound level at both ears from all four locations using a masker token as the probe stimulus. The differences between left and right ears were 1.5, 0.1, −0.8, and −1.3 dB for −90, 0, +45, and +90°, respectively.</p>
        <p>For the example site in <xref ref-type="fig" rid="pbio-1001319-g001">Figure 1A and B</xref>, clean performance was near ceiling at all tested locations. Masked performance was much lower and varied substantially as the target was moved from the ipsilateral side (−90°) to the contralateral side (+90°), holding the masker at −90°. Across recording sites, the masked performance varied much more than clean performance did as a function of location. To quantify this, we computed the spatial sensitivity (defined as the difference between the best and worst performance for a given experimental condition; see <xref ref-type="sec" rid="s4">Materials and Methods</xref>) for each site for both clean and masked targets. Spatial sensitivity was 3-fold higher with a masker present than without (<italic>p</italic>&lt;.001; <xref ref-type="fig" rid="pbio-1001319-g001">Figure 1D</xref>). The driven spike rate in response to clean songs did not vary significantly with location (<italic>r</italic> = .16, <italic>p</italic> = .068; <xref ref-type="fig" rid="pbio-1001319-g001">Figure 1E</xref>). This distinction is important: while target azimuth was at best weakly coded by the rate response of the neurons, information about song identity encoded in spike trains varied greatly with target and masker locations.</p>
        <p>The way in which classification performance varied with spatial configuration varied from site to site. Indeed, some sites responded best when the target was in a particular hemisphere (<xref ref-type="fig" rid="pbio-1001319-g002">Figure 2A</xref>, site 1), some for a particular target-masker location configuration (sites 2 and 3), and some in idiosyncratic configurations that fit no simple description (site 4).</p>
        <fig id="pbio-1001319-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001319.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Spatial performance patterns are diverse across neural recording sites.</title>
            <p>(A) The performances of four example sites that vary widely. The performance is color-coded and percent correct value shown for each spatial configuration. (B) The performances of all neurons at all spatial configurations as dots. The translucent gray shows the “upper envelope”—that is, the surface defined by the best performance across neural sites for each spatial configuration. The best-performing six sites are color-coded so that all the dots of one color show performance for that site for all tested configurations. The order of the colored dots changes across spatial configurations, showing that the diversity of the spatial performance patterns is important for allowing good performance across all spatial configurations. The results shown are for the responses at an SNR of −6 dB; that is, the target sound had half the amplitude of the masker. Recordings were made in both hemispheres and data shown here use the electrode hemisphere as a reference, rather than an absolute left/right coordinate system.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001319.g002" xlink:type="simple"/>
        </fig>
        <p>To explore how such a population of neurons might encode song identity, we considered two population-coding schemes. The first was based on a previous study, which assumed that behavioral performance was determined by the best thresholds across a population of neurons, an approach termed the “lower envelope” principle <xref ref-type="bibr" rid="pbio.1001319-Parker1">[25]</xref>. Here we define the corresponding neural “upper envelope” as the best classification performance across the entire neuronal population. The performance of individual sites and the upper envelope are shown in <xref ref-type="fig" rid="pbio-1001319-g002">Figure 2B</xref> as a function of target and masker location for an SNR of −6 dB. While no one site performs well for all spatial configurations, almost all configurations yield at least some sites that encode target identity well.</p>
        <p>At higher SNRs, the upper envelope is at ceiling (<xref ref-type="fig" rid="pbio-1001319-g003">Figure 3A</xref>). To better reveal the effects of spatial configuration, we calculated the mean performance across sites for each spatial configuration. Despite the complex dependence of performance on spatial configuration for many of the sites, the mean performance varies smoothly with spatial configuration for each SNR. Specifically, mean performance is best when the target is contralateral and the masker ipsilateral to the neural recording site and worst in the reverse configuration (<xref ref-type="fig" rid="pbio-1001319-g003">Figure 3B</xref>). <xref ref-type="fig" rid="pbio-1001319-g003">Figure 3C</xref> shows the mean performances across sites in which the target is farther than the masker from the recording site, in the contralateral direction. Representing the data this way assumes a simple population model in which the neurons in one hemisphere are favored over the other (i.e., the responses from the hemisphere contralateral to the target are enhanced and the ipsilateral responses are suppressed). Using this model (which includes only the values in the lower right half of the grids in <xref ref-type="fig" rid="pbio-1001319-g003">Figure 3B</xref>, including the diagonal), the effect of spatial separation (as well as SNR) is highly significant (<italic>p</italic>&lt;.001 for both); moreover, linear regression fits at each SNR show that performance improves with increasing spatial separation of target and masker. Such performance increases are parallel with results from behavioral studies in humans <xref ref-type="bibr" rid="pbio.1001319-Best1">[26]</xref> and birds <xref ref-type="bibr" rid="pbio.1001319-Dent1">[27]</xref> that report spatial unmasking.</p>
        <fig id="pbio-1001319-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001319.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Population measures of response patterns.</title>
            <p>(A) The upper envelope and (B) the across-site mean performance are shown as grids (with performance color-coded and percent correct value shown in each box) for clean targets and at each SNR (clean, +6 dB, 0 dB, and −6 dB from top to bottom). The upper envelope performance shares its worst-performing spatial configuration with the mean, but is (by necessity) higher than the mean at all points. In fact, the upper envelope performance is at or very near ceiling for the higher two SNRs. At each SNR, the mean varies smoothly as a function of both target and masker location. For both the upper envelope and the mean, the lowest performance is when the target is ipsilateral and the masker is contralateral, and the highest performance is in the complementary configuration. Performance also improves with increasing SNR. (C) Performance increases as a function of spatial separation when considering the subset of spatial configurations in which the target source is more contralateral than or colocated with the masker (in the grids above, the lower right triangle, including the diagonal). Mean performances are shown as markers (upward triangles, circles, and downward triangles for +6, 0, and −6 dB SNR, respectively). Linear regression fits at each SNR are shown as gray lines.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001319.g003" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2b">
        <title>Spike Additions and Subtractions</title>
        <p>Maskers degrade responses to target songs. A simple way to evaluate the masker interference is to compare the response elicited by the target in quiet to that of responses to the target plus masker. Differences between the two responses can be categorized into orthogonal categories of spike additions, where the presence of the masker causes extra spikes (usually in the gaps between syllables), and spike subtractions, where spikes that are elicited by the target alone are reduced by the presence of the masker (usually during syllables; see <xref ref-type="fig" rid="pbio-1001319-g004">Figure 4A–C</xref>). Both types of interference have been studied before <xref ref-type="bibr" rid="pbio.1001319-Narayan2">[18]</xref>; here we extended that analysis. We modeled spike trains that had only subtractions or only additions (<xref ref-type="fig" rid="pbio-1001319-g004">Figure 4D</xref>; see <xref ref-type="sec" rid="s4">Materials and Methods</xref>), and then calculated performance for these modeled spike trains just as we did for the measured ones.</p>
        <fig id="pbio-1001319-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001319.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Spike additions and subtractions affect performance differently.</title>
            <p>For three spatial configurations (left to right: target ipsilateral, masker contralateral; target front, masker front; target contralateral, masker ipsilateral), (A) clean target rate, (B) masked rate, and (C) the difference between masked and clean rates are shown, averaged across all sites. Red peaks show where the masker added spikes, and blue depths show masker subtractions. The large initial peaks have been clipped to increase the dynamic range of the rates that follow. (D) Using these rates, we modeled spike trains that had additions and subtractions, subtractions only, or additions only (“modeled,” which includes additions and subtractions, “sub-only,” and “add-only,” respectively). We calculated percents correct for these generated spike trains for each unit and plotted them against the actual masked performance. (E) The subtractions-only performance for each site (blue circles) and the centroid (black cross, branches are 1 SEM in each direction). Centroids are close to the diagonal, indicating similar subtractions-only and masked performances. (F) Additions-only performances, in the same manner as (E). Centroids are far from the diagonal, indicating a smaller detrimental effect on performance from spike additions. (G) The average (±1 SEM) performance. Additions-only performance does not differ significantly from clean performance for any configuration. Subtractions-only performance is significantly worse than clean performance. As the target moves from ipsilateral to contralateral (and the masker oppositely), subtractions account for an increasing proportion of the masking performance hit, completely accounting for it in the target contralateral, masker ipsilateral configuration. Gray brackets indicate significant differences of <italic>p</italic>&lt;.05.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001319.g004" xlink:type="simple"/>
        </fig>
        <p>We first validated our modeling approach by comparing predictions for modeled spike trains containing both additions and subtractions (i.e., the full effect of the masker) to measured data (see <xref ref-type="fig" rid="pbio-1001319-g004">Figure 4</xref>, “modeled” rasters and performances). The example model rasters look similar to the measured masked spike trains, and target song identification performance closely matched performance using the masked spike trains. These results validate our methods for modeling additions and subtractions.</p>
        <p>Following validation, we modeled spike trains that included only spike additions or only spike subtractions to separate their relative effects on performance. When modeling spike additions only (i.e., when no subtractions were modeled), target identification was better than for the measured response. On the other hand, performance for subtractions-only spike trains was only slightly better than the measured responses for two of the three configurations. For the target-contralateral, masker-ipsilateral configuration (right column of <xref ref-type="fig" rid="pbio-1001319-g004">Figure 4</xref>), performance was essentially equal for the subtractions-only and masked spike trains. These results suggest that additions did not impair discrimination performance when the target was contralateral to the recorded site. However, including additions had some impact on the other two configurations. Overall, this analysis shows that the masker degraded performance more by preventing spikes that a clean target would have elicited than by causing additional spikes.</p>
        <p>The times at which spikes are likely to be added by the masker tend to occur when the clean response rates are low. This can be quantified by correlating the clean stimulus response rate (<xref ref-type="fig" rid="pbio-1001319-g004">Figure 4A</xref>) with the rate of subtractions (blue depths in <xref ref-type="fig" rid="pbio-1001319-g004">Figure 4C</xref>) as a function of time. This correlation is significant and negative, confirming that subtractions reduce spikes the most when the likelihood of a spike in response to the clean stimulus is great (<italic>r</italic> = −.75, <italic>p</italic>&lt;.001). In contrast, the correlation between the time-dependent spike additions (red peaks in <xref ref-type="fig" rid="pbio-1001319-g004">Figure 4C</xref>) and the clean rate is weak (<italic>r</italic> = .08, <italic>p</italic>&lt;.001). Taken together, these results suggest that the effect of removing spikes from the peaks interferes with target identification more than adding spikes. This holds true even in spatial configurations where the number of spikes added is greater than the number of spikes removed.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <sec id="s3a">
        <title>Specific Experimental Paradigms Unveil Inherent Spatial Sensitivity</title>
        <p>Here we show that, in quiet, sound source location has only a modest impact on coding of song identity in field L, an analog of auditory cortex <xref ref-type="bibr" rid="pbio.1001319-Wang1">[16]</xref>. In general, spatial tuning in brainstem is sharper than in cortex, demonstrating that cortical auditory neurons do not directly inherit the already encoded spatial information present in lower centers of the auditory processing stream <xref ref-type="bibr" rid="pbio.1001319-Middlebrooks1">[1]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Lane1">[28]</xref>. However, our results show that the spatial configuration of competing sources strongly affects the coding of those sources' content.</p>
        <p>Spatial effects in cortical neurons are far greater when there are competing sounds than when there is only a single source. This observation suggests that spatial information acts to modulate competition between sources, even in an anesthetized preparation. The fact that these effects arise under anesthesia is important because it shows that they are preattentive. Competition between spatially separated sources helps segregate neural responses, so that information about competing sound sources from different locations is concentrated in distinct subpopulations of cortical neurons. Specifically, most neurons preferentially encode information about contralateral sources; however, some neurons show more specific preferences.</p>
        <p>Thus, even though location is not directly coded in cortical neurons, spatial information strongly modulates cortical responses. This idea fits with recent results showing that the effects of source location on neurons in cortex are enhanced when an awake animal is engaged in a task requiring a localization response <xref ref-type="bibr" rid="pbio.1001319-Lee1">[10]</xref>. The degree to which spatial information affects cortical responses changes with intention: depending on the importance of spatial information to the task being undertaken, spatial coding may be either enhanced or weakened. It is possible that inhibition driven by activity in prefrontal cortex (in mammals) or its analog (in avian species as studied here <xref ref-type="bibr" rid="pbio.1001319-Winkowski1">[29]</xref>) causes the sharpened tuning observed during spatial tasks <xref ref-type="bibr" rid="pbio.1001319-Lee1">[10]</xref>; if so, such connections may also be engaged during selective attention tasks to down-regulate responses of neurons preferentially encoding a masking stimulus that is to be ignored or to up-regulate responses of the distinct population of neurons preferentially encoding the target.</p>
        <p>In an anesthetized preparation like that tested here, the enhancement of spatial effects due to the presence of a competing source cannot be coming from top-down modulation from executive centers of the brain. Instead, these effects must be the result of neural circuitry that is “hard wired.” It may be that weak spatial tuning, which is not strong enough to cause observable changes in neural responses with changes in the location of a single sound source played alone, causes large effects when there are multiple sources from different positions. The preattentive spatial competition we find provides a substrate to realize selective spatial auditory attention. Once responses to competing sounds are partially segregated through this kind of preattentive, spatially sensitive process, attentional signals, including inhibitory feedback from executive control areas, can enhance the spatial selectivity already present.</p>
      </sec>
      <sec id="s3b">
        <title>Acoustic Head Shadow Contributes Little to Observed Spatial Effects</title>
        <p>In humans, many spatial effects are explained by the fact that the head causes a significant acoustic shadow at many audible frequencies <xref ref-type="bibr" rid="pbio.1001319-Best1">[26]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Moore1">[30]</xref>. When competing sound sources come from different azimuthal locations, the SNR at the ear closer to the target will be greater than if the sources were co-located. This kind of “better-ear” effect has nothing to do with neural processing but is a simple consequence of physics. For the human, such effects can be very significant for speech perception, because the head shadow can be 15 dB or more for frequencies important for speech. Thus, although not interesting from a neural processing perspective, these acoustic effects are important for perception.</p>
        <p>Here, in the zebra finch, better-ear effects are small. The zebra finch head is diminutive; its width corresponds to only one quarter of the wavelength of the highest frequency present in our bandlimited stimuli (8 kHz). Given that appreciable acoustic interactions only arise when the wavelength of the sound is comparable to or smaller than the size of the physical object in the environment, the stimuli we presented did not contain frequencies high enough to cause large interaural level differences. This bears out in our measurements, which show an amplitude difference between the ears of approximately 1.5 dB when the stimulus is at ±90°. The better-ear effect is thus limited to 3 dB.</p>
        <p>Performance in the target contralateral, masker ipsilateral configuration was 16.8% better than performance in the target ipsilateral, masker contralateral configuration, on average. In contrast, the performance benefit of lowering the masker noise level by 6 dB is only 8.8%. Moving the masker and target in space, then, has nearly double the effect on identification performance as a 6 dB increase in SNR. Given that the maximum effect of acoustic head shadow is only 3 dB, the better-ear acoustic effects cannot explain the spatial effects obtained. Moreover, although a better-ear effect may contribute to the processing of natural broadband signals that contain frequencies high enough to interact acoustically with the zebra finch head, it is unlikely to play a major role in the effects observed here, where we used low-pass filtered stimuli.</p>
      </sec>
      <sec id="s3c">
        <title>Spike Subtractions Have a Greater Impact than Spike Additions</title>
        <p>Interference from a masker on the response encoding a target can be broken down into two forms: spike additions (primarily in the gaps between syllables) and spike subtractions (primarily during syllables) <xref ref-type="bibr" rid="pbio.1001319-Narayan2">[18]</xref>. Here, we quantified the effects of spatial configuration on spike additions and subtractions, and then evaluated modeled spike trains to determine the relative impacts of these effects on neural discrimination performance. In general, additions were more likely than subtractions when the target was ipsilateral to the recording site and masker was contralateral (see <xref ref-type="fig" rid="pbio-1001319-g004">Figure 4C</xref>), while subtractions were the more prevalent form of interference in the reverse configuration. Because additions and subtractions were calculated by comparing the responses at each spatial configuration to responses to the corresponding target-only stimulus, they represent only the effect of the masker on the response, independent of the minor changes that occur due to absolute target location.</p>
        <p>By modeling spike trains with only additions or only subtractions, we were able to gauge their effects on performance. Spike subtractions degraded performance at all configurations (in <xref ref-type="fig" rid="pbio-1001319-g004">Figure 4C</xref>, blue bars are lower than white bars). In contrast, the spike trains with only additive interference coded target song identity nearly as well as the responses in quiet (red bars are nearly the same as white bars). Additions have a modest impact when subtractions are also present; additions-only performance was better than the fully masked responses in some configurations (compare blue and black bars). Subtractions, on the other hand, interfere with encoding of song identity more seriously and consistently across all spatial configurations.</p>
        <p>Although this analysis does not reveal the mechanisms by which a masker interferes with coding of a target, it does give some insight into the complex interactions that take place when two competing sounds are present in an environment. For instance, one might expect, a priori, that the presence of an ongoing masker would cause activity to increase overall, so that the stereotypical target response in quiet is hidden amidst added spikes elicited by the masker. Yet, instead, the detrimental effects of the masker come about primarily from suppression of responses to key features in the target; moreover, the influence of the masker on the target response depends on spatial configuration. This pattern of spatial-configuration-dependent suppression of spikes suggests that competing sources, each preferentially encoded by a distinct neural subpopulation, mutually suppress each other, giving rise to enhanced spatial modulation of responses compared to when a single, unchallenged sound source is presented in isolation.</p>
      </sec>
      <sec id="s3d">
        <title>Spatial Release From Masking</title>
        <p>For a given site, song identity coding tended to vary with both the target and masker locations and generally was best when the target was contralateral from the recording electrode and the masker was ipsilateral to it. For a single site to show spatial release from masking, performance for that site should increase monotonically with increasing spatial separation between the sources. Thus, neither any single recording site nor mean performance averaged over all sites (shown in <xref ref-type="fig" rid="pbio-1001319-g003">Figure 3B</xref>) exhibits spatial release from masking. Similar results have been seen in the midbrain, in inferior colliculus <xref ref-type="bibr" rid="pbio.1001319-Lane1">[28]</xref>, where, as here, single units showed preferences for encoding responses to different sources, depending on the spatial configuration. However, the activity of thousands of forebrain neurons, not just a single unit, combines to govern perception and behavior. As shown in <xref ref-type="fig" rid="pbio-1001319-g003">Figure 3</xref>, across the population of neurons in forebrain, there are typically neurons contralateral to the target source that encode target identity well. By looking at the mean performance of neurons at recording sites for which the target sound is more contralateral than the masker (or at the best neuron in that population), performance is predicted to improve with spatial separation (see <xref ref-type="fig" rid="pbio-1001319-g003">Figure 3C</xref>). Thus, the ensemble of responses, even from an anesthetized bird, can explain behavioral spatial unmasking if one assumes a mechanism as simple as attending to neurons in the hemisphere that favors encoding of the target and ignoring those from the opposite hemisphere.</p>
        <p>In behavioral experiments, performance improves with increasing separation between target and masker sounds both for speech and for non-speech sounds <xref ref-type="bibr" rid="pbio.1001319-Best1">[26]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Saberi1">[31]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Gilkey1">[32]</xref>. As noted above, better-ear acoustics contribute to spatial release from masking for many sounds important to human behavior, such as speech. Indeed, when a target sound is easily distinguished from a masker (such as when a communication signal is played in steady-state noise), better-ear acoustics can fully account for spatial release from masking in human studies. Interestingly, avian studies do not show the same pattern. The amount of spatial release from masking is essentially identical when behaving birds identify target birdsongs embedded in either a chorus of songs that sound qualitatively like the target songs or a steady-state masker (with the same long-term spectral content as the chorus, but has different short-term structure) <xref ref-type="bibr" rid="pbio.1001319-Dent1">[27]</xref>. This different pattern suggests that humans can segregate a target from a dissimilar masker even when the two sources are near each other in space, rendering spatial cues redundant <xref ref-type="bibr" rid="pbio.1001319-Maddox1">[33]</xref>. In contrast, birds may be less sophisticated in segregating competing sources, relying more heavily on spatial attributes even when target and masker have distinct spectro-temporal content. Regardless, the current results demonstrate how spatial separation of target and masker can support spatial release from masking in those situations where it is observed behaviorally, no matter what species.</p>
      </sec>
    </sec>
    <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Neural Recordings</title>
        <p>All experimental procedures involving animals were done in accordance with the protocol approved by the Boston University Institutional Animal Care and Use Committee. All subjects were male zebra finches (<italic>Taeniopygia guttata</italic>).</p>
        <p>Prior to the day of recording, a preparatory surgery was performed. In this surgery, the location of field L was marked as the point 1.2 mm anterior and 1.5 mm lateral of the midsagittal sinus and a headpin was fixed to the skull. On the day of recording, the bird was first placed in a soft cloth restraining jacket in a quiet, dark room. Injections of urethane anesthetic (20%) were administered every half hour in decreasing amounts (starting with 35 µL) until the bird was unresponsive to its head being patted and its foot being squeezed. Once anesthetized, the bird was placed in a stereotactic frame with its head secured by the previously implanted pin. A craniotomy was performed in which an approximately 2 mm square of skull was removed centered about the spot previously marked as field L. Tungsten microelectrodes (FHC, Bowdoin, ME) ranging in impedance from 2 to 4 MΩ were advanced into the brain using a micron-precision stepper motor. Extracellular potentials were amplified at the headstage, bandpassed between 500 and 10,000 Hz, and recorded with a low-noise soundcard at a sampling rate of 44.1 kHz.</p>
      </sec>
      <sec id="s4b">
        <title>Stimulus Generation and Presentation</title>
        <p>Stimuli were constructed from combinations of two different target zebra finch songs and masking noise (see <xref ref-type="fig" rid="pbio-1001319-g001">Figure 1A and B</xref> for spectrograms), all filtered between 500 and 8,000 Hz. The songs were chosen to have similar durations (∼2 s); they were songs never before heard by the subjects. To generate the masking noise, several songs were concatenated, the discrete Fourier transform computed, the phase randomized uniformly between 0 and 2π (preserving symmetry), and the inverse Fourier transform computed. The result was noise with a magnitude spectrum identical to the average of the spectra of those songs, but with no temporal structure. Ten independent, random tokens of noise were created so that any residual temporal structure was averaged out across repeated presentations. Independent noise tokens were used on each trial instead of using a single, frozen token because individual noise tokens with the same statistics can have drastically different masking effects <xref ref-type="bibr" rid="pbio.1001319-Gai1">[34]</xref>. Additionally, the use of independent masker tokens better simulates what happens in natural settings, where, over time, a bird repeatedly hears highly stereotyped songs from its familiar colony mates, but hears them in a different background of masking sources each time.</p>
        <p>Stimuli were presented using four single-driver loudspeakers in a sound-treated booth (IAC, Winchester, UK) at a sampling rate of 44.1 kHz. Target songs were normalized so that their root-mean-square amplitudes were 72 dB SPL (c-weighted). The loudspeakers were at four locations in the azimuthal plane: ipsilateral to the implanted hemisphere (−90°), in front of the bird (0°), contralateral to the implant (+90°), and at the angle halfway between the front and contralateral angles (+45°). The speaker locations were referenced relative to the recording electrode, with the side ipsilateral to the implant assigned the negative sign.</p>
        <p>Each recording session consisted of 10 blocks. In each block, each of the two target songs was played in isolation from all four locations. Additionally, for each target song, 16 target-masker spatial configurations were tested, each at three SNRs. This resulted in 2×(4+4×4×3) = 104 stimuli per block in which targets were present. We also played the masker alone from each location in each block, resulting in a total of 108 stimuli per block. Each of the 10 blocks used a different, independent token of masking noise semi; the order of the stimuli within each block was randomized. Overall, there were 1,080 two-second stimuli presented with 1.5 s between the end of one trial and the beginning of the next, resulting in a recording session that lasted 63 min for each neural site.</p>
      </sec>
      <sec id="s4c">
        <title>Spike Extraction and Sorting</title>
        <p>Extraction of action potentials (spikes) was performed off-line. First, neural traces were thresholded. The recording to 1 ms on either side of each local maximum was windowed out and considered a potential spike. These waveforms were sorted into user-defined template spike waveforms using a correlation-like coefficient:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001319.e001" xlink:type="simple"/></disp-formula>where <italic>x<sub>S</sub></italic> is a spike waveform and <italic>x<sub>T</sub></italic> a template waveform, and the sums are taken over time. Spikes were sorted into classes based on the template that yielded the highest <italic>r</italic> or were thrown out if they were not above a minimum <italic>r</italic> to any of the templates. This sorting was verified using principal components analysis clustering. Using this method, single units as well as multiunit clusters (which could not be separated into single units) were extracted. Of the sites that met the minimum performance criterion (see below), 17 were single units and 16 were multiunit clusters. Multiunit activity should produce weaker spatial effects than well-isolated single units. By including both isolated and multiunit recordings in our analysis, our approach is likely to underestimate (if anything) the effects of spatial configuration on neurons in the forebrain. Recordings were made in both hemispheres, but a relative coordinate system was used so that negative azimuths always correspond to the hemisphere ipsilateral the recording site and positive azimuths to the contralateral side.</p>
      </sec>
      <sec id="s4d">
        <title>Neural Spike Train Analysis</title>
        <p>Discrimination performance was calculated using a nearest-neighbor template-matching scheme and a spike distance metric. Methods used were similar to those used in past studies <xref ref-type="bibr" rid="pbio.1001319-Narayan1">[17]</xref>–<xref ref-type="bibr" rid="pbio.1001319-Billimoria1">[19]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Schneider1">[22]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Wang2">[24]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Narayan3">[35]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Larson2">[36]</xref>. To compute pairwise distances between recorded spike trains, each spike train was convolved with a decaying exponential kernel whose time constant determined the effective integration time of the spike comparisons; then the sum of the squared difference was calculated. These distances were used to compare a test spike train against two templates, one from each target song. Each spike train was classified as being elicited by the song whose template was closest to the measured spike train. This process was repeated many times for all spatial configurations for kernel time constants of 1, 4, 16, 63, 251, and 1,000 ms. All but one of the recording sites had an optimal time constant of 16 or 63 ms, in the same range as time constants found in similar past studies (the outlier had an optimal time constant of 251 ms) <xref ref-type="bibr" rid="pbio.1001319-Narayan1">[17]</xref>,<xref ref-type="bibr" rid="pbio.1001319-Schneider1">[22]</xref>. In this way, a percent correct score was calculated as a function of time constant, representing how well the spike trains from each spatial configuration matched the target spike trains from the template configuration. The time constant that yielded the best clean target discrimination for each site was used.</p>
        <p>Spatial sensitivity was computed as the difference between the maximum and minimum discrimination performance for a given stimulus type. For clean songs, these extrema were determined across the four target locations. For masked stimuli, they were determined across all 16 location configurations, at the SNR that had the highest variance. So that sites with poor performance did not appear spuriously insensitive to spatial configuration, only sites that had an unmasked discrimination performance of 90% or more were included in the analysis.</p>
      </sec>
      <sec id="s4e">
        <title>Spike Train Modeling</title>
        <p>To analyze the effects of spike additions and deletions separately, modeled spike trains were generated. Spike trains were binned into time bins of 2.5 ms. To generate a new spike train, the mean and standard deviation of the number of spikes in each time bin were computed across the 10 responses to each stimulus. Then, the number of spikes in each bin was chosen randomly from a Gaussian distribution with the same mean and standard deviation, with negative spike counts fixed to zero. Time bins in which the masked rate was higher than the clean rate were labeled “additions.” Thus, to simulate a spike train that had only additions, the higher of the masked and clean rates (and the corresponding SD) was chosen at each time bin. Similarly, to simulate a subtractions-only spike train, the minimum of the masked and clean rates was chosen for each bin. The discrimination performance of these simulated spike trains was then calculated in the same manner as real recordings, described above. Refractory period violations (interspike intervals of less than 1 ms) had a negligible effect on analysis.</p>
      </sec>
      <sec id="s4f">
        <title>Statistical Analysis</title>
        <p>The significance of the difference between the spatial sensitivity for clean and masked responses was computed using a paired Student's <italic>t</italic> test. All correlation <italic>r</italic> values were computed using Pearson's product-moment coefficient, with <italic>p</italic> values calculated using a Student's <italic>t</italic> distribution. The significance of spatial separation and SNR for the data shown in <xref ref-type="fig" rid="pbio-1001319-g003">Figure 3C</xref> were computed using a two-way repeated measures ANOVA. After using a one-way ANOVA to confirm a significant effect of interference type (<italic>p</italic>&lt;.001), Tukey's HSD test was used to compute post hoc comparisons between all performance values at each of the three spatial configurations in <xref ref-type="fig" rid="pbio-1001319-g004">Figure 4G</xref>. All statistics were done using M<sc>atlab</sc>'s built-in functions. A <italic>p</italic> value of .05 or less was considered significant.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors wish to thank Eric Larson for helpful discussion, surgical assistance, and data collection.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pbio.1001319-Middlebrooks1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Middlebrooks</surname><given-names>J. C</given-names></name><name name-style="western"><surname>Pettigrew</surname><given-names>J. D</given-names></name></person-group>             <year>1981</year>             <article-title>Functional classes of neurons in primary auditory cortex of the cat distinguished by sensitivity to sound location.</article-title>             <source>J Neurosci</source>             <volume>1</volume>             <fpage>107</fpage>             <lpage>120</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Imig1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Imig</surname><given-names>T. J</given-names></name><name name-style="western"><surname>Irons</surname><given-names>W. A</given-names></name><name name-style="western"><surname>Samson</surname><given-names>F. R</given-names></name></person-group>             <year>1990</year>             <article-title>Single-unit selectivity to azimuthal direction and sound pressure level of noise bursts in cat high-frequency primary auditory cortex.</article-title>             <source>J Neurophysiol</source>             <volume>63</volume>             <fpage>1448</fpage>             <lpage>1466</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Middlebrooks2">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Middlebrooks</surname><given-names>J. C</given-names></name><name name-style="western"><surname>Clock</surname><given-names>A. E</given-names></name><name name-style="western"><surname>Xu</surname><given-names>L</given-names></name><name name-style="western"><surname>Green</surname><given-names>D. M</given-names></name></person-group>             <year>1994</year>             <article-title>A panoramic code for sound location by cortical neurons.</article-title>             <source>Science</source>             <volume>264</volume>             <fpage>842</fpage>             <lpage>844</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Recanzone1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Recanzone</surname><given-names>G. H</given-names></name><name name-style="western"><surname>Engle</surname><given-names>J. R</given-names></name><name name-style="western"><surname>Juarez-Salinas</surname><given-names>D. L</given-names></name></person-group>             <year>2011</year>             <article-title>Spatial and temporal processing of single auditory cortical neurons and populations of neurons in the macaque monkey.</article-title>             <source>Hear Res</source>             <volume>271</volume>             <fpage>115</fpage>             <lpage>122</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Mickey1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mickey</surname><given-names>B. J</given-names></name><name name-style="western"><surname>Middlebrooks</surname><given-names>J. C</given-names></name></person-group>             <year>2003</year>             <article-title>Representation of auditory space by cortical neurons in awake cats.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>8649</fpage>             <lpage>8663</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Stecker1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Stecker</surname><given-names>G. C</given-names></name><name name-style="western"><surname>Harrington</surname><given-names>I. A</given-names></name><name name-style="western"><surname>Middlebrooks</surname><given-names>J. C</given-names></name></person-group>             <year>2005</year>             <article-title>Location coding by opponent neural populations in the auditory cortex.</article-title>             <source>PLoS Biol</source>             <volume>3</volume>             <fpage>e78</fpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0030078" xlink:type="simple">10.1371/journal.pbio.0030078</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Bizley1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bizley</surname><given-names>J. K</given-names></name><name name-style="western"><surname>Walker</surname><given-names>K. M. M</given-names></name><name name-style="western"><surname>Silverman</surname><given-names>B. W</given-names></name><name name-style="western"><surname>King</surname><given-names>A. J</given-names></name><name name-style="western"><surname>Schnupp</surname><given-names>J. W. H</given-names></name></person-group>             <year>2009</year>             <article-title>Interdependent encoding of pitch, timbre, and spatial location in auditory cortex.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>2064</fpage>             <lpage>2075</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Lomber1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lomber</surname><given-names>S. G</given-names></name><name name-style="western"><surname>Malhotra</surname><given-names>S</given-names></name></person-group>             <year>2008</year>             <article-title>Double dissociation of “what” and “where” processing in auditory cortex.</article-title>             <source>Nat Neurosci</source>             <volume>11</volume>             <fpage>609</fpage>             <lpage>616</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Devore1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Devore</surname><given-names>S</given-names></name><name name-style="western"><surname>Ihlefeld</surname><given-names>A</given-names></name><name name-style="western"><surname>Hancock</surname><given-names>K</given-names></name><name name-style="western"><surname>Shinn-Cunningham</surname><given-names>B</given-names></name><name name-style="western"><surname>Delgutte</surname><given-names>B</given-names></name></person-group>             <year>2009</year>             <article-title>Accurate sound localization in reverberant environments is mediated by robust encoding of spatial cues in the auditory midbrain.</article-title>             <source>Neuron</source>             <volume>62</volume>             <fpage>123</fpage>             <lpage>134</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Lee1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>C-C</given-names></name><name name-style="western"><surname>Middlebrooks</surname><given-names>J. C</given-names></name></person-group>             <year>2011</year>             <article-title>Auditory cortex spatial sensitivity sharpens during task performance.</article-title>             <source>Nat Neurosci</source>             <volume>14</volume>             <fpage>108</fpage>             <lpage>114</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Nelken1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name><name name-style="western"><surname>Fishbach</surname><given-names>A</given-names></name><name name-style="western"><surname>Las</surname><given-names>L</given-names></name><name name-style="western"><surname>Ulanovsky</surname><given-names>N</given-names></name><name name-style="western"><surname>Farkas</surname><given-names>D</given-names></name></person-group>             <year>2003</year>             <article-title>Primary auditory cortex of cats: feature detection or something else?</article-title>             <source>Biol Cybern</source>             <volume>89</volume>             <fpage>397</fpage>             <lpage>406</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Nelken2">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nelken</surname><given-names>I</given-names></name></person-group>             <year>2004</year>             <article-title>Processing of complex stimuli and natural scenes in the auditory cortex.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>14</volume>             <fpage>474</fpage>             <lpage>480</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Rakerd1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rakerd</surname><given-names>B</given-names></name><name name-style="western"><surname>Hartmann</surname><given-names>W. M</given-names></name></person-group>             <year>1985</year>             <article-title>Localization of sound in rooms, II: The effects of a single reflecting surface.</article-title>             <source>J Acoust Soc Am</source>             <volume>78</volume>             <fpage>524</fpage>             <lpage>533</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Ruggles1">
        <label>14</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ruggles</surname><given-names>D</given-names></name><name name-style="western"><surname>Shinn-Cunningham</surname><given-names>B</given-names></name></person-group>             <year>2010</year>             <article-title>Spatial selective auditory attention in the presence of reverberant energy: individual differences in normal-hearing listeners.</article-title>             <source>J Assoc Res Otolaryngol</source>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Kidd1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kidd</surname><given-names>G</given-names></name><name name-style="western"><surname>Mason</surname><given-names>C. R</given-names></name><name name-style="western"><surname>Brughera</surname><given-names>A</given-names></name><name name-style="western"><surname>Hartmann</surname><given-names>W. M</given-names></name></person-group>             <year>2005</year>             <article-title>The role of reverberation in release from masking due to spatial separation of sources for speech identification.</article-title>             <source>Acta Acustica United with Acustica</source>             <volume>91</volume>             <fpage>526</fpage>             <lpage>536</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Wang1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name><name name-style="western"><surname>Brzozowska-Prechtl</surname><given-names>A</given-names></name><name name-style="western"><surname>Karten</surname><given-names>H. J</given-names></name></person-group>             <year>2010</year>             <article-title>Laminar and columnar auditory cortex in avian brain.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>107</volume>             <fpage>12676</fpage>             <lpage>12681</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Narayan1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Narayan</surname><given-names>R</given-names></name><name name-style="western"><surname>Grana</surname><given-names>G</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name></person-group>             <year>2006</year>             <article-title>Distinct time scales in cortical discrimination of natural sounds in songbirds.</article-title>             <source>J Neurophysiol</source>             <volume>96</volume>             <fpage>252</fpage>             <lpage>258</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Narayan2">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Narayan</surname><given-names>R</given-names></name><name name-style="western"><surname>Best</surname><given-names>V</given-names></name><name name-style="western"><surname>Ozmeral</surname><given-names>E</given-names></name><name name-style="western"><surname>Mcclaine</surname><given-names>E</given-names></name><name name-style="western"><surname>Dent</surname><given-names>M</given-names></name><etal/></person-group>             <year>2007</year>             <article-title>Cortical interference effects in the cocktail party problem.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>1601</fpage>             <lpage>1607</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Billimoria1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Billimoria</surname><given-names>C. P</given-names></name><name name-style="western"><surname>Kraus</surname><given-names>B. J</given-names></name><name name-style="western"><surname>Narayan</surname><given-names>R</given-names></name><name name-style="western"><surname>Maddox</surname><given-names>R. K</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name></person-group>             <year>2008</year>             <article-title>Invariance and sensitivity to intensity in neural discrimination of natural sounds.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>6304</fpage>             <lpage>6308</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-vanRossum1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>van Rossum</surname><given-names>M. C</given-names></name></person-group>             <year>2001</year>             <article-title>A novel spike distance.</article-title>             <source>Neural Comput</source>             <volume>13</volume>             <fpage>751</fpage>             <lpage>763</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Machens1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Machens</surname><given-names>C. K</given-names></name><name name-style="western"><surname>Schutze</surname><given-names>H</given-names></name><name name-style="western"><surname>Franz</surname><given-names>A</given-names></name><name name-style="western"><surname>Kolesnikova</surname><given-names>O</given-names></name><name name-style="western"><surname>Stemmler</surname><given-names>M. B</given-names></name><etal/></person-group>             <year>2003</year>             <article-title>Single auditory neurons rapidly discriminate conspecific communication signals.</article-title>             <source>Nat Neurosci</source>             <volume>6</volume>             <fpage>341</fpage>             <lpage>342</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Schneider1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schneider</surname><given-names>D. M</given-names></name><name name-style="western"><surname>Woolley</surname><given-names>S. M</given-names></name></person-group>             <year>2010</year>             <article-title>Discrimination of communication vocalizations by single neurons and groups of neurons in the auditory midbrain.</article-title>             <source>J Neurophysiol</source>             <volume>103</volume>             <fpage>3248</fpage>             <lpage>3265</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Larson1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Larson</surname><given-names>E</given-names></name><name name-style="western"><surname>Billimoria</surname><given-names>C. P</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name></person-group>             <year>2009</year>             <article-title>A biologically plausible computational model for auditory object recognition.</article-title>             <source>J Neurophysiol</source>             <volume>101</volume>             <fpage>323</fpage>             <lpage>331</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Wang2">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wang</surname><given-names>L</given-names></name><name name-style="western"><surname>Narayan</surname><given-names>R</given-names></name><name name-style="western"><surname>Grana</surname><given-names>G</given-names></name><name name-style="western"><surname>Shamir</surname><given-names>M</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name></person-group>             <year>2007</year>             <article-title>Cortical discrimination of complex natural stimuli: can single neurons match behavior?</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>582</fpage>             <lpage>589</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Parker1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Parker</surname><given-names>A. J</given-names></name><name name-style="western"><surname>Newsome</surname><given-names>W. T</given-names></name></person-group>             <year>1998</year>             <article-title>Sense and the single neuron: probing the physiology of perception.</article-title>             <source>Annu Rev Neurosci</source>             <volume>21</volume>             <fpage>227</fpage>             <lpage>277</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Best1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Best</surname><given-names>V</given-names></name><name name-style="western"><surname>Ozmeral</surname><given-names>E</given-names></name><name name-style="western"><surname>Gallun</surname><given-names>F. J</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name><name name-style="western"><surname>Shinn-Cunningham</surname><given-names>B. G</given-names></name></person-group>             <year>2005</year>             <article-title>Spatial unmasking of birdsong in human listeners: energetic and informational factors.</article-title>             <source>J Acoust Soc Am</source>             <volume>118</volume>             <fpage>3766</fpage>             <lpage>3773</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Dent1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dent</surname><given-names>M. L</given-names></name><name name-style="western"><surname>McClaine</surname><given-names>E. M</given-names></name><name name-style="western"><surname>Best</surname><given-names>V</given-names></name><name name-style="western"><surname>Ozmeral</surname><given-names>E</given-names></name><name name-style="western"><surname>Narayan</surname><given-names>R</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Spatial unmasking of birdsong in zebra finches (Taeniopygia guttata) and budgerigars (Melopsittacus undulatus).</article-title>             <source>J Comp Psychol</source>             <volume>123</volume>             <fpage>357</fpage>             <lpage>367</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Lane1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lane</surname><given-names>C. C</given-names></name><name name-style="western"><surname>Delgutte</surname><given-names>B</given-names></name></person-group>             <year>2005</year>             <article-title>Neural correlates and mechanisms of spatial release from masking: single-unit and population responses in the inferior colliculus.</article-title>             <source>J Neurophysiol</source>             <volume>94</volume>             <fpage>1180</fpage>             <lpage>1198</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Winkowski1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Winkowski</surname><given-names>D. E</given-names></name><name name-style="western"><surname>Knudsen</surname><given-names>E. I</given-names></name></person-group>             <year>2006</year>             <article-title>Top-down gain control of the auditory space map by gaze control circuitry in the barn owl.</article-title>             <source>Nature</source>             <volume>439</volume>             <fpage>336</fpage>             <lpage>339</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Moore1">
        <label>30</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Moore</surname><given-names>B. C</given-names></name></person-group>             <year>2006</year>             <source>An introduction to the psychology of hearing</source>             <publisher-loc>Oxford, UK</publisher-loc>             <publisher-name>Elsevier</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">200</size>           </element-citation>
      </ref>
      <ref id="pbio.1001319-Saberi1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Saberi</surname><given-names>K</given-names></name><name name-style="western"><surname>Dostal</surname><given-names>L</given-names></name><name name-style="western"><surname>Sadralodabai</surname><given-names>T</given-names></name><name name-style="western"><surname>Bull</surname><given-names>V</given-names></name><name name-style="western"><surname>Perrott</surname><given-names>D. R</given-names></name></person-group>             <year>1991</year>             <article-title>Free-field release from masking.</article-title>             <source>J Acoust Soc Am</source>             <volume>90</volume>             <fpage>1355</fpage>             <lpage>1370</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Gilkey1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gilkey</surname><given-names>R. H</given-names></name><name name-style="western"><surname>Good</surname><given-names>M. D</given-names></name></person-group>             <year>1995</year>             <article-title>Effects of frequency on free-field masking.</article-title>             <source>Hum Factors</source>             <volume>37</volume>             <fpage>835</fpage>             <lpage>843</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Maddox1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Maddox</surname><given-names>R. K</given-names></name><name name-style="western"><surname>Shinn-Cunningham</surname><given-names>B. G</given-names></name></person-group>             <year>2012</year>             <article-title>Influence of task-relevant and task-irrelevant feature continuity on selective auditory attention.</article-title>             <source>J Assoc Res Otolaryngol</source>             <volume>13</volume>             <fpage>119</fpage>             <lpage>129</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Gai1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gai</surname><given-names>Y</given-names></name><name name-style="western"><surname>Carney</surname><given-names>L. H</given-names></name><name name-style="western"><surname>Abrams</surname><given-names>K. S</given-names></name><name name-style="western"><surname>Idrobo</surname><given-names>F</given-names></name><name name-style="western"><surname>Harrison</surname><given-names>J. M</given-names></name><etal/></person-group>             <year>2007</year>             <article-title>Detection of tones in reproducible noise maskers by rabbits and comparison to detection by humans.</article-title>             <source>J Assoc Res Otolaryngol</source>             <volume>8</volume>             <fpage>522</fpage>             <lpage>538</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Narayan3">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Narayan</surname><given-names>R</given-names></name><name name-style="western"><surname>Ergun</surname><given-names>A</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name></person-group>             <year>2005</year>             <article-title>Delayed inhibition in cortical receptive fields and the discrimination of complex stimuli.</article-title>             <source>J Neurophysiol</source>             <volume>94</volume>             <fpage>2970</fpage>             <lpage>2975</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001319-Larson2">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Larson</surname><given-names>E</given-names></name><name name-style="western"><surname>Maddox</surname><given-names>R. K</given-names></name><name name-style="western"><surname>Perrone</surname><given-names>B. P</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name><name name-style="western"><surname>Billimoria</surname><given-names>C. P</given-names></name></person-group>             <year>2012</year>             <article-title>Neuron-specific stimulus masking reveals interference in spike timing at the cortical level.</article-title>             <source>J Assoc Res Otolaryngol</source>             <volume>13</volume>             <fpage>81</fpage>             <lpage>89</lpage>          </element-citation>
      </ref>
    </ref-list>
    <glossary>
      <title>Abbreviations</title>
      <def-list>
        <def-item>
          <term>SNR</term>
          <def>
            <p>signal-to-noise ratio</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
    
  </back>
</article>
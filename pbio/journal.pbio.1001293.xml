<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PBIOLOGY-D-11-03007</article-id><article-id pub-id-type="doi">10.1371/journal.pbio.1001293</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
          </subj-group>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Cognitive neuroscience</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Social and behavioral sciences</subject>
          <subj-group>
            <subject>Psychology</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Reasoning, Learning, and Creativity: Frontal Lobe Function and Human Decision-Making</article-title><alt-title alt-title-type="running-head">Frontal Lobe Function and Human Decision-Making</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Collins</surname>
            <given-names>Anne</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Koechlin</surname>
            <given-names>Etienne</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Département d'Etudes Cognitives, Ecole Normale Superieure, Paris, France</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Cognitive, Linguistic and Psychological Sciences, Brown University, Providence, Rhode Island, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Université Pierre et Marie Curie, Paris, France</addr-line>       </aff><aff id="aff4"><label>4</label><addr-line>Laboratoire de Neurosciences Cognitives, Institut National de la Santé et de la Recherche Médicale, Paris, France</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>O'Doherty</surname>
            <given-names>John P.</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">California Institute of Technology, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">etienne.koechlin@upmc.fr</email></corresp>
        <fn fn-type="con">
          <p>The author(s) have made the following declarations about their contributions: Conceived and designed the experiments: AC EK. Performed the experiments: AC. Analyzed the data: AC EK. Contributed reagents/materials/analysis tools: AC EK. Wrote the paper: AC EK. Computational modeling: AC EK.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>3</month>
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>27</day>
        <month>3</month>
        <year>2012</year>
      </pub-date><volume>10</volume><issue>3</issue><elocation-id>e1001293</elocation-id><history>
        <date date-type="received">
          <day>24</day>
          <month>7</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>15</day>
          <month>2</month>
          <year>2012</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2012</copyright-year><copyright-holder>Collins, Koechlin</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract abstract-type="toc">
        <p>Computational modeling and behavioral experimentation suggest that human frontal lobe function is capable of monitoring three or four concurrent behavioral strategies in order to select the most suitable one during decision-making.</p>
      </abstract><abstract>
        <p>The frontal lobes subserve decision-making and executive control—that is, the selection and coordination of goal-directed behaviors. Current models of frontal executive function, however, do not explain human decision-making in everyday environments featuring uncertain, changing, and especially open-ended situations. Here, we propose a computational model of human executive function that clarifies this issue. Using behavioral experiments, we show that unlike others, the proposed model predicts human decisions and their variations across individuals in naturalistic situations. The model reveals that for driving action, the human frontal function monitors up to three/four concurrent behavioral strategies and infers online their ability to predict action outcomes: whenever one appears more reliable than unreliable, this strategy is chosen to guide the selection and learning of actions that maximize rewards. Otherwise, a new behavioral strategy is tentatively formed, partly from those stored in long-term memory, then probed, and if competitive confirmed to subsequently drive action. Thus, the human executive function has a monitoring capacity limited to three or four behavioral strategies. This limitation is compensated by the binary structure of executive control that in ambiguous and unknown situations promotes the exploration and creation of new behavioral strategies. The results support a model of human frontal function that integrates reasoning, learning, and creative abilities in the service of decision-making and adaptive behavior.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>Reasoning, learning, and creativity are hallmarks of human intelligence. These abilities involve the frontal lobe of the brain, but it remains unclear how the frontal lobes function in uncertain or open-ended situations. We propose here a computational model of human executive function that integrates multiple processes during decision-making, such as expectedness of uncertainty, task switching, and reinforcement learning. The model was tested in behavioral experiments and accounts for human decisions and their variations across individuals. The model reveals that executive function is capable of monitoring three or four concurrent behavioral strategies and infers online strategies' ability to predict action outcomes. If one strategy appears to reliably predict action outcomes, then it is chosen and possibly adjusted; otherwise a new strategy is tentatively formed, probed, and chosen instead. Thus, human frontal function has a monitoring capacity limited to three or four behavioral strategies. The results support a model of frontal executive function that explains the role and limitations of human reasoning, learning, and creative abilities in decision-making and adaptive behavior.</p>
      </abstract><funding-group><funding-statement>Funders: 1. European Research council Advanced Research Grant to EK: ERC-2009-AdG #250106. 2. Bettencourt-Schueller Foundation. Research Prize to EK. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="16"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>The ability to adapt to uncertain, changing, and open-ended environments is a hallmark of human intelligence. In such natural situations, decision-making involves exploring, adjusting, and exploiting multiple behavioral strategies (i.e., flexible mappings associating stimuli, actions, and expected outcomes <xref ref-type="bibr" rid="pbio.1001293-Simon1">[1]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Glimcher1">[4]</xref>). This faculty engages the frontal lobe function that manages <italic>task sets</italic>—that is, active representations of behavioral strategies stored in long-term memory—for driving action <xref ref-type="bibr" rid="pbio.1001293-Harlow1">[5]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Badre1">[10]</xref>. According to reinforcement learning (RL) models <xref ref-type="bibr" rid="pbio.1001293-Sutton1">[11]</xref>,<xref ref-type="bibr" rid="pbio.1001293-ODoherty1">[12]</xref>, the task set driving ongoing behavior (referred to as the <italic>actor</italic>) is adjusted according to outcome values for maximizing action utility. Uncertainty monitoring (UM) models <xref ref-type="bibr" rid="pbio.1001293-Yu1">[13]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Behrens1">[14]</xref> further indicate that the frontal executive function infers online the actor <italic>reliability</italic>—that is, its ability to infer action outcomes—for resetting the actor whenever it becomes unreliable. Moreover, models combining RL and UM suggest that given a <italic>fixed</italic> collection of concurrent task sets, the frontal function monitors in parallel their <italic>relative</italic> reliability for adjusting and choosing the most reliable actor <xref ref-type="bibr" rid="pbio.1001293-Doya1">[15]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Samejima1">[17]</xref>.</p>
      <p>These models, however, do not explain how the frontal executive function controls an expanding repertoire of behavioral strategies for acting in changing and open-ended environments: that is, how this function decides to create new strategies rather than simply adjusting and switching between previously learned ones. For example, imagine you want to sell lottery tickets to people. After a few trials, you have certainly learned a strategy that appears to be successful for selling your tickets, but your strategy then starts to fail with the next person. You then decide to switch to a new strategy. After adjusting to the new strategy and several successful trials, the new strategy fails again. You may then decide to return to your first strategy or test an entirely new one, and so on. After many trials you have probably learned many different strategies and switch across them and possibly continue to invent new ones. Moreover, among this large collection of behavioral strategies, you may have further learned that several are appropriate with young people, others with older people, some with those wearing hats, others with those holding an umbrella, and so on. How do we learn and manage such an expanding collection of behavioral strategies and decide to create new ones rather than simply adjusting and switching between previously learned ones, possibly according to environmental cues? More formally, little is known about how the frontal executive function continuously arbitrates between (1) adjusting and staying with the current actor set, (2) switching to other learned task sets, and (3) <italic>creating</italic> new task sets for driving action. This issue raises a computational problem that statistical learning models based on Dirichlet process mixtures address <xref ref-type="bibr" rid="pbio.1001293-Gershman1">[18]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Teh1">[20]</xref>. However, it remains unclear how the frontal executive function may implement such statistical models, because they critically rely on <italic>off-line</italic> Bayesian inferences operating on expanding collections of sets that rapidly become computationally intractable <xref ref-type="bibr" rid="pbio.1001293-Daw1">[21]</xref>. Thus, a fundamental issue is to understand how with limited monitoring resources the human executive function controls online the creation of new behavioral strategies and <italic>consequently</italic> manages an expanding collection of behavioral strategies for driving action.</p>
      <p>To clarify this issue, we proposed a computational model of the frontal executive function that controls the creation, learning, storage, retrieval, and selection of behavioral strategies driving action. The model constitutes a biologically plausible, online algorithm. The algorithm approximates Dirichlet process mixtures <xref ref-type="bibr" rid="pbio.1001293-DoshiVelez1">[19]</xref> by combining reinforcement learning, limited Bayesian inferences, and hypothesis testing for arbitrating between adjusting, switching, and creating actor task sets. Consistent with the capacity limit of human working memory <xref ref-type="bibr" rid="pbio.1001293-Cowan1">[22]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Oberauer1">[24]</xref>, the model assumes that the frontal executive function forms and monitors in parallel only a <italic>limited</italic> number of concurrent task sets: the executive function monitors only a small part of behavioral strategies stored in long-term memory <xref ref-type="bibr" rid="pbio.1001293-Cowan1">[22]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Risse1">[23]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Burgess1">[25]</xref>. As previously suggested <xref ref-type="bibr" rid="pbio.1001293-Doya1">[15]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Samejima1">[17]</xref>, task set reliability is inferred online for choosing the actor sets that drive behavior and adjust to external contingencies. The key assumption is that new task sets are tentatively created and probed as actors whenever no current task sets appear to be reliable. Such probe actors are partly formed by recombining the strategies stored in long-term memory according to external cues <xref ref-type="bibr" rid="pbio.1001293-Cowan1">[22]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Risse1">[23]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Burgess1">[25]</xref>. Probe task sets adjust to external contingencies, but may be subsequently discarded when they ultimately appear unnecessary. In the converse case, task set collection is updated with probe task sets: in case the monitoring capacity would be reached, the least recently used task sets are discarded but the associated strategies remain stored in long-term memory. Thus, with limited computing resources, the executive function manages an expanding repertoire of behavioral strategies and controls the selection, learning, retrieval, and creation of behavioral strategies that drive action.</p>
      <p>We provided a proper computational formulation of this model, named the PROBE model. We tested the model predictions in behavioral experiments inspired from the standard neuropsychological test of frontal executive function, namely the Wisconsin Card Sorting Test <xref ref-type="bibr" rid="pbio.1001293-Milner1">[26]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Konishi1">[27]</xref>. We compared the PROBE model to alternative models, ruling out successively key model assumptions: the notion of hypothesis-testing on task set creation (MAX model), that of task set creation (FORGET model, which encompasses existing models), and the notion of task set monitoring (RL models). We found that unlike these alternative models, the PROBE model predicts human decisions and their variations across individuals. Moreover, the PROBE model that best fits human data is endowed with a monitoring capacity of three or four task sets.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Standard Model Assumptions</title>
        <p>We assumed that task sets represent behavioral strategies stored in long-term memory. Each behavioral strategy consists of a <italic>selective</italic> mapping encoding stimulus-response associations, a <italic>predictive</italic> mapping encoding expected action outcomes given stimuli <xref ref-type="bibr" rid="pbio.1001293-Yu1">[13]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Doya1">[15]</xref>, and a <italic>contextual</italic> mapping encoding external cues predicting task set reliability (see <xref ref-type="supplementary-material" rid="pbio.1001293.s001">Figure S1</xref> and <xref ref-type="sec" rid="s4">Materials and Methods</xref>).</p>
        <p>The executive function builds and monitors at most <italic>N</italic> task sets, a bound reflecting the capacity limit of human working memory <xref ref-type="bibr" rid="pbio.1001293-Cowan1">[22]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Oberauer1">[24]</xref>. Consistent with previous studies <xref ref-type="bibr" rid="pbio.1001293-Yu1">[13]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Doya1">[15]</xref>, task set reliability is evaluated online through forward Bayesian inference: the reliability is inferred before acting according to the perceived volatility of external contingencies <xref ref-type="bibr" rid="pbio.1001293-Behrens1">[14]</xref> and the occurrence of external cues (given contextual mappings) for choosing the actor driving immediate behavior (see below). The actor selective mapping then determines the response to stimulus using a softmax policy (inverse temperature <italic>β</italic> and noise <italic>ε</italic>) <xref ref-type="bibr" rid="pbio.1001293-Sutton1">[11]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Doya1">[15]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Daw2">[28]</xref>. Thus, we assumed that in agreement with previous studies (e.g., <xref ref-type="bibr" rid="pbio.1001293-Rogers1">[6]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Dreher1">[29]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Hyafil1">[30]</xref>), selection happens at the level of task sets first, then at the level of actions within task sets.</p>
        <p>After action, selective mappings then adjust according to outcome values through standard reinforcement learning (learning rate <italic>α<sub>s</sub></italic>) <xref ref-type="bibr" rid="pbio.1001293-Sutton1">[11]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Rescorla1">[31]</xref>, while predictive mappings update outcome predictions <xref ref-type="bibr" rid="pbio.1001293-Yu1">[13]</xref>. Task set reliability is also updated according to action outcomes (given predictive mappings) and serves to adjust contextual mappings through a classical stochastic gradient descent (contextual learning rate <italic>α<sub>c</sub></italic>). Contextual mappings thus learn the external cues predicting actual reliability (referred to as contextual cues for clarity).</p>
      </sec>
      <sec id="s2b">
        <title>PROBE Model</title>
        <p>The PROBE model assumes that external contingencies are variable and generated from distinct external states. External states are potentially infinite and not directly observable, thereby reflecting variable, uncertain, and open-ended environments. The PROBE model then builds task sets as instances of external hidden states for appropriately driving behavior according to inferred external states. The reliability of every task set then measures the likelihood that the task set matches current external states given all observable events (contextual cues and the history of action outcomes). For inferring online the opportunity to create new task sets, the PROBE model evaluates task set “absolute” reliability; by concurrently monitoring the reliability of “random behavior,” the PROBE model estimates online the likelihood that no task sets match current external states and, consequently, the reliability of every task set conditional upon the history of action outcomes (and contextual cues) but not upon the collection of current task sets (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>).</p>
        <p>Consequently, when a task set appears to be <italic>reliable</italic> (i.e., more likely reliable than unreliable), it becomes the actor (i.e., the exclusive action selector) because no others meet this criterion. Conversely, whenever no task sets appear to be reliable, a new task set is created and probed as the actor. This actor initially consists of new selective/predictive mappings, which are formed from mixing selective/predictive mappings stored in long-term memory and weighted according to contextual cues (given contextual mappings) <xref ref-type="bibr" rid="pbio.1001293-Cowan1">[22]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Risse1">[23]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Burgess1">[25]</xref>. The mixture is prone to noise scaled by parameter <italic>η</italic> named <italic>recollection entropy</italic> (0≤<italic>η</italic>≤1). Endowed with prior reliability minimizing prior information <xref ref-type="bibr" rid="pbio.1001293-Jaynes1">[32]</xref>, the probe actor is initially unreliable, but its selective/predictive mapping adjusts to external contingencies: when it becomes reliable, while the other task set remains unreliable, task set creation is “confirmed”; task set collection is updated by possibly discarding the least recent actor set in case the capacity limit would be reached. When conversely another task set becomes reliable before the probe actor, the latter is discarded and the former becomes the actor. Thus, the PROBE model is an online, forward approximation of Dirichlet process mixtures <xref ref-type="bibr" rid="pbio.1001293-DoshiVelez1">[19]</xref> based on hypothesis testing on task set creation (i.e., on the critical no-parametric component of Dirichlet processes) (see <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>).</p>
        <p>In the PROBE model, unselected task sets are inferred as being <italic>unreliable</italic> (i.e., unrelated to current external states). The PROBE model therefore assumes that unlike multiple actor models <xref ref-type="bibr" rid="pbio.1001293-Doya1">[15]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Samejima1">[17]</xref>, no learning occurs in selective and predictive mappings within unselected task sets. Thus, only selective/predictive mappings of actor task sets are adjusted according to action outcomes. This assumption is consistent with empirical evidence that in task switching, task set selection inhibits internal mappings of unselected task sets (e.g., <xref ref-type="bibr" rid="pbio.1001293-Rogers1">[6]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Dreher1">[29]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Hyafil1">[30]</xref>).</p>
        <p>Overall, the PROBE model has six free parameters. Standard free parameters are: inverse temperature <italic>β</italic> scaling greediness in action selection, noise <italic>ε</italic> scaling lapses probability in action selection, and learning rates <italic>α<sub>s</sub></italic> and <italic>α<sub>c</sub></italic> scaling updating rates of selective and contextual mappings. Additionally, we treated bounds <italic>N</italic> and recollection entropy <italic>η</italic> as free parameters for investigating multiple theoretical schemes. We also considered two additional free parameters capturing possible human biases (<xref ref-type="sec" rid="s4">Materials and Methods</xref>): <italic>context-sensitivity bias δ</italic>&gt;0 increasing transiently the perceived volatility of external contingencies (i.e., the tendency to switch actors whenever, besides stimuli, additional external cues change between two successive trials) and <italic>confirmation bias θ</italic> enhancing prior reliability of newly formed task sets, thereby restraining their immediate disengagement.</p>
      </sec>
      <sec id="s2c">
        <title>Alternative Models</title>
        <p>The MAX model is identical to the PROBE model, except that it removes the notion of hypothesis testing for creating task sets. New task sets are created for acting only when no task sets appear more reliable than “random behavior” (i.e., when it becomes more likely that no task sets match current external states) (see <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>). Endowed with prior reliability corresponding to random behavior, new task sets therefore appear initially as the most reliable ones, so that task set creation is automatically confirmed. Thus, the most reliable task set is the actor, provided that it remains more reliable than random behavior. The MAX model creates new task sets <italic>only when</italic> no current task sets are more reliable than chance, whereas the PROBE creates new task sets <italic>once</italic> no current task sets appear to be reliable. Conversely, the MAX model keeps new task sets in the monitoring buffer when there are no more actors, whereas the PROBE model keeps them <italic>provided that</italic> they have been reliable. The MAX model corresponds to the one-particle filtering approximation of Dirichlet process mixtures <xref ref-type="bibr" rid="pbio.1001293-Daw1">[21]</xref>. Otherwise, the MAX and PROBE models are identical and have the same free parameters.</p>
        <p>The FORGET model further removes the notion of task set creation (<xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>). The actor is chosen using a softmax policy (inverse temperature <italic>β′</italic>) for possibly recycling task sets. Concomitantly, the strategies associated with unused task sets decay into the random strategy (decay rate <italic>φ</italic>, 0&lt;<italic>φ&lt;1</italic>) <xref ref-type="bibr" rid="pbio.1001293-Cowan2">[33]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Ricker1">[34]</xref>, so that unused task sets may be recycled as “new” task sets. Thus, the collection of task sets is fixed and corresponds to monitoring capacity <italic>N</italic>. As external states are potentially infinite, task set reliability therefore represents relative evidence across distinct behavioral strategies rather than external states. The FORGET model therefore assumes that as in multiple actor models <xref ref-type="bibr" rid="pbio.1001293-Doya1">[15]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Samejima1">[17]</xref> selective/predictive mappings are adjusted concurrently in every task set in proportion to task set reliability. For consistency with both the PROBE and MAX models, we also tested the FORGET model with the assumption that learning occurs only for actor task sets. In the present study, the two assumptions actually yield to virtually the same predictions, so we ignore the distinction henceforth.</p>
        <p>The FORGET model encompasses existing models: basic RL models when bound <italic>N</italic> = 1 <xref ref-type="bibr" rid="pbio.1001293-Sutton1">[11]</xref>,<xref ref-type="bibr" rid="pbio.1001293-ODoherty1">[12]</xref>, UM models when <italic>N</italic> = 2 and decay rate <italic>φ</italic> is large relative to external volatility <xref ref-type="bibr" rid="pbio.1001293-Yu1">[13]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Behrens1">[14]</xref>, and finally, multiple actor models combining RL and UM when <italic>N</italic>&gt;1 and φ = 0 <xref ref-type="bibr" rid="pbio.1001293-Doya1">[15]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Samejima1">[17]</xref>. The FORGET model has the same free parameters as the MAX and PROBE models, except that decay rate <italic>φ</italic> and inverse temperature <italic>β′</italic> replace recollection entropy and confirmation bias, respectively.</p>
      </sec>
      <sec id="s2d">
        <title>Human Decisions With No Contextual Cues</title>
        <p>We conducted the first experiment with 22 participants who responded to successive visual stimuli (three possible digits) by pressing one among four response buttons (see <xref ref-type="supplementary-material" rid="pbio.1001293.s002">Figure S2A</xref> and <xref ref-type="sec" rid="s4">Materials and Methods</xref>). For each stimulus, one response led to a positive outcome with a probability of 90% (audiovisual feedbacks associated with extra monetary payoff), while the others led to a positive outcome with a probability of 10% only. Unbeknownst to the participants, the mapping between stimuli and best responses shifted after an unpredictable number of trials, ranging from 36 to 54. No cues predicted such changes. We refer to a series of trials occurring between two successive changes as an <italic>episode</italic>. Without being instructed, moreover, participants performed two distinct sessions. In the <italic>open</italic> session, every episode corresponded to new stimulus response mappings, whereas in the <italic>recurrent</italic> session, only three mappings reoccurred unpredictably; every episode corresponded to one among these three mappings, so that participants could reuse what they previously learned.</p>
        <p>Following episode changes, participants then produced perseverative responses (best responses in the preceding episode), correct responses (best responses in the ongoing episode), or exploratory responses (neither perseverative nor correct). In both conditions, correct response rates increased from ∼2% at episode onsets to ∼90% about 30 trials later (chance level: 25%). Exploratory response rates increased from ∼5% at episode onsets, peaked at ∼40% about three or four trials later, and then gradually returned to ∼5% (chance level: 50%) (<xref ref-type="fig" rid="pbio-1001293-g001">Figure 1A,B</xref>). Thus, in all episodes, participants maximized pay-offs by learning the associations between stimuli and correct responses. Critically, correct responses increased and exploratory responses vanished faster in the recurrent than open episodes (both <italic>t</italic>s&gt;3.4, <italic>p</italic>s&lt;0.005). Thus, in recurrent episodes, participants retrieved the appropriate associations they had previously learned, although in the meantime they learned incongruent associations.</p>
        <fig id="pbio-1001293-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001293.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Human decisions with no contextual cues.</title>
            <p>Participants' performances in recurrent (red) and open (green) episodes plotted against the number of trials following episode onsets. Shaded areas are S.E.M. across participants. (A) Correct response rates. (B) Exploratory response rates. (C) Mutual dependence (i.e., mutual information) of two successive correct decisions averaged over five-trial sliding bins (see <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.g001" xlink:type="simple"/>
        </fig>
        <p>Moreover, we found that in the first trials of recurrent episodes, a positive feedback caused the production of a correct response in the next trial even when the two successive stimuli differed. Indeed, the mutual dependence between two successive correct decisions strongly increased in the first trials of recurrent compared to open episodes (<italic>t</italic> = 2.8, <italic>p</italic> = 0.012, <xref ref-type="fig" rid="pbio-1001293-g001">Figure 1C</xref> and <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>). In the following trials, by contrast, this mutual dependence remained weak, approximately constant, and similar in both recurrent and open episodes (<italic>t</italic>&lt;1). This finding shows that in the first trials of recurrent episodes, participants used feedbacks to retrieve the appropriate stimulus-response mapping rather than recollecting each stimulus-response association separately. Consequently, participants built and stored multiple stimulus-response mappings and monitored action outcomes for retrieving previously learned mappings or learning new ones. This finding further confirms that the improved performance in the recurrent compared to open condition could not arise from faster learning rates in recurrent than open episodes. Indeed, learning rates are presumed to increase with uncertainty <xref ref-type="bibr" rid="pbio.1001293-Nassar1">[35]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Mathys1">[36]</xref> and should instead be faster in open episodes that feature increased uncertainty.</p>
        <p>To understand this human ability, we computed for every participant the models' parameters that best predict his or her choice in every trial given his or her previous responses (<xref ref-type="fig" rid="pbio-1001293-g002">Figure 2</xref>, legend). As expected, the three models fit participants' responses significantly better than a basic RL model adjusting for a single actor, even when penalizing for increased model complexity (<xref ref-type="fig" rid="pbio-1001293-g002">Figure 2</xref>, left). However, neither the fitted FORGET, MAX, nor RL model accounted for the differential performances observed between the recurrent and open episodes (<xref ref-type="fig" rid="pbio-1001293-g003">Figure 3</xref>). Indeed, the best fitting FORGET model was obtained with bound <italic>N</italic> = 2 (<italic>M</italic> = 2.2; S.E.M. = 0.16) and large decay rate <italic>φ</italic> (<italic>M</italic> = 14%, S.E.M. = 0.9%) relative to the volatility of external contingencies (3%). This model therefore reduces to a standard UM model <xref ref-type="bibr" rid="pbio.1001293-Yu1">[13]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Behrens1">[14]</xref> that monitors only the actor reliability relative to chance with no ability to retrieve previously learned mappings. Similarly, the best fitting MAX model was obtained with bound <italic>N</italic> = 1 (<italic>M</italic> = 1.4; S.E.M. = 0.14). This model again monitors only the actor reliability relative to chance; previously learned mappings are retrieved only by creating new task sets from strategies stored in long-term memory with no guidance from action outcomes. The model therefore fails to account for the increased mutual dependence of successive decisions made in the first trials of recurrent episodes (<xref ref-type="fig" rid="pbio-1001293-g003">Figure 3</xref>).</p>
        <fig id="pbio-1001293-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001293.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Comparison of model fits.</title>
            <p>Models were fitted using the standard maximum log-likelihood (LLH) and least squares (LS) methods. Histograms show the LS and LLH as well as the Bayesian information criterion (BIC) obtained for each model. The LLH method maximizes the predicted (log-)likelihood of observing actual participants' responses. The LS method minimizes the square difference between observed frequencies and predicted probabilities of correct responses. The Bayesian information criterion (BIC) alters LLH values according to model complexity favoring models with less free parameters (<xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>). Larger LLH, lower LS, and lower BIC values correspond to better fits. Left, first experiment with no contextual cues. Parameters that cannot be estimated (i.e., contextual learning rate <italic>α<sub>c</sub></italic> and context-sensitivity bias <italic>δ</italic>) were removed from the fitting. RL, basic reinforcement learning model including a single task-set learning stimulus-response association (free parameters: inverse temperature <italic>β</italic>, noise <italic>ε</italic>, learning rate <italic>α<sub>s</sub></italic>). Right, second experiment with contextual cues. RL, pure reinforcement learning model learning a mixture of stimulus-response and stimulus-cue-response associations (free parameters: inverse temperature <italic>β</italic>, <italic>β′</italic> noise <italic>ε</italic>, learning rates <italic>α<sub>s</sub></italic> and <italic>α<sub>c</sub></italic>, and mixture rate <italic>ω</italic>; see <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>). Note that in both experiments the PROBE model was the best fitting model for every fitting criterion (LS, all <italic>F</italic>s&gt;3.8, <italic>p</italic>&lt;0.001).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.g002" xlink:type="simple"/>
        </fig>
        <fig id="pbio-1001293-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001293.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Predicted versus observed decisions with no contextual cues.</title>
            <p>Correct and exploratory response rates as well as mutual dependences of successive correct decisions in recurrent (red) and open (green) episodes plotted against the number of trials following episode onsets. Lines ± error bars (mean ± S.E.M.): performances predicted by fitted RL, FORGET, MAX, and PROBE models. RL, reinforcement learning model including a single actor learning stimulus-response associations (details in <xref ref-type="fig" rid="pbio-1001293-g002">Figure 2</xref>, legend). Correct and exploratory response rates were computed in every trial according to the actual history of participants' responses. Mutual dependence of successive correct decisions predicted by each fitted model was computed as the mutual information between two successive correct responses produced by the model independently of actual participants' responses (one simulation for each participant). Stars show significant differences at <italic>p</italic>&lt;0.05 (mutual dependences on the first eight trials between recurrent and open episodes. <italic>t</italic> tests, RL &amp; FORGET, all <italic>t</italic>s&lt;1. MAX, all <italic>t</italic>s&lt;2, <italic>p</italic>s&gt;0.06; PROBE, all <italic>t</italic>s&gt;3.2, <italic>p</italic>s&lt;0.004). Lines ± shaded areas (mean+S.E.M.): human performances (data from <xref ref-type="fig" rid="pbio-1001293-g001">Figure 1</xref>). Insets magnify the plots for Trials 7, 8, and 9. See <xref ref-type="supplementary-material" rid="pbio.1001293.s006">Table S1</xref> for fitted model parameters. See <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref> for the discrepancy observed in Trial 5 between participants' exploratory responses and model predictions (section “Comments on Model Fits”).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.g003" xlink:type="simple"/>
        </fig>
        <p>By contrast, the PROBE model predicts participants' responses and their successive dependence in both recurrent and open episodes (<xref ref-type="fig" rid="pbio-1001293-g003">Figure 3</xref>). Consistently, the PROBE model fits participants' responses significantly better than the other models (<xref ref-type="fig" rid="pbio-1001293-g002">Figure 2</xref>, left). The best fitting PROBE model was obtained with bound <italic>N</italic> = 3 (<italic>M</italic> = 3.3; S.E.M. = 0.3); in recurrent episodes, previously learned mappings are retrieved by selecting the appropriate task sets according to action outcomes; this explains the increased dependence of successive decisions made in the first episode trials. In open episodes, by contrast, new task sets are created for driving behavior and learning the new mappings, when facing new external contingencies that cannot be reliably predicted.</p>
        <p>We then tested the hypothesis underlying the PROBE model that action selection involves a two-stage process: first choosing the actor task set and then selecting actions within the actor task set. For that purpose, we considered a variant of the PROBE model that rules out this hypothesis: actions are directly selected by marginalizing over task sets on the basis of task sets' reliability. In this variant, consistently, concurrent learning occurs for every task set in proportion to task set reliability. Again, the best fitting variant was obtained with monitoring bound <italic>N</italic> = 1, so that the variant becomes equivalent to the best fitting FORGET and MAX models and similarly fails to account for the differential performances observed between the recurrent and open episodes. Thus, the data support the PROBE model assumption that action selection is based on first choosing the actor task set according to task set reliability and then selecting actions according to the actor selective model.</p>
        <p>Finally, we compared the PROBE model parameters that best fit participants' responses (see <xref ref-type="supplementary-material" rid="pbio.1001293.s006">Table S1</xref>) to those optimizing PROBE model performance in this protocol. Using computer simulations, the optimal PROBE model parameters were computed as those maximizing the proportion of correct responses produced by the model over both sessions irrespective of participants' data (optimal PROBE model performance, 80%; participants' performance ± S.E.M., 77%±0.6%). As expected, optimal bound <italic>N</italic> was equal to 3, and optimal recollection entropy <italic>η</italic> was equal to 1 (the maximal value); because the optimal model is able to monitor the exact number of recurrent mappings in the recurrent condition, the recollection of behavioral strategies from long-term memory becomes useless. As mentioned above, best fitting bound <italic>N</italic> averaged across participants was similar to the optimal value (<italic>M</italic> = 3.3; S.E.M. = 0.3). Compared to the optimal PROBE model, however, participants exhibited lower recollection entropy <italic>η</italic> (<italic>η<sub>best-fitting</sub></italic> ± S.E.M. = 0.72±0.07) and positive confirmation bias (<italic>θ<sub>optimal</sub></italic> = 0; <italic>θ<sub>best-fitting</sub></italic> = 0.74±0.12). This indicates that participants retrieved learned behavioral strategies by relying more on long-term memory recollection than optimally on working memory retrieval (monitoring buffer). This is consistent with the fact that in several participants, monitoring bound <italic>N</italic>s were lower than the number of recurrent mappings.</p>
        <p>Regarding action selection within task sets, optimal inverse temperature was large and equal to 30 and optimal noise ε equal to 0. As expected, the optimal model behavior is greedy and most often selects best rewarding responses. Interestingly, participants were as greedy as the optimal model behavior with similar best-fitting inverse temperature <italic>β</italic> (32±2) and virtually zero noise <italic>ε</italic> (0.01±0.003). Optimal and best fitting learning rates of selective mappings <italic>α<sub>s</sub></italic> were also similar (<italic>α<sub>s(optimal)</sub></italic> = 0.4; <italic>α<sub>s(best-fitting)</sub></italic> = 0.41±0.03), indicating that participants efficiently stored behavioral strategies in long-term memory.</p>
      </sec>
      <sec id="s2e">
        <title>Human Decisions with Contextual Cues</title>
        <p>In a second experiment, we examined whether in the presence of contextual cues predicting current external contingencies the PROBE model remains the best predictor of participants' decisions. Forty-nine additional participants first carried out the same <italic>recurrent</italic> session as described above, except that unbeknownst to them, stimulus colors informed current mappings between stimuli and best responses. These contextual cues therefore switched at episode onsets and sometimes within episodes, because the same mapping could be associated with distinct color cues (see <xref ref-type="supplementary-material" rid="pbio.1001293.s002">Figure S2B</xref> and <xref ref-type="sec" rid="s4">Materials and Methods</xref>).</p>
        <p>In these cued recurrent episodes, participants roughly behaved as in previous, uncued recurrent episodes (<xref ref-type="fig" rid="pbio-1001293-g004">Figure 4A,B</xref>). Following episode changes, however, correct responses increased and exploratory responses vanished earlier in cued than in uncued episodes. These effects were even observed in the first episode trial before the first (adverse) feedback (both <italic>t</italic>s&gt;4; <italic>p</italic>&lt;0.001), indicating that participants used contextual cues to switch behavior proactively.</p>
        <fig id="pbio-1001293-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001293.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Human decisions with contextual cues.</title>
            <p>Participants' performances are plotted against the number of trials following episode onsets. Shaded areas are S.E.M. across participants. (A and B) Correct and exploratory response rates in uncued (red) and cued (blue) recurrent episodes. Uncued recurrent episodes are from Experiment 1 for participants who performed the recurrent session before the open session (half of participants). Cued recurrent episodes correspond to the first session of the second experiment. (C and D) Correct and exploratory response rates in control (blue), transfer (orange), and open (green) episodes (second experiment, second session). In control episodes, the drop of correct response rates and the peak of exploratory response rates visible on Trial 29 corresponded to contextual cue changes while external contingencies remained unchanged (see <xref ref-type="supplementary-material" rid="pbio.1001293.s003">Figure S3</xref>).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.g004" xlink:type="simple"/>
        </fig>
        <p>Participants then carried out a second session identical to the first one, except that unbeknownst to them, the session intermixed three types of cued episodes: <italic>control</italic> episodes corresponding to cued recurrent episodes encountered in the first session, <italic>transfer</italic> episodes corresponding to such recurrent episodes but associated with new contextual cues, and <italic>open</italic> episodes corresponding to new mappings and contextual cues.</p>
        <p>Following episode changes, correct responses increased and exploratory responses vanished similarly in control and transfer episodes (both <italic>t</italic>s&lt;1.5, <italic>p</italic>s&gt;0.13) but faster and earlier in these episodes than in open episodes (all <italic>t</italic>s&gt;4.4, <italic>p</italic>s&lt;0.001, <xref ref-type="fig" rid="pbio-1001293-g004">Figure 4C,D</xref>). Participants therefore performed without using a single “flat” actor directly learning stimulus-cue-response associations. Indeed, in this case, the performance in transfer episodes would have been similar to the performance in open rather than control episodes.</p>
        <p>For every participant, as described above, we then computed the models' parameters that best predict the participants' responses. Again, the PROBE model was the best fitting model, even when compared to pure RL models learning mixtures of stimulus-response and stimulus-cue-response associations (<xref ref-type="fig" rid="pbio-1001293-g002">Figure 2</xref>, right). Unlike the other models, the PROBE model predicts participants' performances in control, transfer, and open episodes (<xref ref-type="fig" rid="pbio-1001293-g005">Figure 5</xref>). Moreover, the best fitting PROBE model was again obtained with bound <italic>N</italic> = 3 (<italic>M</italic> = 3.2; S.E.M. = 0.3). Other model parameters were also similar to those obtained in the first experiment with no contextual cues (mean ± S.E.M.: recollection entropy <italic>η</italic> = 0.84±0.02; confirmation bias <italic>θ</italic> = 0.71±0.06; inverse temperature <italic>β</italic> = 25±2; noise <italic>ε</italic> = 0.05±0.01), except learning rate <italic>α<sub>s</sub></italic>, which was lower (0.18±0.1). Compared to the optimal PROBE model, however, participants exhibited lower contextual learning rates (<italic>α<sub>c(optimal)</sub></italic> = 0.1; <italic>α<sub>c(best- fitting)</sub></italic> = 0.006±0.002) and large contextual sensitivity bias <italic>δ</italic> (<italic>δ<sub>optimal</sub></italic> = 0; <italic>δ<sub>best fitting</sub></italic> = 0.55±0.04). Unlike a participant, the optimal PROBE model perfectly learns the associations between contextual cues and behavioral strategies and uses them to proactively select/retrieve learned behavioral strategies. The discrepancy is consistent with the fact that in the model only color cues were implemented as additional stimulus attributes, whereas participants faced much more contextual information and were not specifically informed about color cues.</p>
        <fig id="pbio-1001293-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001293.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Predicted versus observed decisions with contextual cues.</title>
            <p>Correct and exploratory response rates in control (blue), transfer (orange), and open (green) episodes plotted against the number of trials following episode onsets. Lines ± error bars (mean ± S.E.M.): performances predicted by fitted RL, FORGET, MAX, and PROBE models in every trial according to the actual history of participants' responses. The RL model includes a single actor learning a mixture of stimulus-response and stimulus-cue-response associations (see <xref ref-type="fig" rid="pbio-1001293-g002">Figure 2</xref> legend for details). Lines ±shaded areas (mean+S.E.M.): human performances (data from <xref ref-type="fig" rid="pbio-1001293-g004">Figure 4C,D</xref>). See <xref ref-type="supplementary-material" rid="pbio.1001293.s006">Table S1</xref> for fitted model parameters. Note the systematic discrepancies between the predictions from RL, FORGET, and MAX models and human data.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.g005" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2f">
        <title>Inter-Individual Variability</title>
        <p>Knowing that adaptive behaviors are highly variable and may even qualitatively differ across individuals <xref ref-type="bibr" rid="pbio.1001293-Braver1">[37]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Gallistel1">[39]</xref>, we examined inter-individual variability by analyzing separately three groups of participants identified from post-tests. Post-tests assessed participants' ability to recollect the three stimulus-response mappings they learned in recurrent sessions (<xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>). We found that only two-thirds of participants recollected the three mappings (13/22 and 34/49 in the first and second experiment, respectively). We refer to them as <italic>exploiting</italic> participants and to the remaining third as <italic>exploring</italic> participants. Furthermore, in the second experiment, only half of exploiting participants (19/34) recollected the contextual cues associated with learned mappings. We refer to them as <italic>context-exploiting</italic> participants and to the remaining half (15/34) as <italic>outcome-exploiting</italic> participants.</p>
        <p>Consistently, in both experiments, exploring participants behaved without retrieving previously learned stimulus-response mappings. Unlike exploiting participants, they performed identically across all episodes (<xref ref-type="fig" rid="pbio-1001293-g006">Figures 6</xref> and <xref ref-type="fig" rid="pbio-1001293-g007">7</xref>). Conversely, only context-exploiting participants adjusted faster in control than transfer episodes (<xref ref-type="fig" rid="pbio-1001293-g007">Figure 7</xref>), indicating that unlike the others, context-exploiting participants further used contextual cues for retrieving the appropriate mappings. Importantly, these individual differences were unrelated to possible variations in fatigue, attention, or motivation across participants. Indeed, in control and transfer episodes, exploiting participants adjusted faster than exploring participants, but in open episodes, the opposite was observed: exploring participants adjusted faster than exploiting participants (<xref ref-type="fig" rid="pbio-1001293-g007">Figure 7</xref>, legend). Moreover, no groups ignored contextual cues as shown in <xref ref-type="supplementary-material" rid="pbio.1001293.s003">Figure S3</xref>.</p>
        <fig id="pbio-1001293-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001293.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Individual differences in decision-making with no contextual cues.</title>
            <p>Correct and exploratory response rates as well as mutual dependence of successive correct decisions in recurrent (red) and open (green) episodes plotted against the number of trials following episode onsets (data from Experiment 1). Lines ± shaded areas (mean+S.E.M.): participants' performances. Lines ± error bars (mean ± S.E.M.): predicted performances from the fitted PROBE model. Predicted correct and exploratory response rates were computed in every trial according to the actual history of participants' responses. Predicted mutual dependence of successive correct decisions was computed as the mutual information between two successive correct responses produced by the model independently of actual participants' responses (one simulation for each participant). Left, exploiting participants: Correct responses increased and exploratory responses vanished faster in recurrent than open episodes (Wilcoxon-test, both <italic>z</italic>s&gt;2.8, <italic>p</italic>s&lt;0.005). Right, exploring participants: performances were similar in recurrent and open episodes (correct and exploratory responses: Wilcoxon-test, both <italic>z</italic>s&lt;1.4, <italic>p</italic>s&gt;0.17). See <xref ref-type="supplementary-material" rid="pbio.1001293.s007">Table S2</xref> for fitted model parameters in each group. See <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref> for the discrepancy observed in Trial 5 between exploiting participants' exploratory responses and model predictions in recurrent episodes (section “Data Analyses”).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.g006" xlink:type="simple"/>
        </fig>
        <fig id="pbio-1001293-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001293.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Individual differences in decision-making with contextual cues.</title>
            <p>Correct and exploratory response rates in control (blue), transfer (orange), and open (green) episodes plotted against the number of trials following episode onsets (data from Experiment 2). Lines ± shaded areas (mean+S.E.M.): participants' performances. Lines ± error bars (mean ± S.E.M.): performances predicted by the fitted PROBE model in every trial according to the actual history of participants' responses. Left, context-exploiting participants: Correct responses increased and exploratory responses vanished faster in control than transfer episodes (Wilcoxon-tests, both <italic>z</italic>s&gt;2.4, <italic>p</italic>s&lt;0.015) and faster in transfer than open episodes (Wilcoxon-tests, both <italic>z</italic>s&gt;3.1, <italic>p</italic>s&lt;0.002). Middle, outcome-exploiting participants: performances were similar in control and transfer episodes (correct and exploratory responses: Wilcoxon-tests, both <italic>z</italic>s&lt;1.4, <italic>p</italic>s&gt;0.15), but correct responses increased and exploratory responses vanished faster in transfer than open episodes (Wilcoxon-tests, both <italic>z</italic>s&gt;2.3, <italic>p</italic>s&lt;0.023). Right, exploring participants: performances were similar in control, transfer, and open episodes (correct and exploratory responses: Friedmann-tests, both χ<sup>2</sup>&lt;5.3, <italic>p</italic>s&gt;0.07). Note that in open episodes, exploring participants adjusted faster than exploiting participants (correct responses: both <italic>t</italic>s&gt;3.0, <italic>p</italic>s&lt;0.004). See <xref ref-type="supplementary-material" rid="pbio.1001293.s007">Table S2</xref> for fitted model parameters in each group.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.g007" xlink:type="simple"/>
        </fig>
        <p>In every group, the PROBE model precisely predicted participants' behavior (<xref ref-type="fig" rid="pbio-1001293-g006">Figures 6</xref> and <xref ref-type="fig" rid="pbio-1001293-g007">7</xref>) and strikingly remained the best fitting model (<xref ref-type="fig" rid="pbio-1001293-g008">Figure 8</xref>). In the best fitting PROBE model, moreover, exploring participants featured only larger <italic>confirmation biases θ</italic> than exploiting participants (<italic>n</italic> = 24 versus 34; Mann-Whitney tests, <italic>p</italic>&lt;0.001; all other parameters, <italic>p</italic>s&gt;0.11). Notably, bounds <italic>N</italic> and recollection entropy <italic>η</italic> were similar between the two groups (<italic>M</italic> ± S.E.M.: <italic>N</italic><sub>exploring</sub> = 3.3±0.3; <italic>N</italic><sub>exploiting</sub> = 3.0±0.3; <italic>η</italic><sub>exploring</sub> = 77%±2%; <italic>η</italic><sub>exploiting</sub> = 82%±6%). With only larger confirmation biases, exploring participants appeared simply more prompt than exploiting participants to accept probe actors they created especially when episodes changed. Consistent with their post-test retrieval performances and large recollection entropy, exploring compared to exploiting participants were thus modeled as re-learning from scratch rather than retrieving the stimulus-response mappings they had previously learned.</p>
        <fig id="pbio-1001293-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.1001293.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Comparison of model fits according to individual differences.</title>
            <p>Least square residuals (LS), maximal log-likelihoods (LLH), and Bayesian information criteria (BIC) obtained for each model in exploring versus exploiting participants (left) and in context- versus outcome-exploiting participants (right). RL, reinforcement learning; F, FORGET; M, MAX; P, PROBE model. See details in the <xref ref-type="fig" rid="pbio-1001293-g002">Figure 2</xref> legend. Note that in every participants' group, the PROBE model was the best fitting model for every fitting criterion (LS, all <italic>F</italic>s&gt;4.2, <italic>p</italic>s&lt;0.001 in exploiting and exploring groups; Wilcoxon tests in context- and outcome-exploiting groups, all <italic>z</italic>s&gt;2.0, <italic>p</italic>s&lt;0.047).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.g008" xlink:type="simple"/>
        </fig>
        <p>By contrast, context- compared to outcome-exploiting participants featured only larger <italic>context-sensitivity biases δ</italic>, larger contextual learning rates <italic>α<sub>C</sub></italic> (<italic>M</italic> = 1.1% versus 0.4%) and slightly lower recollection entropy <italic>η</italic> (<italic>M</italic> = 77%±3% versus 86%±2%) (Mann-Withney tests, all <italic>p</italic>s&lt;0.025; all other parameters, <italic>p</italic>s&gt;0.1). Again, bound <italic>N</italic> was virtually identical in the two groups (<italic>N</italic> = 3.474 versus 3.467, S.E.M.s = 0.4). With larger <italic>context-sensitivity</italic> biases, context- compared to outcome-exploiting participants appeared more prompt to switch behavior whenever contextual cues shifted. In this protocol, this bias along with slightly lower recollection entropy strongly favored the learning of contextual models, because cue changes were most often associated with episode changes. Consistent with their post-test retrieval performances, outcome-exploiting participants were thus modeled as learning more efficiently the associations between contextual cues and stimulus-response mappings.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>We found that the best account of human decisions is the PROBE model combining forward Bayesian inference for evaluating task set reliability and choosing the most reliable actor set and hypothesis-testing for possibly creating new task sets when facing ambiguous or unknown situations. Relaxing successively these assumptions, namely hypothesis-testing (MAX model), task set creation (FORGET model), and reliability monitoring (pure RL models), fails to account for human decisions. In contrast to these alternative models, the PROBE model predicts human decisions and its variations across individuals in recurrent or open-ended environments, with variable external contingencies possibly associated with contextual cues.</p>
      <p>Critically, the PROBE model estimates the “absolute” reliability of task sets and consequently involves <italic>binary</italic> decision-making for selecting actors, even when multiple task sets are monitored in parallel. Indeed, actor selection is based on a “<italic>satisficing</italic>” criterion based on task set reliability <xref ref-type="bibr" rid="pbio.1001293-Simon1">[1]</xref>: either a task set appears to be reliable, in which case it becomes the actor, because no other task sets meet this criterion, or no task set appears reliable, in which case a new task set is created and serves as an actor (<xref ref-type="sec" rid="s4">Materials and Methods</xref>). The results thus show that human executive control (i.e., task set selection) involves <italic>binary</italic> decisions based on task set <italic>reliability</italic>. This finding contrasts with action selection within task sets, which in agreement with previous studies <xref ref-type="bibr" rid="pbio.1001293-Daw2">[28]</xref> involves <italic>multi-valued</italic> decisions based on (soft-) maximizing expected <italic>utility</italic> of actions.</p>
      <p>The PROBE model further indicates that in both experiments participants' performances relied on forming and monitoring at most three or four task sets in parallel. This capacity was independent of individual differences in retrieving task sets but might reflect the number of stimulus-response mappings used in recurrent sessions (i.e., three). To examine this possibility, we fit the PROBE model on participants' performances in open sessions only, which include no recurrent episodes. Again, we found that the best fitting PROBE model was obtained with monitoring bound <italic>N</italic> equal to three or four task sets (<italic>M</italic> = 3.4, S.E.M. = 0.5, with no significant differences between open sessions performed first and second: <italic>N</italic> = 2.9±0.6; <italic>N</italic> = 4.0±0.8; Mann-Whitney test, <italic>p</italic>&gt;0.46). This capacity therefore appears to be independent of the protocol structure. Furthermore, we conducted an additional experiment with 30 additional participants that consisted of a recurrent session identical to that used in Experiment 1, except that <italic>four</italic> recurrent mappings between stimuli and correct responses reoccurred pseudo-randomly across episodes. We found that the best fitting monitoring bound <italic>N</italic> was virtually identical to that found in Experiments 1 and 2 (<italic>M</italic> = 3.4, S.E.M. = 0.3) (<xref ref-type="supplementary-material" rid="pbio.1001293.s004">Figure S4</xref>, legend). Thus, monitoring bound <italic>N</italic> was essentially unaltered by the amount of information stored in long-term memory (selective and predictive mappings). In this session, moreover, participants performed as in open episodes (<xref ref-type="supplementary-material" rid="pbio.1001293.s004">Figure S4</xref>), indicating that, on average, participants monitored no more than three task sets. Altogether, the results provide evidence that, on average, the monitoring capacity of human executive function (also referred to as procedural working-memory <xref ref-type="bibr" rid="pbio.1001293-Risse1">[23]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Oberauer1">[24]</xref>) is limited to three concurrent behavioral strategies (four with probe actors). We note that this limit also matches that previously proposed for human declarative working memory <xref ref-type="bibr" rid="pbio.1001293-Cowan1">[22]</xref>.</p>
      <p>Despite this monitoring capacity, the binary structure of executive control in the PROBE model predicts that humans can flexibly switch back and forth between two task sets but with more difficulty across three or more task sets. Indeed, when only one task set is monitored along with the actor and with no evidence that none fit external contingencies, then the unreliability of the actor <italic>implies</italic> the reliability of the other task set and, consequently, its selection as an actor (<xref ref-type="sec" rid="s4">Materials and Methods</xref>). In the other cases, however, especially when two or more task sets are monitored along with the actor, the unreliability of the actor does not imply the reliability of another one. In that event, a new actor is created and probed until additional evidence will possibly reveal the reliability of another task set and the rejection of the probe actor. This prediction is consistent with previous studies showing that humans are impaired in switching back and forth across three compared to two task sets, irrespective of working memory load <xref ref-type="bibr" rid="pbio.1001293-Charron1">[40]</xref>. According to the present results, this impairment reflects the binary nature rather than the monitoring capacity of human executive control.</p>
      <p>It is worth noting that with monitoring bound <italic>N</italic> equal to three (or more), both the FORGET and MAX models qualitatively account for the differential performances and dependences of successive responses we observed between recurrent and open episodes. However, these differential effects result not only from increased performances in recurrent episodes but mostly from dramatic decreased performances in open episodes; both models become much more perseverative than human participants in open episodes. As shown in the <xref ref-type="sec" rid="s2">Results</xref> section, both models actually reach human performances in open episodes only by monitoring a single actor task set against chance or “random behavior” (which is obtained in the FORGET model through large decay rate <italic>φ</italic>), thereby reproducing the binary control inherent to the PROBE model. In contrast to the PROBE model, however, they consequently fail to properly account for the differential performances observed between recurrent and open conditions. This provides further evidence that the binary structure of task set selection combined with the monitoring of alternative task sets are critical components of human executive function.</p>
      <p>Accordingly, human executive function monitors up to three or four task sets and, when one appears reliable, selects it for driving behavior. Otherwise, the executive function directly creates a new task set and probes it as an actor rather than exploiting only the collection of behavioral strategies associated with current task sets. The probe actor forms a new strategy that recombines previously learned strategies stored in long-term memory and collected according to external cues (given contextual mappings). We found that recollection entropy was large (&gt;0.7), indicating that task set creation especially prompts exploratory (random) behavior, at least when no stored strategies are specifically cued by contextual signals. In the converse case, task set creation comes to re-instantiate such externally cued strategies from long-term memory for driving behavior, even when they are not associated with current task sets. However, the PROBE model further assumes that task set creation is tested; probe actors may be discarded when, despite learning, other task sets become reliable before such probe actors. The results therefore reveal two fundamentally distinct human exploration processes: first, <italic>uncontrolled</italic> exploration stochastically selecting actions within actor task sets according to a softmax policy for learning behavioral strategies that maximize action utility <xref ref-type="bibr" rid="pbio.1001293-Cohen1">[3]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Daw2">[28]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Frank1">[41]</xref>, and second, <italic>controlled</italic> exploration occurring whenever no task sets appear reliable for investigating the opportunity to re-instantiate behavioral strategies stored in long-term memory or to learn new ones depending upon contextual cues.</p>
      <p>For the sake of simplicity, the model described herein assumes that no internal alterations of action outcome utility (e.g., devaluation due to satiety) have occurred when task sets are created from behavioral strategies collected from long-term memory. Consistently, no alterations of outcome utility were induced in the present experimental protocol. To further account for possible utility alterations, selective mappings that encode action utility in behavioral strategies need to be recalibrated according to the <italic>current</italic> utility of action outcomes when new task sets are created. As previously proposed <xref ref-type="bibr" rid="pbio.1001293-Balleine1">[42]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Daw3">[43]</xref>, this internal recalibration is achieved through <italic>model-based</italic> reinforcement learning before experiencing actual action outcomes; using predictive mappings embedded in behavioral strategies for anticipating action outcomes, associated selective mappings are altered according to <italic>current</italic> outcome utility through standard reinforcement learning <xref ref-type="bibr" rid="pbio.1001293-Sutton1">[11]</xref>.</p>
      <p>Accordingly, the PROBE model predicts that task set creation involves <italic>model-based</italic> reinforcement learning based on action outcome predictions, while task set execution involves <italic>model-free</italic> reinforcement learning based on actual action outcomes. The hypothesis is consistent with empirical findings: in extinction paradigms suppressing actual action outcomes following training, differential outcome devaluations were found to impact action selection (e.g., <xref ref-type="bibr" rid="pbio.1001293-Balleine1">[42]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Corbit1">[44]</xref>). In the PROBE model, suppressing actual action outcomes consistently triggers task set creation because the ongoing actor task set becomes unreliable. In the context of the experiment, then, task set creation comes to re-instantiate and recalibrate the learned behavioral strategy for acting (see above); its predictive mapping recalibrates the associated selective mapping according to actual outcome utility. Moreover, as adjustments to external contingencies may be faster for predictive than selective mappings (Bayesian updating versus reinforcement learning, respectively), this hypothesis may also account for contrasted devaluation effects occurring after moderate versus extensive training <xref ref-type="bibr" rid="pbio.1001293-Holland1">[45]</xref>. Thus, the PROBE model predicts that model-based reinforcement learning is involved in forming a new behavioral strategy when ongoing behavior and habit formation driven by model-free reinforcement learning become unreliable. Interestingly, the prediction differs from previous accounts assuming that the arbitration between behavioral strategies driven by model-free versus model-based reinforcement learning is based on their relative reliability <xref ref-type="bibr" rid="pbio.1001293-Daw3">[43]</xref>.</p>
      <p>We assumed that task sets represent behavior strategies comprising selective mappings encoding stimulus-response associations according to action utility, predictive mappings encoding expected action outcomes given stimuli, and contextual mappings encoding external cues predicting task set reliability. Neuroimaging studies suggest that these internal mappings are implemented in distinct frontal regions: (1) selective mappings in lateral premotor regions, because these regions are involved in learning and processing stimulus-response associations <xref ref-type="bibr" rid="pbio.1001293-Badre1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Koechlin2">[46]</xref>; (2) predictive mappings in ventromedial prefrontal regions, because these regions are engaged in learning and processing expected and actual action outcomes <xref ref-type="bibr" rid="pbio.1001293-Boorman1">[47]</xref>–<xref ref-type="bibr" rid="pbio.1001293-Koechlin3">[50]</xref>; and (3) contextual mappings in lateral prefrontal regions, because these regions are involved in learning and selecting task sets according to contextual cues <xref ref-type="bibr" rid="pbio.1001293-Badre1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Koechlin2">[46]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Miller1">[51]</xref>. Neuroimaging studies further show that dorsomedial prefrontal regions evaluate the discrepancies between actual and predicted action outcomes <xref ref-type="bibr" rid="pbio.1001293-Samejima1">[17]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Alexander1">[52]</xref> and estimate the volatility of external contingencies <xref ref-type="bibr" rid="pbio.1001293-Behrens1">[14]</xref>. The PROBE model thus suggests that dorsomedial prefrontal regions monitor task set reliability according to predictive mappings implemented in ventromedial prefrontal regions and volatility estimates. Lateral prefrontal regions then revise task set reliability according to contextual cues for choosing the task set driving immediate behavior (i.e., the selective mapping in the premotor cortex that specifies the responses to stimuli) <xref ref-type="bibr" rid="pbio.1001293-Koechlin2">[46]</xref>.</p>
      <p>The present study suggests that the prefrontal cortex monitors at most three or four task sets. The frontal network described above selects the unique task set appearing reliable for driving behavior and adjusts it according to action outcomes. When none appear reliable, this frontal network presumably enters in <italic>controlled</italic> exploration; a new task set is probed but initially appears unreliable, thereby requiring an additional control system to enforce or discard this probe actor. This system needs to monitor at least the second most reliable task set. When both the actor and its best alternative appear unreliable (or no alternative sets are monitored), the system enforces exploration; a new task set is created from long-term memory in the frontal network described above and drives behavior. Exploration then terminates when either this probe actor or its current best alternative becomes reliable. This putative system matches the function attributed to frontopolar regions, usually referred to as cognitive branching <xref ref-type="bibr" rid="pbio.1001293-Koechlin4">[53]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Koechlin5">[54]</xref>: enabling the unexpected execution of a task, while holding on and monitoring an alternative task for possible future execution. Furthermore, consistent with the notion of controlled exploration, frontopolar regions are engaged in exploratory behavior <xref ref-type="bibr" rid="pbio.1001293-Daw2">[28]</xref>, long-term memory cued retrieval <xref ref-type="bibr" rid="pbio.1001293-Fletcher1">[55]</xref>, and in the early phase of learning new behaviors <xref ref-type="bibr" rid="pbio.1001293-Koechlin3">[50]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Sakai2">[56]</xref>. The PROBE model thus predicts that frontopolar regions monitor at least the reliability of the best alternative to the actor, a prediction supported by recent neuroimaging evidence <xref ref-type="bibr" rid="pbio.1001293-Boorman1">[47]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Boorman2">[57]</xref>. Finally, we found that individual variations in adaptive behavior primarily result from confirmation biases in <italic>controlled</italic> exploration. Consistently, the frontopolar function has been associated with individual variations in fluid intelligence <xref ref-type="bibr" rid="pbio.1001293-Glascher1">[58]</xref>, suggesting that fluid intelligence is associated with the ability to probe new strategies.</p>
      <p>According to previous studies, “creativity is the epitome of cognitive flexibility. The ability to break conventional or obvious patterns of thinking, adopt new and/or higher order rules and think conceptually and abstractly is at the heart of any theory of creativity” (<xref ref-type="bibr" rid="pbio.1001293-Dietrich1">[59]</xref>; see also <xref ref-type="bibr" rid="pbio.1001293-Zabelina1">[60]</xref>). From this perspective, the PROBE model that flexibly builds task sets as abstract mental constructs referring to true or hypothetical “states of the world” for exploring and storing new behavioral rules may help us to understand creative processes underlying human adaptive behavior. In particular, the distinction mentioned above between <italic>uncontrolled</italic> and <italic>controlled</italic> exploration is similar to the distinction made in artificial intelligence between exploratory creativity (generating new low-level actions/objects) and transformational creativity (generating new higher level rules) <xref ref-type="bibr" rid="pbio.1001293-Wiggins1">[61]</xref>,<xref ref-type="bibr" rid="pbio.1001293-Boden1">[62]</xref>. Critically, the PROBE model suggests how the human executive function regulates the exploration versus exploitation of behavioral rules and controls creativity in the service of adaptive behavior.</p>
      <p>In summary, the results support a model of frontal lobe function integrating reasoning, learning, and creative abilities in the service of executive control and decision-making. The model suggests how the frontal lobes create and manage an expanding repertoire of flexible behavioral strategies for driving action in uncertain, changing, and open-ended environments.</p>
    </sec>
    <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>PROBE Model</title>
        <p>To model uncertain, variable, and open-ended environments, we assumed that in every trial <italic>t</italic>, there were external contingencies—that is, the possibly stochastic relationships between stimulus <italic>s<sub>t</sub></italic>, action <italic>a<sub>t</sub></italic>, and outcomes <italic>o<sub>t</sub></italic> depend upon a hidden state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e001" xlink:type="simple"/></inline-formula> only. Hidden states are countable, potentially infinite, and vary across trials independently of stimuli and actions. Stimulus <italic>s<sub>t</sub></italic> may be multidimensional and might include cues about current hidden states, which we refer to as contextual cues for clarity. Hidden state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e002" xlink:type="simple"/></inline-formula> is assumed to depend only upon the preceding hidden state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e003" xlink:type="simple"/></inline-formula> (Markov property) and contextual cues <italic>C<sub>t</sub></italic> to depend only upon current hidden state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e004" xlink:type="simple"/></inline-formula>.</p>
        <p>We describe below the PROBE model computations. In <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>, we present the statistical normative approach to the problem of task set creation based on Dirichlet Processes (see also <xref ref-type="supplementary-material" rid="pbio.1001293.s005">Figure S5</xref>) and how the PROBE model approximates this statistical optimal model for the sake of biological plausibility.</p>
        <sec id="s4a1">
          <title>Task sets</title>
          <p>Task sets <italic>TS<sub>i</sub></italic> represent possible instances of external hidden states. Each task set <italic>i</italic> indexes one strategy stored in long-term memory and comprises (1) a <italic>selective</italic> mapping <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e005" xlink:type="simple"/></inline-formula> encoding expected rewarding values <italic>r</italic>[<italic>o</italic>] of outcomes <italic>o</italic> given action <italic>a</italic> and stimulus <italic>s</italic>; (2) a <italic>predictive</italic> mapping <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e006" xlink:type="simple"/></inline-formula> encoding the likelihood of outcome <italic>o</italic> given action <italic>a</italic> and stimulus <italic>s</italic>; and (3) a <italic>contextual</italic> mapping <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e007" xlink:type="simple"/></inline-formula> encoding the likelihood that hidden state <italic>TS*</italic> matches <italic>TS<sub>i</sub></italic> when contextual cues C are observed (<xref ref-type="supplementary-material" rid="pbio.1001293.s001">Figure S1</xref>).</p>
        </sec>
        <sec id="s4a2">
          <title>Reliability</title>
          <p>We assumed that the executive system monitors the reliability of at most <italic>N</italic> task sets. Reliability of task set <italic>TS<sub>i</sub></italic> is the likelihood that in trial <italic>t</italic>, external hidden state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e008" xlink:type="simple"/></inline-formula> matches <italic>TS<sub>i</sub></italic> given observations. In every trial, task set reliability is estimated in two time points: (1) before acting when stimulus <italic>s<sub>t</sub></italic>, possibly including contextual cues <italic>C<sub>t</sub></italic>, is observed, and (2) after action when action outcome <italic>o<sub>t</sub></italic> is further observed. We refer to these two reliability estimates as <italic>ex-ante</italic> reliability <italic>λ<sub>i</sub></italic>(<italic>t</italic>) and <italic>ex-post</italic> reliability <italic>μ<sub>i</sub></italic>(<italic>t</italic>), respectively. Thus, <italic>λ<sub>i</sub></italic>(<italic>t</italic>) and <italic>μ<sub>i</sub></italic>(<italic>t</italic>) write as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e009" xlink:type="simple"/><label>(1)</label></disp-formula>where <italic>past</italic> refers to all other observations, including those from preceding trials. The PROBE model estimates the “absolute” reliability of task sets (i.e., the likelihood that hidden state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e010" xlink:type="simple"/></inline-formula> matches <italic>TS<sub>i</sub></italic> conditionally upon observations but not upon the collection of current task sets). Such estimates require computing the likelihood that hidden state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e011" xlink:type="simple"/></inline-formula> actually matches no task sets <italic>TS<sub>i</sub></italic>. As task set reliability, this likelihood can be estimated before acting and after action. These two estimates are denoted as <italic>λ</italic><sub>0</sub>(<italic>t</italic>) and <italic>μ</italic><sub>0</sub>(<italic>t</italic>), respectively, and write as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e012" xlink:type="simple"/><label>(2)</label></disp-formula>where <italic>N<sub>t</sub></italic> is the current number of task sets (<italic>N<sub>t</sub></italic>≤<italic>N</italic>) and {1,…, <italic>N<sub>t</sub></italic>} denotes the current collection of task sets.</p>
          <p>Note that uniform predictive mapping <italic>γ</italic><sub>0</sub> corresponding to random predictions over action outcomes is actually an estimate of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e013" xlink:type="simple"/></inline-formula>. Indeed, all outcomes observed with the current collection of task sets remain equally probable, when hidden state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e014" xlink:type="simple"/></inline-formula> is unknown. Consequently, mapping <italic>γ</italic><sub>0</sub> is constant and normalized according to the number of observed outcomes: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e015" xlink:type="simple"/></inline-formula>, where <italic>N<sub>outcomes</sub></italic> counts outcomes <italic>o</italic> such that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e016" xlink:type="simple"/></inline-formula> (e.g., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e017" xlink:type="simple"/></inline-formula> with large inverse temperature <italic>ρ</italic>).</p>
          <p>For clarity, we denote <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e018" xlink:type="simple"/></inline-formula>. Consequently, we can write the following using Equations 1 and 2:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e019" xlink:type="simple"/><label>(3)</label></disp-formula>where <italic>τ<sub>ij</sub></italic> are transition probabilities from states <italic>j</italic> to <italic>i</italic>. Using standard Bayesian calculus and assuming that with no observations all task sets are presumed equally reliable (i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e020" xlink:type="simple"/></inline-formula> is independent of <italic>i</italic>), we then obtain from Equation 3 the following updating rule for ex-ante reliability:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e021" xlink:type="simple"/><label>(4)</label></disp-formula>where indexes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e022" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e023" xlink:type="simple"/></inline-formula> is the normalization term. Finally, we obtain the following updating rule for ex-post reliability:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e024" xlink:type="simple"/><label>(5)</label></disp-formula>where indexes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e025" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e026" xlink:type="simple"/></inline-formula> is the normalization term. Finally, transition probabilities <italic>τ<sub>ij</sub></italic> reflect the perceived volatility <italic>τ</italic> of hidden states (external contingencies) across successive trials: typically <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e027" xlink:type="simple"/></inline-formula>, with 0&lt;<italic>τ</italic>&lt;1 and <italic>N<sub>t</sub></italic> the current number of task sets. As previously proposed <xref ref-type="bibr" rid="pbio.1001293-Behrens1">[14]</xref>, volatility <italic>τ</italic> is estimated using a standard hidden Markov model.</p>
        </sec>
        <sec id="s4a3">
          <title>Task set selection and creation</title>
          <p>As described above, the PROBE model estimates the “absolute” reliability of task sets. Consequently, a minimal requirement is that the actor task set is more likely reliable than unreliable (i.e., <italic>λ<sub>actor</sub></italic>(<italic>t</italic>)&gt;1−<italic>λ<sub>actor</sub></italic>(<italic>t</italic>) or equivalently, <italic>λ<sub>actor</sub></italic>(<italic>t</italic>)&gt;0.5). If a task set meets this reliability criterion, it is necessarily unique, the most reliable one, and therefore used as the actor. The criterion is necessarily fulfilled when only two task sets are monitored and <italic>λ</italic><sub>0</sub>(<italic>t</italic>) is close to zero. In the other cases, the criterion is highly restrictive, so that no task sets may meet the criterion. In that case, a new task set is created to serve as an actor with prior reliability <italic>λ<sub>prior</sub></italic>.</p>
          <p>The new task set is created with initial selective/predictive mappings <italic>M<sub>new</sub></italic> forming a mixture of all selective/predictive mappings stored in long-term memory and weighted according to contextual cues <italic>C<sub>t</sub></italic>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e028" xlink:type="simple"/><label>(6)</label></disp-formula>where <italic>U</italic> denotes uniform mappings, <italic>M<sub>new</sub></italic> and <italic>M<sub>k</sub></italic> are selective/predictive mappings, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e029" xlink:type="simple"/></inline-formula> is the normalization factor. Index <italic>k</italic> runs over all behavioral strategies stored in long-term memory and <italic>η</italic> scales <italic>recollection entropy</italic> (0&lt;<italic>η</italic>&lt;1), as uniform mappings <italic>U</italic> reflect recollection noise. Note that internal mappings with distinct index <italic>k</italic> may encode the same external contingencies; mixture (Equation 6) thus favors external contingencies that frequently re-occur. Given the approximations inherent to the PROBE model, more precisely, mixture (Equation 6) derives from the statistical optimal model based on Dirichlet processes (see <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>). The mixture forms a new probe actor that is adjusted in subsequent trials through learning.</p>
          <p>Prior reliability <italic>λ<sub>prior</sub></italic> of the probe actor is chosen as minimizing prior information over task set reliability because no information is available to estimate it <xref ref-type="bibr" rid="pbio.1001293-Jaynes1">[32]</xref>. Thus, prior reliability <italic>λ<sub>prior</sub></italic> maximizes entropy <italic>H<sub>t</sub></italic> over reliability; that is:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e030" xlink:type="simple"/><label>(7)</label></disp-formula>Maximal entropy <italic>H<sub>t</sub></italic> is then obtained for:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e031" xlink:type="simple"/><label>(8)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e032" xlink:type="simple"/></inline-formula> is the reliability entropy over task sets. We can verify that prior reliability <italic>λ<sub>prior</sub></italic> ranges between 1/(<italic>N<sub>t</sub></italic>+1) and 1/3, so that this new actor initially fails to meet the reliability criterion (i.e., <italic>λ<sub>prior</sub></italic>≤0.5).</p>
          <p>Consequently, the new actor is <italic>probed</italic> because it initially fails to meet the reliability criterion. When another task set subsequently meets the criterion while the probe actor <italic>still</italic> fails, the latter will be entirely <italic>discarded</italic>. When, conversely, learning allows the probe actor to meet the criterion while the others <italic>still</italic> fail, the probe phase terminates and the collection of task sets is updated as described in the main text. Note that this model favors binary compared to multiple alternative choices, because the reliability criterion is automatically fulfilled only when two task sets are monitored (and <italic>λ</italic><sub>0</sub>(<italic>t</italic>)≈0; that is, the likelihood that none matches external contingencies is close to zero).</p>
          <p>Overall, the PROBE model is an online, forward approximation of Dirichlet process mixtures <xref ref-type="bibr" rid="pbio.1001293-DoshiVelez1">[19]</xref> based on hypothesis testing on task set creation (that is, on the critical no-parametric component of Dirichlet processes; see <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>). Hidden states <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e033" xlink:type="simple"/></inline-formula> are provisionally assigned to new task sets as long as no task sets meet the reliability criterion. Conversely, hidden states are definitively assigned to task sets only when task sets meet the reliability criterion. Thus, provisional versus definitive assignments occur precisely when, in optimal statistical learning, offline backward inference is likely versus unlikely to alter previous assignments, respectively.</p>
        </sec>
        <sec id="s4a4">
          <title>Action selection and learning</title>
          <p>Ex-ante reliabilities <italic>λ<sub>i</sub></italic>(<italic>t</italic>) serve to choose the actor. The actor selective mapping then determines the behavioral policy <italic>P</italic>(<italic>a<sub>t</sub></italic>|<italic>s<sub>t</sub></italic>) (i.e., the probability to select action <italic>a<sub>t</sub></italic> in response to stimulus <italic>s<sub>t</sub></italic> based on an <italic>ε</italic>-softmax with inverse temperature <italic>β</italic>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e034" xlink:type="simple"/><label>(9)</label></disp-formula>where <italic>n<sub>a</sub></italic> is the number of available actions and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e035" xlink:type="simple"/></inline-formula> are normalized to 1 over actions (not shown in Equation 9 for clarity). After observing action outcome <italic>o<sub>t</sub></italic>, the actor selective mapping is updated based on outcome values <italic>r</italic>[<italic>o</italic>] according to standard reinforcement learning mechanisms <xref ref-type="bibr" rid="pbio.1001293-Sutton1">[11]</xref> (e.g., the simple delta rule <xref ref-type="bibr" rid="pbio.1001293-Rescorla1">[31]</xref>): <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e036" xlink:type="simple"/></inline-formula>, where <italic>α<sub>s</sub></italic> is the learning rate. The actor predictive mapping simply regularizes action outcome likelihood given stimulus <xref ref-type="bibr" rid="pbio.1001293-Yu1">[13]</xref>. Contextual mappings <italic>F</italic>(<italic>i</italic>|<italic>C<sub>t</sub></italic>) of every task set then adjust to ex-post estimates of reliability according to a standard stochastic gradient descent: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e037" xlink:type="simple"/></inline-formula>, where <italic>α<sub>c</sub></italic> is the learning rate.</p>
        </sec>
        <sec id="s4a5">
          <title>Context-sensitivity bias</title>
          <p>Whenever, besides regular stimuli, additional external cues change between two successive trials, participants might infer that external contingencies (i.e., hidden external states) more likely shift between these trials than others. To account for this possible bias, we considered that in every model, perceived volatility <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e038" xlink:type="simple"/></inline-formula> of external contingencies between such trials might be enhanced: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1001293.e039" xlink:type="simple"/></inline-formula>, where free parameter δ≥0 is named <italic>context-sensitivity</italic> bias.</p>
        </sec>
        <sec id="s4a6">
          <title>Confirmation bias</title>
          <p>Participants might be reluctant to unselect a newly created actor set for returning to another task set. We then considered that prior reliability <italic>λ<sub>prior</sub></italic> of such actors might be biased:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.e040" xlink:type="simple"/><label>(10)</label></disp-formula>where free parameter <italic>θ</italic> is named <italic>confirmation</italic> bias (0.5 is used in Equation 10 for consistency with the creation threshold).</p>
        </sec>
        <sec id="s4a7">
          <title>Alternative models</title>
          <p>See <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>.</p>
        </sec>
      </sec>
      <sec id="s4b">
        <title>Experimental Protocol</title>
        <sec id="s4b1">
          <title>Participants</title>
          <p>Participants were healthy, right-handed volunteers (age range, 18–35 years old) with no auditory and vision deficits and no general medical, neurological, psychiatric, or addictive history as assessed by medical examinations. Participants provided written informed consent approved by the French National Ethics Committee. Participants were paid for their participation.</p>
        </sec>
        <sec id="s4b2">
          <title>Experimental set-up and instructions</title>
          <p>Stimuli were visually presented arabic numbers. Participants responded to each stimulus by pressing one of four keys (<xref ref-type="supplementary-material" rid="pbio.1001293.s002">Figure S2</xref>). The keys were assigned to the index and middle finger of each hand. When key presses occurred no later than 1,500 ms after stimulus onset, stimuli disappeared 100 ms after key presses and participants received audiovisual feedbacks (duration 300 ms). Feedbacks were positive or negative. A positive feedback consisted of an ascending sound and the apparition of the associated stimulus in a box representing the pressed key at the bottom of the screen. Negative feedback consisted of a descending sound only. Otherwise, stimuli were removed and no feedback was delivered. Stimulus onset asynchrony was 2,000 ms. Associations between actual stimuli, response fingers, and feedbacks were orthorgonalized and counterbalanced across participants.</p>
          <p>Participants were instructed that feedback could be uncertain and variable and that payoffs increased with the total number of received positive feedback. No additional instructions were provided to participants.</p>
        </sec>
        <sec id="s4b3">
          <title>Experiment 1</title>
          <p>Experiment 1 included 22 participants (13 females). Unbeknownst to the participants, we made the following manipulations: In every trial, a “correct” response was associated with each stimulus (three possible stimuli) and led to positive feedback with a probability of 90%. All other responses led to negative feedback with a probability of 90%. Distinct stimuli were associated with distinct correct responses. Correct responses to stimuli remained unchanged over a series of successive trials, ranging from 36 to 54, named <italic>episodes</italic>. All correct responses to stimuli changed between two successive episodes.</p>
          <p>The experiment included two behavioral sessions administered on 2 separate days. Each session included 25 episodes. Stimuli were pseudo-randomly chosen from the set ({1,3,5} for one session or {2,4,6} for the other session). In the <italic>open</italic> session, the mappings between stimuli and best responses never repeated across 24 episodes. In the last episode, the mapping from the first episode was used again, because from three stimuli and four possible responses only 24 distinct mappings can be formed (with the constraint that two distinct stimuli are associated with distinct responses). Although the <italic>mappings</italic> were distinct, there were considerable overlaps across the mappings. Every stimulus-response association belongs to six distinct mappings, while every pair of stimulus-response associations belongs to four distinct mappings. In order to properly define episode onsets, mappings were further organized across episodes so that there were no overlaps between two successive mappings. In the <italic>recurrent</italic> session, only three distinct mappings reoccurred over the episodes in a pseudo-randomized order (8/8/9 repetitions). The three mappings did not overlap (i.e., best responses to stimuli systematically differed across mappings). Transition probabilities were equalized across mappings.</p>
          <p>Finally, episode and session order were counterbalanced across participants. Episode durations were pseudo-randomized and ranged from 36 to 54 trials, so that on average volatility of external contingencies was identical in the open and recurrent sessions (3%).</p>
        </sec>
        <sec id="s4b4">
          <title>Experiment 2</title>
          <p>Experiment 2 included 49 additional participants (25 females) and comprised two behavioral sessions administered on 2 consecutive days. Again, participants were not informed about the following manipulations. Stimuli were pseudo-randomly chosen from the set {1,2,3}. The first session was identical to the recurrent session described above with only one exception: stimulus colors predicted the mappings between stimuli and best responses used in each episode with 100% reliability. Two mappings were associated with unique color cues. The third one was associated with two possible color cues for assessing the effects of cue changes without episode changes (an event occurring at most once in such episodes).</p>
          <p>The second session included 13 rehearsal episodes corresponding to the cued recurrent episodes used in the first session followed by 12 intermixed test episodes: four <italic>control</italic> episodes corresponding to the recurrent mapping associated with its two color cues, six <italic>transfer</italic> episodes corresponding to the two other recurrent mappings but now associated with new color cues, and two <italic>open</italic> episodes corresponding to a new mapping associated with new cues. All these mappings were fully incongruent; there were only four possible instances of such mappings, which were used in these 12 episodes. Order of episodes was counterbalanced across participants.</p>
        </sec>
        <sec id="s4b5">
          <title>Data analyses, model fitting, and post-tests</title>
          <p>See <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pbio.1001293.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.s001" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <p>Architecture of task sets. The monitoring buffer comprises a limited number of task sets, each indexing a behavioral strategy stored in long-term memory and comprising a selective, predictive, and contextual mapping (M). The reliability of each task set is monitored online at two time points: right before acting (ex-ante reliability <italic>λ<sub>i</sub></italic>) and right after perceiving action outcomes (ex-post reliability <italic>μ<sub>i</sub></italic>); ex-ante reliability <italic>λ<sub>i</sub></italic> is inferred from ex-post reliability in the preceding trial according to contextual cues C (given contextual models) and the perceived volatility of external contingencies (not shown); ex-post reliability <italic>μ<sub>i</sub></italic> is inferred from ex-ante reliability preceding action according to action outcomes r (given predictive models). Ex-ante reliability serves to choose the actor driving immediate behavior. The actor selective mapping then determines the responses to stimuli. Actor selective and predictive mappings learn according to action outcomes. Contextual mappings of task sets adjust to ex-post reliability and consequently learn contextual cues C predicting task set reliability. Red indicates computations occurring within the actor set only. Arrows indicate information flows occurring within task sets. Broken arrows symbolize learning processes within internal mappings (M). Blue lines represent the associations remaining between internal mappings forming strategies stored in long-term memory and previously indexed by a task set. See <xref ref-type="sec" rid="s4">Materials and Methods</xref> for notations.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001293.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.s002" xlink:type="simple">
        <label>Figure S2</label>
        <caption>
          <p>Trial structure in Experiments 1 and 2. (A) First experiment. Visual stimuli were pseudo-randomly drawn from a set of three arabic numbers (e.g., (1, 3, 5)). Participants had to respond by pressing one among four possible response keys. 100 ms after participants' responses, stimuli were removed and positive or negative feedback was presented during 300 ms; positive feedback consisted of an ascending sound and stimuli appeared in a box at the bottom of the screen corresponding to the pressed key. Negative feedback consisted of descending sounds only. Stimulus onset asynchrony was 2,000 ms. (B) Second experiment. Same as Experiment 1, except that stimuli appeared in different colors. Unbeknownst to participants, stimuli colors were contextual cues associated with the different possible mappings between stimuli and best rewarding responses occurring across the experiment. Color cues changed infrequently. The figure shows the only events and external signals participants could observe in the experiments. In particular, participants had to infer any other information regarding external contingencies, including the associations between stimuli, color cues, response keys and feedback, their occurrence structure, uncertainty, and variations in the experiment.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001293.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.s003" xlink:type="simple">
        <label>Figure S3</label>
        <caption>
          <p>Irrelevant contextual changes within episodes. Left, proportions of correct responses produced by context-, outcome-exploiting, and exploring participants on trials preceding and following changes in contextual cues within control episodes (Experiment 2). Contextual cues changed in Trial T, whereas the mapping between stimuli and best responses remained unchanged. Error bars are S.E.M. across participants. Right, proportions of correct responses predicted by the PROBE model for each group with parameters fitted on every participant. In every trial, predicted proportions are computed according to actual participants' responses in previous trials. Error bars are S.E.M. across participants. The model predicts that, in every group, correct responses drop off in Trial T (decreases from Trial T-1 to T, <italic>F</italic> = 6.7, <italic>p</italic>&lt;0.001; interaction with groups, <italic>F</italic>&lt;1). In every group, consistently, participants' correct responses dropped off in Trial T (decreases from Trial T-1 to T, main effect, <italic>F</italic>&gt;4.9, <italic>p</italic>&lt;0.001; interaction with groups, <italic>F</italic>&lt;1). This result shows that in every group, participants were responsive to contextual cues as predicted by the PROBE model.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001293.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.s004" xlink:type="simple">
        <label>Figure S4</label>
        <caption>
          <p>Human performances and PROBE model fit with four recurrent action sets. Shaded lines, performances from 30 healthy participants (16 females, aged 18–30 years old) in recurrent episodes plotted against the number of trials following episode onset. Shaded areas are S.E.M. across participants (detailed legend in <xref ref-type="fig" rid="pbio-1001293-g001">Figure 1</xref>). The experimental session consisted of 24 recurrent episodes identical to that from Experiment 1 (see text), except that four mappings between stimuli and correct responses re-occurred pseudo-randomly across episodes. The four mappings were fully incongruent. Note that participants performed as in open episodes in Experiment 1 (see <xref ref-type="fig" rid="pbio-1001293-g001">Figure 1</xref>) with no peaks of mutual dependence of successive decisions in the first trials of episodes. Lines ± error bars (mean ± S.E.M.), performances predicted by the fitted PROBE model (details in <xref ref-type="fig" rid="pbio-1001293-g002">Figure 2</xref>): correct and exploratory response rates were computed in every trial according to the actual history of participants' responses. Mutual dependence of successive correct decisions predicted by the model was computed as the mutual information between two successive correct decisions produced by the model independently of actual participants' responses (one simulation for each participant). Best-fitting model parameters (mean(S.E.M.)): inverse temperature β = 35(2.3); noise ε = 0.04(.003); bound <italic>N</italic> = 3.4(.3); learning rate α = 0.34(.04); recollection entropy η = 0.75(.03); and confirmation bias θ = 0.34(.06). Note that the parameters are close to those from Experiment 1 (see <xref ref-type="supplementary-material" rid="pbio.1001293.s006">Table S1</xref>). See <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref> (section “Comments on Model Fits”) for additional comments regarding model and participants' behavior.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001293.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.s005" xlink:type="simple">
        <label>Figure S5</label>
        <caption>
          <p>Performance of the statistical optimal model. Graphs show the best achievable performance in terms of information processing in Experiment 1. The statistical optimal model is described in <xref ref-type="supplementary-material" rid="pbio.1001293.s008">Text S1</xref>, 1-Normative approach to the PROBE model, optimal statistical model. Red, recurrent episodes; green, open episodes. The best achievable performance is obtained with inferences involving at least 25 trials backwards and concentration parameter <italic>η</italic> = 10. Lower concentration parameters improve model performance in recurrent episodes (increased correct responses and decreased exploratory responses), but decrease model performance in open episodes. Conversely, larger concentration parameters decrease model performance in recurrent episodes but improve model performance in open episodes. Inset, human data from <xref ref-type="fig" rid="pbio-1001293-g001">Figure 1</xref> (see <xref ref-type="fig" rid="pbio-1001293-g001">Figure 1</xref> for detailed legend). In both conditions, as expected, the statistical optimal model outperforms human participants dramatically.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001293.s006" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.s006" xlink:type="simple">
        <label>Table S1</label>
        <caption>
          <p>Best fitting model parameters used in <xref ref-type="fig" rid="pbio-1001293-g003">Figures 3</xref> and <xref ref-type="fig" rid="pbio-1001293-g005">5</xref>. Mean(S.E.M.) across participants. See <xref ref-type="sec" rid="s4">Materials and Methods</xref> for detailed parameter description.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001293.s007" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.s007" xlink:type="simple">
        <label>Table S2</label>
        <caption>
          <p>Best fitting parameters in the PROBE model across participants' group used in <xref ref-type="fig" rid="pbio-1001293-g006">Figures 6</xref> and <xref ref-type="fig" rid="pbio-1001293-g007">7</xref>. Mean(S.E.M.) across participants. See <xref ref-type="sec" rid="s4">Materials and Methods</xref> for detailed parameter description. Boxes indicate significant differences across groups (see text).</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio.1001293.s008" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pbio.1001293.s008" xlink:type="simple">
        <label>Text S1</label>
        <caption>
          <p>Supplementary methods.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Beth Pavlicek and Marion Rouault for their help in collecting behavioral data, Jan Drugowitsch for his help in modeling, and Chris Summerfield for his comments.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pbio.1001293-Simon1">
        <label>1</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Simon</surname><given-names>H</given-names></name></person-group>             <year>1997</year>             <source>Models of bounded rationality: empirically grounded economic reason</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>The MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Kahneman1">
        <label>2</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kahneman</surname><given-names>D</given-names></name><name name-style="western"><surname>Tversky</surname><given-names>A</given-names></name></person-group>             <year>2000</year>             <source>Choices, values and frames</source>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Cohen1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cohen</surname><given-names>J. D</given-names></name><name name-style="western"><surname>McClure</surname><given-names>S. M</given-names></name><name name-style="western"><surname>Yu</surname><given-names>A. J</given-names></name></person-group>             <year>2007</year>             <article-title>Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>362</volume>             <fpage>933</fpage>             <lpage>942</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Glimcher1">
        <label>4</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Glimcher</surname><given-names>P. W</given-names></name><name name-style="western"><surname>Camerer</surname><given-names>C. F</given-names></name><name name-style="western"><surname>Fehr</surname><given-names>E</given-names></name><name name-style="western"><surname>Poldrack</surname><given-names>R. A</given-names></name></person-group>             <year>2009</year>             <source>Neuroeconomics: decision-making and the brain</source>             <publisher-loc>London</publisher-loc>             <publisher-name>Academic Press, Elsevier</publisher-name>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Harlow1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Harlow</surname><given-names>H. F</given-names></name></person-group>             <year>1949</year>             <article-title>The formation of learning sets.</article-title>             <source>Psychological Review</source>             <volume>56</volume>             <fpage>51</fpage>             <lpage>65</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Rogers1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rogers</surname><given-names>R. D</given-names></name><name name-style="western"><surname>Monsell</surname><given-names>S</given-names></name></person-group>             <year>1995</year>             <article-title>Costs of predictable switch between simple cognitive tasks.</article-title>             <source>J Exp Psychol Gen</source>             <volume>124</volume>             <fpage>207</fpage>             <lpage>231</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Koechlin1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koechlin</surname><given-names>E</given-names></name><name name-style="western"><surname>Summerfield</surname><given-names>C</given-names></name></person-group>             <year>2007</year>             <article-title>An information theoretical approach to prefrontal executive function.</article-title>             <source>Trends Cogn Sci</source>             <volume>11</volume>             <fpage>229</fpage>             <lpage>235</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Botvinick1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Botvinick</surname><given-names>M. M</given-names></name></person-group>             <year>2008</year>             <article-title>Hierarchical models of behavior and prefrontal function.</article-title>             <source>Trends Cogn Sci</source>             <volume>12</volume>             <fpage>201</fpage>             <lpage>208</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Sakai1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sakai</surname><given-names>K</given-names></name></person-group>             <year>2008</year>             <article-title>Task set and prefrontal cortex.</article-title>             <source>Annu Rev Neurosci</source>             <volume>31</volume>             <fpage>219</fpage>             <lpage>245</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Badre1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Badre</surname><given-names>D</given-names></name><name name-style="western"><surname>Kayser</surname><given-names>A. S</given-names></name><name name-style="western"><surname>D'Esposito</surname><given-names>M</given-names></name></person-group>             <year>2010</year>             <article-title>Frontal cortex and the discovery of abstract action rules.</article-title>             <source>Neuron</source>             <volume>66</volume>             <fpage>315</fpage>             <lpage>326</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Sutton1">
        <label>11</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>R. S</given-names></name><name name-style="western"><surname>Barto</surname><given-names>A. G</given-names></name></person-group>             <year>1998</year>             <source>Reinforcement learning</source>             <publisher-loc>Cambridge, MA</publisher-loc>             <publisher-name>The MIT Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pbio.1001293-ODoherty1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Doherty</surname><given-names>J</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Schultz</surname><given-names>J</given-names></name><name name-style="western"><surname>Deichmann</surname><given-names>R</given-names></name><name name-style="western"><surname>Friston</surname><given-names>K</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning.</article-title>             <source>Science</source>             <volume>304</volume>             <fpage>452</fpage>             <lpage>454</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Yu1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>A</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>2005</year>             <article-title>Uncertainty, neuromodulation, and attention.</article-title>             <source>Neuron</source>             <volume>46</volume>             <fpage>681</fpage>             <lpage>692</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Behrens1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Behrens</surname><given-names>T. E</given-names></name><name name-style="western"><surname>Woolrich</surname><given-names>M. W</given-names></name><name name-style="western"><surname>Walton</surname><given-names>M. E</given-names></name><name name-style="western"><surname>Rushworth</surname><given-names>M. F</given-names></name></person-group>             <year>2007</year>             <article-title>Learning the value of information in an uncertain world.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>1214</fpage>             <lpage>1221</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Doya1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name></person-group>             <year>2002</year>             <article-title>Metalearning and neuromodulation.</article-title>             <source>Neural Netw</source>             <volume>15</volume>             <fpage>495</fpage>             <lpage>506</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Doya2">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name><name name-style="western"><surname>Samejima</surname><given-names>K</given-names></name><name name-style="western"><surname>Katagiri</surname><given-names>K</given-names></name><name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name></person-group>             <year>2002</year>             <article-title>Multiple model-based reinforcement learning.</article-title>             <source>Neural Comput</source>             <volume>14</volume>             <fpage>1347</fpage>             <lpage>1369</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Samejima1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Samejima</surname><given-names>K</given-names></name><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name></person-group>             <year>2007</year>             <article-title>Multiple representations of belief states and action values in corticobasal ganglia loops.</article-title>             <source>Ann N Y Acad Sci</source>             <volume>1104</volume>             <fpage>213</fpage>             <lpage>228</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Gershman1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gershman</surname><given-names>S. J</given-names></name><name name-style="western"><surname>Blei</surname><given-names>D. M</given-names></name><name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name></person-group>             <year>2010</year>             <article-title>Context learning, and extinction.</article-title>             <source>Psychol Rev</source>             <volume>117</volume>             <fpage>1997</fpage>             <lpage>1209</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-DoshiVelez1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Doshi-Velez</surname><given-names>F</given-names></name></person-group>             <year>2009</year>             <article-title>The infinite partially observable markov decision process.</article-title>             <source>Adv Neural Inf Process Syst</source>             <volume>21</volume>             <fpage>477</fpage>             <lpage>485</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Teh1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Teh</surname><given-names>Y. W</given-names></name><name name-style="western"><surname>Jordan</surname><given-names>M. I</given-names></name><name name-style="western"><surname>Beal</surname><given-names>M. J</given-names></name><name name-style="western"><surname>Blei</surname><given-names>D. M</given-names></name></person-group>             <year>2006</year>             <article-title>Hierarchical dirichlet processes.</article-title>             <source>J Am Stat Assoc</source>             <volume>101</volume>             <fpage>1566</fpage>             <lpage>1581</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Daw1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daw</surname><given-names>N. D</given-names></name><name name-style="western"><surname>Courville</surname><given-names>A</given-names></name></person-group>             <year>2007</year>             <article-title>The pigeon as particle filter.</article-title>             <source>Adv Neural Inf Process Syst</source>             <volume>20</volume>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Cowan1">
        <label>22</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cowan</surname><given-names>N</given-names></name></person-group>             <year>2005</year>             <article-title>Working-memory capacity limits in a theoretical context.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Izawa</surname><given-names>C</given-names></name><name name-style="western"><surname>Ohta</surname><given-names>N</given-names></name></person-group>             <source>Human learning and memory: advances in theory and applications</source>             <publisher-name>Erlbaum</publisher-name>             <fpage>155</fpage>             <lpage>175</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Risse1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Risse</surname><given-names>S</given-names></name><name name-style="western"><surname>Oberauer</surname><given-names>K</given-names></name></person-group>             <year>2010</year>             <article-title>Selection of objects and tasks in working memory.</article-title>             <source>Quarterly J Exp Psych</source>             <volume>63</volume>             <fpage>784</fpage>             <lpage>804</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Oberauer1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Oberauer</surname><given-names>K</given-names></name></person-group>             <year>2010</year>             <article-title>Declarative and procedural working memory: common principles, common capacity limits?</article-title>             <source>Psychologica Belgica</source>             <volume>50</volume>             <fpage>277</fpage>             <lpage>308</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Burgess1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Burgess</surname><given-names>N</given-names></name><name name-style="western"><surname>Hitch</surname><given-names>G</given-names></name></person-group>             <year>2005</year>             <article-title>Computational models of working memory: putting long-term memory into context.</article-title>             <source>Trends Cogn Sci</source>             <volume>9</volume>             <fpage>535</fpage>             <lpage>541</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Milner1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Milner</surname><given-names>B</given-names></name></person-group>             <year>1963</year>             <article-title>Effects of brain lesions on card sorting.</article-title>             <source>Arch Neurol</source>             <volume>9</volume>             <fpage>90</fpage>             <lpage>100</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Konishi1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Konishi</surname><given-names>S</given-names></name><name name-style="western"><surname>Nakajima</surname><given-names>K</given-names></name><name name-style="western"><surname>Uchida</surname><given-names>I</given-names></name><name name-style="western"><surname>Kameyama</surname><given-names>M</given-names></name><name name-style="western"><surname>Nakahara</surname><given-names>K</given-names></name><etal/></person-group>             <year>1998</year>             <article-title>Transient activation of inferior prefrontal cortex during cognitive set shifting.</article-title>             <source>Nat Neurosci</source>             <volume>1</volume>             <fpage>80</fpage>             <lpage>84</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Daw2">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daw</surname><given-names>N. D</given-names></name><name name-style="western"><surname>O'Doherty</surname><given-names>J. P</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name><name name-style="western"><surname>Dolan</surname><given-names>R. J</given-names></name></person-group>             <year>2006</year>             <article-title>Cortical substrates for exploratory decisions in humans.</article-title>             <source>Nature</source>             <volume>441</volume>             <fpage>876</fpage>             <lpage>879</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Dreher1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dreher</surname><given-names>J-C</given-names></name><name name-style="western"><surname>Berman</surname><given-names>K. F</given-names></name></person-group>             <year>2002</year>             <article-title>Fractionating the neural substrate of cognitive control processes.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>99</volume>             <fpage>14595</fpage>             <lpage>14600</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Hyafil1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hyafil</surname><given-names>A</given-names></name><name name-style="western"><surname>Summerfield</surname><given-names>C</given-names></name><name name-style="western"><surname>Koechlin</surname><given-names>E</given-names></name></person-group>             <year>2009</year>             <article-title>Two mechanisms for task-switching in the prefrontal cortex.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>5135</fpage>             <lpage>5142</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Rescorla1">
        <label>31</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rescorla</surname><given-names>R. A</given-names></name><name name-style="western"><surname>Wagner</surname><given-names>A R</given-names></name></person-group>             <year>1972</year>             <article-title>A theory of pavlovian conditioning: variations in the effectiveness of reinforcement and nonreinforcement.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Black</surname><given-names>A. H</given-names></name><name name-style="western"><surname>Prokasy</surname><given-names>W. F</given-names></name></person-group>             <source>Classical conditioning II</source>             <publisher-name>Appleton-Century-Crofts</publisher-name>             <fpage>64</fpage>             <lpage>99</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Jaynes1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jaynes</surname><given-names>E. T</given-names></name></person-group>             <year>1957</year>             <article-title>Information theory and statistical mechanics.</article-title>             <source>Physical Review Series II</source>             <volume>106</volume>             <fpage>620</fpage>             <lpage>630</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Cowan2">
        <label>33</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cowan</surname><given-names>N</given-names></name></person-group>             <year>2008</year>             <article-title>What are the differences between long-term, short-term, and working memory.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Sossin</surname><given-names>W. S</given-names></name><name name-style="western"><surname>Lacaille</surname><given-names>J. C</given-names></name><name name-style="western"><surname>Castelluci</surname><given-names>V. F</given-names></name><name name-style="western"><surname>Belleville</surname><given-names>S</given-names></name></person-group>             <source>Progress in brain research</source>             <publisher-name>Elsevier</publisher-name>             <fpage>323</fpage>             <lpage>338</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Ricker1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ricker</surname><given-names>T. J</given-names></name><name name-style="western"><surname>Cowan</surname><given-names>N</given-names></name><name name-style="western"><surname>Morey</surname><given-names>C. C</given-names></name></person-group>             <year>2010</year>             <article-title>Working memory.</article-title>             <source>Wiley Interdisciplinary Review: Cognitive Science</source>             <volume>1</volume>             <fpage>573</fpage>             <lpage>585</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Nassar1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nassar</surname><given-names>M. R</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>R. C</given-names></name><name name-style="western"><surname>Heasly</surname><given-names>B</given-names></name><name name-style="western"><surname>Gold</surname><given-names>J. I</given-names></name></person-group>             <year>2010</year>             <article-title>An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>12366</fpage>             <lpage>12378</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Mathys1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mathys</surname><given-names>C</given-names></name><name name-style="western"><surname>Daunizeau</surname><given-names>J</given-names></name><name name-style="western"><surname>Friston</surname><given-names>K. J</given-names></name><name name-style="western"><surname>Stephan</surname><given-names>K. E</given-names></name></person-group>             <year>2011</year>             <article-title>A Bayesian foundation for individual learning under uncertainty.</article-title>             <source>Front Hum Neurosci</source>             <volume>5</volume>             <fpage>39</fpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Braver1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Braver</surname><given-names>T. S</given-names></name><name name-style="western"><surname>Cole</surname><given-names>M. W</given-names></name><name name-style="western"><surname>Yarkoni</surname><given-names>T</given-names></name></person-group>             <year>2010</year>             <article-title>Vive les differences! Individual variation in neural mechanisms of executive control.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>20</volume>             <fpage>242</fpage>             <lpage>250</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Mercado1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mercado</surname><given-names>E</given-names></name></person-group>             <year>2008</year>             <article-title>Neural and cognitive plasticity: from maps to minds.</article-title>             <source>Psychological Bulletin</source>             <volume>134</volume>             <fpage>109</fpage>             <lpage>137</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Gallistel1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gallistel</surname><given-names>C. R</given-names></name><name name-style="western"><surname>Fairhurst</surname><given-names>S</given-names></name><name name-style="western"><surname>Balsam</surname><given-names>P</given-names></name></person-group>             <year>2004</year>             <article-title>The learning curve: implications of a quantitative analysis.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>101</volume>             <fpage>13124</fpage>             <lpage>13131</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Charron1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Charron</surname><given-names>S</given-names></name><name name-style="western"><surname>Koechlin</surname><given-names>E</given-names></name></person-group>             <year>2010</year>             <article-title>Divided representation of concurrent goals in the human frontal lobes.</article-title>             <source>Science</source>             <volume>328</volume>             <fpage>360</fpage>             <lpage>363</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Frank1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Frank</surname><given-names>M. J</given-names></name><name name-style="western"><surname>Doll</surname><given-names>B. B</given-names></name><name name-style="western"><surname>Oas-Terpstra</surname><given-names>J</given-names></name><name name-style="western"><surname>Moreno</surname><given-names>F</given-names></name></person-group>             <year>2009</year>             <article-title>Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation.</article-title>             <source>Nat Neurosci</source>             <volume>12</volume>             <fpage>1062</fpage>             <lpage>1068</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Balleine1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Balleine</surname><given-names>B. W</given-names></name><name name-style="western"><surname>Dickinson</surname><given-names>A</given-names></name></person-group>             <year>1998</year>             <article-title>Goal-directed instrumental action: contingency and incentive learning and their cortical substrates.</article-title>             <source>Neuropharmacology</source>             <volume>37</volume>             <fpage>407</fpage>             <lpage>419</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Daw3">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Daw</surname><given-names>N. D</given-names></name><name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name></person-group>             <year>2005</year>             <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control.</article-title>             <source>Nat Neurosci</source>             <volume>8</volume>             <fpage>1704</fpage>             <lpage>1711</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Corbit1">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Corbit</surname><given-names>L. H</given-names></name><name name-style="western"><surname>Balleine</surname><given-names>B. W</given-names></name></person-group>             <year>2003</year>             <article-title>The role of prelimbic cortex in instrumental conditioning.</article-title>             <source>Behav Brain Res</source>             <volume>146</volume>             <fpage>145</fpage>             <lpage>157</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Holland1">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Holland</surname><given-names>P. C</given-names></name></person-group>             <year>2004</year>             <article-title>Relations between Pavlovian-instrumental transfer and reinforcer devaluation.</article-title>             <source>J Exp Psychol Anim Behav Process</source>             <volume>30</volume>             <fpage>104</fpage>             <lpage>117</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Koechlin2">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koechlin</surname><given-names>E</given-names></name><name name-style="western"><surname>Ody</surname><given-names>C</given-names></name><name name-style="western"><surname>Kouneiher</surname><given-names>F</given-names></name></person-group>             <year>2003</year>             <article-title>The architecture of cognitive control in the human prefrontal cortex.</article-title>             <source>Science</source>             <volume>302</volume>             <fpage>1181</fpage>             <lpage>1185</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Boorman1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Boorman</surname><given-names>E. D</given-names></name><name name-style="western"><surname>Behrens</surname><given-names>T. E</given-names></name><name name-style="western"><surname>Woolrich</surname><given-names>M. W</given-names></name><name name-style="western"><surname>Rushworth</surname><given-names>M. F</given-names></name></person-group>             <year>2009</year>             <article-title>How green is the grass on the other side? Frontopolar cortex and the evidence in favor of alternative courses of action.</article-title>             <source>Neuron</source>             <volume>62</volume>             <fpage>733</fpage>             <lpage>743</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Rushworth1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rushworth</surname><given-names>M. F. S</given-names></name><name name-style="western"><surname>Behrens</surname><given-names>T. E. J</given-names></name></person-group>             <year>2008</year>             <article-title>Choice, uncertainty and value in prefrontal and cingulate cortex.</article-title>             <source>Nat Neurosci</source>             <volume>11</volume>             <fpage>389</fpage>             <lpage>397</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-ODoherty2">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>O'Doherty</surname><given-names>J. P</given-names></name></person-group>             <year>2007</year>             <article-title>Lights, camembert, action! The role of human orbitofrontal cortex in encoding stimuli, rewards, and choices.</article-title>             <source>Ann N Y Acad Sci</source>             <volume>1121</volume>             <fpage>254</fpage>             <lpage>272</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Koechlin3">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koechlin</surname><given-names>E</given-names></name><name name-style="western"><surname>Danek</surname><given-names>A</given-names></name><name name-style="western"><surname>Burnod</surname><given-names>Y</given-names></name><name name-style="western"><surname>Grafman</surname><given-names>J</given-names></name></person-group>             <year>2002</year>             <article-title>Medial prefrontal and subcortical mechanisms underlying the acquisition of motor and cognitive action sequences in humans.</article-title>             <source>Neuron</source>             <volume>35</volume>             <fpage>371</fpage>             <lpage>381</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Miller1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Miller</surname><given-names>E. K</given-names></name><name name-style="western"><surname>Cohen</surname><given-names>J. D</given-names></name></person-group>             <year>2001</year>             <article-title>An integrative theory of prefrontal cortex function.</article-title>             <source>Annu Rev Neurosci</source>             <volume>24</volume>             <fpage>167</fpage>             <lpage>202</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Alexander1">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Alexander</surname><given-names>W. H</given-names></name><name name-style="western"><surname>Brown</surname><given-names>J. W</given-names></name></person-group>             <year>2010</year>             <article-title>Computational models of performance  and cognitive control.</article-title>             <source>Topics in Cognitive Sciences</source>             <fpage>1</fpage>             <lpage>20</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Koechlin4">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koechlin</surname><given-names>E</given-names></name><name name-style="western"><surname>Hyafil</surname><given-names>A</given-names></name></person-group>             <year>2007</year>             <article-title>Anterior prefrontal function and the limits of human decision-making.</article-title>             <source>Science</source>             <volume>318</volume>             <fpage>594</fpage>             <lpage>598</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Koechlin5">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koechlin</surname><given-names>E</given-names></name><name name-style="western"><surname>Basso</surname><given-names>G</given-names></name><name name-style="western"><surname>Pietrini</surname><given-names>P</given-names></name><name name-style="western"><surname>Panzer</surname><given-names>S</given-names></name><name name-style="western"><surname>Grafman</surname><given-names>J</given-names></name></person-group>             <year>1999</year>             <article-title>The role of the anterior prefrontal cortex in human cognition.</article-title>             <source>Nature</source>             <volume>399</volume>             <fpage>148</fpage>             <lpage>151</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Fletcher1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fletcher</surname><given-names>P. C</given-names></name><name name-style="western"><surname>Henson</surname><given-names>R. N</given-names></name></person-group>             <year>2001</year>             <article-title>Frontal lobes and human memory: insights from functional neuroimaging.</article-title>             <source>Brain</source>             <volume>124</volume>             <fpage>849</fpage>             <lpage>881</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Sakai2">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sakai</surname><given-names>K</given-names></name><name name-style="western"><surname>Hikosaka</surname><given-names>O</given-names></name><name name-style="western"><surname>Miyauchi</surname><given-names>S</given-names></name><name name-style="western"><surname>Takino</surname><given-names>R</given-names></name><name name-style="western"><surname>Sasaki</surname><given-names>Y</given-names></name><etal/></person-group>             <year>1998</year>             <article-title>Transition of brain activation from frontal to parietal areas in visuomotor sequence learning.</article-title>             <source>J Neurosci</source>             <volume>18</volume>             <fpage>1827</fpage>             <lpage>1840</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Boorman2">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Boorman</surname><given-names>E. D</given-names></name><name name-style="western"><surname>Behrens</surname><given-names>T. E</given-names></name><name name-style="western"><surname>Rushworth</surname><given-names>M</given-names></name></person-group>             <year>2011</year>             <article-title>Counterfactual choices and learning in a neural network centered on human lateral frontopolar cortex.</article-title>             <source>PLoS Biol</source>             <volume>9</volume>             <fpage>e1001093</fpage>             <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1001093" xlink:type="simple">10.1371/journal.pbio.1001093</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Glascher1">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Glascher</surname><given-names>J</given-names></name><name name-style="western"><surname>Rudrauf</surname><given-names>D</given-names></name><name name-style="western"><surname>Colom</surname><given-names>R</given-names></name><name name-style="western"><surname>Paul</surname><given-names>L. K</given-names></name><name name-style="western"><surname>Tranel</surname><given-names>D</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Distributed neural system for general intelligence revealed by lesion mapping.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>107</volume>             <fpage>4705</fpage>             <lpage>4709</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Dietrich1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dietrich</surname><given-names>A</given-names></name></person-group>             <year>2004</year>             <article-title>The cognitive neuroscience of creativity.</article-title>             <source>Psychon Bull Rev</source>             <volume>11</volume>             <fpage>1011</fpage>             <lpage>1026</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Zabelina1">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zabelina</surname><given-names>D</given-names></name><name name-style="western"><surname>Robinson</surname><given-names>M. D</given-names></name></person-group>             <year>2010</year>             <article-title>Creativity as flexible cognitive control.</article-title>             <source>Psychology of Aesthetics, Creativity and the Arts</source>             <volume>4</volume>             <fpage>136</fpage>             <lpage>143</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Wiggins1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wiggins</surname><given-names>G. A</given-names></name></person-group>             <year>2006</year>             <article-title>A preliminary framework for description, analysis and comparison of creative system.</article-title>             <source>Knowledge-Based Systems</source>             <volume>19</volume>             <fpage>449</fpage>             <lpage>458</lpage>          </element-citation>
      </ref>
      <ref id="pbio.1001293-Boden1">
        <label>62</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Boden</surname><given-names>M. A</given-names></name></person-group>             <year>1990</year>             <source>The creative mind: myths and mechanisms</source>             <publisher-name>Weidenfeld/Abacus &amp; Basic Books</publisher-name>          </element-citation>
      </ref>
    </ref-list>
    <glossary>
      <title>Abbreviations</title>
      <def-list>
        <def-item>
          <term>RL</term>
          <def>
            <p>reinforcement learning</p>
          </def>
        </def-item>
        <def-item>
          <term>UM</term>
          <def>
            <p>uncertainty monitoring</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
    
  </back>
</article>
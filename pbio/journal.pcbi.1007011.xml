<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1007011</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-01833</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Visual cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Visual cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Hematology</subject><subj-group><subject>Hemodynamics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Memory</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research design</subject><subj-group><subject>Experimental design</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Differential sustained and transient temporal processing across visual streams</article-title>
<alt-title alt-title-type="running-head">Differential sustained and transient temporal processing across visual streams</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1505-8662</contrib-id>
<name name-style="western">
<surname>Stigliani</surname>
<given-names>Anthony</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Jeska</surname>
<given-names>Brianna</given-names>
</name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5404-9606</contrib-id>
<name name-style="western">
<surname>Grill-Spector</surname>
<given-names>Kalanit</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Psychology Department, Stanford University, Stanford, California, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Stanford Neurosciences Institute, Stanford University, Stanford, California, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Jbabdi</surname>
<given-names>Saad</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Oxford University, UNITED KINGDOM</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">kalanit@stanford.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>30</day>
<month>5</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>5</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>5</issue>
<elocation-id>e1007011</elocation-id>
<history>
<date date-type="received">
<day>26</day>
<month>10</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>7</day>
<month>4</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Stigliani et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1007011"/>
<abstract>
<p>How do high-level visual regions process the temporal aspects of our visual experience? While the temporal sensitivity of early visual cortex has been studied with fMRI in humans, temporal processing in high-level visual cortex is largely unknown. By modeling neural responses with millisecond precision in separate sustained and transient channels, and introducing a flexible encoding framework that captures differences in neural temporal integration time windows and response nonlinearities, we predict fMRI responses across visual cortex for stimuli ranging from 33 ms to 20 s. Using this innovative approach, we discovered that lateral category-selective regions respond to visual transients associated with stimulus onsets and offsets but not sustained visual information. Thus, lateral category-selective regions compute moment-to-moment visual transitions, but not stable features of the visual input. In contrast, ventral category-selective regions process both sustained and transient components of the visual input. Our model revealed that sustained channel responses to prolonged stimuli exhibit adaptation, whereas transient channel responses to stimulus offsets are surprisingly larger than for stimulus onsets. This large offset transient response may reflect a memory trace of the stimulus when it is no longer visible, whereas the onset transient response may reflect rapid processing of new items. Together, these findings reveal previously unconsidered, fundamental temporal mechanisms that distinguish visual streams in the human brain. Importantly, our results underscore the promise of modeling brain responses with millisecond precision to understand the underlying neural computations.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>How does the brain encode the timing of our visual experience? Using functional magnetic resonance imaging (fMRI) and a generative temporal model with millisecond resolution, we discovered that visual regions in the lateral and ventral processing streams fundamentally differ in their temporal processing of the visual input. Regions in lateral temporal cortex process visual transients associated with the beginning and ending of the stimulus, but not its stable aspects. That is, lateral regions appear to compute moment-to-moment changes in the visual input. In contrast, regions in ventral temporal cortex process both stable and transient components of the visual input, even as the response to the former exhibits adaptation. Surprisingly, the model predicts that in ventral regions responses to stimulus endings are larger than beginnings. We suggest that ending responses may reflect a memory trace of the stimulus, when it is no longer visible, and the beginning responses may reflect processing of new inputs. Together, these findings (i) reveal a fundamental temporal mechanism that distinguishes visual streams and (ii) highlight both the importance and utility of modeling brain responses with millisecond precision to understand the temporal dynamics of neural computations in the human brain.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000053</institution-id>
<institution>National Eye Institute</institution>
</institution-wrap>
</funding-source>
<award-id>1R01-EY02391501A1</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5404-9606</contrib-id>
<name name-style="western">
<surname>Grill-Spector</surname>
<given-names>Kalanit</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This research was supported by National Eye Institute Grant 1R01-EY02391501A1 awarded to KGS (<ext-link ext-link-type="uri" xlink:href="https://nei.nih.gov/" xlink:type="simple">https://nei.nih.gov/</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="0"/>
<page-count count="26"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-06-19</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data will be held in a public repository at <ext-link ext-link-type="uri" xlink:href="https://osf.io/mw5pk/" xlink:type="simple">https://osf.io/mw5pk/</ext-link> and code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/VPNL/TemporalChannels" xlink:type="simple">https://github.com/VPNL/TemporalChannels</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>How do high-level visual areas encode the temporal characteristics of our visual experience? The temporal sensitivity of early visual areas has been studied with electrophysiology in non-human primates [<xref ref-type="bibr" rid="pcbi.1007011.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref004">4</xref>] and recently using fMRI in humans [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>]. However, the nature of temporal processing in high-level visual regions remains a mystery for two main reasons. First, the temporal resolution of noninvasive fMRI measurements is in seconds [<xref ref-type="bibr" rid="pcbi.1007011.ref007">7</xref>], an order of magnitude longer than the timescale of neural processing, which is in the order of tens of milliseconds. Second, while fMRI responses are roughly linear for stimuli lasting 3–10 s [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>], responses in visual cortex exhibit nonlinearities both for briefer stimuli, which generate stronger than expected responses [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref013">13</xref>], as well as for longer stimuli, which get suppressed due to adaptation [<xref ref-type="bibr" rid="pcbi.1007011.ref014">14</xref>]. Since the standard approach using a general linear model (GLM) to predict fMRI signals from the stimulus [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>] is inadequate for modeling responses to such stimuli, the temporal processing characteristics of human high-level visual cortex have remained largely elusive (but see [<xref ref-type="bibr" rid="pcbi.1007011.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref017">17</xref>]).</p>
<p>We hypothesized that if nonlinearities are of neural (rather than BOLD) origin, a new approach that predicts fMRI responses by modeling neural nonlinearities can be applied to characterize temporal processing in high-level visual cortex. Different than the GLM, which predicts fMRI signals directly from the stimulus, the encoding approach first models neural responses to the stimulus and from them predicts fMRI responses. Recent studies show that accurately modeling neural responses to brief visual stimuli at millisecond resolution better predicts fMRI responses than the GLM [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>]. The encoding approach also enables testing a variety of temporal models and quantifying which model best predicts brain responses. Further, generative computational models of neural processing offer a framework that can provide key insights into multiple facets of temporal processing including integration time windows [<xref ref-type="bibr" rid="pcbi.1007011.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref021">21</xref>], temporal channel contributions [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref025">25</xref>], and response nonlinearities [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>].</p>
<p>One fundamental way in which visual regions differ is in how they process sustained and transient visual stimuli. In the retina [<xref ref-type="bibr" rid="pcbi.1007011.ref026">26</xref>], LGN [<xref ref-type="bibr" rid="pcbi.1007011.ref027">27</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref029">29</xref>], and V1 [<xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>], there are separate temporal channels for processing transient and sustained components of the visual input that are associated with magnocellular (M) and parvocellular (P) pathways, respectively [<xref ref-type="bibr" rid="pcbi.1007011.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref024">24</xref>]. While these channels are likely combined outside early visual cortex (V1-V3), it is thought that regions that process dynamic stimuli such as hMT+ largely receive input from the transient channel in V1 [<xref ref-type="bibr" rid="pcbi.1007011.ref023">23</xref>], and regions in the ventral stream such as hV4 receive inputs from both transient and sustained channels [<xref ref-type="bibr" rid="pcbi.1007011.ref024">24</xref>]. Indeed, using an encoding model with two temporal channels—one sustained and one transient—we were able to successfully predict fMRI responses in early and intermediate visual areas (V4, hMT+) to phase scrambled stimuli varying in duration from 33 ms to 30 s [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>].</p>
<p>Motivated by the success of this approach in early and intermediate visual areas, we considered three hypotheses regarding temporal processing in high-level visual cortex. One possibility is that temporal processing characteristics are similar across high-level visual regions but differ from those of earlier stages of the visual hierarchy. This hypothesis is based on results from animal electrophysiology showing longer latencies of responses in higher-level visual regions compared to primary visual cortex, V1 [<xref ref-type="bibr" rid="pcbi.1007011.ref001">1</xref>], as well as research in humans showing longer temporal receptive windows [<xref ref-type="bibr" rid="pcbi.1007011.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref020">20</xref>] and integration times [<xref ref-type="bibr" rid="pcbi.1007011.ref021">21</xref>] in ventral temporal cortex (VTC) and lateral temporal cortex (LTC) compared to early visual areas. A second possibility is that temporal processing is uniform across high-level regions that process a shared category (e.g. face-selective regions in VTC and LTC), but differs across regions that process different categories (e.g. face- vs. body-selective regions). This prediction is based on data showing differential responses to long-duration (21 s) images in face- vs. place-selective regions in VTC [<xref ref-type="bibr" rid="pcbi.1007011.ref014">14</xref>], as well as differential response characteristics to fast (8 Hz) visual stimulation in body-selective regions vs. other category-selective regions [<xref ref-type="bibr" rid="pcbi.1007011.ref015">15</xref>]. A third possibility is that temporal processing differs across ventral and lateral visual streams rather than across categories. A large body of literature has documented that regions in LTC along the superior temporal sulcus (STS) show heightened responses to biological motion compared to stationary stimuli and other types of motion [<xref ref-type="bibr" rid="pcbi.1007011.ref030">30</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref037">37</xref>], unlike regions in VTC that are thought to represent the static aspect of the stimulus [<xref ref-type="bibr" rid="pcbi.1007011.ref034">34</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref038">38</xref>]. This predicts that lateral regions may show larger transient responses than ventral regions, which instead may show larger sustained responses.</p>
<p>To test these predictions, we measured fMRI responses in high-level visual areas to images of faces, bodies, and words that were either sustained (one continuous image per trial, durations ranging from 3–20 s) (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>A</italic> and 1<italic>B</italic></xref>, <italic>experiment 1</italic>), transient [30 flashed, 33 ms long images per trial with interstimulus intervals (ISIs) ranging from 67–633 ms] (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>A</italic> and 1<italic>B</italic></xref>, <italic>experiment 2</italic>), or contained both transient and sustained components (30 semi-continuous images per trial, durations ranging from 67–633 ms per image with 33 ms ISIs) (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>A</italic> and 1<italic>B</italic></xref>, <italic>experiment 3</italic>). We also collected a separate functional localizer experiment to independently define regions selective to faces and bodies in VTC and LTC (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>C</italic></xref>; <xref ref-type="sec" rid="sec011">Materials and methods</xref>). We used face- and body-selective regions as a model system as there are multiple clusters of selectivity to these categories across the temporal lobe, and face and body regions neighbor on the cortical sheet [<xref ref-type="bibr" rid="pcbi.1007011.ref039">39</xref>]. This organization enabled us to (i) measure how the temporal dynamics of stimuli affect responses in each region and (ii) test if temporal processing characteristics vary across regions selective to different categories (e.g., faces or bodies) or across regions in different anatomical locations (e.g., ventral vs. lateral temporal cortex).</p>
<fig id="pcbi.1007011.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007011.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Measuring brain responses to combinations of sustained and transient visual stimuli in high-level visual cortex.</title>
<p>(<italic>A</italic>) Participants fixated centrally and viewed images of bodies, faces, and pseudowords (<italic>right</italic>) that were presented in trials of different durations interleaved with 12-s periods of a blank screen (<italic>left</italic>). <italic>Experiment 1</italic>: a single image was shown for the duration of a trial. <italic>Experiment 2</italic>: 30 briefly presented images from the same category (33 ms each), each followed by a blank screen, were presented in each trial. As the trial duration lengthens, the gap between images increases, causing the fraction of the trial containing visual stimulation to decline. <italic>Experiment 3</italic>: 30 semi-continuous images from the same category were presented in each trial with a constant 33-ms blank screen between consecutive images. As the block duration lengthens, the duration of each image progressively increases but the gap does not. (<italic>B</italic>) The same trial durations (3, 5, 10, or 20 s) were utilized across all three experiments, while the rate and duration of visual presentation varied between experiments. Corresponding trials in experiments 1 and 3 have almost the same overall duration of stimulation but different numbers of stimuli, whereas trials in experiments 2 and 3 have the same number of stimuli but different durations of stimulation. The same fixation task was used in the three main experiments. (<italic>C</italic>) Functional regions of interest in ventral temporal cortex (<italic>left</italic>) and lateral temporal cortex (<italic>right</italic>) selective to bodies (OTS and MTG, blue) and faces (pSTS and mFus, red), as well as human V4 (hV4) and human motion-sensitive area (hMT+). Regions in each anatomical section are shown in an example subject.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.g001" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Responses in high-level visual cortex exhibit temporal nonlinearities</title>
<p>To assess the feasibility of our approach, we first used a standard widely-used GLM [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>] to predict fMRI responses in the three main experiments. Then, we compared these predictions to measured fMRI responses from two sample functional regions of interest: a ventral body-selective region and a lateral body-selective region.</p>
<p>In general, the GLM predicts longer responses for longer trials and similar responses in experiments 1 and 3 (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>A</italic></xref>, <italic>blue</italic> and <italic>green</italic>). Responses in experiment 1 are predicted to be slightly higher than in experiment 3 because the 33 ms gaps between images in the latter experiment make up 1 s of baseline within each trial. Due to the nature of the hemodynamic response function (HRF), the GLM also predicts that peak response amplitudes in experiments 1 and 3 will increase gradually from 3 s to 10 s trials and subsequently plateau for longer trial durations. In contrast, this model predicts substantially lower responses in experiment 2 compared to the other experiments because the transient 33 ms stimuli in this experiment comprise only a small fraction of each trial duration (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>A</italic></xref>, <italic>red</italic>). Therefore, the GLM predicts a progressive decrease in response amplitude from 3 s to 20 s trials in experiment 2, as the fraction of the trial in which stimuli are presented decreases (from 1/3 to 1/20 of the trial).</p>
<fig id="pcbi.1007011.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007011.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Responses of body-selective regions in ventral and lateral temporal cortex exhibit nonlinearities that are not predicted by a linear model.</title>
<p>(<italic>A</italic>) Predicted responses by a GLM for trials containing one continuous image (<italic>blue</italic>), thirty flashed (33 ms) images (<italic>red</italic>), and thirty longer images that span then entire trial duration except for a 33 ms interstimulus interval (ISI) following each image (<italic>green</italic>). Predictors are fit to OTS-bodies responses using data concatenated across all three experiments shown in (B). (<italic>B</italic>) Measured responses during Exp1-Exp 3 from an independently defined ventral region on the occipitotemporal sulcus (OTS) selective to bodies (OTS-bodies). (<italic>C</italic>) Measured responses during Exp1-Exp 3 from an independently defined lateral region on the middle temporal gyrus (MTG) selective for bodies (MTG-bodies). In (B-C), <italic>lines</italic>: mean response time series across participants for trials with body images; <italic>shaded areas</italic>: standard error of the mean (SEM) across participants; <italic>Horizontal black bars</italic>: stimulus duration.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.g002" xlink:type="simple"/>
</fig>
<p>Strikingly, responses to body images in a ventral body-selective region (OTS-bodies; <xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>B</italic></xref>) and a lateral body-selective region (MTG-bodies; <xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>C</italic></xref>) both deviate from the predictions of the GLM, but in different ways. Although these regions prefer the same category, we observe differences in their maximal response to the different timing conditions in our experiments [significant three-way interaction, <italic>F</italic><sub>6, 54</sub> = 2.28, <italic>P</italic> &lt; .05; three-way ANOVA on peak trial response amplitude for each participant with factors of trial duration (3/5/10/20 s), experiment (1/2/3), and ROI (OTS-bodies/MTG-bodies); <xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>B</italic> and 2<italic>C</italic></xref>].</p>
<p>In contrast to the predictions of the GLM, responses in OTS-bodies to trials of 30 flashed images in experiment 2 (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>B</italic></xref>, <italic>red</italic>) are substantially higher than in corresponding trial durations in experiment 1, when one stimulus is shown per trial (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>B</italic></xref>, <italic>blue</italic>). This occurs despite the fact that stimuli are presented for only a small fraction of each trial duration in experiment 2 compared to experiment 1. Furthermore, peak response amplitudes do not increase with trial duration in experiment 1 as predicted by the GLM. Instead, we observe a systematic decrease in response after the first few seconds of stimulation in the 10 s and 20 s trials, which is consistent with prior reports of fMRI adaptation for prolonged stimuli in nearby face- and place-selective regions [<xref ref-type="bibr" rid="pcbi.1007011.ref014">14</xref>]. Lastly, responses in experiment 3 (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>B</italic></xref>, <italic>green</italic>) exceed responses in both experiment 1 (which has only one image per trial but similar overall durations of stimulation) and experiment 2 (which has the same number of images per trial but shorter stimulus durations). This observation suggests that both the number of stimuli in a trial and their duration impact response amplitudes, as in earlier visual areas such as V1 and hV4 (<xref ref-type="supplementary-material" rid="pcbi.1007011.s001">S1 Fig</xref>).</p>
<p>Unlike OTS-bodies, MTG-bodies illustrates a largely transient response characteristic with substantially lower responses to the prolonged single images in experiment 1. Notably, for the 10 s and 20 s trials, we observe a transient response following both the onset and the offset of the image but no elevation of response in the middle of the trial (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>C</italic></xref>, <italic>blue</italic>). In contrast to the lack of robust responses in experiment 1, MTG-bodies shows surprisingly large responses to briefly flashed stimuli in experiment 2 (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>C</italic></xref>, <italic>red</italic>). Additionally, responses in MTG-bodies during experiment 2 (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>C</italic></xref>, <italic>red</italic>) and experiment 3 (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>C</italic></xref>, <italic>green</italic>), which have 30 stimuli per trial but of different stimulus durations, are similar and both exceed responses in experiment 1, which has a single stimulus per trial. This suggests that, unlike ventral regions, stimulus duration has little impact on MTG-bodies responses, which resemble responses in neighboring motion-sensitive hMT+ (<xref ref-type="supplementary-material" rid="pcbi.1007011.s001">S1 Fig</xref>).</p>
<p>These data demonstrate that (i) varying the temporal properties of visual presentations in the millisecond range has a profound effect on fMRI responses in high-level visual cortex, (ii) the standard GLM is inadequate for predicting measured fMRI responses to these types of stimuli in high-level regions, in agreement with prior data in earlier visual areas [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref013">13</xref>], and (iii) even though OTS-bodies and MTG-bodies prefer the same stimulus category, their temporal response characteristics vastly differ.</p>
</sec>
<sec id="sec004">
<title>An encoding model of temporal processing in high-level visual cortex</title>
<p>Motivated by the recent success of encoding models that predict fMRI responses in earlier visual areas by modeling neural temporal nonlinearities [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>], we applied a similar approach to predict responses in high-level visual areas. Different than the GLM, the temporal encoding approach first models the neural response in millisecond resolution and then convolves the estimated neural response with a HRF to predict fMRI responses (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3</xref>).</p>
<fig id="pcbi.1007011.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007011.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Optimized two-temporal channel A+S model with adaptation and sigmoid nonlinearities.</title>
<p>(<italic>A</italic>) Transitions between stimulus and baseline screens are coded as a step function representing when a stimulus was on vs. off with millisecond temporal resolution. (<italic>B</italic>) Separate neural responses for the sustained (<italic>blue</italic>) and transient (<italic>red</italic>) channels are modeled by convolving the stimulus vector with an IRF for each channel. An exponential decay function is applied to the sustained channel to model response decrements related to neural adaptation, and a compressive sigmoid nonlinearity is applied to the transient channel to vary the temporal characteristics of “on” and “off” responses (<xref ref-type="sec" rid="sec011">Materials and methods</xref>). (<italic>C</italic>) Predictors of sustained and transient fMRI responses are generated by convolving each channel’s neural response predictors with the HRF and down-sampling to match the sampling rate of measured fMRI data. The total fMRI response is the sum of the weighted sustained and transient fMRI predictors for each channel. To optimize model parameters and estimate the contributions (<italic>β</italic> weights) of the sustained (<italic>β</italic><sub>S</sub>) and transient (<italic>β</italic><sub>T</sub>) channels, we fit the model to different splits of the data including runs from all three experiments.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.g003" xlink:type="simple"/>
</fig>
<p>Our encoding model consists of two temporal channels [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>]–a sustained channel and a transient channel—each of which can be modeled using a neural temporal impulse response function (IRF) followed by a nonlinearity [<xref ref-type="bibr" rid="pcbi.1007011.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref040">40</xref>]. The sustained channel is modeled with a monophasic IRF (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3<italic>B</italic></xref>, <italic>blue channel IRF</italic>), which predicts a sustained neural response for the duration of the stimulus. To capture the gradual decay (adaptation, A) of the response observed in ventral regions for sustained images (<xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>B</italic></xref>, <italic>blue</italic>), we apply a nonlinearity to the sustained channel in the form of an exponential decay function (<xref ref-type="sec" rid="sec011">Materials and methods</xref>). The transient channel is characterized by a biphasic IRF (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3<italic>B</italic></xref>, <italic>red channel IRF</italic>) that identifies changes to the visual input. That is, it acts like a derivative function, predicting no further increase in the neural response once a stimulus has been presented for longer than the duration of the IRF [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>]. This channel too has a nonlinearity, as we hypothesize an increase in neural response at both the appearance (onset) and disappearance (offset) of a stimulus. To account for the pronounced transient responses in high-level visual regions (<xref ref-type="supplementary-material" rid="pcbi.1007011.s001">S1 Fig</xref>), we apply a flexible compressive nonlinearity on the transient channel using a pair of sigmoid (S) functions, one for the onset and another for the offset (<xref ref-type="sec" rid="sec011">Materials and methods</xref>). Thus, we refer to this two-temporal channel encoding model as the A+S model. The predicted fMRI response is generated by convolving the neural response predictors for each channel with the HRF and summing the responses of the two temporal channels (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3<italic>C</italic></xref>). Since the HRF effectively acts as a low-pass temporal filter, predicted fMRI responses can be downsampled with minimal distortion to match the slower sampling rate of fMRI measurements.</p>
<p>We estimated optimized A+S model parameters separately for each participant and region using nonlinear programming and a cross-validation approach. In our procedure, we use half the data from all three experiments to estimate model parameters. Using optimization, we estimate a time constant for the neural IRFs (τ), a time constant controlling adaptation of sustained responses (α), and three parameters controlling compression of transient responses (<italic>k</italic><sub>on</sub>, <italic>k</italic><sub>off</sub>, and λ). After optimizing these parameters, we use a GLM to estimate the magnitude of response (<italic>β</italic> weight) for each channel and stimulus category in our experiments, resulting in three <italic>β</italic> weights for the sustained channel (one <italic>β</italic><sub>S</sub> for each category) and three <italic>β</italic> weights for the transient channel (one <italic>β</italic><sub>T</sub> for each category). These parameters and weights are then used to predict responses in left-out data and evaluate the model’s goodness-of-fit (cross-validated variance explained, x-<italic>R</italic><sup>2</sup>).</p>
<p>Comparing the predictions of our optimized A+S model with measured fMRI responses in high-level visual cortex reveals two notable findings. First, our model generates signals that closely track the amplitude of fMRI responses in all three experiments in the left-out data. Second, analysis of x-<italic>R</italic><sup>2</sup> shows that our optimized A+S model consistently outperforms other optimized temporal encoding models.</p>
<p>We illustrate these results for one region, OTS-bodies (<xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4</xref>, <xref ref-type="supplementary-material" rid="pcbi.1007011.s002">S2 Fig</xref>); Results for other regions are in <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3</xref>–<xref ref-type="supplementary-material" rid="pcbi.1007011.s005">S5</xref> Figs. Notably, the A+S model closely tracks response amplitudes in all three experiments [<xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>A</italic>–4<italic>C</italic></xref>, compare overall model prediction (<italic>black</italic>) with measured data from OTS-bodies (<italic>gray</italic>)]. Consistent with our predictions, the sustained channel accounts for the bulk of the response in experiment 1 (<xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>A</italic></xref>, <italic>blue</italic>); The transient channel contributes most of the response in experiment 2 (<xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>B</italic></xref>, <italic>red</italic>), and both channels contribute to responses in experiment 3 (<xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>C</italic></xref>).</p>
<fig id="pcbi.1007011.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007011.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Two-temporal channel model with nonlinearities on both sustained and transient channels predicts responses in ventral temporal cortex.</title>
<p>(A-C) Responses and model predictions for body images in OTS-bodies. <italic>White curve</italic>: mean response across 10 participants. <italic>Shaded gray</italic>: standard deviation across participants. <italic>Blue</italic>: predicted response from the sustained channel. <italic>Red</italic>: predicted response from the transient channel: <italic>Black</italic>: sum of responses from both channels. <italic>Inset</italic>: <italic>mean</italic> contribution (<italic>β</italic> weight) for each channel ±1 SEM across participants. (<italic>A</italic>) Experiment 1 data, 1 continuous image per trial. (<italic>B</italic>) Experiment 2 data, 30 flashed images per trial. (<italic>C</italic>) Experiment 3 data, 30 longer images per trial. (D-F) Model comparison. Bars show the performance of various models for each experiment presented in (A-C). Models are fit using runs from all three experiments, and cross-validation performance (x-<italic>R</italic><sup>2</sup>) is calculated in left-out data from each experiment separately. (<italic>D</italic>) Experiment 1. (<italic>E</italic>) Experiment 2. (<italic>F</italic>) Experiment 3. Single-channel models: G<italic>LM</italic>, general linear model [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>]; <italic>CTS</italic>, a sustained channel with compressive temporal summation [<xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>]. Dual-channel models: <italic>L+Q</italic>, a linear sustained channel and a transient channel with quadratic nonlinearity [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>]; <italic>A+S</italic>: a sustained channel with adaptation and a transient channel with sigmoid nonlinearities. Asterisks denote models with significantly different performance compared to A+S (paired <italic>t</italic>-tests comparing x-<italic>R</italic><sup>2</sup> of each model vs. A+S in each experiment).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.g004" xlink:type="simple"/>
</fig>
<p>We compared the performance of our A+S model to other models of fMRI responses: the standard GLM [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>], the balloon model [<xref ref-type="bibr" rid="pcbi.1007011.ref007">7</xref>], four single-channel models (L, CTS [<xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>], A, S; <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3<italic>A</italic> Fig</xref>), and three alternative two-channel models (L+Q [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>], C+Q, A+Q) across all three experiments (<xref ref-type="sec" rid="sec011">Materials and methods</xref>; <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3</xref>–<xref ref-type="supplementary-material" rid="pcbi.1007011.s005">S5</xref> Figs). For simplicity, <xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>D</italic>–4<italic>F</italic></xref> compares performance in OTS-bodies for our model vs. three others: the standard GLM [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>], a single-channel model with compressive temporal summation (CTS) [<xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>], and a two-channel model composed of a linear sustained channel and a transient channel with a quadratic nonlinearity (L+Q) [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>]. The latter two models have been recently used to model temporal dynamics of early and intermediate visual areas. Comparing the performance of these models in OTS-bodies (<xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>D</italic>–4<italic>F</italic></xref>), we observe significant differences across experiments [significant main effect of model type, <italic>F</italic><sub>6, 54</sub> = 13.79, <italic>P</italic> &lt; .001, two-way ANOVA with factors of model type (GLM/CTS/L+Q/A+S) and experiment (experiment 1/2/3)]. Notably, the A+S model predicts OTS-bodies responses in left out data significantly better than the GLM [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>], which overestimates responses in experiment 1 and underestimates responses in experiment 2 (GLM vs. A+S: all <italic>t</italic>s &gt; 2.64, <italic>P</italic>s &lt; .05, paired <italic>t</italic>-tests on x-<italic>R</italic><sup>2</sup> separately for each experiments) (<xref ref-type="supplementary-material" rid="pcbi.1007011.s002">S2<italic>A</italic> Fig</xref>). The A+S model also outperforms the recently proposed CTS model [<xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>] that enhances early and late portions of the neural response to a stimulus (CTS vs. A+S: all <italic>t</italic>s &gt; 2.60, <italic>P</italic>s &lt; .05). While the CTS model performs considerably better than the GLM in experiment 2, it overestimates responses in experiment 1 with a single continuous image per trial and underestimates responses in experiment 3 with 30 longer images per trial (<xref ref-type="supplementary-material" rid="pcbi.1007011.s002">S2<italic>B</italic> Fig</xref>). In experiments 2 and 3, we also observe a significant advantage of the A+S model compared to the two-temporal channel L+Q model [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>], which underestimates the large responses to transient stimuli in experiment 2 (<xref ref-type="supplementary-material" rid="pcbi.1007011.s002">S2<italic>C</italic> Fig</xref>) (L+Q vs. A+S: <italic>t</italic>s &gt; 4.06, <italic>P</italic>s &lt; .05; the difference fell short of significance for experiment 1, <italic>t</italic><sub>9</sub> = 1.98, <italic>P</italic> = .08).</p>
<p>Thus, an optimized two-temporal channel model with an adaptation nonlinearity in the sustained channel and compressive sigmoid nonlinearities in the transient channel predicts fMRI responses to visual stimuli ranging from milliseconds to seconds in high-level visual cortex with greater accuracy than alternative models.</p>
</sec>
<sec id="sec005">
<title>How do channel contributions differ across ventral and lateral category-selective regions?</title>
<p>Examination of response time series (<xref ref-type="supplementary-material" rid="pcbi.1007011.s001">S1 Fig</xref>) and channel weights (<xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5</xref>) in body- and face-selective regions in VTC and LTC reveals prominent differences across ventral and lateral temporal regions.</p>
<fig id="pcbi.1007011.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007011.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Differential contributions of transient and sustained temporal channels across ventral and lateral regions selective to face and body stimuli.</title>
<p>Contributions (<italic>β</italic> weights) of transient (<italic>x</italic> axis) and sustained (<italic>y</italic> axis) channels for each stimulus category estimated by the two-temporal channel A+S model in (<italic>A</italic>) occipital body-selective region on the lateral occipital sulcus (LOS) and a face-selective region on the inferior occipital gyrus (IOG), (<italic>B</italic>) ventral-temporal body-selective regions on the inferior temproal gyrus (ITG) and occipito-temporal sulcus (OTS) and face-selective regions on the posterior and mid fusiform gyrus, pFus- and mFus-faces, respectivevely, and (<italic>C</italic>) a lateral temporal body-selective region on the mid temporal gyrus (MTG) and a face-selective region on the posterior aspect of the superior temporal sulcus (pSTS-faces). Crosses span ±1 SEM across participants in each axis, and <italic>β</italic> weights were solved by fitting the model using split halves of the data including runs from all three experiments. Data show average model weights across both splits of the data for each participant. <italic>Red</italic>: response to faces. <italic>Blue</italic>: response to bodies. <italic>Gray</italic>: response to words. <italic>Dashed line</italic>: identity line (<italic>β</italic><sub>S</sub> = <italic>β</italic><sub>T</sub>). <italic>Inset</italic>: bars indicate mean contrast effect size (CES) of <italic>β</italic> weights for the preferred vs. nonpreferred categories in each channel ±1 SEM across participants.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.g005" xlink:type="simple"/>
</fig>
<p>First, comparing the response time courses of different category-selective regions shows that ventral temporal regions (e.g., OTS-bodies and mFus-faces) respond strongly to both the sustained stimuli in experiment 1 and the transient stimuli in experiment 2, whereas lateral temporal regions (MTG-bodies and pSTS-faces) respond strongly to the transient stimuli but minimally to the sustained stimuli (<xref ref-type="supplementary-material" rid="pcbi.1007011.s001">S1 Fig</xref>). The ratio of sustained and transient channel amplitudes, <inline-formula id="pcbi.1007011.e001"><alternatives><graphic id="pcbi.1007011.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mo>|</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:math></alternatives></inline-formula>, also differs across regions in ventral and lateral aspects of temporal cortex [significant main effect of processing stream, <italic>F</italic><sub>1, 107</sub> = 14.27, <italic>P</italic> &lt; .01, three-way ANOVA with factors of processing stream (ventral/lateral), stimulus category (faces/bodies/words), and preferred category (bodies/faces); all other effects failed to reach significance; <italic>F</italic>s &lt; 1.39, <italic>P</italic>s &gt; .05]. That is, while both sustained and transient channels contribute to responses in ventral temporal regions (<xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>B</italic></xref>), the transient channel dominates responses in lateral temporal regions (<xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>C</italic></xref>). In fact, zeroing the contribution of the sustained channel slightly improves model performance in lateral regions (i.e. x-<italic>R</italic><sup>2</sup> of the S model is marginally better than the A+S model in MTG-bodies and pSTS-faces; <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3<italic>B</italic> Fig</xref>). In contrast, zeroing the sustained channel detrimentally affects the prediction of responses in ventral regions for prolonged visual stimulation as in experiment 1 (<xref ref-type="supplementary-material" rid="pcbi.1007011.s006">S6<italic>A</italic> Fig</xref>). Finally, ventral temporal regions show a response characteristic similar to both hV4 (<xref ref-type="supplementary-material" rid="pcbi.1007011.s004">S4<italic>A</italic> Fig</xref>) and occipital category-selective regions (<xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>A</italic></xref>), whereas lateral temporal regions show a characteristic similar to motion-sensitive hMT+ (<xref ref-type="supplementary-material" rid="pcbi.1007011.s004">S4<italic>A</italic> Fig</xref>).</p>
<p>Second, in VTC (<xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>B</italic></xref>), category selectivity—or higher responses to a preferred category vs. other categories—is evident in both sustained and transient channels [all <italic>t</italic>s &gt; 2.26, <italic>P</italic>s &lt; .05, one-tailed <italic>t</italic>-tests comparing the contrast effect size (CES) of <italic>β</italic> weights for the preferred vs. nonpreferred categories separately for each channel; <xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>B</italic></xref>, <italic>insets</italic>]. For example, in both channels, the weighting of the predicted response to faces in mFus is significantly higher than the average weighting of responses to words and bodies (<italic>t</italic>s &gt; 5.25, <italic>P</italic>s &lt; .001, paired <italic>t</italic>-test for each channel; <xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>A</italic></xref>, <italic>right</italic>). Likewise, in both channels, the predicted weighting of responses to bodies in OTS is higher than the average weighting of responses to other categories (<italic>t</italic>s &gt; 2.59, <italic>P</italic>s &lt; .05, paired <italic>t</italic>-test for each channel; <xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>A</italic></xref>, <italic>left</italic>). Selectivity across both temporal channels was also observed in nearby word-selective regions (IOS-words and pOTS-words; <xref ref-type="supplementary-material" rid="pcbi.1007011.s007">S7<italic>A</italic> Fig</xref>). Interestingly, category selectivity in the sustained channel was higher in ventral face-selective regions as compared to body-selective regions. In contrast, in LTC (MTG-bodies and pSTS-faces; <xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>C</italic></xref>), there is a significant difference in the CES across sustained and transient channels [significant main effect of channel, <italic>F</italic><sub>1, 8</sub> = 14.88, <italic>P</italic> &lt; .01, two-way ANOVA with factors of channel (sustained/transient) and preferred category (bodies/faces)]. That is, higher responses to the preferred category are observed only in the transient channel (<italic>t</italic>s &gt; 1.99, <italic>P</italic>s &lt; .05; the effect was not significant in the sustained channel, <italic>t</italic>s &lt; 1.37, <italic>P</italic>s &gt; .10; <xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5<italic>B</italic></xref>, <italic>insets</italic>). Thus, these results reveal differential contributions of transient and sustained channels across ventral and lateral category-selective regions.</p>
</sec>
<sec id="sec006">
<title>How do timing parameters vary across ventral and lateral face and body regions?</title>
<p>We next examined the optimized timing and compression parameters for each channel to test if there are functional differences across regions. The parameters in our A+S model were optimized separately for each region within each participant. Thus, for a given ROI, we optimized one time constant for the channel IRFs, one time constant for the adaptation decay function, as well as three sigmoid parameters (<xref ref-type="sec" rid="sec011">Materials and methods</xref>).</p>
<p>For the sustained channel, we assessed how the time to peak of the neural IRF (<italic>IRF</italic><sub>S</sub>) and the adaptation decay constant (α) vary across occipital and ventral temporal regions, omitting lateral temporal regions that did not have significant sustained responses. We discovered a hierarchical progression of longer time to peak and stronger adaptation in the sustained channel ascending from early to later stages of the ventral hierarchy (<xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6<italic>A</italic></xref>). That is, the time to peak of the sustained IRF tended to be shorter in V1 than hV4 and shorter in hV4 than in ventral regions OTS-bodies and mFus-faces (<xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6<italic>A</italic></xref>, <italic>x axis</italic>). At the same time, the adaptation decay constant decreased from V1 to ventral temporal regions, indicating more adaptation in mFus-faces and OTS-bodies than in V1 (<xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6<italic>A</italic></xref>, <italic>y axis</italic>). We also observed a decreasing adaptation constant from occipital regions IOG-faces/LOS-bodies to the ventral regions mFus-faces/OTS-bodies. Thus, analyzing timing parameters in the sustained channel revealed differences in processing across the ventral stream.</p>
<fig id="pcbi.1007011.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007011.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Optimized two-temporal channel model parameters differ across visual cortex.</title>
<p>(<italic>A</italic>) Optimized sustained channel parameters. Time to peak of sustained <italic>IRF</italic><sub>S</sub> (<italic>x</italic> axis) and exponential time constant of the adaptation function (<italic>y</italic> axis) for each set of regions estimated by the two-temporal channel A+S model. Crosses span ±1 SEM across participants in each axis, and parameters were optimized using split halves of the data containing runs from all experiments. Data show model parameters averaged across both splits of the data for each participant. (<italic>B</italic>) Optimized transient channel parameters. Time to peak of transient <italic>IRF</italic><sub>T</sub> (<italic>x</italic> axis) and onset/offset balance (<italic>y</italic> axis) for each set of regions estimated by the two-temporal channel A+S model (with a zeroed sustained channel in lateral regions). The onset/offset balance metric captures differences in the shapes of the sigmoid nonlinearities used to compress transient “on” and “off” responses, where values larger than 0.5 refect elongation of offset responses compared to onset responses. Crosses span ±1 SEM across participants in each axis, and parameters were optimized using split halves of the data from all experiments. Plots show average model parameters across all splits of the data for each participant. Sample IRFs and nonlinearities shown to the right of (A-B) are generated by averaging optimized model parameters across participants.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.g006" xlink:type="simple"/>
</fig>
<p>In the transient channel, we examined how the time to peak of the <italic>IRF</italic><sub>T</sub> varies across regions and if there are asymmetries in the compression of “on” compared to “off” neural responses controlled by the sigmoid shape parameters <italic>k</italic><sub>on</sub> and <italic>k</italic><sub>off</sub>, respectively. Since lower <italic>k</italic> values generally elongate transient responses, the relative contribution of the offset component can be indexed by a balance metric, <inline-formula id="pcbi.1007011.e002"><alternatives><graphic id="pcbi.1007011.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, where a ratio of 0.5 indicates equal contributions from the onset and the offest of a stimulus to BOLD signals (<italic>k</italic><sub>on</sub> = <italic>k</italic><sub>off</sub>). A ratio &lt; 0.5 indicates a larger contribution of onset than offset responses, and a ratio &gt; 0.5 indicates a larger contribution of offset than onset responses.</p>
<p>First, like the sustained channel, the transient channel also shows an increase in the time to peak of <italic>IRF</italic><sub>T</sub> going from V1 to face- and body-selective regions in VTC and LTC (<xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6<italic>B</italic></xref>, <italic>x axis</italic>). Second, VTC face-and body-selective regions tended to show longer time to peak of their transient <italic>IRF</italic><sub>T</sub> as compared to LTC face-and body-selective regions. Third, interestingly, transients in lateral regions, pSTS-faces and MTG-bodies, show balanced contributions of onset and offset responses (balance metric = 0.50±0.09; <xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6<italic>B</italic></xref>, <italic>y axis</italic> and <italic>insets</italic>). In contrast, transients in ventral regions, pFus/mFus-faces and ITG/OTS-bodies, as well as occipital face-selective IOG and body-selective LOS are dominated by offset responses (balance metric = 0.77±0.09; <xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6<italic>B</italic></xref> and <italic>insets</italic>). The surprisingly large offset contribution predicted by our model indicates that the bulk of VTC responses for the brief stimuli in experiment 2 can be attributed to neural responses that occur after the stimuli are no longer visible, rather than during the initial response to these stimuli.</p>
<p>Thus, comparison of optimized A+S model parameters reveals functional differences between early and later stages of the visual hierarchy, as well as distinct nonlinearities across ventral and lateral regions with the same category preference.</p>
</sec>
</sec>
<sec id="sec007" sec-type="conclusions">
<title>Discussion</title>
<p>Using a temporal encoding approach to explain responses in high-level visual regions, we discovered that an optimized two-temporal channel model consisting of a sustained channel with an adaptation nonlinearity and a transient channel with compressive sigmoid nonlinearities successfully predicts fMRI responses in human high-level visual cortex for stimuli presented for durations ranging from tens of milliseconds to tens of seconds. Critically, the innovative temporal encoding framework we introduce combines in a single computational model several components of temporal processing including time windows of temporal integration [<xref ref-type="bibr" rid="pcbi.1007011.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref021">21</xref>], channel contributions [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref025">25</xref>], and nonlinearities in temporal summation [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>]. Using this approach, we (i) uncover the temporal sensitivity of neural responses in human high-level visual cortex, (ii) find differential temporal characteristics across lateral and ventral category-selective regions, and (iii) propose a new mechanism—temporal processing—that functionally distinguishes visual processing streams in the human brain.</p>
<sec id="sec008">
<title>Differences in temporal processing across visual streams</title>
<p>Our results suggest two key differences between temporal processing in the ventral and lateral visual processing streams which project to ventral and lateral temporal cortex, respectively [<xref ref-type="bibr" rid="pcbi.1007011.ref041">41</xref>]. First, there are differences in channel contributions. Lateral temporal cortex is dominated by responses to visual transients, while ventral temporal cortex responds to both sustained and transient visual information. Transient processing in LTC is consistent with the view that face and body-selective regions in the STS and MTG, respectively, are involved in processing dynamic visual information [<xref ref-type="bibr" rid="pcbi.1007011.ref030">30</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref037">37</xref>]. However, different than prior theories that have implicated these lateral regions in specialized processing of biological motion [<xref ref-type="bibr" rid="pcbi.1007011.ref031">31</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref042">42</xref>], our data suggest that there is a more fundamental difference between high-level visual regions in lateral and ventral temporal cortex that is driven by differential temporal channel contributions. Second, there are also differences in the dynamics of transient processing across visual streams. LTC regions show equal increases in neural responses due to the onset and offset of a visual stimulus, suggesting they carry information about moment-to-moment changes in the visual input. However, VTC regions exhibit surprisingly asymmetric contributions from the onset and offset of the stimulus. That is, the accumulation of fMRI responses due to the termination of a stimulus is more pronounced than responses associated with its onset. This difference suggests the intriguing possibility that transient responses in LTC code progressive changes to the visual input, while transient offset responses in VTC may reflect memory traces that are maintained in high-level regions after a stimulus is no longer visible. This prediction is consistent with results from ECoG studies showing that high frequency broadband responses (&gt;60 Hz) in VTC continue for 100–200 ms after the stimulus is off [<xref ref-type="bibr" rid="pcbi.1007011.ref043">43</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref046">46</xref>] and carry stimulus-specific information that may be modulated by attention [<xref ref-type="bibr" rid="pcbi.1007011.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref046">46</xref>].</p>
<p>Observing a strong transient response in LTC regions, MTG-bodies and pSTS-faces, is interesting in the context of classic theories that propose differential contributions of magnocellular (M) and parvocellular (P) inputs to parallel visual streams in the primate visual system [<xref ref-type="bibr" rid="pcbi.1007011.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref024">24</xref>]. In macaques, the M pathway is thought to code transient visual information and projects from V1 to MT, while the P pathway is thought to code sustained information and projects from V1 to V4 and IT. Our results reveal that the transient channel, associated with the M pathway, dominates responses not just in hMT+ [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>] but also in LTC category-selective regions. In turn, this suggest the intriguing possibility that there may be substantial M projections not only to hMT+ as predicted by classic theories [<xref ref-type="bibr" rid="pcbi.1007011.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref024">24</xref>], but also to surrounding face- and body-selective regions.</p>
<p>Different from the predictions of classic theories of a predominant P input to the primate ventral stream [<xref ref-type="bibr" rid="pcbi.1007011.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref024">24</xref>], we find significant contributions from both transient and sustained channels in VTC as well as evidence for category selectivity in VTC in both channels. This finding is consistent with later studies in macaques that reported that both M and P inputs propagate to ventral visual areas such as V4 [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref025">25</xref>]. Surprisingly, our data in <xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5</xref> suggests that the contribution of the transient channel in VTC appears to be larger than the sustained channel. We note that while interpreting the relative amplitude of responses within a channel is straightforward (e.g. comparing <italic>β</italic> weights for the different categories within the transient channel), interpreting the relative weight of sustained vs. temporal channels is complex, as it depends on the specific implementation of the model and the experimental design. Nonetheless, we are confident that there are both sustained and transient responses in VTC for three reasons. First, examination of raw BOLD responses during our experiments (<xref ref-type="supplementary-material" rid="pcbi.1007011.s001">S1 Fig</xref>), which are model free, shows that VTC regions respond strongly both to sustained single images (experiment 1) as well as transient, briefly flashed images (experiment 2). Second, responses in experiment 3, which had a combination of sustained and transient stimulation, exceed those of either experiment 1 or 2, suggesting additive contributions of the two channels. Finally, a two-channel model with sustained and transient channels performs better in VTC than single-channel models with only a sustained channel or only a transient channel (<xref ref-type="supplementary-material" rid="pcbi.1007011.s006">S6 Fig</xref>).</p>
<p>Critically, finding substantial transient responses in VTC suggests a rethinking of the role of transient processing in the ventral visual stream. That is, this finding provides evidence against the prevailing theoretical view that the role of the ventral stream is just to process static visual information. We hypothesize that transient responses in the ventral steam may serve two purposes. First, onset transients may reflect the processing of novel stimuli, which underlie rapid extraction of the gist of the visual input. Second, offset transients in VTC may reflect the ignition of a memory trace of the stimulus after it is no longer visible.</p>
</sec>
<sec id="sec009">
<title>Differences in temporal processing across early and high-level stages of visual processing</title>
<p>Notably, the estimated timing parameters from our experiments are largely consistent with parameters of neural IRFs derived from compressive temporal models applied to fMRI [<xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>], as well ECoG and electrophysiology data [<xref ref-type="bibr" rid="pcbi.1007011.ref047">47</xref>], which have millisecond temporal resolution. Another aspect of our results shows that temporal parameters of neural responses vary across early and high-level areas in the visual processing hierarchy [<xref ref-type="bibr" rid="pcbi.1007011.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1007011.ref021">21</xref>]. Evidence for hierarchical differences in temporal processing is reflected in two ways. First, our model estimates that the time of peak responses of neural IRFs is later in both intermediate visual areas and high-level VTC regions relative to V1 (<xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6</xref>). Second, our data suggests faster adaptation in the sustained channel in VTC regions compared to V1 (<xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6A</xref>).</p>
<p>Nonetheless, not all of our data follow the predictions of hierarchical differences in temporal processing. For example, the time to peak of neural IRFs in mFus-faces (OTS-bodies) is earlier than pFus-faces (ITG-bodies), even though the former two are thought to be higher in the processing hierarchy than the latter. This deviation from the hierarchical view may be due to the impact of additional factors on neural response latencies, which may also vary across areas. For example, the contrast of images may affect the time to peak in V1 more than in higher-level visual regions [<xref ref-type="bibr" rid="pcbi.1007011.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref048">48</xref>].</p>
</sec>
<sec id="sec010">
<title>What are the implications for modeling fMRI responses beyond visual cortex?</title>
<p>Our data has critical implications for computational models of the brain. We developed a parsimonious yet powerful encoding model that can be applied to estimate nonlinear neural responses and temporal integration windows across cortex with millisecond resolution. While our two-temporal channel model provides a significant improvement in predicting fMRI signals compared to other models, we acknowledge that it does not explain the entire variance of the data. Future research may build upon the present results and improve model predictions by incorporating additional nonlinearities and channels. In terms of nonlinearities, future research could examine if there are also adaptation effects in the transient channel by modeling transient responses to repeated vs. non repeated stimuli [<xref ref-type="bibr" rid="pcbi.1007011.ref049">49</xref>]. In terms of processing channels, combining the temporal encoding approach with models of spatial processing such as population receptive field models [<xref ref-type="bibr" rid="pcbi.1007011.ref050">50</xref>] and featural processing models [<xref ref-type="bibr" rid="pcbi.1007011.ref051">51</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref052">52</xref>] may be important for accounting for the remaining unexplained variance of fMRI responses. Further, encoding models with temporal, spatial, and featural components may be necessary to accurately predict brain responses to dynamic real-world visual inputs in higher-level regions [<xref ref-type="bibr" rid="pcbi.1007011.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref052">52</xref>].</p>
<p>Given the pervasive use of the standard GLM in fMRI research, our results have broad implications for fMRI studies of any part of the brain. We find that varying the timing of stimuli in the millisecond range has a substantial impact on the magnitude of fMRI responses. However, by estimating neural responses in millisecond resolution, we can accurately predict fMRI responses in second resolution for both brief and long visual stimuli. Thus, the temporal encoding approach we pioneered marks a transformative advancement in using fMRI to elucidate temporal processing in the brain as it links fMRI responses to the timescale of neural computations. In other words, our approach could be applied to study other brain regions, For example, neurons in auditory cortex are sensitive not only to the frequency of tones, but also to their timing and duration [<xref ref-type="bibr" rid="pcbi.1007011.ref053">53</xref>]. By varying the timing parameters of auditory stimuli and fitting a temporal (or spectral-temporal [<xref ref-type="bibr" rid="pcbi.1007011.ref054">54</xref>]) encoding model to brain responses, the framework we developed here could be used to uncover the shape and timing of neural impulse response functions that characterize auditory cortex, as well as temporal processing of complex stimuli such as speech and music [<xref ref-type="bibr" rid="pcbi.1007011.ref055">55</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref056">56</xref>].</p>
<p>Additionally, as parallel streams occur not just in the visual system but throughout the brain, our data raise the intriguing hypothesis that temporal processing may also segregate other brain systems such as auditory or somatosensory cortex. For example, temporal computations in the auditory ventral stream are thought to differ from those in the auditory dorsal stream [<xref ref-type="bibr" rid="pcbi.1007011.ref057">57</xref>], whereby the latter may be dominated by processing of auditory transients. Others have also suggested hemispheric differences in auditory cortex; in particular, that the temporal resolution of neural processing is higher in left than right auditory cortex [<xref ref-type="bibr" rid="pcbi.1007011.ref058">58</xref>]. These hypotheses can be explicitly tested by developing temporal encoding models for auditory cortex like the ones we have developed here for visual cortex.</p>
<p>Overall, our innovative approach offers a quantitative framework to identify functional and computational differences across cortex [<xref ref-type="bibr" rid="pcbi.1007011.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref060">60</xref>] in many domains such as audition [<xref ref-type="bibr" rid="pcbi.1007011.ref061">61</xref>] and working memory [<xref ref-type="bibr" rid="pcbi.1007011.ref062">62</xref>]. Importantly, the encoding approach can also be applied to study impairments in high-level abilities like reading [<xref ref-type="bibr" rid="pcbi.1007011.ref063">63</xref>] and mathematical processing [<xref ref-type="bibr" rid="pcbi.1007011.ref064">64</xref>] that require integrating visual information over space and time.</p>
<p>In sum, our results provide the first comprehensive computational model of temporal processing in high-level visual cortex. Our findings propose a fundamental new mechanism—temporal processing—that distinguishes visual processing streams. We propose that lateral category-selective regions process moment-to-moment visual transitions, but ventral category-selective regions respond to both sustained and transient components. Visual transients in ventral category-selective regions may reflect rapid detection of changes to the visual content at stimulus onset and a memory trace of a recent stimulus at stimulus offset, which together suggest a new role of transient processing in the visual system beyond processing of dynamic stimuli. Finally, the encoding approach we introduce underscores the importance of modeling brain responses with millisecond precision to better understand the underlying neural computations.</p>
</sec>
</sec>
<sec id="sec011" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec012">
<title>Ethics statement</title>
<p>The Stanford University Institutional Review Board approved of the study (Protocol #29458—Functional Neuroanatomy of High-Level Visual Cortex: A quantitative multi-model approach). We obtained written informed consent by each subject.</p>
</sec>
<sec id="sec013">
<title>Participants</title>
<p>Twelve participants (6 males, 6 females) with normal or corrected-to-normal vision participated in the main experiments (experiments 1–3). Each individual provided written informed consent and participated in two fMRI sessions: one session for experiments 1 and 2 and another session for experiment 3 and a functional localizer experiment [<xref ref-type="bibr" rid="pcbi.1007011.ref015">15</xref>]. Seven participants from the main experiments (3 males, 4 females) also underwent population receptive field (pRF) mapping [<xref ref-type="bibr" rid="pcbi.1007011.ref050">50</xref>] to define retinotopic cortical regions and another experiment to define human motion-sensitive area (hMT+) [<xref ref-type="bibr" rid="pcbi.1007011.ref065">65</xref>]. The Stanford Internal Review Board on Human Subjects Research approved all protocols.</p>
</sec>
<sec id="sec014">
<title>Temporal channels experiments</title>
<sec id="sec015">
<title>Visual stimuli</title>
<p>Stimuli consisted of well-controlled grayscale images of faces, bodies, and pseudowords (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>A</italic></xref>, <italic>right</italic>) used in our previous publications [<xref ref-type="bibr" rid="pcbi.1007011.ref015">15</xref>]. Stimuli were presented using an Eiki LC-WUL100L projector (resolution: 1920 x 1200; refresh rate: 60 Hz) that was controlled by an Apple MacBook Pro using MATLAB (<ext-link ext-link-type="uri" xlink:href="http://www.mathworks.com/" xlink:type="simple">http://www.mathworks.com/</ext-link>) and functions from Psychophysics Toolbox [<xref ref-type="bibr" rid="pcbi.1007011.ref066">66</xref>] (<ext-link ext-link-type="uri" xlink:href="http://psychtoolbox.org" xlink:type="simple">http://psychtoolbox.org</ext-link>). Participants viewed images through an auxiliary mirror mounted on the RF coil with stimuli spanning ~20° of visual angle in each dimension.</p>
</sec>
<sec id="sec016" sec-type="materials|methods">
<title>Experimental design</title>
<p>To develop a temporal encoding model for high-level visual cortex, we adapted a fMRI paradigm previously used to model contributions of sustained and transient temporal channels in early visual cortex [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>]. The three main experiments in this study all used the same stimuli, trial durations, and task but varied in the temporal presentation of the images. Critically, a 12-s baseline period (blank gray screen) always came before and after each trial. In all three experiments, participants were instructed to fixate on a small, central dot and respond by button press when it changed color (occurring randomly once every 2–14 s, 8 s on average).</p>
<p>Experiment 1 ‒ one continuous image per trial: Stimuli were shown in trials of varying durations (3, 5, 10, or 20 s per trial) in which a single image was shown for the entire trial. Across trial durations the number of stimuli and transients (at the onset and offset of each stimulus) are matched but the duration of stimulation varies (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>A</italic> and 1<italic>B</italic></xref>, <italic>blue</italic>). This experiment was designed to enable measurement of sustained responses as well as fMRI-adaptation for prolonged images [<xref ref-type="bibr" rid="pcbi.1007011.ref014">14</xref>].</p>
<p>Experiment 2 ‒ 30 flashed images per trial: used the same trial durations as experiment 1, but in each trial we presented 30 different images from the same category. Each image was shown for 33 ms and followed by a blank interstimulus interval (ISI). Across trial durations the number of stimuli, number of transients, and total duration of visual stimulation are matched, but the ISI between consecutive images varied. Each ISI was 67 ms in the 3-s trials, 133 ms in the 5-s trials, 300 ms in the 10-s trials, and 633 ms in the 20-s trials (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>A</italic> and 1<italic>B</italic></xref>, <italic>red</italic>).</p>
<p>Experiment 3 ‒ 30 longer images per trial: used the same design as experiment 2, except that in each trial we presented 30 images from the same category for longer durations with a constant ISI of 33 ms between images. Image durations varied across trials and were each shown for 67 ms in the 3-s trials, 133 ms in the 5-s trials, 300 ms in the 10-s trials, and 633 ms in the 20-s trials (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>A</italic> and 1<italic>B</italic></xref>, <italic>green</italic>).</p>
</sec>
<sec id="sec017">
<title>Data acquisition</title>
<p>Functional data were acquired using a simultaneous multi-slice EPI sequence with a multiplexing factor of 3 to obtain near whole-brain coverage with a TR of 1 s. Participants viewed four 270-s runs of each experiment. Each run of each experiment contained one instance of every permutation of stimulus category (face/body/word) and trial duration (3, 5, 10, or 20 s) presented in random order.</p>
</sec>
<sec id="sec018">
<title>Category localizer experiment</title>
<p>To functionally define cortical regions that respond preferentially to specific stimulus categories, we collected three 300-s runs of a standard fMRI category localizer experiment used in our previous publications [<xref ref-type="bibr" rid="pcbi.1007011.ref015">15</xref>]. Participants were instructed to fixate on a central dot and respond by button press when an image repeated randomly within a block. Code for the experiment is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/VPNL/fLoc" xlink:type="simple">https://github.com/VPNL/fLoc</ext-link>.</p>
</sec>
<sec id="sec019">
<title>pRF mapping and hMT+ localizer</title>
<p>To delineate retinotopic boundaries, we acquired four 200-s runs of pRF mapping [<xref ref-type="bibr" rid="pcbi.1007011.ref050">50</xref>] in a subset of participants from the main experiments. In this experiment, a bar with flickering black and white checkerboards swept across a circular aperture (40° × 40° of visual angle) in eight directions as participants performed a fixation task. To functionally define hMT+ in the same subset of participants, we collected one 300-s run of a fMRI motion localizer experiment as detailed in our prior publications [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref065">65</xref>].</p>
</sec>
<sec id="sec020">
<title>Magnetic resonance imaging (MRI)</title>
<p>MRI data were collected using a 3T GE Signa MR750 scanner at the Center for Cognitive and Neurobiological Imaging (CNI) at Stanford University.</p>
<p>fMRI: We used a Nova phase-array 32-channel head coil for the main experiments and functional localizer to obtain near whole-brain coverage (48 slices; resolution: 2.4 × 2.4 × 2.4 mm; one-shot T2*-sensitive gradient echo acquisition sequence: FOV = 192 mm, TE = 30 ms, TR = 1000 ms, and flip angle = 76°, multiplexing factor of 3). We also collected T1-weighted inplane images to align each participant’s functional data to their high-resolution whole brain anatomy.</p>
<p>For pRF mapping and the hMT+ localizer, we used a 16-channel visual array coil (28 slices; resolution: 2.4 × 2.4 × 2.4 mm; one-shot T2*-sensitive gradient echo acquisition sequence: FOV = 192 mm, TE = 30 ms, TR = 2000 ms, and flip angle = 77°) and collected T1-weighted inplane images in the same prescription.</p>
<p>Anatomical MRI: We acquired a whole-brain, anatomical volume in each participant using a Nova 32-channel head coil (resolution: 1 × 1 × 1 mm; T1-weighted BRAVO pulse sequence: FOV = 240 mm, TI = 450 ms, and flip angle = 12°).</p>
</sec>
</sec>
<sec id="sec021">
<title>Data analysis</title>
<p>Data were analyzed with MATLAB using code from vistasoft (<ext-link ext-link-type="uri" xlink:href="http://github.com/vistalab" xlink:type="simple">http://github.com/vistalab</ext-link>) and FreeSurfer (<ext-link ext-link-type="uri" xlink:href="http://freesurfer.net" xlink:type="simple">http://freesurfer.net</ext-link>). Code used for predicting fMRI responses using a temporal channels approach is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/VPNL/TemporalChannels" xlink:type="simple">https://github.com/VPNL/TemporalChannels</ext-link>.</p>
<sec id="sec022">
<title>Regions of interest (ROI) definition</title>
<p>Category-selective regions were defined in each participant’s native anatomical space at a common threshold (<italic>t</italic> &gt; 3, voxel level, uncorrected) using functional and anatomical criteria detailed in prior publications [<xref ref-type="bibr" rid="pcbi.1007011.ref015">15</xref>] (<xref ref-type="fig" rid="pcbi.1007011.g001">Fig 1<italic>C</italic></xref>). Face-selective ROIs (faces &gt; others) were defined bilaterally in the inferior occipital gyrus (IOG-faces, <italic>N</italic> = 10), posterior STS (pSTS-faces, <italic>N</italic> = 9), posterior fusiform gyrus (pFus-faces, <italic>N</italic> = 11), and mid fusiform gyrus (mFus-faces; <italic>N</italic> = 11). Body-selective ROIs (bodies &gt; others) were found bilaterally in the lateral occipital sulcus (LOS-bodies, <italic>N</italic> = 10), inferior temporal gyrus (ITG-bodies, <italic>N</italic> = 10), middle temporal gyrus (MTG-bodies, <italic>N</italic> = 11), and occipitotemporal sulcus (OTS, <italic>N</italic> = 10).</p>
<p>Visual areas V1 and hV4 were defined in each hemisphere in a subset of participant (<italic>N</italic> = 7) using data from the pRF mapping experiment. To match the visual field coverage of the stimuli in the main experiments, we restricted ROIs to only included voxels with pRF centers within the central 10°. We also defined bilateral hMT+ in the same subset of participants using data from the motion localizer experiment as in previous publications [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref065">65</xref>].</p>
</sec>
<sec id="sec023">
<title>Optimized two-temporal channel A+S model</title>
<p>To predict responses across all three experiments with a single model, we adapted an encoding approach introduced by prior studies [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref018">18</xref>], which models fMRI responses as the weighted sum of activity across separate sustained and transient temporal channels.</p>
<p>In the procedure illustrated in <xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3</xref>, we first predict neural activity in each channel by convolving the stimulus time course in millisecond resolution (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3<italic>A</italic></xref>) separately with the neural IRF for the sustained channel (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3<italic>B</italic></xref>, <italic>blue channel IRF</italic>) and the transient channel (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3<italic>B</italic></xref>, <italic>red channel IRF</italic>). The sustained channel is characterized by a monophasic <italic>IRF</italic><sub>S</sub> that generates a response for the entire duration of a stimulus followed by an adaptation nonlinearity. This is implemented by multiplying the predicted neural responses in the sustained channel by an exponential decay function beginning at the onset of each stimulus and extending until the onset of the following stimulus. In contrast, the transient channel is characterized by a biphasic <italic>IRF</italic><sub>T</sub> that generates a brief response at the onset and offset of an image [<xref ref-type="bibr" rid="pcbi.1007011.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1007011.ref040">40</xref>]. Here, convolved responses are passed through sigmoid nonlinearities that allow different levels of compression to be applied to the “on” and “off” responses. Then, the estimated neural responses for each channel are convolved with a hemodynamic response function (HRF) to generate a prediction of the fMRI response in each channel (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3<italic>C</italic></xref>). As such, there are neural nonlinearities in each channel of this model, but a linear relationship is assumed between the neural activity and BOLD responses. Finally, we use a GLM to solve for the contributions (<italic>β</italic> weights) of the sustained and transient channels, which reflect how much the predicted response from each channel is scaled before the responses of both channels are summed. Thus, the BOLD response to a stimulus can be expressed as
<disp-formula id="pcbi.1007011.e003">
<alternatives>
<graphic id="pcbi.1007011.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e003" xlink:type="simple"/>
<mml:math display="block" id="M3"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mtext>S</mml:mtext></mml:msub><mml:mo>{</mml:mo><mml:mo>[</mml:mo><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mo>⊗</mml:mo><mml:mi>I</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mtext>S</mml:mtext></mml:msub><mml:mo>)</mml:mo><mml:mo>·</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow/><mml:mrow><mml:mo>/</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mo>]</mml:mo><mml:mo>⊗</mml:mo><mml:mi>H</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi><mml:mo>}</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mo>⊤</mml:mo></mml:msub><mml:mo>{</mml:mo><mml:mo>[</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mo>⊗</mml:mo><mml:mi>I</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mtext>T</mml:mtext></mml:msub><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:mo>⊗</mml:mo><mml:mi>H</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi><mml:mo>}</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mi>x</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow> </mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives></disp-formula>
where <italic>β</italic><sub>S</sub> and <italic>β</italic><sub>T</sub> are the fitted response amplitudes for the sustained and transient channels, respectively; <italic>IRF</italic><sub>S</sub> and <italic>IRF</italic><sub>T</sub> are the impulse response functions for the sustained and transient channels, respectively; α determines the exponential decay at time <italic>t</italic> after stimulus onset; σ is a pointwise sigmoid nonlinearity, and <italic>HRF</italic> is the canonical hemodynamic response function.</p>
</sec>
<sec id="sec024">
<title>Modeling nonlinearities in the neural response</title>
<p>We model the IRFs for each channel (<xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3<italic>B</italic></xref>) using formulas detailed in our prior publications [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>]. Here, we optimize the IRF time constant τ for each region, and the other parameters (taken from Watson [<xref ref-type="bibr" rid="pcbi.1007011.ref040">40</xref>]) are held constant: κ = 1.33, <italic>n</italic><sub>1</sub> = 9, and <italic>n</italic><sub>2</sub> = 10.</p>
<p>Adaptation: To capture fMRI-adaptation [<xref ref-type="bibr" rid="pcbi.1007011.ref014">14</xref>] effects in the sustained channel, we use an exponential decay function, <italic>e</italic><sup><italic>−t</italic>/α</sup>, where <italic>t</italic> represents time after stimulus onset, and α indicates when the function declines to a proportion of 1/<italic>e</italic> (~37%) of the initial response.</p>
<p>Sigmoid nonlinearities: To allow different levels of compression to be applied to “on” and “off” responses in the transient channel, we optimize separate sigmoid nonlinearities for the onset and offset responses using cumulative Weibull distribution functions,
<disp-formula id="pcbi.1007011.e004">
<alternatives>
<graphic id="pcbi.1007011.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e004" xlink:type="simple"/>
<mml:math display="block" id="M4"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mo>−</mml:mo><mml:mi>x</mml:mi><mml:mo>/</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
where λ is a sigmoid scale parameter used in both onset and offset nonlinearities; <italic>k</italic><sub>on</sub> is a sigmoid shape parameter that controls the curvature of the onset compression function, and <italic>k</italic><sub>off</sub> is a shape parameter controlling curvature of the offset compression function. Smaller <italic>k</italic> values produce more compressive nonlinearities that elongate transient “on” and “off” responses compared to larger <italic>k</italic> values.</p>
</sec>
<sec id="sec025">
<title>Fitting and optimizing the two-temporal channel model</title>
<p>Since the HRF acts like a temporal low-pass filter, this allows resampling fMRI response predictors to the lower temporal resolution of the measured fMRI data (TR = 1 s) with minimal distortion. These resampled predictors are then compared with measured fMRI responses to estimate the contributions (<italic>β</italic> weights) of each channel for each category. To normalize the amplitude of predicted fMRI responses for the sustained and transient channels, we match the maximal height of predictors in the design matrix across the two channels. Finally, we used a GLM to estimate <italic>β</italic> weights of the sustained and transient channels for each stimulus category by comparing the predicted responses with the mean response time series of each ROI in each participant. To optimize the A+S model time constants (τ and α) and sigmoid parameters (λ, <italic>k</italic><sub>on</sub>, <italic>k</italic><sub>off</sub>) for each region, we used the constrained nonlinear optimization algorithm <italic>fmincon</italic> in MATLAB (<italic>Optimization procedures</italic>).</p>
</sec>
<sec id="sec026">
<title>Validating the optimized two-temporal channel model</title>
<p>We assessed the predictive power of the optimized two-temporal A+S channel model by testing how well it predicts responses from separate runs of data from all three experiments. We first generated predicted neural response time courses by coding the visual stimulation in the left-out runs and convolving it separately with the IRFs of the sustained and transient channels (optimized using a separate split of the data). We then applied the adaptation and sigmoid nonlinearities, which were also optimized with independent data (<xref ref-type="fig" rid="pcbi.1007011.g006">Fig 6</xref>). These transformed neural predictors were next convolved with the HRF and down-sampled to 1 s temporal resolution to match our fMRI acquisition. Finally, we multiplied each channel’s fMRI predictors with their respective <italic>β</italic> weights (estimated for each category in an independent split of the data) before summing the channel responses to predict fMRI responses. We then quantified how well the predicted responses matched the measured response across all data in the validation split.</p>
<p>Model performance was operationalized as cross-validated <italic>R</italic><sup>2</sup> (x-<italic>R</italic><sup>2</sup>), which indexes the proportion of variance explained by <italic>β</italic> weights and model parameters that were estimated from independent data. While similar to a typical <italic>R</italic><sup>2</sup> statistic, x-<italic>R</italic><sup>2</sup> can be negative when the residual variance of a poor model prediction exceeds the measured variance in the response. Quantification of x-<italic>R</italic><sup>2</sup> within each experiment is presented in <xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>D</italic>–4<italic>F</italic></xref> for OTS-bodies. Performance averaged across all three experiments is shown in <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3</xref>–<xref ref-type="supplementary-material" rid="pcbi.1007011.s005">S5</xref> Figs for all regions.</p>
</sec>
<sec id="sec027">
<title>Testing alternative model architectures</title>
<p>To compare with the performance of our optimized two-temporal channel A+S model with alternatives, we tested five single-channel and three dual-channel models (Figs <xref ref-type="fig" rid="pcbi.1007011.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1007011.g004">4</xref>, <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3</xref>–<xref ref-type="supplementary-material" rid="pcbi.1007011.s005">S5</xref> Figs).</p>
<p>General linear model (GLM): To first benchmark our model against a common GLM approach [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>], we tested a linear model that predicts fMRI responses with a single convolution of the stimulus with the canonical HRF.</p>
<p>Balloon model (B model): To examine if responses in high-level visual cortex can be explained by a nonlinear hemodynamic model, we implemented the balloon model proposed by Buxton an colleagues [<xref ref-type="bibr" rid="pcbi.1007011.ref007">7</xref>] using standard parameters detailed in prior publications [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>].</p>
<p>Linear sustained channel (L model): Similar to the GLM approach [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>] but with two stages of convolution, we tested a single-channel model with a linear sustained channel,
<disp-formula id="pcbi.1007011.e006">
<alternatives>
<graphic id="pcbi.1007011.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mrow><mml:mi>β</mml:mi><mml:mspace width="2pt"/><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>stimulus</mml:mtext><mml:mo>⊗</mml:mo><mml:mi>I</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mtext>S</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>⊗</mml:mo><mml:mi>H</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where <italic>β</italic> is a fitted response amplitude; <italic>IRF</italic><sub>S</sub> is the impulse response function for the sustained channel, and <italic>HRF</italic> is the canonical HRF.</p>
<p>Sustained channel with compressive temporal summation (CTS, <xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4</xref>, <xref ref-type="supplementary-material" rid="pcbi.1007011.s002">S2</xref>–<xref ref-type="supplementary-material" rid="pcbi.1007011.s005">S5</xref> Figs): We also implemented a model proposed by Zhou et al. [<xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>] composed of sustained channel with a compressive static power law,
<disp-formula id="pcbi.1007011.e007">
<alternatives>
<graphic id="pcbi.1007011.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mrow><mml:mi>β</mml:mi><mml:mspace width="2pt"/><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mtext>stimulus</mml:mtext><mml:mo>⊗</mml:mo><mml:mi>I</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mtext>S</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>ε</mml:mo></mml:msup><mml:mo>⊗</mml:mo><mml:mi>H</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where ε is an optimized compression parameter ranging from 0–1.</p>
<p>Sustained channel with adaptation (A model): Identical to the sustained channel shown in <xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3</xref> (blue), we tested a model composed of a single sustained channel with adaptation,
<disp-formula id="pcbi.1007011.e008">
<alternatives>
<graphic id="pcbi.1007011.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mrow><mml:mi>β</mml:mi><mml:mspace width="2pt"/><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mtext>stimulus</mml:mtext><mml:mo>⊗</mml:mo><mml:mi>I</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mtext>S</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mspace width="4pt"/><mml:mo>·</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow/><mml:mrow><mml:mo>/</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:msup><mml:mo>⊗</mml:mo><mml:mi>H</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where α determines the exponential decay at <italic>t</italic> seconds after the onset of a stimulus.</p>
<p>Transient channel with sigmoid nonlinearity (S model; <xref ref-type="supplementary-material" rid="pcbi.1007011.s006">S6 Fig</xref>): Identical to the transient channel shown in <xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3</xref> (red), we also tested a single-channel model composed of a transient channel with the same sigmoid nonlinearities described above,
<disp-formula id="pcbi.1007011.e009">
<alternatives>
<graphic id="pcbi.1007011.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mrow><mml:mi>β</mml:mi><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mo>⊗</mml:mo><mml:mi>I</mml:mi><mml:mi>R</mml:mi><mml:msub><mml:mi>F</mml:mi><mml:mtext>T</mml:mtext></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>⊗</mml:mo><mml:mi>H</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives>
</disp-formula>
where <italic>IRF</italic><sub>T</sub> is the impulse response function for the transient channel and σ is a pointwise nonlinearity composed of separate sigmoid functions for onset and offset responses.</p>
<p>Alternative dual-channel models (L+Q, C+Q, and A+Q models): To compare the optimized two-temporal channel model shown in <xref ref-type="fig" rid="pcbi.1007011.g003">Fig 3</xref> (A+S model) to alternative dual-channel models, we tested three variants of our model that all use a transient channel with a quadratic (Q) nonlinearity (squaring) but apply different nonlinearities in the sustained channel (<xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3<italic>A</italic> Fig</xref>). Combining different combinations of the sustained and transient channels described above, we compared two-channel models composed of a transient channel and either a linear sustained channel (L+Q model), a sustained channel with CTS (C+Q model), or a sustained channel with adaptation (A+Q model).</p>
</sec>
<sec id="sec028">
<title>Optimization procedures</title>
<p>For all models with a neural IRF, we optimized a single time constant, τ, using formulas described in our prior publications [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>]. For models with adaption in the sustained channel (A and A+S), we also optimized an exponential time constant (α). For models with compressive temporal summation (CTS and C+Q models), we instead optimized an exponential compression parameter (ε). For models with a sigmoid nonlinearity in the transient channel (S and A+S models), we optimized three sigmoid parameters (λ, <italic>k</italic><sub>on</sub>, <italic>k</italic><sub>off</sub>). To optimize model parameters, we used the nonlinear optimization algorithm <italic>fmincon</italic> in MATLAB with the following constraints: τ = 4‒20 ms, α = 10‒40 s, ε = 0.01‒1, λ = 0.01‒0.5, <italic>k</italic><sub>on</sub> = 0.1‒6, and <italic>k</italic><sub>off</sub> = 0.1‒6. The initial values passed to the optimizer for each parameter were τ = 4.93 ms, α = 20 s, ε = 0.1, λ = 0.1, <italic>k</italic><sub>on</sub> = 3, and <italic>k</italic><sub>off</sub> = 3. The cross-validation performance of each model averaged across all three experiments is shown in <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3<italic>B</italic> Fig</xref> for category-selective regions in VTC and LTC and in <xref ref-type="supplementary-material" rid="pcbi.1007011.s004">S4</xref> and <xref ref-type="supplementary-material" rid="pcbi.1007011.s005">S5</xref> Figs for other regions.</p>
</sec>
<sec id="sec029">
<title>Statistical analyses</title>
<p><italic>Model-free ROI comparison</italic>. To examine differences in the patterns of response between ventral and lateral body-selective regions in <xref ref-type="fig" rid="pcbi.1007011.g002">Fig 2<italic>B</italic> and 2<italic>C</italic></xref> using a model-free approach, we measured in each participant and region the peak response amplitude to body stimuli for each temporal condition. Then we compared these peaks across regions and conditions using a three-way repeated measure analysis of variance (ANOVA) with factors of trial duration (1, 3, 5, or 10 s), experiment (experiment 1, 2, or 3), and ROI (OTS-bodies vs. MTG-bodies).</p>
</sec>
<sec id="sec030">
<title>Model comparison</title>
<p>To test for differences in model cross-validation performance across regions in VTC and LTC, we used a two-way repeated measures ANOVA with factors of model and region (comparing models and regions shown in <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3<italic>B</italic> Fig</xref>). We then used post-hoc paired two-tailed <italic>t</italic>-tests to compare the x-<italic>R</italic><sup>2</sup> of our model with others. <xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>D</italic>–4<italic>F</italic></xref> contrasts the performance of our model (A+S) in OTS-bodies against three other models (GLM, CTS, L+Q) for each experiment individually. <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3</xref>–<xref ref-type="supplementary-material" rid="pcbi.1007011.s005">S5</xref> Figs contrast the performance of our model averaged across all three experiments vs. every other model for each region. To assess the level of noise in measurements from different brain regions, we also calculated a noise ceiling for each ROI using the inter-trial variability of responses for each condition as described in our prior publications [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>]. The noise ceiling estimate for OTS-bodies in each experiment is plotted in <xref ref-type="fig" rid="pcbi.1007011.g004">Fig 4<italic>D</italic>–4<italic>F</italic></xref>, and the average noise ceiling across all three experiments is plotted in <xref ref-type="supplementary-material" rid="pcbi.1007011.s003">S3</xref>–<xref ref-type="supplementary-material" rid="pcbi.1007011.s005">S5</xref> Figs.</p>
</sec>
<sec id="sec031">
<title>Parameter comparison</title>
<p>After establishing the validity of our model, we used paired two-tailed <italic>t</italic>-tests to compare <italic>β</italic> weights estimated by the A+S model for each region’s preferred category vs. average contributions for nonpreferred categories, separately for the sustained and transient channels. To test whether selectivity in the two channels differs across regions preferring bodies and faces in either VTC or LTC, we also used two-way ANOVAs with factors of channel (sustained/transient) and preferred category (bodies/faces) on the difference in channel weights for preferred vs. nonpreferred categories (contrast effect size, CES; <xref ref-type="fig" rid="pcbi.1007011.g005">Fig 5</xref>). To examine whether the proportion of response attributed to sustained vs. transient channels differs across processing streams, stimulus categories, or regions preferring different categories, we then used a three-way ANOVA on channel contribution ratios, <inline-formula id="pcbi.1007011.e005"><alternatives><graphic id="pcbi.1007011.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007011.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mo>|</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:math></alternatives></inline-formula>, for each category with factors of stream (ventral/lateral), stimulus (faces/bodies/words), and preferred category (bodies/faces).</p>
</sec>
</sec>
</sec>
<sec id="sec032">
<title>Supporting information</title>
<supplementary-material id="pcbi.1007011.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Responses to time-varying stimuli in occipital, ventral, and lateral regions of interest.</title>
<p>Measured responses in occipital (V1, LOS-bodies, IOG-faces), ventral (hV4, OTS-bodies, mFus-faces), and lateral (hMT+, MTG-bodies, pSTS-faces) regions of interest in experiment 1 (<italic>blue</italic>), experiment 2 (<italic>red</italic>), and experiment 3 (<italic>green</italic>) averaged across all three stimulus categories. <italic>Lines</italic>: mean response time series across participants; <italic>shaded areas</italic>: standard error of the mean (SEM) across participants; <italic>Horizontal black bars</italic>: trial duration.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007011.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Comparison of temporal encoding models in OTS-bodies.</title>
<p>(A-C) Responses and model predictions for body images in OTS-bodies for each experiment (<italic>left</italic>) with estimated <italic>β</italic> weights for each model (<italic>right</italic>). <italic>White curve</italic>: mean response across 10 participants. <italic>Shaded gray</italic>: standard deviation across participants. <italic>Black curve</italic>: overall model prediction. <italic>Horizontal black bar</italic>: trial duration. (<italic>A</italic>) Predictions of a general linear model (GLM) [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>]. (<italic>B</italic>) Predictions of a model with compressive temporal summation (CTS) [<xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>]. (<italic>C</italic>) Predictions of the two-temporal channel L+Q model with linear sustained channel and quadratic transient channel. <italic>Blue curve</italic>: predicted response from the sustained channel. <italic>Red curve</italic>: predicted response from the transient channel: <italic>Black curve</italic>: sum of responses from both channels. In the continuous (left) and flashed images (middle) experiments the model’s prediction (black) is obscured by the response of a single channel, as the other channel’s contribution is negligible.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007011.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Comparison of temporal encoding models across high-level visual cortex.</title>
<p>(<italic>A</italic>) Alternative models of sustained (<italic>blue</italic>) and transient (<italic>red</italic>) channels. Schematic depicts neural response predictions generated by different implementations of each channel for both a brief (67 ms) and long (3 s) stimulus. Sustained channel models: <italic>L</italic>, a linear sustained channel; <italic>CTS</italic>, a sustained channel with compressive temporal summation [<xref ref-type="bibr" rid="pcbi.1007011.ref006">6</xref>]; <italic>A</italic>, a sustained channel with adaptation [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>]. Transient channel models: <italic>Q</italic>, a transient channel with a quadratic (squaring) nonlinearity; <italic>S</italic>, a transient channel with a sigmoid nonlinearity. (<italic>B</italic>) Comparison of model performance (cross-validated <italic>R</italic><sup>2</sup>) in each region averaged across all three experiments. Hemodynamic models: <italic>L</italic>, same as in (a); <italic>B</italic>, balloon model [<xref ref-type="bibr" rid="pcbi.1007011.ref007">7</xref>]. Single-channel neural models: <italic>CTS</italic>, <italic>A</italic>, and <italic>S</italic>, same as in (a). Two-channel neural models: <italic>L+Q</italic>, a linear sustained channel and a transient channel with a quadratic nonlinearity [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>]; <italic>C+Q</italic>, a sustained channel with compressive temporal summation and a transient channel with a quadratic nonlinearity; <italic>A+Q</italic>, a sustained channel with adaptation and a transient channel with a quadratic nonlinearity; <italic>A+S</italic>, a sustained channel with adaptation and a transient channel with a sigmoid nonlinearity. Cross-validated <italic>R</italic><sup>2</sup> significantly differs across models in all four regions (significant main effect of model type, <italic>F</italic>s &gt; 6.80, <italic>P</italic>s &lt; .001, one-way repeated measures ANOVA for each region). Asterisks denote models with significantly different performance compared to the A+S model, <italic>p</italic>&lt;0.05.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007011.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Contributions of transient and sustained temporal channels across early and intermediate visual areas.</title>
<p>(<italic>A</italic>) Contributions (<italic>β</italic> weights) of transient (<italic>x</italic> axis) and sustained (<italic>y</italic> axis) channels for each stimulus category estimated by the two-temporal channel A+S model in V1, hV4, and hMT+. Crosses span ±1 SEM across participants in each axis, and <italic>β</italic> were solved by fitting the model using data concatenated across all experiments. Data show average model weights across all splits of the data for each participant. <italic>Red</italic>: response to faces. <italic>Blue</italic>: response to bodies. <italic>Gray</italic>: response to words. <italic>Dashed gray</italic>: identity line (<italic>β</italic><sub>S</sub> = <italic>β</italic><sub>T</sub>). (<italic>B</italic>) Comparison of model performance (cross-validated <italic>R</italic><sup>2</sup>) in each region averaged across all three experiments. Hemodynamic models: <italic>L</italic> and <italic>B</italic>. Single-channel neural models: <italic>CTS</italic>, <italic>A</italic>, and <italic>S</italic>. Two-channel neural models: <italic>L+Q</italic> [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>], <italic>C+Q</italic>, <italic>A+Q</italic>, <italic>and A+S</italic>. Cross-validated <italic>R</italic><sup>2</sup> significantly differs across models in all three regions (significant main effect of model type, <italic>F</italic>s &gt; 16.45, <italic>P</italic>s &lt; .001, one-way repeated measures ANOVA for each region). Asterisks denote models with significantly different performance vs. the A+S model.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007011.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.s005" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Contributions of transient and sustained temporal channels across other face- and body-selective regions.</title>
<p>(<italic>A</italic>) Contributions (<italic>β</italic> weights) of transient (<italic>x</italic> axis) and sustained (<italic>y</italic> axis) channels for each stimulus category estimated by the two-temporal channel A+S model. Crosses span ±1 SEM across participants in each axis, and <italic>β</italic> were solved by fitting the model using data concatenated across all experiments. Data show average model <italic>β</italic> weights across all splits of the data for each participant. <italic>Red</italic>: response to faces. <italic>Blue</italic>: response to bodies. <italic>Gray</italic>: response to words. <italic>Dashed gray</italic>: identity line (<italic>β</italic><sub>S</sub> = <italic>β</italic><sub>T</sub>). (<italic>B</italic>) Comparison of model performance (cross-validated <italic>R</italic><sup>2</sup>) in each region averaged across all three experiments. Hemodynamic models: <italic>L</italic> and <italic>B</italic>. Single-channel neural models: <italic>CTS</italic>, <italic>A</italic>, and <italic>S</italic>. Two-channel neural models: <italic>L+Q</italic> [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>], <italic>C+Q</italic>, <italic>A+Q</italic>, <italic>and A+S</italic>. Cross-validated <italic>R</italic><sup>2</sup> significantly differs across models in all four regions (significant main effect of model type, <italic>F</italic>s &gt; 36.00, <italic>P</italic>s &lt; .001, one-way repeated measures ANOVA for each region). Asterisks denote models with significantly different performance vs. the A+S model, <italic>p</italic>&lt;0.05.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007011.s006" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.s006" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>Single-channel model with transient channel and sigmoid nonlinearity applied to OTS-bodies.</title>
<p>(A-C) Responses for body images in OTS-bodies and predictions of a model with a transient channel, but no sustained channel. <italic>White curve</italic>: mean response across 10 participants. <italic>Shaded gray</italic>: standard deviation across participants. <italic>Black</italic>: predicted response from the transient channel: <italic>Inset</italic>: <italic>mean</italic> contribution (<italic>β</italic> weight) for the transient channel ±1 SEM across participants. (<italic>A</italic>) Experiment 1 data, 1 continuous image per trial. (<italic>B</italic>) Experiment 2 data, 30 flashed images per trial. (<italic>C</italic>) Experiment 3 data, 30 longer images per trial. (D-F) Model comparison. Bars show the performance of various models for each experiment presented in (A-C). Models are fit using runs from all three experiments, and cross-validation performance (x-<italic>R</italic><sup>2</sup>) is calculated in left-out data from each experiment separately. (<italic>D</italic>) Experiment 1. (<italic>E</italic>) Experiment 2. (<italic>F</italic>) Experiment 3. Single-channel models: G<italic>LM</italic>, general linear model [<xref ref-type="bibr" rid="pcbi.1007011.ref008">8</xref>]; <italic>A</italic>, a sustained channel with adaptation; <italic>S</italic>, a transient channel with a sigmoid nonlinearities; <italic>A+S</italic>: a sustained channel with adaptation and a transient channel with sigmoid nonlinearities. Cross-validated <italic>R</italic><sup>2</sup> significantly differs across models [significant main effect of model type, <italic>F</italic><sub>6, 54</sub> = 21.88, <italic>P</italic> &lt; .001, two-way repeated measures ANOVA with factors of model type (GLM/A/S/A+S) and experiment (1/2/3)]. Asterisks denote models with significantly different performance compared to A+S (paired <italic>t</italic>-tests comparing x-<italic>R</italic><sup>2</sup> of each model vs. A+S in each experiment).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007011.s007" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007011.s007" xlink:type="simple">
<label>S7 Fig</label>
<caption>
<title>Contributions of transient and sustained temporal channels across word-selective regions.</title>
<p>(<italic>A</italic>) Contributions (<italic>β</italic> weights) of transient (<italic>x</italic> axis) and sustained (<italic>y</italic> axis) channels for each stimulus category estimated by the two-temporal channel A+S model in additional word-selective regions. Crosses span ±1 SEM across participants in each axis, and <italic>β</italic> were solved by fitting the model using data concatenated across all experiments. Data show average model weights across all splits of the data for each participant. <italic>Red</italic>: response to faces. <italic>Blue</italic>: response to bodies. <italic>Gray</italic>: response to words. <italic>Dashed gray</italic>: identity line (<italic>β</italic><sub>S</sub> = <italic>β</italic><sub>T</sub>). (<italic>B</italic>) Comparison of model performance (cross-validated <italic>R</italic><sup>2</sup>) in each region averaged across all three experiments. Hemodynamic models: <italic>L</italic> and <italic>B</italic>. Single-channel neural models: <italic>CTS</italic>, <italic>A</italic>, and <italic>S</italic>. Two-channel neural models: <italic>L+Q</italic> [<xref ref-type="bibr" rid="pcbi.1007011.ref005">5</xref>], <italic>C+Q</italic>, <italic>A+Q</italic>, <italic>and A+S</italic>. Cross-validated <italic>R</italic><sup>2</sup> significantly differs across models in all three regions (significant main effect of model type, <italic>F</italic>s &gt; 10.17, <italic>P</italic>s &lt; .001, one-way repeated measures ANOVA for each region). Asterisks denote models with significantly different performance vs. the A+S model, &lt;0.05.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Jon Winawer and Jing Zhou for fruitful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1007011.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmolesky</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hanes</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Thompson</surname> <given-names>KG</given-names></name>, <name name-style="western"><surname>Leutgeb</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schall</surname> <given-names>JD</given-names></name>, <etal>et al</etal>. <article-title>Signal timing across the macaque visual system</article-title>. <source>J Neurophysiol</source>. <year>1998</year>;<volume>79</volume>(<issue>6</issue>):<fpage>3272</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1998.79.6.3272" xlink:type="simple">10.1152/jn.1998.79.6.3272</ext-link></comment> <object-id pub-id-type="pmid">9636126</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>De Valois</surname> <given-names>RL</given-names></name>, <name name-style="western"><surname>Cottaris</surname> <given-names>NP</given-names></name>. <article-title>Inputs to directionally selective simple cells in macaque striate cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1998</year>;<volume>95</volume>(<issue>24</issue>):<fpage>14488</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.95.24.14488" xlink:type="simple">10.1073/pnas.95.24.14488</ext-link></comment> <object-id pub-id-type="pmid">9826727</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Conway</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Livingstone</surname> <given-names>MS</given-names></name>. <article-title>Space-time maps and two-bar interactions of different classes of direction-selective cells in macaque V-1</article-title>. <source>J Neurophysiol</source>. <year>2003</year>;<volume>89</volume>(<issue>5</issue>):<fpage>2726</fpage>–<lpage>42</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00550.2002" xlink:type="simple">10.1152/jn.00550.2002</ext-link></comment> <object-id pub-id-type="pmid">12740411</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nandy</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Mitchell</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Jadi</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Reynolds</surname> <given-names>JH</given-names></name>. <article-title>Neurons in Macaque Area V4 Are Tuned for Complex Spatio-Temporal Patterns</article-title>. <source>Neuron</source>. <year>2016</year>;<volume>91</volume>(<issue>4</issue>):<fpage>920</fpage>–<lpage>30</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2016.07.026" xlink:type="simple">10.1016/j.neuron.2016.07.026</ext-link></comment> <object-id pub-id-type="pmid">27499085</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stigliani</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Jeska</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Grill-Spector</surname> <given-names>K</given-names></name>. <article-title>Encoding model of temporal processing in human visual cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2017</year>;<volume>114</volume>(<issue>51</issue>):<fpage>E11047</fpage>–<lpage>E56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1704877114" xlink:type="simple">10.1073/pnas.1704877114</ext-link></comment> <object-id pub-id-type="pmid">29208714</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhou</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Benson</surname> <given-names>NC</given-names></name>, <name name-style="western"><surname>Kay</surname> <given-names>KN</given-names></name>, <name name-style="western"><surname>Winawer</surname> <given-names>J</given-names></name>. <article-title>Compressive Temporal Summation in Human Visual Cortex</article-title>. <source>J Neurosci</source>. <year>2018</year>;<volume>38</volume>(<issue>3</issue>):<fpage>691</fpage>–<lpage>709</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1724-17.2017" xlink:type="simple">10.1523/JNEUROSCI.1724-17.2017</ext-link></comment> <object-id pub-id-type="pmid">29192127</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Buxton</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Wong</surname> <given-names>EC</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>LR</given-names></name>. <article-title>Dynamics of blood flow and oxygenation changes during brain activation: the balloon model</article-title>. <source>Magn Reson Med</source>. <year>1998</year>;<volume>39</volume>(<issue>6</issue>):<fpage>855</fpage>–<lpage>64</lpage>. <object-id pub-id-type="pmid">9621908</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>Engel</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Glover</surname> <given-names>GH</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>Linear systems analysis of functional magnetic resonance imaging in human V1</article-title>. <source>J Neurosci</source>. <year>1996</year>;<volume>16</volume>(<issue>13</issue>):<fpage>4207</fpage>–<lpage>21</lpage>. <object-id pub-id-type="pmid">8753882</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huettel</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name>. <article-title>Evidence for a refractory period in the hemodynamic response to visual stimuli as measured by MRI</article-title>. <source>Neuroimage</source>. <year>2000</year>;<volume>11</volume>(<issue>5 Pt 1</issue>):<fpage>547</fpage>–<lpage>53</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.2000.0553" xlink:type="simple">10.1006/nimg.2000.0553</ext-link></comment> <object-id pub-id-type="pmid">10806040</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ogawa</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Stepnoski</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Zhu</surname> <given-names>XH</given-names></name>, <name name-style="western"><surname>Ugurbil</surname> <given-names>K</given-names></name>. <article-title>An approach to probe some neural systems interaction by functional MRI at neural time scale down to milliseconds</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2000</year>;<volume>97</volume>(<issue>20</issue>):<fpage>11026</fpage>–<lpage>31</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.97.20.11026" xlink:type="simple">10.1073/pnas.97.20.11026</ext-link></comment> <object-id pub-id-type="pmid">11005873</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Birn</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Saad</surname> <given-names>ZS</given-names></name>, <name name-style="western"><surname>Bandettini</surname> <given-names>PA</given-names></name>. <article-title>Spatial heterogeneity of the nonlinear dynamics in the FMRI BOLD response</article-title>. <source>Neuroimage</source>. <year>2001</year>;<volume>14</volume>(<issue>4</issue>):<fpage>817</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.2001.0873" xlink:type="simple">10.1006/nimg.2001.0873</ext-link></comment> <object-id pub-id-type="pmid">11554800</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mukamel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Harel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hendler</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Malach</surname> <given-names>R</given-names></name>. <article-title>Enhanced temporal non-linearities in human object-related occipito-temporal cortex</article-title>. <source>Cereb Cortex</source>. <year>2004</year>;<volume>14</volume>(<issue>5</issue>):<fpage>575</fpage>–<lpage>85</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhh019" xlink:type="simple">10.1093/cercor/bhh019</ext-link></comment> <object-id pub-id-type="pmid">15054073</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wager</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Vazquez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hernandez</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Noll</surname> <given-names>DC</given-names></name>. <article-title>Accounting for nonlinear BOLD effects in fMRI: parameter estimates and a model for prediction in rapid event-related studies</article-title>. <source>Neuroimage</source>. <year>2005</year>;<volume>25</volume>(<issue>1</issue>):<fpage>206</fpage>–<lpage>18</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2004.11.008" xlink:type="simple">10.1016/j.neuroimage.2004.11.008</ext-link></comment> <object-id pub-id-type="pmid">15734356</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gilaie-Dotan</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Nir</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Malach</surname> <given-names>R</given-names></name>. <article-title>Regionally-specific adaptation dynamics in human object areas</article-title>. <source>Neuroimage</source>. <year>2008</year>;<volume>39</volume>(<issue>4</issue>):<fpage>1926</fpage>–<lpage>37</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2007.10.010" xlink:type="simple">10.1016/j.neuroimage.2007.10.010</ext-link></comment> <object-id pub-id-type="pmid">18061482</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stigliani</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Weiner</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Grill-Spector</surname> <given-names>K</given-names></name>. <article-title>Temporal Processing Capacity in High-Level Visual Cortex Is Domain Specific</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>(<issue>36</issue>):<fpage>12412</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4822-14.2015" xlink:type="simple">10.1523/JNEUROSCI.4822-14.2015</ext-link></comment> <object-id pub-id-type="pmid">26354910</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McKeeff</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Remus</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>F</given-names></name>. <article-title>Temporal limitations in object processing across the human ventral visual pathway</article-title>. <source>J Neurophysiol</source>. <year>2007</year>;<volume>98</volume>(<issue>1</issue>):<fpage>382</fpage>–<lpage>93</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00568.2006" xlink:type="simple">10.1152/jn.00568.2006</ext-link></comment> <object-id pub-id-type="pmid">17493920</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gentile</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Rossion</surname> <given-names>B</given-names></name>. <article-title>Temporal frequency tuning of cortical face-sensitive areas for individual face perception</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>90</volume>:<fpage>256</fpage>–<lpage>65</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.11.053" xlink:type="simple">10.1016/j.neuroimage.2013.11.053</ext-link></comment> <object-id pub-id-type="pmid">24321556</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Horiguchi</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Nakadomari</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Misaki</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wandell</surname> <given-names>BA</given-names></name>. <article-title>Two temporal channels in human V1 identified using fMRI</article-title>. <source>Neuroimage</source>. <year>2009</year>;<volume>47</volume>(<issue>1</issue>):<fpage>273</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.03.078" xlink:type="simple">10.1016/j.neuroimage.2009.03.078</ext-link></comment> <object-id pub-id-type="pmid">19361561</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasson</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Vallines</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>N</given-names></name>. <article-title>A hierarchy of temporal receptive windows in human cortex</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>(<issue>10</issue>):<fpage>2539</fpage>–<lpage>50</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.5487-07.2008" xlink:type="simple">10.1523/JNEUROSCI.5487-07.2008</ext-link></comment> <object-id pub-id-type="pmid">18322098</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honey</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Thesen</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Donner</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Silbert</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Carlson</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Devinsky</surname> <given-names>O</given-names></name>, <etal>et al</etal>. <article-title>Slow cortical dynamics and the accumulation of information over long timescales</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>76</volume>(<issue>2</issue>):<fpage>423</fpage>–<lpage>34</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2012.08.011" xlink:type="simple">10.1016/j.neuron.2012.08.011</ext-link></comment> <object-id pub-id-type="pmid">23083743</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mattar</surname> <given-names>MG</given-names></name>, <name name-style="western"><surname>Kahn</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Thompson-Schill</surname> <given-names>SL</given-names></name>, <name name-style="western"><surname>Aguirre</surname> <given-names>GK</given-names></name>. <article-title>Varying Timescales of Stimulus Integration Unite Neural Adaptation and Prototype Formation</article-title>. <source>Curr Biol</source>. <year>2016</year>;<volume>26</volume>(<issue>13</issue>):<fpage>1669</fpage>–<lpage>76</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2016.04.065" xlink:type="simple">10.1016/j.cub.2016.04.065</ext-link></comment> <object-id pub-id-type="pmid">27321999</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Merigan</surname> <given-names>WH</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>. <article-title>How parallel are the primate visual pathways?</article-title> <source>Annu Rev Neurosci</source>. <year>1993</year>;<volume>16</volume>:<fpage>369</fpage>–<lpage>402</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.ne.16.030193.002101" xlink:type="simple">10.1146/annurev.ne.16.030193.002101</ext-link></comment> <object-id pub-id-type="pmid">8460898</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Nealey</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>DePriest</surname> <given-names>DD</given-names></name>. <article-title>Magnocellular and parvocellular contributions to responses in the middle temporal visual area (MT) of the macaque monkey</article-title>. <source>J Neurosci</source>. <year>1990</year>;<volume>10</volume>(<issue>10</issue>):<fpage>3323</fpage>–<lpage>34</lpage>. <object-id pub-id-type="pmid">2213142</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Essen</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Neural mechanisms of form and motion processing in the primate visual system</article-title>. <source>Neuron</source>. <year>1994</year>;<volume>13</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>. <object-id pub-id-type="pmid">8043270</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ferrera</surname> <given-names>VP</given-names></name>, <name name-style="western"><surname>Nealey</surname> <given-names>TA</given-names></name>, <name name-style="western"><surname>Maunsell</surname> <given-names>JH</given-names></name>. <article-title>Responses in macaque visual area V4 following inactivation of the parvocellular and magnocellular LGN pathways</article-title>. <source>J Neurosci</source>. <year>1994</year>;<volume>14</volume>(<issue>4</issue>):<fpage>2080</fpage>–<lpage>8</lpage>. <object-id pub-id-type="pmid">8158258</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaplan</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Benardete</surname> <given-names>E</given-names></name>. <article-title>The dynamics of primate retinal ganglion cells</article-title>. <source>Prog Brain Res</source>. <year>2001</year>;<volume>134</volume>:<fpage>17</fpage>–<lpage>34</lpage>. <object-id pub-id-type="pmid">11702542</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hubel</surname> <given-names>DH</given-names></name>, <name name-style="western"><surname>Wiesel</surname> <given-names>TN</given-names></name>. <article-title>Laminar and columnar distribution of geniculo-cortical fibers in the macaque monkey</article-title>. <source>J Comp Neurol</source>. <year>1972</year>;<volume>146</volume>(<issue>4</issue>):<fpage>421</fpage>–<lpage>50</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/cne.901460402" xlink:type="simple">10.1002/cne.901460402</ext-link></comment> <object-id pub-id-type="pmid">4117368</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schiller</surname> <given-names>PH</given-names></name>, <name name-style="western"><surname>Malpeli</surname> <given-names>JG</given-names></name>. <article-title>Functional specificity of lateral geniculate nucleus laminae of the rhesus monkey</article-title>. <source>J Neurophysiol</source>. <year>1978</year>;<volume>41</volume>(<issue>3</issue>):<fpage>788</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1978.41.3.788" xlink:type="simple">10.1152/jn.1978.41.3.788</ext-link></comment> <object-id pub-id-type="pmid">96227</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Derrington</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Lennie</surname> <given-names>P</given-names></name>. <article-title>Spatial and temporal contrast sensitivities of neurones in lateral geniculate nucleus of macaque</article-title>. <source>J Physiol</source>. <year>1984</year>;<volume>357</volume>:<fpage>219</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1113/jphysiol.1984.sp015498" xlink:type="simple">10.1113/jphysiol.1984.sp015498</ext-link></comment> <object-id pub-id-type="pmid">6512690</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bonda</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Petrides</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ostry</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Evans</surname> <given-names>A</given-names></name>. <article-title>Specific involvement of human parietal systems and the amygdala in the perception of biological motion</article-title>. <source>J Neurosci</source>. <year>1996</year>;<volume>16</volume>(<issue>11</issue>):<fpage>3737</fpage>–<lpage>44</lpage>. <object-id pub-id-type="pmid">8642416</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Puce</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Allison</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Asgari</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gore</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name>. <article-title>Differential sensitivity of human visual cortex to faces, letterstrings, and textures: a functional magnetic resonance imaging study</article-title>. <source>J Neurosci</source>. <year>1996</year>;<volume>16</volume>(<issue>16</issue>):<fpage>5205</fpage>–<lpage>15</lpage>. <object-id pub-id-type="pmid">8756449</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beauchamp</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>, <name name-style="western"><surname>Martin</surname> <given-names>A</given-names></name>. <article-title>Parallel visual motion processing streams for manipulable objects and human movements</article-title>. <source>Neuron</source>. <year>2002</year>;<volume>34</volume>(<issue>1</issue>):<fpage>149</fpage>–<lpage>59</lpage>. <object-id pub-id-type="pmid">11931749</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grossman</surname> <given-names>ED</given-names></name>, <name name-style="western"><surname>Blake</surname> <given-names>R</given-names></name>. <article-title>Brain Areas Active during Visual Perception of Biological Motion</article-title>. <source>Neuron</source>. <year>2002</year>;<volume>35</volume>(<issue>6</issue>):<fpage>1167</fpage>–<lpage>75</lpage>. <object-id pub-id-type="pmid">12354405</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fox</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Moon</surname> <given-names>SY</given-names></name>, <name name-style="western"><surname>Iaria</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Barton</surname> <given-names>JJ</given-names></name>. <article-title>The correlates of subjective perception of identity and expression in the face network: an fMRI adaptation study</article-title>. <source>Neuroimage</source>. <year>2009</year>;<volume>44</volume>(<issue>2</issue>):<fpage>569</fpage>–<lpage>80</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2008.09.011" xlink:type="simple">10.1016/j.neuroimage.2008.09.011</ext-link></comment> <object-id pub-id-type="pmid">18852053</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pitcher</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dilks</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Saxe</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Triantafyllou</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>. <article-title>Differential selectivity for dynamic versus static information in face-selective cortical regions</article-title>. <source>Neuroimage</source>. <year>2011</year>;<volume>56</volume>(<issue>4</issue>):<fpage>2356</fpage>–<lpage>63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2011.03.067" xlink:type="simple">10.1016/j.neuroimage.2011.03.067</ext-link></comment> <object-id pub-id-type="pmid">21473921</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Said</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Engell</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Todorov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>. <article-title>Distributed representations of dynamic facial expressions in the superior temporal sulcus</article-title>. <source>J Vis</source>. <year>2010</year>;<volume>10</volume>(<issue>5</issue>):<fpage>11</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/10.5.11" xlink:type="simple">10.1167/10.5.11</ext-link></comment> <object-id pub-id-type="pmid">20616141</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freiwald</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Duchaine</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Yovel</surname> <given-names>G</given-names></name>. <article-title>Face Processing Systems: From Neurons to Real-World Social Perception</article-title>. <source>Annu Rev Neurosci</source>. <year>2016</year>;<volume>39</volume>:<fpage>325</fpage>–<lpage>46</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-neuro-070815-013934" xlink:type="simple">10.1146/annurev-neuro-070815-013934</ext-link></comment> <object-id pub-id-type="pmid">27442071</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gilaie-Dotan</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Saygin</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Lorenzi</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Rees</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Behrmann</surname> <given-names>M</given-names></name>. <article-title>Ventral aspect of the visual form pathway is not critical for the perception of biological motion</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2015</year>;<volume>112</volume>(<issue>4</issue>):<fpage>E361</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1414974112" xlink:type="simple">10.1073/pnas.1414974112</ext-link></comment> <object-id pub-id-type="pmid">25583504</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weiner</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Grill-Spector</surname> <given-names>K</given-names></name>. <article-title>Sparsely-distributed organization of face and limb activations in human ventral temporal cortex</article-title>. <source>Neuroimage</source>. <year>2010</year>;<volume>52</volume>(<issue>4</issue>):<fpage>1559</fpage>–<lpage>73</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2010.04.262" xlink:type="simple">10.1016/j.neuroimage.2010.04.262</ext-link></comment> <object-id pub-id-type="pmid">20457261</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref040"><label>40</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Watson</surname> <given-names>AB</given-names></name>. <chapter-title>Temporal sensitivity</chapter-title>. In: <name name-style="western"><surname>Boff</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kaufman</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Thomas</surname> <given-names>J</given-names></name>, editors. <source>Handbook of Perception and Human Performance</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1986</year>.</mixed-citation></ref>
<ref id="pcbi.1007011.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weiner</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Grill-Spector</surname> <given-names>K</given-names></name>. <article-title>Neural representations of faces and limbs neighbor in human high-level visual cortex: evidence for a new organization principle</article-title>. <source>Psychol Res</source>. <year>2013</year>;<volume>77</volume>(<issue>1</issue>):<fpage>74</fpage>–<lpage>97</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00426-011-0392-x" xlink:type="simple">10.1007/s00426-011-0392-x</ext-link></comment> <object-id pub-id-type="pmid">22139022</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Courtney</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Ungerleider</surname> <given-names>LG</given-names></name>, <name name-style="western"><surname>Keil</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Haxby</surname> <given-names>JV</given-names></name>. <article-title>Transient and sustained activity in a distributed neural system for human working memory</article-title>. <source>Nature</source>. <year>1997</year>;<volume>386</volume>(<issue>6625</issue>):<fpage>608</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/386608a0" xlink:type="simple">10.1038/386608a0</ext-link></comment> <object-id pub-id-type="pmid">9121584</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fisch</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Privman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Ramot</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Harel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Nir</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Kipervasser</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Neural "ignition": enhanced activation linked to perceptual awareness in human ventral stream visual cortex</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>64</volume>(<issue>4</issue>):<fpage>562</fpage>–<lpage>74</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2009.11.001" xlink:type="simple">10.1016/j.neuron.2009.11.001</ext-link></comment> <object-id pub-id-type="pmid">19945397</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jacques</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Witthoft</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Weiner</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Foster</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Rangarajan</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Corresponding ECoG and fMRI category-selective signals in human ventral temporal cortex</article-title>. <source>Neuropsychologia</source>. <year>2016</year>;<volume>83</volume>:<fpage>14</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuropsychologia.2015.07.024" xlink:type="simple">10.1016/j.neuropsychologia.2015.07.024</ext-link></comment> <object-id pub-id-type="pmid">26212070</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Engell</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name>. <article-title>Selective attention modulates face-specific induced gamma oscillations recorded from ventral occipitotemporal cortex</article-title>. <source>J Neurosci</source>. <year>2010</year>;<volume>30</volume>(<issue>26</issue>):<fpage>8780</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1575-10.2010" xlink:type="simple">10.1523/JNEUROSCI.1575-10.2010</ext-link></comment> <object-id pub-id-type="pmid">20592199</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Davidesco</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Harel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ramot</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Kramer</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Kipervasser</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Andelman</surname> <given-names>F</given-names></name>, <etal>et al</etal>. <article-title>Spatial and object-based attention modulates broadband high-frequency responses across the human visual cortical hierarchy</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>(<issue>3</issue>):<fpage>1228</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.3181-12.2013" xlink:type="simple">10.1523/JNEUROSCI.3181-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23325259</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref047"><label>47</label><mixed-citation publication-type="other" xlink:type="simple">Zhou J, Benson NC, Kay K, Winawer J. Unifying Temporal Phenomena in Human Visual Cortex. bioRxiv. 2018; <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/108639" xlink:type="simple">https://doi.org/10.1101/108639</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1007011.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Avidan</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Harel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hendler</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ben-Bashat</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Zohary</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Malach</surname> <given-names>R</given-names></name>. <article-title>Contrast sensitivity in human visual areas and its relationship to object recognition</article-title>. <source>J Neurophysiol</source>. <year>2002</year>;<volume>87</volume>(<issue>6</issue>):<fpage>3102</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.2002.87.6.3102" xlink:type="simple">10.1152/jn.2002.87.6.3102</ext-link></comment> <object-id pub-id-type="pmid">12037211</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grill-Spector</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kourtzi</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>. <article-title>The lateral occipital complex and its role in object recognition</article-title>. <source>Vision Res</source>. <year>2001</year>;<volume>41</volume>(<issue>10–11</issue>):<fpage>1409</fpage>–<lpage>22</lpage>. <object-id pub-id-type="pmid">11322983</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dumoulin</surname> <given-names>SO</given-names></name>, <name name-style="western"><surname>Wandell</surname> <given-names>BA</given-names></name>. <article-title>Population receptive field estimates in human visual cortex</article-title>. <source>Neuroimage</source>. <year>2008</year>;<volume>39</volume>(<issue>2</issue>):<fpage>647</fpage>–<lpage>60</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2007.09.034" xlink:type="simple">10.1016/j.neuroimage.2007.09.034</ext-link></comment> <object-id pub-id-type="pmid">17977024</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kay</surname> <given-names>KN</given-names></name>, <name name-style="western"><surname>Naselaris</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Prenger</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Identifying natural images from human brain activity</article-title>. <source>Nature</source>. <year>2008</year>;<volume>452</volume>(<issue>7185</issue>):<fpage>352</fpage>–<lpage>5</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature06713" xlink:type="simple">10.1038/nature06713</ext-link></comment> <object-id pub-id-type="pmid">18322462</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Çukur</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Huth</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Nishimoto</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Gallant</surname> <given-names>JL</given-names></name>. <article-title>Functional subdomains within human FFA</article-title>. <source>J Neurosci</source>. <year>2013</year>;<volume>33</volume>(<issue>42</issue>):<fpage>16748</fpage>–<lpage>66</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1259-13.2013" xlink:type="simple">10.1523/JNEUROSCI.1259-13.2013</ext-link></comment> <object-id pub-id-type="pmid">24133276</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barton</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Venezia</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Saberi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Hickok</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Brewer</surname> <given-names>AA</given-names></name>. <article-title>Orthogonal acoustic dimensions define auditory field maps in human cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2012</year>;<volume>109</volume>(<issue>50</issue>):<fpage>20738</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1213381109" xlink:type="simple">10.1073/pnas.1213381109</ext-link></comment> <object-id pub-id-type="pmid">23188798</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Santoro</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Moerel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>De Martino</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Goebel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ugurbil</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Yacoub</surname> <given-names>E</given-names></name>, <etal>et al</etal>. <article-title>Encoding of natural sounds at multiple spectral and temporal resolutions in the human auditory cortex</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>1</issue>):<fpage>e1003412</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003412" xlink:type="simple">10.1371/journal.pcbi.1003412</ext-link></comment> <object-id pub-id-type="pmid">24391486</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Giraud</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Poeppel</surname> <given-names>D</given-names></name>. <article-title>Cortical oscillations and speech processing: emerging computational principles and operations</article-title>. <source>Nat Neurosci</source>. <year>2012</year>;<volume>15</volume>(<issue>4</issue>):<fpage>511</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3063" xlink:type="simple">10.1038/nn.3063</ext-link></comment> <object-id pub-id-type="pmid">22426255</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Norman-Haignere</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>NG</given-names></name>, <name name-style="western"><surname>McDermott</surname> <given-names>JH</given-names></name>. <article-title>Distinct Cortical Pathways for Music and Speech Revealed by Hypothesis-Free Voxel Decomposition</article-title>. <source>Neuron</source>. <year>2015</year>;<volume>88</volume>(<issue>6</issue>):<fpage>1281</fpage>–<lpage>96</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2015.11.035" xlink:type="simple">10.1016/j.neuron.2015.11.035</ext-link></comment> <object-id pub-id-type="pmid">26687225</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rauschecker</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Scott</surname> <given-names>SK</given-names></name>. <article-title>Maps and streams in the auditory cortex: nonhuman primates illuminate human speech processing</article-title>. <source>Nat Neurosci</source>. <year>2009</year>;<volume>12</volume>(<issue>6</issue>):<fpage>718</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2331" xlink:type="simple">10.1038/nn.2331</ext-link></comment> <object-id pub-id-type="pmid">19471271</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zatorre</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Belin</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Penhune</surname> <given-names>VB</given-names></name>. <article-title>Structure and function of auditory cortex: music and speech</article-title>. <source>Trends Cogn Sci</source>. <year>2002</year>;<volume>6</volume>(<issue>1</issue>):<fpage>37</fpage>–<lpage>46</lpage>. <object-id pub-id-type="pmid">11849614</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamins</surname> <given-names>DL</given-names></name>, <name name-style="western"><surname>Hong</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Cadieu</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Solomon</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Seibert</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>DiCarlo</surname> <given-names>JJ</given-names></name>. <article-title>Performance-optimized hierarchical models predict neural responses in higher visual cortex</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>2014</year>;<volume>111</volume>(<issue>23</issue>):<fpage>8619</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1403112111" xlink:type="simple">10.1073/pnas.1403112111</ext-link></comment> <object-id pub-id-type="pmid">24812127</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kriegeskorte</surname> <given-names>N</given-names></name>. <article-title>Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing</article-title>. <source>Annu Rev Vis Sci</source>. <year>2015</year>;<volume>1</volume>:<fpage>417</fpage>–<lpage>46</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-vision-082114-035447" xlink:type="simple">10.1146/annurev-vision-082114-035447</ext-link></comment> <object-id pub-id-type="pmid">28532370</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Werner</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Noppeney</surname> <given-names>U</given-names></name>. <article-title>The contributions of transient and sustained response codes to audiovisual integration</article-title>. <source>Cereb Cortex</source>. <year>2011</year>;<volume>21</volume>(<issue>4</issue>):<fpage>920</fpage>–<lpage>31</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhq161" xlink:type="simple">10.1093/cercor/bhq161</ext-link></comment> <object-id pub-id-type="pmid">20810622</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Druzgal</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>D’Esposito</surname> <given-names>M</given-names></name>. <article-title>Dissecting contributions of prefrontal cortex and fusiform face area to face working memory</article-title>. <source>J Cogn Neurosci</source>. <year>2003</year>;<volume>15</volume>(<issue>6</issue>):<fpage>771</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089892903322370708" xlink:type="simple">10.1162/089892903322370708</ext-link></comment> <object-id pub-id-type="pmid">14511531</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref063"><label>63</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Demb</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Boynton</surname> <given-names>GM</given-names></name>, <name name-style="western"><surname>Heeger</surname> <given-names>DJ</given-names></name>. <article-title>Brain activity in visual cortex predicts individual differences in reading performance</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1997</year>;<volume>94</volume>(<issue>24</issue>):<fpage>13363</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.94.24.13363" xlink:type="simple">10.1073/pnas.94.24.13363</ext-link></comment> <object-id pub-id-type="pmid">9371851</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Harvey</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>BP</given-names></name>, <name name-style="western"><surname>Petridou</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dumoulin</surname> <given-names>SO</given-names></name>. <article-title>Topographic representation of numerosity in the human parietal cortex</article-title>. <source>Science</source>. <year>2013</year>;<volume>341</volume>(<issue>6150</issue>):<fpage>1123</fpage>–<lpage>6</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1239052" xlink:type="simple">10.1126/science.1239052</ext-link></comment> <object-id pub-id-type="pmid">24009396</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weiner</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Grill-Spector</surname> <given-names>K</given-names></name>. <article-title>Not one extrastriate body area: using anatomical landmarks, hMT+, and visual field maps to parcellate limb-selective activations in human lateral occipitotemporal cortex</article-title>. <source>Neuroimage</source>. <year>2011</year>;<volume>56</volume>(<issue>4</issue>):<fpage>2183</fpage>–<lpage>99</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2011.03.041" xlink:type="simple">10.1016/j.neuroimage.2011.03.041</ext-link></comment> <object-id pub-id-type="pmid">21439386</object-id></mixed-citation></ref>
<ref id="pcbi.1007011.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brainard</surname> <given-names>DH</given-names></name>. <article-title>The Psychophysics Toolbox</article-title>. <source>Spat Vis</source>. <year>1997</year>;<volume>10</volume>(<issue>4</issue>):<fpage>433</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">9176952</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="other" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.1002264</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-15-01537</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Community Page</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Meta-research: Evaluation and Improvement of Research Methods and Practices</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Ioannidis</surname>
<given-names>John P. A.</given-names>
</name>
<xref rid="cor001" ref-type="corresp">*</xref>
<xref rid="aff001" ref-type="aff"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Fanelli</surname>
<given-names>Daniele</given-names>
</name>
<xref rid="aff001" ref-type="aff"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dunne</surname>
<given-names>Debbie Drake</given-names>
</name>
<xref rid="aff001" ref-type="aff"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Goodman</surname>
<given-names>Steven N.</given-names>
</name>
<xref rid="aff001" ref-type="aff"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Meta-Research Innovation Center at Stanford (METRICS), Stanford University, Stanford, California, United States of America</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">jioannid@stanford.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>2</day>
<month>10</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="collection">
<month>10</month>
<year>2015</year>
</pub-date>
<volume>13</volume>
<issue>10</issue>
<elocation-id>e1002264</elocation-id>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Ioannidis et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.1002264" xlink:type="simple"/>
<abstract>
<p>As the scientific enterprise has grown in size and diversity, we need empirical evidence on the research process to test and apply interventions that make it more efficient and its results more reliable. Meta-research is an evolving scientific discipline that aims to evaluate and improve research practices. It includes thematic areas of methods, reporting, reproducibility, evaluation, and incentives (how to do, report, verify, correct, and reward science). Much work is already done in this growing field, but efforts to-date are fragmented. We provide a map of ongoing efforts and discuss plans for connecting the multiple meta-research efforts across science worldwide.</p>
</abstract>
<abstract abstract-type="toc">
<p>Meta-research is the science of evaluating how to do, report, verify, correct, and reward scientific investigation. Many initiatives focus on these important issues, and more can be done.</p>
</abstract>
<funding-group>
<funding-statement>The authors received no specific funding for this work. METRICS is funded by a grant by the Laura and John Arnold Foundation.</funding-statement>
</funding-group>
<counts>
<fig-count count="1"/>
<table-count count="2"/>
<page-count count="7"/>
</counts>
</article-meta>
</front>
<body>
<sec id="sec001">
<title>Why Perform Research on Research?</title>
<p>Throughout the history of science, leading scientists have endeavoured to theorize and conduct research on fundamental aspects of the scientific method and to identify ways to implement it most efficiently. While focused subject matter questions and discoveries attract attention and accolades, the machinery of science relies greatly on progressive refinement of methods and improvement of theory verification processes. The large majority of the most used articles across science are about methodology [<xref rid="pbio.1002264.ref001" ref-type="bibr">1</xref>], and many scientific prizes are awarded for the development of techniques (e.g., Nobel prizes for PCR and MRI). Studying the scientific method in itself empirically is thus a topic of great potential value. Even though the scientific method has solid theoretical foundations and a long track record of successes, it is a continuing challenge to know how its basic principles (“systematic observation, measurement, and experiment, and the formulation, testing, and modification of hypotheses”, according to the Oxford English Dictionary) should be applied optimally in ways that can lead to faster, better, more accurate, and ultimately more useful results. In biomedical research in particular, lives can depend on the efficiency with which reliable evidence is generated and used.</p>
<p>This challenge is increasing, in parallel with the clear success of the scientific enterprise, which has grown in both size and diversity. Several million new research papers are published annually, and the number of publishing authors in 1996–2011 exceeded, according to one estimate, 15 million [<xref rid="pbio.1002264.ref002" ref-type="bibr">2</xref>]. Across biomedicine, the number of articles published is increasing, and the acceleration is becoming more prominent over time, e.g., Pubmed has indexed (as of July 6, 2015) 435,302 items published in 1994, 636,951 items published in 2004 (1.46-times those published 10 years ago in 1994), and 1,182,143 items published in 2014 (1.85-times those published 10 years ago in 2004). Moreover, the wide availability of big data and the accumulation of huge amounts of data (available often online) create new opportunities and bias threats for the production of scientific knowledge, and they may challenge existing notions of data sharing, data ownership, research planning, collaboration, and replication. Mounting evidence suggests that the reproducibility of research findings in biomedicine and other disciplines is alarmingly low, that the scientific process is frustratingly inefficient, and that the number of false-positives in the literature exceedingly high; this may be a by-product of the growing complexity and multiplicity of observations, hypotheses, tests, and modifications thereof [<xref rid="pbio.1002264.ref003" ref-type="bibr">3</xref>–<xref rid="pbio.1002264.ref008" ref-type="bibr">8</xref>]. In biomedicine, it has been estimated that 85% of the invested effort and resources are wasted because of a diverse array of inefficiencies [<xref rid="pbio.1002264.ref003" ref-type="bibr">3</xref>].</p>
<p>The geometric growth of the scientific corpus allows new opportunities for studying research practices with large-scale evidence and for testing empirically their effectiveness at producing the most reliable evidence. While one can theorize about biases (e.g., publication bias, reporting bias, selection bias, confounding, etc.), it is now possible to examine them across multiple studies and to think about ways to prevent or correct them. Many ideas and solutions have been proposed about how to strengthen the research record, including, but not limited to, registration of studies, improved standards for reporting of research, wider (even public) availability of raw data and protocols, sharing, prespecification of hypotheses, improved statistical tools and choice of rules of inference, reproducibility checks and adoption of a replication culture, team work and consortia-building, minimization of conflicts of interest, and more [<xref rid="pbio.1002264.ref009" ref-type="bibr">9</xref>].</p>
</sec>
<sec id="sec002">
<title>A Hot but Fragmented Scientific Discipline</title>
<p>Many scientists are already working on these solutions, because they realize that improving methods and practices within research is integral to their quest for better and more reliable research results in their own field. Some fields could benefit from the knowledge and experience that has accumulated in other fields where various solutions have been tested and applied. However, many scientists do not closely track what is happening in fields different from their own, even within their own broad discipline. Thus, independent fragmented efforts are made to solve what are intrinsically similar challenges, albeit in different manifestations and in different environments. It is possible that the best solutions may not be the same for all fields, e.g., preregistration of experimental protocols may not serve the ends of exploratory “blue sky” science in the same way it does for clinical trials. However, one needs to see the big picture to identify the relevant similarities and differences. A research effort is needed that cuts across all disciplines, drawing from a wide range of methodologies and theoretical frameworks, and yet shares a common objective; that of helping science progress faster by conducting scientific research on research itself. This is the field of meta-research.</p>
</sec>
<sec id="sec003">
<title>What Is Included in the Discipline of Meta-research?</title>
<p>As for all disciplines, multiple classifications are possible, and categories are inevitably overlapping. We believe it convenient to categorize meta-research into five major areas of interest: Methods, Reporting, Reproducibility, Evaluation, and Incentives. These correspond, respectively, with how to perform, communicate, verify, evaluate, and reward research. <xref rid="pbio.1002264.t001" ref-type="table">Table 1</xref> lists the issues that are covered under each theme and some delineation of specific interests. Many scientists are currently working on these various aspects of meta-research, motivated by the common objective to improve the scientific enterprise, but tend to do it in methodologic or disciplinary silos; unlike a physical and organic chemist, who both recognize they are chemists, these reformers within science may not recognize that they are all working within the domain of meta-research.</p>
<table-wrap id="pbio.1002264.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002264.t001</object-id>
<label>Table 1</label> <caption><title>Major themes covered by meta-research.</title></caption>
<alternatives>
<graphic id="pbio.1002264.t001g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002264.t001" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Meta-research area</th>
<th align="left" rowspan="1" colspan="1">Specific interests (nonexhaustive list)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><underline><bold>Methods</bold></underline>: "performing research"—study design, methods, statistics, research synthesis, collaboration, and ethics</td>
<td align="left" rowspan="1" colspan="1">Biases and questionable practices in conducting research, methods to reduce such biases, meta-analysis, research synthesis, integration of evidence, crossdesign synthesis, collaborative team science and consortia, research integrity and ethics</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><underline><bold>Reporting</bold></underline>: "communicating research"—reporting standards, study registration, disclosing conflicts of interest, information to patients, public, and policy-makers</td>
<td align="left" rowspan="1" colspan="1">Biases and questionable practices in reporting, explaining, disseminating and popularizing research, conflicts of interest disclosure and management, study registration and other bias-prevention measures, and methods to monitor and reduce such issues</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><underline><bold>Reproducibility</bold></underline>: "verifying research"—sharing data and methods, repeatability, replicability, reproducibility, and self-correction</td>
<td align="left" rowspan="1" colspan="1">Obstacles to sharing data and methods, replication studies, replicability and reproducibility of published research, methods to improve them, effectiveness of correction and self-correction of the literature, and methods to improve them</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><underline><bold>Evaluation</bold></underline>: "evaluating research"—prepublication peer review, postpublication peer review, research funding criteria, and other means of evaluating scientific quality</td>
<td align="left" rowspan="1" colspan="1">Effectiveness, costs, and benefits of old and new approaches to peer review and other science assessment methods, and methods to improve them</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><underline><bold>Incentives</bold></underline>: "rewarding research": promotion criteria, rewards, and penalties in research evaluation for individuals, teams, and institutions</td>
<td align="left" rowspan="1" colspan="1">Accuracy, effectiveness, costs, and benefits of old and new approaches to ranking and evaluating the performance, quality, value of research, individuals, teams, and institutions</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Given the types of questions addressed, meta-research interfaces with many other established disciplines. These include, but are not limited to, history and philosophy of science (epistemology), psychology and sociology of science, statistics, data science, informatics, evidence-based medicine (and evidence-based “X” in general), research synthesis methods (e.g., meta-analysis), journalology, scientometrics and bibliometrics, organizational and operations research, ethics, research integrity and accountability research, communication sciences, policy research, and behavioural economics.</p>
<p>Meta-research includes both theoretical and empirical investigation. The former uses analytical as well as computational methods, the latter yields descriptive evidence (e.g., surveys of biases in a given field), association and correlation observational analyses, and intervention studies (e.g., randomized trials assessing whether one research practice leads to better outcomes than another). Meta-research involves taking a bird’s eye view of science. For example, single meta-analyses that synthesize evidence on multiple studies on a specific question of interest are not within the primary remit of meta-research. However, the combination of data from multiple meta-analyses on multiple topics (“meta-epidemiology”) may offer insights about how common and how consistent certain biases are across a large field or multiple fields. This emphasis on the broader picture is typical of many meta-research investigations.</p>
<p>We are in the process of mapping the influential meta-research literature and identifying the key players in this burgeoning field. By an iterative process of search and manual inspection, we have compiled a search string comprising 79 terms (keywords, sentences, author identifiers) that capture with good efficiency the five thematic areas described above. A search in the Scopus database using these terms, followed by manual inspection and cross-checked selection by two of the authors (JPAI and DF), identified 851 meta-research–relevant publications (out of a starting list of 1,422) that have been published, across all disciplines, in the period January 1–May 16 2015 alone. Around three quarters of these records (<italic>n</italic> = 610) are classified by Scopus as research articles, conference papers, or reviews, and the rest as editorial material or letters. This preliminary “photograph” of the field suggests that meta-research is a growing and truly global enterprise (<xref rid="pbio.1002264.g001" ref-type="fig">Fig 1</xref>), even though our sample is likely to underestimate the true extent of the field, since it is not fully sensitive yet to detect all relevant papers, given the very wide variety of disciplines and nomenclature involved. Identifying the boundaries of any discipline, let alone those of a highly cross-disciplinary field, is a dynamic and somewhat arbitrary process, which requires continuous updates and refinements. Therefore, a list of meta-research literature and details of the search strategy used will be posted on <ext-link ext-link-type="uri" xlink:href="http://metrics.stanford.edu" xlink:type="simple">metrics.stanford.edu</ext-link>, where they will be regularly updated, expanded, and refined over time.</p>
<fig id="pbio.1002264.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002264.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Number of meta-research–related publications registered by the Scopus database between January 1 and May 16 2015, by country of corresponding author and by affiliation of any coauthor.</title>
<p>Countries are attributed based on corresponding or first author address (legend, from light yellow to red, respectively, to 1–5, 5–10, 10–20, 20–50, 50–230 publications). Blue dots indicate the 100 institutions most frequently listed amongst coauthors’ addresses. Dot size is proportional to number of papers (range: 2–37). Papers were selected for inclusion from an initial list of 1,422 papers retrieved from the Scopus database using a combination of search terms aimed at capturing the core areas described in <xref rid="pbio.1002264.t001" ref-type="table">Table 1</xref>. Of the 851 records selected for inclusion, country or affiliation data could not be retrieved for 102 Scopus records, which therefore are not included in the map. Search terms, literature lists, and further details are available at <ext-link ext-link-type="uri" xlink:href="http://metrics.stanford.edu" xlink:type="simple">metrics.stanford.edu</ext-link>. The map and plots therein were generated anew, using the packages ggmap and ggplot2 implemented in the open source statistical software R. <italic>Image Credit: Daniele Fanelli</italic></p>
</caption>
<graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002264.g001" position="float" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec004">
<title>Meta-research–Related Initiatives Worldwide</title>
<p><xref rid="pbio.1002264.t002" ref-type="table">Table 2</xref> shows an illustrative list of some existing initiatives that aim to address different portions of the meta-research agenda. This list is not complete, and the number of initiatives may continue to grow fast. The table aims only to give the reader a sense of the breadth of the various efforts that are ongoing. Many initiatives were launched only within the last few years. This diversity suggests that an effort is needed to better define and connect this rapidly growing discipline.</p>
<table-wrap id="pbio.1002264.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.1002264.t002</object-id>
<label>Table 2</label> <caption><title>A nonexhaustive list of initiatives that address various meta-research themes<xref rid="t002fn001" ref-type="table-fn"><sup>*</sup></xref>.</title></caption>
<alternatives>
<graphic id="pbio.1002264.t002g" position="float" mimetype="image" xlink:href="info:doi/10.1371/journal.pbio.1002264.t002" xlink:type="simple"/>
<table>
<colgroup span="1">
<col align="left" valign="middle" span="1"/>
<col align="left" valign="middle" span="1"/>
</colgroup>
<thead>
<tr>
<th align="left" rowspan="1" colspan="1">Initiative</th>
<th align="left" rowspan="1" colspan="1">Area of work (website)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" rowspan="1" colspan="1"><underline>METHODS</underline></td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Cochrane Collaboration</td>
<td align="left" rowspan="1" colspan="1">Systematic reviews of health care (<ext-link ext-link-type="uri" xlink:href="http://cochrane.org" xlink:type="simple">cochrane.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Campbell Collaboration</td>
<td align="left" rowspan="1" colspan="1">Systematic reviews of social science (<ext-link ext-link-type="uri" xlink:href="http://campbellcollaboration.org" xlink:type="simple">campbellcollaboration.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">James Lind Library</td>
<td align="left" rowspan="1" colspan="1">Evolution of fair tests of treatment (<ext-link ext-link-type="uri" xlink:href="http://jameslindlibrary.org" xlink:type="simple">jameslindlibrary.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Society for Clinical Trials</td>
<td align="left" rowspan="1" colspan="1">Clinical trials (<ext-link ext-link-type="uri" xlink:href="http://sctweb.org" xlink:type="simple">sctweb.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">SRSM</td>
<td align="left" rowspan="1" colspan="1">Methods for research synthesis (<ext-link ext-link-type="uri" xlink:href="http://srsm.org" xlink:type="simple">srsm.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">BioSharing</td>
<td align="left" rowspan="1" colspan="1">Standards for biology, natural, and life sciences (<ext-link ext-link-type="uri" xlink:href="http://biosharing.org" xlink:type="simple">biosharing.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Human Proteome Project</td>
<td align="left" rowspan="1" colspan="1">Collaboration center for proteome (<ext-link ext-link-type="uri" xlink:href="http://thehpp.org" xlink:type="simple">thehpp.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">NCPRE</td>
<td align="left" rowspan="1" colspan="1">Research ethics (<ext-link ext-link-type="uri" xlink:href="http://ethicscenter.csl.illinois.edu" xlink:type="simple">ethicscenter.csl.illinois.edu</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><underline>REPORTING</underline></td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov" xlink:type="simple">ClinicalTrials.gov</ext-link></td>
<td align="left" rowspan="1" colspan="1">Clinical trials registration (<ext-link ext-link-type="uri" xlink:href="http://clinicaltrials.gov" xlink:type="simple">clinicaltrials.gov</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">EQUATOR network</td>
<td align="left" rowspan="1" colspan="1">Reporting standards for research (<ext-link ext-link-type="uri" xlink:href="http://equator-network.org" xlink:type="simple">equator-network.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Sense About Science</td>
<td align="left" rowspan="1" colspan="1">Communicating research in public (<ext-link ext-link-type="uri" xlink:href="http://senseaboutscience.org" xlink:type="simple">senseaboutscience.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Health News Reviews</td>
<td align="left" rowspan="1" colspan="1">Expert review of science news stories (<ext-link ext-link-type="uri" xlink:href="http://healthnewsreview.org" xlink:type="simple">healthnewsreview.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><underline>REPRODUCIBILITY</underline></td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Center for Open Science</td>
<td align="left" rowspan="1" colspan="1">Open science in psychology and more (<ext-link ext-link-type="uri" xlink:href="http://centerforopenscience.org" xlink:type="simple">centerforopenscience.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">BITSS</td>
<td align="left" rowspan="1" colspan="1">Transparency in social sciences (<ext-link ext-link-type="uri" xlink:href="http://bitss.org" xlink:type="simple">bitss.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">BPS</td>
<td align="left" rowspan="1" colspan="1">Best practices in social sciences (<ext-link ext-link-type="uri" xlink:href="http://bps.stanford.edu" xlink:type="simple">bps.stanford.edu</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Political Science Replication</td>
<td align="left" rowspan="1" colspan="1">Reproducibility in political science (<ext-link ext-link-type="uri" xlink:href="http://politicalsciencereplication.com" xlink:type="simple">politicalsciencereplication.com</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">YODA</td>
<td align="left" rowspan="1" colspan="1">Sharing data from clinical research (<ext-link ext-link-type="uri" xlink:href="http://yoda.yale.edu" xlink:type="simple">yoda.yale.edu</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Neurovault</td>
<td align="left" rowspan="1" colspan="1">Data repository for PET and MRI maps (<ext-link ext-link-type="uri" xlink:href="http://neurovault.org" xlink:type="simple">neurovault.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">OpenfMRI</td>
<td align="left" rowspan="1" colspan="1">fMRI data repository (<ext-link ext-link-type="uri" xlink:href="http://openfmri.org" xlink:type="simple">openfmri.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">NIH repositories, examples:</td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">dbGAP</td>
<td align="left" rowspan="1" colspan="1">Raw data on genotype and phenotype (<ext-link ext-link-type="uri" xlink:href="http://ncbi.nlm.nih.gov/gap" xlink:type="simple">ncbi.nlm.nih.gov/gap</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">GEO</td>
<td align="left" rowspan="1" colspan="1">Functional genomics repository (<ext-link ext-link-type="uri" xlink:href="http://ncbi.nlm.nih.gov/geo" xlink:type="simple">ncbi.nlm.nih.gov/geo</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Science Exchange</td>
<td align="left" rowspan="1" colspan="1">Reproducibility checks (<ext-link ext-link-type="uri" xlink:href="http://validation.scienceexchange.com" xlink:type="simple">validation.scienceexchange.com</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><underline>EVALUATION</underline></td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Peer Review Congress</td>
<td align="left" rowspan="1" colspan="1">Evidence on peer review (<ext-link ext-link-type="uri" xlink:href="http://peerreviewcongress.org" xlink:type="simple">peerreviewcongress.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">Center for Scientific Integrity</td>
<td align="left" rowspan="1" colspan="1">Tracking retractions of scientific articles (<ext-link ext-link-type="uri" xlink:href="http://retractionwatch.com/the-center-for-scientific-integrity" xlink:type="simple">retractionwatch.com/the-center-for-scientific-integrity</ext-link></td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">PubMed Commons</td>
<td align="left" rowspan="1" colspan="1">Postpublication comments (<ext-link ext-link-type="uri" xlink:href="http://ncbi.nlm.nih.gov/pubmedcommons" xlink:type="simple">ncbi.nlm.nih.gov/pubmedcommons</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">ArXiv</td>
<td align="left" rowspan="1" colspan="1">Preprint article repository (<ext-link ext-link-type="uri" xlink:href="http://arxiv.org" xlink:type="simple">arxiv.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">ICMJE</td>
<td align="left" rowspan="1" colspan="1">Standards for journal publishing (<ext-link ext-link-type="uri" xlink:href="http://icmje.org" xlink:type="simple">icmje.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">COPE</td>
<td align="left" rowspan="1" colspan="1">Journal publication ethics (<ext-link ext-link-type="uri" xlink:href="http://publicationethics.org" xlink:type="simple">publicationethics.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">PubPeer</td>
<td align="left" rowspan="1" colspan="1">Peer comments on research (<ext-link ext-link-type="uri" xlink:href="http://pubpeer.com" xlink:type="simple">pubpeer.com</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">PEERE</td>
<td align="left" rowspan="1" colspan="1">New models for peer review (<ext-link ext-link-type="uri" xlink:href="http://www.peere.org/" xlink:type="simple">www.peere.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1"><underline>INCENTIVES</underline></td>
<td align="left" rowspan="1" colspan="1"/>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">REWARD</td>
<td align="left" rowspan="1" colspan="1">Reducing waste and rewarding diligence in research (<ext-link ext-link-type="uri" xlink:href="http://researchwaste.net" xlink:type="simple">researchwaste.net</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">AAAS</td>
<td align="left" rowspan="1" colspan="1">Science policy (<ext-link ext-link-type="uri" xlink:href="http://aaas.org" xlink:type="simple">aaas.org</ext-link>)</td>
</tr>
<tr>
<td align="left" rowspan="1" colspan="1">ICSU</td>
<td align="left" rowspan="1" colspan="1">International science policy (<ext-link ext-link-type="uri" xlink:href="http://icsu.org" xlink:type="simple">icsu.org</ext-link>)</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>*for clarity, each initiative has been grouped under one of the five themes of <xref rid="pbio.1002264.t001" ref-type="table">Table 1</xref>, but several of these initiatives cater to more than one of the five themes</p></fn>
<fn id="t002fn002"><p>AAAS: American Association for the Advancement of Science; BITSS: Berkeley Initiative for Transparency in the Social Sciences; BPS: Best Practices in Science; COPE: Committee on Publication Ethics; dbGAP: Database on Genotypes and Phenotypes; EQUATOR: Enhancing the quality and transparency of reporting; GEO: Gene Expression Omnibus; ICMJE: International Committee of Medical Journal Editors; ICSU: International Council for Science; NCPRE: National Center for Professional and Research Ethics; NIH: National Institutes of Health; REWARD: Reduce research waste and reward diligence; SRSM: Society for Research Synthesis Methodology; YODA: Yale University Open Data Access.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>The Meta-Research Innovation Center at Stanford (METRICS) is one such effort that we have undertaken, with the primary objective to connect the disparate elements of this field and enhance their synergy and collective efficiency towards the goal of improving published research. It does this through primary research and creation of a research and policy-focused network of meta-researchers around the world. METRICS has recruited a large number of faculty, from multiple disciplines within and outside biomedicine, and scholars and graduate students at Stanford, has created a seed grant research program to support innovative research ideas in this area, and has started building further this meta-research community through speaker series, curriculum development, regular workshops, and other events.</p>
<p>A major challenge for this center is to connect the much larger global community of meta-researchers and related stakeholders. As part of building and supporting this network, we plan to create an interactive online platform to inform and connect researchers working on these themes. No single center can cover this vast field alone, so we see METRICS as a partner and facilitator of the multiple other related scientific endeavors. A biannual meeting will help bring together scientists working in distant fields who are interested in improving research practices. The first of these meetings will take place at Stanford on November 19–20, 2015.</p>
<p>A central goal of this community is to provide evidence-based guidance on policy initiatives to improve research quality. Such evidence should come not only from observational but also from experimental studies and through dialogue and engagement with key stakeholders from the public and private sectors. The most ambitious and durable transformations will likely require considerable realignment of the reward and incentive system in science. Funding agencies, institutional leaders, scientific journals, and the mass media will all be important partners in ensuring that the best science is designed, conducted, analyzed, published, disseminated, and ultimately rewarded.</p>
</sec>
<sec id="sec005">
<title>Better Education in Better Research Practices</title>
<p>A strong educational curriculum and the development of training materials to equip researchers with the knowledge of best scientific practices will also be a critical component in accomplishing these goals. There is a need to train meta-researchers, in the same way we train immunologists or biologists or computer scientists, and not just expect that some scientists will keep finding their way into meta-research in somewhat random fashion. There is also a need to educate practicing scientists, not just meta-research specialists, on the importance of methods and rigorous, reproducible research practices. Most disciplinary training focuses on learning topical subject matter facts and technical skills that are field-specific and that can have a short half-life. Conversely, there is little training of future investigators and little continuing education of mature investigators on fundamental principles of research methods and practices. Beyond scientists, other key stakeholders, including media, journal editors, and funders can be educated on best research practices.</p>
<p>Building such an educational curriculum may require integrating best research practices modules with required Responsible Conduct of Research training and evaluations and collaborating with other scholars to share best practices and facilitate shared learning, and creating online courses in specific methods areas. NIH recently issued a Request for Proposals for online training in this domain. Even the general public would benefit from exposure to these issues, and many activated consumer networks (e.g., Project LEAD, sponsored by the National Breast Cancer Coalition [<ext-link ext-link-type="uri" xlink:href="http://www.breastcancerdeadline2020.org/get-involved/training/project-lead/" xlink:type="simple">http://www.breastcancerdeadline2020.org/get-involved/training/project-lead/</ext-link>], Consumers United for Evidence-based Healthcare [<ext-link ext-link-type="uri" xlink:href="http://us.cochrane.org/CUE" xlink:type="simple">http://us.cochrane.org/CUE</ext-link>], and PCORI’s Patient Powered Research Networks [<ext-link ext-link-type="uri" xlink:href="http://www.pcornet.org/patient-powered-research-networks/" xlink:type="simple">http://www.pcornet.org/patient-powered-research-networks/</ext-link>]) are leading the way in patient and consumer scientific engagement and education.</p>
</sec>
<sec id="sec006">
<title>Who Will Fund Research on Research?</title>
<p>Funding all these efforts requires a substantial investment. Until recently, the few large-scale initiatives in this space, such as the Cochrane Collaboration, were based mostly on volunteering of idealistic individuals who cared about science and high-quality evidence. Most of that effort was invested on performing systematic reviews on topical questions of interest (e.g., learning about whether a specific drug works and by how much), although this led inevitably to concerns about larger meta-research issues like bias, methods, and reproducibility across studies. Most funding agencies have organized themselves into sections based on topical focus rather than widely applicable, cross disciplinary methods. This disease or discipline-specific paradigm does not lend itself to solving problems that cut across science more generally. Until now, mostly a few private foundations have been championing the cause of meta-research to improve research quality. However, it is encouraging to see several public funders (e.g., NIH [<xref rid="pbio.1002264.ref010" ref-type="bibr">10</xref>] and PCORI [<ext-link ext-link-type="uri" xlink:href="http://www.pcori.org/blog/open-science-pcoris-efforts-make-study-results-and-data-more-widely-available" xlink:type="simple">www.pcori.org/blog/open-science-pcoris-efforts-make-study-results-and-data-more-widely-available</ext-link>] among others) recognizing the need to support such efforts and to eventually generate and apply scientific evidence on scientific investigation, including how they themselves should function.</p>
</sec>
</body>
<back>
<glossary>
<title>Abbreviation</title>
<def-list>
<def-item><term>METRICS</term>
<def><p>Meta-Research Innovation Center at Stanford</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.1002264.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Van Noorden</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Maher</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Nuzzo</surname> <given-names>R</given-names></name> (<year>2014</year>) <article-title>The top 100 papers</article-title>. <source>Nature</source>. <volume>514</volume>(<issue>7524</issue>):<fpage>550</fpage>–<lpage>3</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/514550a" xlink:type="simple">10.1038/514550a</ext-link></comment> <object-id pub-id-type="pmid">25355343</object-id></mixed-citation></ref>
<ref id="pbio.1002264.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Boyack</surname> <given-names>KW</given-names></name>, <name name-style="western"><surname>Klavans</surname> <given-names>R</given-names></name> (<year>2014</year>) <article-title>Estimates of the continuously publishing core in the scientific workforce</article-title>. <source>PLoS One</source>. <volume>9</volume>(<issue>7</issue>):<fpage>e101698</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0101698" xlink:type="simple">10.1371/journal.pone.0101698</ext-link></comment> <object-id pub-id-type="pmid">25007173</object-id></mixed-citation></ref>
<ref id="pbio.1002264.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Macleod</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Michie</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Roberts</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Dirnagl</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Chalmers</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Al-Shahi</surname> <given-names>Salman R</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Glasziou</surname> <given-names>P</given-names></name> (2014) <article-title>Biomedical research: increasing value, reducing waste</article-title>. <source>Lancet</source>. <year>2014</year> <month>Jan</month> <day>11</day>;<volume>383</volume>(<issue>9912</issue>):<fpage>101</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0140-6736(13)62329-6" xlink:type="simple">10.1016/S0140-6736(13)62329-6</ext-link></comment> <object-id pub-id-type="pmid">24411643</object-id></mixed-citation></ref>
<ref id="pbio.1002264.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Begley</surname> <given-names>CG</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name> (<year>2015</year>) <article-title>Reproducibility in science: improving the standard for basic and preclinical research</article-title>. <source>Circ Res</source>. <volume>116</volume>(<issue>1</issue>):<fpage>116</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1161/CIRCRESAHA.114.303819" xlink:type="simple">10.1161/CIRCRESAHA.114.303819</ext-link></comment> <object-id pub-id-type="pmid">25552691</object-id></mixed-citation></ref>
<ref id="pbio.1002264.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Begley</surname> <given-names>CG</given-names></name>, <name name-style="western"><surname>Ellis</surname> <given-names>LM</given-names></name> (<year>2012</year>) <article-title>Drug development: Raise standards for preclinical cancer research</article-title>. <source>Nature</source>. <volume>483</volume>(<issue>7391</issue>):<fpage>531</fpage>–<lpage>3</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/483531a" xlink:type="simple">10.1038/483531a</ext-link></comment> <object-id pub-id-type="pmid">22460880</object-id></mixed-citation></ref>
<ref id="pbio.1002264.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alberts</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Kirschner</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Tilghman</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Varmus</surname> <given-names>H</given-names></name> (<year>2014</year>) <article-title>Rescuing US biomedical research from its systemic flaws</article-title>. <source>Proc Natl Acad Sci U S A</source>. <volume>111</volume>(<issue>16</issue>):<fpage>5773</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1404402111" xlink:type="simple">10.1073/pnas.1404402111</ext-link></comment> <object-id pub-id-type="pmid">24733905</object-id></mixed-citation></ref>
<ref id="pbio.1002264.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manolagas</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Kronenberg</surname> <given-names>HM</given-names></name> (<year>2014</year>) <article-title>Reproducibility of results in preclinical studies: a perspective from the bone field</article-title>. <source>J Bone Miner Res</source>. <volume>29</volume>(<issue>10</issue>):<fpage>2131</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/jbmr.2293" xlink:type="simple">10.1002/jbmr.2293</ext-link></comment> <object-id pub-id-type="pmid">24916175</object-id></mixed-citation></ref>
<ref id="pbio.1002264.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fanelli</surname> <given-names>D</given-names></name> (<year>2012</year>) <article-title>Negative results are disappearing from most disciplines</article-title> <source>Scientometrics</source> <volume>90</volume>:<fpage>891</fpage>–<lpage>904</lpage>.</mixed-citation></ref>
<ref id="pbio.1002264.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name> (<year>2014</year>) <article-title>How to make more published research true</article-title>. <source>PLoS Med</source>. <volume>11</volume>(<issue>10</issue>):<fpage>e1001747</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pmed.1001747" xlink:type="simple">10.1371/journal.pmed.1001747</ext-link></comment> <object-id pub-id-type="pmid">25334033</object-id></mixed-citation></ref>
<ref id="pbio.1002264.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Collins</surname> <given-names>FS</given-names></name>, <name name-style="western"><surname>Tabak</surname> <given-names>LA</given-names></name> (<year>2014</year>) <article-title>Policy: NIH plans to enhance reproducibility</article-title>. <source>Nature</source>. <volume>505</volume>(<issue>7485</issue>):<fpage>612</fpage>–<lpage>3</lpage>. <object-id pub-id-type="pmid">24482835</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
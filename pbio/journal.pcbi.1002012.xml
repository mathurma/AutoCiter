<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-10-00171</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002012</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Learning from Sensory and Reward Prediction Errors during Motor Adaptation</article-title><alt-title alt-title-type="running-head">Learning from Sensory and Reward Prediction Errors</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Izawa</surname>
            <given-names>Jun</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Shadmehr</surname>
            <given-names>Reza</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Department of Biomedical Engineering, Johns Hopkins School of Medicine, Baltimore, Maryland, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Human Media Systems, The University of Electro-Communication, Chofu, Tokyo, Japan</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Körding</surname>
            <given-names>Konrad</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Northwestern University, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">jizawa@jhu.edu</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: JI RS. Performed the experiments: JI. Analyzed the data: JI. Contributed reagents/materials/analysis tools: RS. Wrote the paper: JI RS.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>3</month>
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>10</day>
        <month>3</month>
        <year>2011</year>
      </pub-date><volume>7</volume><issue>3</issue><elocation-id>e1002012</elocation-id><history>
        <date date-type="received">
          <day>29</day>
          <month>10</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>12</day>
          <month>1</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Izawa, Shadmehr</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>Voluntary motor commands produce two kinds of consequences. Initially, a sensory consequence is observed in terms of activity in our primary sensory organs (e.g., vision, proprioception). Subsequently, the brain evaluates the sensory feedback and produces a subjective measure of utility or usefulness of the motor commands (e.g., reward). As a result, comparisons between predicted and observed consequences of motor commands produce two forms of prediction error. How do these errors contribute to changes in motor commands? Here, we considered a reach adaptation protocol and found that when high quality sensory feedback was available, adaptation of motor commands was driven almost exclusively by sensory prediction errors. This form of learning had a distinct signature: as motor commands adapted, the subjects altered their predictions regarding sensory consequences of motor commands, and generalized this learning broadly to neighboring motor commands. In contrast, as the quality of the sensory feedback degraded, adaptation of motor commands became more dependent on reward prediction errors. Reward prediction errors produced comparable changes in the motor commands, but produced no change in the predicted sensory consequences of motor commands, and generalized only locally. Because we found that there was a within subject correlation between generalization patterns and sensory remapping, it is plausible that during adaptation an individual's relative reliance on sensory vs. reward prediction errors could be inferred. We suggest that while motor commands change because of sensory and reward prediction errors, only sensory prediction errors produce a change in the neural system that predicts sensory consequences of motor commands.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>It is thought that motor adaptation relies on sensory prediction errors to form an estimate of the perturbation. Here, we present evidence that motor adaptation can be driven by both sensory and reward prediction errors. We found that learning from sensory prediction error altered the predicted consequences of motor commands, leaving behind a sensory remapping, whereas learning from reward prediction error produced comparable change in motor commands, but did not produce a sensory remapping. It is possible that the neural basis of learning from sensory and reward prediction errors are distinct because they produce different generalization patterns.</p>
      </abstract><funding-group><funding-statement>This work was supported in part by a grant from the National Institutes of Health (NS37422) and a grant from the by Japan Society of Promotion of Science (Grants-in-Aid for scientific research 22800019). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="11"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Our motor commands generally produce two kinds of consequences: a sensory consequence in terms of activity in our primary sensory organs (e.g., vision, proprioception), and a rewarding consequence in terms of forming a subjective measure of utility or usefulness of these sensations (e.g., release of dopamine). For example, while dancing, the motor commands that move our body produce proprioceptive feedback, while internal evaluation of that feedback indicates a pleasurable experience. These two consequences of the motor command form the basis for two kinds of prediction error: a sensory prediction error, and a reward prediction error. In principle, learning from sensory prediction error should alter an internal model that predicts the sensory consequences of motor commands, i.e., a forward model <xref ref-type="bibr" rid="pcbi.1002012-Synofzik1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Synofzik2">[2]</xref>. In contrast, learning from reward prediction error should alter the valuation of the sensory states that are the consequence of those motor commands, i.e., a value function. Motor adaptation studies often focus on learning from sensory prediction error <xref ref-type="bibr" rid="pcbi.1002012-Synofzik1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Synofzik2">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Baddeley1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Berniker1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Kording1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Sing1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-vanBeers1">[7]</xref>, despite the fact that people are also rewarded for each movement. Similarly, studies that focus on learning from reward prediction error (e.g., decision making tasks) often do not consider potential sensory prediction errors <xref ref-type="bibr" rid="pcbi.1002012-Frank1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Schonberg1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Trommershauser1">[10]</xref>. It seems rational that most learning would rely on both kinds of error. Here, we focus on a simple motor adaptation task and consider a mathematical framework in which both reward and sensory prediction errors could contribute to the trial-to-trial change in the motor commands. We attempt to ask whether learning from these two distinct signals can be behaviorally dissociated.</p>
      <p>Our idea is that while motor commands might change because of sensory or reward prediction errors, only in the former case would there also be a change in the map that predicts the sensory consequences of the motor command. We focus on a well studied motor adaptation protocol: reaching in the context of visuomotor perturbations. While there have been numerous models of motor adaptation <xref ref-type="bibr" rid="pcbi.1002012-Berniker1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Kording1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Kawato1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Kawato2">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Thoroughman1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Smith1">[14]</xref>, to our knowledge all current models assume that the process of motor adaptation is driven by sensory prediction errors. Our objective is to test the hypothesis that during motor adaptation, learning from sensory prediction errors leaves a behavioral signature that is distinct from learning from reward prediction errors.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <p>Consider a typical adaptation task in which the learner experiences a perturbation. The limb is covered by a screen to prevent direct observation of the hand, and a cursor that represents hand position undergoes a kinematic rotation so that when the hand moves straight ahead, the cursor moves slightly to the left (<xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1A</xref>). Reward is provided if the cursor passes through the target area. In this reach adaptation task there are two kinds of error: the difference between the expected and observed visual feedback of the hand (i.e. visual cursor), and the difference between the expected and observed success of the reach. Our hypothesis is that learning mechanisms engaged by the two types of error may be behaviorally dissociable.</p>
      <fig id="pcbi-1002012-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002012.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Experimental setup.</title>
          <p>(<bold>A</bold>) In the reaching task, subjects held a handle of a robotic arm and made ‘shooting’ movements to move a cursor through a target at 10 cm. The arm was covered by a screen. During adaptation, the cursor-hand relationship was perturbed so that the cursor position was rotated around the center at the start position. The coordinate system is drawn on the left side of the robot (invisible for subject) where the clockwise rotation around the start is positive. The cumulative score of each block was provided to the subject. In the localization task, subjects pointed with their left hand over the screen to the remembered location of their right hand as it crossed the (unseen) target area in the previous trial. In the localization task, the start box was not visible. (<bold>B</bold>) Experimental paradigms. In ERR, full visual feedback about the cursor position was provided as well as the animation and the sound indicating target explosion regarding success or failure of the task. In EPE, while the cursor was unseen during the shooting movement, it was presented for 200 ms as the hand crossed an imaginary circle with the radius equal to the target, providing endpoint error with respect to the target. The reward signal was also provided as in the ERR condition. In RWD, no visual feedback about the cursor was provided. All information that subjects were able to use was the success or failure of the task. (<bold>C</bold>) Reach angles of three representative subjects during the adaptation phase. The yellow line in the ERR group is the ideal reach angle, which shifted gradually up to 8 degrees by the visual rotation. The gray area indicates the reward region, which shifted with the same schedule in the three groups. (<bold>D</bold>) Reach variability in the final 100 trials for each group. There are the significant differences between ERR and EPE (t-test, p&lt;0.003) as well as between EPE and RWD (t-test, p&lt;0.001). (<bold>E</bold>) Results of the localization task for the three subjects. The reach trajectory is plotted for the POST condition. Red line is for the RWD subject, blue line is for the ERR subject, and green line is for the EPE subject. The circle around the reach trajectory is the averaged pointing location in the localization trial.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.g001" xlink:type="simple"/>
      </fig>
      <p>To examine this hypothesis, we recruited two groups of subjects in Experiment 1. One group (RWD) was provided only with information regarding whether they succeeded or failed at each trial (reward r = 1 or 0), indicated by explosion of the target, and received no other visual feedback regarding their movement (<xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1B</xref>). Another group was provided with full visual feedback of the cursor as well as the reward so that they were able to use both potential error signals (ERR). We asked two questions: 1) In the ERR paradigm in which sensory consequences of motor commands were available, would adaptation of the motor commands accompany a change in the motor-sensory map (i.e., a change in the perceived sensory consequences of motor commands), and 2) in the RWD paradigm in which sensory consequences of motor commands were unavailable, would adaptation of the motor commands take place but without a change in the motor-sensory map.</p>
      <p><xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1C</xref> shows data from representative subjects in the ERR and RWD paradigms. In this figure, the yellow line in the ERR group is the ideal reach angle (shifts gradually up to 8°). The gray area indicates the region that provided reward, which shifts with the same schedule in both groups. The subjects were provided with different kinds of error feedback, but updated their motor commands by roughly the same amount (group data, mean change in reach direction, 7.49° for RWD and 7.63° for ERR, not significantly different from each other p&gt;0.8, t-test). The total amount of adaptation of the two groups was comparable. However, the variability of reach angles was larger for the RWD subject (<xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1C</xref>), and this was consistent across the entire group (<xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1D</xref>).</p>
      <p>Before and after this adaptation task (PRE and POST adaptation), we measured how subjects predicted the sensory consequences of their motor commands. In this localization part of the task, after subjects completed a reach with their right hand, their hand was returned to the center location, and they were then asked to estimate the location of their right hand in the previous trial by pointing with their left hand over the screen (<xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1A</xref>). During the localization neither the cursor nor the target was projected. The localization data for representative subjects are shown in <xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1E</xref>. As a consequence of adaptation, the subject in the ERR group had a sensory remapping in which she estimated her hand to be to the left of its actual position. In contrast, the subject in the RWD group had little or no sensory remapping, suggesting that the changes in the motor commands did not accompany a change in the motor-sensory map.</p>
      <p><xref ref-type="fig" rid="pcbi-1002012-g002">Fig. 2A</xref> shows the group data for the localization task. We compared the change in the estimate of hand position from the PRE to the POST adaptation condition and found that the subjects in the ERR group estimated their hand position to have changed by 8.8°+/−0.6° to the left of actual position. In contrast, in the POST condition of the RWD group, the subjects had no significant change in their sensory estimates (there was a significant difference between PRE and POST in the ERR group p&lt;0.0001, whereas the difference in the RWD group was not significant p = 0.8).</p>
      <fig id="pcbi-1002012-g002" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002012.g002</object-id>
        <label>Figure 2</label>
        <caption>
          <title>The sensory remapping and the generalization function.</title>
          <p>(<bold>A</bold>) The average estimated localization of hand position in PRE and POST conditions. Error bars are SEM. (<bold>B</bold>) Generalization of adaptation from the learned target direction (at 0°) to neighboring target directions. (<bold>C</bold>) Illusion index (change in estimated location of the hand from PRE to POST adaptation), as a function of generalization index in subjects in EPE condition. Each dot indicates individual subject's data. There are significant negative correlation in these two indices (R = −0.68, p = 0.02).</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.g002" xlink:type="simple"/>
      </fig>
      <p>If the sensory and reward prediction errors engage learning in distinct neural structures, then adaptation might result in distinct generalization patterns <xref ref-type="bibr" rid="pcbi.1002012-Pearson1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Shadmehr1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Haswell1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Bedford1">[18]</xref>. To test this idea, we recruited subjects for Experiment 2 and quantified the patterns of generalization that accompanied adaptation. In the adaptation session, the target was projected at 0° (straight ahead). In the pre and post adaptation periods the target appeared randomly at various angular displacements (−30 to 30 deg). For these generalization targets, we provided neither the cursor nor reward information. <xref ref-type="fig" rid="pcbi-1002012-g002">Fig. 2B</xref> plots the average reach angle across subjects for each target direction. We found that the RWD group had a narrower generalization function than the ERR group (ANOVA, F(1,126) = 9.632, p = 0.005). In summary, in the RWD condition the learning that produced changes in the motor commands accompanied a narrow generalization function and no change in the map that predicted the sensory consequences of motor commands. In contrast, in the ERR paradigm the learning that produced changes in the motor commands accompanied a broad generalization function and a significant change in the perceived sensory consequences of motor commands.</p>
      <p>In the RWD paradigm the binary feedback signal carried much less information than the continuous sensory error signal available in the ERR paradigm. This may have forced the subjects to adopt a completely new strategy, making the learning that we see in the RWD paradigm irrelevant for a typical adaptation paradigm. In Experiment 3 we considered a paradigm (EPE) in which the visual cursor was available only at the endpoint of the movement and was otherwise invisible during the reach. In this new experiment we measured the localization change (as in Exp. 1) and the generalization (as in Exp. 2), attempting to test the results of experiments 1 and 2 in the same population.</p>
      <p><xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1C</xref> shows the reach angles of a representative subject in the EPE group. The adaptation in the EPE group was comparable with the ERR group (mean change in reach direction, t-test, p = 0.64), i.e., the motor commands in the three groups adapted by approximately the same amount. Interestingly, in the localization task the subject in the EPE group had a sensory illusion that was in between the ERR and RWD groups (<xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1E</xref>). In the group data in the POST adaptation condition, the strength of the localization illusion in the EPE group was weaker than in the ERR group (t-test, p&lt;0.007), but stronger than the RWD group (t-test, p&lt;0.006) (<xref ref-type="fig" rid="pcbi-1002012-g002">Fig. 2A</xref>). The generalization of the EPE group appeared to be in between ERR and RWD (we did not see a significant difference from either ERR or RWD, <xref ref-type="fig" rid="pcbi-1002012-g002">Fig. 2B</xref>). In Experiment 2 we had found that learning from reward produced a narrow generalization, while in Experiment 1 we had found that learning from error produced a motor-sensory remapping. In Experiment 3 we had the means to test a crucial prediction: across subjects, individuals who relied more on reward (narrow generalization) should show a smaller motor-sensory remapping. Indeed, we found a significant correlation between the amount of generalization and the localization illusion across subjects (<xref ref-type="fig" rid="pcbi-1002012-g002">Fig. 2C</xref>). That is, it appeared that when a subject had a larger sensory illusion (suggesting that learning was driven more by sensory prediction errors), they also had a wider generalization.</p>
      <p>To explore the mechanism behind these findings, we considered a model of adaptation that relied on both sensory and reward prediction errors (<xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3A</xref>). Suppose that the brain generates a motor command <italic>u</italic>, resulting in a change in the state of the hand <italic>h</italic>, which also depends on a perturbation <italic>p</italic>. The nervous system senses the resulting motion of the limb <italic>y</italic> as well as whether that motion was rewarded <italic>r</italic>. Here, we considered a learner who updates motor command <italic>u</italic> to maximize reward. In theory, producing the motor commands that maximize probability of reward may rely on two kinds of learning: forming an optimal action selector, and forming an optimal state predictor (<xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3B</xref>). On trial <italic>k</italic>, action selector outputs motor commands <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e001" xlink:type="simple"/></inline-formula>. This depends on the estimated perturbation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e002" xlink:type="simple"/></inline-formula> (which depends on sensory prediction error <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e003" xlink:type="simple"/></inline-formula>), as well as the reward prediction error <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e004" xlink:type="simple"/></inline-formula>. Therefore, in theory the trial-to-trial change in the motor commands is driven by two different error signals: the state estimator updated by the sensory prediction error, and the action selector updated by the reward prediction error.</p>
      <fig id="pcbi-1002012-g003" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002012.g003</object-id>
        <label>Figure 3</label>
        <caption>
          <title>The theoretical problem of learning motor control.</title>
          <p>(<bold>A</bold>) A generative model of the motor adaptation task. Motor commands are corrupted by a perturbation, which result in a hand position that is sensed via a cursor, and may also result in reward. The objective of the learner is to find the motor commands that maximize reward. White circles are hidden variables and gray circles are observed variables. Arrows indicate conditional probabilities. (<bold>B</bold>) Model of optimal learner. The learning system is composed of two compensatory mechanisms: action selector and internal forward model. At the trial k, the action selector outputs the motor command <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e005" xlink:type="simple"/></inline-formula> to make a transition of the state of the body and task from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e006" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e007" xlink:type="simple"/></inline-formula>. The state variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e008" xlink:type="simple"/></inline-formula> includes three elements: hand position <italic>h</italic>, perturbation <italic>p</italic>, and the position <italic>t</italic>. The brain observes the part of the state of the body <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e009" xlink:type="simple"/></inline-formula>. At the same time, the learner predicts the transition of the body state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e010" xlink:type="simple"/></inline-formula> from the efference copy of the motor command. Kalman filtering correct the prediction to minimize the sensory prediction error <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e011" xlink:type="simple"/></inline-formula> to have the updated state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e012" xlink:type="simple"/></inline-formula>. The action selector selects the optimal action as a function of the updated state at the next trial. (<bold>C</bold>) Sample disturbance and the response of the model. The task is to control the reach angle. Clockwise (CW) direction is positive and the target is at 0°. The uncertainty of the visual feedback was controlled to modulates the Kalman gain. The simulations predict a remapping regarding estimated hand position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e013" xlink:type="simple"/></inline-formula> modulated by the level of visual uncertainty.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.g003" xlink:type="simple"/>
      </fig>
      <p>An important prediction from this model is that reliance on the sensory prediction error is modulated by the Kalman gain, which is the ratio of estimation uncertainty to observation uncertainty. Therefore, if the uncertainty of visual feedback is large, the credit on the sensory prediction error becomes small, which makes the credit on the reward prediction error larger.</p>
      <p><xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3C</xref> shows results of simulations for different uncertainty levels of visual feedback. When the learner is provided with high quality visual feedback <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e014" xlink:type="simple"/></inline-formula> (analogous to ERR condition, <xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3C</xref> left column), it updates its estimate of perturbation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e015" xlink:type="simple"/></inline-formula>, resulting in a motor-sensory remapping. As a result, the estimated hand position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e016" xlink:type="simple"/></inline-formula> is near the location of the cursor and different from actual hand position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e017" xlink:type="simple"/></inline-formula>. In contrast, when the learner is provided with uncertain visual feedback (analogous to EPE condition, middle column in <xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3C</xref>), the learner alters the motor commands using both the sensory prediction error and the reward prediction error. In this case, the adaptation produces a partial sensory remapping (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e018" xlink:type="simple"/></inline-formula> is not very different from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e019" xlink:type="simple"/></inline-formula> in the middle column of <xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3C</xref>). Finally, when the learner is provided with extremely poor visual feedback (analogous to RWD condition, right column of <xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3C</xref>), all that is available to the learner is success or failure (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e020" xlink:type="simple"/></inline-formula>  = 0 or 1). The learner still alters the motor commands to compensate for the perturbation, but the adaptation does not produce a sensory remapping (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e021" xlink:type="simple"/></inline-formula> is not different from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e022" xlink:type="simple"/></inline-formula> in the right column of <xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3C</xref>).</p>
      <p>These three different patterns of sensory remapping generated by the model help explain the reason why we observed different patterns of sensory remapping in the three different paradigms. In the ERR condition in which high quality sensory feedback was available, adaptation produced large change in the state predictor, producing the sensory remapping. In RWD condition in which the visual feedback of the cursor was not available, adaptation focused on the action selector, which was updated by reward prediction error. Because this process did not involve a sensory remapping, we did not observe a change in the localization behavior of the subjects. In the EPE condition in which partial visual feedback was provided, learning depended on both an updating of the state predictor and the action selector. As a result, we observed the partial sensory remapping.</p>
      <p>To validate our model, we used it to estimate how much of the change in the motor commands that we observed in our subjects was due to each type of error. We imagined that the motor commands were generated by the sum of two states with a search noise, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e023" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e024" xlink:type="simple"/></inline-formula> represents the estimate of the perturbation as updated by sensory prediction error and the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e025" xlink:type="simple"/></inline-formula> is updated by reward prediction error. Using a nonlinear optimization algorithm, we fit the model to the trial-to-trial behavior of each subject (reach direction on each trial), and the state of reward on that trial. In the RWD paradigm, the only feedback available was reward prediction error, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e026" xlink:type="simple"/></inline-formula>. The results of our model fit are shown in <xref ref-type="fig" rid="pcbi-1002012-g004">Fig. 4</xref> via the average of estimated parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e027" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e028" xlink:type="simple"/></inline-formula>, and their sum. These estimated values were superimposed on the average of subjects' trial-to-trial reach angle (black line) with SEM across subjects. In the ERR condition, by the end of adaptation the contributions of these two states were [<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e029" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e030" xlink:type="simple"/></inline-formula>] = [7.82,0.26]+/−[0.18,0.31]. Despite the fact that we used the exact the same model to fit the data for ERR and EPE, the best fit estimates of these two states in EPE were [<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e031" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e032" xlink:type="simple"/></inline-formula>] = [4.53,3.33]+/−[0.59,0.69], which were significantly different from those of ERR (ANOVA, F(1,18) = 18.93,p&lt;0.001).</p>
      <fig id="pcbi-1002012-g004" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002012.g004</object-id>
        <label>Figure 4</label>
        <caption>
          <title>Estimated contribution of reward and sensory prediction errors to change in motor output during adaptation.</title>
          <p>When subjects experienced the ERR and EPE condition, we assumed that the motor commands were produced by the sum of two memories, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e033" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e034" xlink:type="simple"/></inline-formula> was updated by the sensory-prediction error and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e035" xlink:type="simple"/></inline-formula> was updated by the reward prediction error. The best fit parameters predict the update of the two memories. The black think line is the averaged subject's reach angle during the adaptation period. The gray shadow is SEM. The superimposed purple line is the estimated reach angle from the model which is a combination of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e036" xlink:type="simple"/></inline-formula> (red) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e037" xlink:type="simple"/></inline-formula> (blue). In the RWD condition, the motor commands are updated by only the reward-prediction error: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e038" xlink:type="simple"/></inline-formula>.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.g004" xlink:type="simple"/>
      </fig>
      <p>By fitting the model to the data, we were able to estimate the search noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e039" xlink:type="simple"/></inline-formula>. We found that the variance of the search noise in ERR was <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e040" xlink:type="simple"/></inline-formula>, which was significantly smaller than that of EPE (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e041" xlink:type="simple"/></inline-formula>, p&lt;0.001), and RWD (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e042" xlink:type="simple"/></inline-formula>, t-test, p&lt;0.01). Our estimate of a significantly smaller search noise in the ERR condition is consistent with our inference that with high quality sensory feedback, the change in the motor commands is driven almost entirely by sensory prediction errors. This is also consistent with the fact that in the ERR condition, there was a scarcity of reward prediction error: In ERR, more than 95% of trials were rewarded, whereas the probability of reward in EPE was 83% and that in RWD was 76%. Therefore, our analysis suggests that in the ERR paradigm the change in the motor commands was due primarily to adaptation of the state estimator (accounting for the sensory remapping), whereas in the RWD paradigm the change was due to adaptation of the action selector (accounting for the lack of sensory remapping). In the EPE paradigm the change was due to both the state estimator and the action selector.</p>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>Our goal was to determine whether during motor adaptation one could dissociate between learning from reward prediction errors vs. learning from sensory prediction errors. We considered a reaching task in which visual feedback regarding cursor position was altered. The quality of this feedback was manipulated so that in one group the sensory feedback was of high quality (available throughout the reach, ERR group), in another group the sensory feedback was of low quality (available only at the end of the reach, EPE group), and in a third group the sensory feedback was unavailable (RWD group). All groups had access to reward (success or failure) at the end of their movement. We found that after a long period of training, all three groups adapted their motor commands. In the ERR group this adaptation accompanied a wide pattern of generalization and a significant change in the perceived sensory consequences of motor commands. In contrast, in the RWD group the adaptation accompanied a narrow pattern of generalization and no change in the perceived sensory consequences of motor commands. In the EPE group, generalization and sensory remapping were intermediate. Interestingly, in the EPE group individuals who demonstrated a larger sensory remap also had a wider generalization function. Increasing the uncertainty in the sensory prediction error altered both the width of generalization function and the amount of sensory remapping, while it did not affect the level of adaptation.</p>
      <p>While previous models of motor adaptation have relied exclusively on sensory prediction errors to form an estimate of the perturbation <xref ref-type="bibr" rid="pcbi.1002012-Berniker1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Kording1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Wolpert1">[19]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Barnes1">[20]</xref>, the comparable levels of motor adaptation in our groups (ERR, RWD, and EPE) suggest that the brain relied on another source of error, the reward prediction error, when the sensory prediction error was not informative. In fact, it has been shown that the reward may modulate motor planning <xref ref-type="bibr" rid="pcbi.1002012-Trommershauser2">[21]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Takikawa1">[22]</xref>. Thus, it seems more rational that the purpose of learning is not merely to estimate the magnitude of a perturbation, but to produce motor commands that maximize reward <xref ref-type="bibr" rid="pcbi.1002012-Doya1">[23]</xref>.</p>
      <p>We formulated this adaptation as a reward maximization process by assuming an “optimal learner”. The optimization relied on two update equations: one was the optimal estimator that inferred the state of the body, and the other was the optimal policy that selected the action as a function of the estimated state <xref ref-type="bibr" rid="pcbi.1002012-Izawa1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Izawa2">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Todorov1">[26]</xref>. Based on this theory, our model of the optimal learner was composed of two components: reinforcement learning for action selection, and state estimation for identifying the sensory consequences of motor commands <xref ref-type="bibr" rid="pcbi.1002012-Shadmehr2">[27]</xref>. In this model, the objective of state estimation was to estimate the perturbation in the environment and the hand position as a consequence of the motor command, while the objective of the reinforcement learning was to update how to select the action to maximize reward probability <xref ref-type="bibr" rid="pcbi.1002012-Izawa3">[28]</xref>. The simulation showed that the learner relied mostly on the sensory prediction error in ERR paradigm. As a result, the learner updated the parameter associated with the sensory consequence of the motor command, which predicted the illusion that we observed in Experiment 1. In contrast with the ERR paradigm, the RWD paradigm did not provide the sensory prediction error. Thus, the simulation with the RWD paradigm showed that the reward-prediction error updated the action but did not change the estimate of hand position. Thus, high quality sensory feedback produced learning that depended primarily on sensory prediction errors.</p>
      <p>While our model was not designed to account for the distinct generalization patterns in the ERR and the RWD paradigms, previous studies have speculated that generalization patterns are a reflection of the neural encoding of information during learning <xref ref-type="bibr" rid="pcbi.1002012-Shadmehr1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Poggio1">[29]</xref>. For example, generalization patterns during reach adaptation in force fields appear consistent with an encoding in which the neurons have activity fields that resemble those in the primary motor cortex <xref ref-type="bibr" rid="pcbi.1002012-Thoroughman1">[13]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Hwang1">[30]</xref>. In contrast, generalization patterns in visuomotor rotations appear more consistent with an encoding similar to cells in the posterior parietal cortex <xref ref-type="bibr" rid="pcbi.1002012-Tanaka1">[31]</xref>. In this framework, the two different generalization patterns seen in RWD and ERR paradigms suggest engagement of two different neural mechanisms that each learn from reward and sensory prediction error. Another possibility, however, is that the two forms of prediction error converge on a single neural structure that guides motor learning.</p>
      <p>By presenting the optimal learner model that includes two forms of prediction error, we built a connection between two disparate areas of research that has focused on different parts of the brain. Motor adaptation has focused on tasks that typically depend on the integrity of the cerebellum <xref ref-type="bibr" rid="pcbi.1002012-Tseng1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Smith2">[33]</xref>. Habit learning <xref ref-type="bibr" rid="pcbi.1002012-Yin1">[34]</xref>, visuomotor sequence learning <xref ref-type="bibr" rid="pcbi.1002012-Nakahara1">[35]</xref>, or action selection <xref ref-type="bibr" rid="pcbi.1002012-Tanaka2">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Samejima1">[37]</xref> have focused on tasks that depend on the integrity of the basal ganglia <xref ref-type="bibr" rid="pcbi.1002012-Packard1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Wickens1">[39]</xref>. In fact, goal directed action in habitual learning is mediated by two representations: a representation of the instrumental contingency between the action and the outcome, and a representation of the outcome as a goal for the agent <xref ref-type="bibr" rid="pcbi.1002012-Dickinson1">[40]</xref>. Because motor adaptation is also a goal directed action, the two learning mechanisms observed in this paper might be the general systems involved in a broad category of procedural learning. For example, these two distinct memories might be mediated by parallel cortico-basal ganglia mechanisms with different sensory domains <xref ref-type="bibr" rid="pcbi.1002012-Nakahara1">[35]</xref>.</p>
      <p>Patients with basal ganglia disorders show little or no deficits in motor adaptation paradigms like force fields <xref ref-type="bibr" rid="pcbi.1002012-Smith2">[33]</xref> or visuomotor perturbations <xref ref-type="bibr" rid="pcbi.1002012-Gabrieli1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Agostino1">[42]</xref> (although patients with PD appear to show a deficit in consolidation of the memory <xref ref-type="bibr" rid="pcbi.1002012-Marinelli1">[43]</xref>). Why is this? Our theory provides a potential answer: in the typical force field or visuomotor tasks, high quality sensory feedback is available, making it likely that sensory prediction errors play a dominant role. Because learning from sensory prediction errors likely depends on the integrity of the cerebellum <xref ref-type="bibr" rid="pcbi.1002012-Synofzik2">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Tseng1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-CriscimagnaHemminger1">[44]</xref>, the implication is that the ability of basal ganglia patients to adapt to visuomotor and force field perturbations is not evidence for normal motor adaptation, but rather evidence for the idea that changes in motor output in these tasks are primarily driven by sensory prediction errors. The other implication of the theory is that the inability to adapt the sensory consequences of motor commands did not prevent adaptation of the motor commands in response to reward prediction errors. Indeed, when we altered the adaptation paradigm and made it so that changes in the motor output were driven by reward prediction errors, we found that in response to the reward prediction error subjects altered their motor commands. This theory predicts that by providing rewards appropriately during a motor adaptation task, the cerebellar patients may be able to update their motor commands without sensory recalibration.</p>
      <p>Another implication of the theory is that the active search noise to explore the motor commands plays an important role in updating the action selector. Indeed, we found that trial-to-trial variability was modulated depending on types of error with significantly larger variability in the RWD than in ERR and in EPE. In previous studies, movement variability is generally thought to be due to signal dependent noise in the neuronal structures that generate motor commands <xref ref-type="bibr" rid="pcbi.1002012-Harris1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Jones1">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Faisal1">[47]</xref>. However, noise is present even in the planning stage of movements <xref ref-type="bibr" rid="pcbi.1002012-Churchland1">[48]</xref>. Here, we found that during adaptation variability in movements was not due to meaningless noise, but an inherent part of a search that the brain engaged in to find motor commands that acquired a more rewarding state.</p>
      <p>In summary, changes that take place in motor commands during adaptation are likely to be driven by both sensory and reward prediction errors. Learning from sensory prediction error alters the predicted sensory consequences of motor commands, leaving behind a sensory remapping. During motor adaptation, the reliance on reward prediction errors can be increased by degrading the quality of the sensory feedback. Learning from reward prediction error does not accompany a sensory remapping. It is likely that the neural basis of learning from sensory and reward prediction errors are distinct because they produce different generalization patterns.</p>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <sec id="s4a">
        <title>Experimental Procedures</title>
        <p>Subjects sat in front of a robotic arm and held its handle <xref ref-type="bibr" rid="pcbi.1002012-Izawa2">[25]</xref>. A video projector painted the screen that covered the manipulandum and the subject's arm. A trial began by the robot positioning the subject's hand in a start box, at which point a target of 6° width appeared at 10 cm. Subjects were instructed to perform a ‘shooting’ motion so that their hand crossed within the target area, at which point the target was animated to show an explosion, and a score was increased by one point. In the error-based learning (ERR) paradigm, the cursor position was displayed during the movement toward the target. In the reward-based learning (RWD) paradigm, the cursor position was not displayed. For both groups, target explosion indicated success of the trial. The cursor was not displayed during the return of the hand to the start position.</p>
      </sec>
      <sec id="s4b">
        <title>Ethics Statement</title>
        <p>Protocols were approved by the local IRB and all subjects signed a consent form.</p>
        <sec id="s4b1">
          <title>Experiment 1: Learning from sensory prediction errors</title>
          <p>Volunteers (n = 14, 26±4.7 years old) were assigned to the ERR (n = 7) or the RWD group (n = 7). After a familiarization session, the experiment was composed of a visuomotor adaptation phase and two localization phases (PRE and POST). In the localization phase (<xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1A</xref>), the subjects performed four shooting trials followed by one localization trial. For the first 4 trials, the cursor was visible for the ERR learning group but invisible for the RWD group. For the 5<sup>th</sup> trial, the cursor was invisible for both groups. In the localization trial, neither the cursor nor the target was projected. In this trial, subjects pointed with their left hand (over the screen) to the estimated position of their right hand as it crossed the target area in the previous trial. That is, the subjects were asked to estimate the location of their right hand in the previous trial. These five trials (four shooting and one localization) were repeated 10 times for the PRE phase, and 10 times for the POST phase. The PRE localization phase was followed by an adaptation phase in which subjects experienced zero-rotation with 40 trials and then the perturbation increased by 1° every 40 trials until it reached 8° (<xref ref-type="fig" rid="pcbi-1002012-g001">Fig. 1C</xref>). The 8° perturbation lasted 80 trials. After a short break, subjects experienced 96 additional trials with the 8° perturbation and then were tested in the POST localization task.</p>
        </sec>
        <sec id="s4b2">
          <title>Experiment 2: Generalization</title>
          <p>The idea behind this experiment was to test whether adaptation in response to sensory prediction errors (ERR paradigm) vs. reward prediction errors (RWD paradigm) differed in their generalization patterns. Volunteers (n = 27, 24±4.4 years old) were assigned to the RWD (n = 18) or ERR groups (n = 9). Both groups were provided with a familiarization session. Subsequently the subjects experienced two baseline blocks composed of 80 trials. In the baseline block, the target position was selected randomly from [−30°, −20°, −10°, 0°, 10°, 20°, 30°] with respect to the trained target. The frequency of the center target (0°) was 32/80 trials and that of each peripheral target was 8/80. The objective of the peripheral targets was to test generalization. During these trials the cursor was not displayed and the target did not explode. For the center target, an explosion was provided for both groups but the cursor was displayed for only the ERR group. The baseline phase was followed by an adaptation phase. In the adaptation phase, the target appeared at only the center direction (0°) and the subjects experienced zero-rotation with 40 trials and then the perturbation shifted every 40 trials by −1° until it reached −8° and was held at this level for 80 trials. After a short break, subjects experienced another 3 blocks of 48 trials with −8° perturbation. Finally, we tested the generalization of this adaptation via a protocol that was the same as pre-adaptation.</p>
        </sec>
        <sec id="s4b3">
          <title>Experiment 3: End point error paradigm</title>
          <p>Volunteers (n = 11, 26.1±5.2 years old) were recruited for the end-point error group (EPE). The target was located at one of seven position [−30 −20 −10 0 +10 +20 +30] degree with respect to the center line, along a boundary circle with a 10 cm radius. At the moment the cursor passed through the boundary circle, the boundary pass point (endpoint) was marked by the cursor for 200 ms. After a familiarization block, the subjects experienced the baseline block for the generalization task which is the same as Experiment 2, followed by the PRE localization block which is the same as the Experiment 1. Then, subjects experienced the adaptation blocks which is the same as Experiment 1, where the perturbation was gradually increased up to −8 degree which was followed by another 2 blocks of 48 trials with −8° perturbation. Next, we tested the generalization of this adaptation via a protocol that was the same as pre-adaptation. Finally, the subjects experienced the POST phase of the localization task.</p>
        </sec>
        <sec id="s4b4">
          <title>Data analysis</title>
          <p>The endpoint of the movement was defined as the intersection between the hand path and a 10 cm radius circle centered at the start position. The reach angle was calculated as the angle between the center of the target and the line that connects the start location and the reach endpoint. With respect to the midline, a clockwise rotation was defined as positive.</p>
        </sec>
        <sec id="s4b5">
          <title>An optimal learner</title>
          <p>Let us cast the problem of adaptation in a framework in which the brain predicts the sensory and reward consequences of motor commands, and then learns from prediction errors in both modalities. Hand position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e043" xlink:type="simple"/></inline-formula> depends on the motor command <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e044" xlink:type="simple"/></inline-formula> (initial reach direction) and is influenced by noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e045" xlink:type="simple"/></inline-formula>:</p>
          <p>
            <disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e046" xlink:type="simple"/><label>(1)</label></disp-formula>
          </p>
          <p>The units of all variables in Eq. (1) are degrees. The hand position controls the cursor position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e047" xlink:type="simple"/></inline-formula>, in which the perturbation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e048" xlink:type="simple"/></inline-formula> is imposed during the trial:</p>
          <p>
            <disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e049" xlink:type="simple"/><label>(2)</label></disp-formula>
          </p>
          <p>On trial <italic>k</italic>, subjects observe their hand position via a visual cursor at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e050" xlink:type="simple"/></inline-formula> but cannot observe the perturbation directly:</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e051" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e052" xlink:type="simple"/></inline-formula> represents perceptual noise. Because subjects observe the hand position indirectly, we suppose that they predict hand position using the efference copy of the motor command</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e053" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e054" xlink:type="simple"/></inline-formula> is the estimate of the perturbation. As subjects are repeatedly exposed to the perturbation, they build a prior knowledge of the characteristics of the perturbation: perturbations are correlated from trial to trial, and are also affected by noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e055" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002012-Berniker1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Burge1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Kording2">[50]</xref>:</p>
          <p>
            <disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e056" xlink:type="simple"/><label>(5)</label></disp-formula>
          </p>
          <p>Set the extended state of the system as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e057" xlink:type="simple"/></inline-formula>. We then have a state update equation that relates motor commands with changes in state:</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e058" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e059" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e060" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e061" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e062" xlink:type="simple"/></inline-formula>, and the observation equation is:</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e063" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e064" xlink:type="simple"/></inline-formula>. In summary, Eqs. (6) and (7) represent the relationship between motor commands and their sensory consequences. We assume that the objective for the learner is to maximize the rewards and minimize the cost. Under this assumption, for a linear dynamical system, optimal feedback control theory suggests that two interacting mechanisms are necessary: the optimal estimator and the optimal policy <xref ref-type="bibr" rid="pcbi.1002012-Izawa1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Todorov1">[26]</xref>. The optimal estimator is composed of a forward model and a Kalman filter:</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e065" xlink:type="simple"/><label>(8)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e066" xlink:type="simple"/></inline-formula> is the Kalman gain and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e067" xlink:type="simple"/></inline-formula> is the sensory prediction error. The Kalman gain is a function of the uncertainty of the estimated state and the measurement noise such that</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e068" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e069" xlink:type="simple"/></inline-formula> is the uncertainty of the state estimation and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e070" xlink:type="simple"/></inline-formula> is the variance of the observation noise.</p>
          <p>The optimal policy outputs motor commands as a function of the estimated state. In optimal control theory, the policy is computed from the end of the learning period backward <xref ref-type="bibr" rid="pcbi.1002012-Izawa1">[24]</xref>. However, in a learning problem, the learner updates the policy on every trial and the backward computation is not plausible. Thus, we used Actor-Critic architecture that enables it to find the optimal policy without backward computation <xref ref-type="bibr" rid="pcbi.1002012-Sutton1">[51]</xref>. Here we represent this policy with</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e071" xlink:type="simple"/><label>(10)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e072" xlink:type="simple"/></inline-formula> represents the active search noise to explore the motor commands and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e073" xlink:type="simple"/></inline-formula> represents changes to the motor commands to maximize reward. Suppose that the expected cost-to-go function is of the form</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e074" xlink:type="simple"/><label>(11)</label></disp-formula>for a general reward function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e075" xlink:type="simple"/></inline-formula> and discount rate of reward <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e076" xlink:type="simple"/></inline-formula>. We used a standard temporal learning algorithm to solve this optimization problem <xref ref-type="bibr" rid="pcbi.1002012-Izawa3">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002012-Sutton1">[51]</xref>. In this algorithm, the policy is updated to minimize the reward prediction error:</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e077" xlink:type="simple"/><label>(12)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e078" xlink:type="simple"/></inline-formula>. We used Temporal Difference (TD) error learning algorithm to updates the policy and the value.</p>
          <p>
            <disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e079" xlink:type="simple"/><label>(13)</label></disp-formula>
          </p>
          <p>For our simulations (<xref ref-type="fig" rid="pcbi-1002012-g003">Fig. 3C</xref>), we used the following definition of the reward function:</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e080" xlink:type="simple"/><label>(14)</label></disp-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e081" xlink:type="simple"/></inline-formula> is the scaling parameter of the motor cost.</p>
          <p>In summary, the learner has two kinds of prediction errors: a sensory prediction error (Eq. 8), and a reward prediction error (Eq. 13). The sensory prediction error updates an estimate of state produced by the motor commands (the sensory consequences of the action). The reward prediction error updates an estimate of the value of the states, and the policy that describes the ‘best’ motor commands to maximize reward.</p>
        </sec>
        <sec id="s4b6">
          <title>Fitting the model to data</title>
          <p>The previous section described how, in principle, one might alter the motor commands from trial to trial based on sensory and reward prediction errors. Here, we wished to fit this model to people's data and then test the predictions of the model. In the ERR and EPE paradigm, subjects were provided with both types of error, whereas in the RWD paradigm they were provided with only reward information. Our objective was to estimate contributions of each form of error to the change in motor commands during these three paradigms.</p>
          <p>Our data from each subject consisted of the following: reach angle <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e082" xlink:type="simple"/></inline-formula>, visual cursor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e083" xlink:type="simple"/></inline-formula> (both in units of degrees), and success or failure on that trial (reward) <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e084" xlink:type="simple"/></inline-formula>. If a subject generated hand position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e085" xlink:type="simple"/></inline-formula> on a given trial, we assumed that this was related to three hidden variables: their estimate of perturbation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e086" xlink:type="simple"/></inline-formula>, the accumulated change in the motor commands due to reward prediction errors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e087" xlink:type="simple"/></inline-formula>, and an active search noise to find more rewarding motor commands <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e088" xlink:type="simple"/></inline-formula>:</p>
          <p>
            <disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e089" xlink:type="simple"/><label>(15)</label></disp-formula>
          </p>
          <p>The problem is to estimate the variables of the right hand side from the measured sequence of hand positions. This requires solving an optimization problem. A rational cost is to minimize the squared difference between the observed sequence of hand positions and the sequence predicted by the model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e090" xlink:type="simple"/></inline-formula>. This is equivalent to minimizing the summation of magnitude of the active search noise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e091" xlink:type="simple"/></inline-formula>. The constraint equations of this optimization process are Eqs. (8) and (13).</p>
          <p>From Eq. (15) we have</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e092" xlink:type="simple"/><label>(16)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e093" xlink:type="simple"/></inline-formula> is the experimenter's observation of subject's hand position, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e094" xlink:type="simple"/></inline-formula>and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e095" xlink:type="simple"/></inline-formula> are the memory the optimal learner model updated. We will substitute Eq. (16) into Eq. (13) to update <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e096" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e097" xlink:type="simple"/></inline-formula>.</p>
          <p>We would also estimate the sensory prediction error is:</p>
          <p><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e098" xlink:type="simple"/><label>(17)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e099" xlink:type="simple"/></inline-formula> is the visual rotation that the experimenter imposed and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e100" xlink:type="simple"/></inline-formula> is the estimation of the perturbation that the optimal learner updated. Then, we substitute Eq. (17) into Eq. (8) in order to update <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e101" xlink:type="simple"/></inline-formula>.</p>
          <p>Starting with initial conditions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e102" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e103" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e104" xlink:type="simple"/></inline-formula>, if we knew the unknown parameters [<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e105" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e106" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e107" xlink:type="simple"/></inline-formula>], we could use the sensory prediction error in Eq. (8) to update <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e108" xlink:type="simple"/></inline-formula>, and the reward prediction error to update <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e109" xlink:type="simple"/></inline-formula> while updating the estimation of the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e110" xlink:type="simple"/></inline-formula> though updating <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e111" xlink:type="simple"/></inline-formula>. We searched for these three unknown parameters (using lsqnonlin in Matlab 6.5) in order to minimize the squared sum of difference between the model generated sequence of hand positions and the measured hand positions for each subject. We found that in the ERR paradigm, the average of the estimated parameters were [<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e112" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e113" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e114" xlink:type="simple"/></inline-formula>] = [6, 0.15, 0.04] and in EPE paradigm, [69, 0.39, 0.03]. In the RWD paradigm, because no visual feedback of the hand position was provided, we assumed that motor commands were updated only by the reward prediction error. We set the Kalman gain to be zero and the average of the estimated parameters were [<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e115" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e116" xlink:type="simple"/></inline-formula>] = [0.13, 0.14]. In the main document, we report the evolution of two memories and the sum of them: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e117" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e118" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002012.e119" xlink:type="simple"/></inline-formula>.</p>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We wish to thank Andy Barto for helpful discussions.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002012-Synofzik1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Synofzik</surname><given-names>M</given-names></name><name name-style="western"><surname>Thier</surname><given-names>P</given-names></name><name name-style="western"><surname>Lindner</surname><given-names>A</given-names></name></person-group>             <year>2006</year>             <article-title>Internalizing agency of self-action: perception of one's own hand movements depends on an adaptable prediction about the sensory action outcome.</article-title>             <source>J Neurophysiol</source>             <volume>96</volume>             <fpage>1592</fpage>             <lpage>1601</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Synofzik2">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Synofzik</surname><given-names>M</given-names></name><name name-style="western"><surname>Lindner</surname><given-names>A</given-names></name><name name-style="western"><surname>Thier</surname><given-names>P</given-names></name></person-group>             <year>2008</year>             <article-title>The cerebellum updates predictions about the visual consequences of one's behavior.</article-title>             <source>Curr Biol</source>             <volume>18</volume>             <fpage>814</fpage>             <lpage>818</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Baddeley1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Baddeley</surname><given-names>RJ</given-names></name><name name-style="western"><surname>Ingram</surname><given-names>HA</given-names></name><name name-style="western"><surname>Miall</surname><given-names>RC</given-names></name></person-group>             <year>2003</year>             <article-title>System identification applied to a visuomotor task: near-optimal human performance in a noisy changing task.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>3066</fpage>             <lpage>3075</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Berniker1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Berniker</surname><given-names>M</given-names></name><name name-style="western"><surname>Kording</surname><given-names>K</given-names></name></person-group>             <year>2008</year>             <article-title>Estimating the sources of motor errors for adaptation and generalization.</article-title>             <source>Nat Neurosci</source>             <volume>11</volume>             <fpage>1454</fpage>             <lpage>1461</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Kording1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kording</surname><given-names>KP</given-names></name><name name-style="western"><surname>Tenenbaum</surname><given-names>JB</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2007</year>             <article-title>The dynamics of memory as a consequence of optimal adaptation to a changing body.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>779</fpage>             <lpage>786</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Sing1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sing</surname><given-names>GC</given-names></name><name name-style="western"><surname>Joiner</surname><given-names>WM</given-names></name><name name-style="western"><surname>Nanayakkara</surname><given-names>T</given-names></name><name name-style="western"><surname>Brayanov</surname><given-names>JB</given-names></name><name name-style="western"><surname>Smith</surname><given-names>MA</given-names></name></person-group>             <year>2009</year>             <article-title>Primitives for motor adaptation reflect correlated neural tuning to position and velocity.</article-title>             <source>Neuron</source>             <volume>64</volume>             <fpage>575</fpage>             <lpage>589</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-vanBeers1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>van Beers</surname><given-names>RJ</given-names></name></person-group>             <year>2009</year>             <article-title>Motor learning is optimally tuned to the properties of motor noise.</article-title>             <source>Neuron</source>             <volume>63</volume>             <fpage>406</fpage>             <lpage>417</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Frank1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Frank</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Doll</surname><given-names>BB</given-names></name><name name-style="western"><surname>Oas-Terpstra</surname><given-names>J</given-names></name><name name-style="western"><surname>Moreno</surname><given-names>F</given-names></name></person-group>             <year>2009</year>             <article-title>Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation.</article-title>             <source>Nat Neurosci</source>             <volume>12</volume>             <fpage>1062</fpage>             <lpage>1068</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Schonberg1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schonberg</surname><given-names>T</given-names></name><name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name><name name-style="western"><surname>Joel</surname><given-names>D</given-names></name><name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name></person-group>             <year>2007</year>             <article-title>Reinforcement learning signals in the human striatum distinguish learners from nonlearners during reward-based decision making.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>12860</fpage>             <lpage>12867</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Trommershauser1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Trommershauser</surname><given-names>J</given-names></name><name name-style="western"><surname>Maloney</surname><given-names>LT</given-names></name><name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name></person-group>             <year>2008</year>             <article-title>Decision making, movement planning and statistical decision theory.</article-title>             <source>Trends Cogn Sci</source>             <volume>12</volume>             <fpage>291</fpage>             <lpage>297</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Kawato1">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name><name name-style="western"><surname>Gomi</surname><given-names>H</given-names></name></person-group>             <year>1992</year>             <article-title>A computational model of four regions of the cerebellum based on feedback-error learning.</article-title>             <source>Biol Cybern</source>             <volume>68</volume>             <fpage>95</fpage>             <lpage>103</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Kawato2">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kawato</surname><given-names>M</given-names></name></person-group>             <year>1999</year>             <article-title>Internal models for motor control and trajectory planning.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>9</volume>             <fpage>718</fpage>             <lpage>727</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Thoroughman1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Thoroughman</surname><given-names>KA</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2000</year>             <article-title>Learning of action through adaptive combination of motor primitives.</article-title>             <source>Nature</source>             <volume>407</volume>             <fpage>742</fpage>             <lpage>747</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Smith1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>MA</given-names></name><name name-style="western"><surname>Ghazizadeh</surname><given-names>A</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2006</year>             <article-title>Interacting adaptive processes with different timescales underlie short-term motor learning.</article-title>             <source>PLoS Biol</source>             <volume>4</volume>             <fpage>e179</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Pearson1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pearson</surname><given-names>TS</given-names></name><name name-style="western"><surname>Krakauer</surname><given-names>JW</given-names></name><name name-style="western"><surname>Mazzoni</surname><given-names>P</given-names></name></person-group>             <year>2010</year>             <article-title>Learning not to generalize: modular adaptation of visuomotor gain.</article-title>             <source>J Neurophysiol</source>             <volume>103</volume>             <fpage>2938</fpage>             <lpage>2952</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Shadmehr1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2004</year>             <article-title>Generalization as a behavioral window to the neural mechanisms of learning internal models.</article-title>             <source>Hum Mov Sci</source>             <volume>23</volume>             <fpage>543</fpage>             <lpage>568</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Haswell1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Haswell</surname><given-names>CC</given-names></name><name name-style="western"><surname>Izawa</surname><given-names>J</given-names></name><name name-style="western"><surname>Dowell</surname><given-names>LR</given-names></name><name name-style="western"><surname>Mostofsky</surname><given-names>SH</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2009</year>             <article-title>Representation of internal models of action in the autistic brain.</article-title>             <source>Nat Neurosci</source>             <volume>12</volume>             <fpage>970</fpage>             <lpage>972</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Bedford1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bedford</surname><given-names>FL</given-names></name></person-group>             <year>1999</year>             <article-title>Keeping perception accurate.</article-title>             <source>Trends Cogn Sci</source>             <volume>3</volume>             <fpage>4</fpage>             <lpage>11</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Wolpert1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wolpert</surname><given-names>DM</given-names></name><name name-style="western"><surname>Ghahramani</surname><given-names>Z</given-names></name></person-group>             <year>2000</year>             <article-title>Computational principles of movement neuroscience.</article-title>             <source>Nat Neurosci</source>             <volume>3</volume>             <supplement>Suppl</supplement>             <fpage>1212</fpage>             <lpage>1217</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Barnes1">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Barnes</surname><given-names>TD</given-names></name><name name-style="western"><surname>Kubota</surname><given-names>Y</given-names></name><name name-style="western"><surname>Hu</surname><given-names>D</given-names></name><name name-style="western"><surname>Jin</surname><given-names>DZ</given-names></name><name name-style="western"><surname>Graybiel</surname><given-names>AM</given-names></name></person-group>             <year>2005</year>             <article-title>Activity of striatal neurons reflects dynamic encoding and recoding of procedural memories.</article-title>             <source>Nature</source>             <volume>437</volume>             <fpage>1158</fpage>             <lpage>1161</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Trommershauser2">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Trommershauser</surname><given-names>J</given-names></name><name name-style="western"><surname>Gepshtein</surname><given-names>S</given-names></name><name name-style="western"><surname>Maloney</surname><given-names>LT</given-names></name><name name-style="western"><surname>Landy</surname><given-names>MS</given-names></name><name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name></person-group>             <year>2005</year>             <article-title>Optimal compensation for changes in task-relevant movement variability.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>7169</fpage>             <lpage>7178</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Takikawa1">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Takikawa</surname><given-names>Y</given-names></name><name name-style="western"><surname>Kawagoe</surname><given-names>R</given-names></name><name name-style="western"><surname>Itoh</surname><given-names>H</given-names></name><name name-style="western"><surname>Nakahara</surname><given-names>H</given-names></name><name name-style="western"><surname>Hikosaka</surname><given-names>O</given-names></name></person-group>             <year>2002</year>             <article-title>Modulation of saccadic eye movements by predicted reward outcome.</article-title>             <source>Exp Brain Res</source>             <volume>142</volume>             <fpage>284</fpage>             <lpage>291</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Doya1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name></person-group>             <year>2000</year>             <article-title>Complementary roles of basal ganglia and cerebellum in learning and motor control.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>10</volume>             <fpage>732</fpage>             <lpage>739</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Izawa1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Izawa</surname><given-names>J</given-names></name><name name-style="western"><surname>Rane</surname><given-names>T</given-names></name><name name-style="western"><surname>Donchin</surname><given-names>O</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2008</year>             <article-title>Motor adaptation as a process of reoptimization.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>2883</fpage>             <lpage>2891</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Izawa2">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Izawa</surname><given-names>J</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2008</year>             <article-title>On-line processing of uncertain information in visuomotor control.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>11360</fpage>             <lpage>11368</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Todorov1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Todorov</surname><given-names>E</given-names></name><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name></person-group>             <year>2002</year>             <article-title>Optimal feedback control as a theory of motor coordination.</article-title>             <source>Nat Neurosci</source>             <volume>5</volume>             <fpage>1226</fpage>             <lpage>1235</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Shadmehr2">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name><name name-style="western"><surname>Krakauer</surname><given-names>JW</given-names></name></person-group>             <year>2008</year>             <article-title>A computational neuroanatomy for motor control.</article-title>             <source>Exp Brain Res</source>             <volume>185</volume>             <fpage>359</fpage>             <lpage>381</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Izawa3">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Izawa</surname><given-names>J</given-names></name><name name-style="western"><surname>Kondo</surname><given-names>T</given-names></name><name name-style="western"><surname>Ito</surname><given-names>K</given-names></name></person-group>             <year>2004</year>             <article-title>Biological arm motion through reinforcement learning.</article-title>             <source>Biol Cybern</source>             <volume>91</volume>             <fpage>10</fpage>             <lpage>22</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Poggio1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name><name name-style="western"><surname>Fahle</surname><given-names>M</given-names></name><name name-style="western"><surname>Edelman</surname><given-names>S</given-names></name></person-group>             <year>1992</year>             <article-title>Fast perceptual learning in visual hyperacuity.</article-title>             <source>Science</source>             <volume>256</volume>             <fpage>1018</fpage>             <lpage>1021</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Hwang1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hwang</surname><given-names>EJ</given-names></name><name name-style="western"><surname>Smith</surname><given-names>MA</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2006</year>             <article-title>Adaptation and generalization in acceleration-dependent force fields.</article-title>             <source>Exp Brain Res</source>             <volume>169</volume>             <fpage>496</fpage>             <lpage>506</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Tanaka1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tanaka</surname><given-names>H</given-names></name><name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name><name name-style="western"><surname>Krakauer</surname><given-names>JW</given-names></name></person-group>             <year>2009</year>             <article-title>Adaptation to visuomotor rotation through interaction between posterior parietal and motor cortical areas.</article-title>             <source>J Neurophysiol</source>             <volume>102</volume>             <fpage>2921</fpage>             <lpage>2932</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Tseng1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tseng</surname><given-names>YW</given-names></name><name name-style="western"><surname>Diedrichsen</surname><given-names>J</given-names></name><name name-style="western"><surname>Krakauer</surname><given-names>JW</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name><name name-style="western"><surname>Bastian</surname><given-names>AJ</given-names></name></person-group>             <year>2007</year>             <article-title>Sensory prediction errors drive cerebellum-dependent adaptation of reaching.</article-title>             <source>J Neurophysiol</source>             <volume>98</volume>             <fpage>54</fpage>             <lpage>62</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Smith2">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>MA</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2005</year>             <article-title>Intact ability to learn internal models of arm dynamics in Huntington's disease but not cerebellar degeneration.</article-title>             <source>J Neurophysiol</source>             <volume>93</volume>             <fpage>2809</fpage>             <lpage>2821</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Yin1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yin</surname><given-names>HH</given-names></name><name name-style="western"><surname>Knowlton</surname><given-names>BJ</given-names></name></person-group>             <year>2006</year>             <article-title>The role of the basal ganglia in habit formation.</article-title>             <source>Nat Rev Neurosci</source>             <volume>7</volume>             <fpage>464</fpage>             <lpage>476</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Nakahara1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Nakahara</surname><given-names>H</given-names></name><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name><name name-style="western"><surname>Hikosaka</surname><given-names>O</given-names></name></person-group>             <year>2001</year>             <article-title>Parallel cortico-basal ganglia mechanisms for acquisition and execution of visuomotor sequences - a computational approach.</article-title>             <source>J Cogn Neurosci</source>             <volume>13</volume>             <fpage>626</fpage>             <lpage>647</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Tanaka2">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tanaka</surname><given-names>SC</given-names></name><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name><name name-style="western"><surname>Okada</surname><given-names>G</given-names></name><name name-style="western"><surname>Ueda</surname><given-names>K</given-names></name><name name-style="western"><surname>Okamoto</surname><given-names>Y</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Prediction of immediate and future rewards differentially recruits cortico-basal ganglia loops.</article-title>             <source>Nat Neurosci</source>             <volume>7</volume>             <fpage>887</fpage>             <lpage>893</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Samejima1">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Samejima</surname><given-names>K</given-names></name><name name-style="western"><surname>Ueda</surname><given-names>Y</given-names></name><name name-style="western"><surname>Doya</surname><given-names>K</given-names></name><name name-style="western"><surname>Kimura</surname><given-names>M</given-names></name></person-group>             <year>2005</year>             <article-title>Representation of action-specific reward values in the striatum.</article-title>             <source>Science</source>             <volume>310</volume>             <fpage>1337</fpage>             <lpage>1340</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Packard1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Packard</surname><given-names>MG</given-names></name><name name-style="western"><surname>Knowlton</surname><given-names>BJ</given-names></name></person-group>             <year>2002</year>             <article-title>Learning and memory functions of the Basal Ganglia.</article-title>             <source>Annu Rev Neurosci</source>             <volume>25</volume>             <fpage>563</fpage>             <lpage>593</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Wickens1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wickens</surname><given-names>JR</given-names></name><name name-style="western"><surname>Reynolds</surname><given-names>JN</given-names></name><name name-style="western"><surname>Hyland</surname><given-names>BI</given-names></name></person-group>             <year>2003</year>             <article-title>Neural mechanisms of reward-related motor learning.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>13</volume>             <fpage>685</fpage>             <lpage>690</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Dickinson1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Dickinson</surname><given-names>A</given-names></name><name name-style="western"><surname>Balleine</surname><given-names>B</given-names></name></person-group>             <year>1994</year>             <article-title>Motivational control of goal-directed action.</article-title>             <source>Anima Learn Behave</source>             <volume>22</volume>             <fpage>1</fpage>             <lpage>8</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Gabrieli1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gabrieli</surname><given-names>JD</given-names></name><name name-style="western"><surname>Stebbins</surname><given-names>GT</given-names></name><name name-style="western"><surname>Singh</surname><given-names>J</given-names></name><name name-style="western"><surname>Willingham</surname><given-names>DB</given-names></name><name name-style="western"><surname>Goetz</surname><given-names>CG</given-names></name></person-group>             <year>1997</year>             <article-title>Intact mirror-tracing and impaired rotary-pursuit skill learning in patients with Huntington's disease: evidence for dissociable memory systems in skill learning.</article-title>             <source>Neuropsychology</source>             <volume>11</volume>             <fpage>272</fpage>             <lpage>281</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Agostino1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Agostino</surname><given-names>R</given-names></name><name name-style="western"><surname>Sanes</surname><given-names>JN</given-names></name><name name-style="western"><surname>Hallett</surname><given-names>M</given-names></name></person-group>             <year>1996</year>             <article-title>Motor skill learning in Parkinson's disease.</article-title>             <source>J Neurol Sci</source>             <volume>139</volume>             <fpage>218</fpage>             <lpage>226</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Marinelli1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Marinelli</surname><given-names>L</given-names></name><name name-style="western"><surname>Crupi</surname><given-names>D</given-names></name><name name-style="western"><surname>Di Rocco</surname><given-names>A</given-names></name><name name-style="western"><surname>Bove</surname><given-names>M</given-names></name><name name-style="western"><surname>Eidelberg</surname><given-names>D</given-names></name><etal/></person-group>             <year>2009</year>             <article-title>Learning and consolidation of visuo-motor adaptation in Parkinson's disease.</article-title>             <source>Parkinsonism Relat Disord</source>             <volume>15</volume>             <fpage>6</fpage>             <lpage>11</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-CriscimagnaHemminger1">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Criscimagna-Hemminger</surname><given-names>SE</given-names></name><name name-style="western"><surname>Bastian</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Shadmehr</surname><given-names>R</given-names></name></person-group>             <year>2010</year>             <article-title>Size of error affects cerebellar contributions to motor learning.</article-title>             <source>J Neurophysiol</source>             <volume>103</volume>             <fpage>2275</fpage>             <lpage>2284</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Harris1">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Harris</surname><given-names>CM</given-names></name><name name-style="western"><surname>Wolpert</surname><given-names>DM</given-names></name></person-group>             <year>1998</year>             <article-title>Signal-dependent noise determines motor planning.</article-title>             <source>Nature</source>             <volume>394</volume>             <fpage>780</fpage>             <lpage>784</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Jones1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>KE</given-names></name><name name-style="western"><surname>Hamilton</surname><given-names>AF</given-names></name><name name-style="western"><surname>Wolpert</surname><given-names>DM</given-names></name></person-group>             <year>2002</year>             <article-title>Sources of signal-dependent noise during isometric force production.</article-title>             <source>J Neurophysiol</source>             <volume>88</volume>             <fpage>1533</fpage>             <lpage>1544</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Faisal1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Faisal</surname><given-names>AA</given-names></name><name name-style="western"><surname>Selen</surname><given-names>LP</given-names></name><name name-style="western"><surname>Wolpert</surname><given-names>DM</given-names></name></person-group>             <year>2008</year>             <article-title>Noise in the nervous system.</article-title>             <source>Nat Rev Neurosci</source>             <volume>9</volume>             <fpage>292</fpage>             <lpage>303</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Churchland1">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Churchland</surname><given-names>MM</given-names></name><name name-style="western"><surname>Afshar</surname><given-names>A</given-names></name><name name-style="western"><surname>Shenoy</surname><given-names>KV</given-names></name></person-group>             <year>2006</year>             <article-title>A central source of movement variability.</article-title>             <source>Neuron</source>             <volume>52</volume>             <fpage>1085</fpage>             <lpage>1096</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Burge1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Burge</surname><given-names>J</given-names></name><name name-style="western"><surname>Ernst</surname><given-names>MO</given-names></name><name name-style="western"><surname>Banks</surname><given-names>MS</given-names></name></person-group>             <year>2008</year>             <article-title>The statistical determinants of adaptation rate in human reaching.</article-title>             <source>J Vis 8: 20</source>             <volume>21-19</volume>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Kording2">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kording</surname><given-names>KP</given-names></name><name name-style="western"><surname>Ku</surname><given-names>SP</given-names></name><name name-style="western"><surname>Wolpert</surname><given-names>DM</given-names></name></person-group>             <year>2004</year>             <article-title>Bayesian integration in force estimation.</article-title>             <source>J Neurophysiol</source>             <volume>92</volume>             <fpage>3161</fpage>             <lpage>3165</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002012-Sutton1">
        <label>51</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sutton</surname><given-names>R</given-names></name><name name-style="western"><surname>Barto</surname><given-names>A</given-names></name></person-group>             <year>1998</year>             <article-title>Reinforcement Learning: An Introduction (Adaptive Computation and Machine Learning).</article-title>                          <publisher-name>MIT Press</publisher-name>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
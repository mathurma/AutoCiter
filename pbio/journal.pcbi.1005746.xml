<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-00831</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005746</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Factor analysis</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (mathematics)</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Factor analysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Clinical genetics</subject><subj-group><subject>Genetic diseases</subject><subj-group><subject>Autosomal recessive diseases</subject><subj-group><subject>Sickle cell disease</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Hematology</subject><subj-group><subject>Hemoglobinopathies</subject><subj-group><subject>Sickle cell disease</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Hematology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Chemistry</subject><subj-group><subject>Chemical reactions</subject><subj-group><subject>Deoxygenation</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Blood cells</subject><subj-group><subject>Red blood cells</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Machine learning</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A deep convolutional neural network for classification of red blood cells in sickle cell anemia</article-title>
<alt-title alt-title-type="running-head">RBC screening based on deep CNNs</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Xu</surname> <given-names>Mengjia</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Papageorgiou</surname> <given-names>Dimitrios P.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Abidi</surname> <given-names>Sabia Z.</given-names></name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dao</surname> <given-names>Ming</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Zhao</surname> <given-names>Hong</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9713-7120</contrib-id>
<name name-style="western">
<surname>Karniadakis</surname> <given-names>George Em</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Key Laboratory of Medical Image Computing of Ministry of Education, Northeastern University, Shenyang, China</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Division of Applied Mathematics, Brown University, Providence, Rhode Island, United States of America</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Materials Science and Engineering, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Nie</surname> <given-names>Qing</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of California Irvine, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">george_karniadakis@brown.edu</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>10</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>19</day>
<month>10</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>10</issue>
<elocation-id>e1005746</elocation-id>
<history>
<date date-type="received">
<day>23</day>
<month>5</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>29</day>
<month>8</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Xu et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005746"/>
<abstract>
<p>Sickle cell disease (SCD) is a hematological disorder leading to blood vessel occlusion accompanied by painful episodes and even death. Red blood cells (RBCs) of SCD patients have diverse shapes that reveal important biomechanical and bio-rheological characteristics, <italic>e.g.</italic> their density, fragility, adhesive properties, etc. Hence, having an objective and effective way of RBC shape quantification and classification will lead to better insights and eventual better prognosis of the disease. To this end, we have developed an automated, high-throughput, ex-vivo RBC shape classification framework that consists of three stages. First, we present an automatic hierarchical RBC extraction method to detect the RBC region (ROI) from the background, and then separate touching RBCs in the ROI images by applying an improved random walk method based on automatic seed generation. Second, we apply a mask-based RBC patch-size normalization method to normalize the variant size of segmented single RBC patches into uniform size. Third, we employ deep convolutional neural networks (CNNs) to realize RBC classification; the alternating convolution and pooling operations can deal with non-linear and complex patterns. Furthermore, we investigate the specific shape factor quantification for the classified RBC image data in order to develop a general multiscale shape analysis. We perform several experiments on raw microscopy image datasets from 8 SCD patients (over 7,000 single RBC images) through a 5-fold cross validation method both for oxygenated and deoxygenated RBCs. We demonstrate that the proposed framework can successfully classify sickle shape RBCs in an automated manner with high accuracy, and we also provide the corresponding shape factor analysis, which can be used synergistically with the CNN analysis for more robust predictions. Moreover, the trained deep CNN exhibits good performance even for a deoxygenated dataset and distinguishes the subtle differences in texture alteration inside the oxygenated and deoxygenated RBCs.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>There are many hematological disorders in the human circulation involving significant alteration of the shape and size of red blood cells (RBCs), e.g. sickle cell disease (SCD), spherocytosis, diabetes, HIV, etc. These morphological alterations reflect subtle multiscale processes taking place at the protein level and affecting the cell shape, its size, and rigidity. In SCD, in particular, there are multiple shape types in addition to the sickle shape, directly related to the sickle hemoglobin polymerization inside the RBC, which is induced by hypoxic conditions, e.g., in the post-capillary regions, in the spleen, etc. Moreover, the induced stiffness of RBCs depends on the de-oxygenation level encountered in hypoxic environments. Here, we develop a new computational framework based on deep convolutional networks in order to classify efficiently the heterogeneous shapes encountered in the sickle blood, and we complement our method with an independent shape factor analysis. This dual approach provides robust predictions and can be potentially used to assess the severity of SCD. The method is general and can be adapted to other hematological disorders as well as to screen diseased cells from healthy ones for different diseases.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>U01HL114476</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9713-7120</contrib-id>
<name name-style="western">
<surname>Karniadakis</surname> <given-names>George Em</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>R01HL121386</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Dao</surname> <given-names>Ming</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>The authors acknowledge support by the National Institutes of Health (NIH) grant U01HL114476 and China Scholarship Council. DPP, SZA and MD acknowledge partial support from the Singapore-MIT Alliance for Research and Technology (SMART) Center and NIH grant R01HL121386. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="22"/>
<table-count count="5"/>
<page-count count="27"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Sickle cell disease (SCD), also known as sickle cell anemia, is a type of inherited RBC disorder associated with abnormal hemoglobin S (HbS) [<xref ref-type="bibr" rid="pcbi.1005746.ref001">1</xref>]. When HbS molecules polymerize inside RBCs, due to lack of oxygen, they affect greatly the shape, elasticity, and adhesion properties of RBCs. Moreover, the RBCs become stiff and more fragile, with vastly heterogeneous shapes in the cell population [<xref ref-type="bibr" rid="pcbi.1005746.ref002">2</xref>], which makes this problem an ideal candidate for the examination of morphological heterogeneity. Unlike the normal RBCs, which are flexible and move easily even through very small blood vessels, sickle RBCs promote vaso-occlusion phenomena. Hence, SCD patients are afflicted with the risk of life-threatening complications, stroke and organ damage over time, resulting in a reduced life expectancy. According to a recent study [<xref ref-type="bibr" rid="pcbi.1005746.ref003">3</xref>], as of 2013 about 3.2 million people have SCD while an additional 43 million have sickle-cell trait, resulting in 176,000 deaths in 2013, up from 113,000 deaths in 1990, mostly of African origin. The prime hallmark of SCD is that is surprisingly variable in its clinical severity. Available methods for treating SCD are mainly supportive and mostly aim at symptom control, but lack the active monitoring of the health status as well as the prediction of disease development in different clinical stages [<xref ref-type="bibr" rid="pcbi.1005746.ref004">4</xref>]. Recent developments in advanced medical imaging technology and computerized image processing methods could provide an effective tool in monitoring the status of SCD patients. Indeed, Darrow et al. [<xref ref-type="bibr" rid="pcbi.1005746.ref005">5</xref>] recently demonstrated a positive correlation between cell volume and protrusion number using soft X-ray tomography. Van beers et al. [<xref ref-type="bibr" rid="pcbi.1005746.ref006">6</xref>] have also shown highly specific and sensitive sickle and normal erythrocyte classification based on sickle imaging flow cytometry assay, a methodology that could be useful in assessing drug efficacy in SCD.</p>
<p>Therefore, implementing an automated, high-throughput cell classification method could become an enabling technology to improve the future clinical diagnosis, prediction of treatment outcome, and especially therapy planning. However, there are several major technical challenges for automatic cell classification: 1) RBCs may touch or overlap each other or appear as clusters in the image, which makes it difficult to detect the hidden edge of cells. 2) The RBC region and the background may have low contrast in the intensity. 3) The boundaries of RBCs may be blurry due to the influence of imaging procedure. 4) Very complex and heterogeneous shapes of RBCs are present in SCD. 5) Artifacts may be present, for instance, dirt on the imaging light path, various halos and shading. 6) Finally, because RBCs lack a nucleus, methods utilizing the nuclei location as an apparent marker for cell counting and detection are not applicable.</p>
<p>The objective of the current work is to develop an automated algorithm for sickle RBC classification test, which may prove a powerful complementary clinical test for a) assessing patient’s disease severity via longitudinal tracking and patient-specific RBC mapping, and b) intervention strategies via personalized medicine treatment monitoring. Next, we present a brief overview of the state-of-the-art techniques involved in cell segmentation and classification.</p>
<p>Cell detection methods are prevalent, see e.g. [<xref ref-type="bibr" rid="pcbi.1005746.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1005746.ref010">10</xref>], and some open source software (e.g., CellProfiler [<xref ref-type="bibr" rid="pcbi.1005746.ref011">11</xref>], CellTrack [<xref ref-type="bibr" rid="pcbi.1005746.ref012">12</xref>], Fiji [<xref ref-type="bibr" rid="pcbi.1005746.ref013">13</xref>] and CellSegm [<xref ref-type="bibr" rid="pcbi.1005746.ref014">14</xref>], etc.) for 2D and 3D cell detection and counting has emerged recently. However, in SCD we need cell classification, which is quite difficult due to the heterogeneous shapes of RBCs and the existence of touching and overlapped RBCs in the raw microscopy image, and existing software cannot be directly used to obtain RBC boundaries and cannot distinguish among the many different types of RBCs. Presently, there are two kinds of cell classification approaches, i.e., manual and automatic. In the manual approach one inspects the blood samples using the microscope to count the number of cells and examines the outliers in each frame. This, apparently, is subjective, labor intensive and time consuming for batch data processing. Coulter Counters and Laser Flow Cytometers enable cell sorting automatically by detecting the current and light refraction changes during cell pass through the channel. However, there are some shortcomings, such as the high cost and low processing speed (106 cells/hour), and in particular, these instruments are not suitable for the classification of heterogeneous cells. Thus, some cellular data analysis tools have been recently developed targeting this problem. For example, ACCENSE [<xref ref-type="bibr" rid="pcbi.1005746.ref015">15</xref>] adopted two clustering methods (k-means and DBSCAN) to facilitate the cellular classification automatically, however, the clustering performance relies on the properly initiation of parameters by hand; moreover, the performance of cell classification degrades for the clusters with different size and different density. More recently, RSIP Vision (<ext-link ext-link-type="uri" xlink:href="http://www.rsipvision.com" xlink:type="simple">http://www.rsipvision.com</ext-link>) has developed a commercial software package, allowing the recognition and count of RBCs by using a classifier to classify the hand-crafted morphological features; however, the main drawback of this method is that it requires domain-specific expertise on the feature extraction,f and is also a time-consuming procedure. In addition, the accuracy of the method has not yet been demonstrated for cell classification. Both of the aforementioned methods use machine learning tools but not deep learning algorithms. Likewise, some other similar studies on the HEp-2 cell classification based on the traditional machine learning methods have emerged recently, such as in [<xref ref-type="bibr" rid="pcbi.1005746.ref016">16</xref>] where multi-variant linear descriptors were adopted to extract the features and applied the SVM method to realize HEp-2 cell classification with an accuracy of 66.6%. Other methods include superpixels-based sparse coding method approach [<xref ref-type="bibr" rid="pcbi.1005746.ref017">17</xref>], k-nearest clustering method for red blood cell and white blood cell classification [<xref ref-type="bibr" rid="pcbi.1005746.ref018">18</xref>], etc.</p>
<p>Due to ineffectiveness of the aforementioned methods and given the recent advances of deep learning technique, Gao et al. [<xref ref-type="bibr" rid="pcbi.1005746.ref019">19</xref>] performed HEp-2 cell classification based on deep CNNs. Also, in order to improve the diversity of single HEp-2 cell data samples, Li et al. [<xref ref-type="bibr" rid="pcbi.1005746.ref020">20</xref>] carried out classification experiments based on deep CNNs by using four different patients’ datasets under different lighting conditions. However, for the currently available automated machine learning methods, which could be used for cell classification, the following are still drawbacks: 1) the classification studies are mostly directly based on already prepared single HEp-2 cellular data, hence, ignoring the initial key procedure of single cell extraction from the raw image data; 2) the adopted conventional machine learning methods are time consuming for the hand-crafted feature extraction and need specific human expertise; moreover, they need an accurate cell segmentation; 3) the classification accuracy is limited by the selected features and the performance of selected classifier. For our application, since RBCs of SCD exhibit special characteristics in terms of heterogeneous shapes and variant sizes, there is still no efficient tool that can be used to facilitate the automated inspection and recognition of various kinds of RBC patterns which are present in SCD blood.</p>
<p>The main focus of our paper is to develop an automated, high-throughput sickle cell classification method based on the deep Convolutional Neural Networks (dCNNs), taking advantage of the hierarchical feature learning goodness of dCNNs. The rest of this paper is organized as follows: In Section 3 we present our methodology, and in Section 4 we present the experimental results, a comparative analysis, and a discussion. Finally, in Section 5 we present the conclusion. <xref ref-type="supplementary-material" rid="pcbi.1005746.s001">S1</xref>–<xref ref-type="supplementary-material" rid="pcbi.1005746.s004">S4</xref> Appendix contain some more details of the collection of raw data, the shape factor analysis, the CNN architecture, and deoxygenation method of sickle RBCs.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<p>On the basis of the raw RBC microscopy image data from SCD patients following cell density fractionation [<xref ref-type="bibr" rid="pcbi.1005746.ref021">21</xref>] as shown in <xref ref-type="supplementary-material" rid="pcbi.1005746.s001">S1 Appendix</xref>, our automatic, high-throughput RBC classification assay consists of four main steps for the RBC-dCNN training: 1) Hierarchical RBC patch extraction, 2) Size-invariant RBC patch normalization, 3) RBC pattern classification based on deep CNN, and 4) Automated RBC shape factor calculation. A detailed overall training flowchart is shown in <xref ref-type="fig" rid="pcbi.1005746.g001">Fig 1</xref>. Each step of the algorithm is described below.</p>
<fig id="pcbi.1005746.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Overall flowchart of our proposed training and learning methodology for the sickle RBC-dCNN classification model describing the four main steps, including an independent shape factor analysis.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g001" xlink:type="simple"/>
</fig>
<sec id="sec003">
<title>Hierarchical RBC patch extraction and size-invariant RBC patch normalization</title>
<p>In the traditional learning-based cell image segmentation or classification method, the two most common techniques to obtain the training patches are the exhaustive pixel-wise sliding window with the same size method [<xref ref-type="bibr" rid="pcbi.1005746.ref022">22</xref>] and the ground truth bounding box method, <italic>e.g.</italic> Li et al. [<xref ref-type="bibr" rid="pcbi.1005746.ref020">20</xref>]. However, the major drawback of the pixel-wise block splitting method for the application of RBC classification is that it generates a large number of unwanted and redundant patches for the background and artifacts (<italic>e.g.</italic>, dirt or debris in the light path) to feed for training and testing of the neural network. This redundancy and artifacts significantly hinder the efficiency of the method to take into account the high resolution of the microscopy data and large background area. The ground truth bounding box method was based on manual labeling of cells present in raw images, a process which is labor intensive and needs specific domain knowledge.</p>
<p>In addition, due to the fact that sickle cells are always heterogeneous in shape and at times touch or overlap, it can be difficult to obtain all single RBC patches by using the sliding or bounding box window with a fixed pixel size. Therefore, in our study, a hierarchical RBC patch extraction method was developed to overcome the above problems. The complete flowchart of the proposed method is shown in <xref ref-type="fig" rid="pcbi.1005746.g002">Fig 2</xref>.</p>
<fig id="pcbi.1005746.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Hierarchical RBC patch extraction algorithm workflow.</title> <p>See also Figs <xref ref-type="fig" rid="pcbi.1005746.g003">3</xref> and <xref ref-type="fig" rid="pcbi.1005746.g004">4</xref> for details of each step.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g002" xlink:type="simple"/>
</fig>
<p>Firstly, the raw microscopy images were divided into overlapped patches by using the sliding window technique, with the block size <italic>N</italic> * <italic>N</italic>. Then, the entropy containing in each image block was estimated by <xref ref-type="disp-formula" rid="pcbi.1005746.e001">Eq (1)</xref> below:
<disp-formula id="pcbi.1005746.e001"><alternatives><graphic id="pcbi.1005746.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="normal">E</mml:mi> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>L</mml:mi></mml:munderover> <mml:msub><mml:mi>P</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo form="prefix">log</mml:mo> <mml:msub><mml:mi>P</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>L</italic> is the maximum grayscale level, <italic>P</italic><sub><italic>i</italic></sub> refers to the probability of occurrence for each intensity level that is encountered in the image block, and it can be derived from the <italic>i</italic>th histogram count <italic>f</italic>(<italic>i</italic>, <italic>j</italic>) divided by the amount of pixels in each subblock image (the size of the block is <italic>N</italic>), as shown in <xref ref-type="disp-formula" rid="pcbi.1005746.e002">Eq (2)</xref> below:
<disp-formula id="pcbi.1005746.e002"><alternatives><graphic id="pcbi.1005746.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">P</mml:mi> <mml:mi mathvariant="normal">i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>f</mml:mi> <mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>N</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula></p>
<p>We have employed the information entropy to measure the uncertainty in RBC regions and the background region; the high entropy regions were extracted as the ROI (region of interest), <italic>i.e.</italic> the RBC regions in the raw microscopy images. The detailed ROI extraction procedure is shown in <xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3</xref>.</p>
<fig id="pcbi.1005746.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Determining ROIs and RBC patch extraction based on information from the entropy statistical estimation and morphology operations.</title>
<p>(A) raw microscopy image. (B) Blocks with high entropy. (C) ROI mask image. (D) Detection of ROIs. (E) Boundaries of ROIs. (F) Single &amp; “touching/overlapped”.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g003" xlink:type="simple"/>
</fig>
<p>First, raw microscopy images (<xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3A</xref> in high resolution were split into overlapped blocks. Next, the information entropy was calculated for all sub-blocks (including the edges and noises blocks). The blocks with high entropy are shown in white color in <xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3B</xref>, where the entropy threshold (5.0) was obtained from our validation experiments on different datasets. The corresponding ROI mask image was generated by filling the holes and removing the artifacts with area smaller than a common RBC prior area (6*10*10) for the result of <xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3B</xref>. The result is shown in <xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3C</xref> with each color representing a single ROI region. <xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3D</xref> shows the “cleaned” RBC ROI region result corresponding to the ROI mask image. The entropy estimation method can effectively extract the complete RBC regions from the raw images, especially for those RBC boundaries in a low intensity contrast. Moreover, it can also detect the RBC region correctly from various datasets regradless of their brightness differences. Thus, it can effectively overcome the shortcomings of the previous commonly used methods (<italic>e.g.</italic>, Ostu, watershed and Sobel, etc.). To obtain the RBC patch images for the deep CNNs, the high-level ROI boundary is detected and by searching the minimum coordination of pixel (<italic>x</italic><sub>0</sub>, <italic>y</italic><sub>0</sub>) and maximum pixel coordination (<italic>x</italic>′, <italic>y</italic>′) from the boundary pixels, the ROI patches are illustrated as shown in <xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3E</xref>.</p>
<p>It should be noted, however, that for the particular situation of overlapped and touching RBCs that may be present in the raw microscopy image, we may obtain some extracted ROI regions containing multiple cells; see the yellow smaller sized box in <xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3F</xref>, where 8 ROI patches contain two or more RBCs, and the pink smaller sized box that includes all segmented single RBC patches. The subimages in the two boxes were obtained by calculating the corresponding bounding boxes of the ROI. Overlapping RBCs were removed from the input of deep CNNs in our work. Therefore, we only focused on the “touching” RBC separation problem by applying the random walk method [<xref ref-type="bibr" rid="pcbi.1005746.ref023">23</xref>] in conjunction with the distance transform [<xref ref-type="bibr" rid="pcbi.1005746.ref024">24</xref>] to generate the RBC boundary. This method can obtain the RBC seed points identification automatically. The specific separation procedure is shown in <xref ref-type="fig" rid="pcbi.1005746.g004">Fig 4</xref>.</p>
<fig id="pcbi.1005746.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Workflow of RBC patch generation from ROIs with touching RBCs.</title>
<p>(A) ROI patch. (B) binary ROI mask image. (C) Euclidean distance transfrom result. (D) Probability map based on random walk method with seeds (green dots) obtained from distance transform result. (E) separated RBC binary mask. (F) segmented RBC outlines (red line). (G) bounding boxes of single RBCs. (H) The touching RBCs are separated into four single RBC patches.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g004" xlink:type="simple"/>
</fig>
<p>Because of the RBC heterogenity in size, shape and orientation, the generated single RBC patches from section B were of different sizes (see <xref ref-type="fig" rid="pcbi.1005746.g003">Fig 3E</xref>). In addition, due to varying brightness and intensity contrast conditions during the procedure of raw RBC microscopy data collection, the background of RBC patch images appeared to differ among datasets. Currently, commonly used image scaling methods for the image size normalization are prone to reducing the RBC patch image fidelity (<italic>e.g.</italic>, intensity contrast, noise and distortion), which will accordingly affect the RBC classification accuracy of the CNN. Therefore, to overcome the above issues, a size-invariant RBC patch normalization method based on statistic intensity linear mapping was employed. The algorithmic workflow is shown in <xref ref-type="fig" rid="pcbi.1005746.g005">Fig 5</xref>.</p>
<fig id="pcbi.1005746.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Workflow of the size-invariant (100px*100 px) RBC patch normalization.</title>
<p>Steps 1-5 are described in the text.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g005" xlink:type="simple"/>
</fig>
<list list-type="order">
<list-item><p><bold>Initial normalization mask selection.</bold> A background region with size of 100*100 pixels was cropped from the raw microscopy image as the initialized normalization mask, as shown in ① of <xref ref-type="fig" rid="pcbi.1005746.g005">Fig 5</xref>.</p></list-item>
<list-item><p><bold>Adaptive normalization mask generation based on statistical intensity linear mapping.</bold> Because the background area of every microscopy image as well as the single RBC patches have a uniform intensity distribution and a low mean intensity difference, we utilized a linear intensity mapping method (see steps from ② to ④ in <xref ref-type="fig" rid="pcbi.1005746.g005">Fig 5</xref>) to estimate the intensity difference between the unnormalized RBC patch and the standard normalization mask. Firstly, <italic>G</italic><sub><italic>k</italic></sub> = {<italic>y</italic><sub><italic>ki</italic></sub>|<italic>i</italic> = 1, 2, 3, 4} refers to the intensity sequence sampled from the <italic>k</italic>th RBC patch image (<italic>I</italic>), and <italic>B</italic> = {<italic>x</italic><sub><italic>i</italic></sub>|<italic>i</italic> = 1, 2, 3, 4} is the intensity sequence of initial standard normalization mask (<italic>M</italic>); <italic>x</italic><sub><italic>i</italic></sub>, <italic>y</italic><sub><italic>i</italic></sub> are the intensity values corresponding to the 4 sampled corners in the mask and patch image. In order to avoid extremely large or small grayscale values, we also employed the statistical median of <italic>G</italic><sub><italic>k</italic></sub> and <italic>B</italic> to estimate the background intensity difference (Δ<italic>M</italic>) between patch image <italic>I</italic> and the standard mask <italic>M</italic>. The median calculation is given in <xref ref-type="disp-formula" rid="pcbi.1005746.e003">Eq (3)</xref> below.
<disp-formula id="pcbi.1005746.e003"><alternatives><graphic id="pcbi.1005746.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="normal">M</mml:mi> <mml:mi mathvariant="normal">G</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>N</mml:mi> <mml:mspace width="4.pt"/><mml:mtext>is</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>odd,</mml:mtext></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mtext>if</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>N</mml:mi> <mml:mspace width="4.pt"/><mml:mtext>is</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>even.</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula></p>
<p>Here, <italic>G</italic>{<italic>x</italic><sub><italic>i</italic></sub>|<italic>i</italic> = 1, 2, …, <italic>N</italic>} is an arranged sequence, and <italic>N</italic> is the total number of observations. Finally, an adaptive normalization mask image was generated by performing the linear intensity mapping technique on the initial normalization background mask <italic>M</italic> according to the calculated intensity difference (Δ<italic>M</italic>); the details are shown in ④ of <xref ref-type="fig" rid="pcbi.1005746.g005">Fig 5</xref>.</p></list-item>
<list-item><p><bold>Align normalization mask with corresponding RBC patch.</bold> All single RBC patches in their respective various sizes were aligned at the center of their corresponding normalization mask, see ⑤ in <xref ref-type="fig" rid="pcbi.1005746.g005">Fig 5</xref>. In order to validate the performance of our method, we performed the proposed method on multiple RBC patches from different datasets with different background intensity distribution. Examples of the normalised size-invariant RBC patches from different datasets in <xref ref-type="fig" rid="pcbi.1005746.g006">Fig 6</xref> show that the RBC shape remains unaltered and staircase artifact free during the algorithmic operations.</p></list-item></list>
<fig id="pcbi.1005746.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Size-invariant RBC patch size normalization for eight different types of diseased RBCs (horizontal) and four different groups (vertical).</title>
<p>Images in the first row should be compared against the first column of “Discocytes”.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec004">
<title>RBC pattern classification based on deep CNN</title>
<p>In our work, we adopted a deep CNN architecture with 10 layers, including 3 convolutional layers (<italic>C</italic>1, <italic>C</italic>3 and <italic>C</italic>5), 3 pooling/subsampling layers (<italic>P</italic>2, <italic>P</italic>4 and <italic>P</italic>6), dropout layers (<italic>D</italic>7 and <italic>D</italic>9, where <italic>p</italic> = 0.5) and a fully connected layer (<italic>F</italic>8). As a result of the computational efficiency, the grayscale RBC image patches were initially resized to 78 * 78. Next, these were then fed into the neural network. A ReLU non-linear activation function was then applied. Following the <italic>F</italic>7 layer, a logistic regression method combining the softmax function (see <xref ref-type="disp-formula" rid="pcbi.1005746.e004">Eq (4)</xref>) with a cross-entropy loss function (see <xref ref-type="disp-formula" rid="pcbi.1005746.e005">Eq (5)</xref>) was implemented to obtain the final learning probability and predicted labels. The softmax function can “squash” the obtained score vector <italic>Q</italic> = {<italic>q</italic><sub><italic>i</italic></sub>|<italic>i</italic> = 1, 2, …, <italic>N</italic>} to a N-dimension probability vector <italic>δ</italic>(<italic>q</italic><sub><italic>i</italic></sub>), so as to aid RBC classification efficiency.
<disp-formula id="pcbi.1005746.e004"><alternatives><graphic id="pcbi.1005746.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:msup><mml:mi mathvariant="normal">Q</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mi>δ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>q</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:msub><mml:mi>q</mml:mi> <mml:mi>i</mml:mi></mml:msub></mml:msup> <mml:mo>/</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msup><mml:mi>e</mml:mi> <mml:msub><mml:mi>q</mml:mi> <mml:mi>j</mml:mi></mml:msub></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula> <disp-formula id="pcbi.1005746.e005"><alternatives><graphic id="pcbi.1005746.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mi mathvariant="normal">D</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="normal">Q</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="normal">Q</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mi>Q</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>Q</mml:mi> <mml:mi>i</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula></p>
<p>According to different shape division level for the original RBC patches, two kinds of RBC labeling principles were employed in the experiment: <italic>coarse labeling</italic>(output = 5) and <italic>refined labeling</italic> (output = 8). Thus, the output layer had two different dimensions (5 or 8 categories). More details about the deep CNN architecture applied in this paper are shown in <xref ref-type="fig" rid="pcbi.1005746.g007">Fig 7</xref> (see also <xref ref-type="supplementary-material" rid="pcbi.1005746.s003">S3 Appendix</xref> for the specific illustration of the layers of deep CNN).</p>
<fig id="pcbi.1005746.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Architecture of deep RBC-dCNN for SCD RBC classification.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g007" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>Automated RBC shape factor analysis following classification</title>
<p>As mentioned previously in the text, RBCs from SCD patients vary significantly in morphology/shape [<xref ref-type="bibr" rid="pcbi.1005746.ref025">25</xref>]. In the previous section, deep CNNs was applied to train and learn the diverse RBC patterns from RBC microscopy imaging data (see <xref ref-type="table" rid="pcbi.1005746.t001">Table 1</xref>). Hence, by utilizing this deep CNNs we can classify sickle RBC in different types according to training. In addition to RBC type classification we perform shape factor analysis for each RBC type to further quantify specific RBC shape parameters derived from the contour analysis of the individual RBCs. Three kinds of shape factors were calculated in this work.The shape factors’ formulas and pseudo-code for the specific implementation of the automatic RBC shape factors quantification method are given in <xref ref-type="supplementary-material" rid="pcbi.1005746.s002">S2 Appendix</xref>.</p>
<list list-type="bullet">
<list-item>
<p><bold>Regional shape factors:</bold> Segmented area and perimeter of RBC (<italic>Area</italic>_<italic>r</italic>, <italic>Perm</italic>_<italic>r</italic>), convex area and perimeter (<italic>Area</italic>_<italic>c</italic> and <italic>Perm</italic>_<italic>c</italic>), maximum Feret diameter (<italic>maxFD</italic>), minimum Feret diameter (<italic>minFD</italic>).</p>
</list-item>
<list-item>
<p><bold>Elliptical shape factors:</bold> Short axis (<italic>Rb</italic>), Long axis (<italic>Ra</italic>), Rotation angle (<italic>θ</italic>), etc.</p>
</list-item>
<list-item>
<p><bold>Derived shape factors:</bold> Ellipticity shape factor (<italic>ESF</italic>), Circular shape factor (<italic>CSF</italic>), Elongation, Convexity (<italic>Conv</italic>) and Compactness (<italic>Compt</italic>).</p>
</list-item>
</list>
<table-wrap id="pcbi.1005746.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.t001</object-id>
<label>Table 1</label>
<caption>
<title>Description of our experimental dataset from eight patients’ imaging data.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005746.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">No.</th>
<th align="left" style="border-bottom:thick">RBCs Type</th>
<th align="center" style="border-bottom:thick">Dataset_1<break/>(4 patients)</th>
<th align="center" style="border-bottom:thick">Dataset_2<break/>(3 more patients)</th>
<th align="center" style="border-bottom:thick">Total<break/>number of RBCs</th>
<th align="center" style="border-bottom:thick">Exp_I<break/>(4 patients)</th>
<th align="center" style="border-bottom:thick">Exp_II<break/>(8 patients)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="border-right:thick">1</td>
<td align="left">Discocytes[Dic]</td>
<td align="left">338</td>
<td align="left">-</td>
<td align="left">338</td>
<td align="left">2028</td>
<td align="left">2028</td>
</tr>
<tr>
<td align="left" style="border-right:thick">2</td>
<td align="left">Echinocytes[Ech]</td>
<td align="left">89</td>
<td align="left">34</td>
<td align="left">123</td>
<td align="left">534</td>
<td align="left">738</td>
</tr>
<tr>
<td align="left" style="border-right:thick">3</td>
<td align="left">Elongated[El]</td>
<td align="left">280</td>
<td align="left">-</td>
<td align="left">280</td>
<td align="left">1680</td>
<td align="left">1680</td>
</tr>
<tr>
<td align="left" style="border-right:thick">4</td>
<td align="left">Granular[Grl]</td>
<td align="left">75</td>
<td align="left">16</td>
<td align="left">91</td>
<td align="left">450</td>
<td align="left">546</td>
</tr>
<tr>
<td align="left" style="border-right:thick">5</td>
<td align="left">Oval[Ovl]</td>
<td align="left">118</td>
<td align="left">-</td>
<td align="left">118</td>
<td align="left">708</td>
<td align="left">708</td>
</tr>
<tr>
<td align="left" style="border-right:thick">6</td>
<td align="left">Reticulocytes[Ret]</td>
<td align="left">82</td>
<td align="left">33</td>
<td align="left">115</td>
<td align="left">492</td>
<td align="left">690</td>
</tr>
<tr>
<td align="left" style="border-right:thick">7</td>
<td align="left">Sickle[Sk]</td>
<td align="left">22</td>
<td align="left">93</td>
<td align="left">115</td>
<td align="left">132</td>
<td align="left">690</td>
</tr>
<tr>
<td align="left" style="border-right:thick;border-bottom:thick">8</td>
<td align="left" style="border-bottom:thick">Stomatocytes[Sto]</td>
<td align="left" style="border-bottom:thick">24</td>
<td align="left" style="border-bottom:thick">-</td>
<td align="left" style="border-bottom:thick">24</td>
<td align="left" style="border-bottom:thick">144</td>
<td align="left" style="border-bottom:thick">144</td>
</tr>
<tr>
<td align="left" colspan="2"><bold>Total number of RBCs</bold></td>
<td align="left">1030</td>
<td align="left">176</td>
<td align="left">1204</td>
<td align="left">6168</td>
<td align="left">7224</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>On the basis of the above automated image-based shape factor analysis scheme, we can perform a comprehensive shape analysis for the classified RBCs or unclassified RBCs according to specific practical applications and requirements.</p>
</sec>
</sec>
<sec id="sec006" sec-type="conclusions">
<title>Results/discussion</title>
<p>In this section, we conduct several experiments to evaluate the performance of the deep CNN used in the special RBC classification cases and present a comparative analysis of the results. In our experiments in order to validate the robustness of our methodology in dealing with different imaging data, we consider 434 raw microscopy images of 8 different SCD patients collected from two different hospitals. The number of images for each patient in different fractions is shown in <xref ref-type="fig" rid="pcbi.1005746.g008">Fig 8</xref>; all the images in different fractions (F1,F2,F3,F4 and UF) are of the same size (1920*1080 pixels) in TIFF format with 4 color channels. Based on the obtained raw images, 7206 single RBC image patches were extracted by using the proposed method in Section 3.1.Subsequently, all RBC patch images were normalized to the same size (78*78) by using the method described in section 3.2. Namely, all the RBC patch images were assigned to 8 different categories (discocytes, echinocytes, elongated, granular, oval, reticulocytes, sickle and stomatocyte) manually with the corresponding quantity of each RBC category presented in <xref ref-type="table" rid="pcbi.1005746.t001">Table 1</xref> as described in [<xref ref-type="bibr" rid="pcbi.1005746.ref026">26</xref>]. Conventionally, our definition of echinocytes is equivalent to echinocyte type II and III mentioned in [<xref ref-type="bibr" rid="pcbi.1005746.ref027">27</xref>]. Echinocyte type I is actually the “granular shape” we mention in this manuscript; moreover, wherever the state of oxygenation is not mentioned it implies “Oxy” state. We note that oval shape refers to the shape of the red cells and is not related to Southeast Asian ovalocytosis. This convention is consistent in our training of the dCNN model. A comparison study on the deep CNNs training model for two datasets with different number of patients’ data was conducted. The input data was enhanced with geometric transformations—a method also known as <italic>data augmentation technique</italic>. This technique adds value to base data by adding information derived from rotation, shifting or mirroring, illumination adjustment, etc., and introduces only a slight distortion to the images but without introducing extra labeling costs. A larger dataset can help evaluate and improve the robustness of RBC classification CNN model as well as restraining the common over-fitting problem. Thus, in our work, five types of data augmentation were performed on the normalized single RBC patch: rotate 90°, 180°, 270° and horizontal and vertical reflection.</p>
<fig id="pcbi.1005746.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Distribution of the number of images in five fractions corresponding to seven different patients.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g008" xlink:type="simple"/>
</fig>
<sec id="sec007">
<title>RBC-dCNN model training, optimization and K-fold validation</title>
<p>In order to test the performance of the deep convolutional neural network model, we conducted systematic convergence studies with respect to the number of iterations and the learning rate; here we show some representative results. For the case of 4 patients (Exp_I), we evaluated the training error and loss in the configuration of different learning rates (0.01 and 0.03), batch size = 20, image size is 78*78 and weight decay is 0.01. In <xref ref-type="fig" rid="pcbi.1005746.g009">Fig 9</xref>, we observe that both the train and the loss errors decay with the increasing number of epochs, and the higher learning rate can accelerate the decay speed, see the corresponding plots of the loss and train error results for two comparative experiments (<italic>T</italic>1 and <italic>T</italic>2) with different learning rate settings. Moreover, another significant observation in <xref ref-type="fig" rid="pcbi.1005746.g009">Fig 9</xref> is that both the train error and loss results start fluctuating after 15 iterations for <italic>T</italic>2 and 25 iterations for <italic>T</italic>1. In particular, the fluctuations in the loss increase as the number of iterations increases, but the train error has a relatively smaller fluctuation. In order to better understand the fluctuation problem (so-called “over-training” or “overfitting”), we optimized the batch size and use the <italic>“dropout”</italic> scheme proposed in [<xref ref-type="bibr" rid="pcbi.1005746.ref028">28</xref>] to overcome this problem. As described before, the dropout layer is implemented after the convolution layer (<italic>p</italic> = 0.5). Finally, when the number of iterations reaches 60, our RBC-dCNN model achieved optimal prediction performance. We plotted the two normalized confusion matrices with respect to different number of maximum iteration times (30 and 60) in <xref ref-type="fig" rid="pcbi.1005746.g010">Fig 10</xref>.</p>
<fig id="pcbi.1005746.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Convergence studies on loss and train error with respect to the number of iterations and different learning rate settings.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g009" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005746.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Normalized confusion matrix results with respect to different number of iterations.</title>
<p>(A) max_iter = 30. (B) max_iter = 60.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g010" xlink:type="simple"/>
</fig>
<p>In <xref ref-type="fig" rid="pcbi.1005746.g010">Fig 10</xref>, we observed that the <italic>Discocytes</italic> and <italic>Granular</italic> classes have relative low prediction accuracy among the 8 classes of RBC before the convergence of loss and training error. However, when the maximum number of iterations was 60, there was a significant improvement in the accuracy of different class prediction due to further decay of the loss and training errors. <xref ref-type="table" rid="pcbi.1005746.t002">Table 2</xref> gives detailed performance analysis of the running time, train error, test error and loss with respect to different maximum iteration times based on Exp_I dataset.</p>
<table-wrap id="pcbi.1005746.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.t002</object-id>
<label>Table 2</label>
<caption>
<title>Comparisons of loss and train errors based on different iterations.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005746.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">Iteration</th>
<th align="left" style="border-bottom:thick">Training error</th>
<th align="left" style="border-bottom:thick">Loss</th>
<th align="left" style="border-bottom:thick">Test error</th>
<th align="left" style="border-bottom:thick">Times(s)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="border-right:thick">25</td>
<td align="char" char=".">0.2094</td>
<td align="char" char=".">0.5879</td>
<td align="char" char=".">0.3500</td>
<td align="char" char=".">2528.4</td>
</tr>
<tr>
<td align="left" style="border-right:thick">30</td>
<td align="char" char=".">0.1598</td>
<td align="char" char=".">0.3867</td>
<td align="char" char=".">0.2750</td>
<td align="char" char=".">2940.1</td>
</tr>
<tr>
<td align="left" style="border-right:thick">40</td>
<td align="char" char=".">0.1213</td>
<td align="char" char=".">0.3637</td>
<td align="char" char=".">0.2469</td>
<td align="char" char=".">4011.5</td>
</tr>
<tr>
<td align="left" style="border-right:thick">60</td>
<td align="char" char=".">0.1026</td>
<td align="char" char=".">0.2805</td>
<td align="char" char=".">0.2094</td>
<td align="char" char=".">5869.6</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>Despite a learning model being trained to fit the statistics, the model cannot be assumed to have a successful predictive capability. This is due to the regularization which increases the performance, while the performance on test is optimal within a range of values of the regularization parameter. Thus, accurate evaluation of predictive performance is a key step for validating the precision and recall of a deep neural network classification model.</p>
<p>K-fold cross-validation is an effective way to measure the predictive performance for the deep CNNs model [<xref ref-type="bibr" rid="pcbi.1005746.ref029">29</xref>]. The K-fold cross-validation procedure is shown in <xref ref-type="fig" rid="pcbi.1005746.g011">Fig 11</xref>. First, the total RBC population was divided into <italic>k</italic> non-overlapped subsets with equal number of RBCs (here <italic>k</italic> was chosen to be 5). Then, for every fold or experiment, one of the 5 subsets was chosen as the validation set (green color data block) and the other <italic>k</italic> − 1 subsets were combined to form the training set (orange color data blocks). Finally, the average validation scores obtained from the five folds were calculated as the final prediction score. Every class of RBC images is divided into 5 equal subsets, the quantity of training data and validation data can in each class can be expressed as <xref ref-type="disp-formula" rid="pcbi.1005746.e006">Eq (6)</xref>.
<disp-formula id="pcbi.1005746.e006"><alternatives><graphic id="pcbi.1005746.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>{</mml:mo> <mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Sum</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="normal">V</mml:mi> <mml:mtext>ij</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>C</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>/</mml:mo> <mml:mn>5</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Sum</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="normal">T</mml:mi> <mml:mtext>ij</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>C</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>/</mml:mo> <mml:mn>5</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable> <mml:mo/> <mml:mi>i</mml:mi> <mml:mo>∈</mml:mo> <mml:mo>[</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>n</mml:mi> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>∈</mml:mo> <mml:mo>[</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>5</mml:mn> <mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
Where, <italic>C</italic>(<italic>i</italic>) is the number of RBC in the <italic>i</italic>th class, <italic>V</italic><sub><italic>ij</italic></sub> describes the <italic>i</italic>-th class and <italic>j</italic>-th validation sub-dataset, and <italic>T</italic><sub><italic>ij</italic></sub> is the corresponding training dataset.<italic>n</italic> can take the values of 5 or 8 for our studies. Finally, 5 folds can be generated by collecting the same subset from different classes alternately. For example, the <italic>j</italic>-th fold can be represented by <xref ref-type="disp-formula" rid="pcbi.1005746.e007">Eq (7)</xref>.
<disp-formula id="pcbi.1005746.e007"><alternatives><graphic id="pcbi.1005746.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>fold</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>j</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>{</mml:mo> <mml:msub><mml:mi>V</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>V</mml:mi> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>V</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>}</mml:mo> <mml:mo>∪</mml:mo> <mml:mo>{</mml:mo> <mml:msub><mml:mi>T</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>T</mml:mi> <mml:mrow><mml:mn>2</mml:mn> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mi>T</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula></p>
<fig id="pcbi.1005746.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Evaluation procedure for 5-fold cross validation.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g011" xlink:type="simple"/>
</fig>
<p>The main advantage in using k-fold cross validation is that each image is limited to one use during the validation process. This can effectively avoid the inaccurate and unstable phenomenon while artificially forcing multiple common samples into both training and testing.</p>
<p>Hence, in order to evaluate the general performance of our RBC-dCNN model, we performed 5-fold cross validation for the new datasets Exp_II (7 patients), in which we created a supplement for the number of <italic>echinocyte, granular, sickle</italic> and <italic>reticulocyte</italic> categories. To evaluate the performance of our deep CNN model for the SCD RBC classification and determine the importance of different types of RBCs present in SCD blood, we perform the experiments according to the following principles:</p>
<list list-type="order">
<list-item>
<p>Comparative study and analysis for two kinds of RBC labeling principles, denoted as “coarse labeling” and “refined labeling”, so as to validate the efficiency of the RBC-dCNN model applied in various kinds of RBC patterns in SCD.</p>
</list-item>
<list-item>
<p>Multiple metrics for the final evaluation of the performance of RBC-dCNN (Precision, Sensitivity, Specificity, F-score, Accuracy and ROC_AUC) are taken into account; the specifications for these measures are shown below.</p>
</list-item>
</list>
<p>
<disp-formula id="pcbi.1005746.e008">
<alternatives>
<graphic id="pcbi.1005746.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:mtable displaystyle="true">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mrow>
<mml:mtext>Precision</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>/</mml:mo>
<mml:mo>(</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>F</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula>
<disp-formula id="pcbi.1005746.e009">
<alternatives>
<graphic id="pcbi.1005746.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mtable displaystyle="true">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mrow>
<mml:mtext>Sensitivity</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>/</mml:mo>
<mml:mo>(</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>F</mml:mi>
<mml:mi>N</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
</alternatives>
<label>(9)</label>
</disp-formula>
<disp-formula id="pcbi.1005746.e010">
<alternatives>
<graphic id="pcbi.1005746.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mtable displaystyle="true">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mrow>
<mml:mtext>Specificity</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>N</mml:mi>
<mml:mo>/</mml:mo>
<mml:mo>(</mml:mo>
<mml:mi>F</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>N</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
</alternatives>
<label>(10)</label>
</disp-formula>
<disp-formula id="pcbi.1005746.e011">
<alternatives>
<graphic id="pcbi.1005746.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mtable displaystyle="true">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mrow>
<mml:mi mathvariant="normal">F</mml:mi>
<mml:mo>-</mml:mo>
<mml:mtext>score</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>*</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>/</mml:mo>
<mml:mo>(</mml:mo>
<mml:mn>2</mml:mn>
<mml:mo>*</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>F</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>F</mml:mi>
<mml:mi>N</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
</alternatives>
<label>(11)</label>
</disp-formula>
<disp-formula id="pcbi.1005746.e012">
<alternatives>
<graphic id="pcbi.1005746.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005746.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:mtable displaystyle="true">
<mml:mtr>
<mml:mtd/>
<mml:mtd>
<mml:mrow>
<mml:mtext>Accuracy</mml:mtext>
<mml:mo>=</mml:mo>
<mml:mo>(</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>N</mml:mi>
<mml:mo>)</mml:mo>
<mml:mo>/</mml:mo>
<mml:mo>(</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>F</mml:mi>
<mml:mi>P</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>F</mml:mi>
<mml:mi>N</mml:mi>
<mml:mo>+</mml:mo>
<mml:mi>T</mml:mi>
<mml:mi>N</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mtd>
</mml:mtr>
</mml:mtable>
</mml:math>
</alternatives>
<label>(12)</label>
</disp-formula>
Here, <italic>TP</italic>, <italic>TN</italic>, <italic>FP</italic> and <italic>FN</italic> are, respectively, the true positive, true negative, false positive and false negative number of RBCs being classified for each class. The above five metrics can help us measure the dCNN’s performance from different perspective; e.g., the precision, or positive predictive value (<italic>PPV</italic>) can be viewed as a measure of a classifiers exactness. A low precision can also indicate a large number of False Positives. The sensitivity—also called recall or true positive rate(<italic>TPR</italic>)– measures the proportion of positives that are correctly identified; it can be viewed as a measure of a classifiers completeness. A low recall indicates many False Negatives; the specificity (<italic>SPC</italic>)—also known as true negative rate(<italic>TNR</italic>)– measures the proportion of negatives that are correctly identified. F1-score considers both precision and recall; it gets the best accuracy when it reaches 1, worst corresponds to 0. The ROC-AUC curve is a plot for TPR and NPR (Negative Positive Rate), which is explained in the experiments below.</p>
<p>In the following, the experimental results based on 5-fold cross validation for the two kinds of labeling datasets are presented respectively.</p>
<p><bold>Evaluation of coarse-labeled RBC dataset (5 categories):</bold> In this experiment, all RBC patch images were coarsely labeled into 5 categories: 1) Dic+Ovl, 2) Ech, 3) El+Sk, 4) Grl, 5) Ret. In accordance with the cross validation scheme in <xref ref-type="fig" rid="pcbi.1005746.g011">Fig 11</xref>, the divided 5-fold cross validation datasets for 5 types of RBC and their corresponding evaluation results are given in <xref ref-type="table" rid="pcbi.1005746.t003">Table 3</xref>.</p>
<table-wrap id="pcbi.1005746.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.t003</object-id>
<label>Table 3</label>
<caption>
<title>5-fold cross validation for 5 types of SCD RBC classification.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005746.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.t003" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">Fold No.</th>
<th align="left" style="border-bottom:thick">Training set</th>
<th align="left" style="border-bottom:thick">Evaluation set</th>
<th align="left" style="border-bottom:thick">Training error</th>
<th align="left" style="border-bottom:thick">Evaluation error</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>1</td>
<td align="left">5664</td>
<td align="left">1416</td>
<td align="left">9.14%</td>
<td align="left">10.54%</td>
</tr>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>2</td>
<td align="left">5664</td>
<td align="left">1416</td>
<td align="left">9.07%</td>
<td align="left">11.16%</td>
</tr>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>3</td>
<td align="left">5664</td>
<td align="left">1416</td>
<td align="left">8.52%</td>
<td align="left">10.08%</td>
</tr>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>4</td>
<td align="left">5670</td>
<td align="left">1410</td>
<td align="left">9.84%</td>
<td align="left">11.27%</td>
</tr>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>5</td>
<td align="left">5658</td>
<td align="left">1422</td>
<td align="left">8.39%</td>
<td align="left">10.55%</td>
</tr>
<tr>
<td align="left" colspan="3"><bold>Mean Accuracy</bold></td>
<td align="left">91.01%±0.33%</td>
<td align="left">89.28%±0.24%</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>As seen from <xref ref-type="table" rid="pcbi.1005746.t003">Table 3</xref>, the mean accuracy for training of 5 types of RBC classification under different folds is 91.01%, and the mean evaluation accuracy is 89.28%. Here, in order to better visualize the discriminative capability of the training deep CNNs model for RBC classification and investigate the sensitivity of the deep CNN model to various RBC categories, the Receiver Operating Characteristic (ROC) curve was used to plot the true positive rate (TPR) against false positive rate (FPR) for different classes of the 5-fold test. The top-left corner of a ROC plot is the “ideal point” while the diagonal dashed line indicates random chance or luck probability. Therefore, the closer the curve followed the left-top border of the ROC space, the more accurate the test can be considered. We also computed the AUC (Area Under the Curve) for each ROC curve to evaluate the prediction performance of our RBC-dCNN model. <xref ref-type="fig" rid="pcbi.1005746.g012">Fig 12</xref> shows the corresponding ROC-AUC results for RBC classification with 5 target categories. In the ROC-AUC plot, the average ROC curve was calculated and shown in blue color, and the corresponding averaged AUC for each fold is at least 0.97. Regarding the prediction performance of the five RBC classes, Granular and Echinocytes received a relative low AUC value, and the other two classes (“Discocytes+Oval”and “Elongated+Sickle”) obtained a high AUC value.</p>
<fig id="pcbi.1005746.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g012</object-id>
<label>Fig 12</label>
<caption>
<title>ROC-AUC result for coarse 5 types of RBC classification based on “Exp_II” dataset by 5-fold cross validation.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g012" xlink:type="simple"/>
</fig>
<p>In addition, <xref ref-type="fig" rid="pcbi.1005746.g013">Fig 13A</xref> shows the corresponding confusion matrix, which can guide humans to observe the confusing classes in red circles; for instance, Ret and Ech are a pair of confusing classes, and the diagonal represents the correctly predicted number of each observation. The calculated sensitivity (right column) and precision (bottom) for each class in yellow color are consistent with the bars in the statistic <xref ref-type="fig" rid="pcbi.1005746.g013">Fig 13C</xref>. Except for these measures, three other measures are also computed for the performance analysis of the experiment, however, the difference in accuracy among the 5 type of RBCs is small because it refers to the true predictions (TP and TN) among the total validation dataset. However, high accuracy is not enough to demonstrate the goodness of the classifier, nor it can tell the sensitivity, precision, specificity and F-score. Therefore, it is necessary to explore these measures for a more in-depth analysis in the experiment. In <xref ref-type="fig" rid="pcbi.1005746.g013">Fig 13C</xref>, the Ret RBCs have a low recall (sensitivity), and the Ech get the lowest precision among the five classes. F-score can be applied to harmonize the above two evaluation metrics; the comparison results of F-score, precision and recall of 5 classes are shown in <xref ref-type="fig" rid="pcbi.1005746.g013">Fig 13B</xref>. Throughout all the evaluation measurements, we can obviously observe that the deep CNN model get a high accuracy and precision in predicting the different types of RBCs,in particular for “Dic+Ovl”, “El+Sk” and “Ret” types.</p>
<fig id="pcbi.1005746.g013" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Performance analysis for SCD RBC classification based on “Exp_II” dataset (coarse labeling).</title>
<p>(A) confusion matrix showing the detailed number of correctly classified RBC images and misclassified RBC images, (B) 5 statistic metrics for the 5 types of RBC category prediction results, (C) Specific F-score, precision and recall analysis for different RBC categories.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g013" xlink:type="simple"/>
</fig>
<p><bold>Evaluation of refined-labeled RBC dataset (8 categories):</bold> To evaluate the robustness of the deep CNN model in the application of more rich types of RBC classification, a refined labeling dataset “Exp_II” was generated, which included 8 types of RBC: <italic>Dic, Ech, El, Grl, Ovl, Ret, Sk</italic> and <italic>Sto</italic>. Similarly, 5-fold cross validation was carried out and the classification result is shown in <xref ref-type="table" rid="pcbi.1005746.t004">Table 4</xref>. The mean evaluation accuracy for the 8 types of RBC classification was 87.50%.</p>
<table-wrap id="pcbi.1005746.t004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.t004</object-id>
<label>Table 4</label>
<caption>
<title>5-fold cross validation for 8 types of SCD RBC classification.</title>
</caption>
<alternatives>
<graphic id="pcbi.1005746.t004g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.t004" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">Fold No.</th>
<th align="left" style="border-bottom:thick">Training set</th>
<th align="left" style="border-bottom:thick">Evaluation set</th>
<th align="left" style="border-bottom:thick">Training error</th>
<th align="left" style="border-bottom:thick">Evaluation error</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>1</td>
<td align="left">5772</td>
<td align="left">1452</td>
<td align="left">10.15%</td>
<td align="left">12.41%</td>
</tr>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>2</td>
<td align="left">5772</td>
<td align="left">1452</td>
<td align="left">11.02%</td>
<td align="left">13.23%</td>
</tr>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>3</td>
<td align="left">5772</td>
<td align="left">1452</td>
<td align="left">10.26%</td>
<td align="left">12.99%</td>
</tr>
<tr>
<td align="left" style="border-right:thick"><italic>Fold</italic>4</td>
<td align="left">5790</td>
<td align="left">1434</td>
<td align="left">10.13%</td>
<td align="left">12.51%</td>
</tr>
<tr>
<td align="left" style="border-bottom:thick;border-right:thick"><italic>Fold</italic>5</td>
<td align="left" style="border-bottom:thick">5790</td>
<td align="left" style="border-bottom:thick">1434</td>
<td align="left" style="border-bottom:thick">9.98%</td>
<td align="left" style="border-bottom:thick">11.38%</td>
</tr>
<tr>
<td align="left" colspan="3"><bold>Mean Accuracy</bold></td>
<td align="left">89.69%±0.17%</td>
<td align="left">87.50%±0.51%</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>The corresponding mean ROC-AUC result for the refined labeling test is shown in <xref ref-type="fig" rid="pcbi.1005746.g014">Fig 14</xref>. The average AUC value for 8 types of RBC is 0.94 as opposed to an average AUC value of 0.97 for the coarse labeling RBC classification. The RBC Categories (<italic>El</italic> and <italic>Ovl</italic>) got a relative low classification performance with an AUC value of 0.92. In addition, in <xref ref-type="fig" rid="pcbi.1005746.g015">Fig 15A</xref>, we see a more detailed confusion matrix for classification of 8 RBC categories. This shows the most confused classes (red circles) for each type of RBC; <xref ref-type="fig" rid="pcbi.1005746.g015">Fig 15b and 15c</xref> give a performance comparison among the 8 categories. <italic>Dic</italic> reached the best values for each metric and exhibited a sensitivity of 94.4% with high class-specific precision on testing sets of 1434 RBC images. <italic>Ovl</italic> type achieved the lowest precision and recall due to the misclassification with <italic>Dic</italic> and <italic>El</italic> types.</p>
<fig id="pcbi.1005746.g014" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g014</object-id>
<label>Fig 14</label>
<caption>
<title>ROC-AUC result for refined 8 types of RBC classification based on “Exp_II” dataset by 5-fold cross validation.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g014" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005746.g015" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g015</object-id>
<label>Fig 15</label>
<caption>
<title>Classification performance analysis for SCD RBC classification based on “Exp_II” dataset (refined labeling).</title>
<p>(A)confusion matrix showing the detailed number of correctly classified RBC images and misclassified RBC images. (B) 5 statistic metrics for the 8 RBC category prediction result. (C) Specific F-score, precision and recall analysis for different RBC categories.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g015" xlink:type="simple"/>
</fig>
<p>From the prediction result example in <xref ref-type="fig" rid="pcbi.1005746.g016">Fig 16</xref> we can observe that some <italic>Ovl</italic> type RBCs (e.g. the RBC in red frame of <xref ref-type="fig" rid="pcbi.1005746.g016">Fig 16</xref>) are misclassified as <italic>Dic</italic> and the <italic>El</italic> type RBCs are prone to be classified to <italic>Ovl</italic> type and <italic>Sk</italic> type, e.g., the RBCs in blue and green frames in <xref ref-type="fig" rid="pcbi.1005746.g016">Fig 16</xref>.</p>
<fig id="pcbi.1005746.g016" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g016</object-id>
<label>Fig 16</label>
<caption>
<title>Prediction result example for 8 types of RBCs.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g016" xlink:type="simple"/>
</fig>
<p>Based on the proposed deep RBC-CNN model, we perform an independent RBC classification test on 8 raw microscopy images in the highest density RBC fraction <italic>i.e.</italic> fraction 4 (typically associated with severe SCD). Statistical quantification results for the number of different types of RBC are shown in <xref ref-type="fig" rid="pcbi.1005746.g017">Fig 17</xref>. Notice the significant heterogeneity of cell types even at the highest density fraction.</p>
<fig id="pcbi.1005746.g017" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g017</object-id>
<label>Fig 17</label>
<caption>
<title>Statistical quantification for the number of various types of RBCs in density fraction 4 (severe SCD).</title>
<p>Notice the significant heterogeneity of cell types even at the highest density fraction.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g017" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec008">
<title>Classification of deoxygenated sickle RBCs</title>
<p>In addition to the above two experiments (EXP_I, EXP_II) on coarse-labeled and refine-labeled sickle RBC classification, in order to test the RBC-dCNN model for oxygenated and deoxygenated RBCs in SCD, we also performed a patient-specific experiment on the classification of a new experimental dataset that includes the previous coarse-labeled five catergories under normoxic conditions (Oxy) and a new catergory: “El+Sk under deoxygenation (DeOxy)”, see appendix for details on the experimental methodology. The specific experimental dataset (EXP_III) is shown in <xref ref-type="table" rid="pcbi.1005746.t005">Table 5</xref> (row 6) and it includes 81 El+Sk (DeOxy) RBCs, which after data augmentation correspond to an equivalent sample of 486 DeOxy RBCs.</p>
<table-wrap id="pcbi.1005746.t005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.t005</object-id>
<label>Table 5</label>
<caption>
<title>Description of our experimental dataset for the coarse-labeled five categories and a new deoxygenated category (row 6).</title>
</caption>
<alternatives>
<graphic id="pcbi.1005746.t005g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.t005" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">No.</th>
<th align="left" style="border-bottom:thick">RBC Types</th>
<th align="left" style="border-bottom:thick">Total number of RBCs</th>
<th align="center" style="border-bottom:thick">EXP_III<break/>(8 patients)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="border-right:thick">1</td>
<td align="left">Dic+Ovl (Oxy)</td>
<td align="left">456</td>
<td align="left">2736</td>
</tr>
<tr>
<td align="left" style="border-right:thick">2</td>
<td align="left">Ech (Oxy)</td>
<td align="left">123</td>
<td align="left">738</td>
</tr>
<tr>
<td align="left" style="border-right:thick">3</td>
<td align="left">El+Sk (Oxy)</td>
<td align="left">395</td>
<td align="left">2370</td>
</tr>
<tr>
<td align="left" style="border-right:thick">4</td>
<td align="left">Grl (Oxy)</td>
<td align="left">91</td>
<td align="left">546</td>
</tr>
<tr>
<td align="left" style="border-right:thick">5</td>
<td align="left">Ret (Oxy)</td>
<td align="left">115</td>
<td align="left">690</td>
</tr>
<tr>
<td align="left" style="border-bottom:thick;border-right:thick">6</td>
<td align="left" style="border-bottom:thick">El+Sk (DeOxy)</td>
<td align="left" style="border-bottom:thick">81</td>
<td align="left" style="border-bottom:thick">486</td>
</tr>
<tr>
<td align="left" colspan="2"><bold>Total number of RBCs</bold></td>
<td align="left">1261</td>
<td align="left">7566</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<p>In order to appreciate the differences in RBCs under Oxy and DeOxy conditions, we present in <xref ref-type="fig" rid="pcbi.1005746.g018">Fig 18</xref> images of RBCs before and after deoxygenation. Even under Oxy, these particular RBCs have crenated shape because they are irreversibly sickled. However, upon deoxygenation we see that there is further polymerization of sickle hemoglobin (HbS) inside the RBCs, manifested by the roughening of the contours of RBCs as well as the alteration of the texture inside the RBCs. While the change in the overall shape of these deoxygenated RBCs is relatively small compared to their Oxy state, the differences are subtle and hence they present a new challenge for our dCNN.</p>
<fig id="pcbi.1005746.g018" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g018</object-id>
<label>Fig 18</label>
<caption>
<title/>
<p>First row: (t = 0) Irreversibly sickled cells (ISCs) under normoxia i.e., Oxy state [<italic>O</italic><sub>2</sub>]: 20%; Initiation of deoxygenation. Second row: (t = 45s) Deoxygenated ISCs i.e., DeOxy state [<italic>O</italic><sub>2</sub>]: 2%; (see <xref ref-type="supplementary-material" rid="pcbi.1005746.s004">S4 Appendix</xref> methods on Oxy/DeOxy states).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g018" xlink:type="simple"/>
</fig>
<p>Having this new mixed Oxy-DeOxy dataset (EXP_III) and the particular RBC inner pattern alteration characteristics, we carried out the dCNN model training and testing using the previous similar 5-fold cross validation schema, which involves four folds for training and one fold for testing. We have a total of 988 RBCs for training, which we arrange in 50 batches of 20 images each except the last one that has only 8 RBCs; see <xref ref-type="fig" rid="pcbi.1005746.g019">Fig 19A</xref>. So each batch contains 20 different RBCs, which may be in any of the six categories that the dCNN model should learn. The RBCs are randomly shuffled before input to dCNN. The hierarchical features can be extracted by dCNN layer-by-layer. For instance, the learned feature maps in the hidden 5th-layer for batch 1 is shown in <xref ref-type="fig" rid="pcbi.1005746.g019">Fig 19B</xref>. We observe that the convolutional operation can extract and highlight image features based on the raw image data field directly and hierarchically, such as detecting the image key points, edges, curves, etc. This is further illustrated in <xref ref-type="fig" rid="pcbi.1005746.g020">Fig 20</xref>, which presents a sequence of feature maps for different layers (layers 5, 6, 8 ad 10) corresponding to four different classes of RBCs in Oxy and DeOxy states. As we move to high layer numbers, we pick up more features from low level to high level, hence bridging the gap between high level representation and low level features. Within each layer different filters can be learned from the data to help extract different features. The images shown in <xref ref-type="fig" rid="pcbi.1005746.g020">Fig 20</xref> correspond to arbitrary selection of filters for each layer. The original raw images are shown on the first column of <xref ref-type="fig" rid="pcbi.1005746.g020">Fig 20</xref>. Hence, the learned hierarchical convolutional features corresponding to variant learning filters play an important role in classifying RBCs in SCD, in particular for the classification of Oxy and irreversibly DeOxy sickle RBCs.</p>
<fig id="pcbi.1005746.g019" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g019</object-id>
<label>Fig 19</label>
<caption>
<title>Snapshots of feature maps for layer 5 including the deoxygenated category.</title>
<p>(<bold>A</bold>) original images in batch 1. (<bold>B</bold>) feature maps in 5th layer.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g019" xlink:type="simple"/>
</fig>
<fig id="pcbi.1005746.g020" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g020</object-id>
<label>Fig 20</label>
<caption>
<title>Learning hierarchical feature maps for layers 5, 6, 8, 10 for Dic+Ovl (Oxy), Ech (Oxy), El+Sk (Oxy), El+Sk (DeOxy).</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g020" xlink:type="simple"/>
</fig>
<p>The final prediction result for the classification of deoxygenated RBCs is shown in <xref ref-type="fig" rid="pcbi.1005746.g021">Fig 21</xref> for the elongated and sickle (DeOxy) category. If there is an obvious intracellular pattern change, then the accuracy of our trained dCNN model can obtain a high recall (93.8%) but a relatively low precision (60.0%). The main reason for this phenomenon can be justified as follows:</p>
<list list-type="order">
<list-item>
<p>The deoxygenated El+Sk RBCs with no obvious intracellular pattern alteration will be confused with the oxygenated El+Sk RBCs. Consequently, the accuracy of our deep CNN is relatively low. This is to be expected because those RBCs are deoxygenated, and as we already mentioned they do not change the shape significantly, so they look similar to El+Sk (Oxy) RBCs.</p>
</list-item>
<list-item>
<p>Initially we have hypothesized that there could be confusion between classes (Ech and El+Sk (DeOxy)) due to apparently similar patterns within the cells. However, surprisingly our trained dCNN (DeOxy) is able to distinguish the intracellular pattern with accuracy exceeding 67.5%.</p>
</list-item>
</list>
<fig id="pcbi.1005746.g021" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g021</object-id>
<label>Fig 21</label>
<caption>
<title>Confusion matrix for the combined oxygenated and deoxygenated categories described in <xref ref-type="table" rid="pcbi.1005746.t005">Table 5</xref>.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g021" xlink:type="simple"/>
</fig>
<p>Taken together, the above observations imply that both intracellular patterns and RBC contours play a significant role in classification (see <xref ref-type="fig" rid="pcbi.1005746.g018">Fig 18</xref>, second row).</p>
</sec>
<sec id="sec009">
<title>Shape factor quantification for classified RBCs</title>
<p>Our proposed RBC classification methodology also relies on the extraction of individual RBCs shape factors that is complementary to RBC classification. Two of the most prevalent shape factors are the Circularity Shape Factor (CSF) and Ellipticity Shape Factor (ESF) (Also see <xref ref-type="supplementary-material" rid="pcbi.1005746.s002">S2 Appendix</xref>) [<xref ref-type="bibr" rid="pcbi.1005746.ref030">30</xref>–<xref ref-type="bibr" rid="pcbi.1005746.ref032">32</xref>]. We computed the CSF and ESF shape factors for the classified RBCs obtained with the RBC-dCNN methodology (see <xref ref-type="fig" rid="pcbi.1005746.g022">Fig 22</xref>). The graph is a statistical visual representation of the classified RBCs (<italic>i.e.</italic>, Elongated, Oval and Discocytes) within the ellipticity and circularity shape factor mapping. In addition to these two factors, we can implement in the workflow and compute any of the additional 12 shape factors mentioned in Table S-I to quantify SCD patient-specific RBC shape parameters. The results here are consistent with results described by Horiuchi et al. [<xref ref-type="bibr" rid="pcbi.1005746.ref030">30</xref>].</p>
<fig id="pcbi.1005746.g022" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005746.g022</object-id>
<label>Fig 22</label>
<caption>
<title>CSF and ESF shape factors estimation for Elongated, Oval and Discocytes RBC types.</title>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.g022" xlink:type="simple"/>
</fig>
<p>In summary, we have used patient-specific microscopy images to develop an automated, high-throughput, <italic>ex-vivo</italic> RBC classification method for the sickle cell disease based on pre-extraction of RBC region and deep CNNs. We employed a hierarchical RBC patch extraction method followed by a shape-invariant RBC patch normalization technique for the input of our deep nets, which can exclude unnecessary background patches and save time during both the training and the learning procedures. Moreover, our experiments for two kinds of labeling datasets (5 and 8 classes) based on different partition levels demonstrate the great capability and robustness of our RBC-dCNNs model on the classification of various RBC categories with characteristics of complex patterns and heterogeneous shapes without the need for hand-crafted feature pre-extraction. While most of the dCNN training was done based on oxygenated SCD RBCs, we also conducted the classification of deoxygenated RBCs, and demonstrate that our model can detect the deoxygenated RBCs with high accuracy capturing the subtle intracellular texture alterations. Furthermore, the explicit shape analysis at the end of the procedure can offer a robust morphological quantitative tool expanding the proposed framework to high-throughput, <italic>ex-vivo</italic> RBC classification.</p>
<p>Our program is written in Python language and C language, and it currently runs on CPUs, but it can also be updated to run on GPUs. It is mainly based on Python open-source libraries Theano, Numpy, SciPy and matplotlib, etc. The program takes only a few seconds on a standard desktop to test over a thousand RBCs using the trained deep neural network model.</p>
<p>In SCD, the shape of sickle RBCs is directly related to the polymerization process inside the RBC, which, in turn, depends on the de-oxygenation rate and hence the specific human organ where a sickle cell crisis may occur, consistent with clinical observations. The ability to perform high-throughput morphological classification utilizing deep CNNs of individual RBCs or other cell types, (<italic>e.g.</italic>, white blood cells) opens up complementary avenues in medical diagnostics for highly heterogeneous cell populations such as in hematological diseases and stored blood used for transfusion.</p>
<p>The framework presented here is powerful but many aspects can be further improved in future work. For example, new work should aim to: (1) develop an accurate segmentation method for the <italic>overlapped</italic> RBCs in the microscopy image; (2) increase the dataset scale on the number of rare categories, e.g. sickle, granular, stomatocytes, etc.; and (3) build a golden standard library containing diverse SCD RBC categories. Given the success of dCNN in classifying deoxygenated RBCs, having been trained mostly with oxygenated RBCs, we believe that with the proper training of dCNN, the overall methodology for classification we propose could be effective in other hematological disorders, e.g., diabetes mellitus, elliptocytosis, spherocytosis, as well as in classifying other cells, e.g., cancer cells, and even detecting the activation state of platelets.</p>
</sec>
</sec>
<sec id="sec010">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005746.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.s001" xlink:type="simple">
<label>S1 Appendix</label>
<caption>
<title>RBC density fractionation and microscopy image data acquisition.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005746.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.s002" xlink:type="simple">
<label>S2 Appendix</label>
<caption>
<title>Automatic RBC shape factor quantification.</title>
<p>It includes two parts: the specific computational formulas for the RBC shape factors and the corresponding pseudocode for RBC shape analysis.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005746.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.s003" xlink:type="simple">
<label>S3 Appendix</label>
<caption>
<title>Review of deep convolutional neural network structure.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005746.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005746.s004" xlink:type="simple">
<label>S4 Appendix</label>
<caption>
<title>Deoxygenation methodology of sickle RBCs.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1005746.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Anglin</surname> <given-names>C</given-names></name>. <article-title>Sickle Cell Disease</article-title>. <source>Journal of Consumer Health on the Internet</source>. <year>2015</year>;<volume>19</volume>(<issue>2</issue>):<fpage>122</fpage>–<lpage>131</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/15398285.2015.1026706" xlink:type="simple">10.1080/15398285.2015.1026706</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fasano</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Booth</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Miles</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Du</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Koyama</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Meier</surname> <given-names>ER</given-names></name>, <etal>et al</etal>. <article-title>Red blood cell alloimmunization is influenced by recipient inflammatory state at time of transfusion in patients with sickle cell disease</article-title>. <source>British journal of haematology</source>. <year>2015</year>;<volume>168</volume>(<issue>2</issue>):<fpage>291</fpage>–<lpage>300</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/bjh.13123" xlink:type="simple">10.1111/bjh.13123</ext-link></comment> <object-id pub-id-type="pmid">25256676</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Abubakar</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Tillmann</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Banerjee</surname> <given-names>A</given-names></name>. <article-title>Global, regional, and national age-sex specific all-cause and cause-specific mortality for 240 causes of death, 1990-2013: a systematic analysis for the Global Burden of Disease Study 2013</article-title>. <source>Lancet</source>. <year>2015</year>;<volume>385</volume>(<issue>9963</issue>):<fpage>117</fpage>–<lpage>171</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0140-6736(14)61682-2" xlink:type="simple">10.1016/S0140-6736(14)61682-2</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Milton</surname> <given-names>JN</given-names></name>, <name name-style="western"><surname>Gordeuk</surname> <given-names>VR</given-names></name>, <name name-style="western"><surname>Taylor</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>Gladwin</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Steinberg</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Sebastiani</surname> <given-names>P</given-names></name>. <article-title>Prediction of fetal hemoglobin in sickle cell anemia using an ensemble of genetic risk prediction models</article-title>. <source>Circulation: Cardiovascular Genetics</source>. <year>2014</year>; p. CIRCGENETICS–113.</mixed-citation>
</ref>
<ref id="pcbi.1005746.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Darrow</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Cinquin</surname> <given-names>BP</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Boudreau</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Rochat</surname> <given-names>RH</given-names></name>, <etal>et al</etal>. <article-title>Visualizing red blood cell sickling and the effects of inhibition of sphingosine kinase 1 using soft X-ray tomography</article-title>. <source>J Cell Sci</source>. <year>2016</year>;<volume>129</volume>(<issue>18</issue>):<fpage>3511</fpage>–<lpage>3517</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1242/jcs.189225" xlink:type="simple">10.1242/jcs.189225</ext-link></comment> <object-id pub-id-type="pmid">27505892</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Beers</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Samsel</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Mendelsohn</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Saiyed</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Fertrin</surname> <given-names>KY</given-names></name>, <name name-style="western"><surname>Brantner</surname> <given-names>CA</given-names></name>, <etal>et al</etal>. <article-title>Imaging flow cytometry for automated detection of hypoxia-induced erythrocyte shape change in sickle cell disease</article-title>. <source>American journal of hematology</source>. <year>2014</year>;<volume>89</volume>(<issue>6</issue>):<fpage>598</fpage>–<lpage>603</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/ajh.23699" xlink:type="simple">10.1002/ajh.23699</ext-link></comment> <object-id pub-id-type="pmid">24585634</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>He</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Gong</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Xiong</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Xu</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Jiang</surname> <given-names>T</given-names></name>, <etal>et al</etal>. <article-title>iCut: an integrative cut algorithm enables accurate segmentation of touching cells</article-title>. <source>Scientific reports</source>. <year>2015</year>;<volume>5</volume>.</mixed-citation>
</ref>
<ref id="pcbi.1005746.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liu</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Xiao</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Yuan</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Chang</surname> <given-names>J</given-names></name>, <etal>et al</etal>. <article-title>Segmentation of White Blood Cells through Nucleus Mark Watershed Operations and Mean Shift Clustering</article-title>. <source>sensors</source>. <year>2015</year>;<volume>15</volume>(<issue>9</issue>):<fpage>22561</fpage>–<lpage>22586</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3390/s150922561" xlink:type="simple">10.3390/s150922561</ext-link></comment> <object-id pub-id-type="pmid">26370995</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Arteta</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lempitsky</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Noble</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Zisserman</surname> <given-names>A</given-names></name>. <article-title>Detecting overlapping instances in microscopy images using extremal region trees</article-title>. <source>Medical image analysis</source>. <year>2016</year>;<volume>27</volume>:<fpage>3</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.media.2015.03.002" xlink:type="simple">10.1016/j.media.2015.03.002</ext-link></comment> <object-id pub-id-type="pmid">25980675</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Arteta</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Lempitsky</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Noble</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zisserman</surname> <given-names>A</given-names></name>. <article-title>Learning to detect cells using non-overlapping extremal regions</article-title>. <source>Medical image computing and computer-assisted intervention–MICCAI 2012</source>. <year>2012</year>; p. <fpage>348</fpage>–<lpage>356</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/978-3-642-33415-3_43" xlink:type="simple">10.1007/978-3-642-33415-3_43</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carpenter</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Jones</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Lamprecht</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Clarke</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Kang</surname> <given-names>IH</given-names></name>, <name name-style="western"><surname>Friman</surname> <given-names>O</given-names></name>, <etal>et al</etal>. <article-title>CellProfiler: image analysis software for identifying and quantifying cell phenotypes</article-title>. <source>Genome biology</source>. <year>2006</year>;<volume>7</volume>(<issue>10</issue>):<fpage>R100</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/gb-2006-7-10-r100" xlink:type="simple">10.1186/gb-2006-7-10-r100</ext-link></comment> <object-id pub-id-type="pmid">17076895</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sacan</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ferhatosmanoglu</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Coskun</surname> <given-names>H</given-names></name>. <article-title>CellTrack: an open-source software for cell tracking and motility analysis</article-title>. <source>Bioinformatics</source>. <year>2008</year>;<volume>24</volume>(<issue>14</issue>):<fpage>1647</fpage>–<lpage>1649</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/bioinformatics/btn247" xlink:type="simple">10.1093/bioinformatics/btn247</ext-link></comment> <object-id pub-id-type="pmid">18511469</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schindelin</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Arganda-Carreras</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Frise</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Kaynig</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Longair</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pietzsch</surname> <given-names>T</given-names></name>, <etal>et al</etal>. <article-title>Fiji: an open-source platform for biological-image analysis</article-title>. <source>Nature methods</source>. <year>2012</year>;<volume>9</volume>(<issue>7</issue>):<fpage>676</fpage>–<lpage>682</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nmeth.2019" xlink:type="simple">10.1038/nmeth.2019</ext-link></comment> <object-id pub-id-type="pmid">22743772</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hodneland</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Kögel</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Frei</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Gerdes</surname> <given-names>HH</given-names></name>, <name name-style="western"><surname>Lundervold</surname> <given-names>A</given-names></name>. <article-title>CellSegm-a MATLAB toolbox for high-throughput 3D cell segmentation</article-title>. <source>Source code for biology and medicine</source>. <year>2013</year>;<volume>8</volume>(<issue>1</issue>):<fpage>16</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1751-0473-8-16" xlink:type="simple">10.1186/1751-0473-8-16</ext-link></comment> <object-id pub-id-type="pmid">23938087</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shekhar</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Brodin</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Chakraborty</surname> <given-names>AK</given-names></name>. <article-title>Automatic classification of cellular expression by nonlinear stochastic embedding (ACCENSE)</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2014</year>;<volume>111</volume>(<issue>1</issue>):<fpage>202</fpage>–<lpage>207</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1321405111" xlink:type="simple">10.1073/pnas.1321405111</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liu</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>L</given-names></name>. <article-title>HEp-2 cell image classification with multiple linear descriptors</article-title>. <source>Pattern Recognition</source>. <year>2014</year>;<volume>47</volume>(<issue>7</issue>):<fpage>2400</fpage>–<lpage>2408</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.patcog.2013.09.022" xlink:type="simple">10.1016/j.patcog.2013.09.022</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Liu</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gao</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Su</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>Z</given-names></name>. <article-title>Sparse coding induced transfer learning for hep-2 cell classification</article-title>. <source>Bio-medical materials and engineering</source>. <year>2014</year>;<volume>24</volume>(<issue>1</issue>):<fpage>237</fpage>–<lpage>243</lpage>. <object-id pub-id-type="pmid">24211903</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref018">
<label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Donato C, Vincenzo T, Marco C, Francesco F, Maria VS, Giuseppe R. HEp-2 cell classification with heterogeneous classes-processes based on k-nearest neighbours. In: Pattern Recognition Techniques for Indirect Immunofluorescence Images (I3A), 2014 1st Workshop on. IEEE; 2014. p. 10–15.</mixed-citation>
</ref>
<ref id="pcbi.1005746.ref019">
<label>19</label>
<mixed-citation publication-type="other" xlink:type="simple">Gao Z, Zhang J, Zhou L, Wang L. Hep-2 cell image classification with convolutional neural networks. In: Pattern Recognition Techniques for Indirect Immunofluorescence Images (I3A), 2014 1st Workshop on. IEEE; 2014. p. 24–28.</mixed-citation>
</ref>
<ref id="pcbi.1005746.ref020">
<label>20</label>
<mixed-citation publication-type="other" xlink:type="simple">Li H, Zhang J, Zheng WS. Deep CNNs for HEp-2 Cells Classification: A Cross-specimen Analysis. arXiv preprint arXiv:160405816. 2016;.</mixed-citation>
</ref>
<ref id="pcbi.1005746.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hosseini</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Abidi</surname> <given-names>SZ</given-names></name>, <name name-style="western"><surname>Du</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Papageorgiou</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Choi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Park</surname> <given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>Cellular normoxic biophysical markers of hydroxyurea treatment in sickle cell disease</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2016</year>; p. 201610435. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1610435113" xlink:type="simple">10.1073/pnas.1610435113</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref022">
<label>22</label>
<mixed-citation publication-type="other" xlink:type="simple">Han XH, Lei J, Chen YW. HEp-2 Cell Classification Using K-Support Spatial Pooling in Deep CNNs. In: International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis. Springer; 2016. p. 3–11.</mixed-citation>
</ref>
<ref id="pcbi.1005746.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Grady</surname> <given-names>L</given-names></name>. <article-title>Random walks for image segmentation</article-title>. <source>IEEE transactions on pattern analysis and machine intelligence</source>. <year>2006</year>;<volume>28</volume>(<issue>11</issue>):<fpage>1768</fpage>–<lpage>1783</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TPAMI.2006.233" xlink:type="simple">10.1109/TPAMI.2006.233</ext-link></comment> <object-id pub-id-type="pmid">17063682</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dokmanic</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Parhizkar</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ranieri</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Vetterli</surname> <given-names>M</given-names></name>. <article-title>Euclidean distance matrices: essential theory, algorithms, and applications</article-title>. <source>IEEE Signal Processing Magazine</source>. <year>2015</year>;<volume>32</volume>(<issue>6</issue>):<fpage>12</fpage>–<lpage>30</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/MSP.2015.2398954" xlink:type="simple">10.1109/MSP.2015.2398954</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ozpolat</surname> <given-names>HT</given-names></name>, <name name-style="western"><surname>Chang</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wu</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Norby</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Konkle</surname> <given-names>BA</given-names></name>, <etal>et al</etal>. <article-title>Evaluation of Cell Types and Morphologies in Sickle Cell Disease with an Imaging Flow Cytometer</article-title>. <source>Blood</source>. <year>2015</year>;<volume>126</volume>(<issue>23</issue>):<fpage>972</fpage>–<lpage>972</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005746.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hiruma</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Noguchi</surname> <given-names>CT</given-names></name>, <name name-style="western"><surname>Uyesaka</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Hasegawa</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Blanchette-Mackie</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Schechter</surname> <given-names>AN</given-names></name>, <etal>et al</etal>. <article-title>Sickle cell rheology is determined by polymer fraction–not cell morphology</article-title>. <source>American journal of hematology</source>. <year>1995</year>;<volume>48</volume>(<issue>1</issue>):<fpage>19</fpage>–<lpage>28</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/ajh.2830480105" xlink:type="simple">10.1002/ajh.2830480105</ext-link></comment> <object-id pub-id-type="pmid">7832188</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>HW</surname> <given-names>GL</given-names></name>, <name name-style="western"><surname>Wortis</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mukhopadhyay</surname> <given-names>R</given-names></name>. <article-title>Stomatocyte–discocyte–echinocyte sequence of the human red blood cell: Evidence for the bilayer–couple hypothesis from membrane mechanics</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2002</year>;<volume>99</volume>(<issue>26</issue>):<fpage>16766</fpage>–<lpage>16769</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.202617299" xlink:type="simple">10.1073/pnas.202617299</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Srivastava</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Krizhevsky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sutskever</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Salakhutdinov</surname> <given-names>R</given-names></name>. <article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title>. <source>Journal of Machine Learning Research</source>. <year>2014</year>;<volume>15</volume>(<issue>1</issue>):<fpage>1929</fpage>–<lpage>1958</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005746.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wong</surname> <given-names>TT</given-names></name>. <article-title>Performance evaluation of classification algorithms by k-fold and leave-one-out cross validation</article-title>. <source>Pattern Recognition</source>. <year>2015</year>;<volume>48</volume>(<issue>9</issue>):<fpage>2839</fpage>–<lpage>2846</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.patcog.2015.03.009" xlink:type="simple">10.1016/j.patcog.2015.03.009</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hijiya</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Horiuchi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Asakura</surname> <given-names>T</given-names></name>. <article-title>Morphology of sickle cells produced in solutions of varying osmolarities</article-title>. <source>The Journal of laboratory and clinical medicine</source>. <year>1991</year>;<volume>117</volume>(<issue>1</issue>):<fpage>60</fpage>–<lpage>66</lpage>. <object-id pub-id-type="pmid">1987310</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Asakura</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Mattiello</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Obata</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Asakura</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Reilly</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Tomassini</surname> <given-names>N</given-names></name>, <etal>et al</etal>. <article-title>Partially oxygenated sickled cells: sickle-shaped red cells found in circulating blood of patients with sickle cell disease</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>1994</year>;<volume>91</volume>(<issue>26</issue>):<fpage>12589</fpage>–<lpage>12593</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.91.26.12589" xlink:type="simple">10.1073/pnas.91.26.12589</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005746.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Asakura</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Asakura</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Obata</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Mattiello</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Ballas</surname> <given-names>SK</given-names></name>. <article-title>Blood samples collected under venous oxygen pressure from patients with sickle cell disease contain a significant number of a new type of reversibly sickled cells: Constancy of the percentage of sickled cells in individual patients during steady state</article-title>. <source>American journal of hematology</source>. <year>2005</year>;<volume>80</volume>(<issue>4</issue>):<fpage>249</fpage>–<lpage>256</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/ajh.20468" xlink:type="simple">10.1002/ajh.20468</ext-link></comment> <object-id pub-id-type="pmid">16315254</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
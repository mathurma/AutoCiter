<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN"><front><journal-meta><journal-id journal-id-type="publisher">pcbi</journal-id><journal-id journal-id-type="allenpress-id">plcb</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">07-PLCB-RA-0484R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000042</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Neuroscience</subject><subject>Neuroscience/Behavioral Neuroscience</subject></subj-group></article-categories><title-group><article-title>Shaping Embodied Neural Networks for Adaptive Goal-directed Behavior</article-title><alt-title alt-title-type="running-head">Training Embodied Networks</alt-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Chao</surname><given-names>Zenas C.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bakkum</surname><given-names>Douglas J.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Potter</surname><given-names>Steve M.</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib></contrib-group><aff id="aff1">          <addr-line>Laboratory for Neuroengineering, Department of Biomedical Engineering, Georgia Institute of Technology and Emory University School of Medicine, Atlanta, Georgia, United States of America</addr-line>       </aff><contrib-group><contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J.</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes><corresp id="cor1">* E-mail: <email xlink:type="simple">steve.potter@bme.gatech.edu</email></corresp><fn fn-type="con"><p>Conceived and designed the experiments: ZC. Performed the experiments: ZC. Analyzed the data: ZC. Contributed reagents/materials/analysis tools: ZC. Wrote the paper: ZC DB SP.</p></fn><fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>3</month><year>2008</year></pub-date><pub-date pub-type="epub"><day>28</day><month>3</month><year>2008</year></pub-date><volume>4</volume><issue>3</issue><elocation-id>e1000042</elocation-id><history><date date-type="received"><day>13</day><month>8</month><year>2007</year></date><date date-type="accepted"><day>20</day><month>2</month><year>2008</year></date></history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2008</copyright-year><copyright-holder>Chao et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>The acts of learning and memory are thought to emerge from the modifications of synaptic connections between neurons, as guided by sensory feedback during behavior. However, much is unknown about how such synaptic processes can sculpt and are sculpted by neuronal population dynamics and an interaction with the environment. Here, we embodied a simulated network, inspired by dissociated cortical neuronal cultures, with an artificial animal (an animat) through a sensory-motor loop consisting of structured stimuli, detailed activity metrics incorporating spatial information, and an adaptive training algorithm that takes advantage of spike timing dependent plasticity. By using our design, we demonstrated that the network was capable of learning associations between multiple sensory inputs and motor outputs, and the animat was able to adapt to a new sensory mapping to restore its goal behavior: move toward and stay within a user-defined area. We further showed that successful learning required proper selections of stimuli to encode sensory inputs and a variety of training stimuli with adaptive selection contingent on the animat's behavior. We also found that an individual network had the flexibility to achieve different multi-task goals, and the same goal behavior could be exhibited with different sets of network synaptic strengths. While lacking the characteristic layered structure of <italic>in vivo</italic> cortical tissue, the biologically inspired simulated networks could tune their activity in behaviorally relevant manners, demonstrating that leaky integrate-and-fire neural networks have an innate ability to process information. This closed-loop hybrid system is a useful tool to study the network properties intermediating synaptic plasticity and behavioral adaptation. The training algorithm provides a stepping stone towards designing future control systems, whether with artificial neural networks or biological animats themselves.</p></abstract><abstract abstract-type="summary"><title>Author Summary</title><p>The ability of a brain to learn has been studied at various levels. However, a large gap exists between behavioral studies of learning and memory and studies of cellular plasticity. In particular, much remains unknown about how cellular plasticity scales to affect network population dynamics. In previous studies, we have addressed this by growing mammalian brain cells in culture and creating a long-term, two-way interface between a cultured network and a robot or an artificial animal. Behavior and learning could now be observed in concert with the detailed and long-term electrophysiology. In this work, we used modeling/simulation of living cortical cultures to investigate the network's capability to learn goal-directed behavior. A biologically inspired simulated network was used to determine an effective closed-loop training algorithm, and the system successfully exhibited multi-task goal-directed adaptive behavior. The results suggest that even though lacking the characteristic layered structure of a brain, the network still could be functionally shaped and showed meaningful behavior. Knowledge gained from working with such closed-loop systems could influence the design of future artificial neural networks, more effective neuroprosthetics, and even the use of living networks themselves as a biologically based control system.</p></abstract><funding-group><funding-statement>This work was supported by grants NS38628 from NIH/NINDS and EB000786 from NIH/NIBIB, and by the Whitaker Foundation, the NSF Center for Behavioral Neuroscience, and a NAKFI (National Academies/Keck Futures Initiative) Smart Prosthetics grant.</funding-statement></funding-group><counts><page-count count="17"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>One of the most important features of the brain is the ability to adapt or learn to achieve a specific goal, which requires continuous sensory feedback about the success of its motor output in a specific context. We developed tools <xref ref-type="bibr" rid="pcbi.1000042-Potter1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1000042-Potter2">[3]</xref> for closing the sensory-motor loop between a cultured network and a robot or an artificial animal (animat) <xref ref-type="bibr" rid="pcbi.1000042-Meyer1">[4]</xref> in order to study learning directly through behavior of the artificial body and its interaction with its environment. Compared to animal models, the cultured network is a simpler and more controllable system to investigate basic network computations; confounding factors such as sensory inputs, attention, and behavioral drives are absent, while diverse and complex activity patterns remain <xref ref-type="bibr" rid="pcbi.1000042-Shefi1">[5]</xref>–<xref ref-type="bibr" rid="pcbi.1000042-VanPelt1">[9]</xref>.</p><p>Previously, an embodied cultured network's ability to control an animat or a mobile robot was demonstrated without a specifically defined goal <xref ref-type="bibr" rid="pcbi.1000042-DeMarse1">[2]</xref>,<xref ref-type="bibr" rid="pcbi.1000042-Martinoia1">[10]</xref>. In another case, animats were designed to avoid obstacles <xref ref-type="bibr" rid="pcbi.1000042-Cozzi1">[11]</xref> or follow objects <xref ref-type="bibr" rid="pcbi.1000042-Bakkum1">[12]</xref>, but deterministically and without learning. By using a lamprey brainstem to control a mobile robot, Mussa-Ivaldi et al. demonstrated the embodied <italic>in vitro</italic> network's tendency to compensate the sensory imbalance caused by artificially altering the sensitivity of the sensors at one side of the robot. Without a pre-defined goal and external training stimulation, long-term changes in behavior in response to the sensory imbalance were found in embodied lamprey brainstems <xref ref-type="bibr" rid="pcbi.1000042-Reger1">[13]</xref>, however, the changes were unpredictable <xref ref-type="bibr" rid="pcbi.1000042-Karniel1">[14]</xref>. In order to further understand the learning capability of an embodied cultured network for goal-directed behavior, we need to investigate how the network can be shaped and rewired, and how to direct this change.</p><p>Previous studies have demonstrated the potential for disembodied cultured networks to achieve functional plasticity. This neural plasticity provides a potential learning capability to cultured networks. Jimbo et al. <xref ref-type="bibr" rid="pcbi.1000042-Jimbo1">[15]</xref> used a localized tetanic stimulus to induce long-lasting changes in the network responses that could be either potentiated or depressed depending on the electrode used to evoke the responses. Moreover, we and others previously found that such tetanus-induced plasticity was spatially localized and asymmetrically distributed <xref ref-type="bibr" rid="pcbi.1000042-Chao1">[16]</xref>,<xref ref-type="bibr" rid="pcbi.1000042-Ruaro1">[17]</xref>. By delivering two different tetanic stimulation patterns, Ruaro et al. trained a cultured network to discriminate the spatial profiles of the stimuli. These results suggest that different stimulation patterns can shape diverse functional connectivity in cultured networks. By incorporating closed-loop feedback, Shahaf and Marom <xref ref-type="bibr" rid="pcbi.1000042-Shahaf1">[18]</xref> showed unidirectional learning: to induce an electrode-specific increase in response. This simple form of learning was achieved by a binary training: to stop a periodic stimulation at one electrode when the desired response level at the target electrode was obtained. In order to scale to more complex behavior, we need to create more structured training stimuli and detailed activity metrics to investigate whether an embodied cultured network can learn multiple tasks simultaneously.</p><p>Unlike <italic>in vivo</italic> systems, the sensory-motor mapping and training algorithm in an embodied cultured network are defined by the experimenters. In order to efficiently find an effective closed-loop design among infinite potential mappings, we first embodied a biologically-inspired simulated network to study an adaptive goal-directed behavior in an animat: learning to move toward and stay within a user-defined area in a 2-D plane. The simulated network of 1000 leaky integrate-and-fire neurons expressed spontaneous and evoked activity patterns similar to that of the dissociated cortical cultures <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>. Furthermore, a similar but larger simulated network showed that localized coherent input resulted in shifts of receptive and projective fields similar to those observed <italic>in vivo</italic> <xref ref-type="bibr" rid="pcbi.1000042-Izhikevich1">[20]</xref>. Thus simulated networks show promise for analyzing biological adaptation with various closed-loop designs.</p><p>The closed-loop design we discuss here consists of four unique elements:</p><list list-type="order"><list-item><p>Patterned stimulation to induce network plasticity. This low-frequency (∼3 Hz) training stimulation differs from most studies of cultured networks, where plasticity was induced by high frequency tetanic stimulations <xref ref-type="bibr" rid="pcbi.1000042-Jimbo1">[15]</xref>,<xref ref-type="bibr" rid="pcbi.1000042-Ruaro1">[17]</xref>.</p></list-item><list-item><p>Continuous low-frequency background stimulation (∼3 Hz) to stabilize accumulated plasticity <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>, which is analogous to continuous sensory inputs and ongoing processing in the brain.</p></list-item><list-item><p>Population coding for motor mapping. Population coding is considered a robust means to represent movement directions in the primary motor cortex <xref ref-type="bibr" rid="pcbi.1000042-Georgopoulos1">[21]</xref>.</p></list-item><list-item><p>Adaptive selection of training stimulation. Because the connectivity in a cultured network is not predictable, the effects of a given training stimulation cannot be known <italic>a priori</italic>. Thus we delivered training stimulation contingent on the animat's performance in order to direct changes in network connectivity that further shift the animat's behavior toward the desired behavior.</p></list-item></list><p>Here, we demonstrate adaptive goal-directed behavior in the simulated network, where multiple tasks were learned simultaneously. The desired behavior could only be achieved with proper selection of stimuli to encode sensory inputs and a variety of training stimuli with adaptive selection contingent on the animat's behavior.</p><p>While lacking the characteristic layered structure of <italic>in vivo</italic> cortical tissue, the biologically-inspired simulated network still could be functionally shaped, and showed meaningful behavior, demonstrating that these neural networks have an innate ability to process information. The proposed design is not restricted to a particular sensory-motor mapping, and could be applied with different and more complex goal-directed behaviors, which may provide a useful <italic>in vitro</italic> model for studying sensory-motor mappings, learning, and memory in the nervous system.</p></sec><sec id="s2"><title>Methods</title><p>We designed a closed-loop system consisting of an animat and a biologically inspired simulated network, looped together through the stimulation of virtual electrodes to encode sensory information and to direct learning, and through recordings from the virtual electrodes used to generate motor output. A series of experiments was performed to validate some of the designs, to determine the system's ability to learn a pre-determined goal behavior, and to verify what was essential in the system for successful learning.</p><sec id="s2a"><title>Closed-Loop System</title><sec id="s2a1"><title>Animat</title><sec id="s2a1a"><title>Environment</title><p>The animat was controlled by a simulated network (see Biologically inspired simulated network section below) to move in a plane within a circle of 50 units radius, which was divided into four quadrants (Q1: northeast, Q2: northwest, Q3: southwest, and Q4: southeast, see <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A</xref>). The animat was put back to a random location within a smaller concentric circle of 5 units radius if it moved outside the outer circle.</p><fig id="pcbi-1000042-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g001</object-id><label>Figure 1</label><caption><title>Closed-loop algorithm.</title><p>(A) Closed-loop design: the sensory mapping (1–2), the motor mapping (3–4), and the training rules (5–6). Refer to <xref ref-type="sec" rid="s2">Methods</xref> for a detailed explanation. (B) Motor mapping transformation. Left: In the beginning of each experiment, each CPS (CPS<sub>Q1</sub>–CPS<sub>Q4</sub>) was continuously delivered every 5 seconds with RBS in between. After the animat reached the outer circle, it was moved back to the inner circle. Middle: The average CAs from probe responses to each CPS were calculated (CA<sub>Q1</sub>–CA<sub>Q4</sub>). The average CAs represent the average movements from each CPS. Right: The transformation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e001" xlink:type="simple"/></inline-formula> for each CPS was created so that the average movement in each quadrant would be the desired movement with a magnitude of 1 unit (M<sub>Q1</sub>–M<sub>Q4</sub>).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g001" xlink:type="simple"/></fig></sec><sec id="s2a1b"><title>Goal</title><p>The goal of the animat was to move and stay within a smaller concentric circle of 5 units radius (see <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A</xref>). Successful behavior required that animat movement in each quadrant be towards the origin.</p></sec><sec id="s2a1c"><title>Sensory system and motor capability</title><p>The animat had two sensory inputs and the neural network's response to the first determined animat movement (<xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A</xref>).</p><sec id="s2a1c1"><title>Animat location</title><p>Location was one of four discrete values representing which quadrant the animat was in (Q1–Q4). Sensory input was applied to the neural network every 5 seconds by stimulating a corresponding sequence of electrodes (CPS<sub>Q1</sub>–CPS<sub>Q4</sub>; see Stimulation protocols section below). The last electrode in the sequence was termed “probe” and evoked network responses used to determine animat movement (see Motor mapping section below).</p></sec><sec id="s2a1c2"><title>Animat performance</title><p>If the animat was outside of the inner circle, its performance determined whether training was required (see Training rules section below). Patterned training stimuli (PTS; see Stimulation protocols section below) was applied if the animat was moving away from the inner circle in order to cause neural plasticity and induce learning. Otherwise, the goal-behavior was being achieved, and random background stimulation (RBS; see Stimulation protocols section below) was applied in order to maintain animat behavior. In order to acquire sufficient training between two movements, the sensory input of location (and thus animat movement) was evaluated every 5 seconds.</p></sec></sec></sec><sec id="s2a2"><title>Biologically inspired simulated network</title><p>The animat was connected to a simulated network through a sensory-motor loop (<xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A</xref>). We used the Neural Circuit SIMulator <xref ref-type="bibr" rid="pcbi.1000042-Natschlager1">[22]</xref> to produce three artificial neural networks, described previously <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref> with parameters detailed in Supplemental Material <xref ref-type="supplementary-material" rid="pcbi.1000042.s001">Text S1</xref>. Briefly, 1,000 leaky integrate-and-fire (LIF) model neurons, with a total of 50,000 synapses, were placed randomly in a 3 mm by 3 mm area. All synapses were frequency-dependent <xref ref-type="bibr" rid="pcbi.1000042-Izhikevich1">[20]</xref>,<xref ref-type="bibr" rid="pcbi.1000042-Markram1">[23]</xref> to model synaptic depression. Seventy percent of the neurons were excitatory, with spike-timing-dependent plasticity (STDP) <xref ref-type="bibr" rid="pcbi.1000042-Song1">[24]</xref>. We included an 8 by 8 grid of electrodes, 60 of these (see <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A, red circles in the simulated network</xref>) were used for recording and stimulation as in a typical real multi-electrode array (MEA) used in our lab (from Multi Channel Systems). The networks were run without external stimulation for 5 hours in simulated time and then with random background stimulation (RBS, see below) for another two hours until the synaptic weights reached equilibrium. The set of stabilized synaptic weights was used as the initial state for the corresponding network.</p><p>In a previous study, we showed that our 1000-neuron LIF model and living MEA cultures expressed similar spontaneous and evoked activity patterns, demonstrating the usefulness of the LIF model for representing the activity of biological networks <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>. In another study, we successfully used this simulated network to find a statistic to detect network functional plasticity in living MEA cultures and to demonstrate region-specific properties of stimulus-induced network plasticity <xref ref-type="bibr" rid="pcbi.1000042-Chao1">[16]</xref>.</p></sec><sec id="s2a3"><title>Closed-loop algorithm</title><p>The closed-loop design in this work included (1) three different stimulation protocols encoding sensory inputs, inducing learning, and maintaining what was learned, (2) a simple sensory mapping, (3) a motor mapping with population coding incorporating spatial information of network activity, and (4) training rules with adaptive selections of training stimuli.</p><sec id="s2a3a"><title>Stimulation protocols</title><p>We used three classes of stimulation protocols for three different purposes: (1) Four <italic>context-control probing sequences (CPSs)</italic> (CPS<sub>Q1</sub>–CPS<sub>Q4</sub>) were used to encode 4 sensory inputs (current location = Q1-Q4). These also evoked neural activity used as motor commands for the animat. (2) Four “pools” of <italic>patterned training stimulation (PTS)</italic> (PTS<sub>Q1</sub>–PTS<sub>Q4</sub>), each also assigned to Q1-Q4, were used to induce network plasticity to train the animat. (3) <italic>Random background stimulation (RBS)</italic> was used to stabilize accumulated plasticity, and was shown previously to stabilize network synaptic weights <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>.</p><sec id="s2a3a1"><title>Context-control probing sequence (CPS)</title><p>Four stimulation sequences were used (CPS<sub>Q1</sub>–CPS<sub>Q4</sub>). Each CPS consisted of a sequence of 3 stimulation pulses from 3 randomly selected electrodes with inter-pulse intervals randomly selected between 200 to 400 msec (<xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A</xref>). The last stimulus, termed probe, was unique to each CPS. For each experiment, the CPSs were fixed throughout.</p><p>Each CPS (CPS<sub>Q1</sub>- CPS<sub>Q4</sub>) was delivered every 5 seconds, when the corresponding sensory input (Q1- Q4) was evaluated. We used the evoked action potentials from the last stimulus (probe responses) to generate motor commands to control the animat. The context before the probe stimulus was found to influence the probe response <xref ref-type="bibr" rid="pcbi.1000042-Darbon1">[25]</xref>. Therefore, in order to directly quantify learning by changes in movement, we sought to reduce the variability in the probe response due to recent neural activity and stimulation history, such that changes in probe responses were due mainly to changes in network connectivity. We found that by controlling the stimulation context (the first two stimuli of a CPS) before the probe with inter-pulse intervals between 200 to 400 msec, the variability of the probe responses was minimized. Data supporting this in both simulated and living networks are shown in Supplemental Material <xref ref-type="supplementary-material" rid="pcbi.1000042.s002">Text S2</xref>.</p></sec><sec id="s2a3a2"><title>Patterned training stimulation (PTS)</title><p>Four pools of PTSs (PTS<sub>Q1</sub>–PTS<sub>Q4</sub>) were used, each associated with its corresponding quadrant. A PTS consisted of repetitive stimulation at two electrodes. The location of the first electrode (PTS-E1) was chosen as the probe electrode used in the preceding CPS (for PTS<sub>Q1</sub>, it was the last stimulus in CPS<sub>Q1</sub>). The two parameters varied among different PTSs in a pool were: the location of second electrode (PTS-E2<sub>k</sub>), and the relative timing from the first electrode (inter-pulse interval, PTS<sub>t</sub>) (see <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A</xref>). PTS-E2<sub>k</sub> was chosen from one of the 60 electrodes (k = 1–60), and PTS<sub>t</sub> was chosen from one of 11 values: −100, −80, −60, −40, −20, 0, 20, 40, 60, 80, and 100 msec. Therefore, each pool consisted of 660 ( = 60*11) PTSs.</p><p>During training, a PTS was delivered repetitively at the pair of electrodes with random inter-PTS-intervals between 400 to 800 msec. Paired stimulation of monosynaptically connected neurons evokes STDP dependent on the stimulation interval <xref ref-type="bibr" rid="pcbi.1000042-Bi1">[26]</xref>, and paired stimulation of two electrodes has the potential to induce STDP throughout any shared activation pathways in the network. In our simulated networks, we found that the network could be shaped into a variety of possible synaptic states by using paired stimulation with different stimulation parameters (electrode pairs, inter-PTS-intervals, etc.) (data not shown). This validates the use of PTSs to direct network plasticity.</p></sec><sec id="s2a3a3"><title>Random background stimulation (RBS)</title><p>RBS was delivered randomly at 60 electrodes, one at a time, with random inter-pulse-intervals ranging from 200 to 400 msec (see <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A</xref>). RBS of an aggregated frequency of 1 Hz was shown previously to have stabilizing effects on network synaptic weights in a simulated network after stimulus-induced plasticity <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>. Thus we delivered RBS to maintain the network synaptic weights if the desired behavior was observed. In this study, the aggregated stimulation frequency of RBS was increased to 3 Hz so that amounts of stimulation in RBS and PTS were comparable.</p><p>The closed-loop system consisted of three parts (see <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1A</xref>): the sensory mapping, the motor mapping, and the training rules.</p></sec></sec><sec id="s2a3b"><title>Sensory mapping</title><p>One CPS (CPS<sub>Q1</sub>, CPS<sub>Q2</sub>, CPS<sub>Q3</sub>, or CPS<sub>Q4</sub>) was delivered every 5 seconds based on which sensory input was received (Q1, Q2, Q3, or Q4) (<xref ref-type="fig" rid="pcbi-1000042-g001">1 and 2 in Figure 1A</xref>).</p></sec><sec id="s2a3c"><title>Motor mapping: Center of activity (CA)</title><p>After delivering a CPS, the number of spikes within 100 msec after the probe were measured at 60 recording electrodes, and the Center of Activity (CA) was calculated (<xref ref-type="fig" rid="pcbi-1000042-g001">3 in Figure 1A</xref>) <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>. CA represents the spatial asymmetry of the activity, which is analogous to the center of mass. Assume FR(k) represents firing rates at recording electrode k within 100 msec after the probe, and Col(k) and Row(k) are the column number and the row number of electrode k, which range from 1 to 8. For example, electrode 28 has column number 2 and row number 8 (<xref ref-type="fig" rid="pcbi-1000042-g001">see 3 in Figure 1A</xref>). Then CA is a two dimensional vector:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e002" xlink:type="simple"/><label>(1)</label></disp-formula>where [4.5, 4.5] represents the center of the 8 by 8 grid of electrodes. Previously we found that the network synaptic state could be more effectively decoded by incorporating the spatial information of activity distribution <xref ref-type="bibr" rid="pcbi.1000042-Chao1">[16]</xref>.</p></sec><sec id="s2a3d"><title>Motor mapping: Population coding and motor mapping transformation</title><p>We instructed incremental movement of the animat [<italic>dX</italic>, <italic>dY</italic>] by using a population vector calculated from CA (<xref ref-type="fig" rid="pcbi-1000042-g001">4 in Figure 1A</xref>):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e003" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e004" xlink:type="simple"/></inline-formula> is a transformation matrix that transformed CAs in the four quadrants into desired movements with average 1 unit moving distance.</p><p>In the beginning of each experiment, CPS<sub>Q1</sub> was continuously delivered every 5 seconds with RBS in between. After the animat reached the outer circle, it was moved back to the inner circle, and CPS<sub>Q2</sub> was delivered, then CPS<sub>Q3</sub> and CPS<sub>Q4</sub>. The whole process was repeated 5 times, and the average CAs from probe responses to each CPS were calculated (shown as CA<sub>Q1</sub>–CA<sub>Q4</sub> in <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1B</xref>). The average CAs represent the average movements from each CPS. The transformations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e005" xlink:type="simple"/></inline-formula> for each CPS were created so that the average movement in each quadrant would be the desired movement (M<sub>Q1</sub>–M<sub>Q4</sub>; pointing to the center of the inner circle) with a magnitude of 1 unit (see <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1B</xref>). For example, for CA<sub>Q1</sub> = [<italic>CA<sub>Q1,X</sub>, CA<sub>Q1,Y</sub></italic>] and the desired movement <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e006" xlink:type="simple"/></inline-formula>, the transformation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e007" xlink:type="simple"/></inline-formula> consisted of two scaling numbers <italic>α<sub>Q1</sub>, and β<sub>Q1</sub></italic> that satisfied:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e008" xlink:type="simple"/><label>(3)</label></disp-formula>Thus, for a CPS<sub>Q1</sub> delivered with no neural plasticity, the animat will move on average at a −135° angle by 1 unit distance. For each experiment, the transformations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e009" xlink:type="simple"/></inline-formula> were calculated first, and then fixed for the duration of the experiment.</p></sec><sec id="s2a3e"><title>Training rules</title><p>If the animat's performance was desirable (moving inward), then RBS was delivered for 5 seconds until the next sensory input was evaluated (<xref ref-type="fig" rid="pcbi-1000042-g001">5 to 2 in Figure 1A</xref>). If the animat's performance was not desired (moving outward), then training was applied (<xref ref-type="fig" rid="pcbi-1000042-g001">5 in Figure 1A</xref>): a PTS was randomly selected from the corresponding pool; if the previous CPS was CPS<sub>Q1</sub>, then the PTS was selected from PTS<sub>Q1</sub> (<xref ref-type="fig" rid="pcbi-1000042-g001">6 in Figure 1A</xref>) and delivered for 5 seconds (<xref ref-type="fig" rid="pcbi-1000042-g001">2 in Figure 1A</xref>). If the performance of the animat was improved but still not desirable after the PTS (still moving outward but at a slower rate), then the same PTS would be used for the next training. Initially, the probability of choosing a PTS from a pool was identical (1/660). Every time a PTS improved the performance of the animat after the next probe, a copy was added into its pool. Thus the size of the pool increased, and the probability of this “favorable” PTS being chosen later was increased. In contrast, if that PTS worsened the performance of the animat (moving outward faster), it was removed from the pool, unless only one PTS of this specific type remained.</p><p>To summarize, if the animat was moving correctly, RBS was delivered to stabilize the corresponding network synaptic state. Otherwise, PTS was delivered to change the network synaptic weights. Also, the probability of specific PTS patterns being chosen was constantly updated according to the performance of the animat.</p></sec></sec></sec><sec id="s2b"><title>Simulation Experiments</title><p>We used three networks with different connectivity, each with 5 different sets of CPSs (randomly selected CPS<sub>Q1</sub>–CPS<sub>Q4</sub>). These 15 setups with different network connectivity and sensory-motor mappings were used for the following simulation experiments:</p><sec id="s2b1"><title>Experiment 1: Validate effects of RBS on stability of network input-output functions</title><p>This experiment was performed to validate the design of using RBS to maintain the desired behavior. In a previous study, we showed that RBS helped stabilize network synaptic weights after stimulus-induced plasticity in a simulated network <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>. Here we further verified how this effect on network synaptic weights affected stability of the network input-output function, that is, stability of the animat's movement under the same sensory input.</p><p>The animat was run with RBS between CPSs without training (no PTS) for one hour. We compared this to the animat's performance without RBS (CPSs only). The initial network state, the random seed for fluctuations in neurons' membrane potentials and synaptic currents, and the sensory-motor mapping were not varied.</p><p>We used mutual information to quantify stability of the relation between sensory inputs (discrete values of 1, 2, 3, or 4 for Q1, Q2, Q3, or Q4, respectively) and motor outputs (animat's movement angles from −180° to 180). Mutual information is a better quantity to measure the general dependence between stimuli (sensory inputs) and responses (motor outputs) than the correlation function which only measures the linear dependence <xref ref-type="bibr" rid="pcbi.1000042-Li1">[27]</xref>. Furthermore, mutual information can be applied to symbolic sequences, such as discrete values of sensory inputs here, while the correlation function can be only applied to numerical sequences <xref ref-type="bibr" rid="pcbi.1000042-Li1">[27]</xref>. The animat's sensory inputs (Q1, Q2, Q3, or Q4) and movement angles (−180–180) were recorded and mutual information was calculated in 5-min moving time windows with a time step of 5 seconds using the histogram-based mutual information methods <xref ref-type="bibr" rid="pcbi.1000042-Moddemeijer1">[28]</xref>. The higher the mutual information between sensory inputs and motor outputs, the lower the uncertainty about the sensory input after a motor output is observed, that is, the higher the stability of the animat's movement under the same sensory input.</p></sec><sec id="s2b2"><title>Experiment 2: Quantify learning by switching the sensory mapping</title><p>We investigated the networks' ability to learn a user-defined goal behavior by “switching” the sensory mapping. This would be analogous to placing an animal into a different environment, or imposing a new task. As described previously, the sensory-motor mapping was set up so that the animat would move toward the center as desired. We quantified the animat's ability to adapt to a switch of the sensory mapping, that is, the ability to restore desired behavior under a different sensory mapping.</p><p>The transformation, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e010" xlink:type="simple"/></inline-formula>, allowed the animat to move correctly, on average, and after 10 minutes the sensory mapping was switched by exchanging CPS<sub>Q1</sub> and CPS<sub>Q3</sub> while CPS<sub>Q2</sub> and CPS<sub>Q4</sub> remained unchanged. That is, if the animat was at Q1, CPS<sub>Q3</sub> was delivered instead of CPS<sub>Q1</sub>, and vice versa. The simulation was stopped when either the simulation time exceeded 4 hours without reaching the goal or the animat stayed within the inner circle 90% of the time (reached the goal) for 10 minutes. If the animat was able to adapt to the new sensory mapping and learn the desired behavior, the network was considered successfully rewired. The time course of this adaptation was quantified by the learning curve, which was measured as the probability of successful behavior within a 2-min moving time window with 5-sec step.</p></sec><sec id="s2b3"><title>Experiment 3: Avoid unsuccessful learning by selecting CPSs with small <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> and small <italic>Max overlap</italic></title><p>In order to avoid unsuccessful adaptations, we selected CPSs that evoked less localized and less overlapped responses (see <xref ref-type="sec" rid="s3">Results</xref>), instead of random selections used in Experiment 2. The level of localization in responses was quantified by <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic>, which was the maximum of CA<sub>Q1</sub> and CA<sub>Q3</sub> (average CAs to CPS<sub>Q1</sub> and CPS<sub>Q3</sub>). The reason that only responses to CPS<sub>Q1</sub> and CPS<sub>Q3</sub> were used are described in Results. The degrees of overlap between the responses of different pairs of CPSs were quantified by <italic>Max overlap</italic>. Assume that <italic>N<sub>Q1</sub></italic> is the set of neurons activated by CPS<sub>Q1</sub>, and <italic>N<sub>Q2</sub></italic> is the set of neurons activated by CPS<sub>Q2</sub>. Then the degree of overlap between responses to CPS<sub>Q1</sub> and CPS<sub>Q2</sub> was defined as:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e011" xlink:type="simple"/><label>(4)</label></disp-formula>where ||·|| represents the number of elements in the set. This value indicates the proportion of neurons activated by CPS<sub>Q1 </sub>that were also activated by CPS<sub>Q2</sub>, which quantifies how much the training in Q1 (a switched quadrant) might affect the behavior in Q2 (un-switched). The maximum of all possible overlaps between a switched quadrant and an un-switched quadrant was found:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e012" xlink:type="simple"/><label>(5)</label></disp-formula>We randomly generated 85 sets of CPSs, in addition to the 15 original ones, and randomly selected 10 sets that satisfied the criteria of <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)&lt;150</italic> and <italic>Max overlap&lt;50%</italic>. Then we repeated Experiment 2 with these 10 setups to see whether the success rate of adaptations could be improved.</p></sec><sec id="s2b4"><title>Experiment 4: Verify the contribution of the network to learning in the system</title><p>The selection of PTSs was an adaptive process. Therefore, successful adaptations in the behavior of the system could solely be a product of the artificial adaptive training algorithm. In order to verify whether the network had contributed toward learning, we repeated the successful-learning simulations found in Experiment 2 with the STDP algorithm turned off to see whether successful adaptations remained. In each new simulation, the same random seed, the same initial network synaptic weights, the same sensory-motor mappings, and the same simulation duration were used as in the corresponding original one. This was analogous to applying neurotransmitter receptor antagonists, such as APV, to block synaptic plasticity in the culture. If learning degrades without the STDP algorithm, then network plasticity is contributing to successful adaptation.</p></sec><sec id="s2b5"><title>Experiment 5: Verify the importance of availability of different PTSs</title><p>We hypothesized that the same PTS might have different effects at different points in time, and therefore successful adaptations would require a variety of different PTSs (see <xref ref-type="sec" rid="s3">Results</xref>). In order to verify this hypothesis, we repeated the successful-learning simulations found in Experiment 2, but used only one PTS pattern for training in each quadrant instead of a pool of 660 PTSs as before. In order to increase the likelihood that these PTSs could achieve better learning results, we selected the four most frequently used PTSs, one for each quadrant in the original successful-learning simulation. A new simulation was run with the same random seed, the same initial network synaptic weights, the same sensory-motor mappings, and the same simulation duration, as in the original simulation.</p></sec><sec id="s2b6"><title>Experiment 6: Verify the importance of behavior-contingent training</title><p>In order to verify the importance of behavior-based training on the performance of the animat, we recorded the whole training stimulation sequence (PTS and RBS) for each successfully adapted simulation in Experiment 2 and replayed it into the same network with the same initial state and with the same sensory-motor mapping. In the replayed-training simulation, a different random seed for fluctuations in neurons' membrane potentials and synaptic currents was used. Thus, responses to CPSs in the replayed-training simulation were not identical to those in the original successful-learning simulation, and hence the trajectory of the animat rapidly diverged from that of the original simulation. The replayed training stimulation was delivered regardless of whether the movement was desired or not. Therefore, the training stimulation soon became no longer contingent on the network activity.</p></sec><sec id="s2b7"><title>Experiment 7: Verify the uniqueness of “solutions”</title><p>In order to investigate whether under a specific sensory mapping, the desired behavior could only be exhibited by a specific set of network synaptic weights, we switched the sensory mapping back to the original sensory mapping, after the network adapted to the switched sensory mapping in Experiment 2, to see whether the network could re-adapt to the original mapping. If the network was able to re-adapt to the original mapping, we checked whether the network synaptic weights were the same as the first time.</p></sec></sec></sec><sec id="s3"><title>Results</title><p>In order to investigate how external training stimuli can shape a network into a desired state, we used a biologically-inspired simulated network to study multi-task goal-directed behavior by embodying the network with an animat. We first validated the design of using random background stimulation (RBS) to maintain what was learned (Experiment 1). We then quantified the system's learning ability (Experiment 2), and investigated the reasons for unsuccessful learning (Experiment 3). We showed that learning in the network was responsible for successful learning in the overall closed-loop system (Experiment 4), and further verified the importance of using a sequence of PTS patterns for training (Experiment 5) contingent on behavior (Experiment 6). We finish by demonstrating that the same desired behavior could be exhibited with different sets of network synaptic strengths (Experiment 7). Experiment protocols are further detailed in <xref ref-type="sec" rid="s2">Methods</xref>. All acronyms are shown in <xref ref-type="table" rid="pcbi-1000042-t001">Table 1</xref>. A diagram of the closed-loop system, stimulation sequences, and motor transformations is shown in <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1</xref>.</p><table-wrap id="pcbi-1000042-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.t001</object-id><label>Table 1</label><caption><title>Acronym list.</title></caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000042-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" colspan="2" rowspan="1">Abbreviation</td><td align="left" colspan="1" rowspan="1">Full Name</td></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">Stimulation protocol</td><td align="left" colspan="1" rowspan="1">CPS</td><td align="left" colspan="1" rowspan="1">Context-control probing sequence</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">PTS</td><td align="left" colspan="1" rowspan="1">Patterned training stimulation</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">RBS</td><td align="left" colspan="1" rowspan="1">Random background stimulation</td></tr><tr><td align="left" colspan="1" rowspan="1">PTS parameters</td><td align="left" colspan="1" rowspan="1">PTS<sub>Δt</sub></td><td align="left" colspan="1" rowspan="1">Inter-pulse interval of a PTS</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">PTS-E1</td><td align="left" colspan="1" rowspan="1">First electrode in a PTS ( = probe electrode)</td></tr><tr><td align="left" colspan="1" rowspan="1"/><td align="left" colspan="1" rowspan="1">PTS-E2<sub>k</sub></td><td align="left" colspan="1" rowspan="1">Second electrode in a PTS</td></tr><tr><td align="left" colspan="2" rowspan="1">CA</td><td align="left" colspan="1" rowspan="1">Center of activity</td></tr><tr><td align="left" colspan="2" rowspan="1">MEA</td><td align="left" colspan="1" rowspan="1">Multi-electrode array</td></tr><tr><td align="left" colspan="2" rowspan="1">STDP</td><td align="left" colspan="1" rowspan="1">Spike-timing-dependent plasticity</td></tr></tbody></table></alternatives></table-wrap><sec id="s3a"><title>Experiment 1: Random Background Stimulation (RBS) Helped Maintain the Network Input-Output Function</title><p>In order to validate the use of RBS to maintain desired behavior, the animat was run with RBS between context-control probing sequences (CPSs) without training (no PTS), and the results were compared to the animat's performance without RBS (CPSs only). An example of the time course of the animat's distance from the origin is shown in <xref ref-type="fig" rid="pcbi-1000042-g002">Figure 2A</xref>. The motor mapping was transformed (by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e015" xlink:type="simple"/></inline-formula>, see <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1B</xref>) to obtain desired movements before the simulation. Therefore, in the beginning of both simulations with RBS and without RBS, the animat moved in desired directions in each quadrant and stayed within the inner circle. The animat maintained this desired behavior for the entire hour over 90% of the time when RBS was applied, whereas it moved outward after 10 minutes when no RBS was applied.</p><fig id="pcbi-1000042-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g002</object-id><label>Figure 2</label><caption><title>RBS stabilized the network input-output function.</title><p>(A) An example of the time course of the distance between the animat and the origin. The animat stayed within the desired area (the inner circle of 5 units radius) for more than 95% of an hour when RBS was applied. When no RBS was applied, the animat moved outward after 10 minutes. When the animat reached the outer circle of 50 units radius, it was put back to a random location within the inner circle, which is shown as vertical downward lines. (B) The mutual information between the movement angle and the sensory input. When no RBS was applied, the mutual information decreased significantly when the animat started moving outward. (C) Comparison between the mutual information during the last 10 minutes (light gray, <italic>P2</italic> period shown in [B]) and that during the first 10 minutes (dark gray, <italic>P1</italic>) for the 15 simulations (3 networks, 5 different selections of CPSs each). With RBS, the mutual information in <italic>P2</italic> was comparable to that in <italic>P1</italic> (p = 0.77). Without RBS, the mutual information in <italic>P2</italic> was significantly lower than that in <italic>P1</italic> (p&lt;1e-4, shown as an asterisk).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g002" xlink:type="simple"/></fig><p>The mutual information between the movement angle and the sensory input is shown in <xref ref-type="fig" rid="pcbi-1000042-g002">Figure 2B</xref>. When the animat started moving outward in an undesired direction, the mutual information decreased significantly. This indicates decreasing stability of the animat's movement under the same sensory input. The mutual information during the last 10 minutes (<italic>P2</italic> period in <xref ref-type="fig" rid="pcbi-1000042-g002">Figure 2B</xref>) was compared to the mutual information during the first 10 minutes (<italic>P1</italic>) in the 15 simulations (3 networks, 5 different selections of CPSs each) (<xref ref-type="fig" rid="pcbi-1000042-g002">Figure 2C</xref>). With RBS, the mutual information in <italic>P2</italic> was 1.42±0.15 bits (mean±SEM, n = 1800 measures, 15 networks, 120 measures in 10 min per network), which was comparable to 1.53±0.09 bits in <italic>P1</italic> (p = 0.77, Wilcoxon signed-rank test). Without RBS, the mutual information in <italic>P2</italic> was 0.14±0.10 bits, which was significantly lower than 1.40±0.24 bits in <italic>P1</italic> (p&lt;1e-4). This indicates that RBS with an aggregate frequency of 3 Hz maintained stability of the network input-output function, validating the use of RBS to maintain desired behavior in the animat. Furthermore, the results also suggested that repetitive non-training stimuli (CPSs and RBS) were unable to induce enough plasticity to systematically alter the animat's behavior.</p></sec><sec id="s3b"><title>Experiment 2: Adaptation to the Switched Sensory Mapping</title><p>We investigated the networks' ability to learn a user-defined goal behavior by “switching” the sensory mapping. A motor mapping was created (through transformations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e013" xlink:type="simple"/></inline-formula>) to obtain desired movements before the experiment began (<xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1B</xref>). The animat's performance was observed for 10 minutes, demonstrating robust goal-directed behavior (<xref ref-type="fig" rid="pcbi-1000042-g003">Figures 3</xref> and <xref ref-type="fig" rid="pcbi-1000042-g004">4</xref>). Then the sensory mapping was suddenly and drastically altered, so that the animat's behavior was no longer correct. Specifically, a CPS appropriate for evoking movement toward the center from Q1 was now delivered when the animat was in Q3, and vice versa. Learning was then quantified by the animat's ability to adapt to the new, fixed sensory mapping and exhibit goal-seeking behavior.</p><fig id="pcbi-1000042-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g003</object-id><label>Figure 3</label><caption><title>Adaptation to a new sensory mapping.</title><p>The animat's learning ability was quantified by its ability to restore desired behavior after a sensory mapping switch. (A) An example of successful learning. The distance between the animat and the origin is shown in the left panel. The animat maintained the desired behavior for the first 10 minutes (the average inward movement in each quadrant during this 10-min duration is shown on the top), before the sensory mapping switch was performed between quadrants Q1 and Q3 at 10 minutes into the simulation. Immediately after the switch, the animat started moving outward (the trajectory is shown in the right panel). The red arrows on the top indicate the average outward movements in Q1 and Q3 during a 5-min time bin after the switch. Eventually, the animat adapted to the switch and restored the desired behavior to stay within the inner circle under the new sensory mapping. The average movements in all quadrants became toward the center again during the last 10 minutes, where the restored desired movements in Q1 and Q3 are highlighted in green. Ten simulations (out of 15) showed successful adaptation to the switch. (B) An example of unsuccessful learning. The animat kept moving outward and was repeatedly returned to the inner circle after reaching the outer circle. The training was unable to restore the desired behavior throughout 4 hours of experiment. Only the first 90 minutes are shown for clarity. One-third of the simulations showed unsuccessful learning.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g003" xlink:type="simple"/></fig><fig id="pcbi-1000042-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g004</object-id><label>Figure 4</label><caption><title>All successful and unsuccessful learning simulations.</title><p>The distances between the animat and the origin in all 15 simulations are shown. The animat maintained the desired behavior before the sensory mapping switch (red triangle) between quadrants Q1 and Q3 at 10 minutes into the simulation (green bar). Immediately after the switch, the animat started moving outward. In 10 simulations, the animat adapted to the switch and restored the desired behavior to stay within the inner circle under the new sensory mapping (orange bar). For the other 5 with unsuccessful learning, the animat kept moving outward and was repeatedly returned to the inner circle after reaching the outer circle. The training was unable to restore the desired behavior throughout 4 hours of experiment (only the first 3 hours are shown for clarity). Type I and Type II failures are indicated (see <xref ref-type="sec" rid="s3">Results</xref>).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g004" xlink:type="simple"/></fig><p>Ten simulations, out of 15, showed successful adaptation to the switch. One successful simulation is shown in <xref ref-type="fig" rid="pcbi-1000042-g003">Figure 3A</xref>, and the corresponding movie is shown in Supplemental Material <xref ref-type="supplementary-material" rid="pcbi.1000042.s003">Movie S1</xref>. Immediately after the switch, as expected, the animat moved outward in the quadrants where the sensory mapping switch was performed (Q1 and Q3). Patterned training stimulation (PTS), paired stimulation designed to induce STDP throughout any shared activation pathways in the network, began to shape the network synaptic weights, and the desired behavior was restored under the switched mapping. An unsuccessful simulation is shown in <xref ref-type="fig" rid="pcbi-1000042-g003">Figure 3B</xref>. In 5 unsuccessful simulations, the animat kept moving outward and was repeatedly put back into the inner circle whenever it reached the outer circle. The training was unable to restore the desired behavior throughout a 4-hr simulation. In <xref ref-type="fig" rid="pcbi-1000042-g003">Figure 3B</xref>, only the first 90 minutes are shown for clarity.</p><p>Distance plots for all 15 simulations are shown in <xref ref-type="fig" rid="pcbi-1000042-g004">Figure 4</xref>. For successful simulations, the average time for the adaptation was 88.6±12.2 minutes (mean±SEM, n = 10 successful-learning simulations). Two different types of unsuccessful learning are also indicated (Type I and Type II failures, see below).</p></sec><sec id="s3c"><title>Experiment 3: Avoid Unsuccessful Learning by Selecting Stimuli to Encode Sensory Inputs</title><p>One-third of the simulations showed unsuccessful learning but were nevertheless informative (see <xref ref-type="fig" rid="pcbi-1000042-g004">Figure 4</xref>). Two types of failures were observed in these following 5 unsuccessful experiments.</p><sec id="s3c1"><title>Type I failure</title><p>The animat showed no sign of improving behavior in the quadrant(s) where the switch of the sensory mapping was performed (Q1 and/or Q3) (see Trajectory in <xref ref-type="fig" rid="pcbi-1000042-g005">Figure 5A</xref>). In those cases, CPS<sub>Q1</sub> and/or CPS<sub>Q3</sub> evoked activity in neurons localized mainly at one quadrant of the network. We hypothesized that this localization reduced or eliminated the ability of the responses to shift the direction of the CA, and thus movement could not be shifted toward a different direction. Compared to more spatially homogeneous or symmetric responses, a localized response results in a larger magnitude in CA (see Equation 1 in <xref ref-type="sec" rid="s2">Methods</xref>). Therefore, we used <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> to quantify the level of localization in responses to CPS<sub>Q1</sub> and CPS<sub>Q3</sub> (see <xref ref-type="sec" rid="s2">Methods</xref>). This measure indicates the likelihood that the directions of CAs to CPS<sub>Q1</sub> and CPS<sub>Q3</sub> can be “reversed”.</p><fig id="pcbi-1000042-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g005</object-id><label>Figure 5</label><caption><title>Hypotheses about the reasons for unsuccessful learning.</title><p>One-third of the experiments showed unsuccessful learning. Two types of learning failures were found, and examples are shown. (A) Type I failure: the animat showed no sign of improving behavior in the quadrant(s) where the switch of the sensory mapping was performed (Q1 and/or Q3). Using the trajectory in Q1 as an example, the animat kept going outward without turning (indicated as a hollow red arrow). In those cases, CPS<sub>Q1</sub> and/or CPS<sub>Q3</sub> evoked activity in neurons localized mainly at one quadrant of the network. The localization of neurons activated by CPS<sub>Q1</sub> is illustrated in the cartoon. We hypothesize that this localization reduced or eliminated the ability of the responses to shift the CA from the original direction (shown as a solid red arrow) toward the desired direction (shown as a black arrow). (B) Type II failure: the animat showed signs of improving by changing movement direction(s) in the quadrant(s) where the switch was performed (Q1 and/or Q3). However, the original desired movement direction(s) in the un-switched quadrant(s) (Q2 and/or Q4) was/were changed into undesired ones(s). Using the trajectory in Q3 and Q4 as an example, the animat was able to turn in Q3 (shown as a hollow black arrow) but the desired direction in Q4 was later altered (shown as a hollow red arrow). In those cases, neurons activated by different CPSs had large degrees of overlap. The neurons activated both by CPS<sub>Q3</sub>, CPS<sub>Q4</sub>, and both are illustrated in the cartoon. We hypothesize that the training stimuli in Q3 caused correlated changes in the overlapped neurons (shown as red dots), which caused undesired change in responses to CPS<sub>Q4</sub>. (C) The degree of overlap (quantified by <italic>Max overlap</italic>, see <xref ref-type="sec" rid="s2">Methods</xref>) is plotted versus the degree of localization (quantified by <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic>), which shows that smaller overlap, smaller CA<sub>Q1</sub> and smaller CA<sub>Q3</sub> were found in all 10 successful cases. Also, Type I failure showed large <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> and Type II failure showed large <italic>Max overlap</italic>.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g005" xlink:type="simple"/></fig></sec><sec id="s3c2"><title>Type II failure</title><p>The animat showed signs of improving by changing moving direction(s) in the quadrant(s) where the switch was performed (Q1 and/or Q3). However, the movement direction in an un-switched quadrant (Q2 and/or Q4) became undesired (<xref ref-type="fig" rid="pcbi-1000042-g005">Figure 5B</xref>). In those cases, neurons activated by different CPSs had large degrees of overlap. We hypothesized that the training stimuli caused correlated changes in multiple CPSs. We used <italic>Max overlap</italic> to quantify the degrees of overlap between the responses of different pairs of CPSs (see <xref ref-type="sec" rid="s2">Methods</xref>).</p><p><italic>Max overlap</italic> is plotted versus <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> in <xref ref-type="fig" rid="pcbi-1000042-g005">Figure 5C</xref>, which shows that smaller overlap, smaller CA<sub>Q1</sub> and smaller CA<sub>Q3</sub> were found in all 10 successful-learning experiments. Also, as hypothesized, Type I failure showed large <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> and Type II failure showed large <italic>Max overlap</italic>.</p><p>In order to further verify the hypotheses, we randomly generated additional 85 sets of CPSs for the 3 networks (a total of 100 sets including the 15 sets in the original simulation in Experiment 2), and randomly chose 10 sets with small overlap, small CA<sub>Q1</sub> and small CA<sub>Q3</sub> to repeat Experiment 2. The <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> and <italic>Max overlap</italic> of these 85 sets and the 15 sets used previously are shown in <xref ref-type="fig" rid="pcbi-1000042-g006">Figure 6A</xref>. A cluster with small <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> (&lt;150) and small <italic>Max overlap</italic> (&lt;50%) was observed (the shaded area in <xref ref-type="fig" rid="pcbi-1000042-g006">Figure 6A</xref>). Therefore, we hypothesized that Type I and Type II learning failures could be avoided by selecting CPSs within this cluster:</p><list list-type="order"><list-item><p>Type I failure can be prevented by choosing CPS<sub>Q1</sub> and CPS<sub>Q3</sub> that each evoke responses which are not too localized, (criterion: <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)&lt;150</italic>).</p></list-item><list-item><p>Type II failure can be prevented by choosing CPSs that evoke responses without too much overlap, (criterion: <italic>Max overlap&lt;50%</italic>).</p></list-item></list><fig id="pcbi-1000042-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g006</object-id><label>Figure 6</label><caption><title>Improved learning by selecting CPSs based on the hypotheses.</title><p>Successful adaptations can be achieved by selecting CPSs with small <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> and small <italic>Max overlap</italic>. (A) <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> and <italic>Max overlap</italic> from 100 randomly-selected sets of CPSs in the three simulated networks. The 15 sets of CPSs used in the previous simulations are indicated as dots and crosses with black outlines. Among the 100 sets, 64 sets satisfied the criteria of <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)&lt;150</italic> and <italic>Max overlap&lt;50%</italic> (red dots). (B) Successful learning was achieved by using 10 randomly-selected sets of CPSs that satisfied the criteria (the selections are indicated as black dots in [A]). The success rate was improved from 66.7% (10/15, see <xref ref-type="fig" rid="pcbi-1000042-g004">Figure 4</xref>) to 100% (10/10). The same representations are used as in <xref ref-type="fig" rid="pcbi-1000042-g004">Figure 4</xref>.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g006" xlink:type="simple"/></fig><p>Sixty-four out of the 100 sets of CPSs satisfied the criteria of <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)&lt;150</italic> and <italic>Max overlap&lt;50%</italic>. By using 10 randomly-selected sets of CPSs that satisfied the criteria to run 10 additional simulations, we found that successful learning could be reliably achieved (<xref ref-type="fig" rid="pcbi-1000042-g006">Figure 6B</xref>). The success rate was improved from 66.7% (from the 15 original simulations, see <xref ref-type="fig" rid="pcbi-1000042-g004">Figure 4</xref>) to 100% (from the 10 new simulations, <xref ref-type="fig" rid="pcbi-1000042-g006">Figure 6B</xref>). The chance that randomly selecting 10 CPSs that all satisfy the criteria from the 100 randomly generated sets is less than 0.01 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000042.e014" xlink:type="simple"/></inline-formula>. This supports the hypotheses and indicates that a higher success rate of adaptations can be achieved by selecting CPSs with smaller <italic>Max(CA<sub>Q1</sub>, CA<sub>Q3</sub>)</italic> and smaller <italic>Max overlap</italic>. The average time for the adaptation in these additional simulations was 71.8±10.7 minutes (n =  10 successful-learning simulations), which was comparable to 88.6±12.2 minutes in the 10 successful-learning simulations shown previously (p = 0.43, Wilcoxon rank sum test). Furthermore, 64 out of 100 random selections of CPSs (64%) satisfied the criteria (see <xref ref-type="fig" rid="pcbi-1000042-g006">Figure 6A</xref>), which was comparable to the success rate (66.7%) from the previous 15 simulations with CPSs selected randomly without the criteria.</p></sec></sec><sec id="s3d"><title>Experiment 4: Network Plasticity Was Essential for Successful Adaptations in the System</title><p>In order to verify that the successful adaptation in the overall system was contributed by learning in the network, and not solely by the adaptive process in the artificial training algorithm, we repeated the original successful-learning simulations with the STDP algorithm turned off. We found that the desired behavior could not be restored without the STDP algorithm, or long-term plasticity, in the network. This also rules out frequency-dependent synaptic depression as the adaptation mechanism, since that algorithm was left turned on. The comparison of the animat's movement in one successful-learning simulation and its corresponding simulation without STDP is shown in <xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7</xref>, and the comparison of learning curves is shown in <xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7B</xref>.</p><fig id="pcbi-1000042-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g007</object-id><label>Figure 7</label><caption><title>Network plasticity was essential for successful learning in the system.</title><p>The successful adaptation in the overall system was contributed by learning in the network, and was not solely a product of the adaptive process in the artificial training algorithm. (A) The distances between the animat and the origin in a successful-learning simulation (with STDP, gray curve with gray shading for clarity) and the corresponding simulation without STDP (blue curve). The desired behavior could not be restored without the STDP algorithm. (B) The comparison of learning curves, defined as the change in probability of successful behavior over time, for simulations in (A). (C) Among 10 original successful-learning simulations, the average probability of successful behavior before the switch was 63.3±3.5%, dropped significantly to 9.8±1.1% after the switch (*p&lt;5e-4, Wilcoxon signed-rank test), and increased significantly back to 53.6±3.5% when the desired behavior was restored (*, p&lt;5e-4). These periods are shown in (B) (<italic>Pre</italic>: the 10 minutes before the switch; <italic>Switch</italic>: the 10 minutes immediately after the switch; and <italic>Post</italic>: the last 10 minutes). The probabilities of successful behavior in <italic>Pre</italic> and <italic>Post</italic> were comparable (p = 0.09). For all corresponding simulations without the STDP algorithm, the probability of successful behavior before the switch was 68.4±4.6% (n = 10 simulations without STDP), dropped significantly to 6.2±0.8% after the switch (*p&lt;5e-4), but showed non-significant increase by the last 10 minutes of the simulation (6.4±0.9%; p = 0.91). This indicates that network long-term plasticity was essential for successful learning in the closed-loop system.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g007" xlink:type="simple"/></fig><p>Among all original successful-learning simulations, the average probability of successful behavior before the switch was 63.3±3.5% (n = 10 successful-learning simulations), dropped significantly to 9.8±1.1% after the switch (p&lt;5e-4, Wilcoxon signed-rank test), and increased significantly back to 53.6±3.5% after 88.6±12.2 minutes when the desired behavior was restored (p&lt;5e-4) (<xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7C</xref>). The probability of successful behavior after the switch was comparable to that before the switch (p = 0.09). For all corresponding simulation without STDP algorithm, the probability of successful behavior before the switch was 68.4±4.6% (n = 10 simulations without STDP), dropped significantly to 6.2±0.8% after the switch (p&lt;5e-4), but showed no significant increase at the end of the simulation (6.4±0.9%) (p = 0.91) (<xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7C</xref>). This indicated that network long-term plasticity was essential for successful learning in the closed-loop system.</p></sec><sec id="s3e"><title>Experiment 5: Successful Learning Required Different PTSs at Different Times</title><p>Different PTSs were delivered at different times before the desired behavior was restored. The training history from the same successful-learning example shown in <xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7</xref> is shown in <xref ref-type="fig" rid="pcbi-1000042-g008">Figure 8A</xref>. We hypothesized that the same PTS might have different effects at different points in time because the network would be in different states. Therefore, successful adaptations would require application of PTSs in a certain sequence. In order to test this hypothesis, we ran 10 additional simulations with only one PTS pattern available for training in each quadrant, instead of a pool of 660 PTSs as in the original stimulations (see <xref ref-type="sec" rid="s2">Methods</xref>). These were the four most often used PTSs in the original simulations, one for each quadrant. For the example shown in <xref ref-type="fig" rid="pcbi-1000042-g008">Figure 8A</xref>, only PTS #575 was delivered in the new simulation when training was required due to unsuccessful movement in Q1.</p><fig id="pcbi-1000042-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g008</object-id><label>Figure 8</label><caption><title>Successful adaptation required not only one PTS but a certain sequence of PTSs.</title><p>(A) The training history of a successful-learning simulation (the distance measure is shown on the top panel). PTSs delivered from four different pools (PTS<sub>Q1</sub>–PTS<sub>Q4</sub>) are shown as black crosses, and the occurrences of RBS are shown as green crosses. From the 660 possible PTSs, the index of PTSs delivered most frequent in Q1, Q2, Q3, and Q4 were 575, 605, 423, and 584, respectively. The electrode locations and PTS<sub>t</sub> of these four most frequent PTS patterns are shown on the right. For each pool, the location of the first electrode (PTS-E1, also the probe electrode, see <xref ref-type="sec" rid="s2">Methods</xref> and <xref ref-type="fig" rid="pcbi-1000042-g001">Figure 1</xref>) is shown as a black X in the grids of 60 electrodes, and the second electrode (PTS-E2<sub>k</sub>) is shown as a blue dot. PTS<sub>t</sub> between the PTS-E1 (black arrow) and PTS-E2<sub>k</sub> (blue arrow) is also indicated for these four PTSs. (B) The learning curves of the successful-learning simulation shown in (A) (gray curve) and the corresponding simulation with only the most frequent PTSs available for training (blue curve, see <xref ref-type="sec" rid="s2">Methods</xref>). In this example, the PTS patterns used for training in Q1, Q2, Q3, and Q4 were PTSs #575, 605, 423, and 584, respectively (see [A]). (C) The average probabilities of successful behavior during <italic>Switch</italic> and <italic>Pre</italic> periods (shown in [B]) in 10 original successful-learning simulations and 10 corresponding new simulations with only single PTS pattern available for training in each quadrant. For the original simulations, the average probability of successful behavior increased significantly back after the desired behavior was restored (*p&lt;5e-4), while the average probability remained low for the simulations with single-PTS training (p = 0.61).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g008" xlink:type="simple"/></fig><p>We compared the original simulation and the corresponding new simulation by their learning curves (one example is shown in <xref ref-type="fig" rid="pcbi-1000042-g008">Figure 8B</xref>). The probability of successful behavior generally kept increasing after the switch for the original successful-learning simulation where multiple PTS patterns were available for training (gray curve), but not for the new simulation where only a single PTS pattern was available (blue curve).</p><p>A significant increase of the probability of successful behavior after the sensory mapping switch was found in the original successful-learning simulations (p&lt;5e-4) (<xref ref-type="fig" rid="pcbi-1000042-g008">Figure 8D</xref>, and also <xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7C</xref>). However, all 10 new simulations with only the four most frequent PTSs available showed no significant increase of the probability of successful behavior from immediately after the switch (9.2±1.0%) to the end of the simulation (10.1±3.7%) (p = 0.61, Wilcoxon signed-rank test) (<xref ref-type="fig" rid="pcbi-1000042-g008">Figure 8D</xref>). This shows that not only one PTS, but a <italic>sequence</italic> of different PTSs was needed in order to restore the desired behavior.</p></sec><sec id="s3f"><title>Experiment 6: Training Contingent on Behavior Was Required for Successful Learning</title><p>We have demonstrated that successful adaptations to altered sensory mappings required a sequence of different PTSs, which was determined by the real-time feedback contingent on the animat's performance. In order to investigate the importance of behavior-contingent training for successful learning, we recorded the whole stimulation sequence (PTS and RBS) for each successfully adapted case and replayed it into the same network with the same initial state and same sensory-motor mapping. Different random seeds for fluctuations in neurons' membrane potentials and synaptic currents were used between the successful-learning simulations and the replayed training simulations. This difference would lead to different network responses, and thus different movement trajectories and different CPS sequences. However, the effect of non-training stimuli (CPSs and RBS) on shaping the network was insignificant, as shown in <xref ref-type="fig" rid="pcbi-1000042-g002">Figure 2</xref>. Therefore, whether the network could adapt to the new sensory mapping solely depended on the effect of training stimulation. The replayed training stimulation was no longer contingent on whether or not desired movement occurred.</p><p>In 10 stimulation-replay experiments, the animat was unable to show successful adaptation to the sensory mapping switch (shown as “non-contingent” in the example of <xref ref-type="fig" rid="pcbi-1000042-g009">Figure 9A</xref>), which had been successful with behavior-contingent training (shown as “contingent”).</p><fig id="pcbi-1000042-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g009</object-id><label>Figure 9</label><caption><title>Behavior-contingent training was necessary for successful learning.</title><p>A comparison between experiments with behavior-contingent training and with replayed training stimulation (non-contingent). (A) With real-time behavior-contingent training, the animat in this example was able to adapt to a sensory mapping switch and reach the desired behavior: moving in desired directions in each quadrant and staying within the inner circle (gray curve with gray shading for clarity). The adaptation was absent in the non-contingent experiment (blue curve). (B) The comparison of the learning curves corresponding for the example in (A). (C) The average probabilities of successful behavior in the 10 successful-learning experiments and the corresponding non-contingent experiments. With behavior-contingent training, the average probability of successful behavior in the last 10 minutes of the simulations (<italic>Post</italic> period shown in [B]) was significantly greater than that measured within 10 minutes after the switch (<italic>Switch</italic>) (*p&lt;5e-4). In non-contingent experiments, the average probability of successful behavior in <italic>Post</italic> was comparable to that in <italic>Switch</italic> (p = 0.47). (D) The changes in all synaptic weights were visualized by Principal Components Analysis (PCA). The first three components (PC1 to PC3) of the network synaptic weights in the same example as (A) and (B) are plotted over time. Starting from the same initial synaptic weights, the network diverged to different synaptic weight distributions as the training became progressively less contingent on the network activity and the animat's performance. The circled periods, <italic>Pre</italic> and <italic>Post</italic>, are indicated at the bottom of (A).</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g009" xlink:type="simple"/></fig><p>A comparison of the learning curves for this example is shown in <xref ref-type="fig" rid="pcbi-1000042-g009">Figure 9B</xref>. With contingent training, a significant increase of the probability of successful behavior after the sensory mapping switch was found (p&lt;5e-4) (<xref ref-type="fig" rid="pcbi-1000042-g009">Figure 9C</xref>, and also <xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7C</xref>). However, with replayed training stimulation, the average probability of successful behavior in the last 10 minutes of the simulations was 11.6±2.2%, which is comparable to 9.2±1.8% measured within 10 minutes after the switch (p = 0.47) (<xref ref-type="fig" rid="pcbi-1000042-g009">Figure 9C</xref>).</p><p>In order to understand how successful (closed-loop) and replayed (open-loop) training stimulation shaped the network differently, we visualized the changes in weights of all synapses by using Principal Components Analysis (PCA). The first three components (PC1 to PC3) of the network synaptic weights for the contingent training simulation and the non-contingent training simulation example shown in <xref ref-type="fig" rid="pcbi-1000042-g009">Figure 9A</xref> are plotted over time (<xref ref-type="fig" rid="pcbi-1000042-g009">Figure 9D</xref>). Starting from the same initial synaptic weights, the network diverged to different synaptic weights distributions as the training became progressively less contingent on the network activity and the animat's performance.</p></sec><sec id="s3g"><title>Experiment 7: The “Solution” for Successful Goal-Directed Behavior Is Not Unique</title><p>We have demonstrated that two different sets of network synaptic weights that were responsible for the desired behavior under two different sensory mappings (<italic>Pre</italic> and <italic>Post-contingent</italic> in <xref ref-type="fig" rid="pcbi-1000042-g009">Figure 9D</xref>). We then further investigated whether under a specific sensory mapping, the desired behavior could only be exhibited by a specific set of network synaptic weights. After the network adapted to the switched sensory mapping, we switched the sensory mapping back to the original sensory mapping to see whether the network could re-adapt to the original mapping (<xref ref-type="fig" rid="pcbi-1000042-g010">Figure 10</xref>). After the switch-back, the behavior-contingent patterned training stimulation was able to restore the desired behavior under the original sensory mapping (<xref ref-type="fig" rid="pcbi-1000042-g010">Figure 10A</xref>), but with a different set of network synaptic weights (<xref ref-type="fig" rid="pcbi-1000042-g010">Figure 10B</xref>). This indicates that multiple synaptic configurations, or “solutions”, existed for the desired behavior.</p><fig id="pcbi-1000042-g010" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000042.g010</object-id><label>Figure 10</label><caption><title>The “solution” for successful goal-directed behavior is not unique.</title><p>The network re-adapted to reapplication of the original sensory mapping via a different state of network synaptic weights. (A) After the network adapted to a switch of the sensory mapping (<italic>Post1</italic> period), the sensory mapping was switched back to see whether the network could re-adapt to the original sensory mapping. One example is shown. The animat was able to restore the desired behavior (<italic>Post2</italic>) after the switch-back. (B) After adaptation to the switch-back, the animat showed the same desired behavior under the same sensory mapping, but with a different set of network synaptic weights. Multiple solutions existed for the desired behavior.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.g010" xlink:type="simple"/></fig></sec></sec><sec id="s4"><title>Discussion</title><p>We demonstrated that an embodied simulated network could be shaped by patterned training stimulation into desirable states capable of expressing meaningful behavior. We applied a switching of the sensory mapping and measured the network's ability to rewire itself in order to restore the desired behavior under a new mapping. Previous studies have shown that functional visual projections routed into non-visual structures can change the modality of the cortex <xref ref-type="bibr" rid="pcbi.1000042-Sur1">[29]</xref>,<xref ref-type="bibr" rid="pcbi.1000042-Sharma1">[30]</xref>. This rewiring process was also found to restore function in the olfactory bulb following injury or neurological disease <xref ref-type="bibr" rid="pcbi.1000042-Costanzo1">[31]</xref>. Successful rewiring observed in the random network suggests that cultured networks could be a useful model to investigate functional reorganization in cortical circuits after deafferentation or changes in sensory contingencies.</p><p>We exploited structured stimuli and detailed activity metrics <xref ref-type="bibr" rid="pcbi.1000042-Chao1">[16]</xref> incorporating spatial information to show that with training contingent on the animat's behavior, the network was capable of learning associations between multiple sensory inputs and motor outputs (Experiment 2). We further showed that successful learning required proper selection of stimuli to encode sensory inputs (Experiment 3), and a variety of training stimuli (Experiment 5) with adaptive selection contingent on the animat's behavior (Experiment 6). We also found that the solution for a desired behavior was not unique (Experiment 7) and could be achieved through different paths of training. These results shed light on the complexity and flexibility of the learning process in neural networks.</p><sec id="s4a"><title>Effects of RBS in Simulated and Living Cortical Networks</title><p>RBS was hypothesized to negate “attractors” in network synaptic weight distributions caused by spontaneous activity (mainly network-wide synchronized bursts of activity called barrages), and to prevent network synaptic weights from drifting to such attractors after inducing plasticity with electrical stimulation <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>. RBS with an aggregate frequency of 1 Hz reduced the occurrence of spontaneous barrages by at least 10 times in the simulated network and dissociated cortical cultures <xref ref-type="bibr" rid="pcbi.1000042-Chao2">[19]</xref>. By reducing the occurrence of spontaneous barrages, the network synaptic weights were mainly affected by activity evoked by RBS. Since RBS was random spatially and temporally, the evoked activity had an unbiased randomizing effect on changing network synaptic weights. In a different approach, a barrage-control stimulation protocol consisting of a group of electrodes cyclically stimulated with an aggregated frequency of 50 Hz was found to completely eliminate spontaneous barrages <xref ref-type="bibr" rid="pcbi.1000042-Wagenaar2">[32]</xref>. Similar to RBS, the barrage-control stimulation stabilized tetanus-induced plasticity in dissociated cortical cultures (Madhavan R, Chao ZC, Potter SM, unpublished data). However, different mechanisms might be involved. RBS evoked network-wide responses with unbiased spatiotemporal structure, while the barrage-control stimulation desynchronized spontaneous activity into spatially localized and temporally dispersed responses.</p><p>In this study, the aggregate stimulation frequency of RBS was increased from 1 to 3 Hz so that the amount of stimulation in RBS and PTS were comparable. RBS did stabilize network synaptic weights (the network synaptic weights were clustered in <italic>Pre</italic> period in <xref ref-type="fig" rid="pcbi-1000042-g009">Figure 9D</xref>) and also stabilized the network input-output function (see <xref ref-type="fig" rid="pcbi-1000042-g002">Figure 2</xref>).</p></sec><sec id="s4b"><title>Selection of Stimuli for Sensory Encoding</title><p>Even though sharing the same network connectivity and the same PTS pools, some simulations showed successful learning and others were unsuccessful. Therefore, we concluded that the selection of CPSs for sensory encoding, which was the only remaining difference, was crucial for determining the success of adaptation. We found that the stimulations used to encode sensory inputs should evoke neither overly localized nor largely overlapped responses. Too much localization reduced the possibility to improve movement directions in switched quadrants, and too much overlap caused unwanted changes in un-switched quadrants. These results suggest a certain level of independence is required between responses to stimulations used to encode different sensory inputs, which could be achieved by using smaller and distinct recording areas to determine movement, or by offsetting the CA through the motor mapping transformation so that the probability of a CA to point in different directions is more uniform. Furthermore, correlated changes in responses to different sensory inputs could also be avoided by using training stimulation that only causes localized plastic changes. These findings could instruct the designs of implant electrode geometries and feedback stimulation patterns in prosthetics to achieve a more efficient and effective adaptation.</p></sec><sec id="s4c"><title>Long-Term Plasticity and Successful Adaptation</title><p>We showed that long-term plasticity in the network (STDP) was essential for the adaptation in the overall system (see <xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7</xref>). Short-term plasticity (frequency-dependent synaptic depression, see <xref ref-type="sec" rid="s2">Methods</xref> and Supplemental Material <xref ref-type="supplementary-material" rid="pcbi.1000042.s001">Text S1</xref>) alone was not able to achieve successful adaptation (<xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7</xref>). Furthermore, learning curves indicate that fewer training stimuli were required to maintain the desired behavior after the system had adapted (see <xref ref-type="fig" rid="pcbi-1000042-g007">Figure 7B</xref> and <xref ref-type="fig" rid="pcbi-1000042-g008">Figure 8B</xref>). These suggest that the improved performance was not due to short-term elastic responses to the stimulation. Elastic change was observed in dissociated cultures where the neurons' responsiveness adapted to very low frequency stimulation but relaxed back within minutes after stimulation was removed <xref ref-type="bibr" rid="pcbi.1000042-Eytan1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000042-Wagenaar3">[34]</xref>.</p></sec><sec id="s4d"><title>Different Training Schemes</title><p>Using paired pulses with different stimulation electrodes and different inter-pulse intervals was one possible design for training. More optimal training algorithms likely exist. Using stimulation sequences with more than two stimuli could help shape the network synaptic weights to a desired state, since they might evoke a greater variety of response patterns and produce different behaviors. However, the tradeoff is that a larger pool of possible training stimuli could lead to a longer training duration before successful adaptation. Furthermore, a different algorithm to adaptively update the probability of selecting PTSs might better find appropriate PTSs and remove unhelpful ones in the pool.</p><p>The simulated network was used to explore many different possible sensory-motor mappings and training algorithms (not described here) because of savings in preparation time and an ability to monitor all synaptic weights. The described algorithm successfully demonstrated adaptive goal-directed behavior with multiple sensory-motor mappings. This closed-loop algorithm is not restricted to a particular type or a particular number of sensory-motor mappings. Integrate-and-fire networks have been used previously for demonstrating goal-directed learning <xref ref-type="bibr" rid="pcbi.1000042-Koene1">[35]</xref>,<xref ref-type="bibr" rid="pcbi.1000042-DelGiudice1">[36]</xref>. In this work, we constructed a simulated network, specifically to mimic living MEA cultures, in order to find a closed-loop design that might be applicable to show goal-directed learning living cultures. In another study, we tested our closed-loop algorithm in a cortical network cultured over an MEA, where we successfully avoid Type I and Type II failure to train a living network to control the movement of an animat in a desired direction (Chao ZC, Bakkum DJ, Potter SM, unpublished data). Studying neural networks' basic computational properties, such as parallel signal processing and learning, by working with simulated/living <italic>in vitro</italic> networks could lead to direct development of more advanced artificial neural networks, more robust computing methods, and even the use of neurally controlled animats themselves as biologically-based control systems.</p></sec></sec><sec id="s5"><title>Supporting Information</title><supplementary-material id="pcbi.1000042.s001" mimetype="application/msword" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.s001" xlink:type="simple"><label>Text S1</label><caption><p>(5.41 MB DOC)</p></caption></supplementary-material><supplementary-material id="pcbi.1000042.s002" mimetype="application/msword" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.s002" xlink:type="simple"><label>Text S2</label><caption><p>(0.24 MB DOC)</p></caption></supplementary-material><supplementary-material id="pcbi.1000042.s003" mimetype="application/msword    .doc video/quicktime" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000042.s003" xlink:type="simple"><label>Movie S1</label><caption><p>Movie of a successful-learning simulation. The trajectory, the trajectory around the inner circle (zoom-in), and the animat's distance from the origin in a successful-learning simulation are shown. A switching of the sensory mappings in Q1 and Q3 was applied after 10 minutes into the simulation. The animat's position is indicated as a blue dot. The trajectory in the zoom-in panel is indicated in different colors for different quadrants after the switch. The animat moved outward in Q1 and Q3 immediately after the switch, and restored the desired behavior after t = 20 min.</p><p>(6.78 MB MOV)</p></caption></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="pcbi.1000042-Potter1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Potter</surname><given-names>SM</given-names></name><name name-style="western"><surname>Fraser</surname><given-names>SE</given-names></name><name name-style="western"><surname>Pine</surname><given-names>J</given-names></name></person-group>             <year>1997</year>             <article-title>Animat in a petri dish: Cultured neural networks for studying neural computation.</article-title>             <source>Proc 4th Joint Symposium on Neural Computation, UCSD</source>             <fpage>167</fpage>             <lpage>174</lpage>          </element-citation></ref><ref id="pcbi.1000042-DeMarse1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>DeMarse</surname><given-names>TB</given-names></name><name name-style="western"><surname>Wagenaar</surname><given-names>DA</given-names></name><name name-style="western"><surname>Blau</surname><given-names>AW</given-names></name><name name-style="western"><surname>Potter</surname><given-names>SM</given-names></name></person-group>             <year>2001</year>             <article-title>The neurally controlled animat: Biological brains acting with simulated bodies.</article-title>             <source>Auton Robots</source>             <volume>11</volume>             <fpage>305</fpage>             <lpage>310</lpage>          </element-citation></ref><ref id="pcbi.1000042-Potter2"><label>3</label><element-citation publication-type="book" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Potter</surname><given-names>SM</given-names></name><name name-style="western"><surname>Wagenaar</surname><given-names>DA</given-names></name><name name-style="western"><surname>DeMarse</surname><given-names>TB</given-names></name></person-group>             <year>2006</year>             <article-title>Closing the loop: Stimulation feedback Systems for embodied MEA cultures.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Taketani</surname><given-names>M</given-names></name><name name-style="western"><surname>Baudry</surname><given-names>M</given-names></name></person-group>             <source>Advances in network electrophysiology using multi-electrode arrays</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Springer</publisher-name>             <fpage>215</fpage>             <lpage>242</lpage>          </element-citation></ref><ref id="pcbi.1000042-Meyer1"><label>4</label><element-citation publication-type="book" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Meyer</surname><given-names>JA</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>SW</given-names></name></person-group>             <year>1991</year>             <source>From Animals to animats: Proceedings of the First International Conference on Simulation of Adaptive Behavior</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref><ref id="pcbi.1000042-Shefi1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shefi</surname><given-names>O</given-names></name><name name-style="western"><surname>Golding</surname><given-names>I</given-names></name><name name-style="western"><surname>Segev</surname><given-names>R</given-names></name><name name-style="western"><surname>Ben-Jacob</surname><given-names>E</given-names></name><name name-style="western"><surname>Ayali</surname><given-names>A</given-names></name></person-group>             <year>2002</year>             <article-title>Morphological characterization of in vitro neuronal networks.</article-title>             <source>Phys Rev E</source>             <volume>66</volume>             <fpage>021905</fpage>          </element-citation></ref><ref id="pcbi.1000042-Gross1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gross</surname><given-names>GW</given-names></name><name name-style="western"><surname>Kowalski</surname><given-names>JM</given-names></name></person-group>             <year>1999</year>             <article-title>Origins of activity patterns in self-organizing neuronal networks in vitro.</article-title>             <source>Journal of Intelligent Material Systems and Structures</source>             <volume>10</volume>             <fpage>558</fpage>             <lpage>564</lpage>          </element-citation></ref><ref id="pcbi.1000042-Rolston1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rolston</surname><given-names>JD</given-names></name><name name-style="western"><surname>Wagenaar</surname><given-names>DA</given-names></name><name name-style="western"><surname>Potter</surname><given-names>SM</given-names></name></person-group>             <year>2007</year>             <article-title>Precisely-timed spatiotemporal patterns of neural activity in dissociated cortical cultures.</article-title>             <source>Neuroscience</source>             <volume>148</volume>             <fpage>294</fpage>             <lpage>303</lpage>          </element-citation></ref><ref id="pcbi.1000042-Wagenaar1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wagenaar</surname><given-names>DA</given-names></name><name name-style="western"><surname>Nadasdy</surname><given-names>Z</given-names></name><name name-style="western"><surname>Potter</surname><given-names>SM</given-names></name></person-group>             <year>2006</year>             <article-title>Persistent dynamic attractors in activity patterns of cultured neuronal networks.</article-title>             <source>Phys Rev E</source>             <volume>73</volume>             <fpage>51907</fpage>          </element-citation></ref><ref id="pcbi.1000042-VanPelt1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Van Pelt</surname><given-names>J</given-names></name><name name-style="western"><surname>Vajda</surname><given-names>I</given-names></name><name name-style="western"><surname>Wolters</surname><given-names>PS</given-names></name><name name-style="western"><surname>Corner</surname><given-names>MA</given-names></name><name name-style="western"><surname>Ramakers</surname><given-names>GJ</given-names></name></person-group>             <year>2005</year>             <article-title>Dynamics and plasticity in developing neuronal networks in vitro.</article-title>             <source>Prog Brain Res</source>             <volume>147</volume>             <fpage>173</fpage>             <lpage>188</lpage>          </element-citation></ref><ref id="pcbi.1000042-Martinoia1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Martinoia</surname><given-names>S</given-names></name><name name-style="western"><surname>Sanguineti</surname><given-names>V</given-names></name><name name-style="western"><surname>Cozzi</surname><given-names>L</given-names></name><name name-style="western"><surname>Berdondini</surname><given-names>L</given-names></name><name name-style="western"><surname>van Pelt</surname><given-names>J</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Towards an embodied in vitro electrophysiology: the NeuroBIT project.</article-title>             <source>Neurocomputing</source>             <volume>58</volume>             <fpage>1065</fpage>             <lpage>1072</lpage>          </element-citation></ref><ref id="pcbi.1000042-Cozzi1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cozzi</surname><given-names>L</given-names></name><name name-style="western"><surname>D'Angelo</surname><given-names>P</given-names></name><name name-style="western"><surname>Chiappalone</surname><given-names>M</given-names></name><name name-style="western"><surname>Ide</surname><given-names>AN</given-names></name><name name-style="western"><surname>Novellino</surname><given-names>A</given-names></name><etal/></person-group>             <year>2005</year>             <article-title>Coding and decoding of information in a bi-directional neural interface.</article-title>             <source>Neurocomputing</source>             <volume>65</volume>             <fpage>783</fpage>             <lpage>792</lpage>          </element-citation></ref><ref id="pcbi.1000042-Bakkum1"><label>12</label><element-citation publication-type="book" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bakkum</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Shkolnik</surname><given-names>AC</given-names></name><name name-style="western"><surname>Ben-Ary</surname><given-names>G</given-names></name><name name-style="western"><surname>Gamblen</surname><given-names>P</given-names></name><name name-style="western"><surname>Demarse</surname><given-names>TB</given-names></name><etal/></person-group>             <year>2004</year>             <article-title>Removing some ‘A’ from AI: embodied cultured networks.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Iida</surname><given-names>F</given-names></name><name name-style="western"><surname>Steels</surname><given-names>L</given-names></name><name name-style="western"><surname>Pfeifer</surname><given-names>R</given-names></name></person-group>             <source>Embodied artificial intelligence</source>             <publisher-name>Springer-Verlag</publisher-name>             <fpage>130</fpage>             <lpage>145</lpage>          </element-citation></ref><ref id="pcbi.1000042-Reger1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Reger</surname><given-names>BD</given-names></name><name name-style="western"><surname>Fleming</surname><given-names>KM</given-names></name><name name-style="western"><surname>Sanguineti</surname><given-names>V</given-names></name><name name-style="western"><surname>Alford</surname><given-names>S</given-names></name><name name-style="western"><surname>Mussa-Ivaldi</surname><given-names>FA</given-names></name></person-group>             <year>2000</year>             <article-title>Connecting brains to robots: The development of a hybrid system for the study of learning in neural tissues.</article-title>             <source>Artif Life</source>             <volume>6</volume>             <fpage>307</fpage>             <lpage>324</lpage>          </element-citation></ref><ref id="pcbi.1000042-Karniel1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Karniel</surname><given-names>A</given-names></name><name name-style="western"><surname>Kositsky</surname><given-names>M</given-names></name><name name-style="western"><surname>Fleming</surname><given-names>KM</given-names></name><name name-style="western"><surname>Chiappalone</surname><given-names>M</given-names></name><name name-style="western"><surname>Sanguineti</surname><given-names>V</given-names></name><etal/></person-group>             <year>2005</year>             <article-title>Computational analysis in vitro: Dynamics and plasticity of a neuro-robotic system.</article-title>             <source>J Neural Eng</source>             <volume>2</volume>             <fpage>S250</fpage>             <lpage>S265</lpage>          </element-citation></ref><ref id="pcbi.1000042-Jimbo1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jimbo</surname><given-names>Y</given-names></name><name name-style="western"><surname>Tateno</surname><given-names>T</given-names></name><name name-style="western"><surname>Robinson</surname><given-names>HPC</given-names></name></person-group>             <year>1999</year>             <article-title>Simultaneous induction of pathway-specific potentiation and depression in networks of cortical neurons.</article-title>             <source>Biophys J</source>             <volume>76</volume>             <fpage>670</fpage>             <lpage>678</lpage>          </element-citation></ref><ref id="pcbi.1000042-Chao1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chao</surname><given-names>ZC</given-names></name><name name-style="western"><surname>Bakkum</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Potter</surname><given-names>SM</given-names></name></person-group>             <year>2007</year>             <article-title>Region-specific network plasticity in simulated and living cortical networks: Comparison of the center of activity trajectory (CAT) with other statistics.</article-title>             <source>J Neural Eng</source>             <volume>4</volume>             <fpage>1</fpage>             <lpage>15</lpage>          </element-citation></ref><ref id="pcbi.1000042-Ruaro1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ruaro</surname><given-names>ME</given-names></name><name name-style="western"><surname>Bonifazi</surname><given-names>P</given-names></name><name name-style="western"><surname>Torre</surname><given-names>V</given-names></name></person-group>             <year>2005</year>             <article-title>Toward the neurocomputer: Image processing and pattern recognition with neuronal cultures.</article-title>             <source>IEEE Trans Biomed Eng</source>             <volume>52</volume>             <fpage>371</fpage>             <lpage>383</lpage>          </element-citation></ref><ref id="pcbi.1000042-Shahaf1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shahaf</surname><given-names>G</given-names></name><name name-style="western"><surname>Marom</surname><given-names>S</given-names></name></person-group>             <year>2001</year>             <article-title>Learning in networks of cortical neurons.</article-title>             <source>J Neurosci</source>             <volume>21</volume>             <fpage>8782</fpage>             <lpage>8788</lpage>          </element-citation></ref><ref id="pcbi.1000042-Chao2"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chao</surname><given-names>ZC</given-names></name><name name-style="western"><surname>Bakkum</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Wagenaar</surname><given-names>DA</given-names></name><name name-style="western"><surname>Potter</surname><given-names>SM</given-names></name></person-group>             <year>2005</year>             <article-title>Effects of random external background stimulation on network synaptic stability after tetanization—A modeling study.</article-title>             <source>Neuroinformatics</source>             <volume>3</volume>             <fpage>263</fpage>             <lpage>280</lpage>          </element-citation></ref><ref id="pcbi.1000042-Izhikevich1"><label>20</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Izhikevich</surname><given-names>EM</given-names></name><name name-style="western"><surname>Gally</surname><given-names>JA</given-names></name><name name-style="western"><surname>Edelman</surname><given-names>GM</given-names></name></person-group>             <year>2004</year>             <article-title>Spike-timing dynamics of neuronal groups.</article-title>             <source>Cereb Cortex</source>             <volume>14</volume>             <fpage>933</fpage>             <lpage>944</lpage>          </element-citation></ref><ref id="pcbi.1000042-Georgopoulos1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Georgopoulos</surname><given-names>A</given-names></name><name name-style="western"><surname>Schwartz</surname><given-names>A</given-names></name><name name-style="western"><surname>Kettner</surname><given-names>R</given-names></name></person-group>             <year>1986</year>             <article-title>Neuronal population coding of movement direction.</article-title>             <source>Science</source>             <volume>233</volume>             <fpage>1416</fpage>             <lpage>1419</lpage>          </element-citation></ref><ref id="pcbi.1000042-Natschlager1"><label>22</label><element-citation publication-type="book" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Natschlager</surname><given-names>T</given-names></name><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name><name name-style="western"><surname>Maass</surname><given-names>W</given-names></name></person-group>             <year>2003</year>             <article-title>Computer models and analysis tools for neural microcircuits.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Kotter</surname><given-names>R</given-names></name></person-group>             <source>Neuroscience databases: A practical guide</source>             <publisher-loc>Boston</publisher-loc>             <publisher-name>Kluwer Academic Publishers</publisher-name>             <fpage>123</fpage>             <lpage>138</lpage>          </element-citation></ref><ref id="pcbi.1000042-Markram1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name><name name-style="western"><surname>Gupta</surname><given-names>A</given-names></name><name name-style="western"><surname>Uziel</surname><given-names>A</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Y</given-names></name><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name></person-group>             <year>1998</year>             <article-title>Information processing with frequency-dependent synaptic connections.</article-title>             <source>Neurobiol Learn Mem</source>             <volume>70</volume>             <fpage>101</fpage>             <lpage>112</lpage>          </element-citation></ref><ref id="pcbi.1000042-Song1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Song</surname><given-names>S</given-names></name><name name-style="western"><surname>Miller</surname><given-names>KD</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name></person-group>             <year>2000</year>             <article-title>Competitive hebbian learning through spike-timing-dependent synaptic plasticity.</article-title>             <source>Nature Neurosci</source>             <volume>3</volume>             <fpage>919</fpage>             <lpage>926</lpage>          </element-citation></ref><ref id="pcbi.1000042-Darbon1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Darbon</surname><given-names>P</given-names></name><name name-style="western"><surname>Scicluna</surname><given-names>L</given-names></name><name name-style="western"><surname>Tscherter</surname><given-names>A</given-names></name><name name-style="western"><surname>Streit</surname><given-names>J</given-names></name></person-group>             <year>2002</year>             <article-title>Mechanisms controlling bursting activity induced by disinhibition in spinal cord networks.</article-title>             <source>Eur J Neurosci</source>             <volume>15</volume>             <fpage>671</fpage>             <lpage>683</lpage>          </element-citation></ref><ref id="pcbi.1000042-Bi1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bi</surname><given-names>G</given-names></name><name name-style="western"><surname>Poo</surname><given-names>M</given-names></name></person-group>             <year>1998</year>             <article-title>Synaptic modifications in cultured hippocampal neurons: Dependence on spike timing, synaptic strength, and postsynaptic cell type.</article-title>             <source>J Neurosci</source>             <volume>18</volume>             <fpage>10464</fpage>             <lpage>10472</lpage>          </element-citation></ref><ref id="pcbi.1000042-Li1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>W</given-names></name></person-group>             <year>1990</year>             <article-title>Mutual information functions versus correlation functions.</article-title>             <source>J Stat Phys</source>             <volume>60</volume>             <fpage>823</fpage>             <lpage>837</lpage>          </element-citation></ref><ref id="pcbi.1000042-Moddemeijer1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Moddemeijer</surname><given-names>R</given-names></name></person-group>             <year>1989</year>             <article-title>On estimation of entropy and mutual information of continuous distributions.</article-title>             <source>Signal Processing</source>             <volume>16</volume>             <fpage>233</fpage>             <lpage>246</lpage>          </element-citation></ref><ref id="pcbi.1000042-Sur1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sur</surname><given-names>M</given-names></name><name name-style="western"><surname>Garraghty</surname><given-names>P</given-names></name><name name-style="western"><surname>Roe</surname><given-names>A</given-names></name></person-group>             <year>1988</year>             <article-title>Experimentally induced visual projections into auditory thalamus and cortex.</article-title>             <source>Science</source>             <volume>242</volume>             <fpage>1437</fpage>             <lpage>1441</lpage>          </element-citation></ref><ref id="pcbi.1000042-Sharma1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sharma</surname><given-names>J</given-names></name><name name-style="western"><surname>Angelucci</surname><given-names>A</given-names></name><name name-style="western"><surname>Sur</surname><given-names>M</given-names></name></person-group>             <year>2000</year>             <article-title>Induction of visual orientation modules in auditory cortex.</article-title>             <source>Nature</source>             <volume>404</volume>             <fpage>841</fpage>             <lpage>847</lpage>          </element-citation></ref><ref id="pcbi.1000042-Costanzo1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Costanzo</surname><given-names>RM</given-names></name></person-group>             <year>2000</year>             <article-title>Rewiring the olfactory bulb: Changes in odor maps following recovery from nerve transection.</article-title>             <source>Chem Senses</source>             <volume>25</volume>             <fpage>199</fpage>             <lpage>205</lpage>          </element-citation></ref><ref id="pcbi.1000042-Wagenaar2"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wagenaar</surname><given-names>D</given-names></name><name name-style="western"><surname>Madhavan</surname><given-names>R</given-names></name><name name-style="western"><surname>Pine</surname><given-names>J</given-names></name><name name-style="western"><surname>Potter</surname><given-names>S</given-names></name></person-group>             <year>2005</year>             <article-title>Controlling bursting in cortical cultures with closed-loop multi-electrode stimulation.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>680</fpage>             <lpage>688</lpage>          </element-citation></ref><ref id="pcbi.1000042-Eytan1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Eytan</surname><given-names>D</given-names></name><name name-style="western"><surname>Brenner</surname><given-names>N</given-names></name><name name-style="western"><surname>Marom</surname><given-names>S</given-names></name></person-group>             <year>2003</year>             <article-title>Selective adaptation in networks of cortical neurons.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>9349</fpage>             <lpage>9356</lpage>          </element-citation></ref><ref id="pcbi.1000042-Wagenaar3"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wagenaar</surname><given-names>D</given-names></name><name name-style="western"><surname>Pine</surname><given-names>J</given-names></name><name name-style="western"><surname>Potter</surname><given-names>S</given-names></name></person-group>             <year>2006</year>             <article-title>Searching for plasticity in dissociated cortical cultures on multi-electrode arrays.</article-title>             <source>J Negat Results Biomed</source>             <volume>5</volume>             <fpage>16</fpage>          </element-citation></ref><ref id="pcbi.1000042-Koene1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koene</surname><given-names>RA</given-names></name><name name-style="western"><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group>             <year>2005</year>             <article-title>An integrate-and-fire model of prefrontal cortex neuronal activity during performance of goal-directed decision making.</article-title>             <source>Cereb Cortex</source>             <volume>15</volume>             <fpage>1964</fpage>             <lpage>1981</lpage>          </element-citation></ref><ref id="pcbi.1000042-DelGiudice1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Del Giudice</surname><given-names>P</given-names></name><name name-style="western"><surname>Fusi</surname><given-names>S</given-names></name><name name-style="western"><surname>Mattia</surname><given-names>M</given-names></name></person-group>             <year>2003</year>             <article-title>Modelling the formation of working memory with networks of integrate-and-fire neurons connected by plastic synapses.</article-title>             <source>J Physiol (Paris)</source>             <volume>97</volume>             <fpage>659</fpage>             <lpage>681</lpage>          </element-citation></ref></ref-list></back></article>
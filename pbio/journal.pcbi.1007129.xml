<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1007129</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-01686</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Mathematical functions</subject><subj-group><subject>Convolution</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Mathematical and statistical techniques</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Database and informatics methods</subject><subj-group><subject>Bioinformatics</subject><subj-group><subject>Sequence analysis</subject><subj-group><subject>Sequence motif analysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Machine learning</subject><subj-group><subject>Deep learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Enzymology</subject><subj-group><subject>Enzymes</subject><subj-group><subject>Protein kinases</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Proteins</subject><subj-group><subject>Enzymes</subject><subj-group><subject>Protein kinases</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Pharmacology</subject><subj-group><subject>Drug research and development</subject><subj-group><subject>Drug discovery</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Extraction techniques</subject><subj-group><subject>Protein extraction</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>DeepConv-DTI: Prediction of drug-target interactions via deep learning with convolution on protein sequences</article-title>
<alt-title alt-title-type="running-head">DeepConv-DTI: Prediction of drug-target interactions</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-8958-2945</contrib-id>
<name name-style="western">
<surname>Lee</surname>
<given-names>Ingoo</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Keum</surname>
<given-names>Jongsoo</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5109-9114</contrib-id>
<name name-style="western">
<surname>Nam</surname>
<given-names>Hojung</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Buk-ku, Gwangju, Republic of Korea</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Briggs</surname>
<given-names>James M.</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Houston, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>No authors have competing interests.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">hjnam@gist.ac.kr</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>14</day>
<month>6</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="collection">
<month>6</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>6</issue>
<elocation-id>e1007129</elocation-id>
<history>
<date date-type="received">
<day>1</day>
<month>10</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>24</day>
<month>5</month>
<year>2019</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Lee et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1007129"/>
<abstract>
<p>Identification of drug-target interactions (DTIs) plays a key role in drug discovery. The high cost and labor-intensive nature of <italic>in vitro</italic> and <italic>in vivo</italic> experiments have highlighted the importance of <italic>in silico</italic>-based DTI prediction approaches. In several computational models, conventional protein descriptors have been shown to not be sufficiently informative to predict accurate DTIs. Thus, in this study, we propose a deep learning based DTI prediction model capturing local residue patterns of proteins participating in DTIs. When we employ a convolutional neural network (CNN) on raw protein sequences, we perform convolution on various lengths of amino acids subsequences to capture local residue patterns of generalized protein classes. We train our model with large-scale DTI information and demonstrate the performance of the proposed model using an independent dataset that is not seen during the training phase. As a result, our model performs better than previous protein descriptor-based models. Also, our model performs better than the recently developed deep learning models for massive prediction of DTIs. By examining pooled convolution results, we confirmed that our model can detect binding sites of proteins for DTIs. In conclusion, our prediction model for detecting local residue patterns of target proteins successfully enriches the protein features of a raw protein sequence, yielding better prediction results than previous approaches. Our code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/GIST-CSBL/DeepConv-DTI" xlink:type="simple">https://github.com/GIST-CSBL/DeepConv-DTI</ext-link>.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Drugs work by interacting with target proteins to activate or inhibit a target’s biological process. Therefore, identification of DTIs is a crucial step in drug discovery. However, identifying drug candidates via biological assays is very time and cost consuming, which introduces the need for a computational prediction approach for the identification of DTIs. In this work, we constructed a novel DTI prediction model to extract local residue patterns of target protein sequences using a CNN-based deep learning approach. As a result, the detected local features of protein sequences perform better than other protein descriptors for DTI prediction and previous models for predicting PubChem independent test datasets. That is, our approach of capturing local residue patterns with CNN successfully enriches protein features from a raw sequence.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100003621</institution-id>
<institution>Ministry of Science, ICT and Future Planning</institution>
</institution-wrap>
</funding-source>
<award-id>NRF-2018M3A9A7053266.</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5109-9114</contrib-id>
<name name-style="western">
<surname>Nam</surname>
<given-names>Hojung</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution>Bio-Synergy Research Project</institution>
</funding-source>
<award-id>NRF-2017M3A9C4092978</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5109-9114</contrib-id>
<name name-style="western">
<surname>Nam</surname>
<given-names>Hojung</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (NRF-2018M3A9A7053266), the Bio-Synergy Research Project (NRF-2017M3A9C4092978) of the Ministry of Science and ICT through the National Research Foundation. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="0"/>
<page-count count="21"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-06-26</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All code we used in manuscript are available from GitHub repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/GIST-CSBL/DeepConv-DTI" xlink:type="simple">https://github.com/GIST-CSBL/DeepConv-DTI</ext-link>)</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The identification of drug-target interactions (DTIs) plays a key role in the early stage of drug discovery. Thus, drug developers screen for compounds that interact with specified targets with biological activities of interest. However, the identification of DTIs in large-scale chemical or biological experiments usually takes 2~3 years of experiments, with high associated costs [<xref ref-type="bibr" rid="pcbi.1007129.ref001">1</xref>]. Therefore, with the accumulation of drugs, targets, and interaction data, various computational methods have been developed for the prediction of possible DTIs to aid in drug discovery.</p>
<p>Among computational approaches, docking methods, which simulate the binding of a small molecule and a protein using 3D structure, were initially studied. Docking methods recruit various scoring functions and mode definitions to minimize free energy for binding. Docking methods have advanced by themselves, and recently, the Docking Approach using Ray-Casting (DARC) model identified 21 compounds by using an elaborate binding pocket topography mapping methodology, and the results were reproduced in a biochemical assay [<xref ref-type="bibr" rid="pcbi.1007129.ref002">2</xref>]. In addition, studies have examined several similarity-based methods in which it was assumed that drugs bind to proteins similar to known targets and vice versa. One of the early methods is that of <italic>Yamanashi et al</italic>., which utilized a kernel regression method to use the information on known drug interactions as the input to identify new DTIs, combining a chemical space and genomic spaces into a pharmacological space [<xref ref-type="bibr" rid="pcbi.1007129.ref003">3</xref>]. To overcome the requirement of the bipartite model for massive computational power, <italic>Beakley et al</italic>. developed the bipartite local model, which trains the interaction model locally but not globally. In addition to substantially reducing the computational complexity, this model exhibited higher performance than the previous model [<xref ref-type="bibr" rid="pcbi.1007129.ref004">4</xref>]. As another approach to DTI prediction models, matrix factorization methods have been recruited to predict DTIs, which approximate multiplying two latent matrices representing the compound and target protein to an interaction matrix and similarity score matrix [<xref ref-type="bibr" rid="pcbi.1007129.ref005">5</xref>, <xref ref-type="bibr" rid="pcbi.1007129.ref006">6</xref>]. In this work, regularized matrix factorization methods successfully learn the manifold lying under DTIs, giving the highest performance among previous DTI prediction methods. However, similarity-based methods are not commonly used at present to predict DTIs, as researchers have found that similarity-based methods work well for DTIs within specific protein classes but not for other classes [<xref ref-type="bibr" rid="pcbi.1007129.ref007">7</xref>]. In addition, some proteins do not show strong sequence similarity with proteins sharing an identical interacting compound [<xref ref-type="bibr" rid="pcbi.1007129.ref008">8</xref>].</p>
<p>Thus, feature-based models that predict DTI features of drugs and targets have been studied [<xref ref-type="bibr" rid="pcbi.1007129.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1007129.ref011">11</xref>]. For feature-based DTI prediction models, a fingerprint is the most commonly used descriptor of the substructure of a drug [<xref ref-type="bibr" rid="pcbi.1007129.ref012">12</xref>]. With a drug fingerprint, a drug is transformed into a binary vector whose index value represents the existence of the substructure of the drug. For proteins, composition, transition, and distribution (CTD) descriptors are conventionally used as computational representations [<xref ref-type="bibr" rid="pcbi.1007129.ref013">13</xref>]. Unfortunately, feature-based models that use protein descriptors and drug fingerprints showed worse performance than previous conventional quantitative structure-activity relationship (QSAR) models [<xref ref-type="bibr" rid="pcbi.1007129.ref009">9</xref>]. To improve the performance of feature-based models, many approaches have been developed, such as the use of interactome networks [<xref ref-type="bibr" rid="pcbi.1007129.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1007129.ref015">15</xref>] and minwise hashing [<xref ref-type="bibr" rid="pcbi.1007129.ref016">16</xref>]. Although various protein and chemical descriptors have been introduced, feature-based models do not show sufficiently good predictive performance [<xref ref-type="bibr" rid="pcbi.1007129.ref017">17</xref>]. For conventional machine learning models, features must be built to be readable by modeling from original raw forms, such as simplified molecular-input line entry system (SMILES) and amino acid sequences. During transformation, rich information, such as local residue patterns or relationships, is lost. In addition, it is hard to recover lost information using traditional machine learning models.</p>
<p>In recent years, many deep learning approaches have recently been developed and recruited for omics data processing [<xref ref-type="bibr" rid="pcbi.1007129.ref018">18</xref>] as well as drug discovery [<xref ref-type="bibr" rid="pcbi.1007129.ref019">19</xref>], and these approaches seem to be able to overcome limitations. For example, DeepDTI built by <italic>Wen et al</italic>. used the deep belief network (DBN) [<xref ref-type="bibr" rid="pcbi.1007129.ref020">20</xref>], with features such as the composition of amino acids, dipeptides, and tripeptides for proteins and extended-connectivity fingerprint (ECFP) [<xref ref-type="bibr" rid="pcbi.1007129.ref021">21</xref>] for drugs [<xref ref-type="bibr" rid="pcbi.1007129.ref007">7</xref>]. The authors also discussed how deep-learning-based latent representations, which are nonlinear combinations of original features, can overcome the limitations of traditional descriptors by showing the performance in each layer. In another study by <italic>Peng et al</italic>. [<xref ref-type="bibr" rid="pcbi.1007129.ref022">22</xref>], MFDR employed sparse Auto-Encoder (SAE) to abstract original features into a latent representation with a small dimension. With latent representation, they trained a support vector machine (SVM), which performed better than previous methods, including feature- and similarity-based methods. In another study called DL-CPI by <italic>Tian et al</italic>. [<xref ref-type="bibr" rid="pcbi.1007129.ref023">23</xref>], domain binary vectors were employed to represent the existence of domains used to describe proteins.</p>
<p>One way to reduce the loss of feature information is to process raw sequences and SMILES as their forms. In a paper by <italic>Öztürk et al</italic>., DeepDTA was used to represent raw sequences and SMILES as one-hot vectors or labels [<xref ref-type="bibr" rid="pcbi.1007129.ref024">24</xref>]. With a convolutional neural network (CNN), the authors extracted local residue patterns to predict the binding affinity between drugs and targets. As a result, their model exhibited better performance on a kinase family bioassay dataset [<xref ref-type="bibr" rid="pcbi.1007129.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1007129.ref026">26</xref>] than the previous model, kronRLS [<xref ref-type="bibr" rid="pcbi.1007129.ref027">27</xref>] and SimBoost [<xref ref-type="bibr" rid="pcbi.1007129.ref028">28</xref>]. Because their model is optimized by densely constructed kinase affinities, DeepDTA is appropriate to predict kinase affinities not to predict new DTIs with various protein classes. Furthermore, they evaluated their performances on the identical dataset, rather than on independent dataset from new sources or databases.</p>
<p>To overcome the aforementioned problems, here, we introduce a deep learning model that predicts massive-scale DTIs using raw protein sequences not only for various target protein classes but also for diverse protein lengths. The overall pipeline of our model is depicted in <xref ref-type="fig" rid="pcbi.1007129.g001">Fig 1</xref>. First, for the training model, we collected large-scale DTIs integrated from various DTI databases, such as DrugBank [<xref ref-type="bibr" rid="pcbi.1007129.ref029">29</xref>], International Union of Basic and Clinical Pharmacology (IUPHAR) [<xref ref-type="bibr" rid="pcbi.1007129.ref030">30</xref>], and Kyoto Encyclopedia of Genes and Genomes (KEGG) [<xref ref-type="bibr" rid="pcbi.1007129.ref031">31</xref>]. Second, in model construction, we adopted convolution filters on the entire sequence of a protein to capture local residue patterns, which are the main protein residues participating in DTIs. By pooling the maximum CNN results of sequences, we can determine how given protein sequences match local residue patterns participating in DTIs. Using these data as input variables for higher layers, our model constructs, abstracts and organizes protein features. After new protein features are generated, our model concatenates protein features with drug features, which come from fingerprints in the fully connected layer and predict the probability of DTIs via higher fully connected layers. Third, we optimized the model with DTIs from MATADOR [<xref ref-type="bibr" rid="pcbi.1007129.ref032">32</xref>] and negative interactions predicted from <italic>Liu et al</italic>. [<xref ref-type="bibr" rid="pcbi.1007129.ref033">33</xref>]. Finally, with the optimized model, we predicted DTIs from bioassays such as PubChem BioAssays [<xref ref-type="bibr" rid="pcbi.1007129.ref034">34</xref>] and KinaseSARfari [<xref ref-type="bibr" rid="pcbi.1007129.ref035">35</xref>] to estimate the performance of our model. As a result, our model exhibits better performance than previous models.</p>
<fig id="pcbi.1007129.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007129.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Overview of our model.</title>
<p>First, we collected training DTI datasets from various databases (DrugBank, KEGG, IUPHAR). Second, we constructed the neural network model using convolution, which is able to capture local residue patterns that can help the DTIs. Third, we optimized the hyperparameters with an external validation dataset that we constructed. Finally, we predicted DTIs from bioassays (independent test dataset) and evaluated the performance of our model. The numbers (#) of compounds, proteins and DTIs are summarized in each step.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.g001" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Performances of the validation dataset and selected hyperparameters</title>
<p>As a normal step of hyperparameter setting, we first tuned the learning rate of the weight update to 0.0001. After the learning rate was fixed, we benchmarked the sizes and number of windows, hidden layers of the drug features, and the concatenating layers with the area under precision-recall (AUPR) on the external unseen validation dataset, which was built with MATADOR and a highly credible negative dataset. Finally, we selected the hyperparameters of the model, as shown in Table A in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>, with the external unseen validation dataset, yielding an AUPR of 0.832 and area under the curve (AUC) of 0.852, as shown in <xref ref-type="fig" rid="pcbi.1007129.g002">Fig 2</xref>. The AUPR value of our model was less than the AUPR of the similarity descriptor; however, that does not mean that our method has lower prediction performance than the similarity method because the size of the validation is too small to evaluate the general performance. In addition, we further examined the effect of fixed maximum protein length on the prediction performance. As shown in Fig A in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>, we confirmed that the prediction performance of our model is not biased to the fixed maximum protein length. Finally, the fully optimized model is visualized as a graph, shown in <xref ref-type="supplementary-material" rid="pcbi.1007129.s002">S1 Fig</xref>, respective to our model, the CTD descriptor, and similarity descriptors. In the same manner, we built and optimized models that use other protein descriptors with the same activation function, learning rate, and decay rate.</p>
<fig id="pcbi.1007129.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007129.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Performance curves for optimized models of protein descriptors.</title>
<p>The AUPR and AUC of the convolution, CTD, and similarity descriptors are shown in panels (A) and (B), respectively.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec004">
<title>Comparison of performance with other protein descriptors</title>
<p>After the hyperparameters were tuned, we compared the performance based on the independent test datasets with the different protein descriptors, the CTD descriptor (which is usually used in the conventional chemo-genomic model) [<xref ref-type="bibr" rid="pcbi.1007129.ref013">13</xref>], the normalized Smith-Waterman (SW) score [<xref ref-type="bibr" rid="pcbi.1007129.ref036">36</xref>], and our convolution method. The results showed that our model exhibited better performance than the other protein descriptors for all datasets, as shown in <xref ref-type="fig" rid="pcbi.1007129.g003">Fig 3</xref> and Fig B in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>. With the threshold selected by the equal error rate (EER) [<xref ref-type="bibr" rid="pcbi.1007129.ref037">37</xref>], our model performed equally well with both the PubChem and KinaseSARfari datasets, indicating that our model has general application power. Our convolution method gave the highest accuracy score and F1 score for the PubChem dataset (<xref ref-type="fig" rid="pcbi.1007129.g003">Fig 3<bold>A</bold></xref>) [<xref ref-type="bibr" rid="pcbi.1007129.ref034">34</xref>] and its subsets (<xref ref-type="fig" rid="pcbi.1007129.g003">Fig 3<bold>B–</bold>3<bold>D</bold></xref>) and a slightly lower F1 score for the KinaseSARfari dataset (Fig B in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>) [<xref ref-type="bibr" rid="pcbi.1007129.ref035">35</xref>]. The CTD descriptor gave the lowest score for any dataset and any metric, which implies that CTD is less informative and less enriched than the other descriptors. Here, we also observed that the model performance using a similarity descriptor for the KinaseSARfari dataset was similar to that of the proposed model. We can interpret this result as the similarity descriptor acts as an informative feature as a local residue pattern at the domain level, not the whole protein complex.</p>
<fig id="pcbi.1007129.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007129.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Performance measures for all of the independent datasets of the PubChem dataset.</title>
<p>We measured various performances such as sensitivity (Sen.), specificity (Spe.), precision (Pre.), accuracy (Acc.), and F1 score (F1) from the prediction results given by descriptors (A-D). (A) All queried PubChem datasets. (B) PubChem dataset whose compounds are not in the training dataset. (C) PubChem dataset whose targets are not in the training dataset. (D) PubChem dataset whose compounds and targets are not in the training dataset. Our convolution model shows better performances for all datasets in terms of accuracy and F1 score.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec005">
<title>Performance comparison with a previous model</title>
<p>In addition to the comparison between convolution in our model and other protein descriptors, in this section, we compared the performance of our model against recently developed deep-learning-based models. We selected three deep learning models for comparisons, SAE (MFDR, <italic>Peng et al</italic>, 2016) [<xref ref-type="bibr" rid="pcbi.1007129.ref022">22</xref>], DBN (DeepDTI, <italic>Wen et al</italic>, 2017) [<xref ref-type="bibr" rid="pcbi.1007129.ref007">7</xref>] and CNN (DeepDTA, <italic>Ozturk et al</italic>, 2018). First, MFDR trains SAE in an unsupervised manner, while proteins are represented by multi-scale local descriptor feature [<xref ref-type="bibr" rid="pcbi.1007129.ref038">38</xref>] and compounds are represented by PubChem fingerprints as input and output for SAE. With trained deep representations of sparse Auto-Encoder, they performed 5-fold cross-validation by using SVM. As a result, their model gives better performances than previous bipartite local models. Because the authors do not provide the model, we implemented the MFDR model with optimized parameters the author provided in their original paper. We tested the validity of implemented MFDR and confirmed that the implemented model produces reasonably same performance compared to the results from its original work (see Fig C <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>). Second, DeepDTI built by <italic>Wen et al</italic>. is based on DBN [<xref ref-type="bibr" rid="pcbi.1007129.ref020">20</xref>], which is a stack of restricted Boltzmann machine (RBM). DeepDTI takes amino acid, dipeptide and tripeptide compositions (protein sequence composition descriptors, PSC) as the protein input and ECFP with radius 1, 2 and 3 as the compound input. We used DeepDTI with the code that the authors provided (<ext-link ext-link-type="uri" xlink:href="https://github.com/Bjoux2/DeepDTIs_DBN" xlink:type="simple">https://github.com/Bjoux2/DeepDTIs_DBN</ext-link>) and optimized hyperparameters as the authors mentioned. Third, DeepDTA built by <italic>Ozturk et al</italic>. used stacked CNN on protein sequences and SMILES to predict affinity between target protein and compound. DeepDTA is optimized for Davis [<xref ref-type="bibr" rid="pcbi.1007129.ref025">25</xref>] and KIBA [<xref ref-type="bibr" rid="pcbi.1007129.ref026">26</xref>] dataset which contains kinases protein, their inhibitors, and dense affinity values, showing better prediction performances than previous affinity prediction models. We also used DeepDTA with the code from the original work (<ext-link ext-link-type="uri" xlink:href="https://github.com/hkmztrk/DeepDTA" xlink:type="simple">https://github.com/hkmztrk/DeepDTA</ext-link>) and optimized hyperparameters they provided. For the DTI prediction performance comparison, we activate the last layer with sigmoid function to predict interaction, not affinity, also we changed loss function as binary cross-entropy from mean squared error. It should be noticed that we compared the performance of all three models by training and testing with the same data set we used for a fair comparison.</p>
<p>Results of performance comparison between our proposed model and the three related models are shown in <xref ref-type="fig" rid="pcbi.1007129.g004">Fig 4</xref>, showing that performances (accuracy, F1) of our model (DeepConv-DTI) are better than other models. MFDR which gave high AUC in 5-fold cross-validation shows decreased performances in the independent test dataset. We can speculate that SAE which learns deep representation of DTI in an unsupervised way is not appropriate for a case that datasets are composed of various protein classes. In the case of DeepDTI, DeepDTI takes physicochemical properties (PSC) of whole protein sequence including subsequences or domains which do not participate in the interaction with compounds, resulting in worse performance than our model which extracts local residue patterns. For DeepDTA, DeepDTA also shows worse performances than our model with having a relatively large variance. We interpret the worse performance of DeepDTA as follows. DeepDTA is optimized for a densely constructed dataset with specific protein class, while the training dataset in this comparison covers various protein classes (kinase, protease, ion channel, nuclear receptor, GPCR, etc), not only kinase class. Thus, DeepDTA which is specialized for a specific protein class could not achieve better prediction performance in the generalized protein classes.</p>
<fig id="pcbi.1007129.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007129.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Comparison of performances between our model and previous models.</title>
<p>We compared performances of our model on independent test dataset (PubChem) with previous models (MFDR, DeepDTI, and DeepDTA). Our model gives better performances than previous models for accuracy and F1 metrics.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.g004" xlink:type="simple"/>
</fig>
<p>In addition to the three models we compared, we also compared our model with DL-CPI [<xref ref-type="bibr" rid="pcbi.1007129.ref023">23</xref>] built by <italic>Tian et al</italic>. which used protein domain information. For proteins whose domain information is not in Pfam [<xref ref-type="bibr" rid="pcbi.1007129.ref039">39</xref>], datasets for training, validation and test are not fully available. Therefore, we independently compared performances between DL-CPI and our model by additionally built the training, validation, and test datasets. Performance comparison results are described in Fig E in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>. We confirmed that the proposed model shows better performance than DL-CPI. Because protein descriptor of DL-CPI is sparse, containing few values in large dimension, which may decrease performances.</p>
<p>In overall, our model shows better performance than previous deep learning models in an independent test dataset from a different database, which contains distinct DTIs, dealing with DTIs with various protein classes and their interacting compounds.</p>
</sec>
<sec id="sec006">
<title>Analysis of convolution results</title>
<p>Because we pooled the maximum convolution results by each filter for each window, the pooled results could highlight regions of matches with local residue patterns. Although we cannot measure exactly how those values affect the DTI prediction results, the pooled maximum convolution result will affect the prediction performance by going through higher fully connected layers. Therefore, if our model is capable of capturing local residue patterns, it would give high values to important protein regions, such as actual binding sites.</p>
<p>Examining and validating the convolution results from the intermediate layer showed that our model could capture local residue patterns that participate in DTIs. The sc-PDB database provides atom-level descriptions of proteins, ligands, and binding sites from complex structures [<xref ref-type="bibr" rid="pcbi.1007129.ref040">40</xref>]. By parsing binding site annotations, we can query binding sites between protein domains and pharmacological ligands for 7,179 entries of Vertebrata. From the queried binding sites and pooled maximum convolution results, we statistically test our assumption that the pooled maximum convolution results cover the important regions, including binding sites. Each window has 128 pooled convolution results, which shows bias in covering some regions. Thus, we randomly generated 128 convolution results 10,000 times for each sc-PDB entry and counted how many of those random results covered each amino acid in the binding sites, which resulted in the construction of normal distributions. For each normal distribution constructed by the randomly generated convolution results, considered a null hypothesis, we executed a right-tailed <italic>t</italic>-test with the number from the convolution results of our model for each window. Because we did not know which window detects the binding site, we took the most significant p-value (minimum p-value adjusted by the Benjamini-Hochberg procedure [<xref ref-type="bibr" rid="pcbi.1007129.ref041">41</xref>]). The sc-PDB entry information and p-values of a window for each sc-PDB entry are summarized in the <xref ref-type="supplementary-material" rid="pcbi.1007129.s003">S1 File</xref>. We summarize the results of binding site detection from the most significant p-value among windows by significance level cutoff in <xref ref-type="fig" rid="pcbi.1007129.g005">Fig 5</xref>. In addition, we examined sc-PDB entries with the most significant p-values for diverse window sizes. We visualized two high-score sc-PDB entries from two perspectives—the whole receptor-ligand complex and binding site-ligand perspectives—by using UCSF Chimera [<xref ref-type="bibr" rid="pcbi.1007129.ref042">42</xref>] as shown in <xref ref-type="fig" rid="pcbi.1007129.g006">Fig 6</xref>. To visualize convolution results with a simplified view, first, we selected the top 5 ranked globally max-pooled results among all filters for each window because whole protein sequences are usually covered by convolution results if we select all results. Second, we rendered residues covered by convolution results by the number of covering convolution results. We visualized two sc-PDB entries, 1a7x_1 and 1ny3_1. 1a7x_1, representing the complex of the ion channel, protein Peptidyl-prolyl cis-trans isomerase FKBP1A (FKB1A_HUMAN in UniProt), which has a short sequence length (108), and BENZYL-CARBAMIC ACID [8-DEETHYL-ASCOMYCIN-8-YL]ETHYL ESTER (FKA in PDB ligand) [<xref ref-type="bibr" rid="pcbi.1007129.ref043">43</xref>]. 1ny3_1 is the complex of the kinase protein, MAP kinase-activated protein kinase 2 (MAPK2_HUMAN in UniProt) with sequence length 400, and ADENOSINE-5’-DIPHOSPHATE (ADP in PDB ligand) [<xref ref-type="bibr" rid="pcbi.1007129.ref044">44</xref>]. Through the above evaluation, we can confirm that our proposed model is capable of capturing local residue patterns of proteins that are considered important features for DTI prediction, such as actual binding sites.</p>
<fig id="pcbi.1007129.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007129.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Statistical test for binding region detection.</title>
<p>We executed a right-tailed <italic>t</italic>-test for the number of covering binding sites from the convolution results with a null distribution, which was constructed from the randomly generated convolution results in the sc-PDB database consisting of 7,179. Because each sc-PDB test has many windows, we selected the most significant p-values adjusted by the Benjamini-Hochberg procedure and examined whether they were significant at levels of 1%, 5% and 10%. The results showed that 14.6%, 30.3% and 42.2% of sc-PDB entries were significantly enriched, respectively (A-C).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.g005" xlink:type="simple"/>
</fig>
<fig id="pcbi.1007129.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007129.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Visualization of convolution results.</title>
<p>We visualized two highly scored sc-PDB entries from two perspectives—the whole receptor-ligand complex and binding site-ligand perspectives—by using UCSF Chimera. To visualize convolution results with a simplified view, first, we selected the top 5 ranked globally max-pooled results among all filters for each window because whole protein sequences are usually covered by convolution results if we select all results. Second, we rendered residues covered by the convolution results by the number of covering convolution results. (A) Complex of the ion channel protein Peptidyl-prolyl cis-trans isomerase FKBP1A (FKB1A_HUMAN in UniProt), which has a short sequence length (108), and FKA in the PDB ligand (1a7x_1 in sc-PDB). As we can see, the number of convolution results near the ligand is more than the number for the other region. (B) For the binding site and ligand of 1a7x_1, most of the binding sites are highly covered by the convolution results. (C) Complex of the kinase protein MAP kinase-activated protein kinase 2 (MAPK2_HUMAN in UniProt) with a sequence length of 400 and ADP in the PDB ligand (1ny3_1 in sc-PDB). Although half of the protein sequence is not represented as a 3D structure, our convolution results cover regions close to ligand binding sites in a biased manner. However, some residues far from binding sites are also highlighted by convolution results, potentially indicating some important structural motifs for binding. (D) For the binding site and ligand of 1ny3_1, most binding sites are covered by the convolution results, although some residues are not covered.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>t-SNE visualization of proteins</title>
<p>From the results shown in <xref ref-type="fig" rid="pcbi.1007129.g006">Fig 6</xref>, we can confirm that our model can capture the local residue patterns of proteins that participate in DTIs. Thus, to examine further characteristics of the captured protein local residue patterns, we visualized the protein features from the fully connected layer after the global max-pooling of convolution results. We visualized 1,527 proteins used in the training dataset categorized in various protein classes. Specifically, we visualized 257 GPCRs, 44 nuclear receptors, 304 ion channel receptors, 604 kinases, and 318 proteases. For visualization, we conducted t-distributed stochastic neighbor embedding (t-SNE) for dimension reduction and visualization [<xref ref-type="bibr" rid="pcbi.1007129.ref045">45</xref>]. t-SNE can map high-dimensional features to low-dimensional ones, such as 2-dimensional features, minimizing information loss during dimension reduction. Surprisingly, although our model is not intended to identify protein classes, it can roughly discriminate protein classes from the intermediate protein layer, as shown in Fig G in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>.</p>
</sec>
</sec>
<sec id="sec008" sec-type="conclusions">
<title>Discussion</title>
<p>In this work, we built a novel DTI prediction model to extract local residue patterns of whole target protein sequences with CNN. We trained the model with DTIs from various drug databases and optimized the model with an external validation dataset. As a result, the detected local features of protein sequences perform better than other protein descriptors, such as CTD and SW scores. Our model also performs better than a previous model built on DBN. In addition, by analyzing pooled convolution results and statistically and manually comparing them with annotations from sc-PDB entries, we showed that, for some proteins, our model is capable of detecting important regions, including binding sites. Therefore, our approach of capturing local residue patterns with CNN successfully enriches protein features for DTI prediction.</p>
<p>The number of 3D structures in Protein Data Bank [<xref ref-type="bibr" rid="pcbi.1007129.ref046">46</xref>] is relatively smaller than the number of sequences, limiting 3D structure-based DTI prediction methods. For example, the number of PDB entries for <italic>Homo sapiens</italic> is 42,745, while the number of protein sequences for <italic>Homo sapiens</italic> is 177,661 in UniProtKB. However, our method does not depend on the 3D structure of proteins because it considers only protein sequence, rather than classical protein feature descriptors such as the CTD descriptor and normalized SW score. As a result, our method can be more generally applied to predict DTIs than methods needing 3D structures.</p>
<p>Although our model shows improved prediction performance, there is still room for improvement. First, we simply used Morgan/Circular fingerprints, which are binary and have large dimensions. Therefore, we will use more informative chemical descriptors, based on neural networks for DTI prediction, to achieve advanced performance. Second, as shown in a previous study [<xref ref-type="bibr" rid="pcbi.1007129.ref047">47</xref>], considering 3D structure information is an effective substitution for chemical elaboration. Therefore, in the future, we will elaborate upon our model by considering 3D structure features.</p>
</sec>
<sec id="sec009" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec010">
<title>Building dataset</title>
<p>To build the training dataset, we obtained known DTIs from three databases: DrugBank, KEGG, and IUPHAR. To remove duplicate DTIs among the three databases, we unified the identifiers of the compounds and the proteins. For the drugs, we standardized the identifiers of the compounds in the DrugBank and KEGG databases with the InChI descriptor. For the proteins, we unified the identifiers of the proteins as UniProtKB/Swiss-Prot accessions [<xref ref-type="bibr" rid="pcbi.1007129.ref048">48</xref>]. Among the collected DTIs, we selectively removed proteins of Prokaryota and single-cell Eukaryota, retaining only proteins of Vertebrata. Finally, 11,950 compounds, 3,675 proteins, and 32,568 DTIs were obtained in total. Because all collected DTIs are regarded as positive samples for training and negative DTIs are not defined in the databases above, a random negative DTI dataset is inevitably generated. To reduce bias from the random generation of negative DTIs, we built ten sets of negative DTIs exclusively from the positive dataset. The detailed statistics of the collected training dataset are shown in Table D in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>.</p>
<p>To optimize our model with the most adequate hyperparameters, we constructed an external validation dataset that had not seen DTIs in the training phase. We collected positive DTIs from the MATADOR database [<xref ref-type="bibr" rid="pcbi.1007129.ref032">32</xref>], including ‘DIRECT’ protein annotations, and all DTIs observed in the training dataset were excluded. To build a credible negative dataset, we obtained negative DTIs via the method of <italic>Liu et al</italic>. [<xref ref-type="bibr" rid="pcbi.1007129.ref033">33</xref>]. This method selects candidate negative DTIs with low similarity to known positive DTIs. From the obtained negative dataset, we balanced the negative dataset with the positive dataset, using a negative score (&gt;0.95). As a result, 370 positive DTIs and 507 negative DTIs were queried for the external validation set. The statistics of the external validation dataset are summarized in Table E in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>.</p>
<p>To evaluate our model, we built two independent test datasets from the PubChem BioAssay database [<xref ref-type="bibr" rid="pcbi.1007129.ref034">34</xref>] and ChEMBL KinaseSARfari [<xref ref-type="bibr" rid="pcbi.1007129.ref035">35</xref>]; these datasets consisted of results from experimental assays. To obtain positive DTIs from PubChem, we collected ‘Active’ DTIs from the assays with the dissociation constant (K<sub>d</sub> &lt; 10μ<italic>m</italic>) [<xref ref-type="bibr" rid="pcbi.1007129.ref049">49</xref>]. Because we sought to predict whether a drug binds to a protein, among the many types of assays (Potency, IC<sub>50</sub>, AC<sub>50</sub>, EC<sub>50</sub>, K<sub>d</sub>, K<sub>i</sub>), evaluation of the dissociation constant (K<sub>d</sub>) was the most appropriate assay for obtaining positive samples. For the negative samples, we took the samples annotated as ‘Inactive’ from the other assay types. Because there were too many negative samples in the PubChem BioAssay database, we first collected only negative samples whose drug or target was included in the positive samples from the PubChem BioAssay database. Second, we selected as many random negative samples as positive DTIs from PubChem BioAssay. As a result, total 36,456 positive and negative samples were built with 21,907 drugs and 698 proteins. For the performance evaluation, we created three subsets of the PubChem bioassay independent dataset for humans, which consisted of only new compounds, new proteins, and new DTIs. Detailed summaries of the PubChem dataset and its subset are shown in Table F in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>. We also collected samples from KinaseSARfari. KinaseSARfari consists of assays involving a compound that binds to a kinase domain. To obtain positive samples from KinaseSARfari, we considered each assay result with a dissociation constant of (K<sub>d</sub> &lt; 10μ<italic>m</italic>) as positive [<xref ref-type="bibr" rid="pcbi.1007129.ref049">49</xref>]; this value is sufficiently small to be considered positive. In contrast to the PubChem BioAssay, the number of negative samples was similar to the number of positive samples in KinaseSARfari; therefore, we did not sample the negative samples. We collected 3,835 positive samples and 5,520 negative samples with 3,379 compounds and 389 proteins. Detailed statistics of the KinaseSARfari dataset are shown in Table F in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>. In addition, we summarize the portion of the protein class in each dataset in Fig H in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>. Here, we confirmed that the training and the validation datasets were not biased toward a specific protein class.</p>
</sec>
<sec id="sec011">
<title>Drug feature representation</title>
<p>In our model, we used the raw protein sequence as the input for the protein but did not use the raw SMILES string as the input for the drug. For the drug, we used the Morgan/Circular drug fingerprint, which analyzes molecules as a graph and retrieves substructures of molecular structures from subgraphs of the whole molecular graph [<xref ref-type="bibr" rid="pcbi.1007129.ref021">21</xref>]. Specifically, we used RDKit [<xref ref-type="bibr" rid="pcbi.1007129.ref050">50</xref>] to yield a Morgan/Circular fingerprint with a radius of 2 from a raw SMILES string. Finally, each drug can be represented as a binary vector with a length of 2,048, whose indices indicate the existence of specific substructures.</p>
</sec>
<sec id="sec012">
<title>Deep neural network model</title>
<sec id="sec013">
<title>Overall schema of the deep learning network</title>
<p>We extracted the local residue patterns from protein sequences via CNN and yielded a latent representation of drug fingerprints via fully connected layers. After processing both the drug and protein layers, we concatenated these layers and constructed the fully connected layer, resulting in the output. Every layer except the output layer was activated with the exponential linear unit (ELU) function [<xref ref-type="bibr" rid="pcbi.1007129.ref051">51</xref>].</p>
<disp-formula id="pcbi.1007129.e001">
<alternatives>
<graphic id="pcbi.1007129.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mi mathvariant="normal">σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">α</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>α</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mi>x</mml:mi></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">for</mml:mi><mml:mspace width="0.25em"/><mml:mi>x</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>x</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">for</mml:mi><mml:mspace width="0.25em"/><mml:mi>x</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow> </mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
<p>The output layer was activated with the sigmoid function for classification. The whole neural network model was implemented with Keras (2.16) [<xref ref-type="bibr" rid="pcbi.1007129.ref052">52</xref>].</p>
</sec>
<sec id="sec014">
<title>Convolution layer with protein embedding vector</title>
<p>One of the difficulties in describing the protein features for the machine learning model and the deep learning model was that the protein lengths were all different. Another difficulty was that only certain parts of a protein, such as specific domains or motifs, are involved in DTIs, rather than the whole protein structure. As a result, the physicochemical properties of the whole protein sequence do not seem to be appropriate features for predicting DTIs due to noise information from the portions of the sequence that are not involved in the DTIs. Thus, the extraction of local residue patterns involved in the DTIs is necessary for precise prediction, and CNN is known to capture important local patterns from the whole space. The overall schema of convolutional layers is depicted in <xref ref-type="fig" rid="pcbi.1007129.g007">Fig 7</xref>. The model starts with an embedding to transform each amino acid to the corresponding embedding vector. The embedding layer is a lookup table of embedding vectors. Embedding vector values are randomly initialized by the Xavier initializer (denoted ‘glorot normal’ in keras), which imposes normal distribution of weights and variance of output following variance of input [<xref ref-type="bibr" rid="pcbi.1007129.ref053">53</xref>]. Embedding vectors are trainable, meaning that embedding vector values are also changed to optimize loss during training. From the lookup table, the embedding matrix for the protein sequence is constructed by querying embedding vectors corresponding to amino acids from the embedding layer, as described in Fig I in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>. The length of the embedding matrix for all proteins was set to the same as the maximum protein length, i.e., 2,500, and the margins were padded with null labels ($) and the corresponding embedding vectors, which would give a meaningless convolution result that is filtered out during global max-pooling as depicted in Fig J in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>. As a result, an embedding layer was constructed for protein features. We executed convolution on the embedding layer of the protein along the sequence in 1D fashion with striding 1, with convolution from j<sup>th</sup> the to the (j+WS)<sup>th</sup> amino acids in sequence, which can be defined as
<disp-formula id="pcbi.1007129.e002">
<alternatives>
<graphic id="pcbi.1007129.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>*</mml:mo><mml:mi mathvariant="normal">w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi mathvariant="normal">W</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<fig id="pcbi.1007129.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1007129.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Overall schema for extracting the local patterns from the whole protein sequence.</title>
<p>First, we transformed the protein sequence to an embedding vector with a fixed size, and the margins were padded, which are marked as $ and the corresponding embedding vectors. Second, we executed convolution along the sequence. Third, for each filter of window size, we pooled the max value. By concatenating all of the max-pooling values, we built a protein feature vector whose dimension is multiplying the number (#) of filters by the number (#) of windows.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.g007" xlink:type="simple"/>
</fig>
<p>Convolution for the whole sequence results in a (MPL-WS+1) size convolution layer for each filter, where WS is the window size. Finally, to extract the most important local feature, we conducted global max-pooling for each filter, which is defined as
<disp-formula id="pcbi.1007129.e003">
<alternatives>
<graphic id="pcbi.1007129.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:msub><mml:mrow><mml:mi mathvariant="normal">g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mo>(</mml:mo><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>*</mml:mo><mml:mi>w</mml:mi><mml:msub><mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where j covers all of the convolution results of the embedding matrix from protein sequence p<sub>k</sub>, resulting in a filter-sized vector with a max-valued convolution result for each window, which does not induce bias from the locations of local residue patterns and the maximum protein length. After pooling all convolution results, we concatenated them to represent the important local patterns for interactions as a vector-formatted feature. Finally, for the organization and abstraction of protein features, concatenated max-pooling results are fed into fully connected layers, which constructs a latent representation of protein.</p>
</sec>
<sec id="sec015">
<title>Fully connected layers for drug fingerprints and concatenating layer</title>
<p>As mentioned in the Introduction, latent representations of the drug fingerprint descriptors made by fully connected layer are useful for predicting DTIs. After features of the protein and drug were refined by the neural network, we concatenated them and constructed fully connected layers to predict whether the drug and target interact.</p>
</sec>
<sec id="sec016">
<title>Calculation of loss and weight optimization</title>
<p>Using the constructed deep neural model, the input flows to the output layer in a feed-forward fashion. The deep neural model calculates loss with binary cross-entropy:
<disp-formula id="pcbi.1007129.e004">
<alternatives>
<graphic id="pcbi.1007129.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mi>J</mml:mi><mml:mo>(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mspace width="0.25em"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>To prevent overfitting, we penalized the loss function with L2-norm:
<disp-formula id="pcbi.1007129.e005">
<alternatives>
<graphic id="pcbi.1007129.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:msub><mml:mrow><mml:mi>J</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>J</mml:mi><mml:mo>(</mml:mo><mml:mi>W</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mo>‖</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>Finally, we updated the weights using the Adam optimizer [<xref ref-type="bibr" rid="pcbi.1007129.ref054">54</xref>] with a penalized loss to give a generalized prediction for the model.</p>
</sec>
<sec id="sec017">
<title>Regularizations of the neural network</title>
<p>In the artificial neural network technique, there are several ways to prevent overfitting. Currently, dropout and batch normalization are most frequently used to regularize neural networks. Dropout masks hidden nodes in the training phase, which makes a subset of hidden nodes unavailable to predict results for training labels [<xref ref-type="bibr" rid="pcbi.1007129.ref055">55</xref>]. By masking some hidden nodes in training, dropout generalizes the model, making the model independent of a specific dataset. We used 1-dimensional spatial dropout on the embedding layer [<xref ref-type="bibr" rid="pcbi.1007129.ref056">56</xref>]. In addition, we used a batch normalization technique to prevent overfitting except in the embedding layer. Batch normalization normalizes the outputs of the neural network with a mean of 0 and a standard deviation of 1 on a minibatch. However, batch normalization could induce a loss in the influence of parameters and linearity of network outputs, rather than nonlinearity. Thus, batch normalization induces a scale factor and a shift factor for normalized outputs, whose values are also introduced in the learning phase, to resolve the problem [<xref ref-type="bibr" rid="pcbi.1007129.ref057">57</xref>].</p>
</sec>
<sec id="sec018">
<title>Selection of hyperparameters</title>
<p>In our deep learning models, hyperparameters, such as the learning rate and window sizes that affect performance, are tuned during cross-validation. However, the hyperparameters should not be determined based on the performance of the subset of the training dataset because the negative datasets are randomly sampled. With the external validation dataset, we first determined the learning rate because a model with a high learning rate is unable to learn a pattern. After the learning rate was selected, we selected activation function and regularization parameters such as the dropout ratio. Finally, we employed a grid-search method for optimization of the other hyperparameters that determine neural network shape. The search range of optimization is summarized in Table A in <xref ref-type="supplementary-material" rid="pcbi.1007129.s001">S1 Text</xref>. We identified hyperparameters that exhibited the best AUPR, which is an appropriate performance evaluation metric for the accuracy of classifying the positive sample. The other descriptors to compare with our methods are numerical vectors, which do not have locality. Therefore, we put fully connected layers on the protein descriptors. We also employed a grid-search strategy while sustaining hyperparameters not related to model shape. When the AUPR is measured, the optimal threshold can be given by the EER [<xref ref-type="bibr" rid="pcbi.1007129.ref037">37</xref>].
<disp-formula id="pcbi.1007129.e006">
<alternatives>
<graphic id="pcbi.1007129.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">E</mml:mi><mml:mi mathvariant="normal">R</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">argmin</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">θ</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>|</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mo>|</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">γ</mml:mi><mml:mo>|</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>|</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where θ is the classification threshold and γ is the constant determining the cost ratio for misclassification from precision and recall, which is set at 2 in our model.</p>
</sec>
</sec>
<sec id="sec019">
<title>Sparse Auto-Encoder (SAE) construction</title>
<p>SAE is Auto-Encoder whose distribution of latent representations is regularized with sparsity term [<xref ref-type="bibr" rid="pcbi.1007129.ref058">58</xref>]. In loss calculation, Kullback-Leibler divergence (KLD) loss between Bernoulli distributions each dimension in latent representation <inline-formula id="pcbi.1007129.e007"><alternatives><graphic id="pcbi.1007129.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">ρ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and desired sparsity parameter ρ is added to reconstruction loss of Auto-Encoder and ridge loss for weights.
<disp-formula id="pcbi.1007129.e008">
<alternatives>
<graphic id="pcbi.1007129.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e008" xlink:type="simple"/>
<mml:math display="block" id="M8">
<mml:msub><mml:mrow><mml:mi mathvariant="normal">J</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">W</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">J</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">W</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">b</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">||</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>ρ</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
where
<disp-formula id="pcbi.1007129.e009">
<alternatives>
<graphic id="pcbi.1007129.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mover accent="true"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">ρ</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munderover><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>During the training of the neural network, KLD acts as a constraint for latent representation following desired sparsity parameter. As a result, for each dimension of latent representation, only a few samples are activated, giving a more reliable representation of original input. In the previous study, MFDR used SAE to build an informative latent representation of DTI, which are composed of multi-scale local descriptors [<xref ref-type="bibr" rid="pcbi.1007129.ref038">38</xref>] and PubChem fingerprints.</p>
</sec>
<sec id="sec020">
<title>Deep belief network (DBN) construction</title>
<p>DBN is a generative graphical model proposed by Geoffrey Hinton [<xref ref-type="bibr" rid="pcbi.1007129.ref020">20</xref>]. DBN is actually a stack of an RBM. RBM consists of visible and hidden units, constructing a bipartite graph. In RBM, probabilistic distribution of visible units is learned in an unsupervised way, with a probabilistic distribution of visible and hidden units
<disp-formula id="pcbi.1007129.e010">
<alternatives>
<graphic id="pcbi.1007129.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e010" xlink:type="simple"/>
<mml:math display="block" id="M10">
<mml:mi mathvariant="normal">P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>h</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>W</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup>
</mml:math>
</alternatives>
</disp-formula>
and marginal distribution of visible units
<disp-formula id="pcbi.1007129.e011">
<alternatives>
<graphic id="pcbi.1007129.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e011" xlink:type="simple"/>
<mml:math display="block" id="M11">
<mml:mi mathvariant="normal">P</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:munder><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>h</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>W</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula>
to maximize the probability of visible units for V in a training set with weight matrix W
<disp-formula id="pcbi.1007129.e012">
<alternatives>
<graphic id="pcbi.1007129.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e012" xlink:type="simple"/>
<mml:math display="block" id="M12">
<mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">argmax</mml:mi></mml:mrow><mml:mrow><mml:mi>W</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mrow><mml:munder><mml:mo stretchy="false">∏</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>∈</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mo>(</mml:mo><mml:mi>v</mml:mi><mml:mo>|</mml:mo><mml:mi>W</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>In DBN, during stacking of RBMs, hidden units of the previous RBM are fed as visible layers of the next RBM. In addition, RBM adopts contrastive divergence for fast training, which uses gradient descent and Gibbs sampling. In a previous study, DeepDTI, the input concatenation of drug and target protein features, PSC descriptors and ECFP with a radius of 1, 2 and 3, was considered a first visible layer. The authors attached logistic regression to the last hidden units to predict DTIs.</p>
</sec>
<sec id="sec021">
<title>Evaluation of performances</title>
<p>To measure the prediction performance of our deep neural model based on the independent test dataset after the classification threshold was fixed, we obtained the following performance metrics: sensitivity (Sen.), specificity (Spe.), precision (Pre.), accuracy (Acc.), and the F1 measure (F1). See the formulas below:
<disp-formula id="pcbi.1007129.e013">
<alternatives>
<graphic id="pcbi.1007129.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e013" xlink:type="simple"/>
<mml:math display="block" id="M13">
<mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>.</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>/</mml:mo><mml:mi mathvariant="normal">P</mml:mi>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1007129.e014">
<alternatives>
<graphic id="pcbi.1007129.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e014" xlink:type="simple"/>
<mml:math display="block" id="M14">
<mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>.</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo>/</mml:mo><mml:mi mathvariant="normal">N</mml:mi>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1007129.e015">
<alternatives>
<graphic id="pcbi.1007129.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e015" xlink:type="simple"/>
<mml:math display="block" id="M15">
<mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>.</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">F</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1007129.e016">
<alternatives>
<graphic id="pcbi.1007129.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e016" xlink:type="simple"/>
<mml:math display="block" id="M16">
<mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mo>.</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">N</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
<disp-formula id="pcbi.1007129.e017">
<alternatives>
<graphic id="pcbi.1007129.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1007129.e017" xlink:type="simple"/>
<mml:math display="block" id="M17">
<mml:mi mathvariant="normal">F</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>*</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:mo>(</mml:mo><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where TP is true positive, TN is true negative, FP is false positive, FN is false negative, T is positive, and N is negative.</p>
</sec>
</sec>
<sec id="sec022">
<title>Supporting information</title>
<supplementary-material id="pcbi.1007129.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Supporting information.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007129.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.s002" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Graph visualization of optimized models.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1007129.s003" mimetype="text/csv" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1007129.s003" xlink:type="simple">
<label>S1 File</label>
<caption>
<title>Metadata and results of statistical test for sc-PDB entries.</title>
<p>(CSV)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1007129.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kapetanovic</surname> <given-names>IM</given-names></name>. <article-title>Computer-aided drug discovery and development (CADDD): in silico-chemico-biological approach</article-title>. <source>Chem Biol Interact</source>. <year>2008</year>;<volume>171</volume>(<issue>2</issue>):<fpage>165</fpage>–<lpage>76</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cbi.2006.12.006" xlink:type="simple">10.1016/j.cbi.2006.12.006</ext-link></comment> <object-id pub-id-type="pmid">17229415</object-id>; PubMed Central PMCID: PMC2253724.</mixed-citation></ref>
<ref id="pcbi.1007129.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gowthaman</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Rogers</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Khowsathit</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lan</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Bai</surname> <given-names>N</given-names></name>, <etal>et al</etal>. <article-title>DARC: Mapping Surface Topography by Ray-Casting for Effective Virtual Screening at Protein Interaction Sites</article-title>. <source>J Med Chem</source>. <year>2016</year>;<volume>59</volume>(<issue>9</issue>):<fpage>4152</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/acs.jmedchem.5b00150" xlink:type="simple">10.1021/acs.jmedchem.5b00150</ext-link></comment> <object-id pub-id-type="pmid">26126123</object-id>; PubMed Central PMCID: PMC4707132.</mixed-citation></ref>
<ref id="pcbi.1007129.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yamanishi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Araki</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gutteridge</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Honda</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Kanehisa</surname> <given-names>M</given-names></name>. <article-title>Prediction of drug-target interaction networks from the integration of chemical and genomic spaces</article-title>. <source>Bioinformatics</source>. <year>2008</year>;<volume>24</volume>(<issue>13</issue>):<fpage>i232</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btn162" xlink:type="simple">10.1093/bioinformatics/btn162</ext-link></comment> <object-id pub-id-type="pmid">18586719</object-id>; PubMed Central PMCID: PMC2718640.</mixed-citation></ref>
<ref id="pcbi.1007129.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bleakley</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Yamanishi</surname> <given-names>Y</given-names></name>. <article-title>Supervised prediction of drug-target interactions using bipartite local models</article-title>. <source>Bioinformatics</source>. <year>2009</year>;<volume>25</volume>(<issue>18</issue>):<fpage>2397</fpage>–<lpage>403</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btp433" xlink:type="simple">10.1093/bioinformatics/btp433</ext-link></comment> <object-id pub-id-type="pmid">19605421</object-id>; PubMed Central PMCID: PMC2735674.</mixed-citation></ref>
<ref id="pcbi.1007129.ref005"><label>5</label><mixed-citation publication-type="other" xlink:type="simple">Zheng X, Ding H, Mamitsuka H, Zhu S. Collaborative matrix factorization with multiple similarities for predicting drug-target interactions. Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining; Chicago, Illinois, USA. 2487670: ACM; 2013. p. 1025–33.</mixed-citation></ref>
<ref id="pcbi.1007129.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ezzat</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Zhao</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wu</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>XL</given-names></name>, <name name-style="western"><surname>Kwoh</surname> <given-names>CK</given-names></name>. <article-title>Drug-Target Interaction Prediction with Graph Regularized Matrix Factorization</article-title>. <source>IEEE/ACM Trans Comput Biol Bioinform</source>. <year>2017</year>;<volume>14</volume>(<issue>3</issue>):<fpage>646</fpage>–<lpage>56</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TCBB.2016.2530062" xlink:type="simple">10.1109/TCBB.2016.2530062</ext-link></comment> <object-id pub-id-type="pmid">26890921</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wen</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Niu</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sha</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Yun</surname> <given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>Deep-Learning-Based Drug-Target Interaction Prediction</article-title>. <source>J Proteome Res</source>. <year>2017</year>;<volume>16</volume>(<issue>4</issue>):<fpage>1401</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/acs.jproteome.6b00618" xlink:type="simple">10.1021/acs.jproteome.6b00618</ext-link></comment> <object-id pub-id-type="pmid">28264154</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref008"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Kimothi Dhananjay SA, Biyani Pravesh,Anand Saket, Hogan James M. Metric learning on biological sequence embeddings. 2017 IEEE 18th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC). 2017;(1–5).</mixed-citation></ref>
<ref id="pcbi.1007129.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cheng</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Tang</surname> <given-names>Y</given-names></name>. <article-title>Prediction of chemical-protein interactions: multitarget-QSAR versus computational chemogenomic methods</article-title>. <source>Mol Biosyst</source>. <year>2012</year>;<volume>8</volume>(<issue>9</issue>):<fpage>2373</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1039/c2mb25110h" xlink:type="simple">10.1039/c2mb25110h</ext-link></comment> <object-id pub-id-type="pmid">22751809</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>He</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shi</surname> <given-names>XH</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>LL</given-names></name>, <name name-style="western"><surname>Kong</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Cai</surname> <given-names>YD</given-names></name>, <etal>et al</etal>. <article-title>Predicting drug-target interaction networks based on functional groups and biological features</article-title>. <source>PLoS One</source>. <year>2010</year>;<volume>5</volume>(<issue>3</issue>):<fpage>e9603</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0009603" xlink:type="simple">10.1371/journal.pone.0009603</ext-link></comment> <object-id pub-id-type="pmid">20300175</object-id>; PubMed Central PMCID: PMC2836373.</mixed-citation></ref>
<ref id="pcbi.1007129.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Luo</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Zheng</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Computational screening for active compounds targeting protein sequences: methodology and experimental validation</article-title>. <source>J Chem Inf Model</source>. <year>2011</year>;<volume>51</volume>(<issue>11</issue>):<fpage>2821</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/ci200264h" xlink:type="simple">10.1021/ci200264h</ext-link></comment> <object-id pub-id-type="pmid">21955088</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cereto-Massague</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ojeda</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Valls</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Mulero</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Garcia-Vallve</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Pujadas</surname> <given-names>G</given-names></name>. <article-title>Molecular fingerprint similarity search in virtual screening</article-title>. <source>Methods</source>. <year>2015</year>;<volume>71</volume>:<fpage>58</fpage>–<lpage>63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ymeth.2014.08.005" xlink:type="simple">10.1016/j.ymeth.2014.08.005</ext-link></comment> <object-id pub-id-type="pmid">25132639</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dubchak</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Muchnik</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Holbrook</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>SH</given-names></name>. <article-title>Prediction of protein folding class using global description of amino acid sequence</article-title>. <source>Proc Natl Acad Sci U S A</source>. <year>1995</year>;<volume>92</volume>(<issue>19</issue>):<fpage>8700</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.92.19.8700" xlink:type="simple">10.1073/pnas.92.19.8700</ext-link></comment> <object-id pub-id-type="pmid">7568000</object-id>; PubMed Central PMCID: PMC41034.</mixed-citation></ref>
<ref id="pcbi.1007129.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname> <given-names>ZC</given-names></name>, <name name-style="western"><surname>Huang</surname> <given-names>MH</given-names></name>, <name name-style="western"><surname>Zhong</surname> <given-names>WQ</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>ZQ</given-names></name>, <name name-style="western"><surname>Xie</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dai</surname> <given-names>Z</given-names></name>, <etal>et al</etal>. <article-title>Identification of drug-target interaction from interactome network with 'guilt-by-association' principle and topology features</article-title>. <source>Bioinformatics</source>. <year>2016</year>;<volume>32</volume>(<issue>7</issue>):<fpage>1057</fpage>–<lpage>64</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btv695" xlink:type="simple">10.1093/bioinformatics/btv695</ext-link></comment> <object-id pub-id-type="pmid">26614126</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Nam</surname> <given-names>H</given-names></name>. <article-title>Identification of drug-target interaction by a random walk with restart method on an interactome network</article-title>. <source>BMC Bioinformatics</source>. <year>2018</year>;<volume>19</volume>(<issue>Suppl 8</issue>):<fpage>208</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s12859-018-2199-x" xlink:type="simple">10.1186/s12859-018-2199-x</ext-link></comment> <object-id pub-id-type="pmid">29897326</object-id>; PubMed Central PMCID: PMC5998759.</mixed-citation></ref>
<ref id="pcbi.1007129.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tabei</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Yamanishi</surname> <given-names>Y</given-names></name>. <article-title>Scalable prediction of compound-protein interactions using minwise hashing</article-title>. <source>BMC Syst Biol</source>. <year>2013</year>;<volume>7</volume> <issue>Suppl 6</issue>:<fpage>S3</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1752-0509-7-S6-S3" xlink:type="simple">10.1186/1752-0509-7-S6-S3</ext-link></comment> <object-id pub-id-type="pmid">24564870</object-id>; PubMed Central PMCID: PMC4029277.</mixed-citation></ref>
<ref id="pcbi.1007129.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sawada</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kotera</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Yamanishi</surname> <given-names>Y</given-names></name>. <article-title>Benchmarking a Wide Range of Chemical Descriptors for Drug-Target Interaction Prediction Using a Chemogenomic Approach</article-title>. <source>Molecular Informatics</source>. <year>2014</year>;<volume>33</volume>(<issue>11–12</issue>):<fpage>719</fpage>–<lpage>31</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/minf.201400066" xlink:type="simple">10.1002/minf.201400066</ext-link></comment> <object-id pub-id-type="pmid">27485418</object-id></mixed-citation></ref>
<ref id="pcbi.1007129.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Min</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Yoon</surname> <given-names>S</given-names></name>. <article-title>Deep learning in bioinformatics</article-title>. <source>Brief Bioinform</source>. <year>2017</year>;<volume>18</volume>(<issue>5</issue>):<fpage>851</fpage>–<lpage>69</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bib/bbw068" xlink:type="simple">10.1093/bib/bbw068</ext-link></comment> <object-id pub-id-type="pmid">27473064</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gawehn</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hiss</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>G</given-names></name>. <article-title>Deep Learning in Drug Discovery</article-title>. <source>Mol Inform</source>. <year>2016</year>;<volume>35</volume>(<issue>1</issue>):<fpage>3</fpage>–<lpage>14</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/minf.201501008" xlink:type="simple">10.1002/minf.201501008</ext-link></comment> <object-id pub-id-type="pmid">27491648</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hinton</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Osindero</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Teh</surname> <given-names>YW</given-names></name>. <article-title>A fast learning algorithm for deep belief nets</article-title>. <source>Neural Comput</source>. <year>2006</year>;<volume>18</volume>(<issue>7</issue>):<fpage>1527</fpage>–<lpage>54</lpage>. WOS:000237698100002. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco.2006.18.7.1527" xlink:type="simple">10.1162/neco.2006.18.7.1527</ext-link></comment> <object-id pub-id-type="pmid">16764513</object-id></mixed-citation></ref>
<ref id="pcbi.1007129.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rogers</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hahn</surname> <given-names>M</given-names></name>. <article-title>Extended-Connectivity Fingerprints</article-title>. <source>Journal of Chemical Information and Modeling</source>. <year>2010</year>;<volume>50</volume>(<issue>5</issue>):<fpage>742</fpage>–<lpage>54</lpage>. WOS:000277911600004. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/ci100050t" xlink:type="simple">10.1021/ci100050t</ext-link></comment> <object-id pub-id-type="pmid">20426451</object-id></mixed-citation></ref>
<ref id="pcbi.1007129.ref022"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Peng W, Chan KCC, You ZH, editors. Large-scale prediction of drug-target interactions from deep representations. 2016 International Joint Conference on Neural Networks (IJCNN); 2016 24–29 July 2016.</mixed-citation></ref>
<ref id="pcbi.1007129.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tian</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Shao</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Guan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>S</given-names></name>. <article-title>Boosting compound-protein interaction prediction by deep learning</article-title>. <source>Methods</source>. <year>2016</year>;<volume>110</volume>:<fpage>64</fpage>–<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.ymeth.2016.06.024" xlink:type="simple">10.1016/j.ymeth.2016.06.024</ext-link></comment> <object-id pub-id-type="pmid">27378654</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ozturk</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Ozgur</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ozkirimli</surname> <given-names>E</given-names></name>. <article-title>DeepDTA: deep drug-target binding affinity prediction</article-title>. <source>Bioinformatics</source>. <year>2018</year>;<volume>34</volume>(<issue>17</issue>):<fpage>i821</fpage>–<lpage>i9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/bty593" xlink:type="simple">10.1093/bioinformatics/bty593</ext-link></comment> <object-id pub-id-type="pmid">30423097</object-id>; PubMed Central PMCID: PMC6129291.</mixed-citation></ref>
<ref id="pcbi.1007129.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Davis</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Hunt</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Herrgard</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ciceri</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wodicka</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Pallares</surname> <given-names>G</given-names></name>, <etal>et al</etal>. <article-title>Comprehensive analysis of kinase inhibitor selectivity</article-title>. <source>Nat Biotechnol</source>. <year>2011</year>;<volume>29</volume>(<issue>11</issue>):<fpage>1046</fpage>–<lpage>51</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nbt.1990" xlink:type="simple">10.1038/nbt.1990</ext-link></comment> <object-id pub-id-type="pmid">22037378</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Szwajda</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Shakyawar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Xu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Hintsanen</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wennerberg</surname> <given-names>K</given-names></name>, <etal>et al</etal>. <article-title>Making sense of large-scale kinase inhibitor bioactivity data sets: a comparative and integrative analysis</article-title>. <source>J Chem Inf Model</source>. <year>2014</year>;<volume>54</volume>(<issue>3</issue>):<fpage>735</fpage>–<lpage>43</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/ci400709d" xlink:type="simple">10.1021/ci400709d</ext-link></comment> <object-id pub-id-type="pmid">24521231</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nascimento</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Prudencio</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Costa</surname> <given-names>IG</given-names></name>. <article-title>A multiple kernel learning algorithm for drug-target interaction prediction</article-title>. <source>BMC Bioinformatics</source>. <year>2016</year>;<volume>17</volume>:<fpage>46</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s12859-016-0890-3" xlink:type="simple">10.1186/s12859-016-0890-3</ext-link></comment> <object-id pub-id-type="pmid">26801218</object-id>; PubMed Central PMCID: PMC4722636.</mixed-citation></ref>
<ref id="pcbi.1007129.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>He</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Heidemeyer</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ban</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Cherkasov</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ester</surname> <given-names>M</given-names></name>. <article-title>SimBoost: a read-across approach for predicting drug-target binding affinities using gradient boosting machines</article-title>. <source>J Cheminform</source>. <year>2017</year>;<volume>9</volume>(<issue>1</issue>):<fpage>24</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s13321-017-0209-z" xlink:type="simple">10.1186/s13321-017-0209-z</ext-link></comment> <object-id pub-id-type="pmid">29086119</object-id>; PubMed Central PMCID: PMC5395521.</mixed-citation></ref>
<ref id="pcbi.1007129.ref029"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Law</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Knox</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Djoumbou</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Jewison</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Guo</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>Y</given-names></name>, <etal>et al</etal>. <article-title>DrugBank 4.0: shedding new light on drug metabolism</article-title>. <source>Nucleic Acids Res</source>. <year>2014</year>;<volume>42</volume>(Database issue):<fpage>D1091</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkt1068" xlink:type="simple">10.1093/nar/gkt1068</ext-link></comment> <object-id pub-id-type="pmid">24203711</object-id>; PubMed Central PMCID: PMC3965102.</mixed-citation></ref>
<ref id="pcbi.1007129.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Southan</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sharman</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Benson</surname> <given-names>HE</given-names></name>, <name name-style="western"><surname>Faccenda</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Pawson</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Alexander</surname> <given-names>SP</given-names></name>, <etal>et al</etal>. <article-title>The IUPHAR/BPS Guide to PHARMACOLOGY in 2016: towards curated quantitative interactions between 1300 protein targets and 6000 ligands</article-title>. <source>Nucleic Acids Res</source>. <year>2016</year>;<volume>44</volume>(<issue>D1</issue>):<fpage>D1054</fpage>–<lpage>68</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkv1037" xlink:type="simple">10.1093/nar/gkv1037</ext-link></comment> <object-id pub-id-type="pmid">26464438</object-id>; PubMed Central PMCID: PMC4702778.</mixed-citation></ref>
<ref id="pcbi.1007129.ref031"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanehisa</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Furumichi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Tanabe</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sato</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Morishima</surname> <given-names>K</given-names></name>. <article-title>KEGG: new perspectives on genomes, pathways, diseases and drugs</article-title>. <source>Nucleic Acids Res</source>. <year>2017</year>;<volume>45</volume>(<issue>D1</issue>):<fpage>D353</fpage>–<lpage>D61</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkw1092" xlink:type="simple">10.1093/nar/gkw1092</ext-link></comment> <object-id pub-id-type="pmid">27899662</object-id>; PubMed Central PMCID: PMC5210567.</mixed-citation></ref>
<ref id="pcbi.1007129.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gunther</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kuhn</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Dunkel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Campillos</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Senger</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Petsalaki</surname> <given-names>E</given-names></name>, <etal>et al</etal>. <article-title>SuperTarget and Matador: resources for exploring drug-target relationships</article-title>. <source>Nucleic Acids Res</source>. <year>2008</year>;<volume>36</volume>(Database issue):<fpage>D919</fpage>–<lpage>22</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkm862" xlink:type="simple">10.1093/nar/gkm862</ext-link></comment> <object-id pub-id-type="pmid">17942422</object-id>; PubMed Central PMCID: PMC2238858.</mixed-citation></ref>
<ref id="pcbi.1007129.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Sun</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Guan</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zheng</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zhou</surname> <given-names>S</given-names></name>. <article-title>Improving compound-protein interaction prediction by building up highly credible negative samples</article-title>. <source>Bioinformatics</source>. <year>2015</year>;<volume>31</volume>(<issue>12</issue>):<fpage>i221</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btv256" xlink:type="simple">10.1093/bioinformatics/btv256</ext-link></comment> <object-id pub-id-type="pmid">26072486</object-id>; PubMed Central PMCID: PMC4765858.</mixed-citation></ref>
<ref id="pcbi.1007129.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Bryant</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Cheng</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gindulyte</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Shoemaker</surname> <given-names>BA</given-names></name>, <etal>et al</etal>. <article-title>PubChem BioAssay: 2017 update</article-title>. <source>Nucleic Acids Res</source>. <year>2017</year>;<volume>45</volume>(<issue>D1</issue>):<fpage>D955</fpage>–<lpage>D63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkw1118" xlink:type="simple">10.1093/nar/gkw1118</ext-link></comment> <object-id pub-id-type="pmid">27899599</object-id>; PubMed Central PMCID: PMC5210581.</mixed-citation></ref>
<ref id="pcbi.1007129.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bento</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Gaulton</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hersey</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Bellis</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Chambers</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Davies</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>The ChEMBL bioactivity database: an update</article-title>. <source>Nucleic Acids Res</source>. <year>2014</year>;<volume>42</volume>(Database issue):<fpage>D1083</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkt1031" xlink:type="simple">10.1093/nar/gkt1031</ext-link></comment> <object-id pub-id-type="pmid">24214965</object-id>; PubMed Central PMCID: PMC3965067.</mixed-citation></ref>
<ref id="pcbi.1007129.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname> <given-names>TF</given-names></name>, <name name-style="western"><surname>Waterman</surname> <given-names>MS</given-names></name>. <article-title>Identification of common molecular subsequences</article-title>. <source>J Mol Biol</source>. <year>1981</year>;<volume>147</volume>(<issue>1</issue>):<fpage>195</fpage>–<lpage>7</lpage>. <object-id pub-id-type="pmid">7265238</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Efron</surname> <given-names>B.</given-names></name> <article-title>Estimating the Error Rate of a Prediction Rule: Improvement on Cross-Validation</article-title>. <source>Journal of the American Statistical Association</source>. <year>1983</year>;<volume>78</volume>(<issue>382</issue>):<fpage>316</fpage>–<lpage>31</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/01621459.1983.10477973" xlink:type="simple">10.1080/01621459.1983.10477973</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1007129.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>You</surname> <given-names>ZH</given-names></name>, <name name-style="western"><surname>Chan</surname> <given-names>KCC</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>PW</given-names></name>. <article-title>Predicting Protein-Protein Interactions from Primary Protein Sequences Using a Novel Multi-Scale Local Feature Representation Scheme and the Random Forest</article-title>. <source>Plos One</source>. <year>2015</year>;<volume>10</volume>(<issue>5</issue>). WOS:000354049700088.</mixed-citation></ref>
<ref id="pcbi.1007129.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Finn</surname> <given-names>RD</given-names></name>, <name name-style="western"><surname>Bateman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Clements</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Coggill</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Eberhardt</surname> <given-names>RY</given-names></name>, <name name-style="western"><surname>Eddy</surname> <given-names>SR</given-names></name>, <etal>et al</etal>. <article-title>Pfam: the protein families database</article-title>. <source>Nucleic Acids Res</source>. <year>2014</year>;<volume>42</volume>(Database issue):<fpage>D222</fpage>–<lpage>30</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkt1223" xlink:type="simple">10.1093/nar/gkt1223</ext-link></comment> <object-id pub-id-type="pmid">24288371</object-id>; PubMed Central PMCID: PMC3965110.</mixed-citation></ref>
<ref id="pcbi.1007129.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Desaphy</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bret</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Rognan</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Kellenberger</surname> <given-names>E</given-names></name>. <article-title>sc-PDB: a 3D-database of ligandable binding sites—10 years on</article-title>. <source>Nucleic Acids Res</source>. <year>2015</year>;<volume>43</volume>(Database issue):<fpage>D399</fpage>–<lpage>404</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gku928" xlink:type="simple">10.1093/nar/gku928</ext-link></comment> <object-id pub-id-type="pmid">25300483</object-id>; PubMed Central PMCID: PMC4384012.</mixed-citation></ref>
<ref id="pcbi.1007129.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Benjamini</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hochberg</surname> <given-names>Y</given-names></name>. <article-title>Controlling the False Discovery Rate—a Practical and Powerful Approach to Multiple Testing</article-title>. <source>J Roy Stat Soc B Met</source>. <year>1995</year>;<volume>57</volume>(<issue>1</issue>):<fpage>289</fpage>–<lpage>300</lpage>. WOS:A1995QE45300017.</mixed-citation></ref>
<ref id="pcbi.1007129.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pettersen</surname> <given-names>EF</given-names></name>, <name name-style="western"><surname>Goddard</surname> <given-names>TD</given-names></name>, <name name-style="western"><surname>Huang</surname> <given-names>CC</given-names></name>, <name name-style="western"><surname>Couch</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Greenblatt</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Meng</surname> <given-names>EC</given-names></name>, <etal>et al</etal>. <article-title>UCSF Chimera—a visualization system for exploratory research and analysis</article-title>. <source>J Comput Chem</source>. <year>2004</year>;<volume>25</volume>(<issue>13</issue>):<fpage>1605</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/jcc.20084" xlink:type="simple">10.1002/jcc.20084</ext-link></comment> <object-id pub-id-type="pmid">15264254</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname> <given-names>LW</given-names></name>, <name name-style="western"><surname>Clardy</surname> <given-names>J</given-names></name>. <article-title>Chemical inducers of dimerization: the atomic structure of FKBP12-FK1012A-FKBP12</article-title>. <source>Bioorg Med Chem Lett</source>. <year>1998</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>6</lpage>. <object-id pub-id-type="pmid">9871618</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Underwood</surname> <given-names>KW</given-names></name>, <name name-style="western"><surname>Parris</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Federico</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Mosyak</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Czerwinski</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Shane</surname> <given-names>T</given-names></name>, <etal>et al</etal>. <article-title>Catalytically active MAP KAP kinase 2 structures in complex with staurosporine and ADP reveal differences with the autoinhibited enzyme</article-title>. <source>Structure</source>. <year>2003</year>;<volume>11</volume>(<issue>6</issue>):<fpage>627</fpage>–<lpage>36</lpage>. <object-id pub-id-type="pmid">12791252</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van der Maaten</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>G</given-names></name>. <article-title>Visualizing Data using t-SNE</article-title>. <source>J Mach Learn Res</source>. <year>2008</year>;<volume>9</volume>:<fpage>2579</fpage>–<lpage>605</lpage>. WOS:000262637600007.</mixed-citation></ref>
<ref id="pcbi.1007129.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berman</surname> <given-names>HM</given-names></name>, <name name-style="western"><surname>Westbrook</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Feng</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Gilliland</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bhat</surname> <given-names>TN</given-names></name>, <name name-style="western"><surname>Weissig</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>The Protein Data Bank</article-title>. <source>Nucleic Acids Res</source>. <year>2000</year>;<volume>28</volume>(<issue>1</issue>):<fpage>235</fpage>–<lpage>42</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/28.1.235" xlink:type="simple">10.1093/nar/28.1.235</ext-link></comment> <object-id pub-id-type="pmid">10592235</object-id>; PubMed Central PMCID: PMC102472.</mixed-citation></ref>
<ref id="pcbi.1007129.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Malhotra</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Karanicolas</surname> <given-names>J</given-names></name>. <article-title>When Does Chemical Elaboration Induce a Ligand To Change Its Binding Mode?</article-title> (vol 60, pg 128, 2017). <source>Journal of Medicinal Chemistry</source>. <year>2017</year>;<volume>60</volume>(<issue>13</issue>):<fpage>5940</fpage>–. WOS:000405764900046. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/acs.jmedchem.7b00868" xlink:type="simple">10.1021/acs.jmedchem.7b00868</ext-link></comment> <object-id pub-id-type="pmid">28653841</object-id></mixed-citation></ref>
<ref id="pcbi.1007129.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boutet</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Lieberherr</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tognolli</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schneider</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bansal</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Bridge</surname> <given-names>AJ</given-names></name>, <etal>et al</etal>. <article-title>UniProtKB/Swiss-Prot, the Manually Annotated Section of the UniProt KnowledgeBase: How to Use the Entry View</article-title>. <source>Methods Mol Biol</source>. <year>2016</year>;<volume>1374</volume>:<fpage>23</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-1-4939-3167-5_2" xlink:type="simple">10.1007/978-1-4939-3167-5_2</ext-link></comment> <object-id pub-id-type="pmid">26519399</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niijima</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Shiraishi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Okuno</surname> <given-names>Y</given-names></name>. <article-title>Dissecting kinase profiling data to predict activity and understand cross-reactivity of kinase inhibitors</article-title>. <source>J Chem Inf Model</source>. <year>2012</year>;<volume>52</volume>(<issue>4</issue>):<fpage>901</fpage>–<lpage>12</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1021/ci200607f" xlink:type="simple">10.1021/ci200607f</ext-link></comment> <object-id pub-id-type="pmid">22414491</object-id>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref050"><label>50</label><mixed-citation publication-type="other" xlink:type="simple">Landrum G, Kelley B, Tosco P, sriniker, gedeck, NadineSchneider, et al. rdkit/rdkit: 2018_03_1 (Q1 2018) Release. 2018. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1222070" xlink:type="simple">10.5281/zenodo.1222070</ext-link></comment></mixed-citation></ref>
<ref id="pcbi.1007129.ref051"><label>51</label><mixed-citation publication-type="other" xlink:type="simple">Clevert D-A, Unterthiner T, Hochreiter S. Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). ArXiv e-prints [Internet]. 2015 November 01, 2015. Available from: <ext-link ext-link-type="uri" xlink:href="https://ui.adsabs.harvard.edu/#abs/2015arXiv151107289C" xlink:type="simple">https://ui.adsabs.harvard.edu/#abs/2015arXiv151107289C</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref052"><label>52</label><mixed-citation publication-type="other" xlink:type="simple">Chollet F. Keras. GitHub repository. 2015.</mixed-citation></ref>
<ref id="pcbi.1007129.ref053"><label>53</label><mixed-citation publication-type="other" xlink:type="simple">Glorot X, Bengio Y. Understanding the difficulty of training deep feedforward neural networks. In: Yee Whye T, Mike T, editors. Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics; Proceedings of Machine Learning Research: PMLR; 2010. p. 249–56.</mixed-citation></ref>
<ref id="pcbi.1007129.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kingma</surname> <given-names>DP</given-names></name>, <name name-style="western"><surname>Ba</surname> <given-names>J</given-names></name>. <article-title>Adam: A Method for Stochastic Optimization</article-title>. <source>ArXiv e-prints [Internet]</source>. <year>2014</year> <month>December</month> <day>1</day>, <volume>2014</volume>; <fpage>1412</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://adsabs.harvard.edu/abs/2014arXiv1412.6980K" xlink:type="simple">http://adsabs.harvard.edu/abs/2014arXiv1412.6980K</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Srivastava</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Hinton</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Krizhevsky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sutskever</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Salakhutdinov</surname> <given-names>R</given-names></name>. <article-title>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</article-title>. <source>J Mach Learn Res</source>. <year>2014</year>;<volume>15</volume>:<fpage>1929</fpage>–<lpage>58</lpage>. WOS:000344638300002.</mixed-citation></ref>
<ref id="pcbi.1007129.ref056"><label>56</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gal</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Ghahramani</surname> <given-names>Z</given-names></name>. <article-title>A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</article-title>. <source>ArXiv e-prints [Internet]</source>. <year>2015</year> <month>December</month> <volume>01</volume>, <fpage>2015</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="https://ui.adsabs.harvard.edu/#abs/2015arXiv151205287G" xlink:type="simple">https://ui.adsabs.harvard.edu/#abs/2015arXiv151205287G</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioffe</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Szegedy</surname> <given-names>C</given-names></name>. <article-title>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</article-title>. <source>ArXiv e-prints [Internet]</source>. <year>2015</year> <month>February</month> <volume>01</volume>, <fpage>2015</fpage>. Available from: <ext-link ext-link-type="uri" xlink:href="https://ui.adsabs.harvard.edu/#abs/2015arXiv150203167I" xlink:type="simple">https://ui.adsabs.harvard.edu/#abs/2015arXiv150203167I</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1007129.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ng</surname> <given-names>A.</given-names></name> <article-title>Sparse autoencoder</article-title>. <source>CS294A Lecture notes</source> <year>2011</year>;<volume>72</volume>.</mixed-citation></ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article article-type="review-article" dtd-version="1.1d3" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.3000043</article-id>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-18-00570</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Primer</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Animal studies</subject><subj-group><subject>Experimental organism systems</subject><subj-group><subject>Model organisms</subject><subj-group><subject>Rats</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Model organisms</subject><subj-group><subject>Rats</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Animal studies</subject><subj-group><subject>Experimental organism systems</subject><subj-group><subject>Animal models</subject><subj-group><subject>Rats</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Amniotes</subject><subj-group><subject>Mammals</subject><subj-group><subject>Rodents</subject><subj-group><subject>Rats</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Learning and memory</subject><subj-group><subject>Learning</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Chemistry</subject><subj-group><subject>Chemical compounds</subject><subj-group><subject>Organic compounds</subject><subj-group><subject>Amines</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Dopamine</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Chemistry</subject><subj-group><subject>Organic chemistry</subject><subj-group><subject>Organic compounds</subject><subj-group><subject>Amines</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Dopamine</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Neurochemistry</subject><subj-group><subject>Neurotransmitters</subject><subj-group><subject>Biogenic amines</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Dopamine</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurochemistry</subject><subj-group><subject>Neurotransmitters</subject><subj-group><subject>Biogenic amines</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Dopamine</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Hormones</subject><subj-group><subject>Catecholamines</subject><subj-group><subject>Dopamine</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Acoustics</subject><subj-group><subject>Acoustic signals</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Behavior</subject><subj-group><subject>Animal behavior</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Zoology</subject><subj-group><subject>Animal behavior</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognition</subject><subj-group><subject>Decision making</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Amniotes</subject><subj-group><subject>Mammals</subject><subj-group><subject>Primates</subject><subj-group><subject>Monkeys</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Learning what to approach</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5976-2013</contrib-id>
<name name-style="western">
<surname>Eshel</surname>
<given-names>Neir</given-names>
</name>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4879-1935</contrib-id>
<name name-style="western">
<surname>Steinberg</surname>
<given-names>Elizabeth E.</given-names>
</name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, California, United States of America</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">neshel@stanford.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>11</day>
<month>10</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<month>10</month>
<year>2018</year>
</pub-date>
<volume>16</volume>
<issue>10</issue>
<elocation-id>e3000043</elocation-id>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Eshel, Steinberg</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.3000043"/>
<related-article ext-link-type="uri" id="related001" related-article-type="companion" xlink:href="info:doi/10.1371/journal.pbio.2004015" xlink:type="simple">
<article-title>Manipulating the revision of reward value during the intertrial interval increases sign tracking and dopamine release</article-title>
</related-article>
<abstract>
<p>Most decisions share a common goal: maximize reward and minimize punishment. Achieving this goal requires learning which choices are likely to lead to favorable outcomes. Dopamine is essential for this process, enabling learning by signaling the difference between what we expect to get and what we actually get. Although all animals appear to use this dopamine prediction error circuit, some do so more than others, and this neural heterogeneity correlates with individual variability in behavior. In this issue of <italic>PLOS Biology</italic>, Lee and colleagues show that manipulating a simple task parameter can bias the animals’ behavioral strategy and modulate dopamine release, implying that how we learn is just as flexible as what we learn.</p>
</abstract>
<funding-group>
<funding-statement>The authors received no specific funding for this work.</funding-statement>
</funding-group>
<counts>
<fig-count count="2"/>
<table-count count="0"/>
<page-count count="7"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-10-23</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<p>Learning the value of objects in the environment is critical for survival. Some mushrooms are deadly; others provide sustenance. Rain in the dry season can be a harbinger of life, while in a monsoon, it means heading for cover. How do animals learn these values and adapt them over time? One of the most common ways is through trial and error. As we explore our environment, we make predictions about the value of stimuli around us. If outcomes match our predictions, there is no need to adapt. If outcomes are different, we use that discrepancy to improve our predictions for the future. This difference between actual and expected outcome is known as prediction error, and it turns out to be crucial for learning in animals [<xref ref-type="bibr" rid="pbio.3000043.ref001">1</xref>–<xref ref-type="bibr" rid="pbio.3000043.ref003">3</xref>] as well as machines [<xref ref-type="bibr" rid="pbio.3000043.ref004">4</xref>,<xref ref-type="bibr" rid="pbio.3000043.ref005">5</xref>]. As befitting such a conserved learning mechanism, the brain has developed a fine-tuned system to encode it.</p>
<p>In the 1990s, Schultz and colleagues [<xref ref-type="bibr" rid="pbio.3000043.ref006">6</xref>,<xref ref-type="bibr" rid="pbio.3000043.ref007">7</xref>] recorded monkey dopamine (DA) neurons and discovered a curious response. When monkeys received an unexpected reward, such as a drop of juice, DA neurons became excited. If animals received the same reward but fully expected it, DA neurons showed no response. Instead, DA neurons fired to the earliest reliable predictor of the reward, typically a sound or picture that indicated juice was coming soon. Finally, if the reward was expected but never materialized, DA neurons dipped below their baseline firing rate at precisely the moment when the reward was anticipated. Together, these results imply that DA neurons encode the difference between actual and expected reward—in other words, reward prediction error (RPE), the precise signal already known to facilitate learning.</p>
<p>The link between DA and RPE has been replicated and extended numerous times in a host of species and tasks (for review see [<xref ref-type="bibr" rid="pbio.3000043.ref008">8</xref>]). Notably, modern neuroscience tools have confirmed that prediction error neurons are indeed dopaminergic [<xref ref-type="bibr" rid="pbio.3000043.ref009">9</xref>] and have revealed a local circuit in the ventral tegmental area that is partially responsible for calculating the RPE signal [<xref ref-type="bibr" rid="pbio.3000043.ref010">10</xref>]. Furthermore, causal manipulations have demonstrated that both positive [<xref ref-type="bibr" rid="pbio.3000043.ref011">11</xref>] and negative [<xref ref-type="bibr" rid="pbio.3000043.ref012">12</xref>] DA RPEs are sufficient to cause associative learning.</p>
<p>While RPE signaling may represent the dominant population response [<xref ref-type="bibr" rid="pbio.3000043.ref013">13</xref>], as more investigators began to study DA and reinforcement learning, it became apparent that DA neurons also encoded other signals. In rats trained to associate an audio–visual stimulus (insertion of a metal lever) with the delivery of a food pellet into a nearby receptacle, an intriguing relationship was found between heterogeneity in DA signaling and individual variability in behavior (<xref ref-type="fig" rid="pbio.3000043.g001">Fig 1</xref>) [<xref ref-type="bibr" rid="pbio.3000043.ref014">14</xref>]. Some rats, termed “sign-trackers,” readily approached and engaged with the reward-predictive lever cue, even though this behavior had no effect on subsequent reward delivery. Other rats, termed “goal-trackers,” used the lever only to time entry into the receptacle in anticipation of food; otherwise, they ignored the lever. Strikingly, these behavioral strategies were characterized by distinct DA responses: DA RPE signals were observed only in sign-trackers. For goal-trackers, cue-evoked DA release was weak, and the DA response to expected reward failed to decline, even when the rats had clearly learned the cue–reward association. Furthermore, pharmacological blockade of DA signaling disrupted the sign-tracking response but had no effect on goal tracking. These data suggest that individual differences in allocating attention and attributing value to meaningful stimuli may be driven, at least in part, by endogenous variation in the function of midbrain DA neurons.</p>
<fig id="pbio.3000043.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.3000043.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Behavioral variability and DA response.</title>
<p>Hungry rats perform a task in which the appearance of a lever predicts food delivery several seconds later. When the lever is presented, some rats, termed sign-trackers (left), immediately approach the lever, while other rats, termed goal-trackers (right), approach the food cup instead. When reward is delivered, all rats approach the food cup. Previous work has demonstrated different patterns of DA release for these two groups: sign-trackers exhibit large DA release to the lever but not the reward, while goal-trackers show small but persistent DA responses to the lever and the reward. Both the behavioral and the neural differences between these groups have been interpreted to reflect the relative weights of two learning systems: model free and model based (see text). When model-free learning predominates, rats sign track; when model-based learning predominates, they goal track. DA, dopamine.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000043.g001" xlink:type="simple"/>
</fig>
<p>The empirical finding that stimuli can acquire different motivational properties in individuals trained on the same task is difficult to explain computationally with DA RPEs. To address this problem, Lesaint and colleagues [<xref ref-type="bibr" rid="pbio.3000043.ref015">15</xref>] recently proposed a model that builds on previous efforts in two important ways. Typically, reinforcement learning algorithms use RPEs to drive learning about the value of states [<xref ref-type="bibr" rid="pbio.3000043.ref016">16</xref>], not discrete stimuli. The Sign-Tracking and Goal-Tracking (STGT) model instead uses RPEs to create factored representations in which the value of stimuli can be adjusted independently, enabling the lever and food cup to acquire distinct motivational properties.</p>
<p>The second key advance is that values calculated by multiple learning systems are integrated as a weighted sum instead of relying exclusively on a value derived from RPEs. Given the wide range of situations that humans and other animals encounter in complex, unpredictable environments, it is unlikely that a single learning system can optimally address all potential problems. The STGT model leverages two previously described systems, termed model free and model based [<xref ref-type="bibr" rid="pbio.3000043.ref017">17</xref>,<xref ref-type="bibr" rid="pbio.3000043.ref018">18</xref>]. Model-free systems learn the value of actions and events through trial and error and store this information for later use. When the same stimuli are encountered again, past experience serves as a guide to estimate future outcomes. In contrast, model-based systems draw on an internal model of the world to make cognitive predictions of future events by forward inference. Model-based systems are able to flexibly generate goal-directed choices based on prospective assessment of the consequences of events or actions, without those consequences actually having to be experienced. Model-free and model-based learning systems offer complementary advantages and are thought to be implemented by distinct neural circuits [<xref ref-type="bibr" rid="pbio.3000043.ref019">19</xref>]. Notably, DA RPEs are ideally suited to drive model-free learning.</p>
<p>The STGT model integrates stimulus values computed by model-free and model-based systems, with individual variation determining the weight assigned to each component. For sign-trackers, the DA-dependent model-free system dominates, assigning greater value to the lever that perfectly predicts reward. Goal-trackers preferentially rely on the DA-independent model-based system, which infers the optimal behavior to maximize reward and favors approach to the location where it will appear. Intermediate behavioral phenotypes are easily explained as a balanced weighting of values computed by the two systems.</p>
<p>In this issue of <italic>PLOS Biology</italic>, Lee and colleagues [<xref ref-type="bibr" rid="pbio.3000043.ref020">20</xref>] test a specific hypothesis from the STGT model: changing the intertrial interval (ITI) will modulate DA signaling and bias animals between sign tracking and goal tracking (<xref ref-type="fig" rid="pbio.3000043.g002">Fig 2</xref>). The logic goes like this: the longer the ITI, the more times an animal might visit the food cup between trials, when there is no food available. Each time this happens, DA neurons encode a negative RPE, and the value of the food cup goes down. Eventually, the food cup loses its salience to the animal, and the animal becomes more likely to sign-track, approaching the lever rather than the food cup. After all, the lever is more reliable at signaling reward: it always predicts food delivery, while the food cup often does not. Mirroring the behavior, DA neurons might show large bursts of activity both when the lever is presented—denoting the lever’s increased value to the animal—and when the food cup actually contains food, since this has become surprising. All of these predictions are reversed if the ITI is short and the animal has limited opportunity to visit an empty food cup.</p>
<fig id="pbio.3000043.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.3000043.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Experimental predictions.</title>
<p>In this issue of <italic>PLOS Biology</italic>, Lee and colleagues randomized rats to short or long ITIs and measured behavior and dopamine release. They predicted that with a long ITI, rats would have more opportunities to engage with an empty food cup, causing repeated negative dopamine responses and biasing the animals toward a model-free, sign-tracking approach. In contrast, short ITIs would bias the animals toward a model-based, goal-tracking approach. ITI, intertrial interval.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.3000043.g002" xlink:type="simple"/>
</fig>
<p>The experiment was simple: on each trial, a lever was presented for 8 s, followed by pellet delivery into the food cup. Some animals then waited 60 s for the next trial to begin, while others had to wait 120 s. As expected, Lee and colleagues found that rats randomized to the 120-s ITI were more likely to sign-track (i.e., approach the lever), while rats randomized to the 60-s ITI were more likely to goal-track (i.e., approach the food cup). This was particularly apparent at the beginning of each trial; after 4 s, the two groups behaved similarly. While the rats were performing the task, the authors used fast-scan cyclic voltammetry to measure a proxy of DA release in the nucleus accumbens and found that the long-ITI group showed significantly higher DA release to both the lever and the food cup compared to the short-ITI group. In fact, the short-ITI group did not show any significant DA response to the reward after learning. These results correlated with the amount of time the rats interacted with the food cup during the ITI: the more time rats spent with the food cup during the ITI, the higher the DA release to both the lever and the food cup. These changes in behavior and DA release developed over a similar time course, implying that they either drive each other or that they are both driven by a common factor.</p>
<p>Together, Lee and colleagues show that a simple manipulation—changing the amount of time between trials—can modulate behavior and DA release in the nucleus accumbens. Based on the STGT model, the authors interpret their results as reflecting interactions with an empty food cup between trials, triggering a lower estimate of the food cup’s value, and biasing the rats toward a model-free, sign-tracking approach. Curiously, when the rats were nudged toward sign-tracking behavior, their DA responses did not recapitulate the sign-tracking pattern observed by Flagel and colleagues [<xref ref-type="bibr" rid="pbio.3000043.ref014">14</xref>], with reward responses decreasing over time. Similarly, when the rats were nudged toward goal-tracking behavior, the DA responses did not show the sustained reward response one might have expected from pure goal-trackers [<xref ref-type="bibr" rid="pbio.3000043.ref014">14</xref>]. In both cases, DA release was a hybrid of the two patterns. This demonstrates that sign tracking and goal tracking are not hardwired and unchanging; rather, these tendencies arise from specific interactions the animals have with stimuli in a task. By the same logic, it is unlikely that the DA-dependent model-free system is ever completely offline; instead, animals give this system more or less weight depending on their experience and needs. The simple one-to-one relationship between DA release and behavioral strategy turns out to be much more complex.</p>
<p>These results suggest a number of important future directions. For example, to shore up the correlations between food cup interactions and DA responses (<xref ref-type="fig" rid="pbio.3000043.g002">Fig 2</xref>), investigators might consider removing the food cup entirely during the ITI [<xref ref-type="bibr" rid="pbio.3000043.ref021">21</xref>]. If the STGT interpretation is correct, this should abolish any effect of ITI on the rats’ behavior. If behavioral differences remain, other interpretations must be sought—for example, long waiting times might simply increase the salience of all stimuli, regardless of interactions with those stimuli in the meantime. Another fruitful approach might be a cross-over design, in which rats experience both ITI lengths at different points in the experiment. Is the effect strong enough to shift an individual rat back and forth between sign tracking and goal tracking? Higher resolution, trial-by-trial measurements of DA (e.g., through extracellular recording) might also be crucial to explore the complicated temporal dynamics of behavior on this task. Finally, causal manipulations of the DA circuit, especially through temporally specific means such as optogenetics, would go a long way toward demonstrating that patterns of DA activity actually control behavior in this task, rather than simply reflect it.</p>
<p>For the field more generally, numerous fascinating questions remain open. Where in the brain do model-based and model-free learning occur, and what determines the relative weight between them [<xref ref-type="bibr" rid="pbio.3000043.ref019">19</xref>]? How are RPEs calculated in the first place [<xref ref-type="bibr" rid="pbio.3000043.ref022">22</xref>]? Is DA the only relevant circuit for RPE-driven model-free learning, or are there redundant circuits, for example, in the cerebellum [<xref ref-type="bibr" rid="pbio.3000043.ref023">23</xref>]? What are the genetic or environmental factors that bias some animals to sign-track and others to goal-track under equivalent testing conditions? What relationship does this phenomenon have to disorders of learning or habit, such as OCD or addiction? Finally, emerging evidence from multiple species indicates that a subset of DA neurons is activated by unpleasant or painful stimuli [<xref ref-type="bibr" rid="pbio.3000043.ref024">24</xref>–<xref ref-type="bibr" rid="pbio.3000043.ref026">26</xref>]. Is there undiscovered individual variability in behavior or DA activity within the aversive domain? Should aversive DA signals be integrated into computational frameworks for reward learning, or do these represent entirely separate computations? These questions will take concerted effort across many labs and multiple years, but they may hold the key to some of the most fundamental questions in neuroscience: how we learn about rewards and punishments and how this process breaks down in neuropsychiatric disease.</p>
<p>Zooming out even further, it is important to note Lee and colleagues’ general approach. They studied a computational model of an interesting physiological phenomenon, developed a specific hypothesis from that model, and then collected new data to test this hypothesis directly. What they found partially validated the model but also brought up new and unanticipated questions. Regardless of the specific results, this is the scientific method at its purest, and it should be celebrated.</p>
</body>
<back>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>DA</term>
<def><p>dopamine</p></def>
</def-item>
<def-item><term>ITI</term>
<def><p>intertrial interval</p></def>
</def-item>
<def-item><term>STGT</term>
<def><p>Sign Tracking and Goal Tracking</p></def>
</def-item>
<def-item><term>RPE</term>
<def><p>reward prediction error</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.3000043.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bush</surname> <given-names>RR</given-names></name>, <name name-style="western"><surname>Mosteller</surname> <given-names>F</given-names></name>. <article-title>A mathematical model for simple learning</article-title>. <source>Psychol Rev</source>. <year>1951</year>;<volume>58</volume>: <fpage>313</fpage>–<lpage>323</lpage>. <object-id pub-id-type="pmid">14883244</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kamin</surname> <given-names>L</given-names></name>. <article-title>Selective association and conditioning</article-title>. <source>Fundamental issues in associative learning</source>. <year>1969</year>. pp. <fpage>42</fpage>–<lpage>64</lpage>.</mixed-citation></ref>
<ref id="pbio.3000043.ref003"><label>3</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Rescorla</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Wagner</surname> <given-names>AR</given-names></name>. <chapter-title>A Theory of Pavlovian Conditioning: Variations in the Effectiveness of Reinforcement and Nonreinforcement</chapter-title>. In: <name name-style="western"><surname>Black</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Prokasy</surname> <given-names>W</given-names></name>, editors. <publisher-name>Classical conditioning II: current research and theory</publisher-name>. <year>1972</year>. pp. <fpage>64</fpage>–<lpage>99</lpage>.</mixed-citation></ref>
<ref id="pbio.3000043.ref004"><label>4</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <source>Reinforcement learning: An introduction</source>. <publisher-name>Cambridge Univ Press</publisher-name>; <year>1998</year>.</mixed-citation></ref>
<ref id="pbio.3000043.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Silver</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schrittwieser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Simonyan</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Antonoglou</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Huang</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Guez</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Mastering the game of Go without human knowledge</article-title>. <source>Nature</source>. <year>2017</year>;<volume>550</volume>: <fpage>354</fpage>–<lpage>359</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature24270" xlink:type="simple">10.1038/nature24270</ext-link></comment> <object-id pub-id-type="pmid">29052630</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mirenowicz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Importance of unpredictability for reward responses in primate dopamine neurons</article-title>. <source>J Neurophysiol</source>. <year>1994</year>;<volume>72</volume>: <fpage>1024</fpage>–<lpage>1027</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1994.72.2.1024" xlink:type="simple">10.1152/jn.1994.72.2.1024</ext-link></comment> <object-id pub-id-type="pmid">7983508</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>. <year>1997</year>;<volume>275</volume>: <fpage>1593</fpage>–<lpage>1599</lpage>. <object-id pub-id-type="pmid">9054347</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Stauffer</surname> <given-names>WR</given-names></name>, <name name-style="western"><surname>Lak</surname> <given-names>A</given-names></name>. <article-title>The phasic dopamine signal maturing: from reward via behavioural activation to formal economic utility</article-title>. <source>Curr Opin Neurobiol</source>. <year>2017</year>;<volume>43</volume>: <fpage>139</fpage>–<lpage>148</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2017.03.013" xlink:type="simple">10.1016/j.conb.2017.03.013</ext-link></comment> <object-id pub-id-type="pmid">28390863</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cohen</surname> <given-names>JY</given-names></name>, <name name-style="western"><surname>Haesler</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Vong</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Lowell</surname> <given-names>BB</given-names></name>, <name name-style="western"><surname>Uchida</surname> <given-names>N</given-names></name>. <article-title>Neuron-type-specific signals for reward and punishment in the ventral tegmental area</article-title>. <source>Nature</source>. <year>2012</year>;<volume>482</volume>: <fpage>85</fpage>–<lpage>88</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature10754" xlink:type="simple">10.1038/nature10754</ext-link></comment> <object-id pub-id-type="pmid">22258508</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eshel</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Bukwich</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rao</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Hemmelder</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Tian</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Uchida</surname> <given-names>N</given-names></name>. <article-title>Arithmetic and local circuitry underlying dopamine prediction errors</article-title>. <source>Nature</source>. <year>2015</year>;<volume>525</volume>: <fpage>243</fpage>–<lpage>246</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature14855" xlink:type="simple">10.1038/nature14855</ext-link></comment> <object-id pub-id-type="pmid">26322583</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Steinberg</surname> <given-names>EE</given-names></name>, <name name-style="western"><surname>Keiflin</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Boivin</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Witten</surname> <given-names>IB</given-names></name>, <name name-style="western"><surname>Deisseroth</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Janak</surname> <given-names>PH</given-names></name>. <article-title>A causal link between prediction errors, dopamine neurons and learning</article-title>. <source>Nat Neurosci</source>. <year>2013</year>; <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.3413" xlink:type="simple">10.1038/nn.3413</ext-link></comment> <object-id pub-id-type="pmid">23708143</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chang</surname> <given-names>CY</given-names></name>, <name name-style="western"><surname>Esber</surname> <given-names>GR</given-names></name>, <name name-style="western"><surname>Marrero-Garcia</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Yau</surname> <given-names>H-J</given-names></name>, <name name-style="western"><surname>Bonci</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Schoenbaum</surname> <given-names>G</given-names></name>. <article-title>Brief optogenetic inhibition of dopamine neurons mimics endogenous negative reward prediction errors</article-title>. <source>Nat Neurosci</source>. <year>2016</year>;<volume>19</volume>: <fpage>111</fpage>–<lpage>116</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4191" xlink:type="simple">10.1038/nn.4191</ext-link></comment> <object-id pub-id-type="pmid">26642092</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eshel</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Tian</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bukwich</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Uchida</surname> <given-names>N</given-names></name>. <article-title>Dopamine neurons share common response function for reward prediction error</article-title>. <source>Nat Neurosci</source>. <year>2016</year>;<volume>19</volume>: <fpage>479</fpage>–<lpage>486</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4239" xlink:type="simple">10.1038/nn.4239</ext-link></comment> <object-id pub-id-type="pmid">26854803</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Flagel</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Mayo</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Czuj</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Willuhn</surname> <given-names>I</given-names></name>, <etal>et al</etal>. <article-title>A selective role for dopamine in stimulus-reward learning</article-title>. <source>Nature</source>. <year>2011</year>;<volume>469</volume>: <fpage>53</fpage>–<lpage>57</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature09588" xlink:type="simple">10.1038/nature09588</ext-link></comment> <object-id pub-id-type="pmid">21150898</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lesaint</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Sigaud</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Flagel</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Khamassi</surname> <given-names>M</given-names></name>. <article-title>Modelling Individual Differences in the Form of Pavlovian Conditioned Approach Responses: A Dual Learning Systems Approach with Factored Representations</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>: <fpage>e1003466</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003466" xlink:type="simple">10.1371/journal.pcbi.1003466</ext-link></comment> <object-id pub-id-type="pmid">24550719</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gläscher</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>. <article-title>States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>66</volume>: <fpage>585</fpage>–<lpage>595</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2010.04.016" xlink:type="simple">10.1016/j.neuron.2010.04.016</ext-link></comment> <object-id pub-id-type="pmid">20510862</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>: <fpage>1704</fpage>–<lpage>1711</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1560" xlink:type="simple">10.1038/nn1560</ext-link></comment> <object-id pub-id-type="pmid">16286932</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Berridge</surname> <given-names>KC</given-names></name>. <article-title>Model-based and model-free Pavlovian reward learning: revaluation, revision, and revelation</article-title>. <source>Cogn Affect Behav Neurosci</source>. <year>2014</year>;<volume>14</volume>: <fpage>473</fpage>–<lpage>492</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3758/s13415-014-0277-8" xlink:type="simple">10.3758/s13415-014-0277-8</ext-link></comment> <object-id pub-id-type="pmid">24647659</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>O’Doherty</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Cockburn</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Pauli</surname> <given-names>WM</given-names></name>. <article-title>Learning, Reward, and Decision Making</article-title>. <source>Annu Rev Psychol</source>. <year>2017</year>;<volume>68</volume>: <fpage>73</fpage>–<lpage>100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-psych-010416-044216" xlink:type="simple">10.1146/annurev-psych-010416-044216</ext-link></comment> <object-id pub-id-type="pmid">27687119</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gentry</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Bissonette</surname> <given-names>GB</given-names></name>, <name name-style="western"><surname>Herman</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Mallon</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Bryden</surname> <given-names>DW</given-names></name>, <etal>et al</etal>. <article-title>Manipulating the revision of reward value during the intertrial interval increases sign tracking and dopamine release</article-title>. <source>PLoS Biol</source>. <year>2018</year>;<volume>16</volume>(<issue>9</issue>):<fpage>e2004015</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.2004015" xlink:type="simple">10.1371/journal.pbio.2004015</ext-link></comment></mixed-citation></ref>
<ref id="pbio.3000043.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lesaint</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Sigaud</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Flagel</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Khamassi</surname> <given-names>M</given-names></name>. <article-title>Experimental predictions drawn from a computational model of sign-trackers and goal-trackers</article-title>. <source>J Physiol Paris</source>. <year>2015</year>;<volume>109</volume>: <fpage>78</fpage>–<lpage>86</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jphysparis.2014.06.001" xlink:type="simple">10.1016/j.jphysparis.2014.06.001</ext-link></comment> <object-id pub-id-type="pmid">24954026</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Watabe-Uchida</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Eshel</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Uchida</surname> <given-names>N</given-names></name>. <article-title>Neural Circuitry of Reward Prediction Error</article-title>. <source>Annu Rev Neurosci</source>. <year>2017</year>;<volume>40</volume>: <fpage>373</fpage>–<lpage>394</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-neuro-072116-031109" xlink:type="simple">10.1146/annurev-neuro-072116-031109</ext-link></comment> <object-id pub-id-type="pmid">28441114</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wagner</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Savall</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Schnitzer</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Luo</surname> <given-names>L</given-names></name>. <article-title>Cerebellar granule cells encode the expectation of reward</article-title>. <source>Nature</source>. <year>2017</year>;<volume>544</volume>: <fpage>96</fpage>–<lpage>100</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature21726" xlink:type="simple">10.1038/nature21726</ext-link></comment> <object-id pub-id-type="pmid">28321129</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Matsumoto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>. <article-title>Two types of dopamine neuron distinctly convey positive and negative motivational signals</article-title>. <source>Nature</source>. <year>2009</year>;<volume>459</volume>: <fpage>837</fpage>–<lpage>841</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature08028" xlink:type="simple">10.1038/nature08028</ext-link></comment> <object-id pub-id-type="pmid">19448610</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hennigan</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>D’Ardenne</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>McClure</surname> <given-names>SM</given-names></name>. <article-title>Distinct midbrain and habenula pathways are involved in processing aversive events in humans</article-title>. <source>J Neurosci</source>. <year>2015</year>;<volume>35</volume>: <fpage>198</fpage>–<lpage>208</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0927-14.2015" xlink:type="simple">10.1523/JNEUROSCI.0927-14.2015</ext-link></comment> <object-id pub-id-type="pmid">25568114</object-id></mixed-citation></ref>
<ref id="pbio.3000043.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Menegas</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Babayan</surname> <given-names>BM</given-names></name>, <name name-style="western"><surname>Uchida</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Watabe-Uchida</surname> <given-names>M</given-names></name>. <article-title>Opposite initialization to novel cues in dopamine signaling in ventral and posterior striatum in mice</article-title>. <source>Elife</source>. <year>2017</year>;<volume>6</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.21886" xlink:type="simple">10.7554/eLife.21886</ext-link></comment> <object-id pub-id-type="pmid">28054919</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
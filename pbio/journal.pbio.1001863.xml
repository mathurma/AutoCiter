<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id><journal-title-group>
<journal-title>PLoS Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PBIOLOGY-D-14-00304</article-id>
<article-id pub-id-type="doi">10.1371/journal.pbio.1001863</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Perspective</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Medicine and health sciences</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Science policy</subject></subj-group></article-categories>
<title-group>
<article-title>Distinguishing between Exploratory and Confirmatory Preclinical Research Will Improve Translation</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Kimmelman</surname><given-names>Jonathan</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Mogil</surname><given-names>Jeffrey S.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Dirnagl</surname><given-names>Ulrich</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="aff" rid="aff5"><sup>5</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Studies of Translation, Ethics, and Medicine (STREAM), Biomedical Ethics Unit, Experimental Medicine, McGill University, Montreal, Quebec, Canada</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Department of Psychology and Alan Edwards Centre for Research on Pain, McGill University, Montreal, Quebec, Canada</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Departments of Neurology and Experimental Neurology, Center for Stroke Research Berlin, and Excellence Cluster NeuroCure Charité – Universitätsmedizin Berlin, Berlin, Germany</addr-line></aff>
<aff id="aff4"><label>4</label><addr-line>German Center for Neurodegeneration Research (DZNE), partner site Berlin, Germany</addr-line></aff>
<aff id="aff5"><label>5</label><addr-line>Center for Cardiovascular Diseases (DZHK), partner site Berlin, Germany</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Jones</surname><given-names>David R.</given-names></name>
<role>Academic Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Leicester, United Kingdom</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">jonathan.kimmelman@mcgill.ca</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>5</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>20</day><month>5</month><year>2014</year></pub-date>
<volume>12</volume>
<issue>5</issue>
<elocation-id>e1001863</elocation-id><permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Kimmelman et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract abstract-type="toc"><sec>
<title/>
<p>Kimmelman and colleagues argue that the key to improving preclinical research lies in distinguishing between two different modes of research: exploratory vs. confirmatory.</p>
</sec></abstract>
<abstract>
<p>Preclinical researchers confront two overarching agendas related to drug development: selecting interventions amid a vast field of candidates, and producing rigorous evidence of clinical promise for a small number of interventions. We suggest that each challenge is best met by two different, complementary modes of investigation. In the first (exploratory investigation), researchers should aim at generating robust pathophysiological theories of disease. In the second (confirmatory investigation), researchers should aim at demonstrating strong and reproducible treatment effects in relevant animal models. Each mode entails different study designs, confronts different validity threats, and supports different kinds of inferences. Research policies should seek to disentangle the two modes and leverage their complementarity. In particular, policies should discourage the common use of exploratory studies to support confirmatory inferences, promote a greater volume of confirmatory investigation, and customize design and reporting guidelines for each mode.</p>
</abstract>
<funding-group><funding-statement>This work was funded by Canadian Institutes of Health Research (EOG 111391). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="4"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>The past few years have witnessed growing consternation over the way researchers perform and report preclinical investigations of new drugs. The vast majority of drugs advanced into trials never recapitulate safety and efficacy observed in animal models, and these failures exact a heavy toll on trial volunteers, the research enterprise, and health care systems via higher drug prices. Because many preclinical studies poorly address internal validity threats <xref ref-type="bibr" rid="pbio.1001863-vanderWorp1">[1]</xref>, fail attempts at replication <xref ref-type="bibr" rid="pbio.1001863-Steward1">[2]</xref>, are not published <xref ref-type="bibr" rid="pbio.1001863-Sena1">[3]</xref>, or provide exaggerated estimates of clinical utility, numerous stakeholders are urging reforms in the way preclinical research is performed <xref ref-type="bibr" rid="pbio.1001863-Landis1">[4]</xref>.</p>
<p>We would like to offer a cautionary perspective on these initiatives. We suggest that the ostensibly poor performance of many preclinical studies may in fact reflect strengths and intrinsic properties of what we call “exploratory investigation”—roughly, studies aimed at generating robust pathophysiological theories of disease. Policies aimed at improving translation should strive to preserve the extraordinary power of exploratory studies, which represent the majority of preclinical studies <xref ref-type="bibr" rid="pbio.1001863-Mogil1">[5]</xref>, while promoting a separate mode of clinical trial-like preclinical research, which we call “confirmatory” studies—that is, studies aimed at demonstrating strong and reproducible treatment effects in relevant animal models. We close by describing some ways of capitalizing on the complementarity of the two modes.</p>
</sec><sec id="s2">
<title>Exploratory Versus Confirmatory Research</title>
<p>Clinical translation of novel interventional strategies confronts two overarching challenges. First, researchers must negotiate a virtually unbounded landscape of potential targets, drugs, doses, and treatment regimens. A key task is to develop the theories, measurement techniques, and evidence for selecting a manageable number of interventions to carry forward. Second, clinical development is enormously expensive and exposes patients to unproven and possibly toxic interventions. Another key task of preclinical research is thus to produce evidence that is sufficiently compelling to warrant the economic and moral costs of clinical development.</p>
<p>Overcoming these two challenges necessitates different modes of investigation. The first set of challenges is best met by studies that operate in the <italic>exploratory</italic> mode. We use “exploratory” to capture something broader than what is generally meant in statistics. In our conception, exploratory studies will aim primarily at developing pathophysiological theories that enable pursuit of different approaches. Exploratory studies tend to consist of a package of small and flexible experiments using different methodologies, including molecular and cellular analyses. These individual experiments may or may not employ inferential statistics. Exploratory studies are often driven by a series of hypotheses that are either loosely articulated or that evolve over the course of sequential experiments. Often, exploratory studies include tests of an intervention's efficacy against disease in live animals as a way of validating the pathophysiological theories (“efficacy studies”). Neither the sequence of individual experiments in exploratory studies, nor details of their design (including sample size, since effect sizes may be unknown), is necessarily established at the outset of investigation.</p>
<p>The second set of challenges is best overcome by studies that operate in a <italic>confirmatory</italic> mode. Such studies will resemble adequately powered clinical trials, and consist mainly of “efficacy studies” that use rigid and pre-specified designs, <italic>a priori</italic> stated hypotheses, prolonged durations, and the most clinically relevant assays and endpoints available. These studies aim less at elaborating theories or mechanisms of a drug's action than rigorously testing a drug's clinical potential and restricting the advance of ineffective interventions advanced into clinical testing. Exploratory studies are a complement to confirmatory studies in that the former generates precisely articulated hypotheses about drug effects that can be put to “crucial testing” in the latter before clinical development.</p>
<p>Currently, the vast majority of preclinical studies more closely resemble exploratory studies, although a small but growing number of studies operate in a confirmatory mode. These different orientations carry important imperatives for the design, reporting, error tendencies, and application of preclinical studies. What may be an inferential strength for exploratory study can be a hindrance or even a fatal flaw for confirmatory studies and vice versa. Policies and practices aimed at improving clinical translation should recognize at least four major contrasts between the two modes of investigation.</p>
</sec><sec id="s3">
<title>Implications for Design and Valid Interpretation</title>
<p>The first difference has already been noted: whereas exploratory studies should mainly aim at deriving or testing theoretical claims, confirmatory studies should test clinical utility of new interventions. Since theories are not directly observable, they are tested by assembling corroboratory evidence across different lines of experimentation. This theoretical orientation in preclinical research is reflected in the fact that a good part of the acreage in publications is devoted to molecular or cellular analyses (e.g., gene expression, immunohistochemistry, electrophysiology), not efficacy studies. Spreading proof across different lines of experiment—a process called “conceptual replication” <xref ref-type="bibr" rid="pbio.1001863-Schmidt1">[6]</xref>—has several consequences for predictive value. On the one hand, threats to the validity of theoretical claims driving a preclinical study are mitigated—though not eliminated—by conceptual replications. On the other hand, therapeutic claims arising from efficacy studies contained in the exploratory package will be prone to larger random and systematic variation: such studies invest less in any single experiment, and therefore employ smaller sample sizes and less fastidious designs. In contrast, because confirmatory studies “bet the house” on a single, pivotal efficacy study and measurement technique, there is more at stake scientifically in minimizing random and systematic error.</p>
<p>Second, whereas exploratory studies should place a premium on sensitivity (i.e., detecting all strategies that might be useful), confirmatory studies should be more concerned with specificity (i.e., excluding all strategies that will prove useless in clinical trials). This is because the task of exploration is to catch a small number of promising theories, targets, compounds, doses, or variants of a target indication against a large field. However, in many areas of drug development, the prior probability of discovering useful strategies is extraordinarily low. This means that even in the ideal, where exploratory studies have very high sensitivity <italic>and</italic> specificity, most candidates that are declared promising will represent false positives. Since there are large financial and human costs for advancing these false positives into trials, the task of confirmation is to eliminate “false positives” that are captured in exploration. Further, the agonizingly low positive predictive value of exploratory studies may have as much to do with base rates as it does with bias.</p>
<p>Third, use of small sample sizes for efficacy experiments contained in exploratory studies may lead to large random variation that produces the appearance of bias even in its absence. This dynamic, known as the “winner's curse” <xref ref-type="bibr" rid="pbio.1001863-Button1">[7]</xref>, reflects the fact that research in the exploratory mode will often test many different strategies in parallel, and this is only feasible if small sample sizes are used. As a consequence of random variation alone, some experiments will produce larger effects that regress to the mean if replicated. In contrast, confirmatory studies should employ sufficiently large sample sizes as to minimize the effect of random variation, such that dwindling effect sizes on replication may be symptomatic of publication bias rather than natural regression.</p>
<p>Last, exploratory studies often involve testing interventions alongside techniques used to measure their effects. In contrast, methods should be well established when an intervention is tested in confirmatory studies. Assays for testing pathophysiological responses, or the probative value of biomarkers, or skills for performing a behavioral test may be still in development at the point of exploratory investigation. One example of this is uncertainty surrounding techniques for testing drugs that target cancer stem cells. Here, standard assays for testing the clinical promise of cancer drugs are almost useless, yet there is little consensus about which assays to use instead <xref ref-type="bibr" rid="pbio.1001863-Shackleton1">[8]</xref>. Another example might be where a graduate student conducts experiments before having mastered the requisite manual skills. As a consequence of uncertainty surrounding measurement, exploratory researchers encounter difficulty discriminating informative and uninformative findings: “positive” findings may be attributable to assay artefacts; “negative” findings may reflect defects in the measurement tools, choice of the wrong treatment regimen, or suboptimal experimenter skill. Since the value of uninformative findings for the broader research community is limited, the absence of firm rules for discrimination legitimately confounds decisions about what findings to publish and how to interpret them. Any blanket proscription against “hiding” data risks obscuring truly interesting findings amid a large volume of studies that the experimenter knows to be uninformative to the broader research community: “practice runs,” experiments on miscalibrated instruments, or findings using methods that are later discovered to be error prone. On the other hand, where researchers have grounds for confidence in the regimens for testing, nonpublication of negative findings represents a demonstrable breach of scientific integrity. This will tend to be a much greater concern in confirmatory testing, since measurement techniques tend to be more established in that setting.</p>
<p>In sum, there are many factors that explain why preclinical studies are prone to producing “false positives” or outcome patterns that give the appearance of bias. Yet to some degree, these reflect strengths of exploratory research, such as its ability to narrow the field of intervention candidates using an economy of resources, to select among myriad pathophysiological theories, and to hone techniques of measuring clinical promise. These are necessary precursors to the sorts of rigorous confirmatory experiments that should be used to justify clinical development.</p>
</sec><sec id="s4">
<title>Improving Design and Interpretation of Preclinical Research</title>
<p>Though some of the above contrasts may appear obvious to anyone with a basic understanding of statistics and experimental design, they are not adequately reflected in many reforms urged by critics of preclinical research—e.g., calls for using larger sample sizes, “gold standard” animal models, or independent replication <xref ref-type="bibr" rid="pbio.1001863-Henderson1">[9]</xref>,<xref ref-type="bibr" rid="pbio.1001863-Howells1">[10]</xref>. Some proposals entail non-trivial burdens such as restructuring laboratory practices, writing up and/or depositing inconclusive findings, or using larger sample sizes, and hence undermine the economy of exploratory activities. Reforms are more likely to have a transformative impact on drug development if researchers can capitalize on the complementary properties of both exploratory <italic>and</italic> translational studies, and tailor study design, reporting, and application of findings accordingly. To that end, we offer three sets of recommendations.</p>
<p>First, all protocols and publications should pre-specify whether they are “exploratory” or “confirmatory” studies, with the latter category reserved for studies that aim at demonstrating promise of clinical utility for an intervention. We note that other commentators have made similar calls <xref ref-type="bibr" rid="pbio.1001863-Wagenmakers1">[11]</xref>,<xref ref-type="bibr" rid="pbio.1001863-Willmann1">[12]</xref>. Journal editors and funding agencies should promote this demarcation by requiring it for submitted manuscripts and grants. Standards for review should then hinge on the way investigators classify studies. For instance, confirmatory studies should be held to internal and construct validity standards similar to those used in clinical trials: studies should address confounders like sample or observation bias, use pre-specified statistical analyses, match the experimental design to the conditions where findings are expected to be applied, and report findings in ways that enable meaningful interpretation by non-experts. Large sample sizes, fastidious experimental conditions, and conservative statistical analyses may be counterproductive for exploration. Instead, exploratory studies should be evaluated on the basis of whether findings using disparate and methodologically sound lines of investigation are coherent and fecund.</p>
<p>Second, the research community should devise mechanisms for coupling confirmatory studies to exploratory ones. As noted above, only a small minority of preclinical studies are put to confirmatory testing. Once intervention strategies are discovered in exploration, those wishing to launch clinical development should be expected to run, or at least reference, stand-alone confirmatory studies before launching trials <xref ref-type="bibr" rid="pbio.1001863-Howells1">[10]</xref>,<xref ref-type="bibr" rid="pbio.1001863-Dirnagl1">[13]</xref>. One way of promoting this would be for oversight bodies—Research Ethics Boards, public funding agencies, and regulators—to condition approval of any trial delivering putatively active drug doses on positive preclinical confirmatory studies. Like clinical trials, such studies should prospectively register, adhere to (and preferably publish) protocols, and report findings according to standards and regardless of effect sizes. As human trial findings are much more informative when they are embedded within a web of related findings <xref ref-type="bibr" rid="pbio.1001863-Kimmelman1">[14]</xref>, medical journals should require that investigators deposit confirmatory preclinical findings when they accept for publication trials involving efficacy primary endpoints.</p>
<p>Third, many recommendations and mechanisms for improving preclinical study design are mainly suited for confirmatory studies. Some recommendations—like calls for more regular replication or simple measures to reduce factors like observer bias (e.g., randomization and assessor blinding) —are sensible across both modes of investigation. Others seem more suited for confirmatory studies and may be counterproductive for exploratory studies. Use of larger sample sizes and prospective registration, for example, involve additional investments, infrastructure, and compliance burdens. The former means sacrifice of more animals than necessary to identify promising strategies. The latter would be very taxing for researchers, since public disclosures early on in a research program would invite free-riding; moreover, registration of exploratory studies offers little to a research community if researchers themselves have significant doubts about measurement techniques. Perhaps the largest validity threats in exploratory research reside not in efficacy studies, but in the withholding of findings that disrupt the coherence of theoretical claims, in the assembly of theories that build on a series of falsely positive experimental results, or in the nonperformance of replication experiments because of insufficient incentive. The research community has much to gain from guidelines and mechanisms that specifically address such tendencies in exploration. One place to start would be to establish data ontologies and databases for deposition of exploratory findings so that discordant findings can be accessed. Another would be the creation of mechanisms that encourage confirmatory studies. For example, several journals now solicit bids for replication studies from the research community, guaranteeing the winning bidder publication on successful completion of the study. Others maintain “results blind” publication categories, where reviews are based on a submitted protocol rather than effect sizes <xref ref-type="bibr" rid="pbio.1001863-Chambers1">[15]</xref>,<xref ref-type="bibr" rid="pbio.1001863-Experimental1">[16]</xref>. Journals might also encourage researchers to deposit replications or experiments that are discordant with published exploratory studies, but that are insufficient to constitute a new paper, by creating a section for very short research reports that consist of a single experiment or an attempted replication.</p>
<p>According to influential accounts of the research process, science flourishes best when researchers pursue different agendas, harboring different biases <xref ref-type="bibr" rid="pbio.1001863-Hull1">[17]</xref>. Preclinical research, in particular, entails two complimentary agendas: one is to narrow a large field of potential therapies by refining pathophysiological theories of disease, and the other is to generate reliable evidence of a therapy's clinical utility in a proxy species. Each encounters different constraints and validity threats. The key to improving preclinical research is devising practices that leverage one to the advantage of the other.</p>
</sec></body>
<back><ref-list>
<title>References</title>
<ref id="pbio.1001863-vanderWorp1"><label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van der Worp</surname><given-names>HB</given-names></name>, <name name-style="western"><surname>Howells</surname><given-names>DW</given-names></name>, <name name-style="western"><surname>Sena</surname><given-names>ES</given-names></name>, <name name-style="western"><surname>Porritt</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Rewell</surname><given-names>S</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Can animal models of disease reliably inform human studies?</article-title> <source>PLoS Med</source> <volume>7</volume>: <fpage>e1000245</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Steward1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Steward</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Popovich</surname><given-names>PG</given-names></name>, <name name-style="western"><surname>Dietrich</surname><given-names>WD</given-names></name>, <name name-style="western"><surname>Kleitman</surname><given-names>N</given-names></name> (<year>2012</year>) <article-title>Replication and reproducibility in spinal cord injury research</article-title>. <source>Exp Neurol</source> <volume>233</volume>: <fpage>597</fpage>–<lpage>605</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Sena1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sena</surname><given-names>ES</given-names></name>, <name name-style="western"><surname>van der Worp</surname><given-names>HB</given-names></name>, <name name-style="western"><surname>Bath</surname><given-names>PM</given-names></name>, <name name-style="western"><surname>Howells</surname><given-names>DW</given-names></name>, <name name-style="western"><surname>Macleod</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Publication bias in reports of animal stroke studies leads to major overstatement of efficacy</article-title>. <source>PLoS Biol</source> <volume>8</volume>: <fpage>e1000344</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Landis1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Landis</surname><given-names>SC</given-names></name>, <name name-style="western"><surname>Amara</surname><given-names>SG</given-names></name>, <name name-style="western"><surname>Asadullah</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Austin</surname><given-names>CP</given-names></name>, <name name-style="western"><surname>Blumenstein</surname><given-names>R</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>A call for transparent reporting to optimize the predictive value of preclinical research</article-title>. <source>Nature</source> <volume>490</volume>: <fpage>187</fpage>–<lpage>191</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Mogil1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mogil</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Simmonds</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Simmonds</surname><given-names>MJ</given-names></name> (<year>2009</year>) <article-title>Pain research from 1975 to 2007: a categorical and bibliometric meta-trend analysis of every Research Paper published in the journal, Pain</article-title>. <source>Pain</source> <volume>142</volume>: <fpage>48</fpage>–<lpage>58</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Schmidt1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schmidt</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Shall we really do it again? The powerful concept of replication is neglected in the social sciences</article-title>. <source>Rev Gen Psychol</source> <volume>13</volume>: <fpage>90</fpage>–<lpage>100</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Button1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Button</surname><given-names>KS</given-names></name>, <name name-style="western"><surname>Ioannidis</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Mokrysz</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Nosek</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Flint</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Power failure: why small sample size undermines the reliability of neuroscience</article-title>. <source>Nat Rev Neurosci</source> <volume>14</volume>: <fpage>365</fpage>–<lpage>378</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Shackleton1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shackleton</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Quintana</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Fearon</surname><given-names>ER</given-names></name>, <name name-style="western"><surname>Morrison</surname><given-names>SJ</given-names></name> (<year>2009</year>) <article-title>Heterogeneity in cancer: cancer stem cells versus clonal evolution</article-title>. <source>Cell</source> <volume>138</volume>: <fpage>822</fpage>–<lpage>829</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Henderson1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Henderson</surname><given-names>VC</given-names></name>, <name name-style="western"><surname>Kimmelman</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Fergusson</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Grimshaw</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>Hackam</surname><given-names>DG</given-names></name> (<year>2013</year>) <article-title>Threats to Validity in the Design and Conduct of Preclinical Efficacy Studies: A Systematic Review of Guidelines for In Vivo Animal Experiments</article-title>. <source>PLoS Med</source> <volume>10</volume>: <fpage>e1001489</fpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Howells1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Howells</surname><given-names>DW</given-names></name>, <name name-style="western"><surname>Sena</surname><given-names>ES</given-names></name>, <name name-style="western"><surname>Macleod</surname><given-names>MR</given-names></name> (<year>2014</year>) <article-title>Bringing rigour to translational medicine</article-title>. <source>Nat Rev Neurol</source> <volume>10</volume>: <fpage>37</fpage>–<lpage>43</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Wagenmakers1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wagenmakers</surname><given-names>E-J</given-names></name>, <name name-style="western"><surname>Wetzels</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Borsboom</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Maas</surname><given-names>HLJvd</given-names></name>, <name name-style="western"><surname>Kievit</surname><given-names>RA</given-names></name> (<year>2012</year>) <article-title>An agenda for purely confirmatory research</article-title>. <source>Perspect Psychol Sci</source> <volume>7</volume>: <fpage>632</fpage>–<lpage>638</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Willmann1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willmann</surname><given-names>R</given-names></name>, <name name-style="western"><surname>De Luca</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Benatar</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Grounds</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Dubach</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Enhancing translation: guidelines for standard pre-clinical experiments in mdx mice</article-title>. <source>Neuromuscul Disord</source> <volume>22</volume>: <fpage>43</fpage>–<lpage>49</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Dirnagl1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dirnagl</surname><given-names>U</given-names></name>, <name name-style="western"><surname>Hakim</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Macleod</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Fisher</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Howells</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>A concerted appeal for international cooperation in preclinical stroke research</article-title>. <source>Stroke</source> <volume>44</volume>: <fpage>1754</fpage>–<lpage>1760</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Kimmelman1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kimmelman</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>JA</given-names></name> (<year>2012</year>) <article-title>Should preclinical studies be registered?</article-title> <source>Nat Biotechnol</source> <volume>30</volume>: <fpage>488</fpage>–<lpage>489</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Chambers1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chambers</surname><given-names>CD</given-names></name> (<year>2013</year>) <article-title>Registered reports: a new publishing initiative at Cortex</article-title>. <source>Cortex</source> <volume>49</volume>: <fpage>609</fpage>–<lpage>610</lpage>.</mixed-citation>
</ref>
<ref id="pbio.1001863-Experimental1"><label>16</label>
<mixed-citation publication-type="other" xlink:type="simple">Experimental Psychology (2014) Instructions to authors. Experimental psychology. Boston: Hogrefe Publishing.</mixed-citation>
</ref>
<ref id="pbio.1001863-Hull1"><label>17</label>
<mixed-citation publication-type="other" xlink:type="simple">Hull DL (1988) Science as a process: an evolutionary account of the social and conceptual development of science. Chicago: University of Chicago Press.</mixed-citation>
</ref>
</ref-list></back>
</article>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005836</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-00614</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Database and informatics methods</subject><subj-group><subject>Bioinformatics</subject><subj-group><subject>Sequence analysis</subject><subj-group><subject>Sequence motif analysis</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Molecular biology</subject><subj-group><subject>Molecular biology techniques</subject><subj-group><subject>Sequencing techniques</subject><subj-group><subject>Nucleotide sequencing</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Molecular biology techniques</subject><subj-group><subject>Sequencing techniques</subject><subj-group><subject>Nucleotide sequencing</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject><subj-group><subject>Network motifs</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Molecular biology</subject><subj-group><subject>Molecular biology techniques</subject><subj-group><subject>Gene mapping</subject><subj-group><subject>Nucleotide mapping</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Molecular biology techniques</subject><subj-group><subject>Gene mapping</subject><subj-group><subject>Nucleotide mapping</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Molecular biology</subject><subj-group><subject>Molecular biology techniques</subject><subj-group><subject>Gene mapping</subject><subj-group><subject>Nucleosome mapping</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Molecular biology techniques</subject><subj-group><subject>Gene mapping</subject><subj-group><subject>Nucleosome mapping</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Database and informatics methods</subject><subj-group><subject>Bioinformatics</subject><subj-group><subject>Sequence analysis</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Artificial intelligence</subject><subj-group><subject>Artificial neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Artificial neural networks</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Artificial neural networks</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Maximum entropy methods for extracting the learned features of deep neural networks</article-title>
<alt-title alt-title-type="running-head">MaxEnt methods for deep learning interpretation</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Finnegan</surname>
<given-names>Alex</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0422-2175</contrib-id>
<name name-style="western">
<surname>Song</surname>
<given-names>Jun S.</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Department of Physics, University of Illinois, Urbana-Champaign, Urbana, Illinois, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>Carl R. Woese Institute for Genomic Biology, University of Illinois, Urbana-Champaign, Urbana, Illinois, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Ioshikhes</surname>
<given-names>Ilya</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Ottawa University, CANADA</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">songj@illinois.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>30</day>
<month>10</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="collection">
<month>10</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>10</issue>
<elocation-id>e1005836</elocation-id>
<history>
<date date-type="received">
<day>18</day>
<month>4</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>23</day>
<month>10</month>
<year>2017</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Finnegan, Song</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005836"/>
<abstract>
<p>New architectures of multilayer artificial neural networks and new methods for training them are rapidly revolutionizing the application of machine learning in diverse fields, including business, social science, physical sciences, and biology. Interpreting deep neural networks, however, currently remains elusive, and a critical challenge lies in understanding which meaningful features a network is actually learning. We present a general method for interpreting deep neural networks and extracting network-learned features from input data. We describe our algorithm in the context of biological sequence analysis. Our approach, based on ideas from statistical physics, samples from the maximum entropy distribution over possible sequences, anchored at an input sequence and subject to constraints implied by the empirical function learned by a network. Using our framework, we demonstrate that local transcription factor binding motifs can be identified from a network trained on ChIP-seq data and that nucleosome positioning signals are indeed learned by a network trained on chemical cleavage nucleosome maps. Imposing a further constraint on the maximum entropy distribution also allows us to probe whether a network is learning global sequence features, such as the high GC content in nucleosome-rich regions. This work thus provides valuable mathematical tools for interpreting and extracting learned features from feed-forward neural networks.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Deep learning is a state-of-the-art reformulation of artificial neural networks that have a long history of development. It can perform superbly well in diverse automated classification and prediction problems, including handwriting recognition, image identification, and biological pattern recognition. Its modern success can be attributed to improved training algorithms, clever network architecture, rapid explosion of available data, and advanced computing power–all of which have allowed the great expansion in the number of unknown parameters to be estimated by the model. These parameters, however, are so intricately connected through highly nonlinear functions that interpreting which essential features of given data are actually used by a deep neural network for its excellent performance has been difficult. We address this problem by using ideas from statistical physics to sample new unseen data that are likely to behave similarly to original data points when passed through the trained network. This synthetic data cloud around each original data point retains informative features while averaging out nonessential ones, ultimately allowing us to extract important network-learned features from the original data set and thus improving the human interpretability of deep learning methods. We demonstrate how our method can be applied to biological sequence analysis.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000153</institution-id>
<institution>Division of Biological Infrastructure</institution>
</institution-wrap>
</funding-source>
<award-id>1442504</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0422-2175</contrib-id>
<name name-style="western">
<surname>Song</surname>
<given-names>Jun S.</given-names>
</name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000054</institution-id>
<institution>National Cancer Institute</institution>
</institution-wrap>
</funding-source>
<award-id>R01CA163336</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0422-2175</contrib-id>
<name name-style="western">
<surname>Song</surname>
<given-names>Jun S.</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work has been supported by the National Science Foundation (DBI-1442504), the National Institutes of Health (R01CA163336), and the Founder Professorship from the Grainger Engineering Breakthroughs Initiative. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="0"/>
<page-count count="20"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-11-09</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>We use synthetic data and already published data that are publicly available from the authors of doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btw255" xlink:type="simple">10.1093/bioinformatics/btw255</ext-link>. Our source code and simulation data can be accessed at <ext-link ext-link-type="uri" xlink:href="https://github.com/jssong-lab/maxEnt" xlink:type="simple">https://github.com/jssong-lab/maxEnt</ext-link></meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<disp-quote>
<p>This is a <italic>PLOS Computational Biology</italic> Methods paper.</p>
</disp-quote>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Multilayer artificial neural networks (ANNs) are becoming increasingly important tools for predicting outcomes from complex patterns in images and diverse scientific data including biological sequences. Recent works have applied multilayer networks, also called deep learning models, to predicting transcription factor (TF) binding [<xref ref-type="bibr" rid="pcbi.1005836.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005836.ref002">2</xref>] and chromatin states [<xref ref-type="bibr" rid="pcbi.1005836.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1005836.ref005">5</xref>] from DNA sequence, greatly advancing the state-of-the-art prediction rate in these fields. The success of these multilayer networks stems from their ability to learn complex, non-linear prediction functions over the set of input sequences. The main challenge in using deep learning currently resides in the fact that the complexity of the learned function coupled with the typically large dimension of the input and parameter spaces makes it difficult to decipher which input features a network is actually learning.</p>
<p>In spite of this challenge, the rise of deep learning has spurred efforts to interpret network prediction. While interpretation methods have been proposed in the fields of computer vision and natural language processing, we focus on genomics and specifically on methods for identifying features in individual input sequences used by an ANN for classification. To the best of our knowledge, two classes of interpretation methods have been proposed to address this problem: the first class of interpretation methods measures network feature importance by expressing the change in the network output for two distinct inputs as a sum of importance values assigned to the input units that encode biological sequence. One such decomposition assigns to each input unit importance given by its term in the 1<sup>st</sup> order Taylor approximation of the change in the network output when the input units encoding a specific sequence are set to zeros. This method of assigning network importance to DNA sequence is called a Saliency Map by Lanchantin <italic>et al</italic>. [<xref ref-type="bibr" rid="pcbi.1005836.ref006">6</xref>] who adapted the method from the computer vision Saliency Map [<xref ref-type="bibr" rid="pcbi.1005836.ref007">7</xref>]. The DeepLIFT interpretation method uses an alternative approach for assigning input sequence importance based on comparing network activations elicited by the input sequences to those of a “reference” network input [<xref ref-type="bibr" rid="pcbi.1005836.ref008">8</xref>]. This approach to assigning importance has been motived as an approximation to Shapley values, which describe distribution of credit in game theory [<xref ref-type="bibr" rid="pcbi.1005836.ref009">9</xref>]. The second class of interpretation method, called <italic>in silico</italic> mutagenesis (ISM), measures changes in network output produced by simulated point mutations. Flexibility in the types of mutations performed means that ISM can, in principle, reveal the network’s dependence on sequence in detail. However, computational cost limits the number and type of progressive mutations that can be performed. As a result, to investigate learned network features using ISM, one must employ prior notions of important features to design a manageable number of sequential mutations for testing.</p>
<p>In this paper, we use the rigorous formalism of statistical physics to develop a novel method for extracting and interpreting network-learned sequence features. The method makes direct reference to the nonlinear function learned by the network by sampling a maximum entropy distribution over all possible sequences, anchored at an input sequence and subject to constraints implied by the learned function and by the background nucleotide content of the genome from which the network’s input sequences are derived.</p>
<p>To extract learned features from inputs, we study two complementary quantities derived from sequences sampled from the constrained maximum entropy (MaxEnt) distribution via Markov Chain Monte Carlo (MCMC): (1) a local profile of nucleotide contents for revealing sequence motifs, and (2) a feature importance score based on the sample variance of a summary statistic for focusing on a particular sequence characteristic of interest. The latter score directly measures the effect of a global sequence feature, such as GC content, on the non-linear function learned by the network, and it can be used to rank global features, thereby answering questions about the relative importance of such features in the context of network prediction.</p>
<p>Our approach can be viewed as a compromise between the two classes of interpretation method described above, extracting features by examining several sequences, instead of just two as in the first class, and eliminating ISM’s need for <italic>a priori</italic> specification of sequential mutations. Importantly, our method is distinguished from other previous approaches in that, rather than assigning an importance score to each base of a given input sequence, our method reveals features by sampling unseen sequences that are assessed by the trained network to be similar to the original input.</p>
<p>We apply our method, termed MaxEnt interpretation, to three separate deep neural networks and compare with the first class of interpretation methods: DeepLIFT and Saliency Map. The first network is a simple yet instructive example, and it demonstrates how the DeepLIFT and Saliency Map methods can encounter difficulties, while the MaxEnt method successfully captures the logic learned by the network. The remaining two networks are trained to predict transcription factor (TF) binding activity from CTCF ChIP-seq [<xref ref-type="bibr" rid="pcbi.1005836.ref002">2</xref>] and nucleosome positioning from chemical cleavage nucleosome mapping data [<xref ref-type="bibr" rid="pcbi.1005836.ref010">10</xref>], thus putatively learning the CTCF binding motifs and nucleosome positioning signals encoded in DNA, respectively. In the motif discovery task, while all methods give good results, correctly localizing the learned CTCF motifs in most cases, our MaxEnt approach achieves better agreement with motif positions called by the conventional motif discovery programs MEME and FIMO. In the task of extracting nucleosome positioning signals, MaxEnt surpasses DeepLIFT and Saliency Mapping in detecting a learned network preference for G/C and A/T nucleotides at positions separated by 10 base pairs (bps). Furthermore, we demonstrate the use of a global sequence feature score, unique to our method, to estimate the fraction of nucleosomal sequences for which the GC content is an important feature for network classification. We do not compare with ISM because, as discussed above, it is less general than other methods and requires the specification of the types of mutations to test.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Constructing an input-specific constrained maximum entropy distribution</title>
<p>Consider a trained, multilayer feed-forward neural network that takes a length <italic>L</italic> genomic sequence as input and performs a classification task, assigning the sequence to one of <italic>K</italic> classes indexed by {0,1,…,<italic>K</italic>-1}. The network consists of a stack of layers, each of which contains a real-valued vector whose entries are called the activations of the layer’s units. The stack starts with an input layer whose activations represent the genomic sequence; activations of each subsequent layer are determined by applying a trained non-linear transformation to the proceeding layer. Activations of units in the output layer encode the predicted probabilities of the <italic>K</italic> classes, thereby assigning the input sequence to the class whose output unit activation is the largest. (<xref ref-type="supplementary-material" rid="pcbi.1005836.s001">S1 Text</xref> describes the types of layers used in this work)</p>
<p>The standard motivation behind multilayer networks is that intermediate layers may learn to recognize a hierarchy of features present in the set of inputs with features becoming more abstract with the depth of the intermediate layer. Since changes in the features detected by a layer are encoded in changes in the intermediate layer’s vector of activations, we propose that it is possible to identify learned features by looking for commonalities among the set of all input sequences that approximately preserve that layer’s vector of activations.</p>
<p>While this approach could be applied to identifying learned features of any intermediate layer, this work focuses on features learned by the penultimate layer, the layer making direct connections to the output layer. Penultimate layer features are interesting for two reasons. First, we are interested only in input sequence patterns that elicit an intermediate layer representation relevant to the classification task and discard sequence variations irrelevant to classification. Since the non-linear functions computed by intermediate layers are, in general, many-to-one mappings, one important role of a layer is to identify which differences in the preceding layer’s activations are irrelevant to the learned classification. Because intermediate layer activations are calculated from the input sequence by composing such non-linear functions, the number of identified classification-irrelevant differences in inputs should increase with the intermediate layer depth, making the penultimate layer the intermediate layer least affected by classification-irrelevant features. Second, the network output layer is either a logistic or a softmax classifier applied to penultimate activations; by uncovering features learned by the penultimate layer, we are thus finding the sequence patterns directly used by these output layer classifiers to make predictions.</p>
<p>To formalize the search for new input sequences that approximately preserve a given penultimate activation, let the vector <bold><italic>x</italic></bold><sub><bold>0</bold></sub> represent an input genomic sequence. The entries in <bold><italic>x</italic></bold><sub><bold>0</bold></sub> encode the presence of one of the nucleotides A, C, G, T at a certain position in the sequence. Let <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>) denote the vector of penultimate layer activations elicited by <bold><italic>x</italic></bold><sub><bold>0</bold></sub>. For notational convenience, assume the trained network has assigned <bold><italic>x</italic></bold><sub><bold>0</bold></sub> to the 0<sup>th</sup> class. We measure the extent to which an arbitrary input sequence <bold><italic>x</italic></bold> reproduces the penultimate activation <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>) by weighing the set of all length <italic>L</italic> genomic sequences with the probability mass function (PMF) <inline-formula id="pcbi.1005836.e001"><alternatives><graphic id="pcbi.1005836.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> that is most similar to a pattern-agnostic PMF <italic>q</italic>, subject to a constraint on the average distance to <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>). More precisely, we define
<disp-formula id="pcbi.1005836.e002">
<alternatives>
<graphic id="pcbi.1005836.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">argmin</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>∥</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mspace width="0.5em"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mspace width="0.5em"/><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow></mml:msub><mml:mo>[</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
<label>(1)</label>
</disp-formula>
where <italic>D</italic><sub><italic>KL</italic></sub>(<italic>p</italic> ‖ <italic>q</italic>) is the Kullback-Leibler (KL) divergence between <italic>p</italic> and <italic>q</italic>, <italic>E</italic><sub><bold><italic>x</italic></bold></sub> denotes expectation calculated when <bold><italic>x</italic></bold> is distributed according to <italic>p</italic>, <italic>d</italic> is a distance metric on the set of penultimate activation vectors, and <italic>D</italic> is a positive constant, with smaller values corresponding to a more exact reproduction of the activation vector <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>). The PMF <italic>q</italic> describes prior beliefs about the background nucleotide content of the genomic regions from which network inputs are derived, and the fact the <inline-formula id="pcbi.1005836.e003"><alternatives><graphic id="pcbi.1005836.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> minimizes <italic>D</italic><sub><italic>KL</italic></sub>(<italic>p</italic> ‖ <italic>q</italic>) subject to the constraint ensures that differences between <inline-formula id="pcbi.1005836.e004"><alternatives><graphic id="pcbi.1005836.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and these prior beliefs arise from the need to reproduce the sequence features encoded in <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>)<bold>.</bold> We take <italic>q</italic> be a product of <italic>L</italic> identical single nucleotide distributions with probabilities of G/C and A/T chosen to reflect the genome-wide GC content. In this case, the solution to (<xref ref-type="disp-formula" rid="pcbi.1005836.e002">1</xref>) is
<disp-formula id="pcbi.1005836.e005">
<alternatives>
<graphic id="pcbi.1005836.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mfrac><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>μ</mml:mi><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup>
</mml:math>
</alternatives>
<label>(2)</label>
</disp-formula>
where <italic>Z</italic> is a normalization constant, <italic>β</italic> is a Lagrange multiplier whose value is chosen to yield the desired value of <italic>D</italic>, <italic>N</italic>(<bold><italic>x</italic></bold>) is the number of G and C nucleotides in sequence <bold><italic>x</italic></bold>, and <inline-formula id="pcbi.1005836.e006"><alternatives><graphic id="pcbi.1005836.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> where <italic>c</italic> is the GC content of the genome (<xref ref-type="supplementary-material" rid="pcbi.1005836.s002">S2 Text</xref>). When <italic>μ</italic> = 0, <inline-formula id="pcbi.1005836.e007"><alternatives><graphic id="pcbi.1005836.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives></inline-formula> is determined solely by the learned function <bold><italic>Φ</italic></bold>, and Eq (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) is the maximum entropy distribution over all length <italic>L</italic> sequences subject to the constraint in (<xref ref-type="disp-formula" rid="pcbi.1005836.e002">1</xref>). For simplicity, we use the term MaxEnt samples to refer to the samples from <inline-formula id="pcbi.1005836.e008"><alternatives><graphic id="pcbi.1005836.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> for any value of <italic>μ</italic>.</p>
<p>We use a weighted Euclidean metric for <italic>d</italic>,
<disp-formula id="pcbi.1005836.e009">
<alternatives>
<graphic id="pcbi.1005836.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e009" xlink:type="simple"/>
<mml:math display="block" id="M9">
<mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mstyle displaystyle="false"><mml:mrow><mml:mo>∑</mml:mo></mml:mrow></mml:mstyle><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Φ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Φ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mspace width="0.15em"/><mml:msubsup><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">i</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">2</mml:mn></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>Φ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>Φ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:msup>
</mml:math>
</alternatives>
<label>(3)</label>
</disp-formula>
where our choice of <italic>W</italic><sub><italic>i</italic></sub> depends on the type of classification task. For binary classification, <italic>W</italic><sub><italic>i</italic></sub> = <italic>w</italic><sub>0,<italic>i</italic></sub>, the weight connecting the <italic>i</italic><sup>th</sup> penultimate unit to the output unit encoding the assigned class label of <bold><italic>x</italic></bold><sub><bold>0</bold></sub> (when there is only one output unit, <italic>W</italic><sub><italic>i</italic></sub> is the weight of connection to this unit). For multiclass classification, <italic>W</italic><sub><italic>i</italic></sub> = <italic>w</italic><sub>0,<italic>i</italic></sub> − <italic>w</italic><sub><italic>k</italic>,<italic>i</italic></sub>, where <italic>k</italic> ∈ {1,2,…<italic>K</italic>−1} is a user-specified class. This choice of <italic>W</italic><sub><italic>i</italic></sub> corresponds to weighting each penultimate activation by its effect on the log ratio of predicted class 0 and class <italic>k</italic> probabilities (<xref ref-type="supplementary-material" rid="pcbi.1005836.s001">S1 Text</xref>).</p>
<p>The mean distance <italic>D</italic> is an increasing function of 1/<italic>β</italic>, whose scale is set by nearest-neighbor distances among penultimate activations, as measured by the metric (<xref ref-type="disp-formula" rid="pcbi.1005836.e009">3</xref>). When <italic>β</italic> is large, <italic>D</italic> approaches 0, the PMF over the set of penultimate activations is a single spike at <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>), and <inline-formula id="pcbi.1005836.e010"><alternatives><graphic id="pcbi.1005836.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> consists of a (relatively) small number of non-zero probability masses on sequences <bold><italic>x</italic></bold> that exactly reproduce <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>). Conversely, decreasing <italic>β</italic> smooths the PMF over penultimate activations and causes <inline-formula id="pcbi.1005836.e011"><alternatives><graphic id="pcbi.1005836.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> to shift probability mass onto sequences that yield penultimate activations similar to <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>). When <italic>β</italic> = 0, <inline-formula id="pcbi.1005836.e012"><alternatives><graphic id="pcbi.1005836.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and <italic>q</italic> are identical, <italic>D</italic> is the expected distance under the distribution <italic>q</italic>, and <inline-formula id="pcbi.1005836.e013"><alternatives><graphic id="pcbi.1005836.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> contains no information on the features encoded in <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>).</p>
<p>This intuition informs one method for choosing <italic>β</italic> (and implicitly <italic>D</italic>): select <italic>β</italic> so that the PMF over the set of penultimate activations has small width relative to an empirical distribution of penultimate activations, while still assigning appreciable probability to sequences with penultimate activations near <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>). Alternatively, because a sufficiently large value of <italic>β</italic> effectively fixes the nucleotide content at certain indices in sequences sampled from <inline-formula id="pcbi.1005836.e014"><alternatives><graphic id="pcbi.1005836.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, one can examine the samples from distributions at different values of <italic>β</italic> to uncover a hierarchy of important features in <bold><italic>x</italic></bold><sub><bold><italic>o</italic></bold></sub>. We give examples of both methods in the following sections, where we sample the distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) using MCMC (Methods). <xref ref-type="fig" rid="pcbi.1005836.g001">Fig 1</xref>, illustrates the sampling of sequences <bold><italic>x</italic></bold> according to their similarity to data set element <bold><italic>x</italic></bold><sub><bold>0</bold></sub> in the space of penultimate layer activations.</p>
<fig id="pcbi.1005836.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005836.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Schematic representation of our MaxEnt interpretation method.</title>
<p>An unseen sequence <bold><italic>x</italic></bold> elicits penultimate unit activations (shaded dots in left figure) via non-linear operations of intermediate layers (illustrated as a horizontal stack of convolutional filters). The MaxEnt method for interpreting a given input sequence <bold><italic>x</italic></bold><sub><bold>0</bold></sub> assigns probability to a new sequence <bold><italic>x</italic></bold> according to its similarity to <bold><italic>x</italic></bold><sub><bold>0</bold></sub> in the space of penultimate activations. The irregular path connecting <bold><italic>x</italic></bold><sub><bold>0</bold></sub> and <bold><italic>x</italic></bold> in sequence space illustrates the steps of MCMC.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.g001" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec004">
<title>Extracting features from samples</title>
<p>We extract features of network input <bold><italic>x</italic></bold><sub><bold>0</bold></sub>, captured by penultimate activation <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>), by examining several statistics of the MCMC samples from <inline-formula id="pcbi.1005836.e015"><alternatives><graphic id="pcbi.1005836.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>. In our first example, the dimension of the input space is low enough to directly visualize the empirical distribution of samples. For higher dimensional input spaces, we summarize the distribution by plotting sample single nucleotide frequencies at each genomic index and also by examining the variance of linear combinations of nucleotide indicator variables that serve to define sequence features of interest.</p>
<p>Plots of single nucleotide frequencies reveal important features by illustrating the extent to which preserving penultimate activation forces the single nucleotide distribution of <inline-formula id="pcbi.1005836.e016"><alternatives><graphic id="pcbi.1005836.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> to be away from that of <italic>q</italic>. Large divergence of sample nucleotide frequencies from <italic>q</italic> signals importance and determines which nucleotide substitutions dramatically affect the penultimate layer representation. By contrast, if the sampled nucleotide distribution of <inline-formula id="pcbi.1005836.e017"><alternatives><graphic id="pcbi.1005836.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is similar to that of <italic>q</italic> at a given base position, and if we assume that the content of the position is independent of other positions under <inline-formula id="pcbi.1005836.e018"><alternatives><graphic id="pcbi.1005836.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula>, then this position is irrelevant for determining <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>) and the classification of <bold><italic>x</italic></bold><sub><bold>0</bold></sub>.</p>
<p>To quantify the importance of sequence features, in a way that accounts for interactions among base positions, we define an input-wide sequence feature <italic>V</italic> as a function that maps an input sequence to a weighed sum of indicator variables for specific nucleotide content:
<disp-formula id="pcbi.1005836.e019">
<alternatives>
<graphic id="pcbi.1005836.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e019" xlink:type="simple"/>
<mml:math display="block" id="M19">
<mml:mi>V</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow>
</mml:math>
</alternatives>
<label>(4)</label>
</disp-formula>
where <italic>x</italic><sub><italic>i</italic></sub> denotes the nucleotide at index <italic>i</italic> in <bold><italic>x</italic></bold>, <italic>I</italic><sub><italic>i</italic></sub>(∙) is the indicator variable for one of a set of nucleotides at index <italic>i</italic> and <italic>c</italic><sub><italic>i</italic></sub> is a real valued weight. We define the concordance of sequence <bold><italic>x</italic></bold> with the input-wide feature <italic>V</italic> to be <italic>V</italic>(<bold><italic>x</italic></bold>). For example, if we are interested in the importance of GC content, <italic>V</italic> would be the sum of indicator variables for S (G or C nucleotide) at each input index, and <bold><italic>x</italic></bold> would have large concordance with this input-wide sequence feature when it contains many G and C nucleotides.</p>
<p>To relate changes in feature concordance to changes in penultimate layer activation, let <italic>X</italic><sub><italic>v</italic></sub> denote the set of length <italic>L</italic> sequences <bold><italic>x</italic></bold>, such that <italic>V</italic>(<bold><italic>x</italic></bold>) = <italic>v</italic>. The quantity
<disp-formula id="pcbi.1005836.e020">
<alternatives>
<graphic id="pcbi.1005836.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e020" xlink:type="simple"/>
<mml:math display="block" id="M20">
<mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle><mml:mspace width="0.25em"/><mml:mrow><mml:mi>q</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mo>∑</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>∈</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mstyle><mml:mrow><mml:mi>q</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(5)</label>
</disp-formula>
is the mean value of <inline-formula id="pcbi.1005836.e021"><alternatives><graphic id="pcbi.1005836.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> under PMF <italic>q</italic>, conditioned on <italic>V</italic>(<bold><italic>x</italic></bold>) = <italic>v</italic>. The rate of decay of <italic>f</italic>(<italic>v</italic>) from its maximum measures the dependence of <inline-formula id="pcbi.1005836.e022"><alternatives><graphic id="pcbi.1005836.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> on feature concordance <italic>V</italic>(<bold><italic>x</italic></bold>). To see this, observe that when <italic>V</italic> sums indicator variables for nucleotides important in eliciting the penultimate activation <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>)<bold>,</bold> the exponential factor <inline-formula id="pcbi.1005836.e023"><alternatives><graphic id="pcbi.1005836.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> will, on average, decay as <italic>V</italic>(<bold><italic>x</italic></bold>) deviates from <italic>V</italic>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>). More rapid decay corresponds to greater importance, since in this case smaller changes in <italic>V</italic>(<bold><italic>x</italic></bold>) suffice to produce large changes in <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold>). By contrast, when <italic>V</italic> sums indicator variables for only those nucleotides unimportant in eliciting <bold><italic>Φ</italic></bold>(<bold><italic>x</italic></bold><sub><bold>0</bold></sub>), the factor <inline-formula id="pcbi.1005836.e024"><alternatives><graphic id="pcbi.1005836.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> does not decay with changes in <italic>V</italic>(<bold><italic>x</italic></bold>).</p>
<p>In <xref ref-type="supplementary-material" rid="pcbi.1005836.s002">S2 Text</xref>, we approximate the decay of <italic>f</italic> from its maximum as
<disp-formula id="pcbi.1005836.e025">
<alternatives>
<graphic id="pcbi.1005836.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e025" xlink:type="simple"/>
<mml:math display="block" id="M25">
<mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>∝</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:mi>δ</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">*</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup>
</mml:math>
</alternatives>
<label>(6)</label>
</disp-formula>
where <italic>v</italic>* maximizes <italic>f</italic>(<italic>v</italic>) and
<disp-formula id="pcbi.1005836.e026">
<alternatives>
<graphic id="pcbi.1005836.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e026" xlink:type="simple"/>
<mml:math display="block" id="M26">
<mml:mi>δ</mml:mi><mml:mo>≡</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac>
</mml:math>
</alternatives>
<label>(7)</label>
</disp-formula>
where <italic>s</italic><sup>2</sup> is the variance of <italic>V</italic>(<bold><italic>x</italic></bold>) under the PMF <inline-formula id="pcbi.1005836.e027"><alternatives><graphic id="pcbi.1005836.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> and <italic>σ</italic><sup>2</sup> is the variance of <italic>V</italic>(<bold><italic>x</italic></bold>) under PMF <italic>q</italic>. The variance <italic>s</italic><sup>2</sup> is estimated from MCMC samples while the variance <italic>σ</italic><sup>2</sup> can be calculated explicitly from <italic>q</italic>. Larger values of <italic>δ</italic> correspond to more rapid decay of <italic>f</italic>(<italic>v</italic>), signaling greater input-wide feature importance.</p>
<p>Our derivation of the proportionality (<xref ref-type="disp-formula" rid="pcbi.1005836.e025">6</xref>) requires that the marginal distributions of <italic>V</italic>(<bold><italic>x</italic></bold>) when <bold><italic>x</italic></bold> is distributed according to <italic>q</italic> or <inline-formula id="pcbi.1005836.e028"><alternatives><graphic id="pcbi.1005836.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> are approximately normal. Approximate normality of <italic>V</italic>(<bold><italic>x</italic></bold>) when <bold><italic>x</italic></bold> is distributed according to <italic>q</italic> is guaranteed by the Lindeberg version of the Central Limit Theorem, provided that <italic>V</italic> sums indicator variables at a large number of base positions with weights roughly equal in magnitude. Approximate normality of <italic>V</italic>(<bold><italic>x</italic></bold>) when <bold><italic>x</italic></bold> is distributed according to <inline-formula id="pcbi.1005836.e029"><alternatives><graphic id="pcbi.1005836.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> can be checked directly by estimating <italic>V</italic>(<bold><italic>x</italic></bold>) from MCMC samples. We have checked that these normal approximations are valid when the number of base positions considered by the function <italic>V</italic> is large, explaining our choice of the name input-wide sequence features.</p>
<p>In Application 3 below, we consider two uses of the importance measure <italic>δ</italic>. First, we choose the weights <italic>c</italic><sub><italic>i</italic></sub> and indicators <italic>I</italic><sub><italic>i</italic></sub>(∙), so that the resulting input-wide feature <italic>V</italic> measures the importance of GC content for a network predicting nucleosome positioning. Second, we use MCMC samples from (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) to find sets of weights <italic>c</italic><sub><italic>i</italic></sub> that approximately maximize <italic>δ</italic>. When <italic>V</italic> captures an important input-wide feature, the exponential factor <inline-formula id="pcbi.1005836.e030"><alternatives><graphic id="pcbi.1005836.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> in (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) should make the marginal distribution of <italic>V</italic> under <inline-formula id="pcbi.1005836.e031"><alternatives><graphic id="pcbi.1005836.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> much narrower than the marginal distribution of <italic>V</italic> under <italic>q</italic>; that is, <italic>s</italic><sup>2</sup> ≪ <italic>σ</italic><sup>2</sup>. In this case, we can thus approximate,
<disp-formula id="pcbi.1005836.e032">
<alternatives>
<graphic id="pcbi.1005836.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e032" xlink:type="simple"/>
<mml:math display="block" id="M32">
<mml:mi>δ</mml:mi><mml:mo>≈</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
<label>(8)</label>
</disp-formula>
Under this approximation, the most important features are given by the lowest variance principal components (PCs) of our MCMC samples. Examining the elements of these low variance PC vectors reveals important input-wide features.</p>
</sec>
<sec id="sec005">
<title>Application 1: Interpreting learned XOR logic</title>
<p>ANN interpretation methods, such as Saliency Map and DeepLIFT, that assign a real-valued importance score to each input unit provide intuitive pictures that are easy to understand, but must confront the challenge of summarizing learned nonlinear interactions between base positions using a base-wise score. To illustrate the practical consequences of these issues, we trained ANNs on an artificial data set of DNA dinucleotides and applied the MaxEnt, Saliency Map and DeepLIFT interpretation methods. Class labels were assigned to each of the 16 possible dinucleotides according to an XOR logic, where sequences (with positions indexed by 0 and 1) were assigned to class 0 unless one, but not both, of the following conditions was satisfied, in which case class 1 was assigned:</p>
<list list-type="bullet">
<list-item><p>sequence position 0 is W (A or T),</p></list-item>
<list-item><p>sequence position 1 is G.</p></list-item>
</list>
<p>We represented sequences with a one-hot encoding scheme and chose a simple convolutional architecture with 2 convolutional filters of stride 1 and taking a single base of the dinucleotide as input, followed by a layer of two fully connected units and then a single output unit indicating the predicted class label. Rectified-linear units (ReLU) were used throughout the network, except for the output which was modeled using a sigmoid function (<xref ref-type="supplementary-material" rid="pcbi.1005836.s001">S1 Text</xref>). We obtained 30 of these convolutional architectures trained to achieve 100% classification accuracy on the set of all possible dinucleotide inputs (Methods).</p>
<p><xref ref-type="fig" rid="pcbi.1005836.g002">Fig 2</xref> shows the results of interpretation analysis on the AA and GG inputs in class 1 for each of the 30 models achieving 100% validation accuracy. Although each network represents the same classification rule, the interpretation results of Saliency Map and DeepLIFT show model dependence in the sign of their interpretation score, indicating in some cases that a nucleotide is evidence for the correct class label and in other cases that the same nucleotide is evidence against this class label (<xref ref-type="fig" rid="pcbi.1005836.g002">Fig 2A–2D</xref>) (see <xref ref-type="supplementary-material" rid="pcbi.1005836.s003">S3 Text</xref> for description of our application of Saliency Map and DeepLIFT).</p>
<fig id="pcbi.1005836.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005836.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Interpretation of XOR network inputs.</title>
<p><bold>(A, B)</bold> Scatter plots of interpretation scores assigned to the 0<sup>th</sup> and 1<sup>st</sup> sequence position by Saliency Map and DeepLIFT interpretation, respectively, for the AA network input. Markers at the origin have size proportional to number of overlapping data points. Colors in <bold>(B)</bold> indicate DeepLIFT interpretation scores using different reference inputs (see <xref ref-type="supplementary-material" rid="pcbi.1005836.s003">S3 Text</xref>). <bold>(C, D)</bold> Same as <bold>(A, B)</bold>, respectively, but for the GG network input. <bold>(E)</bold> Density of MCMC samples from MaxEnt distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) for AA input. Densities are normalized by the most abundant dinucleotide. Green boxes highlight the set of dinucleotide inputs belonging to class 1. <bold>(F)</bold> Same as <bold>(E)</bold> but for the GG network input. All results are interpretation of the same 30 ANNs.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.g002" xlink:type="simple"/>
</fig>
<p>In contrast, our MaxEnt interpretation illuminates, in almost every case, how the trained networks implement the XOR logic defined above, indicating that the GG input is similar to CG and that the AA input is similar to any input with A or T in the 0<sup>th</sup> position and not G in the 1<sup>st</sup> position (<xref ref-type="fig" rid="pcbi.1005836.g002">Fig 2E and 2F</xref>). For this analysis, we sampled the distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) with <italic>μ</italic> = 0 and <italic>β</italic> chosen based on the distribution of penultimate layer activation associated with the 16 dinucleotide inputs (Methods). <xref ref-type="supplementary-material" rid="pcbi.1005836.s004">S1 Fig</xref> shows similar results for the other dinucleotide inputs.</p>
<p><xref ref-type="fig" rid="pcbi.1005836.g002">Fig 2</xref> highlights a key difference that distinguishes the MaxEnt interpretation approach from Salience Map and DeepLIFT. By replacing base-position scores with samples from a distribution, MaxEnt interpretation is able to capture nonlinear classification rules that escape the other methods. The cost of this extra flexibility is some additional effort in assigning meaning to the MaxEnt samples.</p>
</sec>
<sec id="sec006">
<title>Application 2: Localizing learned motifs</title>
<p>We applied MaxEnt interpretation to a network trained on a benchmark motif discovery data set constructed by [<xref ref-type="bibr" rid="pcbi.1005836.ref002">2</xref>] from ENCODE CTCF ChIP-seq data [<xref ref-type="bibr" rid="pcbi.1005836.ref011">11</xref>]. CTCF is a well-studied DNA binding protein with important transcription factor and insulator functions [<xref ref-type="bibr" rid="pcbi.1005836.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1005836.ref013">13</xref>]. In this motif discovery task, the network distinguished elements of the positive class, consisting of 101 base-pair (bp) sequences centered on ChIP-seq peaks, from elements of the negative class consisting of positive class sequences shuffled to maintain dinucleotide frequency. We represented network inputs with a one-hot encoding scheme and trained an architecture consisting of a convolutional layer of 64 convolutional filters each with a stride of 1 and taking 24 bps as input, followed by a layer of 100 units fully connected to the preceding layer and a two unit softmax output layer. ReLUs were used in all layers preceding the output (<xref ref-type="supplementary-material" rid="pcbi.1005836.s001">S1 Text</xref>). The trained network performed well, achieving a mean area under the receiver operating characteristic (AUROC) of 0.978 with standard deviation 0.001 in 5-fold cross-validation (Methods).</p>
<p>We picked a neural network trained on a random fold of the cross-validation, selected 2500 random sequences from all correctly classified CTCF-containing sequences in the test set, and applied MaxEnt, DeepLIFT and Saliency Map interpretation methods. Our application of MaxEnt to this network used <italic>β</italic> = 400, chosen by examining samples collected at a range of <italic>β′s</italic> for a few network inputs and selecting the smallest <italic>β</italic> sufficient to fix the nucleotide content at positions where MaxEnt marginal distributions signaled greatest importance. Because single nucleotide frequencies for the data set were nearly uniform (P(A) = P(T) = 0.27 and P(C) = P(G) = 0.23), we set <italic>μ</italic> = 0 when sampling from the distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>). <xref ref-type="fig" rid="pcbi.1005836.g003">Fig 3A and 3B</xref> show nucleotide frequencies as a function of base index for MCMC MaxEnt samples associated with two input sequences. In both cases, the location of the motif identified by the network was indicated by an interval of single nucleotide frequencies that diverged dramatically from the uniform distribution over nucleotides implied by the distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) for sequence locations with little effect on penultimate layer activations. Sequence logos were generated from the nucleotide frequencies on these intervals using WebLogo [<xref ref-type="bibr" rid="pcbi.1005836.ref014">14</xref>]. We confirmed that the discovered motifs in <xref ref-type="fig" rid="pcbi.1005836.g003">Fig 3A and 3B</xref> correspond to the canonical CTCF motif and its reverse complement by using the motif database querying tool Tomtom [<xref ref-type="bibr" rid="pcbi.1005836.ref015">15</xref>] (Methods, <xref ref-type="supplementary-material" rid="pcbi.1005836.s005">S2 Fig</xref>).</p>
<fig id="pcbi.1005836.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005836.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Interpretation of CTCF-bound sequences.</title>
<p><bold>(A</bold>, <bold>B</bold>) Nucleotide frequencies of MCMC samples from MaxEnt distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) for two input sequences that the ANN correctly identified as CTCF bound. Main plots correspond to sampling at <italic>β</italic> = 400; inset line plots correspond to sampling at <italic>β</italic> = 100, illustrating the multiscale nature of our interpretation method. Inset sequence logos show the called motifs, with the corresponding input sequences indicated below the horizontal axis. Colors green, blue, orange, red correspond to A, C, G, T. <bold>(C)</bold> Kernel-density smoothed distribution of relative distances between motifs called by network interpretation methods and motifs called by FIMO. Null model density is estimated by calling motif positions with uniform probability over the set of 19bp intervals contained in the 101 bp network inputs. (<bold>D)</bold> Cumulative distribution of the absolute distances from <bold>(C)</bold>. Red asterisk at (x,x+1) indicates significantly fewer Saliency Map motif calls than MaxEnt motif calls within x bp from a FIMO motif (one-sided binominal test, p &lt; 0.01)). Green asterisks indicate the similar comparison between DeepLIFT and MaxEnt motif calls.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.g003" xlink:type="simple"/>
</fig>
<p>DeepLIFT and Saliency Map interpretation of these inputs yielded visually similar results (<xref ref-type="supplementary-material" rid="pcbi.1005836.s006">S3 Fig</xref>). However, MaxEnt single nucleotide frequencies provide direct interpretation as motif position-specific scoring matrices utilized by other bioinformatics tools and thus provide advantages over Saliency Map and DeepLIFT base-wise scores.</p>
<p>To make a more global comparison of interpretation methods, we calculated the distribution of relative distances from motif positions called using each interpretation method to motif positions identified by the conventional motif discovery programs MEME and FIMO [<xref ref-type="bibr" rid="pcbi.1005836.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1005836.ref017">17</xref>]. Combined application of MEME and FIMO to the 2500 interpreted inputs found a single 19 bp consensus CTCF motif in 1652 of these input sequences (Methods). Using this motif length as a guide, we called MaxEnt motifs by calculating, for each sequence input, the KL divergence of sample nucleotide frequencies at each base from a uniform distribution and finding the 19 bp running window that has the largest average KL divergence. DeepLIFT and Saliency Map motifs were similarly called for each sequence input at the 19 bp widow with largest interpretation score (see <xref ref-type="supplementary-material" rid="pcbi.1005836.s003">S3 Text</xref> for definition). <xref ref-type="fig" rid="pcbi.1005836.g003">Fig 3C</xref> shows the empirical distribution of the signed center-to-center distances between network interpretation motifs and MEME/FIMO motifs in the 1652 sequences. <xref ref-type="fig" rid="pcbi.1005836.g003">Fig 3D</xref> shows the cumulative distribution of the same unsigned distances. MaxEnt interpretation gives significantly more motif calls within 0, 1, 2, 3 and 4 bp of MEME/FIMO motifs than Saliency Map and DeepLIFT interpretation.</p>
</sec>
<sec id="sec007">
<title>Application 3: Extracting nucleosome positioning signals</title>
<p>Finally, we tested ANN interpretation methods on a genomic data set where we expected learned sequence features to be more diffuse. We constructed a data set based on the chemical cleavage map of nucleosome dyads in <italic>S</italic>. <italic>cerevisiae</italic> [<xref ref-type="bibr" rid="pcbi.1005836.ref010">10</xref>]. Each input was a 201 bp sequence with positive class elements centered on nucleosome dyads and negative class elements centered on locations uniformly sampled from genomic regions at least 3 bps from a dyad. We chose to allow sampling of negative sequences within the 73 bps of nucleosomal DNA flanking the dyad to encourage the network to learn features that direct precise nucleosome positioning as well as those determining nucleosome occupancy.</p>
<p>Our trained network consisted of a convolutional layer with 30 filters, each with a stride of 1 and taking 6 bp windows as input, followed by a 400-unit layer with full connections and a 2-unit output softmax layer. Sigmoid activation functions were used in all layers preceding the output (<xref ref-type="supplementary-material" rid="pcbi.1005836.s001">S1 Text</xref>). The trained network performed well, achieving an AUROC of 0.956 on the test set (Methods). We applied interpretation methods to 2500 input sequences randomly selected from validation set elements corresponding to nucleosomal sequences correctly classified by the network. MaxEnt interpretation sampled the distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) using <italic>μ</italic> = −0.49 and <italic>β</italic> = 40.0. The value of <italic>μ</italic> was determined using the 38% GC content of the <italic>S</italic>. <italic>cerevisiae</italic> genome. The value of <italic>β</italic> was determined by examining the plots of nucleotide frequencies for a range of <italic>β</italic> values and selecting the largest value that permitted fluctuation in the nucleotide content at all of 201 bp. <xref ref-type="supplementary-material" rid="pcbi.1005836.s003">S3 Text</xref> describes our application of DeepLIFT and Saliency Mapping to this network.</p>
<p><xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4A</xref> shows single nucleotide frequencies of MaxEnt samples for one of the 2500 nucleosomal sequences analyzed. <xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4B and 4C</xref> show the results of DeepLIFT and Saliency Map interpretation for the same network input, respectively. This example shows that MaxEnt interpretation surpasses DeepLIFT and Saliency Mapping in capturing the importance of G/C and A/T nucleotides preferentially positioned at anti-phased 10 bp intervals. To confirm this trend across all interpreted nucleosomal sequences, we calculated for each input the Discrete Fourier Transform (DFT) of single nucleotide frequencies of MaxEnt samples, DeepLIFT interpretation scores, and Saliency Map interpretation scores (<xref ref-type="supplementary-material" rid="pcbi.1005836.s003">S3 Text</xref>). DFT represents each of these signals as a sum of sinusoidal functions, with each sinusoid described by a period, phase and amplitude of oscillation. The contribution of a sinusoid to the signal is measured by its amplitude relative to the amplitudes at all periods; we normalized the components of each DFT to account for this relative comparison (Methods). <xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4D</xref> shows the average of these normalized amplitudes over the set of all interpreted inputs, confirming that MaxEnt single nucleotide frequencies provide the strongest evidence for the learned 10bp-periodicity preference in nucleotide positioning.</p>
<fig id="pcbi.1005836.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005836.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Interpretation of nucleosome positioning signals.</title>
<p><bold>(A)</bold> Nucleotide frequencies for samples from MaxEnt distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) associated with a single nucleosomal input sequence. <bold>(B)</bold> DeepLIFT interpretation scores for the input analyzed in <bold>(A). (C)</bold> Saliency Map interpretation scores for the input analyzed in (<bold>A</bold>) (representation of DeepLIFT and Saliency Map scores uses code from [<xref ref-type="bibr" rid="pcbi.1005836.ref008">8</xref>]). <bold>(D)</bold> Normalized Fourier amplitudes of interpretation scores averaged over 2500 interpreted nucleosomal sequences correctly classified by the network. Note vertical axis is scale by maximum value.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.g004" xlink:type="simple"/>
</fig>
<p>Consistent with <xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4D</xref>, 10 bp-periodic signals were found in many individual sets of MaxEnt samples. However, <xref ref-type="supplementary-material" rid="pcbi.1005836.s007">S4 Fig</xref> shows counterexamples to this trend, highlighting that the network does not need to detect the pattern to classify a sequence as nucleosomal. <xref ref-type="supplementary-material" rid="pcbi.1005836.s007">S4 Fig</xref> also shows a plot of nucleotide frequencies averaged over the set of 2500 input nucleosomal sequences.</p>
<p>It is important to recognize that even though these plots of sample nucleotide frequencies illuminate learned features, they do not imply that the periodic features are present in individual MaxEnt samples. Indeed, it has recently been shown that most nucleosomal sequences in <italic>S</italic>. <italic>cerevisiae</italic> do not contain significant 10 bp periodicity [<xref ref-type="bibr" rid="pcbi.1005836.ref018">18</xref>]. To confirm that the MaxEnt samples produced by our method were also not individually enriched for 10 bp periodicity, we calculated the normalized Fourier spectrum of each sample separately and then averaged the amplitudes over all samples associated with the 2500 nucleosomal sequences (Methods). <xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4D</xref> shows that this Fourier amplitude at 10 bp averaged over the pooled MCMC samples is greatly suppressed relative to the Fourier amplitude of nucleotides frequencies averaged over nucleosomal sequences. In this way, MaxEnt samples capture the true nature of the 10 bp periodic feature learned by the network. That is, to be considered similar to an input nucleosomal sequence, it is enough for MaxEnt samples to possess G/C and A/T nucleotides at only <italic>some</italic> of the “hot-spots” separated by 10 bps; at the same time, averaging over these samples gives a coarse and conceptually useful representation of the learned feature.</p>
<p>It is also widely believed that nucleosomal DNA often possesses high GC content relative to the genomic background [<xref ref-type="bibr" rid="pcbi.1005836.ref019">19</xref>]; we thus explored the importance of GC content to our network’s classification. <xref ref-type="fig" rid="pcbi.1005836.g005">Fig 5A</xref> shows that, while mean GC content of MaxEnt samples generally agreed with the background 38% tuned by our choice of <italic>μ</italic>, there was also a significant positive correlation between sample mean GC content and GC content of the associated input. The correlation indicated that changes in GC content affected the penultimate layer activations to the extent that samples tended to preserve the GC enrichment or depletion of their associated input.</p>
<fig id="pcbi.1005836.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005836.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Assessing the importance of GC content for nucleosome positioning.</title>
<p><bold>(A)</bold> Distribution of GC content of 1000 network input sequences corresponding to nucleosomal DNA and the mean GC content of samples associated with these inputs. <bold>(B)</bold> Histogram of the percentiles of GC feature importance scores in the distribution of importance scores of 300 “dummy” sequence features. Histogram summarizes percentiles of GC feature importance scores for 1000 nucleosomal sequences. <bold>(C)</bold> Example of decay in variance associated with ranked principal component vectors in PCA analysis of samples from the distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.g005" xlink:type="simple"/>
</fig>
<p>To rigorously measure the importance of the GC content feature, we defined an input-wide sequence feature <italic>V</italic> that sums the indicators for G or C nucleotides at each of the central 147 bases of the network input. For comparison, we defined “dummy” input-wide features which also sum indicator variables at each of the central 147 bases of network input, but where, at each position, the set of two nucleotides for which the indicator is 1 is uniformly sampled from the list {G,C}, {G,A}, {G,T}, {C,A}, {C,T}, {A,T}. For 1000 inputs chosen at random from the 2500 analyzed, we calculated the feature importance score <italic>δ</italic>, defined in (<xref ref-type="disp-formula" rid="pcbi.1005836.e026">7</xref>), for the GC content feature <italic>V</italic> and for 300 random variables measuring dummy features. We then computed the percentile of the importance score of the GC content variable in the distribution of importance scores of the dummy feature variables for each input. <xref ref-type="fig" rid="pcbi.1005836.g005">Fig 5B</xref> shows the distribution of these percentiles, with enrichment of nucleosomal sequences near the 100<sup>th</sup> percentile; setting a threshold at the 90<sup>th</sup> percentile in the distribution of dummy feature importance scores, we estimate that GC content is a learned network feature of about 26% of the 1000 nucleosomal sequences analyzed.</p>
<p>While assigning relative importance to a chosen input-wide feature is useful, we were also interested in automatically discovering the most important input-wide features from MaxEnt samples, without prior specification of the weights <italic>c</italic><sub><italic>i</italic></sub> in (<xref ref-type="disp-formula" rid="pcbi.1005836.e019">4</xref>). For this purpose, we chose <italic>V</italic> to sum over indicator variables for G/C at each position, with the <italic>c</italic><sub><italic>i</italic></sub>’s to be determined. The variance of this <italic>V</italic>(<bold><italic>x</italic></bold>), with <bold><italic>x</italic></bold> distributed according to (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>), can be written for an arbitrary vector <bold><italic>c</italic></bold> ≡ (<italic>c</italic><sub>1</sub>,<italic>c</italic><sub>1</sub>,…,<italic>c</italic><sub><italic>L</italic></sub>)<sup><italic>T</italic></sup> of weights as
<disp-formula id="pcbi.1005836.e033">
<alternatives>
<graphic id="pcbi.1005836.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e033" xlink:type="simple"/>
<mml:math display="block" id="M33">
<mml:mi mathvariant="normal">V</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>V</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">c</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mi>S</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi>
</mml:math>
</alternatives>
</disp-formula>
where <italic>S</italic> is the covariance matrix of the indicator variables estimated from MCMC samples. Since the approximation (<xref ref-type="disp-formula" rid="pcbi.1005836.e032">8</xref>) implies that feature importance decreases with increasing variance, we seek weight vectors minimizing Var(<italic>V</italic>(<bold><italic>x</italic></bold>)) under the constraint that <bold><italic>c</italic></bold> has unit Euclidean norm. Thus, the problem of identifying low-variance input-wide features amounts to selecting low variance principal components (PCs) in Principal Component Analysis (PCA) using <italic>S</italic>. The elements of the low variance PCs then give the weights of an input-wide feature <italic>V</italic>. Moreover, because the PCs are uncorrelated with respect to <italic>S</italic>, we expect several of the low variance PCs to be interpretable. <xref ref-type="fig" rid="pcbi.1005836.g005">Fig 5C</xref> shows a sharp decrease in the variance of the input-wide features determined by PCA on MaxEnt samples for a single nucleosomal sequence. We empirically observed that this sharp drop, signaling the prominent importance of features corresponding to the lowest variance PC vectors, is typical for our samples.</p>
<p><xref ref-type="supplementary-material" rid="pcbi.1005836.s008">S5 Fig</xref> plots the weight vectors obtained from the two lowest variance PC vectors associated with the MaxEnt distribution depicted in <xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4A</xref>. The lowest variance feature concentrates on a spike at the +3 position relative to the dyad. The strong network dependence on this position is also seen in <xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4A–4C</xref>. The second lowest variance feature shows 10 bp periodicity with the weights changing sign roughly every 5 bp. While the pattern is much like that of <xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4A</xref>, it accounts for correlations in nucleotide content, demonstrating that it is the collective alignment of G/C and A/T content with this weight template that changes the network’s penultimate representation.</p>
<p>Finally, we demonstrated the utility of these features by constructing a simple 10-nearest neighbor classifier, where we used the lowest variance PCs to compute the inter-sequence distance. Briefly, we randomly selected 1200 correctly classified nucleosomal sequences to which we applied our interpretation method with the values of <italic>β</italic> and <italic>μ</italic> given above. For a given nucleosomal sequence, we represented each of its MCMC samples as a 201 dimensional binary vector by evaluating the G/C indicator variable at each base and used the element-wise mean over these vectors to represent the nucleosomal sequence itself as a positive exemplar in the nearest neighbor classification. Likewise, we repeated this task for 1200 correctly classified non-nucleosomal sequences to obtain negative exemplars. We then selected a balanced test set of 10500 sequences that were previously classified correctly by the network and represented each test sequence as a 201 dimensional binary vector indicating the G/C nucleotide composition of its bases. To compute the distance of a test sequence to an exemplar, we projected the vector joining the exemplar and the test sequence onto the space spanned by the exemplar’s 5 lowest variance PC vectors, scaling the projected coordinates by the inverse standard deviation of the associated PC vectors and then computing the Euclidean distance. Test set elements were assigned to the majority class of the 10 nearest exemplars. This simple method yielded a classification accuracy of 76%. For comparison, we repeated this classification replacing the 5 lowest variance PC vectors of each exemplar with 5 mutually orthogonal vectors randomly sampled from the 201 dimensional space (Methods). Using this control, nearest neighbor classification accuracy dropped to 51%. This result thus demonstrates the ability of our interpretation method to extract <italic>de novo</italic> features used in the neural network’s classification.</p>
</sec>
</sec>
<sec id="sec008" sec-type="conclusions">
<title>Discussion</title>
<p>Deep neural networks provide researchers with powerful tools for making predictions based on complex patterns in biological sequence. Methods for extracting learned input features from these networks can provide valuable scientific insights, and several efforts in this direction [<xref ref-type="bibr" rid="pcbi.1005836.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1005836.ref008">8</xref>] have made deep learning an even more appealing approach for tackling complex problems in genomics and other scientific disciplines.</p>
<p>We have contributed to these efforts by introducing a novel feature extraction method based on sampling a maximum entropy distribution with a constraint imposed by the empirical non-linear function learned by the network. From a theoretical standpoint, this constraint allows the derivation of relationships between the statistics of the sampled distribution and the dependence of network classification on specific sequence features. In particular, we have developed a scheme for assessing input-wide feature importance that has been difficult to measure otherwise with currently available approaches to network interpretation.</p>
<p>From a practical standpoint, the MaxEnt approach to feature extraction is distinct from other interpretation methods that assign base-wise importance to sequences. Admittedly, different interpretation schemes may thus have distinct advantages and disadvantages. For example, in Application 1, the MaxEnt method is able to capture the XOR logic that is learned by a simple ANN, but the same logic is difficult to infer using the methods based on base-wise importance. In Application 2, all schemes give similar results, but the MaxEnt interpretation method also provides probabilistic position-specific scoring matrices that are commonly used in bioinformatics. However, DeepLIFT and Saliency Map may be preferred in some cases for their computational efficiency. Interpreting an input in Application 2 via DeepLIFT, Saliency Map and MaxEnt takes 0.64 ms, 0.11 ms, and 181 s, respectively, on a quad-core 3.2 GHz Intel CPU, where the clear computational cost of MaxEnt interpretation stems from our MCMC sampling approach. This cost could be mitigated via a parallel implementation of multiple MCMC chains. Finally, Application 3 illustrates a setting in which MaxEnt interpretation surpasses other methods in elucidating the learned features that are consistent with the current understanding of nucleosome positioning [<xref ref-type="bibr" rid="pcbi.1005836.ref018">18</xref>].</p>
<p>The success of our MaxEnt approach signals that statistical physics may have much to contribute to the task of interpreting deep learning models. Indeed, a central goal of statistical mechanics is to understand constrained MaxEnt distributions of many degrees of freedom that interact according to known microscopic rules. While our formulation addresses an inverse problem of inferring unknown characteristics of network inputs from observed statistics of a constrained MaxEnt distribution, statistical mechanics provides a wide range of tools that could be further explored in this new context. This theoretical paper provides an example of the growing synergy between machine learning and physics towards assessing the role of diffuse and subtle sequence features that direct important biological outcomes, such as the positioning of nucleosomes.</p>
</sec>
<sec id="sec009" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec010">
<title>Monte Carlo sampling</title>
<p>Given a representation <bold><italic>x</italic></bold><sub><bold>0</bold></sub> of a sequence classified to class 0 by the trained network, we sampled sequences <bold><italic>x</italic></bold> from the PMF (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) using a Markov chain Monte Carlo (MCMC) method. We initialized the Markov random sequence <bold><italic>x</italic></bold> at <bold><italic>x</italic></bold><sub><bold>0</bold></sub>, then repeatedly selected an index <italic>i</italic> of <bold><italic>x</italic></bold> with uniform probability and proposed a mutation of nucleotide <italic>x</italic><sub><italic>i</italic></sub> to nucleotide <inline-formula id="pcbi.1005836.e034"><alternatives><graphic id="pcbi.1005836.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:msubsup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> sampled from the set {<italic>G</italic>,<italic>C</italic>,<italic>A</italic>,<italic>T</italic>}–{<italic>x</italic><sub><italic>i</italic></sub>} with uniform probability. The proposed mutation was accepted with probability given by the Metropolis criterion:
<disp-formula id="pcbi.1005836.e035">
<alternatives>
<graphic id="pcbi.1005836.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e035" xlink:type="simple"/>
<mml:math display="block" id="M35">
<mml:msub><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>⁡</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">*</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:mi>μ</mml:mi><mml:mo>[</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">*</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo><mml:mo>−</mml:mo><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <bold><italic>x</italic></bold>* denotes the random variable <bold><italic>x</italic></bold> with the proposed mutation at index <italic>i</italic> [<xref ref-type="bibr" rid="pcbi.1005836.ref020">20</xref>].</p>
<p>To generate the results of Application 1, we used 50 chains in parallel for each <bold><italic>x</italic></bold><sub><bold>0</bold></sub>, with each chain constructed from 100 proposed mutations. Each chain was sampled after every proposal. To generate the results of Application 2, we used 100 Markov chains in parallel for each <bold><italic>x</italic></bold><sub><bold>0</bold></sub>, with each chain constructed from 3 × 10<sup>4</sup> proposed mutations. Each chain was sampled every 100 proposals. To generate the results of Application 3, we used for each <bold><italic>x</italic></bold><sub><bold>0</bold></sub> a single Markov chain constructed by proposing 1 × 10<sup>6</sup> mutations. We sampled the chain every 100 proposals.</p>
</sec>
<sec id="sec011">
<title>Application 1: Interpreting learned XOR logic</title>
<sec id="sec012">
<title>Data set construction and network training</title>
<p>We trained instances of the architecture described in Application 1 on training sets of 2000 dinucleotides constructed by sampling i.i.d. multinomial distributions with P(A) = P(T) = 0.3 and P(G) = P(C) = 0.2, assuming independent bases. Training was performed using stochastic gradient descent with learning rate 5.0 × 10<sup>−3</sup> and binary cross-entropy loss in the python package Keras [<xref ref-type="bibr" rid="pcbi.1005836.ref021">21</xref>]. After each training epoch, we evaluated the model on the set of 16 distinct dinucleotide inputs. Training was stopped when the model achieved 100% classification accuracy or after 40 epochs of training. Using this method, we trained 300 models and selected at random 30 of the 46 models achieving 100% accuracy. To insure stability of the learned solution (stochastic gradient descent of the loss does not guarantee non-decreasing classification accuracy), we trained the selected models for 4 additional epochs checking for 100% validation accuracy at each epoch and then applied the interpretation methods.</p>
</sec>
<sec id="sec013">
<title>Network-dependent selection of <italic>β</italic></title>
<p>We performed MaxEnt interpretation for all inputs to a single network using the same value of <italic>β</italic>. We selected <italic>β</italic> for each model by requiring that the width of MaxEnt samples be small relative to the empirical distribution of all dinucleotide inputs in the space of penultimate activations scaled by weights of connection to the output unit. Specifically, for each input <bold><italic>x</italic></bold><sub><italic>i</italic></sub> to a fixed network, we solved for <italic>β</italic><sub><italic>i</italic></sub> in the equation
<disp-formula id="pcbi.1005836.e036">
<alternatives>
<graphic id="pcbi.1005836.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e036" xlink:type="simple"/>
<mml:math display="block" id="M36">
<mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo>.</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
Here, <italic>D</italic> is a distance scale in the space of scaled penultimate activations at which the probability implied by distribution (<xref ref-type="disp-formula" rid="pcbi.1005836.e005">2</xref>) has decayed by factor <italic>R</italic> and is defined as
<disp-formula id="pcbi.1005836.e037">
<alternatives>
<graphic id="pcbi.1005836.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e037" xlink:type="simple"/>
<mml:math display="block" id="M37">
<mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="bold">Φ</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo>
</mml:math>
</alternatives>
</disp-formula>
where <italic>d</italic> is the distance metric defined in (<xref ref-type="disp-formula" rid="pcbi.1005836.e009">3</xref>) for a network with a single output unit and where <bold>Φ</bold>(<bold><italic>x</italic></bold><sub><italic>NN</italic></sub>) denotes the nearest neighbor vector of penultimate activations in the empirical distribution of penultimate activations, and <italic>ϵ</italic> is a small value (on the scale of the empirical distance distribution measured by <italic>d</italic>) that handles the case of multiple inputs mapping to the same penultimate vector. Results in Application 1 use <italic>R =</italic> 0.4 and <italic>ϵ</italic> = 1.0. We interpreted each network using <italic>β</italic> equal to the mean of all <italic>β</italic><sub><italic>i</italic></sub>’s associated with the 16 dinucleotide inputs.</p>
</sec>
</sec>
<sec id="sec014">
<title>Application 2: Localizing learned motifs</title>
<sec id="sec015">
<title>Data accession and network training</title>
<p>We downloaded the CTCF motif discovery data set from <ext-link ext-link-type="uri" xlink:href="http://cnn.csail.mit.edu/motif_discovery/wgEncodeAwgTfbsHaibSknshraCtcfV0416102UniPk/" xlink:type="simple">http://cnn.csail.mit.edu/motif_discovery/wgEncodeAwgTfbsHaibSknshraCtcfV0416102UniPk/</ext-link> [<xref ref-type="bibr" rid="pcbi.1005836.ref002">2</xref>]. This data set was derived from a CTCF ChIP-seq experiment performed in human neuroblastoma cells treated with retinoic acid. Downloaded data were pre-partitioned into balanced training and test sets with 62,632 and 15,674 elements, respectively. We used this partition as a single fold in 5-fold cross validation (CV) scheme. For each CV fold, we set aside 1/8<sup>th</sup> of training data for validation and trained the network architecture for 20 epochs with a batch size of 80, employing the categorical cross-entropy loss function and the adaDelta optimizer from python package Keras [<xref ref-type="bibr" rid="pcbi.1005836.ref021">21</xref>]. During training, but not during testing or interpretation, the dropout method with probability 0.1 was applied to the output of the fully connected layer to reduce overfitting [<xref ref-type="bibr" rid="pcbi.1005836.ref022">22</xref>]. We evaluated validation performance at the end of each epoch and selected the model with best validation accuracy.</p>
</sec>
<sec id="sec016">
<title>Tomtom database query</title>
<p>We extracted MaxEnt motifs from the single nucleotide frequencies in <xref ref-type="fig" rid="pcbi.1005836.g003">Fig 3A and 3B</xref> as the 19 bp intervals with the largest average KL divergence between sample nucleotide frequencies and a uniform distribution over A,C,G,T. The single nucleotide frequencies of the resulting motifs were then analyzed using the Tomtom webserver (version 4.12.0) [<xref ref-type="bibr" rid="pcbi.1005836.ref015">15</xref>] with default parameters.</p>
</sec>
<sec id="sec017">
<title>MEME motif discovery and FIMO motif scan</title>
<p>We used the program MEME, version 4.10, to discover a consensus motif in 1500 inputs chosen randomly from the set of inputs where we applied our interpretation method [<xref ref-type="bibr" rid="pcbi.1005836.ref016">16</xref>]. We instructed MEME to find zero or one motif in each input with minimum and maximum motif lengths of 6 and 19, respectively. We required the consensus motif to be present in at least 400 inputs and stopped the search when the E-value exceeded 0.01.</p>
<p>We used the program FIMO, version 4.10, to scan the full set of 2500 sequences where we applied our interpretation [<xref ref-type="bibr" rid="pcbi.1005836.ref017">17</xref>]. We instructed FIMO not to search reverse complement strands of input sequences, and FIMO identified motifs in 1652 inputs. To construct the plot of relative distance distributions in <xref ref-type="fig" rid="pcbi.1005836.g003">Fig 3(C) and 3(D)</xref>, whenever FIMO called more than one motif in a sequence, we measured the distance between the network-derived motif and the FIMO motif with the lowest p-value.</p>
</sec>
</sec>
<sec id="sec018">
<title>Application 3: Extracting nucleosome positioning signals</title>
<sec id="sec019">
<title>Data set construction</title>
<p>We downloaded chemical cleavage maps of redundant and unique nucleosome dyads from the supplementary material of [<xref ref-type="bibr" rid="pcbi.1005836.ref010">10</xref>], and we used these dyad indices to construct data sets from the UCSC SAC2 version of the <italic>S</italic>. <italic>cerevisiae</italic> genome. Our positive validation and test data sets consisted of genomic intervals centered on unique nucleosome dyads of chromosomes 7 and 12, respectively. The positive training set consisted of genomic intervals centered on the set of redundant dyads from all other chromosomes (note that the set of redundant dyads contains the set of unique dyads). Each data set was balanced by negative elements centered on genomic indices sampled uniformly and without replacement from genomic indices at least 3 bps from all redundant dyads. This chromosome-based division of training, validation, and test data corresponded to roughly an 80%, 10%, 10% split of available data, and our test set contained 11738 elements. We represented all sequence inputs as one-hot arrays and then mean centered and standardized each entry by subtracting the genome-wide frequency <italic>f</italic> of the corresponding nucleotide and then dividing by <inline-formula id="pcbi.1005836.e038"><alternatives><graphic id="pcbi.1005836.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005836.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:msqrt><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>f</mml:mi><mml:mo>)</mml:mo></mml:msqrt></mml:math></alternatives></inline-formula>. We found that this preprocessing gives a marginal improvement over simple one-hot encoding for this classification task.</p>
</sec>
</sec>
<sec id="sec020">
<title>Network training</title>
<p>We trained the network architecture using stochastic gradient descent with batch size of 8 and the categorical cross entropy loss function. Our training set was augmented with reverse complement sequences, and gradient descent used a learning rate of 0.1, momentum parameter of 0.5, and L2 weight penalty of 0.001. Training was done with the python package Keras [<xref ref-type="bibr" rid="pcbi.1005836.ref021">21</xref>].</p>
</sec>
<sec id="sec021">
<title>Calculation of normalized Fourier amplitudes</title>
<p>Normalized Fourier amplitudes were calculated by performing discrete Fourier transform with the python package numpy [<xref ref-type="bibr" rid="pcbi.1005836.ref023">23</xref>], setting the zero frequency component to 0, then normalizing by the Euclidean norm of the Fourier components and calculating the amplitude at each frequency. These normalized amplitudes were averaged to produce the plots in <xref ref-type="fig" rid="pcbi.1005836.g004">Fig 4(D)</xref>.</p>
</sec>
<sec id="sec022">
<title>Generating random orthogonal vectors for nearest neighbor classifier</title>
<p>We generated sets of 5 orthogonal basis vectors over the unit sphere embedded in 201 dimensions by sampling the 201 components of each vector from standard normal distributions and then performing QR decomposition on the 201 × 5 matrix of column vectors.</p>
</sec>
<sec id="sec023">
<title>Source code and data availability</title>
<p>The source code, simulation data for Application 1, and a Python example workbook are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/jssong-lab/maxEnt" xlink:type="simple">https://github.com/jssong-lab/maxEnt</ext-link>.</p>
</sec>
</sec>
<sec id="sec024">
<title>Supporting information</title>
<supplementary-material id="pcbi.1005836.s001" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Details of neural network layers.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005836.s002" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Derivation of MaxEnt distribution and input-wide feature importance score.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005836.s003" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.s003" xlink:type="simple">
<label>S3 Text</label>
<caption>
<title>Application of Saliency Map and DeepLIFT to network interpretation.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005836.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.s004" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Interpretation of dinucleotide inputs to XOR network.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005836.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.s005" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Top hits for Tomtom database query with MaxEnt motifs.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005836.s006" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.s006" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Saliency Map and DeepLIFT interpretation of CTCF bound sequences.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005836.s007" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.s007" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Additional plots of nucleosome single nucleotide frequencies.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005836.s008" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005836.s008" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Examples of learned low variance nucleosome features.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Miroslav Hejna, Hu Jin and Wooyoung Moon for helpful discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005836.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alipanahi</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Delong</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Weirauch</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Frey</surname> <given-names>BJ</given-names></name>. <article-title>Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning</article-title>. <source>Nat Biotechnol</source>. <year>2015</year>;<volume>33</volume>(<issue>8</issue>):<fpage>831</fpage>–<lpage>8</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nbt.3300" xlink:type="simple">10.1038/nbt.3300</ext-link></comment> <object-id pub-id-type="pmid">26213851</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zeng</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Edwards</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Gifford</surname> <given-names>DK</given-names></name>. <article-title>Convolutional neural network architectures for predicting DNA-protein binding</article-title>. <source>Bioinformatics</source>. <year>2016</year>;<volume>32</volume>(<issue>12</issue>):<fpage>i121</fpage>–<lpage>i7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btw255" xlink:type="simple">10.1093/bioinformatics/btw255</ext-link></comment> <object-id pub-id-type="pmid">27307608</object-id>; PubMed Central PMCID: PMCPMC4908339.</mixed-citation></ref>
<ref id="pcbi.1005836.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhou</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Troyanskaya</surname> <given-names>OG</given-names></name>. <article-title>Predicting effects of noncoding variants with deep learning-based sequence model</article-title>. <source>Nat Methods</source>. <year>2015</year>;<volume>12</volume>(<issue>10</issue>):<fpage>931</fpage>–<lpage>4</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nmeth.3547" xlink:type="simple">10.1038/nmeth.3547</ext-link></comment> <object-id pub-id-type="pmid">26301843</object-id>; PubMed Central PMCID: PMCPMC4768299.</mixed-citation></ref>
<ref id="pcbi.1005836.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kelley</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Snoek</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Rinn</surname> <given-names>JL</given-names></name>. <article-title>Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks</article-title>. <source>Genome Res</source>. <year>2016</year>;<volume>26</volume>(<issue>7</issue>):<fpage>990</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/gr.200535.115" xlink:type="simple">10.1101/gr.200535.115</ext-link></comment> <object-id pub-id-type="pmid">27197224</object-id>; PubMed Central PMCID: PMCPMC4937568.</mixed-citation></ref>
<ref id="pcbi.1005836.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zeng</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Gifford</surname> <given-names>DK</given-names></name>. <article-title>Predicting the impact of non-coding variants on DNA methylation</article-title>. <source>Nucleic acids research</source>. <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkx177" xlink:type="simple">10.1093/nar/gkx177</ext-link></comment> <object-id pub-id-type="pmid">28334830</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lanchantin</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Singh</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Qi</surname> <given-names>Y</given-names></name>. <article-title>Deep Motif Dashboard: Visualizing and Understanding Genomic Sequences Using Deep Neural Networks</article-title>. <source>Pac Symp Biocomput</source>. <year>2016</year>;<volume>22</volume>:<fpage>254</fpage>–<lpage>65</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1142/9789813207813_0025" xlink:type="simple">10.1142/9789813207813_0025</ext-link></comment> <object-id pub-id-type="pmid">27896980</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref007"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Simonyan K, Vedaldi A, Zisserman A, editors. Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps. ICLR Workshop 2014.</mixed-citation></ref>
<ref id="pcbi.1005836.ref008"><label>8</label><mixed-citation publication-type="other" xlink:type="simple">Shrikumar A, Greenside P, Shcherbina A, Kundaje A. Not Just a Black Box: Learning Important Features Through Propagating Activation Differences. 2016;(arXiv:1605.01713 [cs.LG]).</mixed-citation></ref>
<ref id="pcbi.1005836.ref009"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Lundberg S, Lee S-I. An unexpected unity among methods for interpreting model predictions. NIPS 2016 Workshop on Interpretable Machine Learning in Complex Systems. 2016.</mixed-citation></ref>
<ref id="pcbi.1005836.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brogaard</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Xi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Widom</surname> <given-names>J</given-names></name>. <article-title>A map of nucleosome positions in yeast at base-pair resolution</article-title>. <source>Nature</source>. <year>2012</year>;<volume>486</volume>(<issue>7404</issue>):<fpage>496</fpage>–<lpage>501</lpage>. Epub 2012/06/23. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature11142" xlink:type="simple">10.1038/nature11142</ext-link></comment> <object-id pub-id-type="pmid">22722846</object-id>; PubMed Central PMCID: PMCPMC3786739.</mixed-citation></ref>
<ref id="pcbi.1005836.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Consortium</surname> <given-names>EP</given-names></name>. <article-title>An integrated encyclopedia of DNA elements in the human genome</article-title>. <source>Nature</source>. <year>2012</year>;<volume>489</volume>(<issue>7414</issue>):<fpage>57</fpage>–<lpage>74</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature11247" xlink:type="simple">10.1038/nature11247</ext-link></comment> <object-id pub-id-type="pmid">22955616</object-id>; PubMed Central PMCID: PMCPMC3439153.</mixed-citation></ref>
<ref id="pcbi.1005836.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ohlsson</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Renkawitz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Lobanenkov</surname> <given-names>V</given-names></name>. <article-title>CTCF is a uniquely versatile transcription regulator linked to epigenetics and disease</article-title>. <source>Trends Genet</source>. <year>2001</year>;<volume>17</volume>(<issue>9</issue>):<fpage>520</fpage>–<lpage>7</lpage>. Epub 2001/08/30. <object-id pub-id-type="pmid">11525835</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chan</surname> <given-names>CS</given-names></name>, <name name-style="western"><surname>Song</surname> <given-names>JS</given-names></name>. <article-title>CCCTC-binding factor confines the distal action of estrogen receptor</article-title>. <source>Cancer Res</source>. <year>2008</year>;<volume>68</volume>(<issue>21</issue>):<fpage>9041</fpage>–<lpage>9</lpage>. Epub 2008/11/01. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1158/0008-5472.CAN-08-2632" xlink:type="simple">10.1158/0008-5472.CAN-08-2632</ext-link></comment> <object-id pub-id-type="pmid">18974150</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crooks</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>Hon</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Chandonia</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Brenner</surname> <given-names>SE</given-names></name>. <article-title>WebLogo: a sequence logo generator</article-title>. <source>Genome Res</source>. <year>2004</year>;<volume>14</volume>(<issue>6</issue>):<fpage>1188</fpage>–<lpage>90</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/gr.849004" xlink:type="simple">10.1101/gr.849004</ext-link></comment> <object-id pub-id-type="pmid">15173120</object-id>; PubMed Central PMCID: PMCPMC419797.</mixed-citation></ref>
<ref id="pcbi.1005836.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gupta</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Stamatoyannopoulos</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Bailey</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Noble</surname> <given-names>WS</given-names></name>. <article-title>Quantifying similarity between motifs</article-title>. <source>Genome Biol</source>. <year>2007</year>;<volume>8</volume>(<issue>2</issue>). ARTN R24 <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/gb-2007-8-2-r24" xlink:type="simple">10.1186/gb-2007-8-2-r24</ext-link>.</comment> WOS:000246076300019. <object-id pub-id-type="pmid">17324271</object-id></mixed-citation></ref>
<ref id="pcbi.1005836.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bailey</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Grant</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Noble</surname> <given-names>WS</given-names></name>. <article-title>The MEME Suite</article-title>. <source>Nucleic acids research</source>. <year>2015</year>;<volume>43</volume>(<issue>W1</issue>):<fpage>W39</fpage>–<lpage>49</lpage>. Epub 2015/05/09. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkv416" xlink:type="simple">10.1093/nar/gkv416</ext-link></comment> <object-id pub-id-type="pmid">25953851</object-id>; PubMed Central PMCID: PMCPMC4489269.</mixed-citation></ref>
<ref id="pcbi.1005836.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grant</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Bailey</surname> <given-names>TL</given-names></name>, <name name-style="western"><surname>Noble</surname> <given-names>WS</given-names></name>. <article-title>FIMO: scanning for occurrences of a given motif</article-title>. <source>Bioinformatics (Oxford, England)</source>. <year>2011</year>;<volume>27</volume>(<issue>7</issue>):<fpage>1017</fpage>–<lpage>8</lpage>. Epub 2011/02/19. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btr064" xlink:type="simple">10.1093/bioinformatics/btr064</ext-link></comment> <object-id pub-id-type="pmid">21330290</object-id>; PubMed Central PMCID: PMCPMC3065696.</mixed-citation></ref>
<ref id="pcbi.1005836.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jin</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Rube</surname> <given-names>HT</given-names></name>, <name name-style="western"><surname>Song</surname> <given-names>JS</given-names></name>. <article-title>Categorical spectral analysis of periodicity in nucleosomal DNA</article-title>. <source>Nucleic acids research</source>. <year>2016</year>;<volume>44</volume>(<issue>5</issue>):<fpage>2047</fpage>–<lpage>57</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/nar/gkw101" xlink:type="simple">10.1093/nar/gkw101</ext-link></comment> <object-id pub-id-type="pmid">26893354</object-id>; PubMed Central PMCID: PMCPMC4797311.</mixed-citation></ref>
<ref id="pcbi.1005836.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hughes</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Rando</surname> <given-names>OJ</given-names></name>. <article-title>Mechanisms underlying nucleosome positioning in vivo</article-title>. <source>Annu Rev Biophys</source>. <year>2014</year>;<volume>43</volume>:<fpage>41</fpage>–<lpage>63</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev-biophys-051013-023114" xlink:type="simple">10.1146/annurev-biophys-051013-023114</ext-link></comment> <object-id pub-id-type="pmid">24702039</object-id>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Metropolis</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Rosenbluth</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Rosenbluth</surname> <given-names>MN</given-names></name>, <name name-style="western"><surname>Teller</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>Teller</surname> <given-names>E</given-names></name>. <article-title>Equation of State Calculations by Fast Computing Machines</article-title>. <source>J Chem Phys</source>. <year>1953</year>;<volume>21</volume>(<issue>6</issue>):<fpage>1087</fpage>–<lpage>92</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref021"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Chollet F. Keras: GitHub; 2015. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/fchollet/keras" xlink:type="simple">https://github.com/fchollet/keras</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Srivastava</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Hinston</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Krizhevasky</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sutskever</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Salakhutdinov</surname> <given-names>R</given-names></name>. <article-title>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</article-title>. <source>Journal of Machine Learning Research</source> <year>2014</year>;<volume>15</volume>:<fpage>1929</fpage>–<lpage>58</lpage>.</mixed-citation></ref>
<ref id="pcbi.1005836.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van der Walt</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Colbert</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Varoquaux</surname> <given-names>G</given-names></name>. <article-title>The NumPy array: a structure for efficient numerical computation</article-title>. <source>Computing in Science and Engineering</source>. <year>2011</year>;<volume>13</volume>(<issue>2</issue>):<fpage>22</fpage>–<lpage>30</lpage>.</mixed-citation></ref>
</ref-list>
</back>
</article>
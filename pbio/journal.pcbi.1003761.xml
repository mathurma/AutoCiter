<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-14-00323</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003761</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>A Simple Model of Optimal Population Coding for Sensory Systems</article-title>
<alt-title alt-title-type="running-head">A Simple Model of Optimal Population Coding for Sensory Systems</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Doi</surname><given-names>Eizaburo</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Lewicki</surname><given-names>Michael S.</given-names></name><xref ref-type="aff" rid="aff1"/></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Electrical Engineering and Computer Science Department, Case Western Reserve University, Cleveland, Ohio, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Bethge</surname><given-names>Matthias</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>University of Tübingen and Max Planck Institute for Biologial Cybernetics, Germany</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">edoi@case.edu</email></corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: ED. Performed the experiments: ED. Analyzed the data: ED. Interpreted the results: ED MSL. Wrote the paper: ED MSL.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>8</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>14</day><month>8</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>8</issue>
<elocation-id>e1003761</elocation-id>
<history>
<date date-type="received"><day>19</day><month>2</month><year>2014</year></date>
<date date-type="accepted"><day>17</day><month>6</month><year>2014</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Doi, Lewicki</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>A fundamental task of a sensory system is to infer information about the environment. It has long been suggested that an important goal of the first stage of this process is to encode the raw sensory signal efficiently by reducing its redundancy in the neural representation. Some redundancy, however, would be expected because it can provide robustness to noise inherent in the system. Encoding the raw sensory signal itself is also problematic, because it contains distortion and noise. The optimal solution would be constrained further by limited biological resources. Here, we analyze a simple theoretical model that incorporates these key aspects of sensory coding, and apply it to conditions in the retina. The model specifies the optimal way to incorporate redundancy in a population of noisy neurons, while also optimally compensating for sensory distortion and noise. Importantly, it allows an arbitrary input-to-output cell ratio between sensory units (photoreceptors) and encoding units (retinal ganglion cells), providing predictions of retinal codes at different eccentricities. Compared to earlier models based on redundancy reduction, the proposed model conveys more information about the original signal. Interestingly, redundancy reduction can be near-optimal when the number of encoding units is limited, such as in the peripheral retina. We show that there exist multiple, equally-optimal solutions whose receptive field structure and organization vary significantly. Among these, the one which maximizes the spatial locality of the computation, but not the sparsity of either synaptic weights or neural responses, is consistent with known basic properties of retinal receptive fields. The model further predicts that receptive field structure changes less with light adaptation at higher input-to-output cell ratios, such as in the periphery.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>Studies of the computational principles of sensory coding have largely focused on the redundancy reduction hypothesis, which posits that a neural population should encode the raw sensory signal efficiently by reducing its redundancy. Models based on this idea, however, have not taken into account some important aspects of sensory systems. First, neurons are noisy, and therefore, some redundancy in the code can be useful for transmitting information reliably. Second, the sensory signal itself is noisy, which should be counteracted as early as possible in the sensory pathway. Finally, neural resources such as the number of neurons are limited, which should strongly affect the form of the sensory code. Here we examine a simple model that takes all these factors into account. We find that the model conveys more information compared to redundancy reduction. When applied to the retina, the model provides a unified functional account for several known properties of retinal coding and makes novel predictions that have yet to be tested experimentally. The generality of the framework allows it to model a wide range of conditions and can be applied to predict optimal sensory coding in other systems.</p>
</abstract>
<funding-group><funding-statement>This work was partially supported by the National Science Foundation under Grant No. IIS-1111654. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="14"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Barlow's hypothesis of sensory coding posits that neurons should encode sensory information by reducing the high degree of redundancy in the raw sensory signal <xref ref-type="bibr" rid="pcbi.1003761-Barlow1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Bialek1">[6]</xref>, and when applied to natural images, it predicts oriented receptive field organizations <xref ref-type="bibr" rid="pcbi.1003761-Olshausen1">[7]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-vanVreeswijk1">[9]</xref>. These results qualitatively match response properties of simple-cells in the primary visual cortex <xref ref-type="bibr" rid="pcbi.1003761-Hubel1">[10]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Ringach1">[13]</xref>, but not those of retinal output neurons (retinal ganglion cells; RGCs) that exhibit a center-surround type receptive field <xref ref-type="bibr" rid="pcbi.1003761-Kuffler1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Rodieck1">[16]</xref>. The optic nerve poses a far greater bottleneck for the amount of visual information initially available at cone photoreceptors <xref ref-type="bibr" rid="pcbi.1003761-Orban1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Dhingra1">[18]</xref>, so why does the non-redundant code not match the neural representation in the retina? Alternatively, if the retina does use an optimal code, what is it optimized for?</p>
<p>Although redundancy reduction has been a guiding principle for understanding sensory coding, there are some important computations and constraints that have not fully been taken into account. The first is that the signal initially available to the sensory system is already degraded, often significantly, and hence forming a non-redundant code of this raw signal does not fully capture the goals of sensory coding. In the retina, for example, the projected image is already degraded by the optics of the eye <xref ref-type="bibr" rid="pcbi.1003761-Westheimer1">[19]</xref>, which is further degraded by photoreceptor noise <xref ref-type="bibr" rid="pcbi.1003761-Srinivasan1">[20]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-AlaLaurila1">[22]</xref> (<xref ref-type="fig" rid="pcbi-1003761-g001">Figure 1</xref>). Ideally, those degradations should be counteracted as early as possible in the visual system to avoid representing and processing “noise” in subsequent stages. For this reason, it has been suggested that de-blurring <xref ref-type="bibr" rid="pcbi.1003761-Ratliff1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Ruderman1">[24]</xref> and de-noising <xref ref-type="bibr" rid="pcbi.1003761-Srinivasan1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Ruderman1">[24]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-vanHateren1">[27]</xref> should be important aspects of retinal coding (the latter probably best known by Atick and his colleagues' work).</p>
<fig id="pcbi-1003761-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003761.g001</object-id><label>Figure 1</label><caption>
<title>Degradation of sensory signal.</title>
<p>Here we illustrate degradation of the image signal in the eye. The <italic>original signal</italic> is a portion of an unaltered standard test image. The <italic>blurred signal</italic> is computed with the blur function measured at 30° eccentricity of the human eye <xref ref-type="bibr" rid="pcbi.1003761-Navarro1">[50]</xref>. The <italic>observed signal</italic> (also called the raw sensory signal) simulates the noisy response of cone photoreceptors in a square lattice by adding white gaussian noise to the blurred signal.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003761.g001" position="float" xlink:type="simple"/></fig>
<p>A second issue is that redundancy reduction does not, by construction, introduce redundancy in a neural population to compensate for neural noise. Neural precision is inherently limited and the information capacity is estimated to be a few bits per spike <xref ref-type="bibr" rid="pcbi.1003761-Dhingra1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Borst1">[28]</xref>. Such a limited representational capacity might lead us to hypothesize that individual neurons should represent non-overlapping, independent visual features in order to encode as much information as possible <xref ref-type="bibr" rid="pcbi.1003761-Barlow1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Olshausen1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>. It has been argued, however, that some redundancy could be useful to convey visual information reliably with noisy neurons <xref ref-type="bibr" rid="pcbi.1003761-Barlow2">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi1">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Tkacik1">[32]</xref>, and there is some physiological evidence of redundant codes in neural systems <xref ref-type="bibr" rid="pcbi.1003761-Anderson1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Shlens1">[36]</xref>.</p>
<p>Another issue in predicting optimal codes is that different perceptual systems make different trade-offs to achieve behavioral goals with minimal resources. The most direct way for a system to affect this trade-off in the neural code is to vary the size of the neural population. This, along with the neural precision, determines the total information capacity. In the primate retina this resource constraint is readily apparent. In the fovea, the ratio of cone photoreceptors to RGCs is about 1∶1, but in the periphery the number of RGCs is far more limited – only about 1 RGC for every 25 photoreceptors, for instance (<xref ref-type="fig" rid="pcbi-1003761-g002">Figure 2</xref>). One would expect the optimal neural code to vary significantly across such different conditions, but this issue has not been investigated.</p>
<fig id="pcbi-1003761-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003761.g002</object-id><label>Figure 2</label><caption>
<title>The number of output neurons is far more limited in the peripheral retina.</title>
<p>The graph shows the number of cone photoreceptors per midget RGC as a function of eccentricity in the macaque retina. The data at the fovea (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e001" xlink:type="simple"/></inline-formula>) and periphery (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e002" xlink:type="simple"/></inline-formula>) are from <xref ref-type="bibr" rid="pcbi.1003761-Ahmad1">[93]</xref> and <xref ref-type="bibr" rid="pcbi.1003761-Goodchild1">[70]</xref>, respectively, and the smooth curve was a fit to the data using a cubic spline.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003761.g002" position="float" xlink:type="simple"/></fig>
<p>It has also been suggested that resources consumed by neural signaling and connectivity play a role in determining the form of the optimal retinal code <xref ref-type="bibr" rid="pcbi.1003761-Laughlin1">[37]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Sengupta1">[45]</xref>. Any code must extract and transform information from the incoming signal, but there is an inherent cost to doing so, both in terms of the energy to transform and transmit the information and in terms of the physical connections between neurons that subserve the information processing. Energy is always a limited resource, but the physical dimension required for the neural circuits might also be constrained, particularly in the retina where the neural tissue appears to be extremely packed in a highly restricted space. These resource constraints should be balanced against the aforementioned goals of counteracting sensory degradations and forming codes robust to neural noise.</p>
<p>In this article we examine optimal coding of the underlying environmental signal subject to all the aforementioned aspects of sensory systems (signal degradation, neural capacity, and resource constraints) and find that the proposed simple model can account for basic response properties of retinal neurons. Our goal here is to develop a simple model that incorporates key aspects of sensory systems in a unified optimization framework. To achieve this, we make idealizations so that the problem can be analytically well characterized and scales to model large input and output dimensionalities while also accounting for basic properties of sensory systems. In the following, first we systematically contrast the proposed model with a traditional, redundancy reduction model. We find that the optimal model conveys more information about the underlying, original signal, although redundancy reduction can be near-optimal under some conditions. Next, we apply the proposed framework to retinal conditions and find that the concentric center-surround structure of retinal receptive fields can be derived from the optimal model with a constraint of the spatial locality <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, but not with previously examined constraints such as sparse synaptic weights <xref ref-type="bibr" rid="pcbi.1003761-Vincent1">[41]</xref> or sparse neural responses <xref ref-type="bibr" rid="pcbi.1003761-Olshausen1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>. Finally, the proposed model makes a novel prediction that the adaptive change of receptive field structure with different light levels should be much smaller in the periphery than in the fovea due to the much higher cone-to-RGC convergence ratio. An early version of this study was presented as a conference paper <xref ref-type="bibr" rid="pcbi.1003761-Doi3">[46]</xref>, and a minimal theoretical analysis of the model was published in <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>The model</title>
<p>The proposed model is illustrated in <xref ref-type="fig" rid="pcbi-1003761-g003">Figure 3</xref>. The model forms an optimally robust code in the sense that the original sensory signal can be reconstructed from the neural representation with minimum mean squared error (MSE) despite sensory degradation, neural noise, and a limited number of neurons. The model assumes that the environmental or <italic>original signal</italic> is degraded by <italic>blur</italic> followed by additive noise (<italic>sensory noise</italic>) resulting in the <italic>observed signal</italic>. The <italic>neural representation</italic> is computed with the optimal linear transformation (<italic>neural encoding</italic>) of the observed signal. Limited neural precision is modeled with additive noise (<italic>neural noise</italic>), which sets a constant signal-to-noise ratio (SNR) for individual neurons. To quantify coding fidelity, a <italic>reconstructed signal</italic> is computed from the neural representation with an optimal linear estimator (<italic>decoding</italic>). Note that the decoding aspect of the model is only implicit. The neural portion of the model ends with the neural representation. Finally, various resource constraints can be added further without affecting the reconstruction error, which we will examine later. A formal description of the model is given in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<fig id="pcbi-1003761-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003761.g003</object-id><label>Figure 3</label><caption>
<title>The sensory coding model.</title>
<p>(a) Network diagram. Nodes represent individual elements of the indicated variables (noise variables indicated by small gray nodes); lines represent dependencies between them. Bold lines highlight, respectively, a point spread function of the blur from a point in the original signal to the observed signal, an encoding filter (or receptive field) that transforms the observed signal into the neural representation in a single neuron (encoding unit), and a decoding filter (or projective field) which represents the patten of that neuron's contribution in the reconstructed signal (its amplitude is given by the neural representation). In this diagram, the number of coding units at the neural representation is smaller than that of sensory units at the observed signal, which is called an undercomplete representation. Note that the proposed model is general and could form an optimal code with an arbitrary number of neurons, including complete and overcomplete cases. (b) The block flow diagram of the same model using the model variables defined in <xref ref-type="sec" rid="s4">Methods</xref>. Each stage of sensory representation is depicted by a circle; each transformation by a square; each noise by a gray circle.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003761.g003" position="float" xlink:type="simple"/></fig></sec><sec id="s2b">
<title>Stimulus reconstruction from the neural representation</title>
<p>First, let us observe the advantage of using the proposed model which forms an optimally redundant neural representation. We compare it with a traditional, whitening model which forms a minimally redundant representation. In the whitening model, the encoding filters were chosen to de-convolve and de-correlate the raw sensory signal under the idealized assumption of zero sensory noise <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Bell2">[48]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Graham1">[49]</xref> (see eq. 8 for the definition; note that whitening is the optimal solution for information maximization over noisy gaussian channels with zero sensory noise). Both models were evaluated with the fidelity of the stimulus reconstruction from the respective neural representations under the same problem settings (i.e., encoding the same ensemble of natural images subject to the same sensory degradation, neural noise, and neural population size). The reconstructed signal was computed with the optimal linear estimator for each model.</p>
<p><xref ref-type="fig" rid="pcbi-1003761-g004">Figure 4</xref> shows reconstruction examples. The sensory noise level was varied from −10 to 20 dB to simulate dark to bright conditions. The neural population size was also varied to illustrate the effect of cell ratio on coding fidelity. Here, we examine two retinal conditions: in the fovea condition, the ratio of pixels (cones) to encoding units (RGCs) was 1∶1; and 16∶1 in the periphery condition. The same optical blur was used for both conditions (30° eccentricity of the human eye <xref ref-type="bibr" rid="pcbi.1003761-Navarro1">[50]</xref>) to examine the effect of cell ratio alone. Neural noise was added so that the SNR for each neuron was 10 dB, corresponding to 1.7 bits of information capacity which is consistent with estimates of neural capacity <xref ref-type="bibr" rid="pcbi.1003761-Borst1">[28]</xref>.</p>
<fig id="pcbi-1003761-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003761.g004</object-id><label>Figure 4</label><caption>
<title>Image reconstruction examples.</title>
<p>We compare reconstructions from two different codes: whitening and the proposed, optimal model. The <italic>original signal</italic> (121×121 pixels) is degraded with blur and with different levels of sensory noise (−10 to 20 dB), resulting in the <italic>observed signals</italic>, where the percentage indicates the MSE relative to the original signal. These are encoded under two different cell ratios: 1∶1 (<italic>fovea</italic>) and 16∶1 (<italic>periphery</italic>) for each noise level. The <italic>reconstructed signals</italic> are obtained with the optimal decoding matrices, where the percentage indicates the MSE relative to the original signal, which can also be read out in <xref ref-type="fig" rid="pcbi-1003761-g005">Figure 5</xref> (labeled by open and closed triangles for the respective eccentricities).</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003761.g004" position="float" xlink:type="simple"/></fig>
<p>From these examples, we can make a number of observations. First, the optimal model always (and often significantly) yields better reconstruction than whitening, as should be expected by construction. For example, at the fovea and in the 0 dB sensory noise condition, the reconstructed signal from the whitening model has 82.0% error (in which the boat is barely visible), whereas the proposed model has only 31.4% error. Note that the observed signal initially contains 73.0% error relative to the original signal due to the optical blur and sensory noise. This leads to the second observation that the reconstructed signal can be cleaner than the signal available to a sensory system. It would be useful to recall that our problem is different from a simple, de-noising and de-blurring problem because the reconstruction is also constrained by the limited capacity of the neural representation. Third, the relative advantage of using the optimal code over whitening is higher in the fovea than in the periphery. Under the same, 0 dB condition but in the periphery, the reconstructed error with whitening is 42.9%, whereas the error is 38.3% with the optimal, proposed model – the relative advantage in the periphery is not as significant as in the fovea. Finally, the error is consistently smaller in the fovea than in the periphery with the proposed model, which should be expected because there are more neurons available in the fovea. Interestingly, however, this is not the case with the whitening model when the sensory SNR is low, such as at 0 dB, which we will explain in more detail in the next section.</p>
<p>The trends of two conditions shown in <xref ref-type="fig" rid="pcbi-1003761-g004">Figure 4</xref> can be generalized to a continuous range of cell ratios. <xref ref-type="fig" rid="pcbi-1003761-g005">Figure 5</xref> plots the reconstruction error for the proposed model (solid lines) and whitening model (dashed lines) over a range of population sizes, from large numbers of neurons to very few. The plots show that the relative advantage of the optimal codes is greatest at the 1∶1 cell ratio and diminishes as the cell ratio increases (i.e., the neural population size decreases). Note that the whitening model is not defined for an overcomplete case. In contrast, the proposed model is defined for any cell ratio and is able to reduce the reconstruction error by increasing the population size, up to the limiting case of an infinite population (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e003" xlink:type="simple"/></inline-formula> cell ratio). In this limit, there is no loss of information in the neural representation, but there is some error still present inherent to sensory noise and blur <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>. It is also clear that the optimal code yields a large benefit compared to whitening when the level of sensory noise is high. This is also to be expected, because the proposed model takes sensory noise into account while the redundancy reduction model does not. Note that, depending on the sensory SNR, the error reaches an asymptote level with different population sizes. For high SNRs, there is an advantage to having more RGCs relative to cones, whereas for lower SNRs, lower numbers of RGCs are sufficient to encode the available information.</p>
<fig id="pcbi-1003761-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003761.g005</object-id><label>Figure 5</label><caption>
<title>The reconstruction error as a function of neural population size.</title>
<p>Two x-axes represent, respectively, the cone: RGC ratio (top) and the corresponding retinal eccentricity in the macaque retina (bottom; see <xref ref-type="fig" rid="pcbi-1003761-g002">Figure 2</xref>). The problem settings are the same as in <xref ref-type="fig" rid="pcbi-1003761-g004">Figure 4</xref> with extended cell ratios; the common cell ratios (1∶1 and 16∶1) are indicated by the same labels (open and closed triangles, respectively). The signal dimension is 121×121 = 14,641 for all condition; the number of neurons with 16∶1 cell ratio is 915.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003761.g005" position="float" xlink:type="simple"/></fig></sec><sec id="s2c">
<title>Mechanisms of optimal representation and reconstruction</title>
<p>We have seen that the proposed model forms an optimal neural representation for the stimulus reconstruction while whitening fails to do so. To understand how, we can analyze these two models in the spectral domain. The spectral analysis is sufficient to characterize the mathematical mechanisms of both proposed and whitening models that produce different reconstruction errors, because the errors can be expressed solely with the spectral components (see <xref ref-type="sec" rid="s4">Methods</xref> for a formal description). Here, we illustrate the mechanisms using spectral analysis with an idealized model signal (<xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref>).</p>
<fig id="pcbi-1003761-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003761.g006</object-id><label>Figure 6</label><caption>
<title>Spectral analysis of the proposed model compared to whitening.</title>
<p>Every stage of sensory representations and their transformations are illustrated (cf. <xref ref-type="fig" rid="pcbi-1003761-g003">Figure 3</xref>). The signal is 100-dimensional, and the fovea and periphery conditions differ only in the neural population size (100 and 10, respectively). Each is analyzed under two sensory noise levels (20 and −10 dB). The horizontal axes represent the frequency (or spectrum) of the signal and are common across all plots. The vertical axes of the open plots (e.g., original signal) are common and represent the variance of the indicated sensory representations; those of the box plots (e.g., blur) are also common and represent gain (or modulation) with the indicated transformation, where the thin horizontal line indicates unit gain. The <italic>original signal</italic> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e004" xlink:type="simple"/></inline-formula>, yellow) is assumed to have a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e005" xlink:type="simple"/></inline-formula> power spectrum where <italic>f</italic> is the frequency of the signal. The <italic>blur</italic> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e006" xlink:type="simple"/></inline-formula>, black) is assumed to be low-pass gaussian. The <italic>observed signal</italic> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e007" xlink:type="simple"/></inline-formula>) is shown component-wise, i.e., the blurred signal (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e008" xlink:type="simple"/></inline-formula>, blue) and the sensory noise (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e009" xlink:type="simple"/></inline-formula>, red). The observed signal is transformed by the <italic>neural encoding</italic> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e010" xlink:type="simple"/></inline-formula>, black). Solid and dashed lines indicate the gain as a function of frequency for the proposed and whitening model, respectively (and the same line scheme is used in the other plots). The <italic>neural representation</italic> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e011" xlink:type="simple"/></inline-formula>) is also shown component-wise, i.e., the encoded signal (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e012" xlink:type="simple"/></inline-formula>, blue) and neural noise (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e013" xlink:type="simple"/></inline-formula>, red). The optimal <italic>decoding</italic> transform (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e014" xlink:type="simple"/></inline-formula>, black) is applied to the neural representation to obtain the <italic>reconstructed signal</italic> (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e015" xlink:type="simple"/></inline-formula>; blue), which is superimposed with the original signal (yellow); the percentage shows the MSE of reconstruction. Note all axes are in logarithmic scale. It is useful to recall that transforming a signal with a matrix is multiplicative, but it is simply summation in a logarithmic scale, and thus one can visually compute, for example, the blurred signal as the sum of the original signal and blur curves.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003761.g006" position="float" xlink:type="simple"/></fig>
<p>First, let us examine the fovea (complete code) condition under low sensory noise (20 dB, <xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref> first row). The observed signal, which consists of the blurred signal (blue curve) and sensory noise (red curve), is transformed by the neural encoding. The spectra of the neural encodings (dashed and solid curves for the proposed and whitening models) represent modulations of the signal in the frequency domain with the respective neural populations. The neural encoding spectrum is a unique characteristic of a population of spatial receptive fields, and we will discuss the characteristics of the spatial form below. In the whitening model, the neural encoding transforms the blurred signal such that the resulting spectrum becomes flat (or white, hence called whitening). In the neural representation, however, the encoded signal (dashed blue curve) is not entirely flat, because it contains the transformed sensory noise in addition to the transformed (whitened) blurred signal. Note that the curve of the whitening neural encoding is by construction vertically symmetric to that of the blurred signal. As a result, whitening amplifies the higher frequency components. This is problematic because the SNR of the observed signal is lower at the higher frequencies. Consequently, in the neural representation, the higher frequencies of the encoded signal have large variances relative to those of neural noise (red curve), but as we have seen, these are the components dominated by the sensory noise. The ideal strategy should be the other way around, which is the one implemented by the proposed, optimal model (see solid blue curve vs. red curve in the neural representation plot).</p>
<p>Specifically, there are two factors underlying the optimal reconstruction in the proposed model. First, highly noise-dominated components at the high frequencies in the observed signal are not encoded at all by the neural encoding, which is truncated roughly where the blurred signal falls below the sensory noise (the exact location of this cut-off frequency was shown to depend on the details of the problem setting <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>). This allows the neural population to allocate its limited representational capacity to high SNR components of the observed signal. This important characteristic is also demonstrated with the two-dimensional toy problem (<xref ref-type="supplementary-material" rid="pcbi.1003761.s007">Text S1</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003761.s001">Figures S1</xref>-<xref ref-type="supplementary-material" rid="pcbi.1003761.s005">S5</xref>): the optimal receptive fields of two neurons in a population become identical under certain conditions, predicting the most redundant form of code called a <italic>repetitive</italic> code <xref ref-type="bibr" rid="pcbi.1003761-Mukamel1">[51]</xref>. The second factor is that the optimal model tends to transform the redundant (non-flat) spectrum of the blurred signal into a less redundant (closer to flat) spectrum of the encoded signal, but unlike whitening, this flattening is incomplete (it is exactly halfway when there is no sensory noise, hence called <italic>half-whitening</italic> <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>). With this, the high SNR components of the observed signal have large variances relative to those of neural noise, which is in sharp contrast to whitening.</p>
<p>The basic trends described above also hold with high sensory noise (e.g., −10 dB as in <xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref> second row) where there are a greater number of low SNR components in the observed signal. The shape of the optimal neural encoding changes accordingly, but that of whitening is identical across different sensory noise levels up to scaling (and hence they are identical up to the vertical translation in the log-log plot). This scaling is a mere reflection of the neural capacity constraint (i.e., the sum of variances in the neural representations is maintained to be a constant while the variance of the observed signal changes with different amounts of sensory noise). With a large amount of sensory noise (−10 dB), nearly 100% of sensory information is lost in the whitening model, because in the neural representation, only high frequency components are greater than neural noise, but they are already corrupted by sensory noise.</p>
<p>Next, we examine the periphery (undercomplete code) condition (<xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref> bottom two rows). The whitening encoding is exactly the same as in the foveal case except that it has only <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e016" xlink:type="simple"/></inline-formula> as many components. Notably, this acts as a thresholding mechanism which helps alleviate the aforementioned problem of whitening for the fovea case in which the limited neural capacity was wasted on the noise-dominated, high frequency components. Solely because of this, whitening in the periphery yields an error closer to the optimal value, resulting in (ironically) better reconstruction than whitening in the fovea. This mechanism can be understood more intuitively in the spatial domain. With the unavoidable thresholding effect caused by an undercomplete encoding, the filtering is largely low-pass, which in the spatial domain corresponds to pooling over many pixels. This pooling acts to average out sensory noise and selectively encodes low frequency components. The result is roughly equivalent to encoding only the high SNR components as discussed above. Although these coding mechanisms are common between the proposed and whitening models, it is only the proposed model that adapts its encoding to changes in the sensory noise level (from 20 to −10 dB), leading to a substantial improvement in reconstruction error over whitening (compare errors in the reconstructed signal column).</p>
<p>Finally, this analysis would not be complete without examining an overcomplete case. As observed earlier, the proposed model can have a greater number of encoding units relative to sensory units, and it optimally minimizes the error to the bound set by the sensory degradation (<xref ref-type="fig" rid="pcbi-1003761-g005">Figure 5</xref>). Because the encoding units are noisy, it is beneficial to increase the population size in order to better compensate for the neural noise. The model makes optimal use of added neurons by decreasing the effect of the neural noise in the population, which increases the representational capacity <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>. This highlights an important notion that the neural code is not determined by the ratio of sensory units to encoding units <italic>per se</italic>, but depends on many factors (see <xref ref-type="supplementary-material" rid="pcbi.1003761.s007">Text S1</xref> and <xref ref-type="supplementary-material" rid="pcbi.1003761.s001">Figures S1</xref>–<xref ref-type="supplementary-material" rid="pcbi.1003761.s005">S5</xref> for a comprehensive analysis).</p>
</sec><sec id="s2d">
<title>Predicting retinal population coding</title>
<p>The proposed model predicts how the original signal is optimally encoded in a neural population. The solution is uniquely specified in the spectral domain, however, it does not predict a unique spatial organization of the receptive fields. In other words, there are multiple ways to implement the optimal spectral transform (see <xref ref-type="sec" rid="s4">Methods</xref> for a mathematical explanation of why this arises from the model). <xref ref-type="fig" rid="pcbi-1003761-g007">Figure 7a</xref> shows a subset of optimal encoding (and decoding) filters of the proposed model with no additional constraints. This is a randomly chosen one out of many optimal solutions, and the receptive fields are generally unstructured. Additional constraints are necessary to determine the exact spatial form of the receptive fields.</p>
<fig id="pcbi-1003761-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003761.g007</object-id><label>Figure 7</label><caption>
<title>A variety of equally optimal solutions obtained under different resource constraints.</title>
<p>Each panel shows a subset of five pairs of neural encoding (top, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e017" xlink:type="simple"/></inline-formula>) and decoding (bottom, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e018" xlink:type="simple"/></inline-formula>) filters in the foveal setting at four sensory SNRs (columns, −10 to 20 dB) in four conditions (rows): (a) No additional constraint (i.e., the base model). (b) Weight sparsity. (c) Response sparsity. (d) Spatial locality. Only the spatial locality constraint yields center-surround receptive fields. See <xref ref-type="supplementary-material" rid="pcbi.1003761.s006">Figure S6</xref> for the resource costs in respective populations. Note that in (d) the center-surround structure is seen only in the filters, which transform the observed signal into the neural code (and hence correspond to receptive fields). The decoding filters have a different, gaussian-like structure. These features are used to optimally reconstruct the original signal from the neural code.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003761.g007" position="float" xlink:type="simple"/></fig>
<p>We investigated three constraints that are relevant to limited biological resources. The first maximized the sparsity of the receptive field weights <xref ref-type="bibr" rid="pcbi.1003761-Vincent1">[41]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Vincent2">[43]</xref>, which could provide an <italic>energy-efficient</italic> implementation of the optimal solution given that synaptic activities are metabolically expensive <xref ref-type="bibr" rid="pcbi.1003761-Sengupta2">[52]</xref>. This did not, however, yield the types of concentric, center-surround receptive fields found in the retina (<xref ref-type="fig" rid="pcbi-1003761-g007">Figure 7b</xref>).</p>
<p>The second constraint maximized the sparsity of neural responses. This can be justified either by the energy efficiency of the resulting code or from the sparse structure of natural images <xref ref-type="bibr" rid="pcbi.1003761-Olshausen1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>. This also did not yield concentric center-surround receptive fields, but rather oriented, localized Gabor-like filters which resemble receptive fields found in primary visual cortex (<xref ref-type="fig" rid="pcbi-1003761-g007">Figure 7c</xref>).</p>
<p>Finally, we examined a constraint that maximized the spatial locality of the computation (receptive fields), motivated by the notion that the neural systems generally, and the retina in particular, have limited space and thus should minimize the volume and extent of the neural wiring required to compute the code <xref ref-type="bibr" rid="pcbi.1003761-Chklovskii1">[39]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Chklovskii2">[42]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Perge1">[44]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Laughlin3">[53]</xref>. With this locality constraint, the model yielded a center-surround receptive field structure, similar to that found in the retina (<xref ref-type="fig" rid="pcbi-1003761-g007">Figure 7d</xref>).</p>
<p>With this last constraint, we further examined the details of receptive field structure and organization. <xref ref-type="fig" rid="pcbi-1003761-g008">Figure 8</xref> shows the prediction at two retinal eccentricities, 0° (fovea) and 50° (periphery). To better model the conditions in the retina, we took into account the optical blur of the human eye <xref ref-type="bibr" rid="pcbi.1003761-Navarro1">[50]</xref> and the cell ratio (<xref ref-type="fig" rid="pcbi-1003761-g002">Figure 2</xref>) at the respective eccentricities. As above, we modeled different mean light levels by various sensory SNRs. (Additional information in <xref ref-type="sec" rid="s4">Methods</xref>.)</p>
<fig id="pcbi-1003761-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003761.g008</object-id><label>Figure 8</label><caption>
<title>Predicting different retinal light adaptations at different eccentricities.</title>
<p>Each panel consists of three plots. <italic>Top</italic>: The (smoothed) cross section of a typical receptive field through the peak. The horizontal line indicates the weight value of zero. <italic>Middle</italic>: The intensity map of the same receptive field. The bright and dark colors indicate positive and negative weight values, respectively, and the medium gray color indicates zero. Superimposed is the outline of the center subregion (the contour defined by the half-height from the peak) along with the average number of pixels (cones photoreceptors) inside the contour. <italic>Bottom</italic>: The half-height contours of the entire neural population which displays their tiling in the visual field. Two neurons are highlighted for clarity (one of which corresponds to the neuron shown above). The pixel lattice is depicted by the orange grid.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003761.g008" position="float" xlink:type="simple"/></fig>
<p>In the fovea condition, the encoding filters vary from the large, so-called center-only type (−10 dB) to the small, difference-of-gaussian type (20 dB) <xref ref-type="bibr" rid="pcbi.1003761-Barlow3">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-EnrothCugell1">[54]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Shapley1">[55]</xref>. This can be expressed in the spectral domain as the transition from low-pass to band-pass filtering (cf. <xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref>). As a result, the overlap of the central region of the receptive fields is very large at the lower SNR, implying that neighboring neurons are transmitting information about a highly overlapped region of pixels at the expense of transmitting independent information. This overlap, however, is optimal for counteracting the high level of sensory noise and encoding the underlying original signal (cf. <xref ref-type="fig" rid="pcbi-1003761-g004">Figure 4</xref>).</p>
<p>In the periphery condition, a similar adaptive change was observed but to a lesser extent. The shape of the receptive field looks similar across all sensory SNRs. More specifically, with the change from 20 to −10 dB, the number of cones inside the central subregion increases only by a factor of 25% in the periphery compared to 780% in the fovea. As was seen in the spectral analysis (<xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref>), the degree of adaptation is limited by the highly convergent cone-to-RGC ratio.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>In this article we presented a simple theoretical model of optimal population coding that incorporates several key aspects of sensory systems. The model is analytically well characterized (<xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref>; see also <xref ref-type="supplementary-material" rid="pcbi.1003761.s007">Text S1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1003761.s001">Figures S1</xref>–<xref ref-type="supplementary-material" rid="pcbi.1003761.s005">S5</xref>) and scales to systems with high input dimensionality (<xref ref-type="fig" rid="pcbi-1003761-g004">Figures 4</xref>–<xref ref-type="fig" rid="pcbi-1003761-g005">5</xref>). We found that the optimal code conveys significantly more information about the underlying environmental signal compared to a traditional redundancy reduction model. It has long been argued that some redundancy should be useful <xref ref-type="bibr" rid="pcbi.1003761-Barlow2">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-vanHateren1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi1">[29]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Tkacik1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Haft1">[56]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Doi5">[59]</xref>. Here we provide a simple and quantitative model that optimally incorporates redundancy in a neural population under a wide range of settings. In contrast to earlier studies <xref ref-type="bibr" rid="pcbi.1003761-Ruderman1">[24]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-vanHateren1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Haft1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Atick3">[60]</xref>, the proposed model allows for an arbitrary number of neurons in a population, providing previously unavailable insights and predictions: the degree to and the mechanisms by which the error can be minimized with different input-to-output cell ratios (<xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref>); the conditions in which the redundancy reduction model is near-optimal (<xref ref-type="fig" rid="pcbi-1003761-g005">Figure 5</xref>); the degree of adaptation of receptive fields at different eccentricities to different light levels (<xref ref-type="fig" rid="pcbi-1003761-g008">Figure 8</xref>). We observed that the optimal receptive fields are non-unique, as in other models <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi5">[59]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Li1">[61]</xref>, and found that the additional constraint of spatial locality of the computation <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, but not previously examined constraints such as sparse weights <xref ref-type="bibr" rid="pcbi.1003761-Vincent1">[41]</xref> or sparse responses <xref ref-type="bibr" rid="pcbi.1003761-Olshausen1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>, yielded receptive fields similar to those found in the retina (<xref ref-type="fig" rid="pcbi-1003761-g007">Figure 7</xref>).</p>
<p>A number of other studies have also investigated different optimal coding models that extended the basic idea of redundancy reduction, but with different assumptions and conditions. A commonly assumed objective is <italic>information maximization</italic>, which maximizes the number of discriminable states about the environmental signal in the neural code <xref ref-type="bibr" rid="pcbi.1003761-Bialek1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-vanHateren1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Haft1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Borghuis1">[57]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi5">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi6">[62]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Pitkow1">[64]</xref>, whereas the present study assumed <italic>error minimization</italic>, which minimizes the MSE of reconstruction from the neural code <xref ref-type="bibr" rid="pcbi.1003761-Ruderman1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi2">[31]</xref>. These objectives can be interpreted as different mathematical approaches to the same general goal (some predictions from these different objectives are qualitatively similar <xref ref-type="bibr" rid="pcbi.1003761-Ruderman1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi6">[62]</xref>; an equivalence can be established between the two under some settings <xref ref-type="bibr" rid="pcbi.1003761-Guo1">[65]</xref>). Recently, Doi et al. <xref ref-type="bibr" rid="pcbi.1003761-Doi5">[59]</xref> showed that the physiologically estimated retinal transform <xref ref-type="bibr" rid="pcbi.1003761-Field2">[66]</xref> is on average 80% optimal, but note that this model did not uniquely predict concentric center-surround receptive field structures, and that the change of receptive field structure under different conditions (e.g., sensory SNRs and cone-to-RGC ratios) was not examined. Some consequences that arise from the choice of the objective are worth mentioning. One is that de-blurring emerges from error minimization but not from those information maximization models <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-vanHateren1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi5">[59]</xref>, because the error is defined with respect to the original signal prior to blurring. (In <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-vanHateren1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi5">[59]</xref>, the information is defined with respect to the original signal, but it is equivalent to the information about the blurred signal under the model assumptions (eq. 1–2): <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e019" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e020" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e021" xlink:type="simple"/></inline-formula> denote the mutual information and the entropy, respectively.) Another is that, in the limit of zero sensory noise, the optimal neural transform for information maximization is whitening (i.e., redundancy is reduced) <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-vanHateren1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi5">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Pitkow1">[64]</xref> while that for error minimization is half-whitening (i.e., redundancy is half-preserved) <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>.</p>
<p>In many theoretical studies, the input-to-output cell ratio is assumed to be 1∶1, i.e., a complete representation <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Ruderman1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-vanHateren1">[27]</xref>. Although this assumption may be valid in some specific settings such as in the fovea <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, there are many settings in which this assumption is not valid, such as in the periphery (<xref ref-type="fig" rid="pcbi-1003761-g002">Figure 2</xref>). By being able to vary the cell ratio to match the conditions of the system of interest, the proposed model showed that the retinal transform of sensory signals and the resulting redundancy in neural representations vary with the retinal eccentricity. Another common assumption related to the cell ratio is that neural encoding is the inverse of the data generative process <xref ref-type="bibr" rid="pcbi.1003761-Olshausen1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>, where individual neurons are noiseless and represent independent features or intrinsic coordinates of the signal space. In this view, the number of neurons should match the intrinsic dimensionality of the signal. In contrast, in the proposed model the number of neurons may be seen as a parameter for total neural capacity and can be varied independently of the signal's intrinsic dimensionality. Consequently, it is even possible that, while representing an identical signal source, two neurons in the proposed model adaptively change what they represent by changing their receptive fields with different sensory or neural noise levels (Figures S3–S4; notably, two neurons can have identical receptive fields in some extreme cases).</p>
<p>While the current study is based on several simplifying assumptions such as linear neurons with white gaussian neural noise, some recent studies have incorporated more realistic neural properties to investigate the optimality of retinal coding, so it is important to contrast these with the proposed model. Borghuis et al. <xref ref-type="bibr" rid="pcbi.1003761-Borghuis1">[57]</xref> included instantaneous nonlinearities of neural responses and found that the physiologically observed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e022" xlink:type="simple"/></inline-formula> spacing of RGC receptive field arrays <xref ref-type="bibr" rid="pcbi.1003761-DeVries1">[67]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Gauthier1">[68]</xref> is optimal. This is consistent with the prediction of the proposed model under the retinal conditions they studied (i.e., high cone-to-RGC ratios; we estimate the ratio is roughly <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e023" xlink:type="simple"/></inline-formula>, given the reported receptive field size and tiling <xref ref-type="bibr" rid="pcbi.1003761-Borghuis1">[57]</xref> and the cone density in the guinea pig retina <xref ref-type="bibr" rid="pcbi.1003761-Applebury1">[69]</xref>). However, the model presented here predicts that the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e024" xlink:type="simple"/></inline-formula> spacing is not optimal in all conditions (<xref ref-type="fig" rid="pcbi-1003761-g008">Figure 8</xref>). Also note that the center-surround structure in their study was assumed, and did not emerge as a result of an optimization as presented here. Pitkow &amp; Meister <xref ref-type="bibr" rid="pcbi.1003761-Pitkow1">[64]</xref> investigated efficient coding in the retina using a spike count representation and studied the functional role of instantaneous nonlinearity, neither of which was included in this study. Like in the previous study <xref ref-type="bibr" rid="pcbi.1003761-Borghuis1">[57]</xref>, the center-surround receptive fields were measured, not derived. In addition, their analysis assumed zero sensory noise, which as we have shown here can play a significant role in the form of retinal codes. Karklin &amp; Simoncelli <xref ref-type="bibr" rid="pcbi.1003761-Karklin1">[63]</xref> proposed an algorithm for optimizing both receptive fields and instantaneous nonlinearities. While they did not assume additional resource constraints or examine different cone-to-RGC ratios systematically, their predictions in certain conditions are consistent with those presented here. Some differences are significant, for example, in their model different types of receptive fields were derived under different sensory and neural SNRs. Further investigations are necessary to bring clarity to these differences. Overall, it is fair to say that there is no model that incorporates all aspects of retinal coding with realistic assumptions, and developing such a model is an open problem for future research. We would point out, however, that there are advantages to simpler models, especially if they can account for important aspects of sensory coding. Some issues that arise with more realistic (and more complex) models are whether they can be analytically characterized, scale to biologically relevant high-dimensional problems, or provide insights beyond simpler models. The proposed model may be seen as a first-order approximation to a complex sensory system and can be used as a <italic>base</italic> model for developing and comparing to models with more realistic properties. Moreover, the optimization of the model is convex, implying that the optimal solution is guaranteed and can be obtained with standard algorithms.</p>
<p>The proposed model made a novel prediction that the change of receptive field structure and organization with different light levels is much greater in the fovea than in the periphery of the macaque midget RGCs (<xref ref-type="fig" rid="pcbi-1003761-g008">Figure 8</xref>). This prediction has not been tested directly because, to the best of our knowledge, all physiological measurements from RGCs with different light levels have carried out either in cat <xref ref-type="bibr" rid="pcbi.1003761-Barlow3">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-EnrothCugell1">[54]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Shapley1">[55]</xref> or rabbit <xref ref-type="bibr" rid="pcbi.1003761-DeVries1">[67]</xref> retinas, where the reported adaptive changes were marginal. This observation seems to be consistent with our prediction for the periphery, where the cone-to-RGC ratio is high. Note that in the cat retina, the cone-to-RGC ratios (specifically with respect to the most numerous beta RGCs) range from 30 to 200 across eccentricity <xref ref-type="bibr" rid="pcbi.1003761-Goodchild1">[70]</xref>; in the rabbit retina, we estimate the ratio to be greater than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e025" xlink:type="simple"/></inline-formula>, according to the cone density <xref ref-type="bibr" rid="pcbi.1003761-Famiglietti1">[71]</xref>, receptive field sizes, and their tiling <xref ref-type="bibr" rid="pcbi.1003761-DeVries1">[67]</xref>. If the prediction of larger changes in receptive field structure in fovea conditions (cone-to-RGC ratios near 1∶1) is confirmed by physiological measurements, it would be a strong test of the theory. Note also that some studies have reported larger changes in receptive fields sizes <xref ref-type="bibr" rid="pcbi.1003761-Barlow3">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-EnrothCugell1">[54]</xref>, but these were measured between scotopic and photopic conditions. Like previous approaches, here we have only considered cone photoreceptors which implicitly assumes photopic conditions. To include scotopic conditions, one would need to model the rod system <xref ref-type="bibr" rid="pcbi.1003761-Field3">[72]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Field4">[73]</xref>, which has yet to be incorporated into an efficient coding framework.</p>
<p>The proposed model incorporated a broad range of properties and constraints for sensory systems. It is an abstract model and hence predictions can be made for a wide range of sensory systems by incorporating system-specific conditions. Although we have only modeled conditions for the midget RGCs in the macaque retina, the same framework could be applied to other cell types (e.g., parasol RGCs <xref ref-type="bibr" rid="pcbi.1003761-Gauthier1">[68]</xref>) or retinas of other species (e.g., cat <xref ref-type="bibr" rid="pcbi.1003761-Barlow3">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-EnrothCugell1">[54]</xref> or human <xref ref-type="bibr" rid="pcbi.1003761-Goodchild1">[70]</xref>) by incorporating their specific conditions (e.g., cone-to-RGC ratios and optical blur functions). The model can also be applied to other sensory systems, as nothing in the proposed model is specific to the retina. Auditory systems have been approached in the same framework of efficient coding <xref ref-type="bibr" rid="pcbi.1003761-Schwartz1">[74]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Chechik1">[77]</xref>, but the factors introduced in this study have not fully been incorporated into previous models. For example, the cell ratio of sensory units (inner hair cells) to encoding units (auditory nerve fibers) is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e026" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003761-Rubel1">[78]</xref>, i.e., the neural representation is highly overcomplete, which is very different from the retina (<xref ref-type="fig" rid="pcbi-1003761-g002">Figure 2</xref>). Further, the auditory signal is filtered by the head-related transfer function <xref ref-type="bibr" rid="pcbi.1003761-Kistler1">[79]</xref>, which could be modeled by the linear distortion in the proposed framework. Olfactory systems have also been studied in an efficient coding framework (e.g., <xref ref-type="bibr" rid="pcbi.1003761-Olsen1">[80]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Luo1">[81]</xref>; for reviews, <xref ref-type="bibr" rid="pcbi.1003761-Abbott1">[82]</xref>–<xref ref-type="bibr" rid="pcbi.1003761-Gire1">[84]</xref>). It is possible that the optimal redundancy computed with the proposed model may provide insights into olfactory coding beyond decorrelation <xref ref-type="bibr" rid="pcbi.1003761-Luo1">[81]</xref>. Finally, the sensory SNR models the varied intensity of environmental signals relative to the background noise, and the neural SNR models the neural capacity, both of which are broadly relevant. The application of the proposed model to different retinal conditions and other sensory modalities would be a powerful way to investigate common principles of sensory systems.</p>
</sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>The problem formulation</title>
<p>We define the linear gaussian model (<xref ref-type="fig" rid="pcbi-1003761-g003">Figure 3</xref>), a functional model of neural responses on which both the proposed and whitening models are constructed. The observed signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e027" xlink:type="simple"/></inline-formula> is generated by <disp-formula id="pcbi.1003761.e028"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e028" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e029" xlink:type="simple"/></inline-formula> is the original signal, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e030" xlink:type="simple"/></inline-formula> is a linear distortion in the sensing system such as optical blur in vision or the head-related transfer function in audition, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e031" xlink:type="simple"/></inline-formula> is the sensory noise with variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e032" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e033" xlink:type="simple"/></inline-formula> denotes the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e034" xlink:type="simple"/></inline-formula>-dimensional identity matrix. The covariance of the original signal is defined by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e035" xlink:type="simple"/></inline-formula>. We assume that the original signal is zero mean but need not be gaussian (as in <xref ref-type="bibr" rid="pcbi.1003761-Hyvrinen1">[85]</xref>). The sensory SNR is measured in dB, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e036" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e037" xlink:type="simple"/></inline-formula> denotes the trace of a matrix. We set the sensory noise variance, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e038" xlink:type="simple"/></inline-formula>, such that the sensory SNR varies from −10 to 20 dB, which covers the physiological range measured in fly photoreceptors (−2.2 to 9.7 dB) <xref ref-type="bibr" rid="pcbi.1003761-Srinivasan1">[20]</xref>. The neural representation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e039" xlink:type="simple"/></inline-formula> is generated by <disp-formula id="pcbi.1003761.e040"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e040" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e041" xlink:type="simple"/></inline-formula> is the encoding matrix whose row vectors are the encoding filters (or linear receptive fields), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e042" xlink:type="simple"/></inline-formula> is the neural noise with variance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e043" xlink:type="simple"/></inline-formula>. The neural SNR is also measured in dB, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e044" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e045" xlink:type="simple"/></inline-formula> is the covariance of the observed signal, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e046" xlink:type="simple"/></inline-formula> is the covariance of the encoded signal, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e047" xlink:type="simple"/></inline-formula>. We set the neural SNR to 10 dB so that its information capacity, 1.7 bits, is approximately matched to the values of information transmission estimated in various neural systems (0.6–7.8 bits/spike) <xref ref-type="bibr" rid="pcbi.1003761-Borst1">[28]</xref>. The reconstruction of the original signal from the neural representation is computed by a linear transform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e048" xlink:type="simple"/></inline-formula> <disp-formula id="pcbi.1003761.e049"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e049" xlink:type="simple"/><label>(3)</label></disp-formula>that minimizes the MSE <disp-formula id="pcbi.1003761.e050"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e050" xlink:type="simple"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e051" xlink:type="simple"/></inline-formula> indicates sample average and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e052" xlink:type="simple"/></inline-formula> <italic>L</italic><sup>2</sup>-norm, given the covariances of signal and noise components in the neural representation (i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e053" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e054" xlink:type="simple"/></inline-formula>, respectively). In other words, the decoding matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e055" xlink:type="simple"/></inline-formula> is the Wiener filter which estimates the original signal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e056" xlink:type="simple"/></inline-formula> from its degraded version <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e057" xlink:type="simple"/></inline-formula> with the linear transform <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e058" xlink:type="simple"/></inline-formula> and additive correlated gaussian noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e059" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003761-Ruderman1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>. The proposed, optimal encoding, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e060" xlink:type="simple"/></inline-formula>, achieves the theoretical limit of the MSE under the linear gaussian model subject to the neural capacity constraint. This constraint can be defined either for the neural population, i.e., with respect to the total variance of neural responses (total power constraint), <disp-formula id="pcbi.1003761.e061"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e061" xlink:type="simple"/><label>(5)</label></disp-formula>or more strictly for the individual neurons, i.e., with respect to the individual neural variance (the individual power constraint), <disp-formula id="pcbi.1003761.e062"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e062" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e063" xlink:type="simple"/></inline-formula> is the diagonal components of a matrix, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e064" xlink:type="simple"/></inline-formula> is the <italic>M</italic>-dimensional vector whose elements are all 1. Note eq. 6 implies eq. 5. Importantly, the minimum MSEs under those two conditions are identical <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>. The difference between the two solutions is only in the left orthogonal matrix of the singular value decomposition of the encoding matrix, <disp-formula id="pcbi.1003761.e065"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e065" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e066" xlink:type="simple"/></inline-formula> is some <italic>M</italic>-dimensional orthogonal matrix, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e067" xlink:type="simple"/></inline-formula> is a unique diagonal matrix whose diagonal elements are the modulation transfer function (or the gain in the spectrum domain) of the encoding, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e068" xlink:type="simple"/></inline-formula> is the eigenvector matrix of the original signal covariance. To summarize, the minimum value of MSE, the coordinates of the encoding (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e069" xlink:type="simple"/></inline-formula>), and its power spectrum (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e070" xlink:type="simple"/></inline-formula>) are uniquely determined and in common with the optimization problems with total or individual power constraints. For the derivation of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e071" xlink:type="simple"/></inline-formula>, readers should refer to <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>.</p>
<p>The whitening matrix, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e072" xlink:type="simple"/></inline-formula>, removes all the second-order regularities, both of the signal statistics and of the signal blur <xref ref-type="bibr" rid="pcbi.1003761-Bell2">[48]</xref>, and the resulting covariance is the identity matrix with a scaling factor <italic>c</italic>, <disp-formula id="pcbi.1003761.e073"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e073" xlink:type="simple"/><label>(8)</label></disp-formula></p>
<p>This scaling is computed such that the neural capacity constraint is satisfied just as in the proposed model (i.e., eq. 5 or 6), namely, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e074" xlink:type="simple"/></inline-formula>. Note that whitening is defined independent of the level of sensory noise <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e075" xlink:type="simple"/></inline-formula> up to this scaling factor, and that the higher is the noise level, the smaller the scaling. This leads to the vertical translation of the whitening spectra at different sensory SNRs (see <xref ref-type="fig" rid="pcbi-1003761-g006">Figure 6</xref>). Finally, whitening for an undercomplete case, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e076" xlink:type="simple"/></inline-formula>, is computed with respect to the first <italic>M</italic> principal components of the original signal as in the prior ICA studies <xref ref-type="bibr" rid="pcbi.1003761-Hyvrinen1">[85]</xref>.</p>
</sec><sec id="s4b">
<title>Multiplicity of the optimal solution</title>
<p>In general there exist multiple encoding matrices <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e077" xlink:type="simple"/></inline-formula> that achieve the optimal MSE. Note the MSE (eq. 4) is invariant with orthogonal matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e078" xlink:type="simple"/></inline-formula> (eq. 7), and so is the total power constraint (eq. 5). Therefore, subject to the total power constraint, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e079" xlink:type="simple"/></inline-formula> is optimal with any choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e080" xlink:type="simple"/></inline-formula>. On the other hand, in order to satisfy the individual power constraint (eq. 6), some specific <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e081" xlink:type="simple"/></inline-formula> needs to be chosen <xref ref-type="bibr" rid="pcbi.1003761-Doi4">[47]</xref>. The proposed model assumes the individual power constraint so that individual neurons have the same, constant neural precision.</p>
<p>To examine the MSE and the spectrum, there is no need to choose a specific <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e082" xlink:type="simple"/></inline-formula> because they are independent of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e083" xlink:type="simple"/></inline-formula>. The reconstructed signal depends on the choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e084" xlink:type="simple"/></inline-formula> in a weak manner. (The singular value decomposition of the optimal <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e085" xlink:type="simple"/></inline-formula> has <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e086" xlink:type="simple"/></inline-formula> as the right orthogonal matrix, so <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e087" xlink:type="simple"/></inline-formula> cancels out in the multiplication, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e088" xlink:type="simple"/></inline-formula>. The reconstructed signal is expressed as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e089" xlink:type="simple"/></inline-formula>, so the choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e090" xlink:type="simple"/></inline-formula> makes a difference only in the second term of the reconstruction, i.e., how the neural noise appears in the reconstruction.) In <xref ref-type="fig" rid="pcbi-1003761-g004">Figure 4</xref> we used a random orthogonal matrix for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e091" xlink:type="simple"/></inline-formula> in favor of a large scale image reconstruction; see <xref ref-type="bibr" rid="pcbi.1003761-Doi3">[46]</xref> for reconstructions subject to the individual power constraint but with small image patches.</p>
<p>The receptive field structure depends on the choice of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e092" xlink:type="simple"/></inline-formula>, as illustrated in <xref ref-type="fig" rid="pcbi-1003761-g007">Figure 7</xref>. We examined three kinds of additional constraints (on the top of the individual power constraint) to choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e093" xlink:type="simple"/></inline-formula>: (i) <italic>weight sparsity</italic> measured by the <italic>L</italic><sup>1</sup>-norm of the receptive field weights, <disp-formula id="pcbi.1003761.e094"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e094" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e095" xlink:type="simple"/></inline-formula> denotes the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e096" xlink:type="simple"/></inline-formula> entry of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e097" xlink:type="simple"/></inline-formula>; (ii) <italic>response sparsity</italic> measured by the negative log-likelihood with a sparse generalized gaussian distribution, <disp-formula id="pcbi.1003761.e098"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e098" xlink:type="simple"/><label>(10)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e099" xlink:type="simple"/></inline-formula> is the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e100" xlink:type="simple"/></inline-formula> neuron's representation before neural noise is added, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e101" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e102" xlink:type="simple"/></inline-formula> is the standard deviation of the individual neural response, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e103" xlink:type="simple"/></inline-formula> a parameter to define the shape of the distribution (we used <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e104" xlink:type="simple"/></inline-formula>), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e105" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1003761-Box1">[86]</xref>; (iii) <italic>spatial locality</italic> measured by the weighted <italic>L</italic><sup>2</sup>-norm of the squared receptive field weights, <disp-formula id="pcbi.1003761.e106"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e106" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e107" xlink:type="simple"/></inline-formula> is the weighting (or penalty) defined for each neuron, <italic>j</italic>, by the squared distance between the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e108" xlink:type="simple"/></inline-formula> entry and the one with the peak value in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e109" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4c">
<title>An algorithm to derive the solution with an additional constraint</title>
<p>Solutions in <xref ref-type="fig" rid="pcbi-1003761-g007">Figure 7</xref> which respectively satisfy (a) no additional constraint, (b) weight sparsity, (c) response sparsity, or (d) spatial locality, are derived as follows. Let the individual power constraint of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e110" xlink:type="simple"/></inline-formula> neuron, <disp-formula id="pcbi.1003761.e111"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e111" xlink:type="simple"/><label>(12)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e112" xlink:type="simple"/></inline-formula> is the covariance of the sensory representation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e113" xlink:type="simple"/></inline-formula>.</p>
<p>1. Initialize <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e114" xlink:type="simple"/></inline-formula> with some <italic>M</italic>-dimensional orthogonal matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e115" xlink:type="simple"/></inline-formula>.</p>
<p>2. Update <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e116" xlink:type="simple"/></inline-formula> where <disp-formula id="pcbi.1003761.e117"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e117" xlink:type="simple"/><label>(13)</label></disp-formula>is the gradient of the individual power constraint and the additional constraint, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e118" xlink:type="simple"/></inline-formula> is a parameter which sets the importance of the additional constraint, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e119" xlink:type="simple"/></inline-formula> (see eq. 9–11) relative to the individual power constraint, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e120" xlink:type="simple"/></inline-formula>. The additional constraint is selected by the index <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e121" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e122" xlink:type="simple"/></inline-formula> when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e123" xlink:type="simple"/></inline-formula> (no additional constraint). Note that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e124" xlink:type="simple"/></inline-formula> is better in terms of satisfying the constraints than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e125" xlink:type="simple"/></inline-formula>, but is no longer guaranteed to be optimal in terms of MSE.</p>
<p>3. Project <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e126" xlink:type="simple"/></inline-formula> onto the optimal MSE solution manifold subject to the total power constraint, which is parameterized by the <italic>M</italic>-dimensional orthogonal matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e127" xlink:type="simple"/></inline-formula>. This is solved algebraically by finding the <italic>M</italic> -dimensional orthogonal matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e128" xlink:type="simple"/></inline-formula> that corresponds to the closest point in the solution manifold in the Euclidean distance, <disp-formula id="pcbi.1003761.e129"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003761.e129" xlink:type="simple"/><label>(14)</label></disp-formula>with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e130" xlink:type="simple"/></inline-formula> the Frobenius norm <xref ref-type="bibr" rid="pcbi.1003761-Doi5">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Gower1">[87]</xref>.</p>
<p>4. Update the solution as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e131" xlink:type="simple"/></inline-formula>.</p>
<p>5. Repeat until <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e132" xlink:type="simple"/></inline-formula> satisfies the convergence criteria for the individual power and additional constraints.</p>
<p>This algorithm is not guaranteed to find a solution, but we observed that it could find solutions with reasonable tolerance for the individual power constraint (i.e., ≤1% of violation; note the total power constraint is exactly satisfied thanks to eq. 14). <xref ref-type="supplementary-material" rid="pcbi.1003761.s006">Figure S6</xref> shows that the additional desired properties (weight sparsity, response sparsity, or spatial locality) were optimized in the respective populations. Finally, we observed that the algorithm is susceptible to local minima.</p>
</sec><sec id="s4d">
<title>An alternative algorithm for the solution with spatial locality</title>
<p>If we could express the desired additional properties of a population of receptive fields in a matrix form, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e133" xlink:type="simple"/></inline-formula>, then the optimal solution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e134" xlink:type="simple"/></inline-formula> (subject to the total power constraint) closest to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e135" xlink:type="simple"/></inline-formula> can readily be derived with eq. 14. An important example of this method is with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e136" xlink:type="simple"/></inline-formula> in the complete case. It has been proposed that the retinal transform should minimally change the observed signal to generate the neural representation <xref ref-type="bibr" rid="pcbi.1003761-Atick4">[88]</xref>, i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e137" xlink:type="simple"/></inline-formula> should be as close as possible to the identity, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e138" xlink:type="simple"/></inline-formula>. In this case, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e139" xlink:type="simple"/></inline-formula>, and the encoding matrix is given by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e140" xlink:type="simple"/></inline-formula>. This “symmetric” solution was examined earlier with information maximization <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref> and with whitening <xref ref-type="bibr" rid="pcbi.1003761-Atick4">[88]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Atick5">[89]</xref> (which is also called ZCA in the literature <xref ref-type="bibr" rid="pcbi.1003761-Bell1">[8]</xref>).</p>
<p>This algorithm is not limited to the complete case. To derive a spatially localized solution in an undercomplete case, one can set rows of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e141" xlink:type="simple"/></inline-formula> with uniformly tiled gaussian bumps (which may be seen as a generalization of the identity in the undercomplete case). In this study, the locations of the bumps were computed with k-means algorithms with respect to the uniformly distributed samples in the visual field, and the sigma of the gaussians was set by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e142" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e143" xlink:type="simple"/></inline-formula> is the radius of ideal (but unrealizable) circles that completely pack the visual field. We examined different values of the sigma from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e144" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e145" xlink:type="simple"/></inline-formula>, and found that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e146" xlink:type="simple"/></inline-formula> results in the best average locality (eq. 11). The resulting solution is comparable with the one derived with an explicit spatial locality constraint (eq. 11); the spatially localized solutions presented in this article were derived with this alternative algorithm.</p>
</sec><sec id="s4e">
<title>Simulating retinal conditions</title>
<p>There are about twenty types of RGCs in the primate retina which subserve a variety of visual tasks and computations <xref ref-type="bibr" rid="pcbi.1003761-Masland1">[90]</xref>. Here, as in the earlier studies <xref ref-type="bibr" rid="pcbi.1003761-Ruderman1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003761-Atick1">[25]</xref>, we focus on the computational problem of accurately encoding the image signal with high spatial resolution which is thought to be carried out by the so-called midget type, although the model does not make distinctions among different cell types.</p>
<p>According to the measured cell ratio (<xref ref-type="fig" rid="pcbi-1003761-g002">Figure 2</xref>), we set the number of cone photoreceptors (namely, the number of pixels in the small image region) and that of model RGCs as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e147" xlink:type="simple"/></inline-formula> (the ratio is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e148" xlink:type="simple"/></inline-formula>) at the fovea, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e149" xlink:type="simple"/></inline-formula> (the ratio is 27.2) at the periphery. The image sizes were chosen to maintain the number of elements in the encoding matrix to be computationally manageable.</p>
</sec><sec id="s4f">
<title>Natural image statistics</title>
<p>Both the proposed and whitening models are adapted to the second-order statistics. Therefore, the solution can be computed only with the covariance matrix of the original signal, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e150" xlink:type="simple"/></inline-formula>. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e151" xlink:type="simple"/></inline-formula> using the eigenvalue decomposition, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e152" xlink:type="simple"/></inline-formula> is the eigenvector matrix and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e153" xlink:type="simple"/></inline-formula> is a diagonal matrix consisting of the eigenvalues (or the power spectrum).</p>
<p>For the image reconstruction of 121×121 pixel images (<xref ref-type="fig" rid="pcbi-1003761-g004">Figures 4</xref>–<xref ref-type="fig" rid="pcbi-1003761-g005">5</xref>), the power spectrum of the original signal (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e154" xlink:type="simple"/></inline-formula>) is assumed to be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e155" xlink:type="simple"/></inline-formula> with <italic>f</italic> the spatial frequency. The spectrum at <italic>f</italic> = 0 (i.e., the DC component) is set to zero because the signal is assumed to be zero-mean. The eigenvectors (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e156" xlink:type="simple"/></inline-formula>) are assumed to be the two-dimensional discrete Fourier basis with the size of 121×121. These two components define a high-dimensional (14,941-dimensional) covariance matrix. Employing this covariance model allowed us to examine image reconstructions in a much larger scale than those in the previous studies (e.g., 8×8 pixel image patches in <xref ref-type="bibr" rid="pcbi.1003761-Doi2">[31]</xref>). In this article we report the MSE in percent error relative to the original signal variance: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e157" xlink:type="simple"/></inline-formula>.</p>
<p>For the predictions of the retinal code, the signal covariance <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003761.e158" xlink:type="simple"/></inline-formula> is empirically computed with 507,904 image patches (15×15 or 35×35 pixels) randomly sampled from a calibrated 62 natural image data set <xref ref-type="bibr" rid="pcbi.1003761-Doi7">[91]</xref>. Each image consists of 500×640 pixels with the human L cone spectral sensitivity and the cone nonlinearity. We assigned one pixel to one cone photoreceptor, which corresponds to a sampling density of the human cone photoreceptors of 120 cycle/degree at the fovea and 25 cycle/degree at the periphery (50° eccentricity) <xref ref-type="bibr" rid="pcbi.1003761-Rodieck2">[92]</xref>. To derive the solution with response sparsity, however, higher-order statistics are required; in this case, we sampled data from the same natural image data set during the optimization.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003761.s001" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003761.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p><bold>The optimal solution as a function of signal correlation.</bold></p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003761.s002" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003761.s002" position="float" xlink:type="simple"><label>Figure S2</label><caption>
<p><bold>The optimal solution in the case of no blur.</bold> These should be compared with the first two cases in <xref ref-type="supplementary-material" rid="pcbi.1003761.s001">Figure S1</xref>.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003761.s003" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003761.s003" position="float" xlink:type="simple"><label>Figure S3</label><caption>
<p><bold>The optimal solution as a function of sensory SNR.</bold></p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003761.s004" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003761.s004" position="float" xlink:type="simple"><label>Figure S4</label><caption>
<p><bold>The optimal solution as a function of neural SNR.</bold></p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003761.s005" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003761.s005" position="float" xlink:type="simple"><label>Figure S5</label><caption>
<p><bold>The optimal solution with different neural population sizes.</bold> <italic>Row 1</italic>: one neuron in the population, or undercomplete case. <italic>Rows 2 &amp; 3</italic>: three neurons in the population, or overcomplete case. These are two different, but equally optimal, solutions. The number labels indicate the corresponding encoding vectors, the axis of neural representations, and the decoding vectors. The two neuron (or complete) case is shown in the middle row of <xref ref-type="supplementary-material" rid="pcbi.1003761.s004">Figure S4</xref>.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003761.s006" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003761.s006" position="float" xlink:type="simple"><label>Figure S6</label><caption>
<p><bold>Resource costs in equally-optimal solutions.</bold> Resource costs are computed with the solutions presented in <xref ref-type="fig" rid="pcbi-1003761-g007">Figure 7</xref> with the same labels indicating the type of additional constraints. Each row presents the additional fraction of resource cost relative to the optimized population, i.e., weight sparsity (top, optimized in b), response sparsity (middle, optimized in c), and spatial locality (bottom; optimized in d). Each plot indicates the mean (dot) and the 5<sup>th</sup> to 95<sup>th</sup> percentile range (bar), respectively.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003761.s007" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003761.s007" position="float" xlink:type="simple"><label>Text S1</label><caption>
<p><bold>Characterization of the optimal solution with a two-dimensional signal.</bold></p>
<p>(PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>This work made use of the High Performance Computing Resource in the Core Facility for Advanced Research Computing at Case Western Reserve University.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1003761-Barlow1"><label>1</label>
<mixed-citation publication-type="other" xlink:type="simple">Barlow HB (1961) Possible principles underlying the transformation of sensory messages. In: Rosenblith WA, editor, Sensory communication, MA: MIT Press. pp. 217–234.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Field1"><label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1987</year>) <article-title>Relations between the statistics of natural images and the response properties of cortical cells</article-title>. <source>J Opt Soc Am A</source> <volume>4</volume>: <fpage>2379</fpage>–<lpage>2394</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Kersten1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kersten</surname><given-names>D</given-names></name> (<year>1987</year>) <article-title>Predictability and redundancy of natural images</article-title>. <source>J Opt Soc Am A</source> <volume>4</volume>: <fpage>2395</fpage>–<lpage>2400</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Barlow2"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name> (<year>2001</year>) <article-title>Redundancy reduction revisited</article-title>. <source>Network: Comput Neural Syst</source> <volume>12</volume>: <fpage>241</fpage>–<lpage>253</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Simoncelli1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>, <name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name> (<year>2001</year>) <article-title>Natural image statistics and neural representation</article-title>. <source>Annual Review of Neuroscience</source> <volume>24</volume>: <fpage>1193</fpage>–<lpage>216</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Bialek1"><label>6</label>
<mixed-citation publication-type="other" xlink:type="simple">Bialek W, de Ruyter van Steveninck RR, Tishby N (2006) Efficient representation as a design principle for neural coding and computation. In: IEEE International Symposium on Information Theory. pp. 659–663.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Olshausen1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1996</year>) <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source> <volume>381</volume>: <fpage>607</fpage>–<lpage>609</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Bell1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1997</year>) <article-title>The independent components of natural scenes are edge filters</article-title>. <source>Vision Research</source> <volume>37</volume>: <fpage>3327</fpage>–<lpage>3338</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-vanVreeswijk1"><label>9</label>
<mixed-citation publication-type="other" xlink:type="simple">van Vreeswijk C (2001) Whence sparseness. In: Advances in Neural Information Processing Systems 13 (NIPS*2000), The MIT Press. pp. 180–186.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Hubel1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Wiesel</surname><given-names>TN</given-names></name> (<year>1959</year>) <article-title>Receptive fields of single neurones in the cat's striate cortex</article-title>. <source>Journal of Physiology</source> <volume>148</volume>: <fpage>574</fpage>–<lpage>591</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Daugman1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Daugman</surname><given-names>JG</given-names></name> (<year>1985</year>) <article-title>Uncertainty relation for resolution in space, spatial frequency, and orientation optimized by two-dimensional visual cortical filters</article-title>. <source>J Opt Soc Am A</source> <volume>2</volume>: <fpage>1160</fpage>–<lpage>1169</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Jones1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jones</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Palmer</surname><given-names>LA</given-names></name> (<year>1987</year>) <article-title>An evaluation of the two-dimensional gabor filter model of simple receptive fields in cat striate cortex</article-title>. <source>Journal of Neurophysiology</source> <volume>58</volume>: <fpage>1233</fpage>–<lpage>1258</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Ringach1"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ringach</surname><given-names>DL</given-names></name> (<year>2002</year>) <article-title>Spatial structure and symmetry of simple-cell receptive fields in macaque primary visual cortex</article-title>. <source>Journal of Neurophysiology</source> <volume>88</volume>: <fpage>455</fpage>–<lpage>463</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Kuffler1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kuffler</surname><given-names>SW</given-names></name> (<year>1953</year>) <article-title>Discharge patterns and functional organization of mammalian retina</article-title>. <source>Journal of Neurophysiology</source> <volume>16</volume>: <fpage>37</fpage>–<lpage>68</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Barlow3"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Barlow</surname><given-names>HB</given-names></name>, <name name-style="western"><surname>Fitzhugh</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Kuffler</surname><given-names>SW</given-names></name> (<year>1957</year>) <article-title>Change of organization in the receptive fields of the cat's retina during dark adaptation</article-title>. <source>Journal of Physiology</source> <volume>137</volume>: <fpage>338</fpage>–<lpage>354</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Rodieck1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rodieck</surname><given-names>RW</given-names></name> (<year>1965</year>) <article-title>Quantitative analysis of cat retinal ganglion cell response to visual stimuli</article-title>. <source>Vision Res</source> <volume>5</volume>: <fpage>583</fpage>–<lpage>601</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Orban1"><label>17</label>
<mixed-citation publication-type="other" xlink:type="simple">Orban GA (1984) Neuronal operations in the visual cortex. Springer-Verlag.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Dhingra1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dhingra</surname><given-names>NK</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>RG</given-names></name> (<year>2004</year>) <article-title>Spike generator limits efficiency of information transfer in a retinal ganglion cell</article-title>. <source>Journal of Neuroscience</source> <volume>24</volume>: <fpage>2914</fpage>–<lpage>2922</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Westheimer1"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Westheimer</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Campbell</surname><given-names>FW</given-names></name> (<year>1962</year>) <article-title>Light distribution in the image formed by the living human eye</article-title>. <source>Journal of Optical Society of America</source> <volume>52</volume>: <fpage>1040</fpage>–<lpage>1044</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Srinivasan1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Dubs</surname><given-names>A</given-names></name> (<year>1982</year>) <article-title>Predictive coding: a fresh view of inhibition in the retina</article-title>. <source>Proc R Soc Lond B</source> <volume>216</volume>: <fpage>427</fpage>–<lpage>459</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Abshire1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abshire</surname><given-names>PA</given-names></name>, <name name-style="western"><surname>Andreou</surname><given-names>AG</given-names></name> (<year>2001</year>) <article-title>A communication channel model for information transmission in the blowy photoreceptor</article-title>. <source>BioSystems</source> <volume>62</volume>: <fpage>113</fpage>–<lpage>133</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-AlaLaurila1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ala-Laurila</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Greschner</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname><given-names>EJ</given-names></name>, <name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name> (<year>2011</year>) <article-title>Cone photoreceptor contributions to noise and correlations in the retinal output</article-title>. <source>Nature neuroscience</source> <volume>14</volume>: <fpage>1309</fpage>–<lpage>1316</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Ratliff1"><label>23</label>
<mixed-citation publication-type="other" xlink:type="simple">Ratliff F (1965) Mach bands: quantitative studies on neural networks in the retina. Holden-Day.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Ruderman1"><label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ruderman</surname><given-names>DL</given-names></name> (<year>1994</year>) <article-title>Designing receptive fields for highest fidelity</article-title>. <source>Network: Comput Neural Syst</source> <volume>5</volume>: <fpage>147</fpage>–<lpage>155</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Atick1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name> (<year>1990</year>) <article-title>Towards a theory of early visual processing</article-title>. <source>Neural Computation</source> <volume>2</volume>: <fpage>308</fpage>–<lpage>320</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Atick2"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name> (<year>1992</year>) <article-title>What does the retina know about natural scenes?</article-title> <source>Neural Computation</source> <volume>4</volume>: <fpage>196</fpage>–<lpage>210</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-vanHateren1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Hateren</surname><given-names>JH</given-names></name> (<year>1992</year>) <article-title>A theory of maximizing sensory information</article-title>. <source>Biological Cybernetics</source> <volume>68</volume>: <fpage>23</fpage>–<lpage>29</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Borst1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>1999</year>) <article-title>Information theory and neural coding</article-title>. <source>Nature Neuroscience</source> <volume>2</volume>: <fpage>947</fpage>–<lpage>957</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Doi1"><label>29</label>
<mixed-citation publication-type="other" xlink:type="simple">Doi E, Lewicki MS (2005) Sparse coding of natural images using an overcomplete set of limited capacity units. In: Advances in Neural Information Processing Systems (NIPS*2004). MIT Press, volume 17, pp. 377–384.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Bethge1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Factorial coding of natural images: how effective are linear models in removing higher-order dependencies?</article-title> <source>J Opt Soc Am A</source> <volume>23</volume>: <fpage>1253</fpage>–<lpage>1268</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Doi2"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doi</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Balcan</surname><given-names>DC</given-names></name>, <name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name> (<year>2007</year>) <article-title>Robust coding over noisy overcomplete channels</article-title>. <source>IEEE Transactions on Image Processing</source> <volume>16</volume>: <fpage>442</fpage>–<lpage>452</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Tkacik1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tkacik</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Prentice</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Balasubramanian</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name> (<year>2010</year>) <article-title>Optimal population coding by noisy spiking neurons</article-title>. <source>Proc Natl Acad Sci USA</source> <volume>107</volume>: <fpage>14419</fpage>–<lpage>24</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Anderson1"><label>33</label>
<mixed-citation publication-type="other" xlink:type="simple">Anderson CH, DeAngelis GC (2004) Population codes and signal to noise ratios in primary visual cortex. In: Society for Neuroscience Abstract. p. 822.3.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Puchalla1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Puchalla</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Harris</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Berry</surname><given-names>MJ</given-names></name> (<year>2005</year>) <article-title>Redundancy in the population code of the retina</article-title>. <source>Neuron</source> <volume>46</volume>: <fpage>493</fpage>–<lpage>504</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Schneidman1"><label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Berry</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Segev</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name> (<year>2006</year>) <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population</article-title>. <source>Nature</source> <volume>440</volume>: <fpage>1007</fpage>–<lpage>1012</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Shlens1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shlens</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>GD</given-names></name>, <name name-style="western"><surname>Gauthier</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Grivich</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Petrusca</surname><given-names>D</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>The structure of multineuron firing patterns in primate retina</article-title>. <source>Journal of Neuroscience</source> <volume>26</volume>: <fpage>8254</fpage>–<lpage>8266</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Laughlin1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>JC</given-names></name> (<year>1998</year>) <article-title>The metabolic cost of neural information</article-title>. <source>Nature Neuroscience</source> <volume>1</volume>: <fpage>36</fpage>–<lpage>41</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Laughlin2"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name> (<year>2001</year>) <article-title>Energy as a constraint on the coding and processing of sensory information</article-title>. <source>Curr Opin Neurobiol</source> <volume>11</volume>: <fpage>475</fpage>–<lpage>80</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Chklovskii1"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chklovskii</surname><given-names>DB</given-names></name>, <name name-style="western"><surname>Schikorski</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Stevens</surname><given-names>CF</given-names></name> (<year>2002</year>) <article-title>Wiring optimization in cortical circuits</article-title>. <source>Neuron</source> <volume>34</volume>: <fpage>341</fpage>–<lpage>347</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Balasubramanian1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balasubramanian</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Berry</surname><given-names>MJ</given-names></name> (<year>2002</year>) <article-title>A test of metabolically efficient coding in the retina</article-title>. <source>Network: Computation in Neural Systems</source> <volume>13</volume>: <fpage>531</fpage>–<lpage>52</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Vincent1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vincent</surname><given-names>BT</given-names></name>, <name name-style="western"><surname>Baddeley</surname><given-names>RJ</given-names></name> (<year>2003</year>) <article-title>Synaptic energy efficiency in retinal processing</article-title>. <source>Research</source> <volume>43</volume>: <fpage>1283</fpage>–<lpage>1290</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Chklovskii2"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chklovskii</surname><given-names>DB</given-names></name> (<year>2004</year>) <article-title>Exact solution for the optimal neuronal layout problem</article-title>. <source>Neural Computation</source> <volume>16</volume>: <fpage>2067</fpage>–<lpage>2078</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Vincent2"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vincent</surname><given-names>BT</given-names></name>, <name name-style="western"><surname>Baddeley</surname><given-names>RJ</given-names></name>, <name name-style="western"><surname>Troscianko</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Gilchrist</surname><given-names>ID</given-names></name> (<year>2005</year>) <article-title>Is the early visual system optimised to be energy efficient?</article-title> <source>Network: Comput Neural Syst</source> <volume>16</volume>: <fpage>175</fpage>–<lpage>190</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Perge1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Perge</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Sterling</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Balasubramanian</surname><given-names>V</given-names></name> (<year>2009</year>) <article-title>How the optic nerve allocates space, energy, capacity, and information</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>7917</fpage>–<lpage>28</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Sengupta1"><label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengupta</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name> (<year>2013</year>) <article-title>Balanced excitatory and inhibitory synaptic currents promote efficient coding and metabolic efficiency</article-title>. <source>PLoS Computational Biology</source> <volume>9</volume>: <fpage>e1003263</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Doi3"><label>46</label>
<mixed-citation publication-type="other" xlink:type="simple">Doi E, Lewicki MS (2007) A theory of retinal population coding. In: Advances in Neural Information Processing Systems (NIPS*2006). MIT Press, volume <volume>19</volume> , pp. 353–360.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Doi4"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doi</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name> (<year>2011</year>) <article-title>Characterization of minimum error linear coding with sensory and neural noise</article-title>. <source>Neural Computation</source> <volume>23</volume>: <fpage>2498</fpage>–<lpage>2510</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Bell2"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1995</year>) <article-title>An information-maximization approach to blind separation and blind deconvolution</article-title>. <source>Neural Computation</source> <volume>7</volume>: <fpage>1129</fpage>–<lpage>1159</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Graham1"><label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Graham</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Chandler</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>2006</year>) <article-title>Can the theory of “whitening” explain the centersurround properties of retinal ganglion cell receptive fields?</article-title> <source>Vision Research</source> <volume>46</volume>: <fpage>2901</fpage>–<lpage>2913</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Navarro1"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Navarro</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Artal</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Williams</surname><given-names>DR</given-names></name> (<year>1993</year>) <article-title>Modulation transfer of the human eye as a function of retinal eccentricity</article-title>. <source>Journal of Optical Society of America A</source> <volume>10</volume>: <fpage>201</fpage>–<lpage>212</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Mukamel1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mukamel</surname><given-names>EA</given-names></name>, <name name-style="western"><surname>Schnitzer</surname><given-names>MJ</given-names></name> (<year>2005</year>) <article-title>Retinal coding of visual scenes – repetitive and redundant too?</article-title> <source>Neuron</source> <volume>5</volume>: <fpage>357</fpage>–<lpage>9</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Sengupta2"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengupta</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Stemmler</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name> (<year>2010</year>) <article-title>Action potential energy efficiency varies among neuron types in vertebrates and invertebrates</article-title>. <source>PLoS Computational Biology</source> <volume>6</volume>: <fpage>e1000840</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Laughlin3"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>2003</year>) <article-title>Communication in neuronal networks</article-title>. <source>Science</source> <volume>301</volume>: <fpage>1870</fpage>–<lpage>1874</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-EnrothCugell1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Enroth-Cugell</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Robson</surname><given-names>JG</given-names></name> (<year>1966</year>) <article-title>The contrast sensitivity of retinal ganglion cells of the cat</article-title>. <source>Journal of Physiology</source> <volume>187</volume>: <fpage>517</fpage>–<lpage>552</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Shapley1"><label>55</label>
<mixed-citation publication-type="other" xlink:type="simple">Shapley R, Enroth-Cugell C (1984) Visual adaptation and retinal gain controls. In: Osborne N, Chader G, editors, Progress in Retinal Research, Pergamon, volume <volume>3</volume> . pp. 263–346.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Haft1"><label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haft</surname><given-names>M</given-names></name>, <name name-style="western"><surname>van Hemmen</surname><given-names>JL</given-names></name> (<year>1998</year>) <article-title>Theory and implementation of infomax filters for the retina</article-title>. <source>Network: Computation in Neural Systems</source> <volume>9</volume>: <fpage>39</fpage>–<lpage>71</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Borghuis1"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Borghuis</surname><given-names>BG</given-names></name>, <name name-style="western"><surname>Ratliff</surname><given-names>CP</given-names></name>, <name name-style="western"><surname>Smith</surname><given-names>RG</given-names></name>, <name name-style="western"><surname>Sterling</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Balasubramanian</surname><given-names>V</given-names></name> (<year>2008</year>) <article-title>Design of a neuronal array</article-title>. <source>Journal of Neuroscience</source> <volume>28</volume>: <fpage>3178</fpage>–<lpage>3189</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Eichhorn1"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Eichhorn</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sinz</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Bethge</surname><given-names>M</given-names></name> (<year>2009</year>) <article-title>Natural image coding in V1: how much use is orientation selectivity?</article-title> <source>PLoS Computational Biology</source> <volume>5</volume>: <fpage>1</fpage>–<lpage>16</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Doi5"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doi</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Gauthier</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>GD</given-names></name>, <name name-style="western"><surname>Shlens</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Sher</surname><given-names>A</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Efficient coding of spatial information in the primate retina</article-title>. <source>Journal of Neuroscience</source> <volume>32</volume>: <fpage>16256</fpage>–<lpage>16264</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Atick3"><label>60</label>
<mixed-citation publication-type="other" xlink:type="simple">Atick JJ, Li Z, Redlich AN (1990) Color coding and its interaction with spatiotemporal processing in the retina. Technical Report IASSNS-HEP-90/75, Institute for Advanced Study.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Li1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Li</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name> (<year>1994</year>) <article-title>Toward a theory of the striate cortex</article-title>. <source>Neural Computation</source> <volume>6</volume>: <fpage>127</fpage>–<lpage>146</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Doi6"><label>62</label>
<mixed-citation publication-type="other" xlink:type="simple">Doi E, Paninski L, Simoncelli EP (2008) Maximizing sensory information with neural populations of arbitrary size. In: Computational and Systems Neuroscience (CoSyNe). Salt Lake City, Utah.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Karklin1"><label>63</label>
<mixed-citation publication-type="other" xlink:type="simple">Karklin Y, Simoncelli EP (2011) Efficient coding of natural images with a population of noisy linear-nonlinear neurons. In: Advances in Neural Information Processing Systems (NIPS*2010), MIT Press, volume <volume>24</volume> . pp. 999–1007.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Pitkow1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pitkow</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Meister</surname><given-names>M</given-names></name> (<year>2012</year>) <article-title>Decorrelation and efficient coding by retinal ganglion cells</article-title>. <source>Nature Neuroscience</source> <volume>15</volume>: <fpage>628</fpage>–<lpage>635</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Guo1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guo</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Shamai</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Verdu</surname><given-names>S</given-names></name> (<year>2005</year>) <article-title>Mutual information and minimum mean-square error in gaussian channels</article-title>. <source>IEEE Transactions on Information Theory</source> <volume>51</volume>: <fpage>1261</fpage>–<lpage>1282</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Field2"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Field</surname><given-names>GD</given-names></name>, <name name-style="western"><surname>Gauthier</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Sher</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Greschner</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Machado</surname><given-names>TA</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Functional connectivity in the retina at the resolution of photoreceptors</article-title>. <source>Nature</source> <volume>467</volume>: <fpage>673</fpage>–<lpage>677</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-DeVries1"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DeVries</surname><given-names>SH</given-names></name>, <name name-style="western"><surname>Baylor</surname><given-names>DA</given-names></name> (<year>1997</year>) <article-title>Mosaic arrangement of ganglion cell receptive fields in rabbit retina</article-title>. <source>Journal of Neurophysiology</source> <volume>78</volume>: <fpage>2048</fpage>–<lpage>2060</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Gauthier1"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gauthier</surname><given-names>JL</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>GD</given-names></name>, <name name-style="western"><surname>Sher</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Shlens</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Greschner</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2009</year>) <article-title>Uniform signal redundancy of parasol and midget ganglion cells in primate retina</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>4675</fpage>–<lpage>4680</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Applebury1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Applebury</surname><given-names>ML</given-names></name>, <name name-style="western"><surname>Antoch</surname><given-names>MP</given-names></name>, <name name-style="western"><surname>Baxter</surname><given-names>LC</given-names></name>, <name name-style="western"><surname>Chun</surname><given-names>LL</given-names></name>, <name name-style="western"><surname>Falk</surname><given-names>JD</given-names></name>, <etal>et al</etal>. (<year>2000</year>) <article-title>The murine cone photoreceptor: a single cone type expresses both S and M opsins with retinal spatial patterning</article-title>. <source>Neuron</source> <volume>27</volume>: <fpage>513</fpage>–<lpage>523</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Goodchild1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Goodchild</surname><given-names>AK</given-names></name>, <name name-style="western"><surname>Ghosh</surname><given-names>KK</given-names></name>, <name name-style="western"><surname>Martin</surname><given-names>PR</given-names></name> (<year>1996</year>) <article-title>Comparison of photoreceptor spatial density and ganglion cell morphology in the retina of human, macaque monkey, cat, and the marmoset Callithrix jacchus</article-title>. <source>Journal of Comparative Neurology</source> <volume>366</volume>: <fpage>55</fpage>–<lpage>75</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Famiglietti1"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Famiglietti</surname><given-names>EV</given-names></name>, <name name-style="western"><surname>Sharpe</surname><given-names>SJ</given-names></name> (<year>1995</year>) <article-title>Regional topography of rod and immunocytochemically characterized “blue” and “green” cone photoreceptors in rabbit retina</article-title>. <source>Visual neuroscience</source> <volume>12</volume>: <fpage>1151</fpage>–<lpage>1175</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Field3"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Field</surname><given-names>GD</given-names></name>, <name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name> (<year>2002</year>) <article-title>Nonlinear signal transfer from mouse rods to bipolar cells and implications for visual sensitivity</article-title>. <source>Neuron</source> <volume>34</volume>: <fpage>773</fpage>–<lpage>785</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Field4"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Field</surname><given-names>GD</given-names></name>, <name name-style="western"><surname>Sampath</surname><given-names>AP</given-names></name>, <name name-style="western"><surname>Rieke</surname><given-names>F</given-names></name> (<year>2005</year>) <article-title>Retinal processing near absolute threshold: from behavior to mechanism</article-title>. <source>Annual Review of Physiology</source> <volume>67</volume>: <fpage>491</fpage>–<lpage>514</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Schwartz1"><label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schwartz</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name> (<year>2001</year>) <article-title>Natural signal statistics and sensory gain control</article-title>. <source>Nature Neuroscience</source> <volume>4</volume>: <fpage>819</fpage>–<lpage>825</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Lewicki1"><label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name> (<year>2002</year>) <article-title>Efficient coding of natural sounds</article-title>. <source>Nature Neuroscience</source> <volume>5</volume>: <fpage>356</fpage>–<lpage>363</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Smith1"><label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>EC</given-names></name>, <name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name> (<year>2006</year>) <article-title>Efficient auditory coding</article-title>. <source>Nature</source> <volume>439</volume>: <fpage>978</fpage>–<lpage>982</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Chechik1"><label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chechik</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Bar-Yosef</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Young</surname><given-names>ED</given-names></name>, <name name-style="western"><surname>Tishby</surname><given-names>N</given-names></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>Reduction of information redundancy in the ascending auditory pathway</article-title>. <source>Neuron</source> <volume>51</volume>: <fpage>359</fpage>–<lpage>368</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Rubel1"><label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rubel</surname><given-names>EW</given-names></name>, <name name-style="western"><surname>Fritzsch</surname><given-names>B</given-names></name> (<year>2002</year>) <article-title>Auditory system development: primary auditory neurons and their targets</article-title>. <source>Annual review of neuroscience</source> <volume>25</volume>: <fpage>51</fpage>–<lpage>101</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Kistler1"><label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kistler</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Wightman</surname><given-names>FL</given-names></name> (<year>1992</year>) <article-title>A model of head-related transfer functions based on principal components analysis and minimum-phase reconstruction</article-title>. <source>Journal of Acoustical Society of America</source> <volume>91</volume>: <fpage>1637</fpage>–<lpage>1647</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Olsen1"><label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olsen</surname><given-names>SR</given-names></name>, <name name-style="western"><surname>Bhandawat</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Wilson</surname><given-names>RI</given-names></name> (<year>2010</year>) <article-title>Divisive normalization in olfactory population codes</article-title>. <source>Neuron</source> <volume>66</volume>: <fpage>287</fpage>–<lpage>299</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Luo1"><label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Luo</surname><given-names>SX</given-names></name>, <name name-style="western"><surname>Axel</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Abbott</surname><given-names>LR</given-names></name> (<year>2010</year>) <article-title>Generating sparse and selective third-order responses in the olfactory system of the y</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>107</volume>: <fpage>10713</fpage>–<lpage>10718</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Abbott1"><label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>, <name name-style="western"><surname>Luo</surname><given-names>SX</given-names></name> (<year>2007</year>) <article-title>A step toward optimal coding in olfaction</article-title>. <source>Nature neuroscience</source> <volume>10</volume>: <fpage>1342</fpage>–<lpage>1343</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Cleland1"><label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cleland</surname><given-names>TA</given-names></name> (<year>2010</year>) <article-title>Early transformations in odor representation</article-title>. <source>Trends in neurosciences</source> <volume>33</volume>: <fpage>130</fpage>–<lpage>139</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Gire1"><label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gire</surname><given-names>DH</given-names></name>, <name name-style="western"><surname>Restrepo</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Greer</surname><given-names>C</given-names></name>, <name name-style="western"><surname>De Carlos</surname><given-names>JA</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Temporal processing in the olfactory system: can we see a smell?</article-title> <source>Neuron</source> <volume>78</volume>: <fpage>416</fpage>–<lpage>432</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Hyvrinen1"><label>85</label>
<mixed-citation publication-type="other" xlink:type="simple">Hyvärinen A, Karhunen J, Oja E (2001) Independent Component Analysis. John Wiley &amp; Sons.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Box1"><label>86</label>
<mixed-citation publication-type="other" xlink:type="simple">Box GEP, Tiao GC (1973) Bayesian Inference in Statistical Analysis. John Wiley &amp; Sons.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Gower1"><label>87</label>
<mixed-citation publication-type="other" xlink:type="simple">Gower JC, Dijksterhuis GB (2004) Procrustes problems. Oxford University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Atick4"><label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name> (<year>1993</year>) <article-title>What does post-adaptation color appearance reveal about cortical color representation?</article-title> <source>Vision Research</source> <volume>33</volume>: <fpage>123</fpage>–<lpage>129</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Atick5"><label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Atick</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Redlich</surname><given-names>AN</given-names></name> (<year>1993</year>) <article-title>Convergent algorithm for sensory receptive field development</article-title>. <source>Neural Computation</source> <volume>5</volume>: <fpage>45</fpage>–<lpage>60</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Masland1"><label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Masland</surname><given-names>RH</given-names></name> (<year>2012</year>) <article-title>The neuronal organization of the retina</article-title>. <source>Neuron</source> <volume>76</volume>: <fpage>266</fpage>–<lpage>280</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Doi7"><label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Doi</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Inui</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Lee</surname><given-names>TW</given-names></name>, <name name-style="western"><surname>Wachtler</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>2003</year>) <article-title>Spatiochromatic receptive field properties derived from information-theoretic analyses of cone mosaic responses to natural scenes</article-title>. <source>Neural Computation</source> <volume>15</volume>: <fpage>397</fpage>–<lpage>417</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Rodieck2"><label>92</label>
<mixed-citation publication-type="other" xlink:type="simple">Rodieck RW (1998) The First Steps in Seeing. MA: Sinauer.</mixed-citation>
</ref>
<ref id="pcbi.1003761-Ahmad1"><label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ahmad</surname><given-names>KM</given-names></name>, <name name-style="western"><surname>Klug</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Herr</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Sterling</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Schein</surname><given-names>S</given-names></name> (<year>2003</year>) <article-title>Cell density ratios in a foveal patch in macaque retina</article-title>. <source>Visual Neuroscience</source> <volume>20</volume>: <fpage>189</fpage>–<lpage>209</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
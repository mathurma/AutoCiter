<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-0583R2</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000577</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Sensory Systems</subject><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>Analyzing Short-Term Noise Dependencies of Spike-Counts in Macaque Prefrontal Cortex Using Copulas and the Flashlight Transformation</article-title><alt-title alt-title-type="running-head">Spike-Count Copula Models</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Onken</surname><given-names>Arno</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Grünewälder</surname><given-names>Steffen</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Munk</surname><given-names>Matthias H. J.</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Obermayer</surname><given-names>Klaus</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>School of Electrical Engineering and Computer Science, Technische Universität Berlin, Berlin, Germany</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Bernstein Center for Computational Neuroscience Berlin, Berlin, Germany</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Centre for Computational Statistics and Machine Learning, University College London, London, United Kingdom</addr-line>       </aff><aff id="aff4"><label>4</label><addr-line>Max Planck Institute for Biological Cybernetics, Tübingen, Germany</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Aertsen</surname><given-names>Ad</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University of Freiburg, Germany</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">aonken@cs.tu-berlin.de</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: MHJM. Performed the experiments: MHJM. Analyzed the data: AO. Contributed reagents/materials/analysis tools: AO SG KO. Wrote the paper: AO SG KO.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>11</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>26</day><month>11</month><year>2009</year></pub-date><volume>5</volume><issue>11</issue><elocation-id>e1000577</elocation-id><history>
<date date-type="received"><day>21</day><month>5</month><year>2009</year></date>
<date date-type="accepted"><day>23</day><month>10</month><year>2009</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Onken et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Simultaneous spike-counts of neural populations are typically modeled by a Gaussian distribution. On short time scales, however, this distribution is too restrictive to describe and analyze multivariate distributions of discrete spike-counts. We present an alternative that is based on copulas and can account for arbitrary marginal distributions, including Poisson and negative binomial distributions as well as second and higher-order interactions. We describe maximum likelihood-based procedures for fitting copula-based models to spike-count data, and we derive a so-called flashlight transformation which makes it possible to move the tail dependence of an arbitrary copula into an arbitrary orthant of the multivariate probability distribution. Mixtures of copulas that combine different dependence structures and thereby model different driving processes simultaneously are also introduced. First, we apply copula-based models to populations of integrate-and-fire neurons receiving partially correlated input and show that the best fitting copulas provide information about the functional connectivity of coupled neurons which can be extracted using the flashlight transformation. We then apply the new method to data which were recorded from macaque prefrontal cortex using a multi-tetrode array. We find that copula-based distributions with negative binomial marginals provide an appropriate stochastic model for the multivariate spike-count distributions rather than the multivariate Poisson latent variables distribution and the often used multivariate normal distribution. The dependence structure of these distributions provides evidence for common inhibitory input to all recorded stimulus encoding neurons. Finally, we show that copula-based models can be successfully used to evaluate neural codes, e.g., to characterize stimulus-dependent spike-count distributions with information measures. This demonstrates that copula-based models are not only a versatile class of models for multivariate distributions of spike-counts, but that those models can be exploited to understand functional dependencies.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>The brain has an enormous number of neurons that do not work alone but in an ensemble. Yet, mostly individual neurons were measured in the past and therefore models were restricted to independent neurons. With the advent of new multi-electrode techniques, however, it becomes possible to measure a great number of neurons simultaneously. As a result, models of how populations of neurons co-vary are becoming increasingly important. Here, we describe such a framework based on so-called copulas. Copulas allow to separate the neural variation structure of the population from the variability of the individual neurons. Contrary to standard models, versatile dependence structures can be described using this approach. We explore what additional information is provided by the detailed dependence. For simulated neurons, we show that the variation structure of the population allows inference of the underlying connectivity structure of the neurons. The power of the approach is demonstrated on a memory experiment in macaque monkey. We show that our framework describes the measurements better than the standard models and identify possible network connections of the measured neurons.</p>
</abstract><funding-group><funding-statement>This work was supported by BMBF grant 01GQ0410. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="13"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>So far, it is still unknown which statistics are crucial for analysis in order to understand the neural code. One approach is to analyze simultaneous spike-counts of neural populations. Responses from populations of sensory neurons vary even when the same stimulus is presented repeatedly, and the variations between the simultaneous spike-counts are usually correlated (<italic>noise correlations</italic>) at least for neighboring neurons. These noise correlations have been subject of a substantial number of studies (see <xref ref-type="bibr" rid="pcbi.1000577-Averbeck1">[1]</xref> for a review). For computational reasons, however, these studies typically assume Gaussian noise. Thus, correlated spike rates are generally modeled by multivariate normal distributions with a specific covariance matrix that describes all pairwise linear correlations.</p>
<p>For long time intervals or high firing rates, the average number of spikes is sufficiently large for the <italic>central limit theorem</italic> to apply and the normal distribution is a good approximation for the spike-count distributions. Several experimental findings, however, suggest that processing of sensory information can take place on shorter time scales, involving only tens to hundreds of milliseconds <xref ref-type="bibr" rid="pcbi.1000577-Bair1">[2]</xref>,<xref ref-type="bibr" rid="pcbi.1000577-Kohn1">[3]</xref>. In this regime the normal distribution is no longer a valid approximation:</p>
<list list-type="order"><list-item>
<p>Its marginals are continuous with a symmetric shape, whereas empirical distributions of real spike-counts tend to have a positive skew (see <xref ref-type="fig" rid="pcbi-1000577-g001">Figure 1A</xref>).</p>
</list-item><list-item>
<p>The normal distribution has to be heuristically modified in order to avoid positive probabilities for negative values which are not meaningful for spike-counts. This is a major issue for low rates for which the probability of negative values would be high.</p>
</list-item><list-item>
<p>The dependence structure of a multivariate normal distribution is always elliptical, whereas spike-count data often show a so-called tail-dependence with probability mass concentrated on one of the corners (see <xref ref-type="fig" rid="pcbi-1000577-g001">Figure 1A</xref>).</p>
</list-item><list-item>
<p>The multivariate normal distribution assumes second order correlations only. Although it was shown that pairwise interactions are sufficient for describing the spike-count distributions of retinal ganglion cells and cortex cells <italic>in vitro</italic> <xref ref-type="bibr" rid="pcbi.1000577-Schneidman1">[4]</xref>, there is evidence for significant higher order interactions of spike-counts recorded from cortical areas <italic>in vivo</italic> <xref ref-type="bibr" rid="pcbi.1000577-Michel1">[5]</xref>.</p>
</list-item></list>
<fig id="pcbi-1000577-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g001</object-id><label>Figure 1</label><caption>
<title>Modeling a spike-count distribution.</title>
<p>(A) Normalized empirical distributions of spike-counts from a pair of neurons recorded in macaque prefrontal cortex (see Section “<xref ref-type="sec" rid="s2">Materials and Methods</xref>”). The bin size was <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e001" xlink:type="simple"/></inline-formula>. Gray values of the squares denote the number of occurrences of pairs of spike-counts (dark to bright corresponding to low to high, see scale bar). The corresponding marginals are plotted below and left of the coordinate axes. The distribution is based on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e002" xlink:type="simple"/></inline-formula> occurrences. (B) Joint distribution and marginals of the discretized and rectified multivariate normal distribution with the mean and covariance matrix set to the sample mean and sample covariance matrix. (C) Joint distribution and marginals of the best fitting Clayton copula (see Section “Multivariate Spike-Count Distributions Based on Copulas”, parameter: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e003" xlink:type="simple"/></inline-formula>) and negative binomial marginals (parameters: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e004" xlink:type="simple"/></inline-formula>).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g001" xlink:type="simple"/></fig>
<p>Though not widespread for modeling spike-counts, alternative models have been proposed in previous studies that have Poisson distributed marginals and separate parameters for higher order correlations, e.g. the multiple interaction process model <xref ref-type="bibr" rid="pcbi.1000577-Kuhn1">[6]</xref> and the compound Poisson model <xref ref-type="bibr" rid="pcbi.1000577-Ehm1">[7]</xref>. Both models are point processes. In terms of their induced spike-count distributions these models are special cases of the multivariate Poisson latent variables distribution first introduced by Kawamura <xref ref-type="bibr" rid="pcbi.1000577-Kawamura1">[8]</xref> and presented in a compact matrix notation by Karlis and Meligkotsidou <xref ref-type="bibr" rid="pcbi.1000577-Karlis1">[9]</xref>. Similar to the multivariate normal distribution this model has also a couple of shortcomings for spike-count modeling: (1) Only Poisson-marginals can be modeled. (2) Negative correlations cannot be represented. (3) The dependence structure is inflexible: features like tail dependence cannot be modeled.</p>
<p>We use and extend a versatile class of models for multivariate discrete distributions that overcome the shortcomings of the afore-mentioned models <xref ref-type="bibr" rid="pcbi.1000577-Onken1">[10]</xref>,<xref ref-type="bibr" rid="pcbi.1000577-Berkes1">[11]</xref>. These models are based on the concept of <italic>copulas</italic> <xref ref-type="bibr" rid="pcbi.1000577-Nelsen1">[12]</xref>, which allow to combine arbitrary marginal distributions using a rich set of dependence structures. In neuroscience they were also applied to model the distribution of continuous first-spike-latencies <xref ref-type="bibr" rid="pcbi.1000577-Jenison1">[13]</xref>.</p>
<p><xref ref-type="fig" rid="pcbi-1000577-g001">Figure 1</xref> illustrates the copula concept using spike-count data from two real neurons. <xref ref-type="fig" rid="pcbi-1000577-g001">Figure 1A</xref> shows the bivariate empirical distribution and its two marginals. The distribution of the counts depends on the length of the time bin that is used to count the spikes, here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e005" xlink:type="simple"/></inline-formula>. In the case considered, the correlation at low counts is higher than at high counts. This is called <italic>lower tail dependence</italic> <xref ref-type="bibr" rid="pcbi.1000577-Nelsen1">[12]</xref>. <xref ref-type="fig" rid="pcbi-1000577-g001">Figure 1B</xref> shows the discretized and rectified multivariate normal distribution. On the other hand, the spike-count probabilities for a copula-based distribution (<xref ref-type="fig" rid="pcbi-1000577-g001">Figure 1C</xref>) correspond well to the empirical distribution in <xref ref-type="fig" rid="pcbi-1000577-g001">Figure 1A</xref>.</p>
<p>The paper is organized as follows. The next Section “<xref ref-type="sec" rid="s2">Materials and Methods</xref>” contains a description of methodological details regarding the multivariate normal distribution, the multivariate Poisson latent variables distribution, the copula approach for spike-counts and the model fitting procedures. In this section we will also introduce a novel transformation for copula families. The method is innovative and yields a novel result. We will then describe the computational model used to generate synthetic data and the experimental recording and analysis procedures. In the Section “<xref ref-type="sec" rid="s3">Results</xref>” copula-based models will be applied to artificial data generated by integrate-and-fire models of coupled neural populations and to data recorded from macaque prefrontal cortex (PFC) during a visual memory task. The appropriateness of the models is also investigated. The paper concludes with a discussion of the strengths and weaknesses of the copula approach for spike-counts.</p>
</sec><sec id="s2">
<title>Materials and Methods</title>
<sec id="s2a">
<title>Ethics Statement</title>
<p>All procedures were approved by the local authorities (Regierungspräsidium) and are in full compliance with the guidelines of the European Community (EUVD 86/609/EEC) for the care and use of laboratory animals.</p>
</sec><sec id="s2b">
<title>The Discretized Multivariate Normal Distribution</title>
<p>The multivariate normal (MVN) distribution is characterized by a probability density over continuous variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e006" xlink:type="simple"/></inline-formula> and its cumulative distribution function (CDF) with mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e007" xlink:type="simple"/></inline-formula> and covariance matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e008" xlink:type="simple"/></inline-formula> is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e009" xlink:type="simple"/></disp-formula></p>
<p>In order to apply it to spike-count distributions (which are discrete and non-negative) it is discretized and rectified (probability for negative values is set to zero). Its CDF is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e010" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e011" xlink:type="simple"/></inline-formula> denotes the floor operation for the discretization. The probability mass function will have peaks at the zero count rows, due to the rectification of the CDF. It would be desirable to distribute the cut off mass equally to the complete domain. However, this is infeasible for more than three dimensions, because the necessary normalization term is computationally too time-consuming. Note that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e012" xlink:type="simple"/></inline-formula> is no longer the mean of the distribution corresponding to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e013" xlink:type="simple"/></inline-formula>, because the mean is shifted to larger values as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e014" xlink:type="simple"/></inline-formula> is rectified. This shift grows with the dimension <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e015" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s2c">
<title>The Poisson Latent Variables Distribution</title>
<p>The Poisson latent variables distribution is characterized by a probability mass function (PMF) over non-negative integer variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e016" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000577-Karlis1">[9]</xref>. A random variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e017" xlink:type="simple"/></inline-formula> with this distribution is composed of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e018" xlink:type="simple"/></inline-formula> latent variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e019" xlink:type="simple"/></inline-formula>. These latent variables are independent univariate Poisson distributed with rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e020" xlink:type="simple"/></inline-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e021" xlink:type="simple"/></inline-formula> takes the form <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e022" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e023" xlink:type="simple"/></inline-formula> is a mixture matrix. The PMF of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e024" xlink:type="simple"/></inline-formula> is then given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e025" xlink:type="simple"/></disp-formula></p>
<p>When we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e026" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e027" xlink:type="simple"/></inline-formula> we can vary all pairwise and higher order interactions separately using the rates of the latent variables. However, only non-negative correlations can be modeled, because the rates of the latent variables are non-negative. Furthermore, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e028" xlink:type="simple"/></inline-formula> are marginally Poisson distributed.</p>
</sec><sec id="s2d">
<title>Copula Models of Multivariate Distributions</title>
<p>A copula is a cumulative distribution function (CDF) which is defined on the unit hypercube and which has uniform marginals <xref ref-type="bibr" rid="pcbi.1000577-Nelsen1">[12]</xref>. Formally, a copula <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e029" xlink:type="simple"/></inline-formula> is defined as follows:</p>
<sec id="s2d1">
<title>Definition 1</title>
<p><italic>A d</italic>-copula <italic>is a function </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e030" xlink:type="simple"/></inline-formula><italic> such that </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e031" xlink:type="simple"/></inline-formula><italic>:</italic></p>
<list list-type="order"><list-item>
<p><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e032" xlink:type="simple"/></inline-formula> <italic>if at least one coordinate of </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e033" xlink:type="simple"/></inline-formula><italic> is</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e034" xlink:type="simple"/></inline-formula>.</p>
</list-item><list-item>
<p><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e035" xlink:type="simple"/></inline-formula> <italic>if all coordinates of </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e036" xlink:type="simple"/></inline-formula><italic> are </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e037" xlink:type="simple"/></inline-formula><italic> except</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e038" xlink:type="simple"/></inline-formula>.</p>
</list-item><list-item>
<p><italic>Let </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e039" xlink:type="simple"/></inline-formula><italic>, then </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e040" xlink:type="simple"/></inline-formula><italic>.</italic></p>
</list-item></list>
<p>Property 3 states that the mass in every hypercube is non-negative. Together with property 1 it guarantees that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e041" xlink:type="simple"/></inline-formula> is a proper CDF on the unit hypercube, whereas property 2 ensures uniform marginals.</p>
<p>Copulas can now be used to couple arbitrary marginal CDFs to form a joint CDF. This is formalized in Sklar's Theorem <xref ref-type="bibr" rid="pcbi.1000577-Nelsen1">[12]</xref>,<xref ref-type="bibr" rid="pcbi.1000577-Sklar1">[14]</xref>, which states:</p>
</sec><sec id="s2d2">
<title>Theorem 1</title>
<p><italic>Let </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e042" xlink:type="simple"/></inline-formula><italic> be a d-dimensional cumulative distribution function with marginals </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e043" xlink:type="simple"/></inline-formula><italic>. Then there exists a d-copula </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e044" xlink:type="simple"/></inline-formula><italic> such that for all </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e045" xlink:type="simple"/></inline-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e046" xlink:type="simple"/></disp-formula></p>
<p><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e047" xlink:type="simple"/></inline-formula> <italic>is unique, if </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e048" xlink:type="simple"/></inline-formula> <italic>are all continuous, and unique on </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e049" xlink:type="simple"/></inline-formula>, if <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e050" xlink:type="simple"/></inline-formula> <italic>are discrete.</italic></p>
<p><italic>Conversely, if </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e051" xlink:type="simple"/></inline-formula><italic> is a d-copula and</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e052" xlink:type="simple"/></inline-formula> <italic>are CDFs, then the function </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e053" xlink:type="simple"/></inline-formula><italic> defined by </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e054" xlink:type="simple"/></inline-formula><italic> is a d-dimensional CDF with marginals</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e055" xlink:type="simple"/></inline-formula>.</p>
<p>Theorem 1 provides a way to construct multivariate distributions by attaching marginal CDFs to copulas. Copulas make an attachment possible, because they have continuous uniform marginals. In the univariate case a continuous uniform distribution on the unit interval can be easily transformed into any other distribution by applying the inverse of its CDF (inversion method). In the case of discrete marginal distributions, however, typical measures of dependence, such as Pearson's correlation coefficient or Kendall's <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e056" xlink:type="simple"/></inline-formula> are effected by the shape of these marginals. This is due to the restricted uniqueness of the copula to the range of the discrete marginal distributions <xref ref-type="bibr" rid="pcbi.1000577-Genest1">[15]</xref>. Moreover, an interpretation of the dependence structure for varying discrete marginals is difficult <xref ref-type="bibr" rid="pcbi.1000577-Genest1">[15]</xref>. In this study, copula families are compared with respect to fixed marginals.</p>
</sec></sec><sec id="s2e">
<title>Multivariate Spike-Count Distributions Based on Copulas</title>
<p>Our goal is to construct multivariate distributions for simultaneously recorded spike-counts that can model a wide range of dependence structures. Copulas make it possible to model multivariate distributions based on two distinct parts: the distributions of the individual elements and the dependence structure. Let us now assume that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e057" xlink:type="simple"/></inline-formula> represents the spike-count of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e058" xlink:type="simple"/></inline-formula> within a given interval. According to Theorem 1 we can then describe the joint cumulative distribution function of the spike counts <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e059" xlink:type="simple"/></inline-formula> by choosing a copula <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e060" xlink:type="simple"/></inline-formula> from a particular family, and by setting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e061" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e062" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e063" xlink:type="simple"/></inline-formula> are the models of the marginal distributions, i.e. the cumulative distributions of spike-counts of the individual neurons. Often, the Poisson distribution is a good approximation to spike-count variations of single neurons <xref ref-type="bibr" rid="pcbi.1000577-Tolhurst1">[16]</xref>, hence the CDFs of the marginals take the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e064" xlink:type="simple"/></disp-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e065" xlink:type="simple"/></inline-formula> is the mean spike-count of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e066" xlink:type="simple"/></inline-formula> for a given bin size. A more flexible marginal is the negative binomial distribution,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e067" xlink:type="simple"/></disp-formula>which allows to model spike-count distributions showing overdispersion. Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e068" xlink:type="simple"/></inline-formula> is the gamma function, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e069" xlink:type="simple"/></inline-formula> is again the mean spike-count of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e070" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e071" xlink:type="simple"/></inline-formula> is a positive parameter, which controls the degree of overdispersion. The smaller the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e072" xlink:type="simple"/></inline-formula>, the greater is the Fano factor, and as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e073" xlink:type="simple"/></inline-formula> approaches infinity, the negative binomial distribution converges to the Poisson distribution.</p>
<p>The second part of the model is the copula family. Many different families have been discussed in the literature in the past. Families differ by the number of free parameters and by the class of dependence structures they can represent. The most simplistic copula is the product copula defined as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e074" xlink:type="simple"/></inline-formula> for which independence is attained. We selected a number of useful copula families (see <xref ref-type="table" rid="pcbi-1000577-t001">Table 1</xref>). <xref ref-type="fig" rid="pcbi-1000577-g002">Figure 2</xref> shows their bivariate probability density functions (PDFs).</p>
<fig id="pcbi-1000577-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g002</object-id><label>Figure 2</label><caption>
<title>Bivariate copula probability densities of commonly used families.</title>
<p>(A) Clayton copula (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e075" xlink:type="simple"/></inline-formula>). (B) Gumbel-Hougaard copula (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e076" xlink:type="simple"/></inline-formula>). (C) Frank copula (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e077" xlink:type="simple"/></inline-formula>). (D) Ali-Mikhail-Haq copula (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e078" xlink:type="simple"/></inline-formula>). (E) Farlie-Gumbel-Morgenstern copula (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e079" xlink:type="simple"/></inline-formula>).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g002" xlink:type="simple"/></fig><table-wrap id="pcbi-1000577-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.t001</object-id><label>Table 1</label><caption>
<title>Five commonly used Copula families.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000577-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Copula Family</td>
<td align="left" colspan="1" rowspan="1"> Cumulative Distribution Function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e080" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">Constraints</td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">Clayton</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e081" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e082" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Gumbel-Hougaard</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e083" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e084" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Frank</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e085" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e086" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">Ali-Mikhail-Haq</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e087" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e088" xlink:type="simple"/></inline-formula></td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">FGM</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e089" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">See caption<xref ref-type="table-fn" rid="nt102">1</xref></td>
</tr>
</tbody>
</table></alternatives><table-wrap-foot><fn id="nt101"><label/><p>Cumulative distribution functions of five copula families are listed. The parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e090" xlink:type="simple"/></inline-formula> denotes the dimension of the distribution. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e091" xlink:type="simple"/></inline-formula> are the function arguments.</p></fn><fn id="nt102"><label>1</label><p>Constraints for the Farlie-Gumbel-Morgenstern family: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e092" xlink:type="simple"/></inline-formula></p></fn></table-wrap-foot></table-wrap>
<p>The Clayton family has a so-called lower tail dependence: the correlation between its elements is higher for low values than for high values (see <xref ref-type="fig" rid="pcbi-1000577-g002">Figure 2A</xref>). The scalar parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e093" xlink:type="simple"/></inline-formula> controls the strength of dependence. Note that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e094" xlink:type="simple"/></inline-formula> does not only control the strength of pairwise interactions but also the degree of higher order interactions. We define <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e095" xlink:type="simple"/></inline-formula>.</p>
<p>The Gumbel-Hougaard (short Gumbel) family has an upper tail dependence. Here, the region of high correlation is in the upper right corner of the density. Hence, the correlation between its elements is higher for high values than for low values (see <xref ref-type="fig" rid="pcbi-1000577-g002">Figure 2B</xref>). The scalar parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e096" xlink:type="simple"/></inline-formula> controls the strength of dependence.</p>
<p>The Frank family has no tail dependence. There is no difference between the correlation for low and for high values (see <xref ref-type="fig" rid="pcbi-1000577-g002">Figure 2C</xref>). Again, the scalar parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e097" xlink:type="simple"/></inline-formula> controls the strength of dependence and we define <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e098" xlink:type="simple"/></inline-formula>.</p>
<p>The Ali-Mikhail-Haq (AMH) family models are positively ordered, i.e. for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e099" xlink:type="simple"/></inline-formula> it holds for all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e100" xlink:type="simple"/></inline-formula> (see <xref ref-type="fig" rid="pcbi-1000577-g002">Figure 2D</xref>). Again we define <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e101" xlink:type="simple"/></inline-formula>.</p>
<p>The Farlie-Gumbel-Morgenstern (FGM) family has <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e102" xlink:type="simple"/></inline-formula> parameters that individually determine the pairwise and higher order interactions. It has <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e103" xlink:type="simple"/></inline-formula> parameters less than the Poisson latent variables distribution because the rates of the neurons can be parametrized by the marginals. Non-zero values of the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e104" xlink:type="simple"/></inline-formula> indicate the presence of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e105" xlink:type="simple"/></inline-formula> order interaction. For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e106" xlink:type="simple"/></inline-formula> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e107" xlink:type="simple"/></inline-formula> order interactions are absent. If, for example all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e108" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e109" xlink:type="simple"/></inline-formula>, the corresponding probability distribution includes only parameters of second order, similar to the multivariate normal distribution. The constraints on the parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e110" xlink:type="simple"/></inline-formula>, however, constrain the corresponding correlation to be small in terms of their absolute value.</p>
</sec><sec id="s2f">
<title>The Flashlight Transformation and Mixtures of Copulas</title>
<p>We now introduce a novel extension of standard copula models, which is particularly useful for modeling distributions of spike-counts. It is based on the orthant dependence concept. Here, an <italic>orthant</italic> refers to one of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e111" xlink:type="simple"/></inline-formula> hypercubes of equal size in the unit hypercube, i.e. a “corner” of the copula distribution. Let us consider a distribution with a so-called lower tail dependence (see <xref ref-type="fig" rid="pcbi-1000577-g003">Figure 3A</xref>), i.e. a distribution, for which the correlation between spike-counts of two neurons is higher for low values than for high values. We now introduce the <italic>flashlight transformation</italic> which allows to shift the region of high correlation to an arbitrary orthant (see <xref ref-type="fig" rid="pcbi-1000577-g003">Figure 3B–D</xref>). The whole dependence structure between spike-counts is rotated accordingly, but remains unchanged otherwise. The transformation is a function that operates on CDFs. Yet, it rotates the corresponding PDF, not the CDF.</p>
<fig id="pcbi-1000577-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g003</object-id><label>Figure 3</label><caption>
<title>Probability densities of four different orthant dependencies generated by the flashlight transformation.</title>
<p>The original distribution was the bivariate Clayton copula (parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e112" xlink:type="simple"/></inline-formula>). The transformation takes a set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e113" xlink:type="simple"/></inline-formula> as a parameter which contains the indices of the elements that are transformed. (A) Original Clayton copula, which is also recovered for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e114" xlink:type="simple"/></inline-formula>. (B) Element <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e115" xlink:type="simple"/></inline-formula> is transformed (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e116" xlink:type="simple"/></inline-formula>). (C) Element <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e117" xlink:type="simple"/></inline-formula> is transformed (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e118" xlink:type="simple"/></inline-formula>). (D) Both elements are transformed (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e119" xlink:type="simple"/></inline-formula>).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g003" xlink:type="simple"/></fig>
<p>The flashlight transformation is specified in the following theorem (see <xref ref-type="supplementary-material" rid="pcbi.1000577.s001">Text S1</xref> in the supplementary material):</p>
<sec id="s2f1">
<title>Theorem 2</title>
<p><italic>Let </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e120" xlink:type="simple"/></inline-formula><italic> be a d-copula, </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e121" xlink:type="simple"/></inline-formula><italic>, </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e122" xlink:type="simple"/></inline-formula><italic>, </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e123" xlink:type="simple"/></inline-formula><italic> a measure, and </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e124" xlink:type="simple"/></inline-formula><italic>. Then </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e125" xlink:type="simple"/></inline-formula><italic> is a d-copula and can be expressed as</italic><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e126" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e127" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e128" xlink:type="simple"/></inline-formula></p>
<p>The flashlight transformation is a generalization of the so-called survival transformation, which is well known in the economics literature <xref ref-type="bibr" rid="pcbi.1000577-Georges1">[17]</xref>, and which is recovered for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e129" xlink:type="simple"/></inline-formula>. An example is shown in <xref ref-type="fig" rid="pcbi-1000577-g003">Figure 3D</xref>.</p>
<p>For heterogeneous data more versatile dependence structures are required. In order to generate this flexibility, one can construct finite mixtures of copulas each of which is weighted by a parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e130" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000577-Fortin1">[18]</xref>. The CDF of mixtures of copulas takes the following form:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e131" xlink:type="simple"/></disp-formula></p>
<p>The latent variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e132" xlink:type="simple"/></inline-formula> represents the responsibility of the corresponding copula <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e133" xlink:type="simple"/></inline-formula>.</p>
</sec></sec><sec id="s2g">
<title>Model Fitting</title>
<p>Once a family of marginal distributions and a family of copulas for describing the dependence structure has been selected, model parameters have to be estimated from the data, i.e. from the empirical distribution. Here we suggest a method which is similar to maximum likelihood estimation.</p>
<p>Theorem 1 provides a method to construct multivariate CDFs based on copulas. Therefore, the approach yields a <italic>CDF</italic> of a multivariate distribution. In order to calculate the likelihood we have to transform the CDF to a probability mass function (PMF).</p>
<p>For this purpose we define the sets <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e134" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e135" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e136" xlink:type="simple"/></inline-formula>. The probability of a particular set of spike-counts <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e137" xlink:type="simple"/></inline-formula> can then be expressed using only the CDF <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e138" xlink:type="simple"/></inline-formula>, making use of the so-called inclusion-exclusion principle of Poincaré and Sylvester <xref ref-type="bibr" rid="pcbi.1000577-Comtet1">[19]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e139" xlink:type="simple"/><label>(2)</label></disp-formula></p>
<p>Let<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e140" xlink:type="simple"/></disp-formula>denote the sum of log likelihoods of the marginal distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e141" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e142" xlink:type="simple"/></inline-formula> are the parameters of the chosen family of marginals. Furthermore, let<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e143" xlink:type="simple"/></disp-formula>be the log likelihood of the joint probability mass function, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e144" xlink:type="simple"/></inline-formula> denotes the parameter of the chosen copula family. The so-called <italic>inference for margins</italic> (IFM) method <xref ref-type="bibr" rid="pcbi.1000577-Joe1">[20]</xref> now proceeds in two steps. First, the marginal likelihoods are maximized separately:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e145" xlink:type="simple"/></disp-formula></p>
<p>Then, the full likelihood is maximized given the estimated marginal parameters:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e146" xlink:type="simple"/></disp-formula></p>
<p>It was shown that the IFM estimator is asymptotically efficient <xref ref-type="bibr" rid="pcbi.1000577-Joe1">[20]</xref>. The estimator is computationally more convenient than the maximum likelihood estimator, because parameter optimization in low dimensional parameter spaces needs less computation time.</p>
<p>Depending on whether the copula parameters are constrained, either the Nelder-Mead simplex method for unconstrained nonlinear optimization <xref ref-type="bibr" rid="pcbi.1000577-Lagarias1">[21]</xref> or the line-search algorithm for constrained nonlinear optimization <xref ref-type="bibr" rid="pcbi.1000577-Waltz1">[22]</xref> can be applied to estimate the copula parameters using Eqn 2 as the objective function.</p>
<p>For mixtures of copulas, where the values of the latent variables <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e147" xlink:type="simple"/></inline-formula> have to be estimated in addition, we suggest to use the expectation-maximization algorithm <xref ref-type="bibr" rid="pcbi.1000577-Dempster1">[23]</xref>,<xref ref-type="bibr" rid="pcbi.1000577-Hu1">[24]</xref>. In the expectation step, the weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e148" xlink:type="simple"/></inline-formula> are updated using<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e149" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e150" xlink:type="simple"/></inline-formula> is the PMF of the model based on the copula <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e151" xlink:type="simple"/></inline-formula>. In the maximization step the copula parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e152" xlink:type="simple"/></inline-formula> are determined for fixed values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e153" xlink:type="simple"/></inline-formula> by applying the IFM method. Both steps are repeated until parameter values converge.</p>
</sec><sec id="s2h">
<title>Leaky Integrate-and-Fire Model for Generation of Synthetic Data</title>
<p>The leaky integrate-and-fire neuron is a simple neuron model that models only subthreshold membrane potentials. The equation for the membrane potential is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e154" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e155" xlink:type="simple"/></inline-formula> denotes the resting membrane potential, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e156" xlink:type="simple"/></inline-formula> is the total membrane resistance, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e157" xlink:type="simple"/></inline-formula> is the synaptic input current, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e158" xlink:type="simple"/></inline-formula> is the time constant. The model is completed by a rule which states that whenever <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e159" xlink:type="simple"/></inline-formula> reaches a threshold <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e160" xlink:type="simple"/></inline-formula>, an action potential is fired and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e161" xlink:type="simple"/></inline-formula> is reset to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e162" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000577-Dayan1">[25]</xref>. In all of our simulations we used <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e163" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e164" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e165" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e166" xlink:type="simple"/></inline-formula>, and initialized <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e167" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e168" xlink:type="simple"/></inline-formula>. These are typical values that can be found in <xref ref-type="bibr" rid="pcbi.1000577-Dayan1">[25]</xref>.</p>
<p>Current-based synaptic input for an isolated presynaptic release that occurs at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e169" xlink:type="simple"/></inline-formula> can be modeled by the so-called <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e170" xlink:type="simple"/></inline-formula>-function <xref ref-type="bibr" rid="pcbi.1000577-Dayan1">[25]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e171" xlink:type="simple"/></disp-formula></p>
<p>The function reaches its peak <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e172" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e173" xlink:type="simple"/></inline-formula> and then decays with time constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e174" xlink:type="simple"/></inline-formula>. We can model an excitatory synapse by a positive <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e175" xlink:type="simple"/></inline-formula> and an inhibitory synapse by a negative <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e176" xlink:type="simple"/></inline-formula>. We used <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e177" xlink:type="simple"/></inline-formula> for excitatory synapses, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e178" xlink:type="simple"/></inline-formula> for inhibitory synapses, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e179" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s2i">
<title>Multi-Tetrode Recordings</title>
<p>Neural activity was recorded from the lateral prefrontal cortex within an area of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e180" xlink:type="simple"/></inline-formula> located on the ventral bank of the principal sulcus of an adult female rhesus monkey (<italic>macaca mulatta</italic>). Recordings were performed simultaneously from up to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e181" xlink:type="simple"/></inline-formula> adjacent sites with an array of individually movable fiber micro-tetrodes (manufactured by Thomas Recording) with an inter-tetrode distance of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e182" xlink:type="simple"/></inline-formula>. Data were sampled at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e183" xlink:type="simple"/></inline-formula> and bandpass filtered between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e184" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e185" xlink:type="simple"/></inline-formula>. Recording positions of individual electrodes were chosen to maximize the recorded activity and the signal quality. The recorded data were processed by a principal component analysis-based spike sorting method. Automatic cluster cutting was manually corrected by subsequent cluster merging if indicated by quantitative criteria such as the ISI-histograms or amplitude stability.</p>
<p>Activity was recorded while the monkey performed a visual working memory task. One out of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e186" xlink:type="simple"/></inline-formula> visual stimuli (fruits and vegetables) were presented for approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e187" xlink:type="simple"/></inline-formula>. After a delay of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e188" xlink:type="simple"/></inline-formula>, during which the monkey had to memorize the sample, a test stimulus (“test”) was presented and the monkey had to decide by differential button press whether both stimuli were the same or not. Correct responses were rewarded. Match and non-match trials were randomly presented with equal probability (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e189" xlink:type="simple"/></inline-formula>).</p>
<sec id="s2i1">
<title>Data preprocessing</title>
<p>We selected six neurons with stimulus specific responses, i.e. those neurons whose firing rate averaged over the time interval of presentation of the sample stimulus changed most compared to the pre-stimulus interval baseline. It turned out that each of these neurons was recorded from a different tetrode.</p>
<p>Spike trains were analyzed separately for each of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e190" xlink:type="simple"/></inline-formula> different stimuli and the four trial intervals: pre-stimulus, sample stimulus presentation, delay, and test stimulus presentation. Spike trains were binned into successive <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e191" xlink:type="simple"/></inline-formula> intervals and converted into six dimensional spike-counts for each bin. Due to the different interval lengths, the total sample size per condition varied between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e192" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e193" xlink:type="simple"/></inline-formula>. A representative example of the empirical distribution of a pair of these counts is presented in <xref ref-type="fig" rid="pcbi-1000577-g001">Figure 1A</xref>.</p>
</sec></sec><sec id="s2j">
<title>Estimation of Mutual Information</title>
<p>The mutual information between spike-counts <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e194" xlink:type="simple"/></inline-formula> and stimuli is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e195" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e196" xlink:type="simple"/></inline-formula> is the set of stimuli, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e197" xlink:type="simple"/></inline-formula> is the probability distribution over the stimuli, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e198" xlink:type="simple"/></inline-formula> is the likelihood of a neural response <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e199" xlink:type="simple"/></inline-formula> given a stimulus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e200" xlink:type="simple"/></inline-formula>. For higher dimensions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e201" xlink:type="simple"/></inline-formula> the sum over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e202" xlink:type="simple"/></inline-formula> prohibits an exact computation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e203" xlink:type="simple"/></inline-formula>, since the number of terms of the sum grows exponentially with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e204" xlink:type="simple"/></inline-formula>. The evaluation of this sum is therefore practically infeasible unless the number of neurons is very small. However, we can estimate the mutual information using Monte Carlo sampling. For each of the stimuli <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e205" xlink:type="simple"/></inline-formula>, we can estimate the second sum by drawing samples <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e206" xlink:type="simple"/></inline-formula> with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e207" xlink:type="simple"/></inline-formula>. The term<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e208" xlink:type="simple"/></disp-formula>will then converge to the second sum in Eqn 3, as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e209" xlink:type="simple"/></inline-formula> approaches infinity <xref ref-type="bibr" rid="pcbi.1000577-Robert1">[26]</xref>.</p>
</sec></sec><sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Reliability of Model Estimation</title>
<p>Typically the number of samples that can be obtained in electro-physiological experiments is small. Thus, it might appear to be hopeless to estimate a multidimensional model with a detailed dependence structure. However, since our marginal distributions are discrete the copula matters only at a small number of points. In the following, we will demonstrate that it is not always necessary to obtain a great number of samples for a reliable model estimation. For this purpose we selected the Clayton-copula model with negative binomial marginals as a ground truth model which was used to draw samples. We calculated the deviation of the log likelihood of the estimated model from the log likelihood of the ground truth model in percent of the ground truth log likelihood. The correlation strength of the ground truth model was varied by the Clayton parameter. The results are shown in <xref ref-type="fig" rid="pcbi-1000577-g004">Figure 4</xref> for three different Clayton parameters of the ground truth model. For moderate dependence strengths (as are typically found in the data) <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e210" xlink:type="simple"/></inline-formula> samples were sufficient for estimations of the log likelihood with an error of less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e211" xlink:type="simple"/></inline-formula>.</p>
<fig id="pcbi-1000577-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g004</object-id><label>Figure 4</label><caption>
<title>Deviation of the estimated likelihood from the likelihood for different dependence strengths.</title>
<p>The deviation is given in percent of the likelihood. Samples were drawn from a Clayton-copula model with negative binomial marginals. The marginals were parametrized by maximum likelihood estimates obtained on the entire data that is described in Section “Multi-Tetrode Recordings”. The vertical axis indicates the number of samples in the training set. The evaluation took place on a separate set of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e212" xlink:type="simple"/></inline-formula> samples. Above the black line the deviation is smaller than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e213" xlink:type="simple"/></inline-formula>. (A) Correlation coefficient <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e214" xlink:type="simple"/></inline-formula>. (B) Correlation coefficient <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e215" xlink:type="simple"/></inline-formula>. (C) Correlation coefficient <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e216" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g004" xlink:type="simple"/></fig></sec><sec id="s3b">
<title>Application of Copula-Based Models to Synthetic Data</title>
<p>One cause for dependence between spike-counts of different neurons are common input populations. Therefore, we investigated network models with different types of common input. We set up two current based leaky integrate-and-fire neurons (see Section “<xref ref-type="sec" rid="s2">Materials and Methods</xref>”) and three input populations modeled as Poisson spike generators. The left input population projected only to neuron 1 and the right input population projected only to neuron 2. The center input population was the common input population, projecting to both neuron 1 and neuron 2. We investigated all four combinations of excitatory (E) and inhibitory (I) projections from the common population to the two neurons (see <xref ref-type="fig" rid="pcbi-1000577-g005">Figure 5A</xref>1–A4).</p>
<fig id="pcbi-1000577-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g005</object-id><label>Figure 5</label><caption>
<title>Copula-based analysis of bivariate spike-count data.</title>
<p>(A1–A4) Neural network models used to generate the synthetic spike-count data. Two leaky integrate-and-fire neurons (“LIF1” and “LIF2”, see Section “<xref ref-type="sec" rid="s2">Materials and Methods</xref>”) receive spike inputs from three separate populations of neurons (rectangular boxes and circles), but only one population sends input to both of the neurons. All input spike trains were Poisson-distributed. Each neuron had a total inhibitory input rate of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e217" xlink:type="simple"/></inline-formula>. We had three times as many excitatory spikes as inhibitory spikes. We increased the absolute correlation between the spike-counts by shifting the rate of the left and right populations to the center population. The center population was active in half the simulation time. The total simulation time amounted to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e218" xlink:type="simple"/></inline-formula>. Spike-counts were calculated for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e219" xlink:type="simple"/></inline-formula> bins. (B) Empirical distribution for the model with an inhibitory input population (see A3) obtained for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e220" xlink:type="simple"/></inline-formula> bins and a correlation coefficient of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e221" xlink:type="simple"/></inline-formula>. (C1–C4) Log likelihoods of the best fitting Clayton copulas with negative binomial marginals as a function of the strength of the input correlation. Plots shown (C1 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e222" xlink:type="simple"/></inline-formula> C4) correspond to the four different network models (A1 <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e223" xlink:type="simple"/></inline-formula> A4). Dotted, dashed, solid, and dashed-dotted lines correspond to the best fitting Clayton copula with lower, lower-right, upper-left, and upper orthant dependence (see <xref ref-type="fig" rid="pcbi-1000577-g003">Figure 3</xref>). Copulas were fitted using the IFM estimators.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g005" xlink:type="simple"/></fig>
<p>In this network model a lower tail dependence should arise if the projections from the common input projection are mostly inhibitory: each time the common population is active the firing rates of both neurons will decrease simultaneously. Therefore, only low spike-counts should be strongly correlated and the Clayton family should provide a good fit to the responses of such a network. Similarly, two excitatory projections should result in an upper tail dependence and other combinations should become apparent as dependence blobs in other corners of the probability density function of the copula. The flashlight transformation shifts the dependence blob of a given copula with orthant dependence into other orthants of the probability density function and is thus capable of modeling different types of common input populations in a stochastic manner. For two neurons, the lower left corner models an inhibitory input population, the upper right corner models an excitatory input population, and the other corners model a combination of excitatory and inhibitory input populations.</p>
<p>The spike trains of the two neurons were binned into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e224" xlink:type="simple"/></inline-formula> intervals. We applied copula-based models with negative binomial marginals to fit the generated data from the four models using the IFM method (see Section “Model Fitting”). Four different copula families were applied: the unmodified bivariate Clayton family and the three remaining flashlight transformations of the Clayton family (<xref ref-type="fig" rid="pcbi-1000577-g003">Figure 3</xref>). <xref ref-type="fig" rid="pcbi-1000577-g005">Figure 5C</xref>1–C4 shows the log likelihoods of the fits for the corresponding networks as shown in <xref ref-type="fig" rid="pcbi-1000577-g005">Figure 5A</xref>1–A4. The respective model performed best for the combination of projection types of the common input population it was supposed to model, i.e. Clayton for I-I, Clayton survival for E-E, etc. Hence, by determining the best fitting transformation the most likely combination of input types could be identified. Each of the transformations could be associated with a distinct combination of projection types.</p>
<p>To investigate whether the results of the reconstruction depend on the strengths of the synapses we varied <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e225" xlink:type="simple"/></inline-formula> between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e226" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e227" xlink:type="simple"/></inline-formula> for excitatory synapses and between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e228" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e229" xlink:type="simple"/></inline-formula> for inhibitory synapses (data not shown). While the relation of the best fitting copula families was constant across all strengths the differences between the curves decreased for decreasing strengths. For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e230" xlink:type="simple"/></inline-formula> it was hard to distinguish between the likelihoods of lower and upper tail dependencies. Therefore, tail dependencies were less pronounced in the spike-counts. In the multi-tetrode data, however, we found significant differences between the likelihoods of the copula families (see Section “Application of Copula-Based Models to Multi-Tetrode Data”).</p>
<p>To investigate the impact of the bin size on the reconstruction performance we also binned the data into smaller and larger intervals (data not shown). When the bin size was too small or too large (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e231" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e232" xlink:type="simple"/></inline-formula>) the reconstruction did not succeed. In the intermediate range (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e233" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e234" xlink:type="simple"/></inline-formula>), however, the connection types could be reconstructed. This can be explained by the asymptotic distributions of the multivariate spike-counts. According to the <italic>central limit theorem</italic> the multivariate normal distribution provides a good approximation when the bin size is sufficiently large. Hence, tail dependencies will vanish. On the contrary, when the bin size becomes too small the marginal distributions are essentially Bernoulli distributed and the tail dependencies will vanish as well. Of course, the range of the intermediate bin size depends on the rates of the neurons. The larger the rates the smaller the bin sizes in the intermediate range. For the simulated data the rates were comparable to the data recorded from the prefrontal cortex (see Section “Multi-Tetrode Recordings”).</p>
</sec><sec id="s3c">
<title>Application of Copula-Based Models to Multi-Tetrode Data</title>
<p>Our copula-based models are capable of modeling different dependence structures with marginals that are tailored to single neuron spike-count distributions. Thus, we expected that the copula-based models would provide a much better fit to data recorded from real neurons than the multivariate normal distribution or the multivariate Poisson latent variables distribution. To test this, we applied copula-based models from different families and with different marginal distributions to data, which has been recorded from macaque prefrontal cortex for each of the twenty presented stimuli and each of the four phases (pre-stimulus presentation, stimulus presentation, delay, presentation of the test stimulus) of the visual working memory task. We compared the results to models of the discretized multivariate normal and the Poisson latent variables distribution (see Section “<xref ref-type="sec" rid="s2">Materials and Methods</xref>”)</p>
<p>We randomly selected <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e235" xlink:type="simple"/></inline-formula> count vectors for each task phase and each stimulus as the validation set. We then estimated the model parameters on the remaining count vectors (training set) and used the validation set for obtaining an unbiased estimate of the likelihoods of the selected models.</p>
<p>We used the IFM-estimator for the copula-based models and the maximum likelihood estimator for the Poisson latent variables distribution. The parameters <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e236" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e237" xlink:type="simple"/></inline-formula> of the discretized MVN distribution were estimated by the sample mean and the sample covariance matrix of the spike-counts. This procedure does not correspond to the maximum likelihood estimate of the discretized distribution. We used it, because the maximum likelihood estimator was too expensive to compute for six neurons. The high computational costs come from the estimation of the CDF of the MVN.</p>
<p>The rate parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e238" xlink:type="simple"/></inline-formula> for the Poisson distribution and negative binomial distribution were estimated via the sample mean. The maximum likelihood estimates for the overdispersion parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e239" xlink:type="simple"/></inline-formula> were computed iteratively by Newton's method.</p>
<p><xref ref-type="fig" rid="pcbi-1000577-g006">Figure 6A</xref> summarizes the results for the discretized MVN, the Poisson latent variables distribution, and two copula-based distributions with different marginals, the Poisson distribution, and the negative binomial distribution. The negative binomial distribution provided for all four task phases a significantly better fit than the Poisson distribution, the MVN distribution, and the Poisson latent variables distribution. The likelihood for the copula-based models was significantly greater than for the discretized MVN model (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e240" xlink:type="simple"/></inline-formula>, paired-sample Student's <italic>t</italic> test over stimuli) and the Poisson latent variables model (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e241" xlink:type="simple"/></inline-formula>). Moreover, the likelihood for the negative binomial marginals was even greater than that for the Poisson marginals (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e242" xlink:type="simple"/></inline-formula>). Thus, the copula-based approach provided models that were indeed superior for the data at hand. Moreover, the additional flexibility of the negative binomial marginals improved the fit significantly.</p>
<fig id="pcbi-1000577-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g006</object-id><label>Figure 6</label><caption>
<title>Log likelihoods of the best fitting MVN, Poisson latent variables, and copula-based models for the validation set.</title>
<p>(A) Log likelihoods for the discretized multivariate normal distribution (circles), the multivariate Poisson latent variables distribution (crosses), the best fitting copula-based model with Poisson (squares), and with negative binomial marginals (diamonds). The figure shows the log likelihoods averaged over all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e243" xlink:type="simple"/></inline-formula> different stimuli, but separately for the pre-stimulus, sample stimulus, delay, and test stimulus phase of the memory task. For the best fitting copula, we considered all the copula families shown in B. AMH denotes the Ali-Mikhail-Haq family, FGM the Farlie-Gumbel-Morgenstern family (see <xref ref-type="table" rid="pcbi-1000577-t001">Table 1</xref>). For the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e244" xlink:type="simple"/></inline-formula> order model of the FGM family we set all but the first <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e245" xlink:type="simple"/></inline-formula> parameters to zero, therefore leaving only parameters for pairwise interactions. In contrast, for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e246" xlink:type="simple"/></inline-formula> order model we set all but the first <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e247" xlink:type="simple"/></inline-formula> parameters to zero. (B) Difference between the log likelihood of a model with independent spike-counts and negative binomial marginals (“ind. model”) and the log likelihoods of the best fitting representatives of the different copula-based models shown in the legend. Negative binomial marginals were used. Data was again averaged over the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e248" xlink:type="simple"/></inline-formula> different stimuli.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g006" xlink:type="simple"/></fig>
<p>We applied different copula families to examine the importance of the dependence structure for the model fit. <xref ref-type="fig" rid="pcbi-1000577-g006">Figure 6B</xref> shows an evaluation of the different copula families with different dependence structures for the best fitting marginal, which was the negative binomial distribution. The model based on the Clayton copula family provided the best fit. The fit was significantly better than for the second best fitting copula family (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e249" xlink:type="simple"/></inline-formula>), the Gumbel family. In spite of having more parameters, the FGM copulas performed worse. However, the FGM model with third order interactions fitted the data significantly better than the model that included only pairwise interactions (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e250" xlink:type="simple"/></inline-formula>).</p>
<p>The best fitting copula-based model, the Clayton copula, is characterized by a lower tail dependence. Apart of the Gumbel family, the other families that we applied so far do not model orthant dependencies. To check whether other orthant dependencies would improve the fit, we applied the flashlight transformation and we transformed the Clayton copula tail towards all corners of the six dimensional hyper cube. The results are shown in <xref ref-type="fig" rid="pcbi-1000577-g007">Figure 7</xref>. The standard Clayton copula with lower tail dependence had the significantly highest value of the log likelihood on the validation set indicating that the empirical spike-count distribution has indeed a lower tail dependence. The second highest peak was reached by the Clayton survival copula. The central peak corresponded to those transformations that were close to the Clayton and the Clayton survival copulas: sectors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e251" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e252" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e253" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e254" xlink:type="simple"/></inline-formula> decimal). Thus, a common lower tail dependence was prominent in the data.</p>
<fig id="pcbi-1000577-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g007</object-id><label>Figure 7</label><caption>
<title>Log likelihoods of different Clayton-copula models transformed using the flashlight transformation.</title>
<p>(A) Cartoon indicating the labeling of orthants for the six dimensional space. Each number indicates the orthant, into which the originally lower tail dependence was transformed. (B) Mean log likelihoods on the test interval validation set for all possible flashlight transformed Clayton copulas and negative binomial marginals. The bars mark the standard errors. (C) Mean log likelihoods on the test interval validation set for a mixture of the Clayton copula with all possible flashlight transformed Clayton copulas and negative binomial marginals.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g007" xlink:type="simple"/></fig>
<p>We applied mixtures of copulas as described in Section “The Flashlight Transformation and Mixtures of Copulas” to check whether there was indeed a prominent common upper tail dependence beside the lower tail dependence in the data. Therefore, we fixed the Clayton copula (which models a lower tail dependence) as the first mixture component and varied the sector of the flashlight transformed Clayton copula for the second mixture component. <xref ref-type="fig" rid="pcbi-1000577-g007">Figure 7C</xref> shows the mean log likelihoods of the mixture models with negative binomial marginals on the same data set used for <xref ref-type="fig" rid="pcbi-1000577-g007">Figure 7B</xref>. All of the mixture models exhibit similar performance. Therefore, the upper tail dependence that we observed for the unmixed model appears to be an artifact of the lower tail dependence.</p>
<p>In summary, we could show that the copula-based approach provided a significant improvement in the goodness of fit compared to the discretized and rectified multivariate normal distribution and the Poisson latent variables distribution. Moreover, the dependence structure alone has a significant impact as well.</p>
</sec><sec id="s3d">
<title>Appropriateness of Model</title>
<p>Our model consists of two parts: 1) the copula and 2) the marginals. We already analyzed the effect of the copula. In this section we describe the investigation of the marginals. In particular, we are interested in understanding how the goodness of fit is influenced by the marginals. For this purpose we compared the log likelihoods of the Clayton-copula model with Poisson, negative binomial, and empirical marginals fitted to the training set of the sample stimulus presentation phase. The model with empirical marginals was a so-called semiparametric distribution consisting of a parametric dependence structure (the copula family) and nonparametric marginals. We drew samples from these distributions in order to learn whether the training and validation sets were typical samples from the fitted distributions. For a complex model we expect the likelihood of training samples to be close to the mode of the histogram, while we expect the validation samples to have a much smaller likelihood. Contrary, for a model with small complexity we expect the likelihood of the training samples to be close to the likelihood of the validation samples. When the complexity is too small we expect the likelihoods of the training and the validation samples to be much smaller than the mode of the histogram.</p>
<p>In our setting the most complex model is the one with empirical marginals. Histograms of the log likelihoods for copula models with the three different marginals are shown in <xref ref-type="fig" rid="pcbi-1000577-g008">Figure 8</xref>. For Poisson marginals, the log likelihoods of both the training set and the validation set were much smaller than the log likelihoods of the samples drawn from the fitted distribution. Thus, the Poisson marginals seem to be too simple for a good fit to the data, whereas the negative binomial marginals generalized well in spite of their increased complexity. On the training set the model with the empirical marginals performed best. However, there was a huge discrepancy to the likelihood of the model with empirical marginals on the validation set, whereas the likelihoods of the other two models did not change much. This result can be explained by overfitting. The empirical marginals matched the marginals of the training set perfectly. The empirical marginals of the training set, however, were noisy representations of the true marginals, because of the limited sample size. Hence, a perfect fit is not beneficial when it comes to novel data. In contrast to that, the likelihoods of the models with Poisson and negative binomial marginals were almost equal to the respective likelihoods on the training set. Thus, these models did not suffer from overfitting.</p>
<fig id="pcbi-1000577-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g008</object-id><label>Figure 8</label><caption>
<title>Distribution of log likelihoods from models fitted to data from the sample stimulus phase.</title>
<p>The Clayton-copula model with different marginals was used. A histogram of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e255" xlink:type="simple"/></inline-formula> samples is shown where each sample represents an average over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e256" xlink:type="simple"/></inline-formula> spike-count vectors. The solid line corresponds to the log likelihood of the training set whereas the dashed line corresponds to the log likelihood of the validation set. (A) Model with Poisson marginals. (B) Model with negative binomial marginals. (C) Model with empirical marginals.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g008" xlink:type="simple"/></fig>
<p>In order to relate these findings to the number of samples in our training set we can compare the number of samples to the estimated number of required samples for the toy example in Section “Model Fitting”. <xref ref-type="fig" rid="pcbi-1000577-g006">Figure 6</xref> shows that the log likelihood for the Clayton-copula model deviated from the second best family by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e257" xlink:type="simple"/></inline-formula>. In Section “Model Fitting” we showed that for this model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e258" xlink:type="simple"/></inline-formula> samples were sufficient for good estimations of the log likelihood. For the delay phase and for the test stimulus phase, the number of samples varied between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e259" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e260" xlink:type="simple"/></inline-formula> per stimulus. Therefore, the number of samples was sufficient for these phases. Taken together with the histogram analysis, we found that the model complexity was appropriate for the available amount of data at hand.</p>
</sec><sec id="s3e">
<title>Information Analysis</title>
<p>We will now show that the copula-based models can be used to measure the short-term information about a stimulus that is encoded by the spike-count dependence structure of the recorded neurons. The first step is to estimate the total information of the spike-count responses. We applied the best fitting copula model, the Clayton-copula model with negative binomial marginals, to estimate the mutual information between stimuli and responses via Monte Carlo sampling (see Section “<xref ref-type="sec" rid="s2">Materials and Methods</xref>”). <xref ref-type="fig" rid="pcbi-1000577-g009">Figure 9A</xref> shows the estimated mutual information for each of the four task phases. The mutual information was greater during the sample stimulus interval and the test stimulus interval than during the delay interval. Therefore, a stimulus presentation evoked a spike-count response which instantly encoded information about the stimulus. In the test stimulus phase the dotted line is above the dashed line, so the spike-counts coded more information about the sample stimulus that was previously presented than about the test stimulus.</p>
<fig id="pcbi-1000577-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000577.g009</object-id><label>Figure 9</label><caption>
<title>Monte Carlo estimates of the mutual information between stimuli and responses.</title>
<p>The estimation is based on the Clayton-copula model with negative binomial marginals. The Monte Carlo method was terminated when the standard error was below <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e261" xlink:type="simple"/></inline-formula>. The sample stimulus was presented in phase two, whereas the test stimulus was presented in phase four. For the test stimulus phase, the estimation was performed twice: for the sample stimulus that was previously presented (dashed line) and for the test stimulus (dotted line). (A) Estimated mutual information based on IFM parameters determined on the training set for each of the task phases (pre-stimulus, sample stimulus, delay, and test stimulus). (B) Estimated information increase that is due to the dependence structure. The mutual information <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e262" xlink:type="simple"/></inline-formula> of the model with independent spike-counts and negative binomial marginals was subtracted from and normalized to the mutual information <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e263" xlink:type="simple"/></inline-formula> of the Clayton-copula model with negative binomial marginals.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.g009" xlink:type="simple"/></fig>
<p><xref ref-type="fig" rid="pcbi-1000577-g009">Figure 9B</xref> shows the information estimate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e264" xlink:type="simple"/></inline-formula>, normalized to the mutual information <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e265" xlink:type="simple"/></inline-formula> that is shown in <xref ref-type="fig" rid="pcbi-1000577-g009">Figure 9A</xref>. The dependence structure carried between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e266" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e267" xlink:type="simple"/></inline-formula> of the mutual information. During the test stimulus interval the dependence structure encoded almost twice as much information about the test stimulus as about the sample stimulus that was previously presented.</p>
</sec></sec><sec id="s4">
<title>Discussion</title>
<p>We developed a framework for analyzing the noise dependence of spike-counts and used synthetic data from a model of leaky integrate-and-fire neurons to derive interpretations for different dependence structures. Applying the framework to our data from the macaque prefrontal cortex we found that: (1) copula-based models with negative binomial marginals rather than the multivariate normal distribution or the Poisson latent variables distribution are appropriate models of spike-count data for short time intervals; (2) the dependence structure encodes between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e268" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e269" xlink:type="simple"/></inline-formula> of the mutual information about the presented stimuli; (3) the amount of data required for a good likelihood estimation is present in our data set; and (4) a lower tail dependence between all neurons is present in the data and can be explained by common inhibitory input.</p>
<p>The copula approach has many advantages compared to previous models. Recently, the Ising model gained a lot of attention in neuroscience <xref ref-type="bibr" rid="pcbi.1000577-Schneidman1">[4]</xref>,<xref ref-type="bibr" rid="pcbi.1000577-Shlens1">[27]</xref>. This model is a maximum entropy model of binary variables called spins that have only pairwise interactions <xref ref-type="bibr" rid="pcbi.1000577-Ising1">[28]</xref>. The model is applied to the neuroscience setting by binning spike trains into very short time intervals such that at most one spike falls into each bin. The spin for that bin then indicates whether or not a spike was present. Using this model pairwise interactions between simultaneously recorded neurons can be modeled <xref ref-type="bibr" rid="pcbi.1000577-Schneidman1">[4]</xref>. The Ising model is a special case of a more general class of nested maximum entropy models <xref ref-type="bibr" rid="pcbi.1000577-Amari1">[29]</xref>. Other models in this class can be used to model higher order interactions between neurons. Nevertheless, an independence assumption for subsequent bins is necessary due to the limited number of samples present in typical neuroscience settings. Therefore, the marginal spike-counts of individual neurons will be binomial distributed. The variance of this distribution is always smaller than its mean which is a severe disadvantage of this model class. The copula approach on the other hand can model arbitrary marginals.</p>
<p>Another class of models are doubly stochastic models where some parameters of the data distribution are themselves random variables. The doubly stochastic Poisson point process presented by Krumin and Shoham belongs to this class <xref ref-type="bibr" rid="pcbi.1000577-Krumin1">[30]</xref>. For such models the marginal distributions change whenever the dependence is modified. It is thus very hard to disentangle the effects of the dependence structure from the effects of the marginals.</p>
<p>In contrast to the multivariate normal distribution and the multivariate Poisson latent variables distribution the copula approach can be used to model arbitrary marginal distributions that are appropriate for the data at hand. The marginal distributions can therefore be discrete without any mass on the negative axis and with variance greater than the mean. We compared the fits of negative binomial marginals to Poisson and empirical marginals and found that only the negative binomial marginals provided a reasonable fit to the data. Contrary to the Poisson marginals, the negative binomial marginals were complex enough such that likelihoods of samples from the model were consistent with the likelihood of the data. Moreover, the negative binomial marginals did not suffer from overfitting as did the empirical marginals. We conclude that the negative binomial marginals are appropriate to describe the spike-counts recorded from the prefrontal cortex.</p>
<p>The dependence structure of the copula approach is flexible. Higher order interactions can be parametrized separately if desired. Furthermore, in contrast to the multivariate Poisson latent variables distribution, negative correlations can be modeled as well. Another advantage of the copula approach is that it is modular in the sense that the copula family used for the data analysis can be easily exchanged by another family. Many different copula families exist, each representing and parameterizing different properties of the dependence structures. Thus, it is easy to test for different properties of a distribution. Specific examples are the Clayton and Gumbel families. These families have lower and upper tail dependencies, respectively. Lower and upper tail dependencies can arise from common input populations with inhibitory and excitatory projections, respectively. By deriving the flashlight transformation we could construct additional families that account for combinations of inhibition and excitation.</p>
<p>When applying the flashlight transformation to the data from the prefrontal cortex, we found that the unmodified Clayton family provided the best fit to the test data. Therefore, a common lower tail dependence to all neurons is present in the data. One explanation is a common input population whose projections are mostly inhibitory to all the analyzed neurons. Two types of common inhibitory sources are possible: (1) A local source of inhibitory input such as common interneurons. (2) Another area projecting to the prefrontal cortex. It was found that interneurons have a reach of no more than a few hundred micrometers whereas the inter-tetrode distance was <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e270" xlink:type="simple"/></inline-formula>. Thus, it is unlikely that a population of common interneurons inhibits all the stimulus specific neurons that we recorded from. Another area, therefore, is more likely to be the source of the common inhibitory input. One possibility could be the ventral tegmental area (VTA). In the rat cortex it was found that the VTA exerts a direct inhibitory influence on the PFC. In a study <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e271" xlink:type="simple"/></inline-formula> of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e272" xlink:type="simple"/></inline-formula> recorded PFC neurons were inhibited as a result of VTA stimulation <xref ref-type="bibr" rid="pcbi.1000577-Godbout1">[31]</xref>. Moreover, the VTA is thought to be a central component of the reward system <xref ref-type="bibr" rid="pcbi.1000577-Hikosaka1">[32]</xref> which is essential for a memory task. Our analysis provides evidence for such an influence based on the spike-count statistics.</p>
<p>The second best fit was achieved by the Clayton survival family. One explanation for this result is provided by an upper tail dependence between all neurons in addition to the stronger lower tail dependence. We applied mixtures of copulas to elucidate this issue and found that a mixture of the Clayton and Clayton survival family did not provide the best fit out of all mixtures of the Clayton family with a Clayton flashlight transformation. At first sight it is puzzling that the upper tail dependence seems to disappear when mixed with the lower tail dependence. However, the Clayton copula and the Clayton survival copula have their dependence along the same line in the six dimensional space that is spanned by the neuronal spike-counts, though predominantly at different ends of this line. Hence, the Clayton survival family can capture some of the dependence that is inherent to the Clayton family. We conclude that the prominence of the upper tail dependence that was observed for the unmixed model is an artifact of the lower tail dependence component.</p>
<p>The results show that important properties of dependence structures such as tail dependencies arise very naturally in simple input scenarios, and that the copula approach can be used to construct generative models that are capable of capturing these aspects of this underlying connectivity. In principle, copula-based models can be used to guide reconstructions of functional connectivity, but this topic is outside the scope of this study. If the reader is interested in detailed reconstruction of functional connectivity we recommend the studies in <xref ref-type="bibr" rid="pcbi.1000577-Perkel1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1000577-Tetzlaff1">[35]</xref> as a starting point.</p>
<p>We could show that there is important information represented in the dependence structure which has been ignored in studies reporting only the correlation coefficient. Based on the flashlight transformation we could derive novel copula families with interesting interpretations for neuroscience: the statistical dependence gives insight into possible connections of the underlying network. Other copula families might be applicable to investigate different properties of the network.</p>
<p>We could also show that the Gaussian distribution is not an appropriate approximation of the spike-count distribution of short time intervals. Yet, many studies applied this approximation in their investigations. Therefore, these studies should be reassessed with respect to their validity for short-term coding.</p>
<p>We also compared the copula-based approach to the multivariate Poisson latent variables distribution. In terms of spike-counts this model corresponds to previous point process models that account for higher order correlations. The copula-based approach overcomes a number of shortcomings of this distribution, namely the Poisson marginals, the restriction to non-negative correlations and the inflexible dependence structure. We could show that the improvement in the goodness-of-fit is significant.</p>
<p>Taken together, the copula-based approach allows us to model and analyze spike-count dependencies in much more detail than previously applied models. A drawback is the small number of neurons to which the approach can be applied so far. The approach is computationally too demanding for higher numbers of neurons because the model fitting complexity is exponential in the number of neurons. Approximate inference methods might provide a solution to the computational problem. However, another problem is the number of samples available in typical electro-physiological experiments. We could show that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000577.e273" xlink:type="simple"/></inline-formula> samples are sufficient for six dimensional data with moderate dependence strengths. Nevertheless, the amount of required data increases dramatically for increasing dimensions, i.e. for the number of neurons. A combination with dimensionality reduction techniques might provide a solution to this problem.</p>
</sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1000577.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000577.s001" xlink:type="simple"><label>Text S1</label><caption>
<p>Proof of the theorem that introduces the flashlight transformation for copula families.</p>
<p>(0.08 MB PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We thank Benjamin Staude for his fundamental advice and the anonymous reviewers for their constructive comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000577-Averbeck1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Averbeck</surname><given-names>BB</given-names></name>
<name name-style="western"><surname>Latham</surname><given-names>PE</given-names></name>
<name name-style="western"><surname>Pouget</surname><given-names>A</given-names></name>
</person-group>             <year>2006</year>             <article-title>Neural correlations, population coding and computation.</article-title>             <source>Nat Rev Neurosci</source>             <volume>7</volume>             <fpage>358</fpage>             <lpage>366</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Bair1"><label>2</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bair</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Zohary</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name>
</person-group>             <year>2001</year>             <article-title>Correlated firing in macaque visual area MT: time scales and relationship to behavior.</article-title>             <source>J Neurosci</source>             <volume>21</volume>             <fpage>1676</fpage>             <lpage>1697</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Kohn1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kohn</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Smith</surname><given-names>MA</given-names></name>
</person-group>             <year>2005</year>             <article-title>Stimulus dependence of neuronal correlation in primary visual cortex of the macaque.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>3661</fpage>             <lpage>3673</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Schneidman1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Berry</surname><given-names>MJ</given-names></name>
<name name-style="western"><surname>Segev</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name>
</person-group>             <year>2006</year>             <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population.</article-title>             <source>Nature</source>             <volume>440</volume>             <fpage>1007</fpage>             <lpage>1012</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Michel1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Michel</surname><given-names>MM</given-names></name>
<name name-style="western"><surname>Jacobs</surname><given-names>RA</given-names></name>
</person-group>             <year>2006</year>             <article-title>The costs of ignoring high-order correlations in populations of model neurons.</article-title>             <source>Neural Comput</source>             <volume>18</volume>             <fpage>660</fpage>             <lpage>682</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Kuhn1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kuhn</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Aertsen</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Rotter</surname><given-names>S</given-names></name>
</person-group>             <year>2003</year>             <article-title>Higher-order statistics of input ensembles and the response of simple model neurons.</article-title>             <source>Neural Comput</source>             <volume>15</volume>             <fpage>67</fpage>             <lpage>101</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Ehm1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ehm</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Staude</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Rotter</surname><given-names>S</given-names></name>
</person-group>             <year>2007</year>             <article-title>Decomposition of neuronal assembly activity via empirical de-Poissonization.</article-title>             <source>Electron J Stat</source>             <volume>1</volume>             <fpage>473</fpage>             <lpage>495</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Kawamura1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kawamura</surname><given-names>K</given-names></name>
</person-group>             <year>1979</year>             <article-title>The structure of multivariate Poisson distribution.</article-title>             <source>Kodai Math J</source>             <volume>2</volume>             <fpage>337</fpage>             <lpage>345</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Karlis1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Karlis</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Meligkotsidou</surname><given-names>L</given-names></name>
</person-group>             <year>2005</year>             <article-title>Multivariate Poisson regression with covariance structure.</article-title>             <source>Stat Comput</source>             <volume>15</volume>             <fpage>255</fpage>             <lpage>265</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Onken1"><label>10</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Onken</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Grünewälder</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Munk</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Obermayer</surname><given-names>K</given-names></name>
</person-group>             <year>2009</year>             <article-title>Modeling short-term noise dependence of spike counts in macaque prefrontal cortex.</article-title>             <fpage>1233</fpage>             <lpage>1240</lpage>             <comment>In: Koller D, Schuurmans D, Bengio Y, Bottou L, editors, Advances in Neural Information Processing Systems 21</comment>          </element-citation></ref>
<ref id="pcbi.1000577-Berkes1"><label>11</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Wood</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Pillow</surname><given-names>J</given-names></name>
</person-group>             <year>2009</year>             <article-title>Characterizing neural dependencies with copula models.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Koller</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Schuurmans</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Bottou</surname><given-names>L,</given-names></name>
</person-group>             <source>Advances in Neural Information Processing Systems 21</source>             <fpage>129</fpage>             <lpage>136</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Nelsen1"><label>12</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nelsen</surname><given-names>RB</given-names></name>
</person-group>             <year>2006</year>             <article-title>An Introduction to Copulas.</article-title>             <publisher-loc>New York</publisher-loc>             <publisher-name>Springer, second edition</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000577-Jenison1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jenison</surname><given-names>RL</given-names></name>
<name name-style="western"><surname>Reale</surname><given-names>RA</given-names></name>
</person-group>             <year>2004</year>             <article-title>The shape of neural dependence.</article-title>             <source>Neural Comput</source>             <volume>16</volume>             <fpage>665</fpage>             <lpage>672</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Sklar1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sklar</surname><given-names>A</given-names></name>
</person-group>             <year>1959</year>             <article-title>Fonctions de répartition à n dimensions et leurs marges.</article-title>             <source>Pub Inst Stat Univ Paris</source>             <volume>8</volume>             <fpage>229</fpage>             <lpage>231</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Genest1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Genest</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Ne˘slehová</surname><given-names>J</given-names></name>
</person-group>             <year>2007</year>             <article-title>A primer on discrete copulas.</article-title>             <source>ASTIN Bull</source>             <volume>37</volume>             <fpage>475</fpage>             <lpage>515</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Tolhurst1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name>
<name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name>
<name name-style="western"><surname>Dean</surname><given-names>AF</given-names></name>
</person-group>             <year>1982</year>             <article-title>The statistical reliability of signals in single neurons in cat and monkey visual cortex.</article-title>             <source>Vision Res</source>             <volume>23</volume>             <fpage>775</fpage>             <lpage>785</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Georges1"><label>17</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Georges</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Lamy</surname><given-names>AG</given-names></name>
<name name-style="western"><surname>Nicolas</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Quibel</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Roncalli</surname><given-names>T</given-names></name>
</person-group>             <year>2001</year>             <article-title>Multivariate survival modelling: a unified approach with copulas.</article-title>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://ssrn.com/abstract=1032559" xlink:type="simple">http://ssrn.com/abstract=1032559</ext-link>. Accessed 1 September 2008</comment>          </element-citation></ref>
<ref id="pcbi.1000577-Fortin1"><label>18</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fortin</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Kuzmics</surname><given-names>C</given-names></name>
</person-group>             <year>2002</year>             <article-title>Tail-dependence in stock-return pairs. Economics Series 126, Institute for Advanced Studies.</article-title>             <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://econpapers.repec.org/RePEc:ihs:ihsesp:126" xlink:type="simple">http://econpapers.repec.org/RePEc:ihs:ihsesp:126</ext-link>. Accessed 1 November 2008</comment>          </element-citation></ref>
<ref id="pcbi.1000577-Comtet1"><label>19</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Comtet</surname><given-names>L</given-names></name>
</person-group>             <year>1974</year>             <article-title>Advanced Combinatorics: the Art of Finite and Infinite Expansions.</article-title>             <comment>Dordrecht: Reidel, 176–177</comment>          </element-citation></ref>
<ref id="pcbi.1000577-Joe1"><label>20</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Joe</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Xu</surname><given-names>JJ</given-names></name>
</person-group>             <year>1996</year>             <article-title>The estimation method of inference functions for margins for multivariate models.</article-title>             <comment>Technical Report 166, Department of Statistics, University of British Colombia</comment>          </element-citation></ref>
<ref id="pcbi.1000577-Lagarias1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Lagarias</surname><given-names>JC</given-names></name>
<name name-style="western"><surname>Reeds</surname><given-names>JA</given-names></name>
<name name-style="western"><surname>Wright</surname><given-names>MH</given-names></name>
<name name-style="western"><surname>Wright</surname><given-names>PE</given-names></name>
</person-group>             <year>1998</year>             <article-title>Convergence properties of the Nelder-Mead simplex method in low dimensions.</article-title>             <source>SIAM J Optimiz</source>             <volume>9</volume>             <fpage>112</fpage>             <lpage>147</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Waltz1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Waltz</surname><given-names>RA</given-names></name>
<name name-style="western"><surname>Morales</surname><given-names>JL</given-names></name>
<name name-style="western"><surname>Nocedal</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Orban</surname><given-names>D</given-names></name>
</person-group>             <year>2006</year>             <article-title>An interior algorithm for nonlinear optimization that combines line search and trust region steps.</article-title>             <source>Math Program</source>             <volume>107</volume>             <fpage>391</fpage>             <lpage>408</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Dempster1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dempster</surname><given-names>AP</given-names></name>
<name name-style="western"><surname>Laird</surname><given-names>NM</given-names></name>
<name name-style="western"><surname>Rubin</surname><given-names>DB</given-names></name>
</person-group>             <year>1977</year>             <article-title>Maximum likelihood from incomplete data via the EM algorithm.</article-title>             <source>J R Stat Soc</source>             <volume>39</volume>             <fpage>1</fpage>             <lpage>38</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Hu1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hu</surname><given-names>L</given-names></name>
</person-group>             <year>2006</year>             <article-title>Dependence patterns across financial markets: a mixed copula approach.</article-title>             <source>Appl Finan Econ</source>             <volume>16</volume>             <fpage>717</fpage>             <lpage>729</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Dayan1"><label>25</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>
</person-group>             <year>2001</year>             <article-title>Theoretical Neuroscience.</article-title>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000577-Robert1"><label>26</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Robert</surname><given-names>CP</given-names></name>
<name name-style="western"><surname>Casella</surname><given-names>G</given-names></name>
</person-group>             <year>2004</year>             <article-title>Monte Carlo Statistical Methods.</article-title>             <publisher-loc>New York</publisher-loc>             <publisher-name>Springer, second edition.</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000577-Shlens1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Shlens</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Field</surname><given-names>GD</given-names></name>
<name name-style="western"><surname>Gauthier</surname><given-names>JL</given-names></name>
<name name-style="western"><surname>Grivich</surname><given-names>MI</given-names></name>
<name name-style="western"><surname>Petrusca</surname><given-names>D</given-names></name>
<etal/></person-group>             <year>2006</year>             <article-title>The structure of multi-neuron firing patterns in primate retina.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>8254</fpage>             <lpage>8266</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Ising1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ising</surname><given-names>E</given-names></name>
</person-group>             <year>1925</year>             <article-title>Beitrag zur Theorie des Ferromagnetismus.</article-title>             <source>Z Phys</source>             <volume>13</volume>             <fpage>253</fpage>             <lpage>258</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Amari1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Amari</surname><given-names>A</given-names></name>
</person-group>             <year>2001</year>             <article-title>Information geometry on hierarchy of probability distributions.</article-title>             <source>IEEE T Inform Theory</source>             <volume>47</volume>             <fpage>1701</fpage>             <lpage>1711</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Krumin1"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Krumin</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Shoham</surname><given-names>S</given-names></name>
</person-group>             <year>2009</year>             <article-title>Generation of spike trains with controlled auto- and cross-correlation functions.</article-title>             <source>Neural Comput</source>             <volume>21</volume>             <fpage>1642</fpage>             <lpage>1664</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Godbout1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Godbout</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Mantz</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Pirot</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Glowinski</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Thierry</surname><given-names>AM</given-names></name>
</person-group>             <year>1991</year>             <article-title>Inhibitory influence of the mesocortical dopaminergic neurons on their target cells: electrophysiological and pharmacological characterization.</article-title>             <source>J Pharmacol Exp Ther</source>             <volume>258</volume>             <fpage>728</fpage>             <lpage>738</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Hikosaka1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hikosaka</surname><given-names>O</given-names></name>
<name name-style="western"><surname>Bromberg-Martin</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Hong</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Matsumoto</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>New insights on the subcortical representation of reward.</article-title>             <source>Curr Opin Neurobiol</source>             <volume>18</volume>             <fpage>203</fpage>             <lpage>208</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Perkel1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Perkel</surname><given-names>DH</given-names></name>
<name name-style="western"><surname>Gerstein</surname><given-names>GL</given-names></name>
<name name-style="western"><surname>Moore</surname><given-names>GP</given-names></name>
</person-group>             <year>1967</year>             <article-title>Neuronal spike trains and stochastic point processes. II. Simultaneous spike trains.</article-title>             <source>Biophys J</source>             <volume>7</volume>             <fpage>419</fpage>             <lpage>440</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Aertsen1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Aertsen</surname><given-names>AM</given-names></name>
<name name-style="western"><surname>Gerstein</surname><given-names>GL</given-names></name>
<name name-style="western"><surname>Habib</surname><given-names>MK</given-names></name>
<name name-style="western"><surname>Palm</surname><given-names>G</given-names></name>
</person-group>             <year>1989</year>             <article-title>Dynamics of neuronal firing correlation: modulation of “effective connectivity”.</article-title>             <source>J Neurophysiol</source>             <volume>61</volume>             <fpage>900</fpage>             <lpage>917</lpage>          </element-citation></ref>
<ref id="pcbi.1000577-Tetzlaff1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tetzlaff</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Rotter</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Stark</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Abeles</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Aertsen</surname><given-names>A</given-names></name>
<etal/></person-group>             <year>2008</year>             <article-title>Dependence of neuronal correlations on filter characteristics and marginal spike train statistics.</article-title>             <source>Neural Comput</source>             <volume>20</volume>             <fpage>2133</fpage>             <lpage>2184</lpage>          </element-citation></ref>
</ref-list>

</back>
</article>
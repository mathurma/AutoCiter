<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">10-PLCB-RA-2260</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002510</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Population genetics</subject>
              <subj-group>
                <subject>Genetic drift</subject>
                <subject>Neutral theory</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Evolutionary modeling</subject>
              <subject>Natural language processing</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Evolutionary biology</subject>
            <subj-group>
              <subject>Evolutionary processes</subject>
              <subj-group>
                <subject>Adaptation</subject>
                <subject>Emergence</subject>
                <subject>Genetic drift</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Population genetics</subject>
              <subj-group>
                <subject>Effective population size</subject>
                <subject>Genetic drift</subject>
                <subject>Neutral theory</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Evolutionary theory</subject>
              <subject>Forms of evolution</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Genetics</subject>
            <subj-group>
              <subject>Population genetics</subject>
              <subj-group>
                <subject>Genetic drift</subject>
                <subject>Neutral theory</subject>
              </subj-group>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Theoretical biology</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Mathematics</subject>
          <subj-group>
            <subject>Nonlinear dynamics</subject>
          </subj-group>
          <subj-group>
            <subject>Probability theory</subject>
            <subj-group>
              <subject>Markov model</subject>
              <subject>Stochastic processes</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Genetics and Genomics</subject>
          <subject>Computational Biology</subject>
          <subject>Evolutionary Biology</subject>
          <subject>Mathematics</subject>
        </subj-group>
      </article-categories><title-group><article-title>Structural Drift: The Population Dynamics of Sequential Learning</article-title><alt-title alt-title-type="running-head">Structural Drift</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Crutchfield</surname>
            <given-names>James P.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Whalen</surname>
            <given-names>Sean</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Complexity Sciences Center, Physics Department, University of California Davis, Davis, California, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Computer Science Department, Columbia University, New York, New York, United States of America</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Bergstrom</surname>
            <given-names>Carl T.</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">University of Washington, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">chaos@ucdavis.edu</email></corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: JPC SW. Performed the experiments: JPC SW. Analyzed the data: JPC SW. Contributed reagents/materials/analysis tools: JPC SW. Wrote the paper: JPC SW.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>6</month>
        <year>2012</year>
      </pub-date><pub-date pub-type="epub">
        <day>7</day>
        <month>6</month>
        <year>2012</year>
      </pub-date><volume>8</volume><issue>6</issue><elocation-id>e1002510</elocation-id><history>
        <date date-type="received">
          <day>19</day>
          <month>5</month>
          <year>2010</year>
        </date>
        <date date-type="accepted">
          <day>22</day>
          <month>3</month>
          <year>2012</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2012</copyright-year><copyright-holder>Crutchfield and Whalen</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
        <p>We introduce a theory of sequential causal inference in which learners in a chain estimate a structural model from their upstream “teacher” and then pass samples from the model to their downstream “student”. It extends the population dynamics of genetic drift, recasting Kimura's selectively neutral theory as a special case of a generalized drift process using structured populations with memory. We examine the diffusion and fixation properties of several drift processes and propose applications to learning, inference, and evolution. We also demonstrate how the organization of drift process space controls fidelity, facilitates innovations, and leads to information loss in sequential learning with and without memory.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>Human knowledge is often transmitted orally within a group via a sequence of communications between individuals. The children's game of <italic>Telephone</italic> is a familiar, simplified version. A phrase is uttered, understood, and then transmitted to another. Genetic information is communicated in an analogous sequential communication chain via replication. We show that the evolutionary dynamics of both problems is a form of genetic drift which accounts for memory in the communication chain. Using this, one can predict the mechanisms that lead to variations in fidelity and to structural innovation.</p>
      </abstract><funding-group><funding-statement>This work was partially supported by the Defense Advanced Research Projects Agency's Physical Intelligence Program under Subcontract No. 9060-000709. The funders had no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts>
        <page-count count="12"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>“Send Three- and Four-Pence, We're Going to a Dance”</p>
      <p>This phrase was heard, it is claimed, over the radio during WWI instead of the transmitted tactical phrase “Send reinforcements we're going to advance” <xref ref-type="bibr" rid="pcbi.1002510-Smith1">[1]</xref>. As illustrative as it is apocryphal, this garbled yet comprehensible transmission sets the tone for our investigations here. Namely, what happens to knowledge when it is communicated sequentially along a chain, from one individual to the next? What fidelity can one expect? How is information lost? How do innovations occur?</p>
      <p>To answer these questions we introduce a theory of sequential causal inference in which learners in a communication chain estimate a structural model from their upstream “teacher” and then, using that model, pass along samples to their downstream “student”. This reminds one of the familiar children's game <italic>Telephone</italic>. By way of quickly motivating our sequential learning problem, let's briefly recall how the game works.</p>
      <p>To begin, one player invents a phrase and whispers it to another player. This player, believing they have understood the phrase, then repeats it to a third and so on until the last player is reached. The last player announces the phrase, winning the game if it matches the original. Typically it does not, and that's the fun. Amusement and interest in the game derive directly from how the initial phrase evolves in odd and surprising ways. The further down the chain, the higher the chance that errors will make recovery impossible and the less likely the original phrase will survive.</p>
      <p>The game is often used in education to teach the lesson that human communication is fraught with error. The final phrase, though, is not merely accreted error but the product of a series of attempts to parse, make sense, and intelligibly communicate the phrase. The phrase's evolution is a trade off between comprehensibility and accumulated distortion, as well as the source of the game's entertainment. We employ a much more tractable setting to make analytical progress on sequential learning, based on <italic>computational mechanics</italic> <xref ref-type="bibr" rid="pcbi.1002510-Crutchfield1">[2]</xref>–<xref ref-type="bibr" rid="pcbi.1002510-Shalizi1">[4]</xref>, intentionally selecting a simpler language system and learning paradigm than likely operates with children.</p>
      <p>Specifically, we develop our theory of sequential learning as an extension of the evolutionary population dynamics of genetic drift, recasting Kimura's selectively neutral theory <xref ref-type="bibr" rid="pcbi.1002510-Kimura1">[5]</xref> as a special case of a generalized drift process of structured populations with memory. This is a substantial departure from the unordered populations used in evolutionary biology. Notably, this requires a new and more general information-theoretic notion of fixation. We examine the diffusion and fixation properties of several drift processes, demonstrating that the space of drift processes is highly organized. This organization controls fidelity, facilitates innovations, and leads to information loss in sequential learning and evolutionary processes with and without memory. We close by describing applications to learning, inference, and evolution, commenting on related efforts.</p>
      <p>To get started, we briefly review genetic drift and fixation. This will seem like a distraction, but it is a necessary one since available mathematical results are key. Then we introduce in detail our structured variants of these concepts—defining the <italic>generalized drift process</italic> and formulating a generalized definition of fixation appropriate to it. With the background laid out, we begin to examine the complexity of structural drift behavior. We demonstrate that it is a diffusion process within a space that decomposes into a connected network of structured subspaces. Building on this decomposition, we explain how and when processes jump between these subspaces—innovating new structural information or forgetting it—thereby controlling the long-time fidelity of the communication chain. We then close by outlining future research and listing several potential applications for structural drift, drawing out consequences for evolutionary processes that learn.</p>
      <p>Those familiar with neutral evolution theory are urged to skip to Section Sequential Learning, after skimming the next sections to pick up our notation and extensions.</p>
      <sec id="s1a">
        <title>From Genetic to Structural Drift</title>
        <p>Genetic drift refers to the change over time in genotype frequencies in a population due to random sampling. It is a central and well studied phenomenon in population dynamics, genetics, and evolution. A population of genotypes evolves randomly due to drift, but typically changes are neither manifested as new phenotypes nor detected by selection—they are <italic>selectively neutral</italic>. Drift plays an important role in the spontaneous emergence of mutational robustness <xref ref-type="bibr" rid="pcbi.1002510-vanNimwegen1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Bloom1">[7]</xref>, modern techniques for calibrating molecular evolutionary clocks <xref ref-type="bibr" rid="pcbi.1002510-Raval1">[8]</xref>, and nonadaptive (neutral) evolution <xref ref-type="bibr" rid="pcbi.1002510-Crutchfield3">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Koelle1">[10]</xref>, to mention only a few examples.</p>
        <p>Selectively neutral drift is typically modeled as a stochastic process: A random walk that tracks finite populations of individuals in terms of their possessing (or not) a variant of a gene. In the simplest models, the random walk occurs in a space that is a function of genotypes in the population. For example, a drift process can be considered to be a random walk of the <italic>fraction</italic> of individuals with a given variant. In the simplest cases there, the model reduces to the dynamics of repeated binomial sampling of a biased coin, in which the empirical estimate of bias becomes the bias in the next round of sampling. In the sense we will use the term, the sampling process is <italic>memoryless</italic>. The biased coin, as the population being sampled, has no memory: The past is independent of the future. The current state of the drift process is simply the bias, a number between zero and one that summarizes the state of the population.</p>
        <p>The theory of genetic drift predicts a number of measurable properties. For example, one can calculate the expected time until all or no members of a population possess a particular gene variant. These final states are referred to as <italic>fixation</italic> and <italic>deletion</italic>, respectively. Variation due to sampling vanishes once these states are reached and, for all practical purposes, drift stops. From then on, the population is homogeneous; further sampling can introduce no genotypic variation. These states are fixed points—in fact, absorbing states—of the drift stochastic process.</p>
        <p>The analytical predictions for the time to fixation and time to deletion were developed by Kimura and Ohta <xref ref-type="bibr" rid="pcbi.1002510-Kimura1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Kimura2">[11]</xref> in the 1960s and are based on the memoryless models and simplifying assumptions introduced by Wright <xref ref-type="bibr" rid="pcbi.1002510-Wright1">[12]</xref> and Fisher <xref ref-type="bibr" rid="pcbi.1002510-Fisher1">[13]</xref> in the early 1930s. The theory has advanced substantially since then to handle more realistic models and to predict additional effects due to selection and mutation. These range from multi-allele drift models and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e001" xlink:type="simple"/></inline-formula>-statistics <xref ref-type="bibr" rid="pcbi.1002510-Holsinger1">[14]</xref> to pseudohitchhiking models of “genetic draft” <xref ref-type="bibr" rid="pcbi.1002510-Gillespie1">[15]</xref>.</p>
        <p>The following explores what happens when we relax the memoryless restriction. The original random walk model of genetic drift forces the statistical structure at each sampling step to be an independent, identically distributed (IID) stochastic process. This precludes any memory in the sampling. Here, we extend the IID theory to use time-varying probabilistic state machines to describe memoryful population sampling.</p>
        <p>In the larger setting of sequential learning, we will show that memoryful sequential sampling exhibits structurally complex, drift-like behavior. We call the resulting phenomenon <italic>structural drift</italic>. Our extension presents a number of new questions regarding the organization of the space of drift processes and how they balance structure and randomness. To examine these questions, we require a more precise description of the original drift theory.</p>
      </sec>
      <sec id="s1b">
        <title>Genetic Drift</title>
        <p>We begin with the definition of an <italic>allele</italic>, which is one of several alternate forms of a gene. The textbook example is given by Mendel's early experiments on heredity <xref ref-type="bibr" rid="pcbi.1002510-Mendel1">[16]</xref>, in which he observed that the flowers of a pea plant were colored either white or violet, this being determined by the combination of alleles inherited from its parents. A new, <italic>mutant</italic> allele is introduced into a population by the mutation of a <italic>wild-type</italic> allele. A mutant allele can be passed on to an individual's offspring who, in turn, may pass it on to their offspring. Each inheritance occurs with some probability.</p>
        <p><italic>Genetic drift</italic>, then, is the change of allele frequencies in a population over time. It is the process by which the number of individuals with an allele varies generation after generation. The Fisher-Wright theory <xref ref-type="bibr" rid="pcbi.1002510-Wright1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Fisher1">[13]</xref> models drift as a stochastic evolutionary process with neither selection nor mutation. It assumes random mating between individuals and that the population is held at a finite, constant size. Moreover, successive populations do not overlap in time.</p>
        <p>Under these assumptions the Fisher-Wright theory reduces drift to a binomial or multinomial sampling process—a more complicated version of familiar random walks such as Gambler's Ruin or Prisoner's Escape <xref ref-type="bibr" rid="pcbi.1002510-Feller1">[17]</xref>. Offspring receive either the wild-type allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e002" xlink:type="simple"/></inline-formula> or the mutant allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e003" xlink:type="simple"/></inline-formula> of a particular gene <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e004" xlink:type="simple"/></inline-formula> from a random parent in the previous generation with replacement. A population of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e005" xlink:type="simple"/></inline-formula> diploid individuals will have <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e006" xlink:type="simple"/></inline-formula> total copies of these alleles. (Though we first use diploid populations (two alleles per individual and thus a sample length of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e007" xlink:type="simple"/></inline-formula>) for direct comparison to previous work, we later transition to haploid (single allele per individual) populations for notational simplicity.) Given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e008" xlink:type="simple"/></inline-formula> initial copies of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e009" xlink:type="simple"/></inline-formula> in the population, an individual has either <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e010" xlink:type="simple"/></inline-formula> with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e011" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e012" xlink:type="simple"/></inline-formula> with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e013" xlink:type="simple"/></inline-formula>. The probability that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e014" xlink:type="simple"/></inline-formula> copies of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e015" xlink:type="simple"/></inline-formula> exist in the offspring's generation given <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e016" xlink:type="simple"/></inline-formula> copies in the parent's generation is:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e017" xlink:type="simple"/><label>(1)</label></disp-formula>This specifies the transition dynamic of the drift stochastic process over the discrete state space<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e018" xlink:type="simple"/></inline-formula></p>
        <p>This model of genetic drift is a discrete-time random walk, driven by samples of a biased coin, over the space of biases. The population is a set of coin flips, where the probability of HEADS or TAILS is determined by the coin's current bias. After each generation of flips, the coin's bias is updated to reflect the number of HEADS or TAILS realized in the new generation. The walk's absorbing states—all HEADS or all TAILS—capture the notion of fixation and deletion.</p>
      </sec>
      <sec id="s1c">
        <title>Genetic Fixation</title>
        <p><italic>Fixation</italic> occurs with respect to an allele when all individuals in the population carry that specific allele and none of its variants. Restated, a mutant allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e019" xlink:type="simple"/></inline-formula> reaches fixation when all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e020" xlink:type="simple"/></inline-formula> alleles in the population are copies of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e021" xlink:type="simple"/></inline-formula> and, consequently, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e022" xlink:type="simple"/></inline-formula> has been <italic>deleted</italic> from the population. This halts the random fluctuations in the frequency of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e023" xlink:type="simple"/></inline-formula>, assuming <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e024" xlink:type="simple"/></inline-formula> is not reintroduced.</p>
        <p>Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e025" xlink:type="simple"/></inline-formula> be a binomially distributed random variable with bias probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e026" xlink:type="simple"/></inline-formula> that represents the fraction of copies of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e027" xlink:type="simple"/></inline-formula> in the population. The expected number of copies of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e028" xlink:type="simple"/></inline-formula> is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e029" xlink:type="simple"/></inline-formula>. That is, the expected number of copies of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e030" xlink:type="simple"/></inline-formula> remains constant over time and depends only on its initial probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e031" xlink:type="simple"/></inline-formula> and the total number (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e032" xlink:type="simple"/></inline-formula>) of alleles in the population. However, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e033" xlink:type="simple"/></inline-formula> eventually reaches fixation or deletion due to the change in allele frequency introduced by random sampling and the presence of absorbing states. Prior to fixation, the mean and variance of the change in allele frequency <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e034" xlink:type="simple"/></inline-formula> are:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e035" xlink:type="simple"/><label>(2)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e036" xlink:type="simple"/><label>(3)</label></disp-formula>respectively.</p>
        <p>On average there is no change in frequency. However, sampling variance causes the process to drift towards the absorbing states at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e037" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e038" xlink:type="simple"/></inline-formula>. The drift rate is determined by the current generation's allele frequency and the total number of alleles. For the neutrally selective case, the average number of generations until fixation (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e039" xlink:type="simple"/></inline-formula>) or deletion (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e040" xlink:type="simple"/></inline-formula>) is given by Kimura and Ohta <xref ref-type="bibr" rid="pcbi.1002510-Kimura1">[5]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e041" xlink:type="simple"/><label>(4)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e042" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e043" xlink:type="simple"/></inline-formula> denotes effective population size. For simplicity we take <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e044" xlink:type="simple"/></inline-formula>, meaning all individuals in the population are candidates for reproduction. As <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e045" xlink:type="simple"/></inline-formula>, the boundary condition is given by:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e046" xlink:type="simple"/><label>(6)</label></disp-formula>That is, excluding cases of deletion, an initially rare mutant allele spreads to the entire population in <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e047" xlink:type="simple"/></inline-formula> generations.</p>
        <p>One important consequence of the theory is that when fixation (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e048" xlink:type="simple"/></inline-formula>) or deletion (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e049" xlink:type="simple"/></inline-formula>) are reached, variation in the population vanishes: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e050" xlink:type="simple"/></inline-formula>. With no variation there is a homogeneous population, and sampling from this population produces the same homogeneous population. In other words, this establishes fixation and deletion as absorbing states of the stochastic sampling process. Once there, drift stops.</p>
        <p><xref ref-type="fig" rid="pcbi-1002510-g001">Figure 1</xref> illustrates this, showing both the simulated and theoretically predicted number of generations until fixation occurs for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e051" xlink:type="simple"/></inline-formula>, as well as the predicted time to deletion for reference. Each simulation was performed for a different initial value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e052" xlink:type="simple"/></inline-formula> and averaged over 400 realizations. Using the same methodology as Kimura and Ohta <xref ref-type="bibr" rid="pcbi.1002510-Kimura1">[5]</xref>, we include only those realizations whose mutant allele reaches fixation.</p>
        <fig id="pcbi-1002510-g001" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g001</object-id>
          <label>Figure 1</label>
          <caption>
            <title>Time to fixation for a population of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e053" xlink:type="simple"/></inline-formula> individuals (sample size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e054" xlink:type="simple"/></inline-formula>) plotted as a function of initial allele probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e055" xlink:type="simple"/></inline-formula> under the Monte Carlo (MC) sampling regime and as given by theoretical prediction (solid line) of Eq. (4).</title>
            <p>Time to deletion is also shown (dashed line), Eq. (5).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g001" xlink:type="simple"/>
        </fig>
        <p>Populations are produced by repeated binomial sampling of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e056" xlink:type="simple"/></inline-formula> uniform random numbers between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e057" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e058" xlink:type="simple"/></inline-formula>. An initial probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e059" xlink:type="simple"/></inline-formula> is assigned to allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e060" xlink:type="simple"/></inline-formula> and probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e061" xlink:type="simple"/></inline-formula> to allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e062" xlink:type="simple"/></inline-formula>. The count <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e063" xlink:type="simple"/></inline-formula> of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e064" xlink:type="simple"/></inline-formula> in the initial population is incremented for each random number less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e065" xlink:type="simple"/></inline-formula>. This represents an individual acquiring the allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e066" xlink:type="simple"/></inline-formula> instead of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e067" xlink:type="simple"/></inline-formula>. The maximum likelihood estimate of allele frequency in the initial sample is simply the number of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e068" xlink:type="simple"/></inline-formula> alleles over the sample length: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e069" xlink:type="simple"/></inline-formula>. This estimate of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e070" xlink:type="simple"/></inline-formula> is then used to generate a new population of offspring, after which we re-estimate the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e071" xlink:type="simple"/></inline-formula>. These steps are repeated each generation until fixation at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e072" xlink:type="simple"/></inline-formula> or deletion at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e073" xlink:type="simple"/></inline-formula> occurs. This is the <italic>Monte Carlo</italic> (MC) sampling method.</p>
        <p>Kimura's theory and simulations predict the time to fixation or deletion of a mutant allele in a finite population by the process of genetic drift. The Fisher-Wright model and Kimura's theory assume a memoryless population in which each offspring inherits allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e074" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e075" xlink:type="simple"/></inline-formula> via an IID binomial sampling process. We now generalize this to memoryful stochastic processes, giving a new definition of fixation and exploring examples of structural drift behavior.</p>
      </sec>
    </sec>
    <sec id="s2" sec-type="methods">
      <title>Methods</title>
      <sec id="s2a">
        <title>Sequential Learning</title>
        <p>How can genetic drift be a memoryful stochastic process? Consider a population of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e076" xlink:type="simple"/></inline-formula> haploid organisms. Each generation consists of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e077" xlink:type="simple"/></inline-formula> alleles and so is represented by a string of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e078" xlink:type="simple"/></inline-formula> symbols, e.g. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e079" xlink:type="simple"/></inline-formula>, where each symbol corresponds to an individual with a particular allele. In the original drift models, a generation of offspring is produced by a memoryless binomial sampling process, selecting an offspring's allele from a parent with replacement. In contrast, the structural drift model produces a generation of individuals in which the sample order is tracked. The population is now a string of alleles, giving the potential for memory and structure in sampling—spatial, temporal, or other interdependencies between individuals within a sample.</p>
        <p>At first, this appears as a major difference from the usual setting employed in population biology, where populations are treated as unordered collections of individuals and sampling is modeled as an independent, identically distributed stochastic process. That said, the structure we have in mind has several biological interpretations, such as inbreeding and subdivision <xref ref-type="bibr" rid="pcbi.1002510-Gillespie2">[18]</xref> or the life histories of heterogeneous populations <xref ref-type="bibr" rid="pcbi.1002510-Leibler1">[19]</xref>. We later return to these alternative interpretations when considering applications.</p>
        <p>The model class we select to describe memoryful sampling is the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e080" xlink:type="simple"/></inline-formula>-machine : the unique, minimal, and optimal representation of a stochastic process <xref ref-type="bibr" rid="pcbi.1002510-Shalizi1">[4]</xref>. As we will show, these properties give an important advantage when analyzing structural drift, since they allow one to monitor the amount of structure innovated or lost during drift. We next give a brief overview of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e081" xlink:type="simple"/></inline-formula>-machines and refer the reader to the previous reference for details.</p>
        <p>The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e082" xlink:type="simple"/></inline-formula>-machine representations of the finite-memory discrete-valued stochastic processes we consider here form a class of (deterministic) probabilistic finite-state machine or unifilar hidden Markov model. An <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e083" xlink:type="simple"/></inline-formula>-machine consists of a set of <italic>causal states</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e084" xlink:type="simple"/></inline-formula> and a set of per-symbol transition matrices:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e085" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e086" xlink:type="simple"/></inline-formula> is the set of alleles and where the transition probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e087" xlink:type="simple"/></inline-formula> gives the probability of transitioning from causal state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e088" xlink:type="simple"/></inline-formula> to causal state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e089" xlink:type="simple"/></inline-formula> and emitting allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e090" xlink:type="simple"/></inline-formula>. The causal state probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e091" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e092" xlink:type="simple"/></inline-formula>, is determined as the left eigenvector of the state-to-state transition matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e093" xlink:type="simple"/></inline-formula>.</p>
        <p>Maintaining our connection to (haploid) population dynamics, we think of an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e094" xlink:type="simple"/></inline-formula>-machine as a generator of populations or length-<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e095" xlink:type="simple"/></inline-formula> strings: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e096" xlink:type="simple"/></inline-formula>. As a model of a sampling process, an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e097" xlink:type="simple"/></inline-formula>-machine gives the most compact representation of the distribution of strings produced by sampling.</p>
        <p>Consider a simple binary process that alternately generates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e098" xlink:type="simple"/></inline-formula>s and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e099" xlink:type="simple"/></inline-formula>s called the <italic>Alternating Process</italic> shown in <xref ref-type="fig" rid="pcbi-1002510-g002">Figure 2</xref>. Its <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e100" xlink:type="simple"/></inline-formula>-machine generates either the string <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e101" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e102" xlink:type="simple"/></inline-formula> depending on the start state. The per-symbol transition matrices are:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e103" xlink:type="simple"/><label>(8)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e104" xlink:type="simple"/><label>(9)</label></disp-formula></p>
        <fig id="pcbi-1002510-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e105" xlink:type="simple"/></inline-formula>-Machine for the Alternating Process consisting of two causal states <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e106" xlink:type="simple"/></inline-formula> and two transitions.</title>
            <p>State <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e107" xlink:type="simple"/></inline-formula> emits allele 0 with probability one and transitions to state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e108" xlink:type="simple"/></inline-formula>, while <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e109" xlink:type="simple"/></inline-formula> emits allele 1 with probability one and transitions to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e110" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g002" xlink:type="simple"/>
        </fig>
        <p>Enforcing the alternating period-2 pattern requires two states, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e111" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e112" xlink:type="simple"/></inline-formula>, as well as two positive probability transitions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e113" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e114" xlink:type="simple"/></inline-formula>. Branching transitions are required for a process to structurally drift; the Alternating Process has none. Two simple <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e115" xlink:type="simple"/></inline-formula>-machines with branching structure are the smaller Fair Coin Process (<xref ref-type="fig" rid="pcbi-1002510-g003">Figure 3</xref>) and more complex Golden Mean Process (<xref ref-type="fig" rid="pcbi-1002510-g004">Figure 4</xref>). Both are discussed in detail later.</p>
        <fig id="pcbi-1002510-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e116" xlink:type="simple"/></inline-formula>-Machine for the Fair Coin Process consisting of a single causal state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e117" xlink:type="simple"/></inline-formula> and a self-transition for both HEADS and TAILS.</title>
            <p>Each transition is labeled <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e118" xlink:type="simple"/></inline-formula> to indicate the probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e119" xlink:type="simple"/></inline-formula> of taking that transition and emitting allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e120" xlink:type="simple"/></inline-formula>. We refer to the Biased Coin Process when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e121" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g003" xlink:type="simple"/>
        </fig>
        <fig id="pcbi-1002510-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e122" xlink:type="simple"/></inline-formula>-Machine for the Golden Mean Process consisting of two causal states <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e123" xlink:type="simple"/></inline-formula> that generates a population with no consecutive <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e124" xlink:type="simple"/></inline-formula>s.</title>
            <p>In state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e125" xlink:type="simple"/></inline-formula> the probabilities of generating a 0 or 1 are <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e126" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e127" xlink:type="simple"/></inline-formula>, respectively.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g004" xlink:type="simple"/>
        </fig>
        <p>Beyond using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e128" xlink:type="simple"/></inline-formula>-machines as generators of stochastic processes, as just described, several alternative <italic>reconstruction</italic> algorithms exist to infer <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e129" xlink:type="simple"/></inline-formula>-machines from data samples—tree-merging <xref ref-type="bibr" rid="pcbi.1002510-Crutchfield1">[2]</xref>, state-splitting <xref ref-type="bibr" rid="pcbi.1002510-Shalizi2">[20]</xref>, and spectral <xref ref-type="bibr" rid="pcbi.1002510-Varn1">[21]</xref>. These algorithms share a general approach: First, estimate the distribution of subsequences. (If given data as a single string, for example, slide a window of length <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e130" xlink:type="simple"/></inline-formula> over the string and count subsequences of lengths <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e131" xlink:type="simple"/></inline-formula>.) Second, compute the distinct probability distributions of future subsequences conditioned on past subsequences (histories). Third, partition histories into equivalence classes (causal states) that give the same conditional future distributions. And, finally, calculate the transition dynamic between states. Properly reconstructed, the causal states form a minimal sufficient statistic for prediction in the sense of Kullback <xref ref-type="bibr" rid="pcbi.1002510-Kullback1">[22]</xref>. Here, we circumvent these methods' complications. Section Structural Innovation and Loss introduces an alternative that avoids them and is, at the same time, more computationally efficient.</p>
        <p>We are now ready to describe <italic>sequential learning</italic>, depicted in <xref ref-type="fig" rid="pcbi-1002510-g005">Figure 5</xref>. We begin by selecting the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e132" xlink:type="simple"/></inline-formula>-machine <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e133" xlink:type="simple"/></inline-formula> as an initial population generator. Following a path through <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e134" xlink:type="simple"/></inline-formula>, guided by its transition probabilities, produces a length-<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e135" xlink:type="simple"/></inline-formula> string <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e136" xlink:type="simple"/></inline-formula> that represents the first population of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e137" xlink:type="simple"/></inline-formula> individuals possessing alleles <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e138" xlink:type="simple"/></inline-formula>. We then infer an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e139" xlink:type="simple"/></inline-formula>-machine <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e140" xlink:type="simple"/></inline-formula> from the population <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e141" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e142" xlink:type="simple"/></inline-formula> is then used to produce a new population <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e143" xlink:type="simple"/></inline-formula>, from which a new <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e144" xlink:type="simple"/></inline-formula>-machine <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e145" xlink:type="simple"/></inline-formula> is estimated. This new population has the same allele distribution as the previous, plus some amount of variance. The cycle of inference and re-inference is repeated while allele frequencies drift each generation until fixation or deletion is reached. At that point, the populations (and so <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e146" xlink:type="simple"/></inline-formula>-machines ) cannot vary further. The net result is a stochastically varying time series of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e147" xlink:type="simple"/></inline-formula>-machines (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e148" xlink:type="simple"/></inline-formula>) that terminates when the populations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e149" xlink:type="simple"/></inline-formula> stop changing.</p>
        <fig id="pcbi-1002510-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Sequential inference with a chain of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e150" xlink:type="simple"/></inline-formula>-machines.</title>
            <p>An initial population generator <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e151" xlink:type="simple"/></inline-formula> produces a length-<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e152" xlink:type="simple"/></inline-formula> string <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e153" xlink:type="simple"/></inline-formula> from which a new model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e154" xlink:type="simple"/></inline-formula> is inferred. These steps are repeated using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e155" xlink:type="simple"/></inline-formula> as the population generator and so on, until a terminating condition is met.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g005" xlink:type="simple"/>
        </fig>
        <p>Thus, at each step a new representation or model is estimated from the previous step's sample. The inference step highlights that this is learning: a model of the generator is estimated from the given finite data. The repetition of this step creates a sequential communication chain. Sequential learning is thus closely related to genetic drift except that sample order is tracked, and this order is used in estimating the next generator.</p>
        <p>The procedure is analogous to flipping a biased coin a number of times, estimating the bias from the results, and re-flipping the newly biased coin. Eventually, the coin will be completely biased towards H<sc>eads</sc> or T<sc>ails</sc>. In our drift model the coin is replaced by an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e156" xlink:type="simple"/></inline-formula>-machine, which removes the IID model constraint and allows for the sampling process to take on structure and memory. Not only do the transition probabilities <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e157" xlink:type="simple"/></inline-formula> change, but <italic>the structure of the generator itself</italic>—the number of states and the presence or absence of transitions—drifts over time to capture the statistics of the sample using as little information as possible. This is an essential and distinctive aspect of structural drift.</p>
        <p>Before we can explore this dynamic, we first need to examine how an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e158" xlink:type="simple"/></inline-formula>-machine reaches fixation or deletion.</p>
      </sec>
      <sec id="s2b">
        <title>Structural Stasis</title>
        <p>Recall the Alternating Process from <xref ref-type="fig" rid="pcbi-1002510-g001">Figure 1</xref>, producing the strings <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e159" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e160" xlink:type="simple"/></inline-formula> depending on the start state. Regardless of the initial state, the original <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e161" xlink:type="simple"/></inline-formula>-machine is re-inferred from any sufficiently long string it produces. In the context of sequential learning, this means the population at each generation is the same.</p>
        <p>However, if we consider allele <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e162" xlink:type="simple"/></inline-formula> to be represented by symbol <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e163" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e164" xlink:type="simple"/></inline-formula> by symbol <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e165" xlink:type="simple"/></inline-formula>, neither allele reaches fixation or deletion according to current definitions. Nonetheless, the Alternating Process prevents any variance between generations and so, despite the population not being all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e166" xlink:type="simple"/></inline-formula> s or all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e167" xlink:type="simple"/></inline-formula> s, the population does reach an equilibrium: half <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e168" xlink:type="simple"/></inline-formula> s and half <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e169" xlink:type="simple"/></inline-formula> s. For these reasons, one cannot use the original population-dynamics definitions of fixation and deletion.</p>
        <p>This leads us to introduce <italic>structural stasis</italic> to combine the notions of fixation, deletion, and the inability to vary caused by periodicity. Said more directly, structural stasis corresponds to a process becoming nonstochastic, since it ceases to introduce variance between generations and so prevents further drift. However, we need a method to detect the occurrence of structural stasis in a drift process.</p>
        <p>A state machine representing a periodic sampling process enforces the constraint of periodicity via its internal memory. One measure of this memory is the <italic>population diversity</italic> <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e170" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002510-Pielou1">[23]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e171" xlink:type="simple"/><label>(10)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e172" xlink:type="simple"/><label>(11)</label></disp-formula>where the units are [bits]. (For background on information theory as used here, the reader is referred to Ref. <xref ref-type="bibr" rid="pcbi.1002510-Crutchfield4">[24]</xref>.) The population diversity of the Alternating Process is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e173" xlink:type="simple"/></inline-formula> bit at any size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e174" xlink:type="simple"/></inline-formula>. This single bit of information corresponds to the machine's current phase or state. Generally, though, the value diverges—<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e175" xlink:type="simple"/></inline-formula>—for arbitrary sampling processes, and so population diversity is not suitable as a general test for stasis.</p>
        <p>Instead, the condition for stasis can be given as the vanishing of the <italic>growth rate</italic> of population diversity:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e176" xlink:type="simple"/><label>(12)</label></disp-formula>Equivalently, we can test the per-allele entropy of the sampling process. We call this <italic>allelic entropy</italic>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e177" xlink:type="simple"/><label>(13)</label></disp-formula>where the units are [bits per allele]. Allelic entropy gives the average information per allele in bits, and structural stasis occurs when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e178" xlink:type="simple"/></inline-formula>. While closer to a general test for stasis, this quantity is difficult to estimate from population samples since it relies on an asymptotic estimate of the population diversity. However, the allelic entropy can be calculated in closed-form from the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e179" xlink:type="simple"/></inline-formula>-machine representation of the sampling process:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e180" xlink:type="simple"/><label>(14)</label></disp-formula>For example, the Alternating Process has <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e181" xlink:type="simple"/></inline-formula>, the Fair Coin Process <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e182" xlink:type="simple"/></inline-formula>, and the Golden Mean Process <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e183" xlink:type="simple"/></inline-formula>; all in units of bits per symbol. When <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e184" xlink:type="simple"/></inline-formula>, the sampling process has become periodic and lost all randomness generated via its branching transitions. In this way, we replace the vanishing variance (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e185" xlink:type="simple"/></inline-formula>) of a single bias parameter in the Kimura drift setting with a general measure of the sampling process's stochasticity. This new criterion subsumes the notions of fixation and deletion as well as periodicity. An <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e186" xlink:type="simple"/></inline-formula>-machine has zero allelic entropy if any of these conditions occur. More formally, we have the following statement.</p>
        <p><bold>Definition</bold> Structural stasis <italic>occurs when the sampling process's allelic entropy vanishes: </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e187" xlink:type="simple"/></inline-formula><italic>.</italic></p>
        <p><bold>Proposition</bold> <italic>Structural stasis is a fixed point of finite-memory structural drift.</italic></p>
        <p><bold>Proof</bold> <italic>Finite-memory means that the </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e188" xlink:type="simple"/></inline-formula><italic>-machine representing the population sampling process has a finite number of states. Given this, if </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e189" xlink:type="simple"/></inline-formula><italic>, then the </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e190" xlink:type="simple"/></inline-formula><italic>-machine has no branching in its recurrent states: </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e191" xlink:type="simple"/></inline-formula><italic>, where </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e192" xlink:type="simple"/></inline-formula><italic> and </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e193" xlink:type="simple"/></inline-formula><italic> are asymptotically recurrent states. This results in no variation in the inferred </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e194" xlink:type="simple"/></inline-formula><italic>-machine when sampling sufficiently large populations. Lack of variation, in turn, means the transition probabilities can no longer change and so the drift process stops. If allelic entropy vanishes at time </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e195" xlink:type="simple"/></inline-formula><italic> and no mutations are allowed, then it is zero for all </italic><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e196" xlink:type="simple"/></inline-formula><italic>. Thus, structural stasis is an absorbing state of the drift stochastic process.</italic></p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Results</title>
      <p>While more can be said analytically about structural drift, our present purpose is to introduce the main concepts. We will show that structural drift leads to interesting and nontrivial behavior. First, we calibrate the new class of drift processes against the original genetic drift theory.</p>
      <sec id="s3a">
        <title>Memoryless Drift</title>
        <p>The Biased Coin Process is represented by a single-state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e197" xlink:type="simple"/></inline-formula>-machine with a self loop for both H<sc>eads</sc> and T<sc>ails</sc> symbols; see <xref ref-type="fig" rid="pcbi-1002510-g003">Figure 3</xref>. It is an IID sampling process that generates populations with a binomial distribution of alleles. Unlike the Alternating Process, the coin's bias <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e198" xlink:type="simple"/></inline-formula> is free to drift during sequential inference. These properties make the Biased Coin Process an ideal candidate for exploring memoryless drift.</p>
        <p><xref ref-type="fig" rid="pcbi-1002510-g006">Figure 6</xref> shows structural drift, using two different measures, for a single realization of the Biased Coin Process with initial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e199" xlink:type="simple"/></inline-formula> [H<sc>eads</sc>] = Pr [T<sc>ails</sc>] = 0.5. Structural stasis (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e200" xlink:type="simple"/></inline-formula>) is reached after <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e201" xlink:type="simple"/></inline-formula> generations. The initial Fair Coin <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e202" xlink:type="simple"/></inline-formula>-machine occurs at the left of <xref ref-type="fig" rid="pcbi-1002510-g006">Figure 6</xref> and the final, completely biased <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e203" xlink:type="simple"/></inline-formula>-machine occurs at the right.</p>
        <fig id="pcbi-1002510-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Drift of allelic entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e204" xlink:type="simple"/></inline-formula> and Pr[H<sc>eads</sc>] for a single realization of the Biased Coin Process with sample size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e205" xlink:type="simple"/></inline-formula>.</title>
            <p>The drift of Pr[H<sc>eads</sc>] is annotated with its initial machine <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e206" xlink:type="simple"/></inline-formula> (left inset) and the machine at stasis <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e207" xlink:type="simple"/></inline-formula> (right inset).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g006" xlink:type="simple"/>
        </fig>
        <p>Note that the drift of allelic entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e208" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e209" xlink:type="simple"/></inline-formula> [T<sc>ails</sc>] are inversely related, with allelic entropy converging quickly to zero as stasis is approached. This reflects the rapid drop in population diversity. After stasis occurs, all randomness has been eliminated from the transitions at state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e210" xlink:type="simple"/></inline-formula>, resulting in a single transition that always produces TAILS. Anticipating later discussion, we note that during this run only Biased Coin Processes were observed.</p>
        <p>The time to stasis of the Biased Coin Process as a function of initial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e211" xlink:type="simple"/></inline-formula> [H<sc>eads</sc>] was shown in <xref ref-type="fig" rid="pcbi-1002510-g007">Figure 7</xref>. Also shown there was the previous Monte Carlo Kimura drift simulation modified to terminate when either fixation or deletion occurs. This experiment illustrates the definition of structural stasis and allows direct comparison of structural drift with genetic drift in the memoryless case.</p>
        <fig id="pcbi-1002510-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Time to stasis as a function of initial Pr[H<sc>eads</sc>] for structural drift (SD) of the Biased Coin Process versus Monte Carlo (MC) simulation of Kimura's model.</title>
            <p>Kimura's predicted times to fixation and deletion are shown for reference. Each estimated time is averaged over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e212" xlink:type="simple"/></inline-formula> realizations with sample size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e213" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g007" xlink:type="simple"/>
        </fig>
        <p>Not surprisingly, we can interpret genetic drift as a special case of the structural drift process for the Biased Coin. Both simulations follow Kimura's theoretically predicted curves, combining the lower half of the deletion curve with the upper half of the fixation curve to reflect the initial probability's proximity to the absorbing states. A high or low initial bias leads to a shorter time to stasis as the absorbing states are closer to the initial state. Similarly, a Fair Coin is the furthest from absorption and thus takes the longest average time to reach stasis.</p>
      </sec>
      <sec id="s3b">
        <title>Structural Drift</title>
        <p>The Biased Coin Process represents an IID sampling process with no memory of previous flips, reaching stasis when Pr[H<sc>eads</sc>] = 1.0 or 0.0 and, correspondingly, when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e214" xlink:type="simple"/></inline-formula>. We now introduce memory by starting drift with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e215" xlink:type="simple"/></inline-formula> as the <italic>Golden Mean Process</italic>, which produces binary populations with no consecutive <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e216" xlink:type="simple"/></inline-formula>s. Its <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e217" xlink:type="simple"/></inline-formula>-machine was shown in <xref ref-type="fig" rid="pcbi-1002510-g004">Figure 4</xref>. Note that one can initialize drift using any stochastic process; for example, see the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e218" xlink:type="simple"/></inline-formula>-machine library of Ref. <xref ref-type="bibr" rid="pcbi.1002510-Johnson1">[25]</xref>.</p>
        <p>Like the Alternating Process, the Golden Mean Process has two causal states. However, the transitions from state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e219" xlink:type="simple"/></inline-formula> have nonzero entropy, allowing their probabilities to drift as new <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e220" xlink:type="simple"/></inline-formula>-machines are inferred from generation to generation. If the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e221" xlink:type="simple"/></inline-formula> transition probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e222" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002510-g004">Figure 4</xref>) becomes zero the transition is removed, and the Golden Mean Process reaches stasis by transforming into the Fixed Coin Process (top right, <xref ref-type="fig" rid="pcbi-1002510-g006">Figure 6</xref>). Instead, if the same transition drifts towards probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e223" xlink:type="simple"/></inline-formula>, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e224" xlink:type="simple"/></inline-formula> transition is removed. In this case, the Golden Mean Process reaches stasis by transforming into the Alternating Process (<xref ref-type="fig" rid="pcbi-1002510-g002">Figure 2</xref>).</p>
        <p>To compare structural drift behaviors, consider also the Even Process. Similar in form to the Golden Mean Process, the Even Process produces populations in which blocks of consecutive <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e225" xlink:type="simple"/></inline-formula>s must be even in length when bounded by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e226" xlink:type="simple"/></inline-formula>s <xref ref-type="bibr" rid="pcbi.1002510-Crutchfield4">[24]</xref>. <xref ref-type="fig" rid="pcbi-1002510-g008">Figure 8</xref> compares the drift of Pr[H<sc>eads</sc>] for a single realization of the Biased Coin, Golden Mean, and Even Processes. One observes that the Even and Biased Coin Processes reach stasis as the Fixed Coin Process, while the Golden Mean Process reaches stasis as the Alternating Process. For different realizations, the Even and Golden Mean Processes might instead reach different stasis points.</p>
        <fig id="pcbi-1002510-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Drift of Pr[H<sc>eads</sc>] for a single realization of the Biased Coin, Golden Mean, and Even Processes, plotted as a function of generation.</title>
            <p>The Even and Biased Coin Processes become the Fixed Coin Process at stasis, while the Golden Mean Process becomes the Alternating Process. Note that the definition of structural stasis recognizes the lack of variance in the Alternating Process subspace even though the allele probability is neither 0 nor 1.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g008" xlink:type="simple"/>
        </fig>
        <p>It should be noted that the memoryful Golden Mean and Even Processes reach stasis markedly faster than the memoryless Biased Coin. While <xref ref-type="fig" rid="pcbi-1002510-g008">Figure 8</xref> shows only a single realization of each sampling process type, the top panel of <xref ref-type="fig" rid="pcbi-1002510-g009">Figure 9</xref> shows the large disparity in stasis times holds across all settings of each process's initial bias. This is one of our first general observations about memoryful processes: The structure of memoryful processes substantially impacts the average time to stasis by increasing variance between generations. In the cases shown, time to stasis is greatly shortened.</p>
        <fig id="pcbi-1002510-g009" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g009</object-id>
          <label>Figure 9</label>
          <caption>
            <p><italic>Top:</italic> Time to stasis of the Golden Mean, Even, and Biased Coin Processes. <italic>Middle</italic>: Stasis time of the Golden Mean Process as the weighted sum of stasis times for the Fixed Coin (FC) and Alternating Process (AP) pathways. <italic>Bottom</italic>: Stasis time of the FC pathway as the weighted sum of Golden Mean (GM) and Biased Coin (BC) subspace diffusion times.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g009" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s3c">
        <title>Isostructural Subspaces</title>
        <p>To illustrate the richness of structural drift and to understand how it affects average time to stasis, we examine the complexity-entropy (CE) diagram <xref ref-type="bibr" rid="pcbi.1002510-Feldman1">[26]</xref> of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e227" xlink:type="simple"/></inline-formula>-machines produced over several realizations of an arbitrary sampling process. The CE diagram displays how the allelic entropy <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e228" xlink:type="simple"/></inline-formula> of an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e229" xlink:type="simple"/></inline-formula>-machine varies with the allelic complexity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e230" xlink:type="simple"/></inline-formula> of its causal states:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e231" xlink:type="simple"/><label>(15)</label></disp-formula>where the units are [bits]. The allelic complexity is the Shannon entropy over an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e232" xlink:type="simple"/></inline-formula>-machine 's stationary state distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e233" xlink:type="simple"/></inline-formula>. It measures the memory needed to maintain the internal state while producing stochastic outputs. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e234" xlink:type="simple"/></inline-formula>-Machine minimality guarantees that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e235" xlink:type="simple"/></inline-formula> is the smallest amount of memory required to do so. Since there is a one-to-one correspondence between processes and their <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e236" xlink:type="simple"/></inline-formula>-machines, a CE diagram is a projection of process space onto the two coordinates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e237" xlink:type="simple"/></inline-formula>. Used in tandem, these two properties differentiate many types of sampling process, capturing both their intrinsic memory (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e238" xlink:type="simple"/></inline-formula>) and the diversity (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e239" xlink:type="simple"/></inline-formula>) of populations they generate.</p>
        <sec id="s3c1">
          <title>Subspace diffusion</title>
          <p>Two such CE diagrams are shown in <xref ref-type="fig" rid="pcbi-1002510-g010">Figure 10</xref>, illustrating different subspaces and stasis points reachable by the Golden Mean Process during structural drift. Consider the left panel first. An <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e240" xlink:type="simple"/></inline-formula>-machine reaches stasis by transforming into either the Fixed Coin or the Alternating Process. To reach the former, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e241" xlink:type="simple"/></inline-formula>-machine begins on the upper curve in the left panel and drifts until the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e242" xlink:type="simple"/></inline-formula> transition probability nears zero and the inference algorithm decides to merge states in the next generation. This forces the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e243" xlink:type="simple"/></inline-formula>-machine to jump to the Biased Coin subspace on the line <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e244" xlink:type="simple"/></inline-formula> where it will most likely diffuse until the Fixed Coin stasis point at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e245" xlink:type="simple"/></inline-formula> is reached. If instead the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e246" xlink:type="simple"/></inline-formula> transition probability drifts towards zero, the Golden Mean stays on the upper curve until reaching the Alternating Process stasis point at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e247" xlink:type="simple"/></inline-formula>. Thus, the two stasis points are differentiated not by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e248" xlink:type="simple"/></inline-formula> but by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e249" xlink:type="simple"/></inline-formula>, with the Alternating Process requiring 1 bit of memory to track its internal state and the Biased Coin Process requiring none.</p>
          <p>What emerges from these diagrams is a broader view of how population structure drifts in process space. Roughly, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e250" xlink:type="simple"/></inline-formula> diffuse locally in the parameter space specified by the current, fixed architecture of states and transitions. During this, transition probability estimates vary stochastically due to sampling variance. Since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e251" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e252" xlink:type="simple"/></inline-formula> are continuous functions of the transition probabilities, this variance causes the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e253" xlink:type="simple"/></inline-formula> to fall on well defined curves or regions corresponding to a particular process subspace. (See <xref ref-type="fig" rid="pcbi-1002510-g004">Figures 4</xref> and <xref ref-type="fig" rid="pcbi-1002510-g005">5</xref> in Ref. <xref ref-type="bibr" rid="pcbi.1002510-Feldman1">[26]</xref> and the theory for these curves and regions there.)</p>
          <p>We refer to these curves as <italic>isostructural curves</italic> and the associated sets of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e254" xlink:type="simple"/></inline-formula>-machines as <italic>isostructural subspaces</italic>. They are metastable subspaces of sampling processes that are quasi-invariant under the structural drift dynamic. When one or more <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e255" xlink:type="simple"/></inline-formula>-machine parameters diffuse sufficiently so that inference is forced to change topology by adding or removing states or transitions to reflect the statistics of the sample, this quasi-invariance is broken. We call such topological shifts <italic>subspace jumps</italic> to reflect the new region occupied by the resulting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e256" xlink:type="simple"/></inline-formula>-machine in process space, as visualized by the CE diagram. Movement between subspaces is often not bidirectional—innovations from a previous topology may be lost either temporarily (when the innovation can be restored by returning to the subspace) or permanently. For example, the Golden Mean subspace commonly jumps to the Biased Coin subspace but the opposite is highly improbable without mutation. (We consider the latter type of structural drift elsewhere.)</p>
          <p>Before describing the diversity seen in the CE diagram of <xref ref-type="fig" rid="pcbi-1002510-g010">Figure 10</xref>'s right panel, we first turn to analyze in some detail the time-to-stasis underlying the behavior illustrated in the left panel.</p>
          <fig id="pcbi-1002510-g010" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002510.g010</object-id>
            <label>Figure 10</label>
            <caption>
              <title>Complexity-entropy diagram for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e257" xlink:type="simple"/></inline-formula> realizations of the Golden Mean Process with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e258" xlink:type="simple"/></inline-formula>, both without (left) and with (right) structural innovation.</title>
              <p>Alternating Process and Fixed Coin pathways are clearly visible in the left panel where the Golden Mean subspace exists on the upper curve and the Biased Coin subspace exists on the line <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e259" xlink:type="simple"/></inline-formula>. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e260" xlink:type="simple"/></inline-formula>-Machines within the same isostructural subspace have identical colors.</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.g010" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s3c2">
          <title>Subspace decomposition</title>
          <p>A <italic>pathway</italic> is a set of subspaces passed through by any drift realization starting from some initial process and reaching a specific stasis point. The time to stasis of a drift process <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e261" xlink:type="simple"/></inline-formula> is the sum of time spent in the subspaces <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e262" xlink:type="simple"/></inline-formula> visited by its pathways to stasis <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e263" xlink:type="simple"/></inline-formula>, weighted by the probabilities that these pathways and subspaces will be reached. The time spent in a subspace <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e264" xlink:type="simple"/></inline-formula> merely depends on the transition parameter(s) of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e265" xlink:type="simple"/></inline-formula>-machine at the time of entry and is otherwise independent of the prior subspace <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e266" xlink:type="simple"/></inline-formula>. Thus, calculating the stasis time of a structured population can be broken down into independent subspace times when we know the values of the transition parameters at subspace jumps. These values can be derived both empirically and analytically, and we aim to develop the latter for general drift processes in future work.</p>
          <p>More formally, the time to stasis <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e267" xlink:type="simple"/></inline-formula> of a drift process <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e268" xlink:type="simple"/></inline-formula> is simply the weighted sum of the stasis times for its connected pathways <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e269" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e270" xlink:type="simple"/><label>(16)</label></disp-formula>Similarly, the stasis time of a particular pathway decomposes into the time spent diffusing in its connected subspaces <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e271" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e272" xlink:type="simple"/><label>(17)</label></disp-formula>To demonstrate, <xref ref-type="fig" rid="pcbi-1002510-g009">Figure 9</xref> shows the stasis time of the Golden Mean Process (GMP) with initial bias <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e273" xlink:type="simple"/></inline-formula> in more detail. Regression lines along with their 95% confidence intervals are displayed for simulations with initial biases <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e274" xlink:type="simple"/></inline-formula>. The middle panel shows the total time to stasis as the weighted sum of its Fixed Coin (FC) and Alternating Process (AP) pathways:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e275" xlink:type="simple"/></disp-formula>For low <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e276" xlink:type="simple"/></inline-formula>, the transition from state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e277" xlink:type="simple"/></inline-formula> to state <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e278" xlink:type="simple"/></inline-formula> is unlikely, so <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e279" xlink:type="simple"/></inline-formula> s are rare and the AP pathway is reached infrequently. Thus, the total stasis time is initially dominated by the FC pathway (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e280" xlink:type="simple"/></inline-formula> is high). As <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e281" xlink:type="simple"/></inline-formula> and above, the AP pathway is reached more frequently (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e282" xlink:type="simple"/></inline-formula> grows) and its stasis time begins to influence the total. The FC pathway is less likely as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e283" xlink:type="simple"/></inline-formula> and the total time becomes dominated by the AP pathway (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e284" xlink:type="simple"/></inline-formula> is high).</p>
          <p>Since the AP pathway visits only one subspace, the bottom panel shows the stasis time of the FC pathway as the weighted sum of the Golden Mean (GM) and Biased Coin (BC) subspace times:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e285" xlink:type="simple"/><label>(18)</label></disp-formula>This corresponds to time spent diffusing in the GM subspace <italic>before</italic> the subspace jump and time spent diffusing in the BC subspace <italic>after</italic> the subspace jump. Note that the times quoted are simply diffusion times within a subspace, since not every subspace in a pathway contains a stasis point.</p>
          <p>These expressions emphasize the dependence of stasis time on the transition parameters at jump points as well as on the architecture of isostructural subspaces in drift process space. For example, if the GM jumps to the BC subspace at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e286" xlink:type="simple"/></inline-formula>, the stasis time will be large since the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e287" xlink:type="simple"/></inline-formula>-machine is maximally far from either stasis point. However, the inference algorithm will typically jump at very low values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e288" xlink:type="simple"/></inline-formula> resulting in a small average stasis time for the BC subspace in the FC pathway. Due to this, calculating the stasis time for the GMP requires knowing the AP and FC pathways as well as the value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e289" xlink:type="simple"/></inline-formula> where the GM<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e290" xlink:type="simple"/></inline-formula>BC jump occurs.</p>
        </sec>
        <sec id="s3c3">
          <title>Structural innovation and loss</title>
          <p>Inference of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e291" xlink:type="simple"/></inline-formula>-machines from finite populations is computationally expensive, particularly in our sequential setting with many realizations. The topology of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e292" xlink:type="simple"/></inline-formula>-machine is inferred directly from the statistics of finite samples; both states and transitions are added and removed over time to capture innovation and loss of population structure. In the spirit of Kimura's <italic>pseudo-sampling variable</italic> (PSV) method <xref ref-type="bibr" rid="pcbi.1002510-Kimura3">[27]</xref>, we introduce a PSV algorithm for efficient structural drift simulation and increased control of the trade-off between structural innovation and loss.</p>
          <p>Instead of inferring and re-inferring an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e293" xlink:type="simple"/></inline-formula>-machine each generation, we explicitly define the conditions for topological changes to the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e294" xlink:type="simple"/></inline-formula>-machine of the previous generation. To test for <italic>structural innovation</italic>, a random causal state from the current <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e295" xlink:type="simple"/></inline-formula> is cloned and random incoming transitions are routed instead to the cloned state. This creates a new model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e296" xlink:type="simple"/></inline-formula> that describes the same process. Gaussian noise is then added to the cloned state's outgoing transitions to represent some change in population structure. The likelihood of the population <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e297" xlink:type="simple"/></inline-formula> is calculated for both <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e298" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e299" xlink:type="simple"/></inline-formula> and the model with the maximum a posteriori (MAP) likelihood is retained:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e300" xlink:type="simple"/><label>(19)</label></disp-formula>If the original <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e301" xlink:type="simple"/></inline-formula> was retained, its transition parameters are updated by feeding the sample through the model to obtain edge counts which are then normalized to obtain probabilities. This produces a generator for the next generation's population in a way that allows for innovation. As well, it side-steps the computational cost of the inference algorithm.</p>
          <p>To capture structural loss, we monitor near-zero transition probabilities where an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e302" xlink:type="simple"/></inline-formula>-machine inference algorithm would merge states. When such a transition exists we test for structural simplification by considering all pairwise mergings of causal states and select the topology via the MAP likelihood. However, unlike above, we penalize likelihood using the Akaike Information Criterion (AIC) <xref ref-type="bibr" rid="pcbi.1002510-Akaike1">[28]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e303" xlink:type="simple"/><label>(20)</label></disp-formula>and, in particular, the AIC corrected for finite sample sizes <xref ref-type="bibr" rid="pcbi.1002510-Burnham1">[29]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e304" xlink:type="simple"/><label>(21)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e305" xlink:type="simple"/></inline-formula> is the number of model parameters, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e306" xlink:type="simple"/></inline-formula> is the sample likelihood, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e307" xlink:type="simple"/></inline-formula> is the sample size. A penalized likelihood is necessary because a smaller <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e308" xlink:type="simple"/></inline-formula>-machine is more general and cannot fit the data as well. When penalized by model size, however, a smaller model with sufficient fit to the data may be selected over a larger, better fitting model. This method allows loss to occur while again avoiding the expense of the full <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e309" xlink:type="simple"/></inline-formula>-machine inference algorithm. Extensive comparisons with several versions of the latter show that the new PSV structural drift algorithm produces qualitatively the same behavior.</p>
          <p>Having explained how the pseudo-drift algorithm introduces structural innovation and loss we can now describe the drift runs of <xref ref-type="fig" rid="pcbi-1002510-g010">Figure 10</xref>'s right panel. In contrast to the left panel, structural innovation was enabled. The immediate result is that the drift process visits a much wider diversity of isostructural subspaces—sampling processes that are markedly more complex. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e310" xlink:type="simple"/></inline-formula>-Machines with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e311" xlink:type="simple"/></inline-formula> or more states are created, some of which are quite entropic and so produce high sampling variance. Stasis <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e312" xlink:type="simple"/></inline-formula>-machines with periods <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e313" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e314" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e315" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e316" xlink:type="simple"/></inline-formula> are seen, while only those with periods <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e317" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e318" xlink:type="simple"/></inline-formula> are seen in runs without innovation (left panel).</p>
          <p>By way of closing this first discussion of structural drift, it should be emphasized that none of the preceding phenomena occur in the limit of infinite populations or infinite sample size. The variance due to finite sampling drives sequential learning, the diffusion through process space, and the jumps between isostructural subspaces.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s4">
      <title>Discussion</title>
      <sec id="s4a">
        <title>Applications and Extensions</title>
        <p>Much of the previous discussion focused on structural drift as a kind of stochastic process, with examples and behaviors selected to emphasize the role of structure. Although there was a certain terminological bias toward neutral evolution theory since the latter provides an entree to analyzing how structural drift works, our presentation was intentionally general. Motivated by a variety of potential applications and extensions, we describe these now and close with several summary remarks on structural drift itself.</p>
        <sec id="s4a1">
          <title>Emergent semantics and learning in communication chains</title>
          <p>Let's return to draw parallels with the opening example of the game of <italic>Telephone</italic> or, more directly, to the sequential inference of temporal structure in an utterance passed along a serially coupled communication chain. There appears to be no shortage of related theories of language evolution. These range from the population dynamics of Ref. <xref ref-type="bibr" rid="pcbi.1002510-Komarova1">[30]</xref> and the ecological dynamics of Ref. <xref ref-type="bibr" rid="pcbi.1002510-Sol1">[31]</xref> to the cataloging of error sources in human communication <xref ref-type="bibr" rid="pcbi.1002510-Campbell1">[32]</xref> and recent efforts to understand cultural evolution as reflecting learning biases <xref ref-type="bibr" rid="pcbi.1002510-Grifiths1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Chater1">[34]</xref>.</p>
          <p>By way of contrast, structural drift captures the language-centric notion of dynamically changing semantics and demonstrates how behavior is driven by finite-sample fluctuations within a semantically organized subspace. The symbols and words in the generated strings have a semantics given by the structure of a subspace's <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e319" xlink:type="simple"/></inline-formula>-machine ; see Ref. <xref ref-type="bibr" rid="pcbi.1002510-Crutchfield2">[3]</xref>. A particularly simple example was identified quite early in the information-theoretic analysis of natural language: The Golden Mean <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e320" xlink:type="simple"/></inline-formula>-machine (<xref ref-type="fig" rid="pcbi-1002510-g004">Figure 4</xref>) describes the role of isolated space symbols in written English <xref ref-type="bibr" rid="pcbi.1002510-Miller1">[35, Figure 1]</xref>. Notably, this structure is responsible for the Mandelbrot-Zipf power-law scaling of word frequencies <xref ref-type="bibr" rid="pcbi.1002510-Mandelbrot1">[36]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Zipf1">[37]</xref>. More generally, though, the semantic theory of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e321" xlink:type="simple"/></inline-formula>-machines shows that causal states provide dynamic contexts for interpretation as individual symbols and words are recognized. Quantitatively, the allelic complexity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e322" xlink:type="simple"/></inline-formula> is the total amount of semantic content that can be generated by an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e323" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002510-Crutchfield2">[3]</xref>. In this way, shifts in the architecture of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e324" xlink:type="simple"/></inline-formula> during drift correspond to semantic changes. That is, diffusion within an isostructural subspace corresponds to constant semantics, while jumps between isostructural subspaces correspond to semantic innovations (or losses).</p>
          <p>In the drift behaviors explored above, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e325" xlink:type="simple"/></inline-formula> went to stasis (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e326" xlink:type="simple"/></inline-formula>) corresponding to periodic formal languages. Clearly, such a long-term condition falls far short as a model of human communication chains. The resulting communications, though distant from those at the beginning of the chain, are not periodic. To more closely capture emergent semantics in the context of sequential language learning, we have extended structural drift to include mutation and selection. In future work we will use these extensions to investigate how the former prevents permanent stasis and the latter enables a preference for intelligible phrases.</p>
        </sec>
        <sec id="s4a2">
          <title>Cultural evolution and iterated learning</title>
          <p>Extending these observations, the Iterated Learning Model (ILM) of language evolution <xref ref-type="bibr" rid="pcbi.1002510-Smith2">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Kirby1">[39]</xref> is of particular interest. In this model, a language evolves by repeated production and acquisition by agents under cultural pressures and the “poverty of the stimulus” <xref ref-type="bibr" rid="pcbi.1002510-Smith2">[38]</xref>. Via this process, language is effectively forced through a transmission bottleneck that requires the learning agent to generalize from finite data. This, in turn, exerts pressure on the language to adapt to the bias of the learner. Thus, in contrast to traditional views that the human brain evolved to learn language, ILM suggests that language also adapts to be learnable by the human brain.</p>
          <p>ILM incorporates the sequential learning and propagation of error we discuss here and provides valuable insight into the effects of error and cultural mutations on the evolution of language for the “human niche”. There are various simulation approaches to ILM with both single and multiple agents based on, for example, neural networks and Bayesian inference, as well as experiments with human subjects. We suggest that structural drift could also serve as the basis for single-agent ILM experiments, as found in Swarup et al. <xref ref-type="bibr" rid="pcbi.1002510-Swarup1">[40]</xref>, where populations of alleles in the former are replaced by linguistic features of the latter. The benefits are compelling: an information-theoretic framework for quantifying the trade-off between learner bias and transmission bottleneck pressures, visualization of cultural evolution via the CE diagram, and decomposition of the time-to-stasis of linguistic features in terms of isostructural subspaces as presented above.</p>
        </sec>
        <sec id="s4a3">
          <title>Epochal evolution</title>
          <p>Beyond applications to knowledge transmission via serial communication channels, structural drift gives an alternative view of drift processes in population genetics. In light of new kinds of evolutionary behavior, it reframes the original questions about underlying mechanisms and extends their scope to phenomena that exhibit memory in the sampling process or that derive from structure in populations. Examples of the latter include niche construction <xref ref-type="bibr" rid="pcbi.1002510-OdlingSmee1">[41]</xref>, the effects of environmental toxins <xref ref-type="bibr" rid="pcbi.1002510-Medina1">[42]</xref>, changes in predation <xref ref-type="bibr" rid="pcbi.1002510-Tremblay1">[43]</xref>, and socio-political factors <xref ref-type="bibr" rid="pcbi.1002510-Kayser1">[44]</xref> where memory lies in the spatial distribution of populations. In addition to these, several applications to areas beyond population genetics proper suggest themselves.</p>
          <p>An intriguing parallel exists between structural drift and the longstanding question about the origins of <italic>punctuated equilibrium</italic> <xref ref-type="bibr" rid="pcbi.1002510-Gould1">[45]</xref> when modeled as the dynamics of <italic>epochal evolution</italic> <xref ref-type="bibr" rid="pcbi.1002510-vanNimwegen2">[46]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Crutchfield5">[47]</xref>. The possibility of evolution's intermittent progress—long periods of stasis punctuated by rapid change—dates back to Fisher's demonstration of metastability in drift processes with multiple alleles <xref ref-type="bibr" rid="pcbi.1002510-Fisher1">[13]</xref>.</p>
          <p>Epochal evolution, though, presented an alternative to the view of metastability posed by Fisher's model and Wright's adaptive landscapes <xref ref-type="bibr" rid="pcbi.1002510-Wright2">[48]</xref>. Within epochal evolutionary theory, equivalence classes of genotype fitness, called <italic>subbasins</italic>, are connected by fitness-changing <italic>portals</italic> to other subbasins. A genotype is free to diffuse within its subbasin via selectively neutral mutations, until an advantageous mutation drives genotypes through a portal to a higher-fitness subbasin. An increasing number of genotypes derive from this founder and diffuse in the new subbasin until another portal to higher fitness is discovered. Thus, the structure of the subbasin-portal architecture dictates the punctuated dynamics of evolution.</p>
          <p>Given an adaptive system which learns structure by sampling its past organization, structural drift theory implies that its evolutionary dynamics are inevitably described by punctuated equilibria. Diffusion in an isostructural subspace corresponds to a period of structured equilibrium in a subbasin and subspace jumps correspond to rapid innovation or loss of organization during the transit of a portal. In this way, structural drift establishes a connection between evolutionary innovation and structural change, identifying the conditions for creation or loss of organization. Extending structural drift to include mutation and selection will provide a theoretical framework for epochal evolution using any number of structural constraints in a population.</p>
        </sec>
        <sec id="s4a4">
          <title>Evolution of graph-structured populations</title>
          <p>We focused primarily on the drift of sequentially ordered populations in which the generator (an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e327" xlink:type="simple"/></inline-formula>-machine ) captured the structure and randomness in that ordering. We aimed to show that a population's organization plays a crucial role in its dynamics. This was, however, only one example of the general class of drift process we have in mind. For example, computational mechanics also describes structure in spatially extended systems <xref ref-type="bibr" rid="pcbi.1002510-Hanson1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1002510-Varn2">[50]</xref>. Given this, it is straightforward to build a model of drift in geographically distributed populations that exhibit spatiotemporal structure.</p>
          <p>Though they have not tracked the structural complexity embedded in populations as we have done here, a number of investigations consider various classes of structured populations. For example, the evolutionary dynamics of structured populations have been studied using undirected graphs to represent correlations between individuals. Edge weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e328" xlink:type="simple"/></inline-formula> between individuals <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e329" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e330" xlink:type="simple"/></inline-formula> give the probability that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e331" xlink:type="simple"/></inline-formula> will replace <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e332" xlink:type="simple"/></inline-formula> with its offspring when selected to reproduce.</p>
          <p>By studying fixation and selection behavior on different types of graphs, Lieberman et al. found that graph structures can sometimes amplify or suppress the effects of selection, even guaranteeing the fixation of advantageous mutations <xref ref-type="bibr" rid="pcbi.1002510-Lieberman1">[51]</xref>. Jain and Krishna <xref ref-type="bibr" rid="pcbi.1002510-Jain1">[52]</xref> investigated the evolution of directed graphs and the emergence of self-reinforcing autocatalytic networks of interaction. They identified the attractors in these networks and demonstrated a diverse range of behaviors from the creation of structural complexity to its collapse and permanent loss.</p>
          <p>Graph evolution is a model of population structure complementary to that presented by structural drift. In the latter, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e333" xlink:type="simple"/></inline-formula>-machine structure evolves over time with nodes representing equivalence classes of the distribution of selectively neutral alleles. Unlike <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e334" xlink:type="simple"/></inline-formula>-machines, the multinomial sampling of individuals in graph evolution is a memoryless process. A combined approach will allow one to examine how amplification and suppression of selection and the emergence of autocatalysis are affected by external influences on the population structure. For example, this could include how a population uses temporal memory to maintain desirable properties in anticipation of structural shifts in the environment. The result would provide a theory for niche construction in which a nonlinear dynamics of pattern formation spontaneously changes population structure.</p>
        </sec>
      </sec>
      <sec id="s4b">
        <title>Final Remarks</title>
        <p>The Fisher-Wright model of genetic drift can be viewed as a random walk of coin biases, a stochastic process that describes generational change in allele frequencies based on a strong statistical assumption: the sampling process is memoryless. Here, we developed a generalized structural drift model that adds memory to the process and examined the consequences of such population sampling memory.</p>
        <p>Memoryful sampling is a substantial departure from modeling evolutionary processes with unordered populations. Rather than view structural drift as a replacement for the well understood theory of genetic drift, and given that the latter is a special case of structurally drifting populations, we propose that it be seen as a new avenue for theoretical invention. Given its additional ties to language and cultural evolution, we believe it will provide a novel perspective on evolution in nonbiological domains, as well.</p>
        <p>The representation selected for the population sampling mechanism was the class of probabilistic finite-state hidden Markov models called <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e335" xlink:type="simple"/></inline-formula>-machines. We discussed how a sequential chain of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e336" xlink:type="simple"/></inline-formula>-machines inferred and re-inferred from the finite data they generate parallels the drift of alleles in a finite population, using otherwise the same assumptions made by the Fisher-Wright model. The mathematical foundations developed for the latter and its related models provide a good deal quantitative, predictive power. Much of this has yet to be exploited. In concert with this, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e337" xlink:type="simple"/></inline-formula>-machine minimality allowed us to monitor information processing, information storage, and causal architecture during the drift process. We introduced the information-theoretic notion of structural stasis to combine the concepts of deletion, fixation, and periodicity for drift processes. Generally, structural stasis occurs when the population's allelic entropy vanishes—a quantity one can calculate in closed form due to the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e338" xlink:type="simple"/></inline-formula>-machine representation of the sampling process.</p>
        <p>We revisited Kimura and Ohta's early results measuring the time to fixation of drifting alleles and showed that the generalized structural drift process reproduces these well known results when staying within the memoryless sampling process subspace. Starting with structured populations outside of that subspace led the sampling process to exhibit memory effects including structural innovation and loss, complex transients, and greatly reduced stasis times.</p>
        <p>Simulations demonstrated how an <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e339" xlink:type="simple"/></inline-formula>-machine diffuses through isostructural process subspaces during sequential learning. The result was a very complex time-to-stasis dependence on the initial probability parameter—much more complicated than Kimura's theory describes. Nonetheless, we showed that a process' time to stasis can be decomposed into sums over these independent subspaces. Moreover, the time spent in an isostructural subspace depends on the value of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e340" xlink:type="simple"/></inline-formula>-machine probability parameters at the time of entry. This suggests an extension to Kimura's theory for predicting the time to stasis for each isostructural component independently. Much of the phenomenological analysis was facilitated by the global view of drift process space given by the complexity-entropy diagram.</p>
        <p>Drift processes with memory generally describe the evolution of structured populations without mutation or selection. Nonetheless, we showed that structure leads to substantially shorter stasis times. This was seen in drifts starting with the Biased Coin and Golden Mean Processes, where the Golden Mean jumps into the Biased Coin subspace close to an absorbing state. This suggests that even without selection, population structure and sampling memory matter in evolutionary dynamics. The temporal or spatial memory captured by the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e341" xlink:type="simple"/></inline-formula>-machine can be interpreted as nonrandom mating, reducing the effective population size <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e342" xlink:type="simple"/></inline-formula> and, in doing so, increasing sampling variance. It also suggests that memoryless models restrict sequential learning and overestimate stasis times for structured populations.</p>
        <p>We demonstrated how structural drift—diffusion, structural innovation and loss—are controlled by the architecture of connected isostructural subspaces. Many questions remain about these subspaces. What is the degree of subspace-jump irreversibility? Can we predict the likelihood of these jumps? What does the phase portrait of a drift process look like? Thus, to better understand structural drift, we need to analyze the high-level organization of generalized drift process space.</p>
        <p>Fortunately, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e343" xlink:type="simple"/></inline-formula>-machines are in one-to-one correspondence with structured processes <xref ref-type="bibr" rid="pcbi.1002510-Johnson1">[25]</xref>. Thus, the preceding question reduces to understanding the space of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002510.e344" xlink:type="simple"/></inline-formula>-machines and how they can be connected by diffusion processes. Is the diffusion within each process subspace predicted by Kimura's theory or some simple variant? We have given preliminary evidence that it does. And so, there are reasons to be optimistic that in face of the open-ended complexity of structural drift, a good deal can be predicted analytically. And this, in turn, will lead to quantitative applications.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002510-Smith1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>CUM</given-names></name></person-group>             <year>1988</year>             <article-title>Send reinforcements we're going to advance.</article-title>             <source>Bio Phil</source>             <volume>3</volume>             <fpage>214</fpage>             <lpage>217</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Crutchfield1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name><name name-style="western"><surname>Young</surname><given-names>K</given-names></name></person-group>             <year>1989</year>             <article-title>Inferring Statistical Complexity.</article-title>             <source>Phys Rev Lett</source>             <volume>63</volume>             <fpage>105</fpage>             <lpage>108</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Crutchfield2">
        <label>3</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name></person-group>             <year>1992</year>             <article-title>Semantics and Thermodynamics.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Casdagli</surname><given-names>M</given-names></name><name name-style="western"><surname>Eubank</surname><given-names>S</given-names></name></person-group>             <source>Non-linear Modeling and Forecasting</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Addison-Wesley</publisher-name>             <fpage>317</fpage>             <lpage>359</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Shalizi1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shalizi</surname><given-names>CR</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name></person-group>             <year>2001</year>             <article-title>Computational Mechanics: Pattern and Prediction, Structure and Simplicity.</article-title>             <source>J Stat Phys</source>             <volume>104</volume>             <fpage>817</fpage>             <lpage>879</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Kimura1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kimura</surname><given-names>M</given-names></name><name name-style="western"><surname>Ohta</surname><given-names>T</given-names></name></person-group>             <year>1969</year>             <article-title>The Average Number of Generations until Fixation of a Mutant Gene in a Finite Population.</article-title>             <source>Genetics</source>             <volume>61</volume>             <fpage>763</fpage>             <lpage>771</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-vanNimwegen1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>van Nimwegen</surname><given-names>E</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name><name name-style="western"><surname>Huynen</surname><given-names>M</given-names></name></person-group>             <year>1999</year>             <article-title>Neutral evolution of mutational robustness.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>96</volume>             <fpage>9716</fpage>             <lpage>9720</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Bloom1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bloom</surname><given-names>JD</given-names></name><name name-style="western"><surname>Labthavikul</surname><given-names>ST</given-names></name><name name-style="western"><surname>Otey</surname><given-names>CR</given-names></name><name name-style="western"><surname>Arnold</surname><given-names>FH</given-names></name></person-group>             <year>2006</year>             <article-title>Protein stability promotes evolvability.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>103</volume>             <fpage>5869</fpage>             <lpage>5874</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Raval1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Raval</surname><given-names>A</given-names></name></person-group>             <year>2007</year>             <article-title>Molecular Clock on a Neutral Network.</article-title>             <source>Phys Rev Lett</source>             <volume>99</volume>             <fpage>138104</fpage>             <lpage>138108</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Crutchfield3">
        <label>9</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name><name name-style="western"><surname>Schuster</surname><given-names>PK</given-names></name></person-group>             <year>2003</year>             <source>Evolutionary Dynamics: Exploring the Interplay of Selection, Accident, Neutrality, and Function. Santa Fe Institute Series in the Sciences of Complexity</source>             <publisher-name>Oxford University Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Koelle1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Koelle</surname><given-names>K</given-names></name><name name-style="western"><surname>Cobey</surname><given-names>S</given-names></name><name name-style="western"><surname>Grenfell</surname><given-names>B</given-names></name><name name-style="western"><surname>Pascual</surname><given-names>M</given-names></name></person-group>             <year>2006</year>             <article-title>Epochal evolution shapes the phylodynamics of interpandemic inuenza A (H3N2) in humans.</article-title>             <source>Science</source>             <volume>314</volume>             <fpage>1898</fpage>             <lpage>1903</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Kimura2">
        <label>11</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kimura</surname><given-names>M</given-names></name></person-group>             <year>1983</year>             <source>The Neutral Theory of Molecular Evolution</source>             <publisher-loc>Cambridge, UK</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">367</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002510-Wright1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wright</surname><given-names>S</given-names></name></person-group>             <year>1931</year>             <article-title>Evolution in Mendelian Populations.</article-title>             <source>Genetics</source>             <volume>16</volume>             <fpage>97</fpage>             <lpage>126</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Fisher1">
        <label>13</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fisher</surname><given-names>RA</given-names></name></person-group>             <year>1930</year>             <source>The Genetical Theory of Natural Selection</source>             <publisher-loc>Oxford, England</publisher-loc>             <publisher-name>Clarendon Press</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">272</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002510-Holsinger1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Holsinger</surname><given-names>KE</given-names></name><name name-style="western"><surname>Weir</surname><given-names>BS</given-names></name></person-group>             <year>2009</year>             <article-title>Genetics in geographically structured populations: Defining, estimating and interpreting F ST.</article-title>             <source>Nat Rev Gen</source>             <volume>10</volume>             <fpage>639</fpage>             <lpage>650</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Gillespie1">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gillespie</surname><given-names>JH</given-names></name></person-group>             <year>2000</year>             <article-title>Genetic Drift in an Infinite Population: The Pseudohitchhiking Model.</article-title>             <source>Genetics</source>             <volume>155</volume>             <fpage>909</fpage>             <lpage>919</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Mendel1">
        <label>16</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mendel</surname><given-names>G</given-names></name></person-group>             <year>1925</year>             <source>Experiments in Plant Hybridisation</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>Harvard University Press</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Feller1">
        <label>17</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Feller</surname><given-names>W</given-names></name></person-group>             <year>1968</year>             <source>An Introduction to Probability Theory and Its Applications, Volume 1</source>             <publisher-loc>San Francisco</publisher-loc>             <publisher-name>John Wiley and Sons. 3rd edition</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">509</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002510-Gillespie2">
        <label>18</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gillespie</surname><given-names>JH</given-names></name></person-group>             <year>2004</year>             <source>Population Genetics: A Concise Guide</source>             <publisher-name>Johns Hopkins University Press. 2nd edition</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Leibler1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Leibler</surname><given-names>S</given-names></name><name name-style="western"><surname>Kussell</surname><given-names>E</given-names></name></person-group>             <year>2010</year>             <article-title>Individual histories and selection in heterogeneous populations.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>107</volume>             <fpage>13183</fpage>             <lpage>13188</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Shalizi2">
        <label>20</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shalizi</surname><given-names>CR</given-names></name><name name-style="western"><surname>Shalizi</surname><given-names>KL</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name></person-group>             <year>2002</year>             <article-title>Pattern Discovery in Time Series, Part I: Theory, Algorithm, Analysis, and Convergence.</article-title>             <comment><ext-link ext-link-type="uri" xlink:href="http://arXiv.org/abs/cs.LG/0210025" xlink:type="simple">http://arXiv.org/abs/cs.LG/0210025</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Varn1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Varn</surname><given-names>DP</given-names></name><name name-style="western"><surname>Canright</surname><given-names>GS</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name></person-group>             <year>2002</year>             <article-title>Discovering planar disorder in close-packed structures from x-ray diffraction: Beyond the fault model.</article-title>             <source>Phys Rev B Condens Matter</source>             <volume>66</volume>             <fpage>174110</fpage>             <lpage>3</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Kullback1">
        <label>22</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kullback</surname><given-names>S</given-names></name></person-group>             <year>1959</year>             <source>Information Theory and Statistics</source>             <publisher-loc>San Francisco</publisher-loc>             <publisher-name>John Wiley and Sons</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">432</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002510-Pielou1">
        <label>23</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pielou</surname><given-names>EC</given-names></name></person-group>             <year>1967</year>             <article-title>The use of information theory in the study of the diversity of biological populations.</article-title>             <source>Proceedings of the 5th Berkeley Symposium on Mathematical Statistics and Probability; vol. 4</source>             <publisher-name>University of California Press</publisher-name>             <fpage>163</fpage>             <lpage>177</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Crutchfield4">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name><name name-style="western"><surname>Feldman</surname><given-names>DP</given-names></name></person-group>             <year>2003</year>             <article-title>Regularities unseen, randomness observed: Levels of entropy convergence.</article-title>             <source>CHAOS</source>             <volume>13</volume>             <fpage>25</fpage>             <lpage>54</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Johnson1">
        <label>25</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Johnson</surname><given-names>BD</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name><name name-style="western"><surname>Ellison</surname><given-names>CJ</given-names></name><name name-style="western"><surname>McTague</surname><given-names>CS</given-names></name></person-group>             <year>2010</year>             <article-title>Enumerating finitary processes.</article-title>             <comment><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1011.0036" xlink:type="simple">http://arxiv.org/abs/1011.0036</ext-link></comment>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Feldman1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Feldman</surname><given-names>DP</given-names></name><name name-style="western"><surname>McTague</surname><given-names>CS</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name></person-group>             <year>2008</year>             <article-title>The organization of intrinsic computation: Complexity-entropy diagrams and the diversity of natural information processing.</article-title>             <source>CHAOS</source>             <volume>18</volume>             <fpage>59</fpage>             <lpage>73</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Kimura3">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kimura</surname><given-names>M</given-names></name></person-group>             <year>1980</year>             <article-title>Average Time until Fixation of a Mutant Allele in a Finite Population under Continued Mutation Pressure: Studies by Analytical, Numerical, and Pseudo-Sampling Methods.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>77</volume>             <fpage>522</fpage>             <lpage>526</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Akaike1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Akaike</surname><given-names>H</given-names></name></person-group>             <year>1974</year>             <article-title>A new look at the statistical model identification.</article-title>             <source>IEEE Trans Automat Contr</source>             <volume>19</volume>             <fpage>716</fpage>             <lpage>723</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Burnham1">
        <label>29</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Burnham</surname><given-names>KP</given-names></name><name name-style="western"><surname>Anderson</surname><given-names>D</given-names></name></person-group>             <year>2002</year>             <source>Model Selection and Multi-Model Inference</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Springer</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Komarova1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Komarova</surname><given-names>N</given-names></name><name name-style="western"><surname>Nowak</surname><given-names>MA</given-names></name></person-group>             <year>2003</year>             <article-title>Language Dynamics in Finite Populations.</article-title>             <source>J Theor Biol</source>             <volume>221</volume>             <fpage>445</fpage>             <lpage>457</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Sol1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Solé</surname><given-names>RV</given-names></name><name name-style="western"><surname>Corominas-Murtra</surname><given-names>B</given-names></name><name name-style="western"><surname>Fortuny</surname><given-names>J</given-names></name></person-group>             <year>2010</year>             <article-title>Diversity, competition, extinction: The ecophysics of language change.</article-title>             <source>J R Soc Interface</source>             <volume>7</volume>             <fpage>1647</fpage>             <lpage>1664</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Campbell1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Campbell</surname><given-names>DT</given-names></name></person-group>             <year>1958</year>             <article-title>Systematic error on the part of human links in communication systems.</article-title>             <source>Info Control</source>             <volume>1</volume>             <fpage>334</fpage>             <lpage>369</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Grifiths1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grifiths</surname><given-names>TL</given-names></name><name name-style="western"><surname>Kalish</surname><given-names>ML</given-names></name><name name-style="western"><surname>Lewandowsky</surname><given-names>S</given-names></name></person-group>             <year>2008</year>             <article-title>Theoretical and empirical evidence for the impact of inductive biases on cultural evolution.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>363</volume>             <fpage>3503</fpage>             <lpage>14</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Chater1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Chater</surname><given-names>N</given-names></name><name name-style="western"><surname>Christiansen</surname><given-names>MH</given-names></name></person-group>             <year>2009</year>             <article-title>Language Acquisition Meets Language Evolution.</article-title>             <source>Cogn Sci</source>             <volume>34</volume>             <fpage>1131</fpage>             <lpage>1157</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Miller1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Miller</surname><given-names>GA</given-names></name><name name-style="western"><surname>Newman</surname><given-names>EB</given-names></name><name name-style="western"><surname>Friedman</surname><given-names>EA</given-names></name></person-group>             <year>1958</year>             <article-title>Length-Frequency Statistics for Written English.</article-title>             <source>Info Control</source>             <volume>1</volume>             <fpage>370</fpage>             <lpage>389</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Mandelbrot1">
        <label>36</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mandelbrot</surname><given-names>B</given-names></name></person-group>             <year>1953</year>             <article-title>An informational theory of the statistical structure of languages.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Jackson</surname><given-names>W</given-names></name></person-group>             <source>Communication Theory</source>             <publisher-loc>London</publisher-loc>             <publisher-name>Butterworths</publisher-name>             <fpage>486</fpage>             <lpage>502</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Zipf1">
        <label>37</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zipf</surname><given-names>GK</given-names></name></person-group>             <year>1965</year>             <source>The Psycho-Biology of Language: An Introduction to Dynamic Philology</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press. 2nd edition</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Smith2">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Smith</surname><given-names>K</given-names></name><name name-style="western"><surname>Kirby</surname><given-names>S</given-names></name><name name-style="western"><surname>Brighton</surname><given-names>H</given-names></name></person-group>             <year>2003</year>             <article-title>Iterated learning: A framework for the emergence of language.</article-title>             <source>Artif Life</source>             <volume>9</volume>             <fpage>371</fpage>             <lpage>386</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Kirby1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kirby</surname><given-names>S</given-names></name><name name-style="western"><surname>Dowman</surname><given-names>M</given-names></name><name name-style="western"><surname>Grifiths</surname><given-names>TL</given-names></name></person-group>             <year>2007</year>             <article-title>Innateness and culture in the evolution of language.</article-title>             <source>Proc Natl Acad Sci U S A</source>             <volume>104</volume>             <fpage>5241</fpage>             <lpage>5245</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Swarup1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Swarup</surname><given-names>S</given-names></name><name name-style="western"><surname>Gasser</surname><given-names>L</given-names></name></person-group>             <year>2009</year>             <article-title>The Iterated Classification Game: A New Model of the Cultural Transmission of Language.</article-title>             <source>Adapt Behav</source>             <volume>17</volume>             <fpage>213</fpage>             <lpage>235</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-OdlingSmee1">
        <label>41</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Odling-Smee</surname><given-names>FJ</given-names></name><name name-style="western"><surname>Laland</surname><given-names>KN</given-names></name><name name-style="western"><surname>Feldman</surname><given-names>MW</given-names></name></person-group>             <year>2003</year>             <source>Niche Construction: The Neglected Process in Evolution</source>             <publisher-loc>Princeton, New Jersey</publisher-loc>             <publisher-name>Princeton University Press</publisher-name> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">468</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002510-Medina1">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Medina</surname><given-names>MH</given-names></name><name name-style="western"><surname>Correa</surname><given-names>JA</given-names></name><name name-style="western"><surname>Barata</surname><given-names>C</given-names></name></person-group>             <year>2007</year>             <article-title>Micro-evolution due to pollution: Possible consequences for ecosystem responses to toxic stress.</article-title>             <source>Chemosphere</source>             <volume>67</volume>             <fpage>2105</fpage>             <lpage>2114</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Tremblay1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Tremblay</surname><given-names>A</given-names></name><name name-style="western"><surname>Lesbarreres</surname><given-names>D</given-names></name><name name-style="western"><surname>Merritt</surname><given-names>T</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>C</given-names></name><name name-style="western"><surname>Gunn</surname><given-names>J</given-names></name></person-group>             <year>2008</year>             <article-title>Genetic Structure and Phenotypic Plasticity of Yellow Perch (Perca Flavescens) Populations Inuenced by Habitat, Predation, and Contamination Gradients.</article-title>             <source>Integr Environ Assess Manag</source>             <volume>4</volume>             <fpage>264</fpage>             <lpage>266</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Kayser1">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kayser</surname><given-names>M</given-names></name><name name-style="western"><surname>Lao</surname><given-names>O</given-names></name><name name-style="western"><surname>Anslinger</surname><given-names>K</given-names></name><name name-style="western"><surname>Augustin</surname><given-names>C</given-names></name><name name-style="western"><surname>Bargel</surname><given-names>G</given-names></name><etal/></person-group>             <year>2005</year>             <article-title>Significant genetic differentiation between Poland and Germany follows present-day political borders, as revealed by Y-chromosome analysis.</article-title>             <source>Hum Genet</source>             <volume>117</volume>             <fpage>428</fpage>             <lpage>443</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Gould1">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gould</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Eldredge</surname><given-names>N</given-names></name></person-group>             <year>1977</year>             <article-title>Punctuated equilibria: The tempo and mode of evolution reconsidered.</article-title>             <source>Paleobiology</source>             <volume>3</volume>             <fpage>115</fpage>             <lpage>151</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-vanNimwegen2">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>van Nimwegen</surname><given-names>E</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name><name name-style="western"><surname>Mitchell</surname><given-names>M</given-names></name></person-group>             <year>1999</year>             <article-title>Statistical Dynamics of the Royal Road Genetic Algorithm.</article-title>             <source>Theor Comput Sci</source>             <volume>229</volume>             <fpage>41</fpage>             <lpage>102</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Crutchfield5">
        <label>47</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name></person-group>             <year>2003</year>             <article-title>When Evolution is Revolution—Origins of Innovation.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name><name name-style="western"><surname>Schuster</surname><given-names>PK</given-names></name></person-group>             <source>Evolutionary Dynamics—Exploring the Interplay of Selection, Neutrality, Accident, and Function, Santa Fe Institute Series in the Sciences of Complexity</source>             <publisher-loc>Oxford, UK</publisher-loc>             <publisher-name>Oxford University Press</publisher-name>             <fpage>101</fpage>             <lpage>133</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Wright2">
        <label>48</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wright</surname><given-names>S</given-names></name></person-group>             <year>1932</year>             <article-title>The roles of mutation, inbreeding, crossbreeding, and selection in evolution.</article-title>             <source>Proceedings of the Sixth International Congress of Genetics; vol. 1</source>             <fpage>355</fpage>             <lpage>366</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Hanson1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hanson</surname><given-names>JE</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name></person-group>             <year>1997</year>             <article-title>Computational Mechanics of Cellular Automata: An Example.</article-title>             <source>Physica D</source>             <volume>103</volume>             <fpage>169</fpage>             <lpage>189</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Varn2">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Varn</surname><given-names>DP</given-names></name><name name-style="western"><surname>Crutchfield</surname><given-names>JP</given-names></name></person-group>             <year>2004</year>             <article-title>From Finite to Infinite Range Order via Annealing: The Causal Architecture of Deformation Faulting in Annealed Close-Packed Crystals.</article-title>             <source>Phys Lett A</source>             <volume>324</volume>             <fpage>299</fpage>             <lpage>307</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Lieberman1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Lieberman</surname><given-names>E</given-names></name><name name-style="western"><surname>Hauert</surname><given-names>C</given-names></name><name name-style="western"><surname>Nowak</surname><given-names>MA</given-names></name></person-group>             <year>2005</year>             <article-title>Evolutionary dynamics on graphs.</article-title>             <source>Nature</source>             <volume>433</volume>             <fpage>312</fpage>             <lpage>316</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002510-Jain1">
        <label>52</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jain</surname><given-names>S</given-names></name><name name-style="western"><surname>Krishna</surname><given-names>S</given-names></name></person-group>             <year>2002</year>             <article-title>Graph theory and the evolution of autocatalytic networks.</article-title>             <person-group person-group-type="editor"><name name-style="western"><surname>Bornholdt</surname><given-names>S</given-names></name><name name-style="western"><surname>Schuster</surname><given-names>HG</given-names></name></person-group>             <source>Handbook of Graphs and Networks</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Wiley-VCH Verlag GmbH &amp; Co. KGaA</publisher-name>             <fpage>355</fpage>             <lpage>395</lpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
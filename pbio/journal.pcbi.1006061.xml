<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006061</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-01171</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Earth sciences</subject><subj-group><subject>Atmospheric science</subject><subj-group><subject>Climatology</subject><subj-group><subject>Albedo</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Astronomical sciences</subject><subj-group><subject>Planetary sciences</subject><subj-group><subject>Albedo</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Electromagnetic radiation</subject><subj-group><subject>Light</subject><subj-group><subject>Visible light</subject><subj-group><subject>Luminance</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Probability distribution</subject><subj-group><subject>Skewness</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Visual system</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Reflection</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Image analysis</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Material and shape perception based on two types of intensity gradient information</article-title>
<alt-title alt-title-type="running-head">Material and shape perception based on two types of intensity gradient information</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-0725-3214</contrib-id>
<name name-style="western">
<surname>Sawayama</surname>
<given-names>Masataka</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Nishida</surname>
<given-names>Shin'ya</given-names>
</name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001"><addr-line>Human Information Science Laboratory, NTT Communication Science Laboratories, Nippon Telegraph and Telephone Corporation, Atsugi, Kanagawa, Japan</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Einhäuser</surname>
<given-names>Wolfgang</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Technische Universitat Chemnitz, GERMANY</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">masa.sawayama@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>27</day>
<month>4</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="collection">
<month>4</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>4</issue>
<elocation-id>e1006061</elocation-id>
<history>
<date date-type="received">
<day>17</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>27</day>
<month>2</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Sawayama, Nishida</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006061"/>
<abstract>
<p>Visual estimation of the material and shape of an object from a single image includes a hard ill-posed computational problem. However, in our daily life we feel we can estimate both reasonably well. The neural computation underlying this ability remains poorly understood. Here we propose that the human visual system uses different aspects of object images to separately estimate the contributions of the material and shape. Specifically, material perception relies mainly on the intensity gradient magnitude information, while shape perception relies mainly on the intensity gradient order information. A clue to this hypothesis was provided by the observation that luminance-histogram manipulation, which changes luminance gradient magnitudes but not the luminance-order map, effectively alters the material appearance but not the shape of an object. In agreement with this observation, we found that the simulated physical material changes do not significantly affect the intensity order information. A series of psychophysical experiments further indicate that human surface shape perception is robust against intensity manipulations provided they do not disturb the intensity order information. In addition, we show that the two types of gradient information can be utilized for the discrimination of albedo changes from highlights. These findings suggest that the visual system relies on these diagnostic image features to estimate physical properties in a distal world.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Objects in our visual world contain a variety of material information. Although such information enables us to experience rich material impressions, it can be a distraction for the estimation of other physical properties such as shapes, albedos, and illuminations. The coupled estimation of these properties we humans perform in daily situations is one of the fundamental mysteries in visual neuroscience. Here, we show that material and shape perception depend on two different types of intensity gradient information. Specifically, our image analyses and psychophysical experiments show that a human’s material perception relies mainly on the intensity gradient magnitude information, while shape perception relies mainly on the intensity gradient order information. In addition, we show that the intensity order information can be utilized for discriminating albedo changes on an object surface from other physical properties including specular highlights.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000646</institution-id>
<institution>Japan Society for the Promotion of Science London</institution>
</institution-wrap>
</funding-source>
<award-id>JP15H05915</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Nishida</surname>
<given-names>Shin'ya</given-names>
</name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by Grant-in-Aid for Scientific Research on Innovative Areas from Japan Society of Promotion of Science to SN (JSPS KAKENHI Grant Number JP15H05915)(<ext-link ext-link-type="uri" xlink:href="https://kaken.nii.ac.jp/en/grant/KAKENHI-PLANNED-15H05915/" xlink:type="simple">https://kaken.nii.ac.jp/en/grant/KAKENHI-PLANNED-15H05915/</ext-link>). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="24"/>
<table-count count="0"/>
<page-count count="40"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-05-22</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The physical parameters that affect a retinal image are extremely complex. In addition, the same retinal image can be produced from an infinite number of combinations of materials, shapes, and illuminations in the distal world. Therefore, it is a hard ill-posed problem to estimate what exists in the distal world from a single retinal image. This appears to be a chicken-and-egg problem as material estimation requires knowledge about shape (and illumination), while shape estimation requires knowledge about material (and illumination). Nevertheless, (we believe) we can estimate the physical parameters that produce a retinal image. For instance, from a single photograph wherein a metal teapot is placed on a table, we can simultaneously judge the material and shape of the object. This paper concerns the visual processing underlying such simultaneous estimation.</p>
<p>We found a clue for solving this problem in the image-based material editing methods developed in the computer graphics community [<xref ref-type="bibr" rid="pcbi.1006061.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref003">3</xref>]. By changing image parameters, not physical ones in the distal world, these methods can alter the material appearance of an object without significantly affecting its apparent shape or illumination. Among them, a simple yet effective method is to modulate the luminance histogram of an image. For instance, when the histogram of the original image in <xref ref-type="fig" rid="pcbi.1006061.g001">Fig 1(A)</xref> is matched with that of the reference image in <xref ref-type="fig" rid="pcbi.1006061.g001">Fig 1(B)</xref>, the material appearance of the original image becomes very similar to that of the reference image (<xref ref-type="fig" rid="pcbi.1006061.g001">Fig 1(C)</xref>). Another example is the use of monotonic nonlinear tone-remapping for print or screen display devices to transform the intensity histogram of an input image and modify its qualitative appearance [<xref ref-type="bibr" rid="pcbi.1006061.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006061.ref005">5</xref>].</p>
<fig id="pcbi.1006061.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g001</object-id>
<label>Fig 1</label>
<caption>
<title>A histogram-matching method.</title>
<p>The intensity histogram of the original image (a) is matched with that of the reference image (b) in the histogram-matched image (c). The geometric model of (a) is "Julius Caesar" designed by Yousef Mansy (<ext-link ext-link-type="uri" xlink:href="https://pinshape.com/items/25809-3d-printed-julius-caesar-scan-the-world" xlink:type="simple">https://pinshape.com/items/25809-3d-printed-julius-caesar-scan-the-world</ext-link>), and that of (b) is "Venus sculpture" designed by SHINING 3D (<ext-link ext-link-type="uri" xlink:href="https://pinshape.com/items/19446-3d-printed-venus-sculpture" xlink:type="simple">https://pinshape.com/items/19446-3d-printed-venus-sculpture</ext-link>). The cumulative probability densities of pixels of the original and reference image are shown in (d) and (e), respectively. (f) Pixel intensity of the histogram-matched image plotted as a function of that of the original image.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g001" xlink:type="simple"/>
</fig>
<p>Successful manipulation of material appearance by histogram transformation suggests that luminance histograms contain critical information for material perception [<xref ref-type="bibr" rid="pcbi.1006061.ref006">6</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref012">12</xref>]. Specifically, Motoyoshi et al. [<xref ref-type="bibr" rid="pcbi.1006061.ref008">8</xref>] found that a surface tends to look glossier when the luminance histogram of the surface’s image is positively skewed. Although histogram skewness can be affected by various image parameters, it can be a very good predictor of apparent gloss when the images are nearly the same in other respects, as is the case for histogram-transformed images. Motoyoshi et al. [<xref ref-type="bibr" rid="pcbi.1006061.ref008">8</xref>] also showed that adaptation to textures with skewed statistics alters the perceived glossiness of surfaces subsequently viewed. These findings led them to conclude that human observers may use histogram skewness, or some image features correlated with it, in making judgments about glossiness.</p>
<p>However, when the spatial structure of an image is inconsistent with a natural glossy surface (e.g., a pixel- or phase-scrambled image), the image does not look glossy regardless of histogram manipulation [<xref ref-type="bibr" rid="pcbi.1006061.ref008">8</xref>]. Kim, Marlow and Anderson [<xref ref-type="bibr" rid="pcbi.1006061.ref013">13</xref>] further investigated spatial conditions of gloss perception and found that when specular highlights of an object image are inconsistent in position and/or orientation with the diffuse shading component, they look more like white blobs produced by surface reflectance changes (see also, [<xref ref-type="bibr" rid="pcbi.1006061.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref017">17</xref>]). Marlow, Todorovic and Anderson [<xref ref-type="bibr" rid="pcbi.1006061.ref018">18</xref>] have demonstrated that three-dimensional shape perception of a surface affects gloss perception of the surface.</p>
<p>These findings suggest that the visual system has to simultaneously solve at least three mutually dependent problems: it has to estimate surface material, surface shape (surface orientation), and reflectance changes. As mentioned above, we believe that material editing by histogram manipulation suggests a clue to this complex computation. The histogram-matching method, as shown in <xref ref-type="fig" rid="pcbi.1006061.g001">Fig 1</xref>, successfully changes the material appearance of a surface image, while it seems to have a negligible effect on surface shape. This suggests that the image properties changed by the histogram transformation affect material processing, while those unchanged by the histogram transformation affect shape processing. In what follows, we will show which components in the image are changed and unchanged by histogram manipulation and then consider the effects of each component on the perception of material, shape and reflectance change. The analysis will lead us to a computational strategy the visual system may follow to simultaneously and nearly independently estimate material, shape and reflectance change from a single image of an object.</p>
<p>To anticipate the conclusion, we here propose that the human visual system may use orthogonal features about image intensity gradient to estimate material and shape: the intensity gradient magnitude for material perception, and the intensity gradient order for shape perception. We also suggest that the intensity order structure provides the critical information for discrimination of highlights from albedo changes [<xref ref-type="bibr" rid="pcbi.1006061.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref017">17</xref>]. The intensity gradient magnitude is related to the intensity histogram statistics, which some have suggested are related to material perception [<xref ref-type="bibr" rid="pcbi.1006061.ref008">8</xref>], while the intensity gradient order is related to the isophote and orientation flow that have been suggested to be important for robust shape estimations [<xref ref-type="bibr" rid="pcbi.1006061.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref027">27</xref>]. Combining thoughtful insights originating from past theories with new image analyses and psychophysical experiments, we attempt to comprehensively understand how the human visual system simultaneously estimates many interdependent object properties from a single picture.</p>
</sec>
<sec id="sec002" sec-type="results">
<title>Results</title>
<sec id="sec003">
<title>Image constraints for material changes</title>
<p>To explore image constraints for discriminating material changes from other property changes, we focused on a histogram-transformation method that has been widely used to edit the material appearance of a surface image [<xref ref-type="bibr" rid="pcbi.1006061.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006061.ref003">3</xref>,<xref ref-type="bibr" rid="pcbi.1006061.ref006">6</xref>]. In this method, to adjust the luminance histogram of an original image to that of a reference image, each histogram of the original and reference images is converted into a cumulative histogram (<xref ref-type="fig" rid="pcbi.1006061.g001">Fig 1(D) and 1(E)</xref>). Then, the bin values of the original histogram are transformed into those of the reference histogram so that each cumulative value of the original histogram is matched to that of the reference one. Consequently, histogram matching does not change the intensity order of the image. When the pixel intensity of the output image is plotted as a function of that of the original image (<xref ref-type="fig" rid="pcbi.1006061.g001">Fig 1F</xref>), the tone-remapping function monotonically increases, or at least does not decrease. Similar features are observed in general tone mapping techniques [<xref ref-type="bibr" rid="pcbi.1006061.ref005">5</xref>]. These observations suggest that retaining the intensity order of the original image may be the key feature for editing material while keeping other physical properties constant.</p>
<p>When we consider the image generation processing of an object image, there are good reasons to believe that retaining the intensity order information is critical for material editing. A (monochromatic) surface image can be decomposed into albedo, shading, and specular images (<xref ref-type="fig" rid="pcbi.1006061.g002">Fig 2A</xref>). The albedo image of a surface indicates how much illumination is diffusely reflected at each surface point. It is irrelevant to the surface normal and thus independent of the shading and specular images. The shading image of a surface is the interaction map of the surface normal and the illumination. With diffuse Lambertian shading, the shading intensity is a function of the incident angle of light. The specular component is the direct mirror-like reflection of the incident light. The specular intensity of a surface is a function of the incident and viewing angles of light.</p>
<fig id="pcbi.1006061.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g002</object-id>
<label>Fig 2</label>
<caption>
<title/>
<p>(a) The image is decomposed into its intrinsic components: albedo, shading, and specular images. Whereas the reflectance image is independent of the shading image, the specular image is dependent on the shading image. This is because the shading intensity is a function of the incident angle of light, while the specular intensity is a function of the incident and viewing angles of the light. (b) The intensities of the shading image within the highlight regions tend to be uniform because both specular and shading intensity depend on the incident angle of light. (c) Intensity gradient maps and the direction maps of the intensity gradient obtained from input images. The magnitude and direction of the vector are indicated as the hue and saturation of a color map, respectively.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g002" xlink:type="simple"/>
</fig>
<p>Since both specular and shading intensities depend on the incident angle of light, the specular image is dependent on the shading image. Under a collimated illumination, the surface normal directions of highlight regions are nearly uniform, and the intensity of the matte component behind the highlight regions is also nearly uniform (<xref ref-type="fig" rid="pcbi.1006061.g002">Fig 2B</xref>). If the highlight regions are uniformly painted with (or replaced by) the hidden matte intensity, the image becomes something akin to a matte surface image. Although the hidden matte intensity is not known, the specular highlights tend to be produced near the highest intensity of the diffuse shading, but the position could shift slightly depending upon the difference between the incident angle and viewing angle [<xref ref-type="bibr" rid="pcbi.1006061.ref024">24</xref>]. Because of these constraints, adding specular gloss on a matte image, unlike adding an albedo change, has relatively little effect on the intensity order of the image.</p>
<p>If the luminance order structure is the same, so is the isophote structure (an isophote is a contour of equal intensity in an image). The direction of the luminance gradient is orthogonal to the isophote. Hence, if the intensity order information of an image is kept constant, the direction of the intensity gradient is too. <xref ref-type="fig" rid="pcbi.1006061.g002">Fig 2C</xref> shows how adding gloss affects the intensity gradient structures. To make an intensity gradient map, we computed the horizontal and vertical derivatives of the intensity distribution, and then converted them to the polar coordinate. In <xref ref-type="fig" rid="pcbi.1006061.g002">Fig 2C</xref>, the magnitude and direction of the intensity gradient vector are indicated by the hue and saturation of a color map, respectively. The intensity gradient map shows that highlight regions have larger gradient magnitudes, which implies that adding specular highlights drastically changes the gradient magnitudes. However, when the gradient magnitudes are normalized and only the directional information of intensity gradients is preserved, the map of the gloss image is similar to that of the matte image. The results suggest that adding gloss to a matte image has a negligible effect on the direction map of the intensity gradient.</p>
</sec>
<sec id="sec004">
<title>Image analysis</title>
<p>To test the generality of the observations, we analyzed material images rendered using the MERL BRDF (Bidirectional Reflectance Distribution Function) database [<xref ref-type="bibr" rid="pcbi.1006061.ref028">28</xref>], which is a set of measured BRDFs of 100 materials, including rubber, plastic, metal, and fabric. There were four illumination conditions: three single point light sources (slant = 0, 20, and 40 degrees) and one HDR (High Dynamic Range) environment map (<xref ref-type="fig" rid="pcbi.1006061.g003">Fig 3</xref>). <xref ref-type="fig" rid="pcbi.1006061.g004">Fig 4A</xref> shows the results of the analysis. Each cell of the panels indicates the correlation coefficient of the magnitude or the direction map of the intensity gradient between the images rendered with the BRDFs of the row and the column. When the point light source lit the objects from the viewing direction, the direction of the intensity gradient consistently showed quite a high correlation (<xref ref-type="fig" rid="pcbi.1006061.g004">Fig 4(B)</xref>, upper), whereas the magnitude of the intensity gradient showed correlations that are relatively low and highly variable depending on the comparison pair (<xref ref-type="fig" rid="pcbi.1006061.g004">Fig 4(B)</xref>, bottom). These findings can be confirmed from the probability density distribution of the correlation coefficients in <xref ref-type="fig" rid="pcbi.1006061.g004">Fig 4(B)</xref>.</p>
<fig id="pcbi.1006061.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Stimulus examples used in the image analysis.</title>
<p>The bumpy surfaces were rendered using the BRDFs in the MERL database (100 BRDFs). The left panel shows the images rendered under a point light source with a slant of 0°, and the right panel shows the images rendered under an HDR environment map. Each panel includes 100 images rendered with different BRDFs. The same geometry is used for the rendered images in the left and right panels. From each rendered image, the direction and the magnitude maps of the intensity gradient were computed.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g003" xlink:type="simple"/>
</fig>
<fig id="pcbi.1006061.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Probably density distributions of correlation coefficients between all pairs of BRDFs.</title>
<p>(a) The left and right panels show the correlation coefficients on the direction and the magnitude of the intensity gradient of the rendered image, respectively. For the direction condition, the circular correlation was used [<xref ref-type="bibr" rid="pcbi.1006061.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref030">30</xref>]. Each cell of the panels indicates the correlation coefficient between the BRDFs of rows and columns. The numbers from #1 to #100 indicate the index of MERL BRDFs. (b) The probability density distribution of the correlation coefficients. The top panel indicates the correlation of the direction of the intensity gradient. The bottom panel indicates the correlation of the magnitude of the intensity gradient. When the point light source lit the objects from the viewing direction, the direction of the intensity gradient consistently shows quite a high correlation, whereas the magnitude of the intensity gradient shows correlations that are relatively low and highly variable depending on the comparison pair.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g004" xlink:type="simple"/>
</fig>
<p>When the incident angle of the light deviates from the viewing angle, the position of specular highlights tends to shift from the position of the highest intensity of the diffuse shading [<xref ref-type="bibr" rid="pcbi.1006061.ref024">24</xref>]. However, the displacements of the lighting direction do not significantly change the pattern of results (<xref ref-type="fig" rid="pcbi.1006061.g005">Fig 5(A) and 5(B)</xref>). The analysis of the surface images rendered under point light sources suggests that material changes (with no changes in shape and illumination) have little effect on the direction of the intensity gradient.</p>
<fig id="pcbi.1006061.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g005</object-id>
<label>Fig 5</label>
<caption>
<title/>
<p>Probability density distributions under the lighting conditions of (a) 20° and (b) 40°. The displacements of the lighting direction do not significantly change the pattern of the correlation distributions.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g005" xlink:type="simple"/>
</fig>
<p>Under the HDR illumination environment, the correlation in the direction of the intensity gradient is reduced for some material combinations (<xref ref-type="fig" rid="pcbi.1006061.g006">Fig 6(A)</xref>). This is because the direction of the intensity gradient is disturbed by the spatially complex illumination that produces spatially non-uniform mirror reflections, especially when the BRDF has low specular roughness. Since we computed the intensity gradient on a small scale (the kernel size was 5 x 5 pix for an image size of 256 x 256 pix), the fine structures of a mirror reflection of the environment affect the direction of the intensity gradient. However, a simple tone operation can reduce the effect of a mirror reflection of the environment. While tone remappings normally change the intensity histogram without changing the intensity order, strong compressive tone remappings in which the output intensity levels off beyond a certain input intensity can remove the intensity gradients in the high intensity range. Since the mirror reflection generally has higher intensities than those of the shading pattern, a strong compressive tone mapping can eliminate the variation caused by the spatially non-uniform mirror reflection. In one analysis (<xref ref-type="fig" rid="pcbi.1006061.g006">Fig 6(B)</xref>), when the magnitude became smaller than a very small threshold value, we excluded the gradient values from computation of gradient directions. The analysis showed that the correlation in the direction of the intensity gradient is markedly improved.</p>
<fig id="pcbi.1006061.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g006</object-id>
<label>Fig 6</label>
<caption>
<title/>
<p>(a) Probability density distributions in the HDR environment map. The correlation in the direction of the intensity gradient is reduced for some material combinations. (b) The correlation of the image in the HDR environment map was calculated after applying the compressive tone-mapping of Eq (<xref ref-type="disp-formula" rid="pcbi.1006061.e001">1</xref>) to the surface image. As a consequence, the correlation in the direction of the intensity gradient is markedly improved.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g006" xlink:type="simple"/>
</fig>
<p>In addition, it should be noted that the strong correlations in the direction of the intensity gradient across different materials can be obtained only under similar illumination conditions. When we compute the correlation across different illuminations, e.g., between the lighting conditions of 0° and 40°, the direction information of the intensity gradient is markedly different (<xref ref-type="fig" rid="pcbi.1006061.g007">Fig 7</xref>).</p>
<fig id="pcbi.1006061.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Probability density distributions of the correlation between the lighting conditions of 0° and 40°.</title>
<p>The correlations in the direction of the intensity gradient are much lower compared with those under the identical illumination environment condition (Figs <xref ref-type="fig" rid="pcbi.1006061.g004">4</xref>–<xref ref-type="fig" rid="pcbi.1006061.g006">6</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g007" xlink:type="simple"/>
</fig>
<p>The present analysis suggests that the material change of a surface strongly modulates the magnitude of the intensity gradient but does not unduly disrupt the intensity order or the direction of the intensity gradient. This explains why the histogram-matching method, which affects the magnitude of the intensity gradient while preserving intensity order, effectively changes the material appearance.</p>
<p>At the same time, our analysis suggests that the intensity order of an object image contains rich information about the surface shape and reflectance pattern. In the context of computer vision, intensity order information is widely utilized as a feature descriptor [<xref ref-type="bibr" rid="pcbi.1006061.ref031">31</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref034">34</xref>]. For instance, Dalal and Triggs [<xref ref-type="bibr" rid="pcbi.1006061.ref031">31</xref>] utilized the local histograms of image gradient orientation (called histograms of oriented gradient, or HOG). They showed that the descriptor is robust against environmental changes. In addition, shape-from-shading studies suggest that the intensity order information or the directional information of the intensity gradient is useful for shape estimation [<xref ref-type="bibr" rid="pcbi.1006061.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref027">27</xref>].</p>
<p><xref ref-type="fig" rid="pcbi.1006061.g008">Fig 8</xref> shows a hypothetical processing scheme that the human visual system may use for simultaneous estimation of a variety of surface properties. The critical idea is that an input surface image is analyzed in two ways. One focuses on the information about the order of intensity. It could be in the form of isophote, gradient direction map, or orientation map. Shape processing mainly relies on this intensity order information. The other image analysis focuses on the information about the magnitude of the intensity gradient. Material processing mainly relies on this gradient magnitude information. To be precise, the important information for material estimation is likely to be the intensity gradient relative to the surface orientation change [<xref ref-type="bibr" rid="pcbi.1006061.ref018">18</xref>], but we assume this is computed in subsequent stages. The estimation of the remaining properties, i.e., surface albedo and illumination, relies both on the intensity order and gradient information, along with the absolute intensity level. According to this hypothesis, one can tell whether a bright spot is produced by an albedo change or by a specular highlight by checking how it affects the intensity order information.</p>
<fig id="pcbi.1006061.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g008</object-id>
<label>Fig 8</label>
<caption>
<title>A hypothetical processing scheme that the human visual system may use for simultaneous estimation of a variety of surface properties.</title>
<p>We hypothesize that human shape processing is more sensitive to image features given by the intensity order information than those conveyed by the gradient magnitude information, while the magnitude information is dominantly used for material processing.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g008" xlink:type="simple"/>
</fig>
<p>While previous studies have suggested that luminance histogram manipulation is an effective way to change material appearance [<xref ref-type="bibr" rid="pcbi.1006061.ref008">8</xref>], as well as pointing out the importance of orientation field or isophote map in shape perception [<xref ref-type="bibr" rid="pcbi.1006061.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref027">27</xref>], to our knowledge, one potential implication of these findings has not been recognized. That is, material perception and shape perception may be based on separate, independent, orthogonal features of the object image, and this is why the visual system can simultaneously estimate material and shape. Although visual estimation of the material and shape appears to include a hard chicken-and-egg problem (material estimation requires shape information, while shape estimation requires material information), the brain may be able to solve it by computing the two attributes, at least initially, based on the independently measurable image features.</p>
<p>Although our hypothesis includes an explanation as to how the visual system robustly estimates the shape for some materials, it does not cover every kind of material. This is because our basic intuition came from a critical observation that luminance histogram matching affects apparent material, but not shape. While luminance histogram matching realized by monotonic luminance re-mapping can produce a wide range of matte and glossy objects, it cannot easily make mirrored objects with a perfectly specular reflectance. Hence, we do not have a strong theoretical basis to assume that our theory is applicable to mirrored objects. Textured objects and line drawings are also outside our scope. Compared to the “orientation field” theory proposed by [<xref ref-type="bibr" rid="pcbi.1006061.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref025">25</xref>], we consider a more specific problem of monocular shape perception (see <xref ref-type="sec" rid="sec015">Discussion</xref> for details).</p>
<p>In the five psychophysical experiments reported below, we empirically tested our hypothesis. The first three experiments measured the apparent shape (surface orientation) of object images to see whether it is affected by the intensity order information but not by the intensity gradient magnitude information. Experiment 1 changed the intensity distribution by means of histogram matching that preserved the intensity order information. Experiment 2 changed the intensity distribution by means of non-linear intensity remapping that disrupted the intensity order information under some conditions. Experiment 3 disrupted the intensity order information more naturally by using velvet-like surface reflectance. The last two experiments examined apparent surface gloss and reflectance uniformity to ascertain whether they are affected by the intensity gradient magnitude information but not by the intensity order information. By using objects with veridical and inconsistent highlights, we considered how the two types of intensity information are used to discriminate material features from reflectance changes. Experiment 4 changed the intensity distribution by means of histogram matching, while Experiment 5 changed it by means of compressive remapping.</p>
</sec>
<sec id="sec005">
<title>Perception of shapes</title>
<sec id="sec006">
<title>Experiment 1</title>
<p>The first experiment examined how modulating the intensity distribution of the object images affects its shape appearance. We used a histogram matching method, which affects the intensity gradient magnitude information but not the intensity order information. The object had diffuse reflection or specular reflection producing veridical highlights. The skewness of the intensity histogram of these object images was modulated by using the histogram matching method (<xref ref-type="fig" rid="pcbi.1006061.g009">Fig 9</xref>). We measured the perceived shape using a “gauge probe” task [<xref ref-type="bibr" rid="pcbi.1006061.ref035">35</xref>]. For comparison, we also measured the perceived glossiness in a rating task.</p>
<fig id="pcbi.1006061.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Stimuli used in Experiment 1.</title>
<p>The skewness of the intensity histogram of each object image with highlights was modulated using a standard histogram matching method.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g009" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec007">
<title>Glossiness judgment</title>
<p><xref ref-type="fig" rid="pcbi.1006061.g010">Fig 10(A)</xref> shows the results of the glossiness ratings for the object images, plotted as a function of the skewness of the intensity histogram of the object images. Each symbol indicates the rating values averaged across different observers. Error bars denote ± 1 SEM across observers.</p>
<fig id="pcbi.1006061.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Results of Experiment 1.</title>
<p>(a) Rating results for the glossiness judgment plotted as a function of the skewness of the intensity histogram. Error bars indicate ± 1 SEM across observers. (b) The perceived tilt (left) or slant (right) for the histogram-modulated object plotted as a function of those for each original object. Different symbols indicate different skew parameters as shown in the legend.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g010" xlink:type="simple"/>
</fig>
<p>Results show that the perceived glossiness changed with the skewness of the object images. Specifically, when the intensity histogram of the object image was negatively skewed, the image did not look glossy at all. In contrast, when the intensity histogram of the object image was positively skewed, the image looked glossy. The effects of histogram skewness on gloss perception are consistent with the findings of Motoyoshi et al. [<xref ref-type="bibr" rid="pcbi.1006061.ref008">8</xref>].</p>
</sec>
<sec id="sec008">
<title>Shape estimation</title>
<p><xref ref-type="fig" rid="pcbi.1006061.g010">Fig 10(B)</xref> shows the results of the effects of histogram manipulations on surface shape perception by scatter plots between the perceived shapes of the histogram-modulated objects and those of the original objects. For each observer, each gauge position, and each stimulus condition, we averaged the perceived tilt or slant of the gauge probe across trials. The perceived tilt (left) or slant (right) of the histogram-modulated object is plotted against that for the original object in <xref ref-type="fig" rid="pcbi.1006061.g010">Fig 10(B)</xref>. In the figure, different color symbols indicate different skew parameters. The results show high correlations between the perceived shapes of the histogram-modulated and original objects, regardless of the histogram skewness. That is, the perceived shape of an object image was barely affected by the intensity histogram as long as the intensity order was not disrupted, in agreement with the idea that human shape processing is sensitive to intensity order information but not sensitive to intensity gradient magnitude information. The results are consistent with the previous finding showing that adding specular highlights to a matte object does not change the perceived shape [<xref ref-type="bibr" rid="pcbi.1006061.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref037">37</xref>].</p>
</sec>
<sec id="sec009">
<title>Experiment 2a</title>
<p>Experiment 1 showed that holding intensity order information did not change the perceived shape. In Experiment 2a, we investigated what happens to shape perception when the intensity order of an object image is disrupted (<xref ref-type="fig" rid="pcbi.1006061.g011">Fig 11</xref>). In the experiment, while applying a variety of non-linear remappings on several object images, we estimated the perceived shape of the objects by asking observers to set a gauge probe to match the apparent surface slant/tilt. Specifically, linear tone curves having several slopes (0.5, 1, and 2) were modulated by a sinusoidal modulation of four different amplitudes. When the slope was steep, the intensity order of the original image was not disrupted by the modulation regardless of its amplitude. In contrast, when the slope was gentle, the intensity order was disrupted by the modulation unless the modulation amplitude was small.</p>
<fig id="pcbi.1006061.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Stimuli used in Experiment 2a.</title>
<p>(a) We applied a variety of monotonic and nonmonotonic nonlinear remappings to several object images. When the slope was steep (right), the intensity order of the original image was not disrupted by the modulation regardless of its amplitude. In contrast, when the slope was gentle (left), the intensity order was disrupted by the modulation unless the modulation amplitude was small. When the intensity order of the original image was disrupted (left bottom), the shape of the image was perceived differently from the original one (middle bottom). (b) The three object images used in Experiment 2. The gauge probes on the image show the position measured in the experiment.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g011" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1006061.g012">Fig 12</xref> shows the results of the experiment. The angular differences in the tone-mapped images from the original image are plotted as a function of the amplitude of the sinusoidal modulations. For each stimulus condition, the angular difference was calculated for each gauge probe within each observer, and the nine angular differences were averaged across the gauge probes. Then, the mean angular differences were averaged across observers. Error bars indicate 95% confidence intervals computed using bootstrap estimates. The solid horizontal line shows the angular difference for the same original object measured in different sessions (i.e., the control condition). Magenta (dashed) horizontal lines indicate 95% confidence intervals of the control condition computed using bootstrap estimates.</p>
<fig id="pcbi.1006061.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Results of Experiment 2a.</title>
<p>The angular difference between the judgments on tone-mapped and original images is plotted as a function of the amplitude of the sinusoidal modulation. Error bars indicate 95% confidence intervals computed using bootstrap estimates. Different symbols indicate different slopes as indicated in the legend. The orange (solid) horizontal line shows the mean angular difference of matched gauges for the same original object measured in different sessions (i.e., the control condition). Magenta (dashed) horizontal lines indicate 95% confidence intervals of the control condition computed using bootstrap estimates. For slope 1, the intensity order of the original image was disrupted when the sinusoidal modulation was 0.115 or 0.165. For slope 0.5, the intensity order was disrupted when the sinusoidal modulation was 0.065, 0.115 or 0.165. For slope 2, the modulations did not change the intensity order. Results show that the large deviations of the perceived shape were obtained when the intensity order of the original image was markedly disrupted.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g012" xlink:type="simple"/>
</fig>
<p>Results show that the perceived shape of the tone-remapped images was similar to that of the original images unless their intensity order was disrupted. Specifically, when the slope of the linear tone curve was gentle (0.5), the perceived shape of the tone-remapping images was markedly different from that of the original image even when the modulation amplitude was small (i.e., <italic>a</italic><sub><italic>1</italic></sub> = 0.065). In contrast, when the slope was steep (2), the perceived shape of the tone-remapped images was not affected by the addition of the modulation. The modulation effects were slightly different across the three object images, but the order of the effects was consistent. The findings suggest that the disruption of the intensity order information affects the perceived shape.</p>
</sec>
<sec id="sec010">
<title>Experiment 2b</title>
<p>In Experiments 1 and 2a we used the object images under a point light source placed in the same direction as the viewing direction (i.e., illumination slant = 0°). We additionally conducted Experiment 2b to see whether the effect of the intensity order is affected by the illumination direction. We applied a variety of non-linear remappings, as in Experiment 2a, on an object image (Object 4) rendered under a point light source placed in the front direction (illumination slant = 0°) or in the upper-right direction to the object (illumination slant = 45°) (<xref ref-type="fig" rid="pcbi.1006061.g013">Fig 13</xref>). For both illumination conditions, the intensity order of the original image was disrupted by the amplitude modulation when the slope of the remapping was gentle (i.e., slope = 0.5), but not when the slope was steep (i.e., slope = 2). As before, we asked observers to set a gauge probe to match the apparent surface slant/tilt.</p>
<fig id="pcbi.1006061.g013" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Stimuli used in Experiment 2b.</title>
<p>We applied a variety of monotonic and nonmonotonic remappings to the object images under the lighting conditions of slant 0° (left) and slant 45° (right). When the slope of the remapping was steep (i.e., slope = 2), the intensity order of the original image was not disrupted by the amplitude modulation (0.165) as in Experiment 2. In contrast, when the slope was gentle (i.e., slope = 0.5), the intensity order was disrupted by the modulation. Object 4 was used in the experiment. The six gauge probes as shown in the gauge position figures were used.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g013" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1006061.g014">Fig 14</xref> shows the results of the experiment. The angular differences in the tone-mapped images from the original image are plotted as a function of the amplitude of the sinusoidal modulations. The way in which each angular difference was averaged was the same as in Experiment 2a (<xref ref-type="fig" rid="pcbi.1006061.g012">Fig 12</xref>). Results were similar to those of Experiment 2a for both illumination conditions. Specifically, when the slope of the linear tone curve was gentle (0.5), the perceived shape of the tone-remapping images was markedly different from that of the original image due to the addition of the amplitude modulation. In contrast, when the slope was steep (2), the perceived shape of the tone-remapped images was not affected by the addition of the modulation. Again, the findings are consistent with the notion that the intensity order information is critical to how the shape is perceived. In addition, it is noteworthy that the mean angular difference across observers between the judgments of original images with different illuminations (0° and 45°) was 0.25 (95% confidence interval: 0.21–0.31). This small difference in value is comparable to those under the order-retained conditions, although the intensity order information across different illuminations is markedly different. The finding suggests that the visual system is adept at discounting the influence of the illumination field in recovery of the perceived shape from the intensity order information.</p>
<fig id="pcbi.1006061.g014" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g014</object-id>
<label>Fig 14</label>
<caption>
<title>Results of Experiment 2b.</title>
<p>The angular difference between the judgments on tone-mapped and original images is plotted as a function of the amplitude of the sinusoidal modulation. Error bars indicate 95% confidence intervals computed using bootstrap estimates. Different symbols indicate different slopes as indicated in the legend of <xref ref-type="fig" rid="pcbi.1006061.g012">Fig 12</xref>. For both illumination conditions, results show that large deviations in the perceived shape were obtained when amplitude modulation was added to the remapping with a slope 0.5, i.e., when the intensity order of the original image was disrupted.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g014" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec011">
<title>Experiment 3</title>
<p>While the Experiments 2a &amp; 2b showed that disrupting the order of the intensity gradient altered apparent shape, our stimulus manipulation was somewhat unnatural. If a similar disruption of intensity order is produced naturally, different results might be obtained. Although most BRDFs in the MERL database do not affect the intensity order information (<xref ref-type="fig" rid="pcbi.1006061.g004">Fig 4</xref>), some materials do; velvet is one example. To elucidate the effect of a change in material that alters intensity order information, we compared the perceived shape between velvet and Lambertian materials. As the reflectance model of velvet materials, we used the asperity scattering BRDF model [<xref ref-type="bibr" rid="pcbi.1006061.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref039">39</xref>]. For the asperity model, two values of the asperity parameter <italic>a</italic> (<italic>a</italic> = 0.2 or 0.02) were used (Figs <xref ref-type="fig" rid="pcbi.1006061.g015">15</xref> and <xref ref-type="fig" rid="pcbi.1006061.g016">16</xref>). When <italic>a</italic> is moderately small (0.2), the intensity order is preserved in the lower range of Lambertian pixel intensity, while it is reversed in the higher range. When <italic>a</italic> is even smaller (0.02), the intensity order is reversed across most of the intensity range. In addition to a Lambertian object and two asperity objects, we used an object the intensity of which was completely reversed from the Lambertian object (<xref ref-type="fig" rid="pcbi.1006061.g016">Fig 16</xref>). In the experiment, we measured the perceived shape in a gauge probe task.</p>
<fig id="pcbi.1006061.g015" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g015</object-id>
<label>Fig 15</label>
<caption>
<title>Relation between pixel intensities of Lambertian and asperity surfaces.</title>
<p>We assume that the incident and reflected angles of the illumination are the same. Each plot of the L<sub>A</sub> is scaled from 0 to the max intensity of the L<sub>l</sub>. The intensity order of each plot changes with parameter <italic>a</italic>. For instance, when parameter <italic>a</italic> is 0.2, the intensity order is preserved in the lower range of Lambertian pixel intensity, while it is reversed in the higher range. When <italic>a</italic> is 0.02, the intensity order is reversed across most of the intensity range.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g015" xlink:type="simple"/>
</fig>
<fig id="pcbi.1006061.g016" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g016</object-id>
<label>Fig 16</label>
<caption>
<title>Stimulus examples used in Experiment 4.</title>
<p>Upper images indicate the experimental stimuli with different BRDFs as in the legend. Lower images indicate the directional map of each image.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g016" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1006061.g017">Fig 17(A)</xref> shows a scatter plot of the shape estimations between the normal and reversed Lambertian objects. The correlation coefficients for tilt and slant were .92 and .80, respectively. These high correlations indicate that intensity reversal of the whole image has a negligible effect on shape perception from shading, suggesting that intensity order information relevant to shape perception is not sensitive to the direction of order.</p>
<fig id="pcbi.1006061.g017" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g017</object-id>
<label>Fig 17</label>
<caption>
<title>Results of Experiment 3.</title>
<p>(a) The scatter plots of the perceived surface orientation between the normal and reversed Lambertian conditions. Left and right panels show the results for the tilt and slant, respectively. Each plot indicates the averaged judgment across trials within each observer for each gauge position. The circular correlation [<xref ref-type="bibr" rid="pcbi.1006061.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref030">30</xref>] and Pearson’s correlation coefficients are shown in the tilt and slant panels, respectively. (b) The gauge positions in the stimulus. Red colors in each figure show the positions where the direction of the intensity gradient on the stimulus condition was the same as that on the Lambertian object. Green in each figure shows the positions where the direction of the intensity gradient on the stimulus condition was opposite to that on the Lambertian object. (c) The angular difference between the judgments on the two asperity conditions and the Lambertian condition. The horizontal axis indicates the gauge number, which is shown in the <xref ref-type="fig" rid="pcbi.1006061.g017">Fig 17(B)</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g017" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1006061.g017">Fig 17(C)</xref> indicates the angular difference of an asperity condition (left panel: <italic>a</italic> = 0.2, right panel: <italic>a</italic> = 0.02) from the Lambertian condition at nine gauge locations. For comparison, the angular differences of the reversed Lambertian condition are shown in the same format. When the intensity order of the asperity object was almost totally reversed (a = 0.02, <xref ref-type="fig" rid="pcbi.1006061.g017">Fig 17(C)</xref>, right), the angular differences were as small as those for the reversed Lambertian condition. In contrast, when the intensity order of the asperity object was partially reversed (a = 0.2, <xref ref-type="fig" rid="pcbi.1006061.g017">Fig 17(C)</xref>, right), the angular differences were higher than those for the reversed Lambertian condition. In particular, when the gauge was placed on the border where the intensity order of the asperity object changed between consistent (red in <xref ref-type="fig" rid="pcbi.1006061.g017">Fig 17(B)</xref>] and inconsistent (green in <xref ref-type="fig" rid="pcbi.1006061.g017">Fig 17(B)</xref>) with that of the Lambertian object, the angular difference was increased. We conducted a two-way repeated-measures ANOVA with the gauge location and the BRDF condition (two asperity materials and reversed Lambertian) as the within-subject variables. The two main effects and the interaction between the two variables were statistically significant (F(8,72) = 6.238, p &lt; .0001; F(2,18) = 9.077, p = .0019; and F(16,144) = 2.381, p = .0035, respectively). The post-hoc analysis showed that the angular difference for the asperity (a = 0.2) object was statistically higher than that for the reversed Lambertian object (p = .0352, Bonferroni-corrected), while the angular difference for the asperity (a = 0.02) object was not (p = .1871, Bonferroni-corrected). These findings suggest that human shape perception is affected by local intensity order distortion of an object image even when the distortion is produced by a natural material, while it is tolerant to global intensity order reversal and relatively insensitive to intensity gradient magnitude.</p>
<p>In addition, to see the dependency of the illumination direction as in Experiment 2b, we additionally conducted a shape estimation experiment for a different illumination direction. When the illumination direction changes and is different from the viewing direction, the remapping constraint shown in <xref ref-type="fig" rid="pcbi.1006061.g015">Fig 15</xref> is not satisfied. For that condition, the intensity order of the asperity scattering is always slightly different from that of the Lambertian image (<xref ref-type="fig" rid="pcbi.1006061.g018">Fig 18(A)</xref>). However, approximately speaking, when parameter <italic>a</italic> of the asperity scattering is relatively small (0.02), most of the intensity order in an image tends to be reversed. Results of the shape estimation experiment show that for the small <italic>a</italic> condition (<italic>a</italic> = 0.02, <xref ref-type="fig" rid="pcbi.1006061.g018">Fig 18(B)</xref>), the angular differences were as small as those for the reversed Lambertian condition. In contrast, when the asperity parameter is large (<italic>a</italic> = 0.2, <xref ref-type="fig" rid="pcbi.1006061.g018">Fig 18B</xref>), the angular differences were higher than those for the reversed Lambertian condition. We conducted a two-way repeated-measures ANOVA with the gauge location and the BRDF condition as the within-subject variables. The two main effects and the interaction between the two variables were statistically significant (F(8,72) = 2.654, p &lt; .0131; F(2,18) = 8.169, p = .003; and F(16,144) = 1.743, p = .0449, respectively). The post-hoc analysis showed that the angular difference for the asperity (a = 0.2) object was statistically higher than that for the reversed Lambertian object (p = .0338, Bonferroni-corrected), while the angular difference for the asperity (a = 0.02) object was not (p = .3049, Bonferroni-corrected).</p>
<fig id="pcbi.1006061.g018" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g018</object-id>
<label>Fig 18</label>
<caption>
<title>Stimuli and results of the additional experiment of Experiment 3.</title>
<p>(a) The same stimulus set as Experiment 3 under a different lighting condition (illumination slant = 45) is used in the experiment. The directional distortion of intensity gradients from the Lambertian object image is shown in the bottom of each stimulus on the red-green axis. (b) The angular difference between the judgments on the two asperity conditions and the Lambertian condition. The horizontal axis indicates the gauge number.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g018" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec012">
<title>Perception of materials and reflectance changes</title>
<p>In the previous section, we showed that perceived shape is sensitive to the intensity order information but not to the intensity gradient magnitude information. In this section, we will consider the perception of materials and surface reflectance properties.</p>
<p>Although we have seen effective modulations of perceived material by changing the intensity gradient magnitude information with no change in the intensity order information, it is hard for the visual system to estimate material only from the intensity gradient magnitude information. This is not only because of the effects of surface shape on material perception [<xref ref-type="bibr" rid="pcbi.1006061.ref018">18</xref>] but also because albedo/reflectance changes on the surface of the object affect the intensity gradient magnitude information. For example, a white patch with a steep intensity gradient on the object surface could be either a specular highlight or white paint. To distinguish between them, the visual system can use the intensity order information, since the addition of a reflectance change does, while that of a highlight does not, make the intensity order map significantly different from that of the shading pattern of an object with diffuse uniform reflectance.</p>
<p>When a highlight is located and/or oriented in a manner inconsistent with the shading pattern, it is perceived as an albedo change (e.g., white blob) and does not make the pattern look glossy [<xref ref-type="bibr" rid="pcbi.1006061.ref014">14</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref017">17</xref>]. While past studies proposed congruence in brightness and orientation as conditions for highlight consistency, we additionally suggest that if a white patch is a specular highlight, it does not disrupt the luminance order of the shading pattern. This means that when reducing the bright patch intensity by histogram matching to a less skewed intensity distribution or by applying a compressive tone remapping, one can smoothly erase the highlight and obtain a diffuse surface image. This should not happen if a white patch is an albedo change, since an albedo change disrupts the luminance order map. It should remain visible regardless of how the intensity gradient magnitude information is altered by the manipulation of the intensity distribution. If this hypothesis is correct, our predictions are as follows: For consistent highlights, apparent glossiness is reduced for negative skew or by compressive tone mapping, and the uniformity rating is always low. For inconsistent highlights, apparent glossiness is always low, and the uniformity rating is always high. These predictions were tested in the following two psychophysical experiments.</p>
<sec id="sec013">
<title>Experiment 4</title>
<p>In Experiment 4, to elucidate the relation between material and albedo changes of an object image, we used histogram matching to change the skewness of the intensity distribution of such object images that had either veridical or inconsistent highlights (<xref ref-type="fig" rid="pcbi.1006061.g019">Fig 19</xref>). We measured the perceived material (glossiness) and perceived albedo (reflectance non-uniformity) using rating tasks.</p>
<fig id="pcbi.1006061.g019" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g019</object-id>
<label>Fig 19</label>
<caption>
<title>Stimuli used in Experiment 4.</title>
<p>An object with inconsistent highlights was made by combining the diffuse pattern with the rotated and displaced specular pattern (bottom). The skewness of the intensity histogram of the object image was modulated using a standard histogram matching method. The glossy objects with veridical highlights are also shown (upper). They are the same stimuli as used in Experiment 1 (<xref ref-type="fig" rid="pcbi.1006061.g009">Fig 9</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g019" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1006061.g020">Fig 20</xref> shows the glossiness and non-uniformity ratings, respectively, which are plotted as a function of the skewness of the intensity histogram of the object images. Each symbol indicates the averaged rating values across different observers. Different symbols denote the results under different stimulus conditions as shown in the legend. Error bars denote ± 1 SEM across observers. The glossiness ratings for the object with veridical highlights are those obtained in Experiment 1 (<xref ref-type="fig" rid="pcbi.1006061.g010">Fig 10(A)</xref>).</p>
<fig id="pcbi.1006061.g020" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g020</object-id>
<label>Fig 20</label>
<caption>
<title>Results of Experiment 4.</title>
<p>(a) Ratings for the glossiness judgment and (b) for the non-uniformity judgment are plotted as a function of the skewness of the intensity histogram. Stimulus conditions are shown as in the legend. Error bars indicate ± 1 SEM across observers. The ratings for the object with veridical highlights in Experiment 1 (<xref ref-type="fig" rid="pcbi.1006061.g010">Fig 10(A)</xref>) are plotted again in the glossiness judgment (red).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g020" xlink:type="simple"/>
</fig>
<p>The glossiness rating shows that the objects with inconsistent highlights were perceived to be less glossy than those with veridical highlights (the same data as in <xref ref-type="fig" rid="pcbi.1006061.g010">Fig 10</xref>) when the luminance distribution was positively skewed. A two-way repeated-measures ANOVA with the highlight condition (veridical or inconsistent) and skewness condition (-1.1, 0, 1.1) as the within-subject variables showed that the main effect of the skewness condition and the interaction were statistically significant (F(1,7) = 34.210, p &lt; .0001; and F(2,14) = 13.116, p = .0006, respectively), while the main effect of the highlight condition was not (F(1,7) = 0.873, p = .381). The post hoc analysis of the interaction showed that the simple main effect of the highlight condition was statistically significant for the skewness of 1.1 (F(1,7) = 8.768, p = .021). The results are consistent with previous findings [<xref ref-type="bibr" rid="pcbi.1006061.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref015">15</xref>].</p>
<p>The non-uniformity rating shows that the objects with inconsistent highlights were judged to be less uniform than those with veridical highlights. This was the case regardless of the histogram manipulation of the image, while there was a weak trend where the non-uniformity increased with increasing skewness. We conducted a two-way repeated-measures ANOVA with the highlight condition (veridical or inconsistent) and skewness condition (-1.1, 0, 1.1) as the within-subject variables. The main effect of the highlight condition was statistically significant (F(1,7) = 11.297, p = .012), while the main effect of the skewness condition and the interaction were not (F(2,14) = 2.444, p = .123; and F(2,14) = 0.530, p = .600, respectively). The results suggest that the inconsistent highlights are more likely to be judged as reflectance changes than the veridical highlights, and this tendency is robustly observed even when histogram manipulation changes the intensity gradient magnitude information while keeping the intensity order information. In summary, the histogram manipulation of an object image affected the perceived glossiness but did not affect the perceived albedo. This finding suggests that the intensity order information of an object image is useful to separate highlights from albedo changes within the object.</p>
</sec>
<sec id="sec014">
<title>Experiment 5</title>
<p>In Experiment 4, we used simple objects under a point light source. To confirm the generality of the finding, Experiment 5 investigated the effect of luminance histograms on the perception of gloss and reflectance uniformity using more complex objects under a point light source or an HDR environment light field (<xref ref-type="fig" rid="pcbi.1006061.g021">Fig 21</xref>). To modulate the image intensity distribution, we used compressive tone remapping as we did when analyzing the MERL objects under the HDR illumination environment (<xref ref-type="fig" rid="pcbi.1006061.g006">Fig 6(B)</xref>). The compressive tone-remapping makes the histogram distribution more negatively skewed. It is mathematically equivalent to histogram matching to a more negatively skewed distribution, but, unlike the method used in Experiments 1 and 4, it does not keep the mean and standard deviation of the luminance histogram the same. Instead, the compressive tone-remapping is able to selectively dim high-intensity pixels, which are likely produced by highlights, without affecting the remaining pixels (<xref ref-type="fig" rid="pcbi.1006061.g022">Fig 22</xref>).</p>
<fig id="pcbi.1006061.g021" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g021</object-id>
<label>Fig 21</label>
<caption>
<title>Stimulus conditions in Experiment 5.</title>
<p>(a) Three object images (Stanford bunny, low frequency bump, and 1/f bump) were used. In addition to veridical rendering for the object, object images with inconsistent specular highlights were created. The object images were rendered under (a) the point light source or (b) the HDR environment map.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g021" xlink:type="simple"/>
</fig>
<fig id="pcbi.1006061.g022" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g022</object-id>
<label>Fig 22</label>
<caption>
<title>Effect of tone-remapping on the appearance of the material and albedo.</title>
<p>We changed the cut-off intensity of compressive tone-remapping applied to several object images with veridical or inconsistent highlights.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g022" xlink:type="simple"/>
</fig>
<p><xref ref-type="fig" rid="pcbi.1006061.g023">Fig 23</xref> showed the rating values for the glossiness judgment (red) and non-uniformity judgment (blue), each plotted as a function of the cut-off intensity of the tone mappings. Each symbol indicates the averaged rating values across different observers. <xref ref-type="fig" rid="pcbi.1006061.g023">Fig 23</xref>(left) shows the results for object images rendered by using the point light source, and <xref ref-type="fig" rid="pcbi.1006061.g023">Fig 23</xref>(right) shows those for object images rendered by Debevec's HDR environment map. Different panels indicated different highlight conditions. Since similar results were obtained across different objects, the data are pooled over the three objects.</p>
<fig id="pcbi.1006061.g023" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g023</object-id>
<label>Fig 23</label>
<caption>
<title>Results of Experiment 5.</title>
<p>The rating values for the glossiness (top) and non-uniformity (bottom) judgments are plotted as a function of the cut-off point. The rating values for the object condition were pooled across observers. The column panels indicate the lighting condition (point or environment). Error bars indicate ± 1 SEM across observers.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g023" xlink:type="simple"/>
</fig>
<p>The gloss rating for the original images with veridical highlights was relatively high and rapidly declined as the cut-off intensity was decreased, while that for the inconsistent highlight images was relatively low and only slowly declined as the cut-off intensity was decreased. Similar results were obtained for the two illumination conditions, except that the gloss rating was generally higher for the environmental illumination than for the point-light illumination.</p>
<p>The non-uniformity rating was low for the vertical highlight images but high for the inconsistent highlight images. In both cases, the non-uniformity rating was affected only slightly by the cut-off intensity. Similar results were obtained for the two illumination conditions, except that the non-uniformity rating for the inconsistent highlight images was slightly higher for the environmental illumination than for the point-light illumination.</p>
<p>In agreement with Experiment 4, the results demonstrate that compressive tone-remapping smoothly erases veridical highlights and makes the object less glossy, while it leaves inconsistent highlights visible as albedo changes regardless of the cut-off intensity. The results support the idea that the luminance order information plays a critical role in discriminating between highlights and reflectance changes. It is noteworthy that the finding was obtained not only under the point light source but also under the HDR environment map. Object images rendered using HDR environment maps have complex specular highlights, the local orientations of which could be inconsistent with shading patterns, as shown in <xref ref-type="fig" rid="pcbi.1006061.g006">Fig 6</xref>. However, given that such spatial non-uniformity is mainly produced in the high intensity range, it can be effectively removed by compressive tone-remapping as we saw in <xref ref-type="fig" rid="pcbi.1006061.g006">Fig 6</xref>.</p>
</sec>
</sec>
</sec>
<sec id="sec015" sec-type="conclusions">
<title>Discussion</title>
<p>The ultimate goal of our study is to comprehensively understand how human vison estimates the material property together with other object properties such as shapes, albedos, and illuminations. Our opening question was: Why does intensity histogram manipulation affect human material perception to a much greater extent than it does the perception of other physical properties. The image analyses of a variety of materials revealed that typical material changes have little effect on the intensity order information (which defines the isophote map and the direction of the intensity gradient), while they strongly affect the residual information, i.e., the magnitude of the intensity gradient. This led us to a hypothesis that the human visual system may mainly use the intensity gradient magnitude information for material perception, while it uses the intensity order information for shape perception and albedo change detection (<xref ref-type="fig" rid="pcbi.1006061.g008">Fig 8</xref>). The first three experiments confirmed that shape perception was affected little by the intensity gradient magnitude information but was affected strongly by the intensity order information. The last two experiments confirmed that perceptual discrimination of material-related intensity changes (veridical highlights) from albedo-related intensity changes (inconsistent highlights) is dependent on the intensity order information.</p>
<sec id="sec016">
<title>Material processing</title>
<p>Numerous studies have utilized histogram-transformation methods as used in Experiment 1 to modulate the pattern of intensity histogram [<xref ref-type="bibr" rid="pcbi.1006061.ref001">1</xref>,<xref ref-type="bibr" rid="pcbi.1006061.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1006061.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref040">40</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref042">42</xref>]. As shown in our image analysis, the transformation does not disturb the intensity order information of a surface image, but it does distort the magnitude information of the intensity gradient of the image. In addition to histogram matching, compressive nonlinear tone mapping is widely used for appearance control in printing or screen display devices [<xref ref-type="bibr" rid="pcbi.1006061.ref004">4</xref>,<xref ref-type="bibr" rid="pcbi.1006061.ref005">5</xref>]. The mapping also usually retains the intensity order information of an input image. These techniques are consistent with the present finding that the modulation of the gradient magnitude information can be a diagnostic for the material appearance of the surface.</p>
</sec>
<sec id="sec017">
<title>Shape processing</title>
<p>If the intensity order of the image histogram of a surface is kept constant, then so is the isophote structure or the direction of the intensity gradient of the surface image. The effect of the structure of isophotes on surface shape estimation has been traditionally recognized in the context of shape-from-shading [<xref ref-type="bibr" rid="pcbi.1006061.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref027">27</xref>]. For instance, Koenderink &amp; van Doorn [<xref ref-type="bibr" rid="pcbi.1006061.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref020">20</xref>] showed the structural relationships between the pattern of isophotes across a diffuse surface and the geometric structure of the surface. Specifically, they focused on the “Gauss map”, which is a spherical image where a surface in Euclidean space is mapped to the unit sphere. Since in simple stimulus situations (e.g., Lambertian materials under a collimated illumination) the radiance of a point in a surface only depends on the surface normal, each radiance of the surface image with an identical normal can be mapped to the same point on the sphere image. Koenderink and van Doorn showed that when a specific region of a surface image, such as a convex, concave, or saddle-shaped region, is extracted based on the local extrema of the image, its spherical image corresponds to the surface geometry in a one-to-one fashion. Then the isophotes of the Gauss map can have invariant structures related to the surface geometry, irrespective of illumination directions.</p>
<p>Similarly, Breton &amp; Zucker [<xref ref-type="bibr" rid="pcbi.1006061.ref021">21</xref>] showed that under a diffuse surface illuminated by a point light source, the orientation of the intensity gradient field of the surface only depends on the geometric properties of the surface irrespective of the irradiance and the diffuse reflectance. They computed the “shading flow field” based on the orientation information and showed that the flow field can be used for shape estimation and edge classification. For instance, an attached shadow cast on a corrugated surface produces discontinuity in the continuous shading field of the surface and thus the discontinuity can be a cue for edge classification. More recently, Zucker and his colleagues introduced the idea of constructing a set of local surfaces based on the shading flow field for diffuse surfaces under any point light source [<xref ref-type="bibr" rid="pcbi.1006061.ref026">26</xref>].</p>
<p>Although the elegant analyses by Koenderink and van Doorn (1980) and Zucker et al. on potential shape information in intensity gradient maps assume Lambertian objects, the present findings indicate that their theories are also helpful for understanding shape perception for non-Lambertian materials.</p>
<p>In this regard, the contribution of the present study is to show that the effect of the intensity order information is considerably robust against material changes. Our image analysis showed that the changes in natural BRDFs (100 types) did not strongly affect the intensity order information of object images. In addition, we showed in Experiment 3 that when a specific material change distorted the intensity order information of an object image, the perceived shape was changed with the distortion. This finding is consistent with previous studies showing that shape constancy across specific materials could not be obtained [<xref ref-type="bibr" rid="pcbi.1006061.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref044">44</xref>]. The findings suggest that human shape processing strongly relies on the intensity order information and that distortion of the information tends to cause the perceived shape’s modulation even when actual material changes produce the distortion.</p>
<p>Our psychophysical experiments show that keeping the intensity order constant makes the perceived shape constant (Experiment 1 and 2). In addition, when we disturb the intensity order information, the perceived shape changed with the distortion (Experiments 2 and 3). However, we emphasize that the same shape can have different intensity order maps and that different intensity order maps do not always produce different perceived shapes, due to, say, the effect of illumination differences. Our study mainly investigated material and shape perception under the conditions where an object is placed in a specific illumination environment, but as shown in the Image Analysis section (<xref ref-type="fig" rid="pcbi.1006061.g007">Fig 7</xref>), illumination changes can produce large distortions of the intensity gradient information. Nevertheless, identical objects under different illuminations can be perceived as similar in shape even when their intensity order information is markedly different, as shown in Experiment 2b (<xref ref-type="fig" rid="pcbi.1006061.g014">Fig 14</xref>). The previous studies also reported that the perception of shape and material is quite robust across different illumination contexts [<xref ref-type="bibr" rid="pcbi.1006061.ref045">45</xref>]. Hence, to recover the perceived shape from the intensity order information, the visual system has to discount the influence of the illumination field. While how it does this remains an open question, one possibility is that the occluding contour of a surface image may normalize the mid-level representation of an object obtained from the intensity order information [<xref ref-type="bibr" rid="pcbi.1006061.ref018">18</xref>]. Another possibility is that the visual system may extract some illuminant-invariant higher order differential structures from the intensity order information (cf., [<xref ref-type="bibr" rid="pcbi.1006061.ref026">26</xref>]).</p>
<p>A luminance-order map is far from sufficient to recover the geometrical ground truth of an object even when material information is given. Shape estimation solely from luminance-order information must introduce many ambiguities. It is obvious that the shape-from-intensity-order-map problem suffers from bas-relief ambiguity [<xref ref-type="bibr" rid="pcbi.1006061.ref046">46</xref>], since our theory concerns perception of matte (diffuse) and gloss (diffuse+specular) objects seen without light source information. In addition, in many cases, luminance-order maps must be equated between completely different shapes by adjusting material (BRDF, BSSRDF, BTF) and/or illumination parameters. Although we have not theoretically analyzed this ambiguity, this would seem to be a hard analysis, since it should consider not only geometrical optics, but also natural statistics of reflectance and illumination parameters. Furthermore, in order to understand human vision, the important issue is not only ambiguity in estimation of the ground-truth 3D structure, but also ambiguity in estimation of the perceived shape. The perceptual representation of shape is degenerated in the sense that it does not contain full detailed information about the ground truth structure, though what is perceptually represented about shape remains controversial [<xref ref-type="bibr" rid="pcbi.1006061.ref047">47</xref>]. According to our experiments, provided we preserved the luminance order map, the observers reported similar shapes. Despite enormous physical ambiguity, we found little evidence of perceptual ambiguity like that observed in the Necker cube. We think this provides an important hint about perceptual shape representations in the human brain.</p>
<p>Consider next the relationships of luminance-order information to orientation information that Fleming and his colleagues proposed were influential in shape estimation [<xref ref-type="bibr" rid="pcbi.1006061.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref025">25</xref>]. Like Zucker and his colleagues, they constructed the orientation field of a surface image. The dominant orientation of the field was determined according to the relative powers of oriented-linear filters’ outputs. They showed that the distortion of the orientation field of a surface image corresponds to the distortion of the perceived shape of the surface. In computer graphics also, the orientation field has been utilized for apparent shape editing [<xref ref-type="bibr" rid="pcbi.1006061.ref027">27</xref>]. Specifically, Vergne et al. [<xref ref-type="bibr" rid="pcbi.1006061.ref027">27</xref>] used structure tensors of a surface image to construct the orientation field and showed that the modulation of the field drastically changed the apparent shape. In addition, they showed in their statistical analysis that the orientation information of identical shapes with different materials (four types) or illuminations (four types) can be similar to each other, as in our image analysis.</p>
<p>Fleming and his colleagues have constructed a general framework of shape perception from image orientation information. Their investigation started from perfectly specular (mirrored) objects, and then generalized their theory to shape perception from diffuse shading, texture or contours. In contrast, our theory was based on a critical observation that luminance histogram matching affects apparent material. Since luminance histogram matching realized by monotonic luminance re-mapping can control the material appearance of an object in the range between pure matte (diffuse) and gloss (diffuse+specular), but cannot easily make perfectly specular appearances (we need non-monotonic luminance re-mapping [<xref ref-type="bibr" rid="pcbi.1006061.ref041">41</xref>]), we do not have a strong theoretical basis to assume that our theory is applicable to mirrored objects. Textured objects and line drawings are also outside our scope. Despite having a scope narrower than that of Fleming et al., our theory has more specific predictions about material and shape perception of objects within the scope of our analyses.</p>
<p>A critical question is what kind of directional information, i.e., a vector map modulo 180 or 360 degrees, or both, the visual system relies on. The orientation field of Fleming and his colleagues is based on a vector map modulo 180 degrees, while the present study used a vector map modulo 360 degrees to explain the perceived shape. In Experiments 2 and 3, we found that the modulation of the tone-mapping curves of a surface image changed the perceived shape of the surface, even though it only distorted the vector map modulo 360 degrees while keeping constant the vector map modulo 180 degrees. The finding suggests that at least for the class of materials we considered, shape perception is different when the orientation map is similar, but the luminance order is different, as predicted by our theory.</p>
<p>Fleming et al. proposed a ground theory for a wide range of monocular shape perception including cases where shape perception is similar even when luminance order is not preserved [<xref ref-type="bibr" rid="pcbi.1006061.ref048">48</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref050">50</xref>]. We also recognize that non-linear tone re-mappings that do not preserve luminance order information are able to change glossy objects into mirrored or translucent objects of similar shapes (e.g., [<xref ref-type="bibr" rid="pcbi.1006061.ref041">41</xref>]). We speculate the perceived shape distortion may depend on the spatial flow structure where the flow distortion emerges. For instance, in Experiment 3 (<xref ref-type="fig" rid="pcbi.1006061.g017">Fig 17</xref>) a perceived shape distortion for the asperity (a = 0.2) condition was obtained in gauge position 6 where the shading flow produces a cusp. The finding suggests that the effectiveness of the vector map modulo 360 degrees may depend on the diagnostic flow structure.</p>
<p>Although we show the importance of the signed intensity gradient in shape estimation, we agree that unsigned orientation measurements are also useful in shape processing. For instance, the computation based on 180 degrees would be beneficial in the estimation of specular-only images because the processing modulo 180 degrees is tolerant to the first-order modulation due to mirror reflections. Thus, the processing based on the vector map modulo either 180 or 360 degrees has benefits in some situations. This suggests a possibility that two types of processing are adopted by the visual system, and thus further studies are necessary to elucidate how human shape processing codes directional information.</p>
<p>While Fleming et al. [<xref ref-type="bibr" rid="pcbi.1006061.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref025">25</xref>] measured unsigned orientations at multiple scales, the luminance gradient computation normally has a single value at each location. Simultaneous gradient measurements at multiple spatial scales might be more beneficial, but we have not investigated this possibility yet.</p>
<p>In sum, although the relationship of our theory with the theory of Fleming et al. is still to be clarified, we can at least say that a luminance-order map contains richer information than that of an orientation map, and that human shape processing does not refrain from using the extra information when it is available and useful.</p>
<p>As for the effect of gradient magnitude, although we showed that the perceived shape is little affected by modulating the magnitude of intensity gradients, we understand that in some cases the perceived shape, especially perceived volume, can be affected by position/scale specific modulation. When intensity magnitudes are small, the surface tends to appear to have less curvature (i.e., they appear flatter) than when the magnitudes are large, even if the intensity ordering is constant. In particular, Giesel &amp; Zaidi [<xref ref-type="bibr" rid="pcbi.1006061.ref051">51</xref>] showed that enhancing the amplitude of specific spatial frequency components increases perceived volume, although the modulation does not change the perceived tilt. It has been shown that the perceived volume (slant) of an object image is unstable, compared with its perceived tilt [<xref ref-type="bibr" rid="pcbi.1006061.ref052">52</xref>], and therefore it might be affected by several factors depending on the context in which the object is placed.</p>
</sec>
<sec id="sec018">
<title>Perception of reflectance changes</title>
<p>This study suggests that the computation based on two types of intensity gradient information may facilitate a comprehensive understanding of material and shape processing. In addition, we showed that this computation may also be used for the perception of reflectance changes. That is, the present study revealed that the specular-shading consistency could be judged in the shading processing as a problem of discrimination of smooth shadings from reflectance changes. It is noteworthy that in Experiments 4 and 5 the perception of albedo-uniformity for an object image with inconsistent highlights was not changed by histogram modulations (Figs <xref ref-type="fig" rid="pcbi.1006061.g020">20</xref> and <xref ref-type="fig" rid="pcbi.1006061.g023">23</xref>). This finding suggests that processing based on the intensity order information may be sufficient for discriminating an object image with veridical highlights from inconsistent ones.</p>
<p>Although the algorithms of intrinsic image decomposition in the field of computer vision can discriminate smooth shadings from reflectance changes [<xref ref-type="bibr" rid="pcbi.1006061.ref053">53</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref059">59</xref>], it is not easy for many of them to discriminate veridical specular highlights from reflectance changes such as white blobs. For instance, when one of the cutting-edge algorithms [<xref ref-type="bibr" rid="pcbi.1006061.ref058">58</xref>] is applied to object images with veridical and inconsistent highlights, even for a uniform albedo image with veridical highlights, it incorrectly detects the highlights as regions with different albedos. However, when the same algorithm is applied to a slope-normalized image (<xref ref-type="fig" rid="pcbi.1006061.g024">Fig 24B</xref>, right), it correctly predicts the image with veridical highlights to have a uniform albedo, while the image with inconsistent highlights to have non-uniform albedos. This observation suggests that, if the visual system has a pre-processing stage to extract a luminance-order (slope-independent) image, it can easily discriminate smooth shadings from reflectance changes, and correctly solve the highlight consistency problem.</p>
<fig id="pcbi.1006061.g024" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006061.g024</object-id>
<label>Fig 24</label>
<caption>
<title>Demonstration of detecting albedo changes based on the intensity gradient.</title>
<p>(a) Veridical highlights have little effect on the direction map, i.e., the map for the veridical highlight was similar to that for the matte one. In contrast, inconsistent highlights mark an abrupt change in the direction map. (b) When one of the intrinsic image decomposition algorithms [<xref ref-type="bibr" rid="pcbi.1006061.ref058">58</xref>] was applied to the object images with veridical and inconsistent highlights (left), even for the uniform albedo image with veridical highlights it incorrectly detects the highlights as different albedos. The estimated albedo images are shown at the bottom of the figure. In contrast, when it was applied to the slope-normalized image (right), the image with veridical highlights can be regarded as a uniform albedo.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.g024" xlink:type="simple"/>
</fig>
<p>We do not intend to dispute a previous hypothesis that the position and orientation congruence of specular highlights relative to diffuse surface shading could be critical for discrimination [<xref ref-type="bibr" rid="pcbi.1006061.ref013">13</xref>]. In terms of our hypothesis, position and orientation incongruences imply non-smooth luminance-order maps, and thus are likely to arise from albedo changes.</p>
</sec>
<sec id="sec019">
<title>Neural mechanisms</title>
<p>The cortical processing of intensity order information, as well as that of intensity magnitude information, remains unclear. One plausible hypothesis is that the brain decodes the direction and magnitude of the local intensity gradient from the outputs of orientation-selective filters. These filters should be located at early stages where local phase information is preserved, not at later stages where local orientation energy is represented. However, since little attention has been paid to intensity order information, we can only speculate on its cortical mechanism at present. Our brain may adopt a completely different strategy to process luminance-order information. We hope the present psychophysical findings will motivate future neurological investigations into the mechanisms of cortical processing of the intensity order and magnitude information. Specifically, it would be interesting to see which cortical areas are more sensitive to intensity order than to intensity magnitude, and vice versa. Some neurological studies have found gloss-selective neurons in the ventral stream of monkeys and common marmosets [<xref ref-type="bibr" rid="pcbi.1006061.ref060">60</xref>–<xref ref-type="bibr" rid="pcbi.1006061.ref062">62</xref>]. For instance, Nishio et al. [<xref ref-type="bibr" rid="pcbi.1006061.ref061">61</xref>] found neurons in the inferior temporal (IT) cortex of the monkey that selectively and parametrically respond to physical gloss enhancements. These neurons are likely to be more sensitive to intensity gradient magnitude information. On the other hand, object-selective neurons in the other parts of the IT cortex may be more sensitive to intensity order information.</p>
</sec>
<sec id="sec020">
<title>Conclusions</title>
<p>While investigating the effects of histogram transformation methods on material perception, we showed that material processing depends on detailed gradient information rather than intensity order information, such as the direction of the intensity gradient. These findings also revealed the image constraints produced by other physical properties such as albedo and shape. The present study suggested that specular-shading consistency could be judged from intensity order information, with which a specular consistency problem becomes a general shading-reflectance separation problem. In addition, our study suggests that human perception of shape from shading is sensitive to the intensity order information of an object image but not sensitive to the detailed intensity gradient information.</p>
</sec>
</sec>
<sec id="sec021" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec022">
<title>Ethics statement</title>
<p>All the psychophysical experiments were approved by the Ethical Committees at NTT Communication Science Laboratories and were conducted in accordance with the Declaration of Helsinki.</p>
</sec>
<sec id="sec023">
<title>Image constraints for material changes</title>
<sec id="sec024">
<title>Image analysis</title>
<p>In the analysis, we used three surface geometries, all of which were surfaces modulated in depth by Gaussian band-pass noises (<xref ref-type="fig" rid="pcbi.1006061.g003">Fig 3</xref>). The surface images were rendered using PBRT [<xref ref-type="bibr" rid="pcbi.1006061.ref063">63</xref>] under a point light source facing in the same direction as the viewing direction (slant = 0°), under a point light source facing in two different directions from the viewing direction (slant = 20° and 40°), or under the HDR environment map in Bernhard Vogl’s website (“Overcast day at Techgate Donaucity”, <ext-link ext-link-type="uri" xlink:href="http://dativ.at/lightprobes/index.html" xlink:type="simple">http://dativ.at/lightprobes/index.html</ext-link>). The size of the rendered images was 256 × 256 pix. Each rendered image was transformed to gray scale and divided into the direction and the magnitude maps of the intensity gradient using a gradient operator [<xref ref-type="bibr" rid="pcbi.1006061.ref064">64</xref>]. The size of the gradient kernel was 5 x 5 pix. Then the correlation between all pairs of material changes with the same geometry model was calculated. For the magnitude map, Pearson’s correlation coefficient was used; for the direction maps, the circular correlation was used [<xref ref-type="bibr" rid="pcbi.1006061.ref029">29</xref>,<xref ref-type="bibr" rid="pcbi.1006061.ref030">30</xref>]. The number of pixels used for the calculation of each correlation was 196,608 (256 × 256 pix × 3 surface geometries).</p>
<p>In one analysis, we applied a compressive tone mapping to the surfaces rendered under the HDR maps (<xref ref-type="fig" rid="pcbi.1006061.g006">Fig 6(B)</xref>). The compressive tone mapping was defined as follows.
<disp-formula id="pcbi.1006061.e001">
<alternatives>
<graphic id="pcbi.1006061.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006061.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>r</mml:mi></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>r</mml:mi></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>1)</label>
</disp-formula>
where <italic>L</italic><sub><italic>o</italic></sub> is the pixel intensities of the original image. The intensity ranged from 0 to 1. <italic>c</italic> is the cut-off intensity of the mapping, and <italic>r</italic> is a smoothing factor around the cut-off intensity. <italic>r</italic> was set to 30 in the present analysis, and c was determined in each image by subtracting 1 SD from the mean intensity. When the magnitude of the intensity gradient was close to zero after tone-mapping (threshold &lt; 0.0002), we excluded the gradient from the correlation computation of the direction and the magnitude analyses.</p>
</sec>
</sec>
<sec id="sec025">
<title>Perception of shapes</title>
<sec id="sec026">
<title>Experiment 1</title>
<p>Observers. Eight observers participated in the experiment. They were naïve to the purpose and methods of the experiment and had normal or corrected to normal visual acuity. They were paid for their participation and gave their written informed consent before the start of the experiment.</p>
<p><italic>Apparatus.</italic> The experimental stimuli were displayed using Matlab R2013b in conjunction with the Psychophysics Toolbox 3 [<xref ref-type="bibr" rid="pcbi.1006061.ref065">65</xref>,<xref ref-type="bibr" rid="pcbi.1006061.ref066">66</xref>]. They were displayed on a calibrated 30-inch EIZO color monitor (ColorEdge CG303W) driven by an NVIDIA video card (Quadro 600) with a pixel resolution of 2560 × 1600 and a frame rate of 30 Hz. The intensity of each phosphor could be varied with 10-bit resolution. The experiment was run in a dark room.</p>
<p><italic>Stimuli.</italic> The stimuli used in the experiment were computer-generated images (<xref ref-type="fig" rid="pcbi.1006061.g009">Fig 9</xref>). We made the geometry models of a bumpy sphere modulated in each surface normal direction using Gaussian band-pass noises and lit them using a point light source placed in the same direction as the viewing direction. The object images were rendered with the Ward reflection model [<xref ref-type="bibr" rid="pcbi.1006061.ref067">67</xref>]:
<disp-formula id="pcbi.1006061.e002">
<alternatives>
<graphic id="pcbi.1006061.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006061.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mi>π</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">exp</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">tan</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>δ</mml:mi><mml:mo>/</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mi>α</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">cos</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mi mathvariant="normal">cos</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>2)</label>
</disp-formula>
where <italic>ρ(θi</italic>,<italic>φi</italic>,<italic>θo</italic>,<italic>φo)</italic> is the surface reflection model, and <italic>θi</italic>, <italic>φi</italic>, and <italic>θo</italic>, <italic>φo</italic> are the incoming and outgoing directions, respectively. There are three parameters in the model; <italic>ρd</italic>, <italic>ρs</italic>, and <italic>α</italic>, where <italic>ρd</italic> is the diffuse reflectance of a surface, <italic>ρs</italic> is the energy of its specular component, and <italic>α</italic> is the spread of the specular lobe. The values of <italic>ρd</italic>, <italic>ρs</italic>, and <italic>α</italic> used in the experiment were 0.5, 0.25, and 0.25, respectively.</p>
<p>We applied standard linear tone mapping to the rendered images and then modulated the skewness of the intensity histogram of the object images using the histogram matching method (<xref ref-type="fig" rid="pcbi.1006061.g001">Fig 1</xref>). The reference distribution for the matching <italic>h</italic><sub><italic>3</italic></sub> was made using a Beta distribution as in [<xref ref-type="bibr" rid="pcbi.1006061.ref008">8</xref>], given by:
<disp-formula id="pcbi.1006061.e003">
<alternatives>
<graphic id="pcbi.1006061.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006061.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:msubsup><mml:mi>L</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>∫</mml:mo><mml:mn>0</mml:mn><mml:mn>1</mml:mn></mml:msubsup></mml:mstyle><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>3)</label>
</disp-formula>
where <italic>L</italic><sub><italic>r</italic></sub> is the pixel intensity, and <italic>p</italic> is the parameter that modulates the amount of skewness. In the present experiment we set the values of <italic>p</italic> as 1.5, 5, and 8.5, which approximately correspond to skewness of -1.1, 0, and 1.1, respectively (<xref ref-type="fig" rid="pcbi.1006061.g009">Fig 9</xref>). The mean and SD were set to those of the original image by rescaling the Beta distribution. These stimuli were presented on the experimental monitor, the maximum luminance of which was 150.6 cd/m<sup>2</sup>. Each stimulus was presented in a window of 3.5 deg × 3.5 deg on the monitor.</p>
</sec>
<sec id="sec027">
<title>Procedure</title>
<p><italic>Glossiness judgment.</italic> In the glossiness judgment, observers rated how glossy the object image appeared to be on a 5-point scale. A rating of 1 meant that the object image appeared to be perfectly matte, while a rating value of 5 meant that the object image appeared highly glossy. Each stimulus condition was tested six times in total for each observer.</p>
<p><italic>Shape estimation using gauge probes.</italic> In the shape estimation task, observers reported the perceived shape of the object images by setting a gauge probe with a hand-held mouse to match the apparent surface slant/tilt at nine locations per object. Following Fleming et al. [<xref ref-type="bibr" rid="pcbi.1006061.ref023">23</xref>], we simultaneously presented a pair of the same images on the monitor. One image showed the latest status of all nine probes that the observer had to match, and the other image contained only a single probe that the observer was currently adjusting (see also Fig 4A in [<xref ref-type="bibr" rid="pcbi.1006061.ref023">23</xref>]). In addition to the skew modulated objects (<xref ref-type="fig" rid="pcbi.1006061.g009">Fig 9</xref>), each original object with highlights was used for the control condition. Each stimulus condition was tested six times in total for each observer.</p>
</sec>
</sec>
<sec id="sec028">
<title>Experiment 2a</title>
<p>We applied a variety of nonlinear remappings to three object images (<xref ref-type="fig" rid="pcbi.1006061.g011">Fig 11</xref>). The remapping function was defined as follows.
<disp-formula id="pcbi.1006061.e004">
<alternatives>
<graphic id="pcbi.1006061.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006061.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mi mathvariant="normal">sin</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>m</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>4)</label>
</disp-formula>
where <italic>m</italic> is the mean intensity, <italic>s</italic><sub><italic>1</italic></sub> is the slope of the remapping function, <italic>s</italic><sub><italic>2</italic></sub> is the amplitude of a sinusoidal modulation, ω is the angular velocity of the modulation, andφis its phase. Specifically, we made fifteen remapping curves by adding a sinusoidal modulation with one of five different amplitudes (<italic>s</italic><sub><italic>2</italic></sub> = 0, 0.015, 0.065, 0.115, or 0.165) to a linear tone remapping function with one of three different slopes (<italic>s</italic><sub><italic>1</italic></sub> = 0.5, 1, or 2). The ω and φ in the experiment were the constant values of 2.857π and π, respectively. When the slope was the steepest (2), the remapping curve always monotonically increased. This implies that the intensity order of the original image was not disrupted even by the largest modulation. When the slope was midway between steep and gentle (1), the remapping curve was non-monotonic, and the intensity order of the original image was disrupted when <italic>a</italic><sub><italic>1</italic></sub> was 0.115 or 0.165. When the slope was gentle (0.5), the intensity order was disrupted when <italic>a</italic><sub><italic>1</italic></sub> was 0.065, 0.115 or 0.165. It should be noted that our manipulation did not change the orientation (modulo 180 degrees) map of the image. The geometric models we used in the experiment were two bumpy spheres (the displacement in the normal direction of the surface of each sphere was given by a coarse or fine Gaussian band-pass noise; <xref ref-type="fig" rid="pcbi.1006061.g011">Fig 11</xref>, bottom left and bottom center), and a cylinder (<xref ref-type="fig" rid="pcbi.1006061.g011">Fig 11</xref>, bottom right). Each model was lit by a point light source from the camera direction.</p>
<p>Eight observers were asked to estimate the perceived shape of the objects by setting a gauge probe with the matching apparent surface slant/tilt. The position of the nine gauge probes is shown in <xref ref-type="fig" rid="pcbi.1006061.g011">Fig 11</xref>. Each of the 45 stimuli (3 objects x 15 tone-mapping types including the original image) was tested three times for each observer. In addition, to confirm the performance stability of the gauge task, the gauge matching for the original images of the three objects was again conducted three times in a different session. These data were used for the baseline and showed as no shape changes in <xref ref-type="fig" rid="pcbi.1006061.g012">Fig 12</xref>. The other methods were the same as in Experiment 1.</p>
</sec>
<sec id="sec029">
<title>Experiment 2b</title>
<p>In the experiment, we applied a variety of non-linear remappings, as in Experiment 2a, on several object images rendered under a point light source place in the same direction as the viewing one or in the upper-right direction for the object where the illumination slant was 45° and the illumination tilt was 30°. Ten observers were asked to estimate the perceived shape of the objects by setting a gauge probe with the matching apparent surface slant/tilt. The position of the six gauge probes is shown in <xref ref-type="fig" rid="pcbi.1006061.g013">Fig 13</xref>. Each of the 10 stimuli (2 illumination direction x 5 tone-mapping types including the original image) was tested ten times for each observer. The other methods were the same as those used in Experiment 2a.</p>
</sec>
<sec id="sec030">
<title>Experiment 3</title>
<p>The geometric model was a bumpy object with low spatial frequency bumps (Object 4) (<xref ref-type="fig" rid="pcbi.1006061.g016">Fig 16</xref>). The model was lit by a point light source from the camera direction. The reflection model used in the experiment was the Lambertian or asperity material [<xref ref-type="bibr" rid="pcbi.1006061.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1006061.ref039">39</xref>]. The output intensities on the models were determined as follows:
<disp-formula id="pcbi.1006061.e005">
<alternatives>
<graphic id="pcbi.1006061.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006061.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>d</mml:mi></mml:msub></mml:mrow><mml:mi>π</mml:mi></mml:mfrac><mml:msub><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>⋅</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>5)</label>
</disp-formula>
<disp-formula id="pcbi.1006061.e006">
<alternatives>
<graphic id="pcbi.1006061.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006061.e006" xlink:type="simple"/>
<mml:math display="block" id="M6">
<mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mi>a</mml:mi><mml:mrow><mml:mi>π</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>⋅</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo>⋅</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mfrac><mml:msub><mml:mi>l</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>I</mml:mi><mml:mo>⋅</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>6)</label>
</disp-formula>
where <italic>L</italic><sub><italic>l</italic></sub> and <italic>L</italic><sub><italic>a</italic></sub> are the intensity of the Lambertian and asperity materials, respectively. <italic>I</italic>, and <italic>J</italic> are the incident and reflected angles, respectively. <italic>N</italic> is the surface normal, <italic>l</italic> is the intensity of the light source, and <italic>a</italic> is the asperity parameter known as the edge brightening factor. When the incident and reflected angles are the same, which is true under the lighting condition we used, the intensity of the asperity material, <italic>L</italic><sub><italic>a</italic></sub>, can be described as a function of the intensity of the Lambertian material as follows:
<disp-formula id="pcbi.1006061.e007">
<alternatives>
<graphic id="pcbi.1006061.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006061.e007" xlink:type="simple"/>
<mml:math display="block" id="M7">
<mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:msub><mml:mi>l</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:msub><mml:mi>L</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:msub><mml:mi>ρ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>π</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:msubsup><mml:mi>L</mml:mi><mml:mi>l</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mi>ρ</mml:mi><mml:mi>d</mml:mi></mml:msub><mml:msub><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfrac></mml:mrow>
</mml:math>
</alternatives>
<label>7)</label>
</disp-formula>
This could be regarded as an intensity remapping function from Lambertian to asperity materials, the shape of which is dependent on parameter <italic>a</italic> (<xref ref-type="fig" rid="pcbi.1006061.g015">Fig 15</xref>). As the <italic>L</italic><sub><italic>l</italic></sub> increases, the remapping function first rises and then falls after a transition point. The transition point (peak) shifts towards the lower range with a decrease in <italic>a</italic>. When <italic>a</italic> is moderately small (0.2), the intensity order is preserved in the lower range of Lambertian pixel intensity, while reversed in the higher range. When <italic>a</italic> is even smaller (0.02), the intensity order is reversed in most of the intensity range. We rendered asperity objects using these two values of <italic>a</italic> (<xref ref-type="fig" rid="pcbi.1006061.g016">Fig 16</xref>). In the experiment, the parameters <italic>l</italic><sub><italic>l</italic></sub>, and <italic>ρ</italic><sub><italic>d</italic></sub> were π and 0.6, respectively. The parameter l<sub>a</sub> was π under the asperity(a = 0.2) condition, and 4π under the asperity(a = 0.02) condition. In addition to a Lambertian object and two asperity objects, we used an object the intensity of which was completely reversed from that of the Lambertian object (<xref ref-type="fig" rid="pcbi.1006061.g016">Fig 16</xref>).</p>
<p>Ten observers participated in Experiment 3. The observers were asked to estimate the perceived shape of the objects by setting a gauge probe. The other methods were the same as those used in Experiment 2.</p>
<p>The same ten observers in Experiment 3 participated in one additional experiment. In the experiment, the geometric model was lit by a point light source in the upper-right direction for the object where the illumination slant was 45° and the illumination tilt was 30° (<xref ref-type="fig" rid="pcbi.1006061.g018">Fig 18</xref>). The same four reflection models and nine gauge probes as those in Experiment 3 were used. The observers were asked to estimate the perceived shape of the objects by setting a gauge probe.</p>
</sec>
<sec id="sec031">
<title>Perception of reflectance changes and materials</title>
<sec id="sec032">
<title>Experiment 4</title>
<p>Unless otherwise noted, the methods were the same as those used in the rating experiment of Experiment 1.</p>
<p>To make object images with inconsistent specular highlights (<xref ref-type="fig" rid="pcbi.1006061.g019">Fig 19</xref>), in which the highlights are incongruent in position and orientation with the diffuse shading component, we decomposed original glossy object images illuminated by a point-light source into diffuse and specular patterns and recombined the diffuse pattern with a rotated and displaced version of the specular pattern. We then modulated the image intensity modulation by histogram-matching to a Beta function (<xref ref-type="disp-formula" rid="pcbi.1006061.e003">Eq 3</xref>) with skewness parameter <italic>p</italic> set to -1.1, 0 or +1.1. We also used matte images with Lambertian reflection (i.e., <italic>ρs</italic> = 0 in Eq (<xref ref-type="disp-formula" rid="pcbi.1006061.e002">2</xref>)).</p>
<p>The observers were asked to rate glossiness and non-uniformity. In the glossiness judgment, observers rated how glossy the object image appeared on a 5-point scale. In the non-uniformity judgment, observers rated the degree of reflectance non-uniformity of the object images on a 5-point scale. A rating value of 1 on the scale meant that the object image appeared to have completely uniform albedo; a rating value of 5 meant that the object image appeared to have many dark stains or paint marks on a uniform albedo surface. The same eight observers in Experiment 1 participated this experiment.</p>
</sec>
<sec id="sec033">
<title>Experiment 5</title>
<p>We used three types of object models: the Stanford bunny (<xref ref-type="fig" rid="pcbi.1006061.g021">Fig 21(A) and 21(B)</xref> Stanford bunny) [<xref ref-type="bibr" rid="pcbi.1006061.ref068">68</xref>], a bumpy object with low spatial frequency bumps (<xref ref-type="fig" rid="pcbi.1006061.g021">Fig 21(A) and 21(B)</xref>, low freq. bump), and a sphere with 1/f noise bumps (<xref ref-type="fig" rid="pcbi.1006061.g021">Fig 21(A) and 21(B)</xref>, 1/f bump). We lit our models using a point light source facing the same direction as the viewing direction or using one of Debevec's HDR environment maps, “pisa” [<xref ref-type="bibr" rid="pcbi.1006061.ref069">69</xref>]. The object images were rendered with the Ward reflection model (Eq (<xref ref-type="disp-formula" rid="pcbi.1006061.e002">2</xref>)] using Mitsuba’s physically based renderer [<xref ref-type="bibr" rid="pcbi.1006061.ref070">70</xref>]. The values of parameters <italic>ρd</italic> and <italic>ρs</italic> used in the experiment were 0.5 and 0.15, respectively. The value of parameter <italic>α</italic> for object images under the HDR environment map was 0.1.</p>
<p>In addition to veridically rendered specular images (<xref ref-type="fig" rid="pcbi.1006061.g021">Fig 21(A) and 21(B)</xref>, left panel), we made object images with inconsistent specular highlights (<xref ref-type="fig" rid="pcbi.1006061.g021">Fig 21(A) and 21(B)</xref>, right panel) by combining the diffuse pattern with a rotated and displaced version of the specular pattern.</p>
<p>For the 18 object images [Object (bunny, low freq., and 1/f noise) × Lighting (point and environment) × Highlight-consistency (consistent and two types of inconsistent images)], we modulated the pixel intensity distribution by changing the cut-off intensity of Eq (<xref ref-type="disp-formula" rid="pcbi.1006061.e001">1</xref>). In the experiment, the values of <italic>c</italic> were 0.25, 0.35, or 1. The value of <italic>n</italic> was fixed at 30.</p>
<p>Two rating tasks were conducted: glossiness and non-uniformity, as in Experiment 4. Eight observers participated in Experiment 5.</p>
</sec>
</sec>
</sec>
<sec id="sec034">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006061.s001" mimetype="application/zip" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006061.s001" xlink:type="simple">
<label>S1 Dataset</label>
<caption>
<title>Individual data of all psychophysical experiments.</title>
<p>(ZIP)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006061.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reinhard</surname> <given-names>E.</given-names></name>, <name name-style="western"><surname>Ashikhmin</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Gooch</surname> <given-names>B.</given-names></name>, &amp; <name name-style="western"><surname>Shirley</surname> <given-names>P.</given-names></name> (<year>2001</year>). <article-title>Color transfer between images</article-title>. <source><italic>IEEE Computer graphics and applications</italic></source> (<issue>5</issue>), <fpage>34</fpage>–<lpage>41</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Khan</surname> <given-names>E. A.</given-names></name>, <name name-style="western"><surname>Reinhard</surname> <given-names>E.</given-names></name>, <name name-style="western"><surname>Fleming</surname> <given-names>R. W.</given-names></name>, &amp; <name name-style="western"><surname>Bülthoff</surname> <given-names>H. H.</given-names></name> (<year>2006</year>). <article-title>Image-based material editing</article-title>. <source><italic>ACM Transactions on Graphics (TOG)</italic></source>, <volume>25</volume>(<issue>3</issue>), <fpage>654</fpage>–<lpage>663</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref003"><label>3</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Reinhard</surname> <given-names>E.</given-names></name>, <name name-style="western"><surname>Khan</surname> <given-names>E. A.</given-names></name>, <name name-style="western"><surname>Akyuz</surname> <given-names>A. O.</given-names></name>, &amp; <name name-style="western"><surname>Johnson</surname> <given-names>G.</given-names></name> (<year>2008</year>). <chapter-title>Color imaging: fundamentals and applications</chapter-title>, <publisher-name>CRC Press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cowan</surname> <given-names>W. B.</given-names></name> (<year>1983</year>). <article-title>An inexpensive scheme for calibration of a colour monitor in terms of CIE standard coordinates</article-title>. <source><italic>ACM SIGGRAPH Computer Graphics</italic></source>, <volume>17</volume>(<issue>3</issue>), <fpage>315</fpage>–<lpage>321</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Reinhard</surname> <given-names>E.</given-names></name>, <name name-style="western"><surname>Stark</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Shirley</surname> <given-names>P.</given-names></name>, &amp; <name name-style="western"><surname>Ferwerda</surname> <given-names>J.</given-names></name> (<year>2002</year>). <article-title>Photographic tone reproduction for digital images</article-title>. <source><italic>ACM Transactions on Graphics (TOG)</italic></source>, <volume>21</volume>(<issue>3</issue>), <fpage>267</fpage>–<lpage>276</lpage></mixed-citation></ref>
<ref id="pcbi.1006061.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nishida</surname> <given-names>S.</given-names></name>, &amp; <name name-style="western"><surname>Shinya</surname> <given-names>M.</given-names></name> (<year>1998</year>). <article-title>Use of image-based information in judgments of surface-reflectance properties</article-title>. <source><italic>Journal of the Optical Society of America A</italic></source>, <volume>15</volume>(<issue>12</issue>), <fpage>2951</fpage>–<lpage>2965</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref007"><label>7</label><mixed-citation publication-type="other" xlink:type="simple">Adelson, E. H. (2001). <italic>On seeing stuff: The perception of materials by humans and machines</italic>. In B. E. Rogowitz &amp; T. N. Pappas (Eds.), <italic>Proceedings of the SPIE. Volume 4299: Human vision and electronic imaging VI</italic> (pp. 1–12). Bellingham, WA: SPIE.</mixed-citation></ref>
<ref id="pcbi.1006061.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Motoyoshi</surname> <given-names>I.</given-names></name>, <name name-style="western"><surname>Nishida</surname> <given-names>S.</given-names></name>, <name name-style="western"><surname>Sharan</surname> <given-names>L.</given-names></name>, &amp; <name name-style="western"><surname>Adelson</surname> <given-names>E. H.</given-names></name> (<year>2007</year>). <article-title>Image statistics and the perception of surface qualities</article-title>. <source><italic>Nature</italic></source>, <volume>447</volume>(<issue>7141</issue>), <fpage>206</fpage>–<lpage>209</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nature05724" xlink:type="simple">10.1038/nature05724</ext-link></comment> <object-id pub-id-type="pmid">17443193</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharan</surname> <given-names>L.</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>Y.</given-names></name>, <name name-style="western"><surname>Motoyoshi</surname> <given-names>I.</given-names></name>, <name name-style="western"><surname>Nishida</surname> <given-names>S.</given-names></name>, &amp; <name name-style="western"><surname>Adelson</surname> <given-names>E. H.</given-names></name> (<year>2008</year>). <article-title>Image statistics for surface reflectance perception</article-title>. <source><italic>Journal of the Optical Society of America A</italic></source>, <volume>25</volume>(<issue>4</issue>), <fpage>846</fpage>–<lpage>865</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Arce-Lopera</surname> <given-names>C.</given-names></name>, <name name-style="western"><surname>Masuda</surname> <given-names>T.</given-names></name>, <name name-style="western"><surname>Kimura</surname> <given-names>A.</given-names></name>, <name name-style="western"><surname>Wada</surname> <given-names>Y.</given-names></name>, &amp; <name name-style="western"><surname>Okajima</surname> <given-names>K.</given-names></name> (<year>2012</year>). <article-title>Luminance distribution modifies the perceived freshness of strawberries</article-title>. <source><italic>i-Perception</italic></source>, <volume>3</volume>(<issue>5</issue>), <fpage>338</fpage>–<lpage>355</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1068/i0471" xlink:type="simple">10.1068/i0471</ext-link></comment> <object-id pub-id-type="pmid">23145288</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sawayama</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Nishida</surname> <given-names>S.</given-names></name>, &amp; <name name-style="western"><surname>Shinya</surname> <given-names>M.</given-names></name> (<year>2017</year>). <article-title>Human perception of subresolution fineness of dense textures based on image intensity statistics</article-title>. <source><italic>Journal of Vision</italic></source>, <volume>17</volume>(<issue>4</issue>):<fpage>8</fpage>, 1–18, <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/17.4.8" xlink:type="simple">10.1167/17.4.8</ext-link></comment> <object-id pub-id-type="pmid">28423413</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sawayama</surname> <given-names>M.</given-names></name>, <name name-style="western"><surname>Adelson</surname> <given-names>E. H.</given-names></name>, &amp; <name name-style="western"><surname>Nishida</surname> <given-names>S.</given-names></name> (<year>2017</year>). <article-title>Visual wetness perception based on image color statistics</article-title>. <source><italic>Journal of Vision</italic></source>, <volume>17</volume>(<issue>5</issue>):<fpage>7</fpage>, 1–24, <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/17.5.7" xlink:type="simple">10.1167/17.5.7</ext-link></comment> <object-id pub-id-type="pmid">28505665</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kim</surname> <given-names>J.</given-names></name>, <name name-style="western"><surname>Marlow</surname> <given-names>P.</given-names></name>, &amp; <name name-style="western"><surname>Anderson</surname> <given-names>B. L.</given-names></name> (<year>2011</year>). <article-title>The perception of gloss depends on highlight congruence with surface shading</article-title>. <source><italic>Journal of Vision</italic></source>, <volume>11</volume>(<issue>9</issue>):<fpage>4</fpage>, 1–19, <ext-link ext-link-type="uri" xlink:href="http://www.journalofvision.org/content/11/9/4" xlink:type="simple">http://www.journalofvision.org/content/11/9/4</ext-link>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/11.9.4" xlink:type="simple">10.1167/11.9.4</ext-link></comment> <object-id pub-id-type="pmid">21841140</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Beck</surname> <given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Prazdny</surname> <given-names>S.</given-names></name> (<year>1981</year>). <article-title>Highlights and the perception of glossiness</article-title>. <source><italic>Attention</italic>, <italic>Perception</italic>, <italic>&amp; Psychophysics</italic></source>, <volume>30</volume>(<issue>4</issue>), <fpage>407</fpage>–<lpage>410</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname> <given-names>B. L.</given-names></name>, &amp; <name name-style="western"><surname>Kim</surname> <given-names>J.</given-names></name> (<year>2009</year>). <article-title>Image statistics do not explain the perception of gloss and lightness</article-title>. <source><italic>Journal of Vision</italic></source>, <volume>9</volume> (<issue>11</issue>):<fpage>10</fpage>, 1–17, <ext-link ext-link-type="uri" xlink:href="http://journalofvision.org/9/11/10/" xlink:type="simple">http://journalofvision.org/9/11/10/</ext-link>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/9.11.10" xlink:type="simple">10.1167/9.11.10</ext-link></comment> <object-id pub-id-type="pmid">20053073</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marlow</surname> <given-names>P.</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Anderson</surname> <given-names>B. L.</given-names></name> (<year>2011</year>). <article-title>The role of brightness and orientation congruence in the perception of surface gloss</article-title>. <source><italic>Journal of Vision</italic></source>, <volume>11</volume>(<issue>9</issue>):<fpage>16</fpage>, 1–12, <ext-link ext-link-type="uri" xlink:href="http://www.journalofvision.org/content/11/9/16" xlink:type="simple">http://www.journalofvision.org/content/11/9/16</ext-link>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/11.9.16" xlink:type="simple">10.1167/11.9.16</ext-link></comment> <object-id pub-id-type="pmid">21873616</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marlow</surname> <given-names>P. J.</given-names></name>, <name name-style="western"><surname>Kim</surname> <given-names>J.</given-names></name>, &amp; <name name-style="western"><surname>Anderson</surname> <given-names>B. L.</given-names></name> (<year>2012</year>). <article-title>The perception and misperception of specular surface reflectance</article-title>. <source><italic>Current Biology</italic></source>, <volume>22</volume>(<issue>20</issue>), <fpage>1909</fpage>–<lpage>1913</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2012.08.009" xlink:type="simple">10.1016/j.cub.2012.08.009</ext-link></comment> <object-id pub-id-type="pmid">22959347</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marlow</surname> <given-names>P. J.</given-names></name>, <name name-style="western"><surname>Todorovic</surname> <given-names>D.</given-names></name>, &amp; <name name-style="western"><surname>Anderson</surname> <given-names>B. L.</given-names></name> (<year>2015</year>). <article-title>Coupled computations of three-dimensional shape and material</article-title>. <source><italic>Current Biology</italic></source>, <volume>25</volume>(<issue>6</issue>), <fpage>R221</fpage>–<lpage>222</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2015.01.062" xlink:type="simple">10.1016/j.cub.2015.01.062</ext-link></comment> <object-id pub-id-type="pmid">25784037</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koenderink</surname> <given-names>J. J.</given-names></name>, &amp; <name name-style="western"><surname>van Doorn</surname> <given-names>A. J.</given-names></name> (<year>1980</year>). <article-title>Photometric invariants related to solid shape</article-title>. <source><italic>Journal of Modern Optics</italic></source>, <volume>27</volume>(<issue>7</issue>), <fpage>981</fpage>–<lpage>996</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref020"><label>20</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Koenderink</surname> <given-names>J. J.</given-names></name> <name name-style="western"><surname>van Doorn</surname> <given-names>A. J.</given-names></name> (<year>2003</year>). <chapter-title>Shape and shading</chapter-title>. In <name name-style="western"><surname>Chalupa</surname> <given-names>L. M. J. S.</given-names></name>, <name name-style="western"><surname>Werner</surname></name> (Eds.), <source><italic>The visual neurosciences</italic></source> (pp. <fpage>1090</fpage>–<lpage>1105</lpage>). <publisher-loc>Cambridge</publisher-loc>: <publisher-name>MIT Press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref021"><label>21</label><mixed-citation publication-type="other" xlink:type="simple">Breton, P., &amp; Zucker, S. W. (1996). Shadows and shading flow fields. <italic>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, 782–789</mixed-citation></ref>
<ref id="pcbi.1006061.ref022"><label>22</label><mixed-citation publication-type="other" xlink:type="simple">Ben-Shahar, O., &amp; Zucker, S. W. (2001). On the perceptual organization of texture and shading flows: From a geometrical model to coherence computation. <italic>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, 1048–1055.</mixed-citation></ref>
<ref id="pcbi.1006061.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleming</surname> <given-names>R. W.</given-names></name>, <name name-style="western"><surname>Torralba</surname> <given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Adelson</surname> <given-names>E. H.</given-names></name> (<year>2004</year>). <article-title>Specular reflections and the perception of shape</article-title>. <source><italic>Journal of Vision</italic></source>, <volume>4</volume>(<issue>9</issue>), <fpage>798</fpage>–<lpage>820</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/4.9.10" xlink:type="simple">10.1167/4.9.10</ext-link></comment> <object-id pub-id-type="pmid">15493971</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref024"><label>24</label><mixed-citation publication-type="other" xlink:type="simple">Fleming RW, Torralba A, Adelson EH (2009) Shape from sheen. MIT Tech Report, MIT- CSAIL-TR-2009-051. Available at <ext-link ext-link-type="uri" xlink:href="http://hdl.handle.net/1721.1/49511" xlink:type="simple">http://hdl.handle.net/1721.1/49511</ext-link>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleming</surname> <given-names>R. W.</given-names></name>, <name name-style="western"><surname>Holtmann-Rice</surname> <given-names>D.</given-names></name>, &amp; <name name-style="western"><surname>Bülthoff</surname> <given-names>H. H.</given-names></name> (<year>2011</year>). <article-title>Estimation of 3D shape from image orientations</article-title>. <source><italic>Proceedings of the National Academy of Sciences</italic></source>, <volume>108</volume>(<issue>51</issue>), <fpage>20438</fpage>–<lpage>20443</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kunsberg</surname> <given-names>B.</given-names></name>, &amp; <name name-style="western"><surname>Zucker</surname> <given-names>S. W.</given-names></name> (<year>2014</year>). <article-title>How shading constrains surface patches without knowledge of light sources</article-title>. <source><italic>SIAM Journal on Imaging Sciences</italic></source>, <volume>7</volume>(<issue>2</issue>), <fpage>641</fpage>–<lpage>668</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vergne</surname> <given-names>R.</given-names></name>, <name name-style="western"><surname>Barla</surname> <given-names>P.</given-names></name>, <name name-style="western"><surname>Bonneau</surname> <given-names>G. P.</given-names></name>, and <name name-style="western"><surname>Fleming</surname> <given-names>R. W.</given-names></name> (<year>2016</year>). <article-title>Flow-guided warping for image-based shape manipulation</article-title>. <source><italic>ACM Transactions on Graphics (TOG)</italic></source>, <volume>35</volume>(<issue>4</issue>), <fpage>93:1</fpage>–<lpage>93:12</lpage></mixed-citation></ref>
<ref id="pcbi.1006061.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Matusik</surname> <given-names>W.</given-names></name>, <name name-style="western"><surname>Pfister</surname> <given-names>H.</given-names></name>, <name name-style="western"><surname>Brand</surname> <given-names>M.</given-names></name>, &amp; <name name-style="western"><surname>McMillan</surname> <given-names>L.</given-names></name> (<year>2003</year>). <article-title>A Data-Driven Reflectance Model</article-title>. <source><italic>ACM Transactions on Graphics</italic></source>, <volume>22</volume>(<issue>3</issue>), <fpage>759</fpage>–<lpage>769</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref029"><label>29</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Jammalamadaka</surname> <given-names>S. R.</given-names></name>, &amp; <name name-style="western"><surname>Sengupta</surname> <given-names>A.</given-names></name> (<year>2001</year>). <chapter-title>Topics in circular statistics</chapter-title> (Vol. <volume>5</volume>), <publisher-name>World Scientific</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berens</surname> <given-names>P.</given-names></name> (<year>2009</year>). <article-title>CircStat: a MATLAB toolbox for circular statistics</article-title>. <source><italic>Journal of Statistical Software</italic></source>, <volume>31</volume>(<issue>10</issue>), <fpage>1</fpage>–<lpage>21</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref031"><label>31</label><mixed-citation publication-type="other" xlink:type="simple">Dalal, N., &amp; Triggs, B. (2005). Histograms of oriented gradients for human detection. <italic>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, 886–893</mixed-citation></ref>
<ref id="pcbi.1006061.ref032"><label>32</label><mixed-citation publication-type="other" xlink:type="simple">Wang, X., Han, T. X., &amp; Yan, S. (2009). An HOG-LBP human detector with partial occlusion handling. <italic>In Proceedings of the IEEE Conference on International Conference on Computer Vision (ICCV)</italic>, 32–39.</mixed-citation></ref>
<ref id="pcbi.1006061.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tola</surname> <given-names>E.</given-names></name>, <name name-style="western"><surname>Lepetit</surname> <given-names>V.</given-names></name>, &amp; <name name-style="western"><surname>Fua</surname> <given-names>P.</given-names></name> (<year>2010</year>). <article-title>Daisy: An efficient dense descriptor applied to wide-baseline stereo</article-title>. <source><italic>IEEE transactions on pattern analysis and machine intelligence</italic></source>, <volume>32</volume>(<issue>5</issue>), <fpage>815</fpage>–<lpage>830</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TPAMI.2009.77" xlink:type="simple">10.1109/TPAMI.2009.77</ext-link></comment> <object-id pub-id-type="pmid">20299707</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref034"><label>34</label><mixed-citation publication-type="other" xlink:type="simple">Wang, Z., Fan, B., &amp; Wu, F. (2011). Local intensity order pattern for feature description. <italic>In Proceedings of the IEEE Conference on International Conference on Computer Vision (ICCV)</italic>, 603–610.</mixed-citation></ref>
<ref id="pcbi.1006061.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koenderink</surname> <given-names>J. J.</given-names></name>, <name name-style="western"><surname>Van Doorn</surname> <given-names>A. J.</given-names></name>, &amp; <name name-style="western"><surname>Kappers</surname> <given-names>A. M.</given-names></name> (<year>1992</year>). <article-title>Surface perception in pictures</article-title>. <source><italic>Perception &amp; Psychophysics</italic></source>, <volume>52</volume>(<issue>5</issue>), <fpage>487</fpage>–<lpage>496</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref036"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Todd</surname> <given-names>J. T.</given-names></name>, &amp; <name name-style="western"><surname>Mingolla</surname> <given-names>E.</given-names></name> (<year>1983</year>). <article-title>Perception of surface curvature and direction of illumination from patterns of shading</article-title>. <source><italic>Journal of Experimental Psychology</italic>: <italic>Human perception and performance</italic></source>, <volume>9</volume>(<issue>4</issue>), <fpage>583</fpage>–<lpage>595</lpage>. <object-id pub-id-type="pmid">6224894</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nefs</surname> <given-names>H. T.</given-names></name>, <name name-style="western"><surname>Koenderink</surname> <given-names>J. J.</given-names></name>, &amp; <name name-style="western"><surname>Kappers</surname> <given-names>A. M.</given-names></name> (<year>2006</year>). <article-title>Shape-from-shading for matte and glossy objects</article-title>. <source><italic>Acta Psychologica</italic></source>, <volume>121</volume>(<issue>3</issue>), <fpage>297</fpage>–<lpage>316</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.actpsy.2005.08.001" xlink:type="simple">10.1016/j.actpsy.2005.08.001</ext-link></comment> <object-id pub-id-type="pmid">16181604</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pont</surname> <given-names>S. C.</given-names></name>, &amp; <name name-style="western"><surname>Pas</surname> <given-names>S. F. t.</given-names></name> (<year>2006</year>). <article-title>Material–illumination ambiguities and the perception of solid objects</article-title>. <source><italic>Perception</italic></source>, <volume>35</volume>(<issue>10</issue>), <fpage>1331</fpage>–<lpage>1350</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1068/p5440" xlink:type="simple">10.1068/p5440</ext-link></comment> <object-id pub-id-type="pmid">17214380</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Khang</surname> <given-names>B.-G.</given-names></name>, <name name-style="western"><surname>Koenderink</surname> <given-names>J. J.</given-names></name>, &amp; <name name-style="western"><surname>Kappers</surname> <given-names>A. M. L.</given-names></name> (<year>2007</year>). <article-title>Shape from shading from images rendered with various surface types and light fields</article-title>. <source><italic>Perception</italic></source>, <volume>36</volume>(<issue>8</issue>), <fpage>1191</fpage>–<lpage>1213</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1068/p5807" xlink:type="simple">10.1068/p5807</ext-link></comment> <object-id pub-id-type="pmid">17972483</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleming</surname> <given-names>R.W.</given-names></name> and <name name-style="western"><surname>Bülthoff</surname> <given-names>H. H.</given-names></name> (<year>2005</year>). <article-title>Low-level image cues in the perception of translucent materials</article-title>. <source><italic>ACM Transactions on Applied Perception</italic></source>, <volume>2</volume>(<issue>3</issue>), <fpage>346</fpage>–<lpage>382</lpage></mixed-citation></ref>
<ref id="pcbi.1006061.ref041"><label>41</label><mixed-citation publication-type="other" xlink:type="simple">Motoyoshi, I., Nishida, S. &amp; Adelson, E.H. (2005). Luminance re-mapping for the control of apparent material. <italic>Second Symposium on Applied Perception in Graphics and Visualization (APGV 2005 /ACM)</italic>, 165. [APGV 2005]</mixed-citation></ref>
<ref id="pcbi.1006061.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Boyadzhiev</surname> <given-names>I.</given-names></name>, <name name-style="western"><surname>Bala</surname> <given-names>K.</given-names></name>, <name name-style="western"><surname>Paris</surname> <given-names>S.</given-names></name>, &amp; <name name-style="western"><surname>Adelson</surname> <given-names>E.</given-names></name> (<year>2015</year>). <article-title>Band-sifting decomposition for image-based material editing</article-title>. <source><italic>ACM Transactions on Graphics (TOG)</italic></source>, <volume>34</volume>(<issue>5</issue>), <fpage>163</fpage>:1–163:16.</mixed-citation></ref>
<ref id="pcbi.1006061.ref043"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wijntjes</surname> <given-names>M. W. A.</given-names></name>, <name name-style="western"><surname>Doerschner</surname> <given-names>K.</given-names></name>, <name name-style="western"><surname>Kucukoglu</surname> <given-names>G.</given-names></name>, &amp; <name name-style="western"><surname>Pont</surname> <given-names>S. C.</given-names></name> (<year>2012</year>). <article-title>Relative flattening between velvet and matte 3D shapes: Evidence for similar shape-from-shading computations</article-title>. <source><italic>Journal of Vision</italic></source>, <volume>12</volume>(<issue>1</issue>):<fpage>2</fpage>, 1–11, <ext-link ext-link-type="uri" xlink:href="http://www.journalofvision.org/content/12/1/2" xlink:type="simple">http://www.journalofvision.org/content/12/1/2</ext-link>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/12.1.2" xlink:type="simple">10.1167/12.1.2</ext-link></comment> <object-id pub-id-type="pmid">22214564</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref044"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mooney</surname> <given-names>S. W.</given-names></name>, &amp; <name name-style="western"><surname>Anderson</surname> <given-names>B. L.</given-names></name> (<year>2014</year>). <article-title>Specular image structure modulates the perception of three-dimensional shape</article-title>. <source><italic>Current Biology</italic></source>, <volume>24</volume>(<issue>22</issue>), <fpage>2737</fpage>–<lpage>2742</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2014.09.074" xlink:type="simple">10.1016/j.cub.2014.09.074</ext-link></comment> <object-id pub-id-type="pmid">25455034</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Todd</surname> <given-names>J. T.</given-names></name>, <name name-style="western"><surname>Egan</surname> <given-names>E. J.</given-names></name>, &amp; <name name-style="western"><surname>Phillips</surname> <given-names>F.</given-names></name> (<year>2014</year>). <article-title>Is the perception of 3D shape from shading based on assumed reflectance and illumination?</article-title> <source><italic>i-Perception</italic></source>, <volume>5</volume>(<issue>6</issue>), <fpage>497</fpage>–<lpage>514</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1068/i0645" xlink:type="simple">10.1068/i0645</ext-link></comment> <object-id pub-id-type="pmid">26034561</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Belhumeur</surname> <given-names>P. N.</given-names></name>, <name name-style="western"><surname>Kriegman</surname> <given-names>D. J.</given-names></name>, &amp; <name name-style="western"><surname>Yuille</surname> <given-names>A. L.</given-names></name> (<year>1999</year>). <article-title>The bas-relief ambiguity</article-title>. <source><italic>International journal of computer vision</italic></source>, <volume>35</volume>(<issue>1</issue>), <fpage>33</fpage>–<lpage>44</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koenderink</surname> <given-names>J.</given-names></name>, <name name-style="western"><surname>van Doorn</surname> <given-names>A.</given-names></name>, &amp; <name name-style="western"><surname>Wagemans</surname> <given-names>J.</given-names></name> (<year>2014</year>). <article-title>Local shape of pictorial relief</article-title>. <source><italic>i-Perception</italic></source>, <volume>5</volume>(<issue>3</issue>), <fpage>188</fpage>–<lpage>204</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1068/i0659" xlink:type="simple">10.1068/i0659</ext-link></comment> <object-id pub-id-type="pmid">25469225</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleming</surname> <given-names>R. W.</given-names></name> , <name name-style="western"><surname>Bülthoff</surname> <given-names>H. H.</given-names></name>; <article-title>Orientation fields in the perception of 3D shape</article-title>. <source><italic>Journal of Vision</italic></source> <year>2005</year>;<volume>5</volume>(<issue>8</issue>):<fpage>525</fpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleming</surname> <given-names>R.</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>Y.</given-names></name>, <name name-style="western"><surname>Adelson</surname> <given-names>E. H.</given-names></name>; <article-title>Image statistics for 3D shape estimation</article-title>. <source><italic>Journal of Vision</italic></source> <year>2008</year>;<volume>8</volume>(<issue>6</issue>):<fpage>76</fpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fleming</surname> <given-names>R.</given-names></name>, <name name-style="western"><surname>Vergne</surname> <given-names>R.</given-names></name>, <name name-style="western"><surname>Zucker</surname> <given-names>S.</given-names></name>; <article-title>Predicting the effects of illumination in shape from shading</article-title>. <source><italic>Journal of Vision</italic></source> <year>2013</year>;<volume>13</volume>(<issue>9</issue>):<fpage>611</fpage></mixed-citation></ref>
<ref id="pcbi.1006061.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Giesel</surname> <given-names>M.</given-names></name>, &amp; <name name-style="western"><surname>Zaidi</surname> <given-names>Q.</given-names></name> (<year>2013</year>). <article-title>Frequency-based heuristics for material perception</article-title>. <source><italic>Journal of Vision</italic></source>, <volume>13</volume>(<issue>14</issue>):<fpage>7</fpage>, 1–19, <ext-link ext-link-type="uri" xlink:href="http://www.journalofvision.org/content/13/14/7" xlink:type="simple">http://www.journalofvision.org/content/13/14/7</ext-link>, <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/13.14.7" xlink:type="simple">10.1167/13.14.7</ext-link></comment> <object-id pub-id-type="pmid">24317425</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koenderink</surname> <given-names>J. J.</given-names></name>, <name name-style="western"><surname>van Doorn</surname> <given-names>A. J.</given-names></name>, <name name-style="western"><surname>Kappers</surname> <given-names>A. M.</given-names></name>, &amp; <name name-style="western"><surname>Todd</surname> <given-names>J. T.</given-names></name> (<year>2001</year>). <article-title>Ambiguity and the ‘mental eye’in pictorial relief</article-title>. <source><italic>Perception</italic></source>, <volume>30</volume>(<issue>4</issue>), <fpage>431</fpage>–<lpage>448</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1068/p3030" xlink:type="simple">10.1068/p3030</ext-link></comment> <object-id pub-id-type="pmid">11383191</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Land</surname> <given-names>E. H.</given-names></name>, &amp; <name name-style="western"><surname>McCann</surname> <given-names>J. J.</given-names></name> (<year>1971</year>). <article-title>Lightness and retinex theory</article-title>. <source><italic>Journal of the Optical Society of America A</italic></source>, <volume>61</volume>(<issue>1</issue>), <fpage>1</fpage>–<lpage>11</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freeman</surname> <given-names>W. T.</given-names></name>, &amp; <name name-style="western"><surname>Viola</surname> <given-names>P. A.</given-names></name> (<year>1998</year>). <article-title>Bayesian model of surface perception</article-title>. <source><italic>Advances in Neural Information Processing Systems</italic></source>, <volume>10</volume>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref055"><label>55</label><mixed-citation publication-type="other" xlink:type="simple">Bell, M., &amp; Freeman, W. T. (2001). Learning local evidence for shading and reflectance. <italic>In Proceedings of the IEEE Conference on International Conference on Computer Vision (ICCV)</italic>, 670–677</mixed-citation></ref>
<ref id="pcbi.1006061.ref056"><label>56</label><mixed-citation publication-type="other" xlink:type="simple">Tappen, M. F., Adelson, E. H., &amp; Freeman, W. T. (2006). Estimating intrinsic component images using non-linear regression. <italic>In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</italic>, 1992–1999</mixed-citation></ref>
<ref id="pcbi.1006061.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zhao</surname> <given-names>Q.</given-names></name>, <name name-style="western"><surname>Tan</surname> <given-names>P.</given-names></name>, <name name-style="western"><surname>Dai</surname> <given-names>Q.</given-names></name>, <name name-style="western"><surname>Shen</surname> <given-names>L.</given-names></name>, <name name-style="western"><surname>Wu</surname> <given-names>E.</given-names></name>, &amp; <name name-style="western"><surname>Lin</surname> <given-names>S.</given-names></name> (<year>2012</year>). <article-title>A closed-form solution to retinex with nonlocal texture constraints</article-title>.<source><italic>IEEE Transactions on Pattern Analysis and Machine Intelligence</italic></source>, <volume>34</volume>(<issue>7</issue>), <fpage>1437</fpage>–<lpage>1444</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TPAMI.2012.77" xlink:type="simple">10.1109/TPAMI.2012.77</ext-link></comment> <object-id pub-id-type="pmid">22450820</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref058"><label>58</label><mixed-citation publication-type="other" xlink:type="simple">Barron, J., &amp; Malik, J. (2013). Shape, illumination, and reflectance from shading.</mixed-citation></ref>
<ref id="pcbi.1006061.ref059"><label>59</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bell</surname> <given-names>S.</given-names></name>, <name name-style="western"><surname>Bala</surname> <given-names>K.</given-names></name>, &amp; <name name-style="western"><surname>Snavely</surname> <given-names>N.</given-names></name> (<year>2014</year>). <article-title>Intrinsic images in the wild</article-title>. <source><italic>ACM Transactions on Graphics (TOG)</italic></source>, <volume>33</volume>(<issue>4</issue>), <fpage>159</fpage>:1–159:12.</mixed-citation></ref>
<ref id="pcbi.1006061.ref060"><label>60</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nishio</surname> <given-names>A.</given-names></name>, <name name-style="western"><surname>Goda</surname> <given-names>N.</given-names></name>, &amp; <name name-style="western"><surname>Komatsu</surname> <given-names>H.</given-names></name> (<year>2012</year>). <article-title>Neural selectivity and representation of gloss in the monkey inferior temporal cortex</article-title>. <source><italic>Journal of Neuroscience</italic></source>, <volume>32</volume>(<issue>31</issue>), <fpage>10780</fpage>–<lpage>10793</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1095-12.2012" xlink:type="simple">10.1523/JNEUROSCI.1095-12.2012</ext-link></comment> <object-id pub-id-type="pmid">22855825</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref061"><label>61</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nishio</surname> <given-names>A.</given-names></name>, <name name-style="western"><surname>Shimokawa</surname> <given-names>T.</given-names></name>, <name name-style="western"><surname>Goda</surname> <given-names>N.</given-names></name>, &amp; <name name-style="western"><surname>Komatsu</surname> <given-names>H.</given-names></name> (<year>2014</year>). <article-title>Perceptual gloss parameters are encoded by population responses in the monkey inferior temporal cortex</article-title>. <source><italic>Journal of Neuroscience</italic></source>, <volume>34</volume>(<issue>33</issue>), <fpage>11143</fpage>–<lpage>11151</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.1451-14.2014" xlink:type="simple">10.1523/JNEUROSCI.1451-14.2014</ext-link></comment> <object-id pub-id-type="pmid">25122910</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref062"><label>62</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miyakawa</surname> <given-names>N.</given-names></name>, <name name-style="western"><surname>Banno</surname> <given-names>T.</given-names></name>, <name name-style="western"><surname>Abe</surname> <given-names>H.</given-names></name>, <name name-style="western"><surname>Tani</surname> <given-names>T.</given-names></name>, <name name-style="western"><surname>Suzuki</surname> <given-names>W.</given-names></name>, &amp; <name name-style="western"><surname>Ichinohe</surname> <given-names>N.</given-names></name> (<year>2017</year>). <article-title>Representation of Glossy Material Surface in Ventral Superior Temporal Sulcal Area of Common Marmosets</article-title>. <source><italic>Frontiers in Neural Circuits</italic></source>, <volume>11</volume>, <fpage>17</fpage>, 1–15. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fncir.2017.00017" xlink:type="simple">10.3389/fncir.2017.00017</ext-link></comment> <object-id pub-id-type="pmid">28367117</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref063"><label>63</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Pharr</surname> <given-names>M.</given-names></name>, &amp; <name name-style="western"><surname>Humphreys</surname> <given-names>G.</given-names></name> (<year>2004</year>). <chapter-title>Physically based rendering: From theory to implementation</chapter-title>, <publisher-name>Morgan Kaufmann</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref064"><label>64</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Farid</surname> <given-names>H.</given-names></name>, &amp; <name name-style="western"><surname>Simoncelli</surname> <given-names>E. P.</given-names></name> (<year>2004</year>). <article-title>Differentiation of discrete multidimensional signals</article-title>.<source><italic>IEEE Transactions on Image Processing</italic></source>, <volume>13</volume>(<issue>4</issue>), <fpage>496</fpage>–<lpage>508</lpage>. <object-id pub-id-type="pmid">15376584</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref065"><label>65</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brainard</surname> <given-names>D. H.</given-names></name> (<year>1997</year>). <article-title>The Psychophysics Toolbox</article-title>. <source><italic>Spatial Vision</italic></source>, <volume>10</volume>(<issue>4</issue>), <fpage>433</fpage>–<lpage>436</lpage>. <object-id pub-id-type="pmid">9176952</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref066"><label>66</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pelli</surname> <given-names>D. G.</given-names></name> (<year>1997</year>). <article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title>. <source><italic>Spatial Vision</italic></source>, <volume>10</volume>(<issue>4</issue>), <fpage>437</fpage>–<lpage>442</lpage>. <object-id pub-id-type="pmid">9176953</object-id></mixed-citation></ref>
<ref id="pcbi.1006061.ref067"><label>67</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ward</surname> <given-names>G. J.</given-names></name> (<year>1992</year>). <article-title>Measuring and modeling anisotropic reflection</article-title>. <source><italic>ACM SIGGRAPH Computer Graphics</italic></source>, <volume>26</volume>(<issue>2</issue>), <fpage>265</fpage>–<lpage>272</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref068"><label>68</label><mixed-citation publication-type="other" xlink:type="simple">Curless, B., &amp; Levoy, M. (1996). A volumetric method for building complex models from range images. <italic>In Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques, ser. SIGGRAPH ‘96</italic>, 303–312.</mixed-citation></ref>
<ref id="pcbi.1006061.ref069"><label>69</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Debevec</surname> <given-names>P.</given-names></name> (<year>2002</year>). <article-title>Image-based lighting</article-title>. <source><italic>IEEE Computer Graphics and Applications</italic></source>(<issue>2</issue>), <fpage>26</fpage>–<lpage>34</lpage>.</mixed-citation></ref>
<ref id="pcbi.1006061.ref070"><label>70</label><mixed-citation publication-type="other" xlink:type="simple">Jakob, W. (2010). Mitsuba physically based renderer. <ext-link ext-link-type="uri" xlink:href="http://mitsuba-renderer.org" xlink:type="simple">mitsuba-renderer.org</ext-link>.</mixed-citation></ref>
</ref-list>
</back>
</article>
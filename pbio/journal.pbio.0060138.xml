<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pbio</journal-id><journal-id journal-id-type="allenpress-id">plbi</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="doi">10.1371/journal.pbio.0060138</article-id><article-id pub-id-type="publisher-id">07-PLBI-RA-3763R3</article-id><article-id pub-id-type="sici">plbi-06-06-05</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Neural Correlates of Auditory Perceptual Awareness under Informational Masking</article-title><alt-title alt-title-type="running-head">Auditory Awareness and Informational Masking</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Gutschalk</surname>
            <given-names>Alexander</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Micheyl</surname>
            <given-names>Christophe</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Oxenham</surname>
            <given-names>Andrew J</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1">
				<label>1</label><addr-line> Department of Neurology, Ruprecht-Karls-Universität Heidelberg, Heidelberg, Germany
			</addr-line></aff><aff id="aff2">
				<label>2</label><addr-line> Department of Psychology, University of Minnesota, Minneapolis, Minnesota, United States of America
			</addr-line></aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Griffiths</surname>
            <given-names>Timothy D</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Newcastle University Medical School, United Kingdom</aff><author-notes>
        <corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">Alexander.Gutschalk@med.uni-heidelberg.de</email></corresp>
        <fn fn-type="con" id="ack1">
          <p> AG, CM, and AJO conceived and designed the experiments. AG performed the experiments. AG analyzed the data. AG, CM, and AJO wrote the paper.</p>
        </fn>
      <fn fn-type="conflict" id="ack3">
        <p> The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="ppub">
        <month>6</month>
        <year>2008</year>
      </pub-date><pub-date pub-type="epub">
        <day>10</day>
        <month>6</month>
        <year>2008</year>
      </pub-date><volume>6</volume><issue>6</issue><elocation-id>e138</elocation-id><history>
        <date date-type="received">
          <day>12</day>
          <month>11</month>
          <year>2007</year>
        </date>
        <date date-type="accepted">
          <day>23</day>
          <month>4</month>
          <year>2008</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2008</copyright-year><copyright-holder> Gutschalk et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><related-article ext-link-type="doi" id="RA1" page="e155" related-article-type="companion" vol="6" xlink:href="info:doi/10.1371/journal.pbio.0060155" xlink:title="Primer" xlink:type="simple">
				<article-title>On the Emergence and Awareness of Auditory Objects</article-title>
			</related-article><abstract>
        <p>Our ability to detect target sounds in complex acoustic backgrounds is often limited not by the ear's resolution, but by the brain's information-processing capacity. The neural mechanisms and loci of this “informational masking” are unknown. We combined magnetoencephalography with simultaneous behavioral measures in humans to investigate neural correlates of informational masking and auditory perceptual awareness in the auditory cortex. Cortical responses were sorted according to whether or not target sounds were detected by the listener in a complex, randomly varying multi-tone background known to produce informational masking. Detected target sounds elicited a prominent, long-latency response (50–250 ms), whereas undetected targets did not. In contrast, both detected and undetected targets produced equally robust auditory middle-latency, steady-state responses, presumably from the primary auditory cortex. These findings indicate that neural correlates of auditory awareness in informational masking emerge between early and late stages of processing within the auditory cortex.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <sec id="st1">
          <title/>
          <p>Sounds that are well above the sensory threshold may sometimes fail to be perceived when they occur amid competing sounds, as often happens in everyday life. This phenomenon is generally referred to as “informational masking.” We took advantage of this effect to isolate brain responses that correlate with conscious auditory perception. Human listeners performed an auditory detection task in which they had to indicate when they heard a stream of repeating tones (targets) embedded in a stochastic tone background (masker). At the same time, brain responses were recorded using magnetoencephalography. By comparing the responses to perceptually detected and undetected target tones in the auditory cortex, we isolated a neural response component in the latency range of 50–250 ms, which was only present for detected sounds. We propose that this component, the “awareness related negativity,” specifically reflects conscious sound perception. In contrast, earlier responses in the auditory cortex were evoked by both detected and undetected target tones. These results suggest that conscious sound perception emerges from within the auditory cortex.</p>
        </sec>
      </abstract><abstract abstract-type="toc">
        <p>How does the brain process sound when we can't always be aware of all auditory information at once? A new study shows that auditory processing depends on whether the sound is consciously perceived.</p>
      </abstract><funding-group><funding-statement> Work supported by Deutsche Forschungsgemeinschaft (DFG) grant GU 593/3–1 (to AG), Bundesministerium für Bildung und Forschung (BMBF) junior research group bioimaging, grant 01EV0712 (to AG), the Dietmar-Hopp-Stiftung, and National Institute on Deafness and Other Communication Disorders (NIDCD) grant R01 DC07657 (to AJO).</funding-statement></funding-group><counts>
        <page-count count="10"/>
      </counts><!--===== Restructure custom-meta-wrap to custom-meta-group =====--><custom-meta-group>
        <custom-meta>
          <meta-name>citation</meta-name>
          <meta-value>Gutschalk A, Micheyl C, Oxenham AJ (2008) Neural correlates of auditory perceptual awareness under informational masking. PLoS Biol 6(6): e138. <ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0060138" xlink:type="simple">10.1371/journal.pbio.0060138</ext-link></meta-value>
        </custom-meta>
      </custom-meta-group></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>On a busy street corner, in a crowded restaurant, or in a rainforest at twilight, the sounds emitted from multiple sources mix together to form a highly convoluted and complex acoustic environment. Ecologically relevant warning or mating calls, or the speech from your neighbor at a restaurant table, must be heard out of this background cacophony. When a certain sound is not heard out of a background mixture, it is said to be masked. Many examples of masking can be explained in terms of the way sounds are processed in the inner ear, or cochlea [<xref ref-type="bibr" rid="pbio-0060138-b001">1</xref>]. The background or masking sound produces a pattern of excitation in the cochlea that either swamps or suppresses the activity due to the target sound, so that the target is no longer accurately represented in the auditory nerve [<xref ref-type="bibr" rid="pbio-0060138-b002">2</xref>]. This form of masking, traditionally known as “energetic masking,” has been the subject of most formal psychophysical studies of masking dating back nearly 100 years [<xref ref-type="bibr" rid="pbio-0060138-b003">3</xref>]. In general such masking, measured behaviorally, corresponds well to predictions based on physiological measurements from the cochlea or auditory nerve [<xref ref-type="bibr" rid="pbio-0060138-b004">4</xref>,<xref ref-type="bibr" rid="pbio-0060138-b005">5</xref>]. The maskers and targets used in such experiments are typically predictable (i.e., the same sounds are presented over many repetitions), and are easily distinguished from one another.</p>
      <p>More recently it has become clear that the principles and predictions of energetic masking may not hold in many natural situations, where competing sounds are neither predictable nor readily distinguishable. Masking under conditions of uncertainty and timbral similarity has been referred to as “informational masking.” The term informational masking, which was initially applied to the perception of elemental sounds, such as pure tones [<xref ref-type="bibr" rid="pbio-0060138-b006">6</xref>,<xref ref-type="bibr" rid="pbio-0060138-b007">7</xref>], has more recently been applied to a wide range of contexts, including the masking of speech by other speech sounds [<xref ref-type="bibr" rid="pbio-0060138-b008">8</xref>]. Although it is unlikely that the same mechanisms underlie all forms of informational masking, they all have in common that the effects cannot be explained in terms of interactions in the auditory periphery (the cochlea and auditory nerve) [<xref ref-type="bibr" rid="pbio-0060138-b009">9</xref>]. In this study, we investigated the neural correlates of informational masking as it applies to the detection of a target tone sequence embedded in a random multi-tone background.</p>
      <p>Where and how informational masking occurs in the auditory system remains unknown. In fact, with our current state of knowledge, informational masking may originate at any processing stage along the auditory pathways, from the cochlear nucleus in the brainstem, up to (and possibly beyond) the auditory cortex (AC). We combined a behavioral informational masking paradigm with simultaneous magnetoencephalography (MEG) recordings in humans to investigate the role of the AC in informational masking in particular, and auditory awareness in general.</p>
      <p>Our listeners' task was to detect a stream of regularly repeating target tones against a background of masking tones that were randomly placed in time and frequency (<xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>A). The stimuli are similar to those used in earlier studies of informational masking using random multi-tone backgrounds [<xref ref-type="bibr" rid="pbio-0060138-b010">10</xref>,<xref ref-type="bibr" rid="pbio-0060138-b011">11</xref>], with the exception that our masking tones were not synchronized with the target tones. This desynchronization allowed us to separate the time-locked MEG responses evoked by the target tones from those evoked by the masker tones.</p>
      <fig id="pbio-0060138-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0060138.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Experiment 1A and 1B</title>
          <p>(A) Schematic spectrogram of the stimulus paradigm, arranged in 18 log-spaced frequency bands (239–5,000 Hz). The target (black) was a regularly repeating tone (489–2,924 Hz). Two frequency bands above and below the target were kept as protected region; masker tones were present in the remaining frequency bands. The stimulus-onset asynchrony (SOA, interval between the onsets of two subsequent tones) within a masker band was randomized with an average SOA of 200 ms (left panel) or 800 ms (right panel).</p>
          <p>(B) Average detection probability across listeners (± 1 s.e.m.) for the 200-ms (filled circles) and the 800-ms SOA masker condition (open circles) over time. False positive responses were derived from masker-only conditions. Because the listeners' task was to indicate when they detected repeating target tones, which required that they detected at least two consecutive target tones, the two target tones preceding a detection response (key press) were counted as detected tones in our analysis of behavioral responses.</p>
          <p>(C) Location of ARN dipoles in the AC for a sample listener.</p>
          <p>(D) Source waveforms averaged over hemispheres, SOA-conditions, and listeners. Confidence intervals indicate <italic>t</italic>-intervals (<italic>p</italic> &lt; 0.05, two-tailed). As for the behavioral data, the two target tones that preceded a key press were considered detected.</p>
          <p>(E) Average amplitudes in the time range 75–175 ms after target-tone onset (± 1 s.e.m.), for left (blue) and right (red) AC. The data on the left represent the data from the 200-ms, the middle set the data from the 800-ms masker SOA, and the right-most set the control data with unmasked targets.</p>
          <p>(F) MEG-source amplitudes for each separate target repetition (mean ± 1 s.e.m., time-range 75–175 ms; average across hemispheres and SOA conditions; <italic>n</italic> = 12).</p>
          <p>(G) MEG-source amplitudes for each separate target-frequency band (mean ± 1 s.e.m., <italic>n</italic> = 12, except detected targets at 2.0 kHz: <italic>n</italic> = 11).</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.g001" xlink:type="simple"/>
      </fig>
      <p>To limit the contribution of energetic masking and peripheral interactions between the targets and maskers, the target tones were separated from the masking tones by a fixed minimum frequency gap or “protected region.” A frequency gap also promotes the perceptual segregation of target and masker tones into distinct sound “streams,” making it easier for listeners to identify the regularly repeating, constant-frequency target tones amid the randomly varying masker tones [<xref ref-type="bibr" rid="pbio-0060138-b012">12</xref>–<xref ref-type="bibr" rid="pbio-0060138-b014">14</xref>]. Although the presence of the target is obvious in the visual representation of <xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>A, the targets in this configuration were not clearly audible; in fact, listeners reported hearing them on only about half the presentations. On some trials, the target tones “popped out” from the background and became clearly audible well before the end of the stimulus sequence; on other trials they were not heard at all. Such dramatic changes in perception from one trial to the next are typical in informational masking experiments. Because detection in this task is not associated with systematic changes in the physical stimuli (the exact same stimulus can elicit detection on one occasion and not on another), this paradigm provides ideal conditions for identifying neural correlates of auditory awareness, independent of both physical stimulus manipulations and peripheral auditory interactions.</p>
      <p>We compared MEG signals that were time-locked to either detected or undetected target tones in the AC. We identified robust early AC responses (the middle-latency steady-state responses—SSR) to the target, which remained the same whether the target was detected or not. Changes in later AC responses, starting approximately 70 ms after target onset, were found to depend critically on whether listeners were aware of the target tones. This longer-latency MEG response was strong when listeners reported hearing the target, but was not measurable when listeners failed to detect the target, or when their attention was directed elsewhere. The finding of robust early neural responses in the AC to sounds, regardless of whether they are detected, in conjunction with later AC responses that are highly correlated with detection, suggests that auditory awareness in a classical informational masking paradigm emerges from within the AC, rather than in lower-level brainstem or higher-level supra-modal cortical structures.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Experiment 1A and 1B: Behavior</title>
        <p>In the first experiment, listeners were presented with 10.4-s stochastic tone sequences generated by adding multiple tone bursts with pseudo-random frequencies and onset times. In two-thirds of these random-onset multi-tone sequences, a tone repeating regularly at a constant frequency throughout the sequence was added (<xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>A). To indicate when they were aware of these targets, listeners were instructed to press a key as soon as they began to hear the regularly repeating target tones against the randomly varying background tones. The probability that listeners detected the target stream increased over the duration of each sequence, reaching on average about 0.6 by the end of the sequence. The rate of false-alarms (i.e., target-detection responses on trials in which only the masker tones were presented) also increased slightly over the course of the stimulus sequence, reflecting listeners' increasing expectation to hear out the target tones, but remained low overall (<xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>B). The listeners' unbiased detection performance, <italic>d'</italic>, computed as the difference between the <italic>z</italic>-transformed hit and false-alarm rates, increased over the duration of the sequence, reaching an average value close to 2 at the end (<xref ref-type="supplementary-material" rid="pbio-0060138-sg001">Figure S1</xref>).</p>
        <p>The experiment was repeated with two different informational maskers: in one (Experiment 1A), the average stimulus-onset asynchrony (SOA), defined as the time interval between the onsets of two consecutive tones within each of the masker frequency bands, was 200 ms; in the other (Experiment 1B), the average SOA was 800 ms, producing a more sparsely populated masking stimulus (compare left and right panels in <xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>A). The behavioral results obtained with these two variants of the experiment were very similar overall (<xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>B). Although hit and false-alarm rates were slightly higher in the 200-ms SOA condition than in the 800-ms SOA condition, the average values of <italic>d'</italic> (1.81 and 1.76, respectively) did not differ significantly from each other (<italic>F</italic><sub>(1,11)</sub> = 0.09; <italic>p</italic> = 0.7674; <xref ref-type="supplementary-material" rid="pbio-0060138-sg001">Figure S1</xref>), indicating that the amount of informational masking was essentially the same in both conditions. Therefore, the data from Experiments 1A and 1B were pooled in most instances for the analyses presented below.</p>
      </sec>
      <sec id="s2b">
        <title>Experiment 1A and 1B: Long-Latency Responses to Detected and Undetected Targets</title>
        <p>To determine whether time-locked brain activity in response to the targets depended on them being consciously detected by the listeners, MEG responses to detected target tones were averaged separately from MEG responses to undetected target tones. Detected targets evoked a prominent bilateral wave with maximal amplitudes on gradiometers positioned over the temporal lobes in the time range from 50 to 250 ms after stimulus onset. The topography of this wave was similar to that of the well-known N<sub>1</sub>m, evoked by single tones in silence. A source analysis with two dipoles, one for each auditory cortex, consistently resulted in dipole locations in Heschl's gyrus or planum temporale, or very close to it, with respect to the listeners' individual magnetic resonance imaging (MRI) anatomy (<xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>C). Averaged across listeners, Talairach coordinates (<xref ref-type="table" rid="pbio-0060138-t001">Table 1</xref>) were located in the central AC, at the border between Heschl's gyrus and planum temporale, as determined in representative populations [<xref ref-type="bibr" rid="pbio-0060138-b015">15</xref>,<xref ref-type="bibr" rid="pbio-0060138-b016">16</xref>]. The variance was similar to that found for other components generated in the auditory cortex [<xref ref-type="bibr" rid="pbio-0060138-b017">17</xref>,<xref ref-type="bibr" rid="pbio-0060138-b018">18</xref>]. The location of fitted dipoles in the presence of the masking tones was not significantly different from the location of the dipoles fitted to the N<sub>1</sub>m measured in the target-alone condition, in the absence of any masking tones (<italic>F</italic><sub>(2,22)</sub> = 0.028; <italic>p</italic> = 0.7603).</p>
        <table-wrap content-type="2col" id="pbio-0060138-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.0060138.t001</object-id><label>Table 1</label><caption>
            <p>Mean Dipole Locations ± Standard Deviations (<italic>n</italic> = 12) in the Space of Talairach and Tournoux (1988)</p>
          </caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.t001" xlink:type="simple"/><!-- <table frame="hsides" rules="none"><colgroup><col id="tb1col1" align="left" charoff="0" char=""/><col id="tb1col2" align="left" charoff="0" char=""/><col id="tb1col3" align="char" charoff="0" char="plusmn"/><col id="tb1col4" align="char" charoff="0" char="plusmn"/><col id="tb1col5" align="char" charoff="0" char="plusmn"/><col id="tb1col6" align="char" charoff="0" char="plusmn"/><col id="tb1col7" align="char" charoff="0" char="plusmn"/><col id="tb1col8" align="char" charoff="0" char="plusmn"/><col id="tb1col9" align="char" charoff="0" char="plusmn"/><col id="tb1col10" align="char" charoff="0" char="plusmn"/></colgroup><thead><tr><td align="left" rowspan="3"><hr/>Experiment</td><td>MEG Component</td><td colspan="6"><hr/>Talairach Coordinates (Mean &plusmn; SD)</td></tr><tr><td colspan="3"><hr/>Left Auditory Cortex</td><td colspan="3"><hr/>Right Auditory Cortex</td></tr><tr><td><hr/></td><td><hr/><italic>x</italic></td><td><hr/><italic>y</italic></td><td><hr/><italic>x</italic></td><td><hr/><italic>x</italic></td><td><hr/><italic>y</italic></td><td><hr/><italic>z</italic></td></tr></thead><tbody><tr><td>1A and 1B</td><td>ARN</td><td>&ndash;51 &plusmn; 5</td><td>&ndash;22 &plusmn; 6</td><td>5 &plusmn; 8</td><td>52 &plusmn; 6</td><td>&ndash;17 &plusmn; 5</td><td>8 &plusmn; 10</td></tr><tr><td>1A and 1B</td><td>N<sub>1</sub>m (no masker)</td><td>&ndash;48 &plusmn; 8</td><td>&ndash;20 &plusmn; 9</td><td>8 &plusmn; 7</td><td>50 &plusmn; 4</td><td>&ndash;18 &plusmn; 5</td><td>5 &plusmn; 7</td></tr><tr><td>1C</td><td>ARN</td><td>&ndash;43 &plusmn; 8</td><td>&ndash;22 &plusmn; 6</td><td>5 &plusmn; 11</td><td>46 &plusmn; 6</td><td>&ndash;17 &plusmn; 7</td><td>8 &plusmn; 7</td></tr><tr><td>1C</td><td>N<sub>1</sub>m (no masker)</td><td>&ndash;44 &plusmn; 5</td><td>&ndash;18 &plusmn; 2</td><td>6 &plusmn; 7</td><td>46 &plusmn; 6</td><td>&ndash;16 &plusmn; 9</td><td>6 &plusmn; 6</td></tr><tr><td>2</td><td>ARN</td><td>&ndash;42 &plusmn; 7</td><td>&ndash;19 &plusmn; 8</td><td>9 &plusmn; 10</td><td>45 &plusmn; 6</td><td>&ndash;13 &plusmn; 5</td><td>9 &plusmn; 9</td></tr><tr><td>2</td><td>N<sub>1</sub>m (no masker)</td><td>&ndash;48 &plusmn; 8</td><td>&ndash;19 &plusmn; 6</td><td>13 &plusmn; 8</td><td>51 &plusmn; 9</td><td>&ndash;16 &plusmn; 7</td><td>12 &plusmn; 7</td></tr><tr><td>2</td><td>SSR (no masker)</td><td>&ndash;46 &plusmn; 8</td><td>&ndash;16 &plusmn; 4</td><td>12 &plusmn; 10</td><td>47 &plusmn; 8</td><td>&ndash;14 &plusmn; 4</td><td>12 &plusmn; 5</td></tr></tbody></table> --><!-- --></table-wrap>
        <p>The fitted dipoles were then used as a spatial filter to generate source waveforms [<xref ref-type="bibr" rid="pbio-0060138-b019">19</xref>], estimating the time course of MEG activity in the auditory cortex. The source waveforms were qualitatively very similar when the detected-target or the target-only conditions were used to fit the dipoles, and the following summary is based on the detected-target conditions. The source waveforms associated with these dipoles are shown in <xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>D (confidence intervals represent bootstrap based <italic>t</italic>-intervals, <italic>p</italic> &lt; 0.05, two-tailed).</p>
        <p>The averaged response to detected target tones showed a prominent negativity (detected versus undetected targets: <italic>F</italic><sub>(1,11)</sub> = 32.15; <italic>p</italic> = 0.0001), peaking around 120–200 ms after tone onset [mean peak latency: 183 ± 14 ms s.e.m. (200-ms-SOA masker); 141 ± 9 ms s.e.m. (800-ms-SOA masker)]. The wave was broad-based, and the deviation of the trace from 0 was statistically significant (<italic>p</italic> &lt; 0.05) everywhere in a 71–283-ms range around the negative peak. There was no significant difference in amplitude (<italic>F</italic><sub>(1,11)</sub> = 0.63; <italic>p</italic> = 0.4425) or latency (<italic>F</italic><sub>(1,11)</sub> = 1.16; <italic>p</italic> = 0.3044) between right and left hemispheres. We refer to the negative wave evoked by the detected tones as the “awareness related negativity” or ARN. This functional label was chosen for convenience and to avoid premature assignment to another response component; it does not imply that the ARN is necessarily a completely separate component of the auditory evoked fields. The ARN peak was somewhat smaller in magnitude and longer in latency than the typical N<sub>1</sub>m evoked by the target tones presented without the masker (lower right panel in <xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>C), which peaked at 108 ms (±10 ms s.e.m), and was significant from 50 to 276 ms post stimulus onset (<italic>p</italic> &lt; 0.05).</p>
        <p>In contrast, the average MEG response to undetected target tones was essentially flat, similar to the average response to sequences containing only the masker and no target (undetected targets versus masker-only trials: <italic>F</italic><sub>(1,11)</sub> = 4.12; <italic>p</italic> = 0.0672). The fact that the no-target trace is flat confirms our expectation that the systematic randomization of masking-tone onset effectively cancelled out the responses to the masking tones. In addition, this trace provides a baseline against which the responses to undetected targets can be compared. The results suggest that the responses to undetected targets are very similar to those found for no targets.</p>
        <sec id="s2b1">
          <title>Potential effects of target order and frequency.</title>
          <p>The behavioral data (<xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>B) show that target tones were more likely to be detected when they occurred near the end of the sequence (linear-contrast analysis: <italic>F</italic><sub>(1,11)</sub> = 79.13; <italic>p</italic> = 0.0001). If the ARN is related to listeners' awareness, it should remain present throughout a sequence of detected targets, whereas undetected targets should not evoke an ARN during any part of the sequence.</p>
          <p>The time-dependence of our behavioral data suggests another possible interpretation of the ARN, if it is assumed that the amplitude of the ARN actually increases over the duration of the sequence: it may be that the increasing probability of detection over time co-varies with increasing evoked amplitude of the ARN over time, producing a spurious correlation between ARN amplitude and detection. This alternative seems unlikely, given that the undetected-target conditions produced no measurable ARN. Nevertheless, we tested this possibility further by separately computing the magnitude of the response to detected and undetected targets for each target-tone position in the sequence. The results of this analysis are shown in <xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>F. The mean magnitude of the response to target tones alone (in the absence of masker tones) is shown for comparison. As can be seen, a marked difference between the neural responses to detected and undetected targets was present for all but the first target in the sequence in the time range 75–175 ms (two tailed <italic>t</italic>-tests; <italic>p</italic> &lt; 0.05).</p>
          <p>Since the listeners' task was to detect <italic>repeating</italic> target tones, which required that they detected at least two target tones, the two target tones preceding a detection response (key press) were counted as detected in both the behavioral and MEG data analyses. To investigate the temporal relationship between overt detection (as indicated by the key press) and the time course of ARN appearance, the responses in target-detected conditions were realigned and averaged based on the timing of the listeners' key presses. The results confirmed significant negativity evoked by two tones before the key-press, although the response evoked two tones prior to key-presses was smaller, and delayed in latency compared to the waves evoked by all subsequent tones (<xref ref-type="fig" rid="pbio-0060138-g002">Figure 2</xref>). After the key-press, the ARN shows some adaptation (<xref ref-type="fig" rid="pbio-0060138-g002">Figure 2</xref>), similar to the N<sub>1</sub>m evoked in the target-only condition. The delay observed for two tones before the key press is reflected by the higher amplitude in the time interval 175–275 ms, compared to the time interval 75–175 ms used for analysis of the ARN throughout this paper (<xref ref-type="fig" rid="pbio-0060138-g002">Figure 2</xref>C). In fact, when the analysis shown in <xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>F was done for the 175–275-ms time interval, a significantly stronger negativity for the detected compared to the undetected targets was observed for all target tones in the sequence, including the first (<italic>t</italic> = 3.1, <italic>p</italic> = 0.0100).</p>
          <fig id="pbio-0060138-g002" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pbio.0060138.g002</object-id>
            <label>Figure 2</label>
            <caption>
              <title>ARN in Relation to Behavioral Response Time</title>
              <p>(A) ARN source waveforms of experiment 1 (A and B), averaged relative to the behavioral response of the listeners (key press) instead of their position in the stimulus sequence. A strong negativity is evoked by the two tones prior to the key press. The negativity is delayed and more broad-based two tones before the key press. Accordingly, the negativity is smaller in the time interval from (B) 75–175 ms (used for most analyses throughout the paper) than in the time interval (C) 175–275 ms. The data in panels B and C represent the mean amplitude and standard errors across listeners (<italic>n</italic> = 12).</p>
            </caption>
            <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.g002" xlink:type="simple"/>
          </fig>
          <p>Another possible source of averaging bias relates to the finding that targets in the higher-frequency bands were detected less frequently than in lower-frequency bands (<italic>F</italic><sub>(5,55)</sub> = 8.68; <italic>p</italic> = 0.0002). Again, however, the magnitude of the response to the target tones was consistently larger for the detected than the undetected target tones, even when the analysis was carried out separately for each of the six target frequencies (<xref ref-type="fig" rid="pbio-0060138-g001">Figure 1</xref>G; planned comparisons using two tailed <italic>t</italic>-test; <italic>p</italic> &lt; 0.05). Thus, the ARN is not due merely to averaging the responses to targets that occupy different temporal or spectral positions.</p>
        </sec>
      </sec>
      <sec id="s2c">
        <title>Experiment 1C: Modulating Informational Masking without an Active Task</title>
        <p>In experiment 1A and 1B, recording of the ARN was coupled to an active task that involved motor responses. Here we evaluated if the ARN could also be recorded when no active task was performed while listening. Subjects listened passively to a set of shorter-duration sequences (4.8 s), consisting of six target tones and an 800-ms SOA random-onset multitone masker, as well as control conditions comprising only target or only masker tones. Because the listeners' perception remained unknown in the passive setup, an additional manipulation was introduced: the identical masker and target sequences were presented twice (at random positions within the presentation), once in isolation, and once preceded by a cue before the target, in an effort to make the subsequent target tones more detectable [<xref ref-type="bibr" rid="pbio-0060138-b020">20</xref>]. The cue consisted of three tones of identical frequency, and presented with the same 800-ms SOA, as the subsequent target tones, which were presented in silence prior to the multitone masker. It was assumed that the ARN would be larger in the cued condition, because of reduced uncertainty and informational masking, allowing for a larger number of consciously perceived target tones in the cued trials.</p>
        <p>The results of experiment 1C confirmed this prediction (<xref ref-type="fig" rid="pbio-0060138-g003">Figure 3</xref>). A significantly larger ARN was evoked by the six target tones following the cue compared to the six non-cued target tones (<italic>F</italic><sub>(1,11)</sub> = 15.67; <italic>p</italic> = 0.0022; difference significant from 57 to 307 ms, <italic>p</italic> &lt; 0.05). This result indicates that the ARN does not depend on motor preparation or other task-related processes.</p>
        <fig id="pbio-0060138-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0060138.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Experiment 1C: Cued Targets</title>
            <p>In this experiment, listeners attended passively to the stimulation. Targets started either after the informational masker (uncued targets) or two tones before the informational masker (cued targets). Except for the cue, the masker and targets used in the two conditions were identical. This setting was chosen to test the influence of perception on the ARN without the necessity for an active task by the listener. Listeners were naive as to the experiment's objective.</p>
            <p>(A) Average source waveforms across listeners (<italic>n</italic> = 12) and hemispheres. Confidence intervals represent bootstrap-based <italic>t</italic>-intervals (two-tailed, <italic>p</italic> &lt; 0.05).</p>
            <p>(B) Mean amplitudes and standard errors of the mean in the time window from 75–175 ms post target tone onset. The ARN evoked by cued targets is significantly stronger than the ARN elicited by uncued targets.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.g003" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2d">
        <title>Experiment 2: Attentional Influences on Long-Latency Responses</title>
        <p>Conscious detection of a target tone will generally be expected to involve the allocation of attention toward the target. In the context of a multitone masker (without a cue), the perceptual salience of the target is comparatively low, and the contribution of bottom-up (exogenous) mechanisms that could attract attention toward the targets is unlikely to be very strong. Therefore, the direction of attention toward the targets is likely to facilitate detection, while directing attention away from the targets is likely to impair detection. If so, directing listeners' attention away from the targets should lead to a reduced or absent ARN in response to the targets. In experiment 2, the target and masker tone sequences were presented to the left ear only, while an unrelated stimulus sequence, containing occasional “deviant” tones interspersed among standard tones, was presented to the right ear (see <xref ref-type="sec" rid="s4">Materials and Methods</xref> for details). In the first phase of this experiment, the listeners were instructed to detect the deviant tones in the right ear. They were not informed that regularly repeating tones would sometimes be presented to the left ear and, when later interviewed, ten listeners reported that they had heard only irregular bleeps in their left ear; only two listeners reported occasionally noticing regularly repeating tones. In the second phase, listeners were instructed to attend to stimuli in the left ear, ignoring tones in the right ear, and to indicate when they detected the regularly repeating target tones. The stimuli used in the two phases of the experiment were identical.</p>
        <p>The average percentage of correct responses in the right-ear deviant-detection task (first phase of the experiment) was 86.8% (±11.7%, S.D.) and the percentage of false alarms was 2.1% (±2.7%, S.D.), yielding a <italic>d'</italic> of 3.4 (±0.7 S.D.). This high level of performance confirms that listeners were attending to the right-ear sequence, as intended. The MEG responses to the target tones were averaged into two groups, depending on whether those same (identical) physical stimuli were detected or undetected in the second phase of the experiment (see below). The MEG responses collected during this first phase (top panel in <xref ref-type="fig" rid="pbio-0060138-g004">Figure 4</xref>A) reveal that no ARN was evoked by target tones in the left ear when attention was directed away from them (all targets versus masker epochs: <italic>F</italic><sub>(2,22)</sub> = 0.23; <italic>p</italic> = 0.7970). The traces were similar to those obtained during epochs where listeners had not detected the targets in the second phase of the experiment, where they were attending to the targets, comprising a P<sub>1</sub>m and a hint of an N<sub>1</sub>m.</p>
        <fig id="pbio-0060138-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0060138.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Experiment 2: ARN</title>
            <p>(A) Grand average activity evoked by targets presented to the left ear (masker-only condition subtracted). The middle panel shows the data from the second phase of the experiment, where subjects listened to the stimuli presented to their left ear, and indicated whether they did (black wave) or did not (blue wave) hear the target stream. The ARN is observed when listeners indicated conscious perception of the target stream. The top panel shows an average over the same selection of physically identical trials (based on the responses in phase 2), when listeners performed the right ear target detection task in phase 1. This condition was recorded first, and listeners were generally not aware of the target stream. The bottom panel shows the activity evoked by an unmasked target stream on the left ear, while subjects were attending to the right. The N<sub>1</sub>m and sustained field (SF) are now evoked without active attention.</p>
            <p>(B) Mean source amplitudes (± 1 s.e.m.) in the time window 75–175 ms post target tone onset; dipoles were fitted to the ARN.</p>
            <p>(C) Behavioral data during the left ear task in phase 2.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.g004" xlink:type="simple"/>
        </fig>
        <p>In the second phase of the experiment, where the task was to detect the repeating target tones in the left ear (as in the original experiment), the average percentage of correct detections (<xref ref-type="fig" rid="pbio-0060138-g004">Figure 4</xref>C) was 40.2% (±24.5 S.D.), corresponding to a <italic>d'</italic> of 1.05 (<xref ref-type="supplementary-material" rid="pbio-0060138-sg001">Figure S1</xref>B). The MEG responses collected during this second phase (middle panel of <xref ref-type="fig" rid="pbio-0060138-g004">Figure 4</xref>A) confirm the findings of the first experiment. They show a clear ARN in response to detected targets. No ARN was observed in the average MEG response to undetected targets (detected versus undetected targets: <italic>F</italic><sub>(1,11)</sub> = 25.93; <italic>p</italic> = 0.0003; no significant hemisphere effects; undetected targets versus masker-only epochs: <italic>F</italic><sub>(1,11)</sub> = 1.24; <italic>p</italic> = 0.2900).</p>
        <p>In a third and final phase of this experiment, the regularly repeating target tones were presented in the left ear without the multitone masker, while listeners again performed the right-ear distraction task. Although performance was similar to that measured during the first phase [correct responses: 82.4% ± 11.5%; false alarms: 1.6% ± 2.0%; <italic>d'</italic> = 3.3 ± 0.8 (mean ± S.D.)], listeners now reported being aware of the presence of regularly repeating tones in their left ear. Likewise, the unattended left-ear targets evoked a prominent N<sub>1</sub>m (bottom panel in <xref ref-type="fig" rid="pbio-0060138-g004">Figure 4</xref>A), and a short sustained field because of the longer tone duration (250 ms versus 100 ms; note that the ARN was also more sustained). Dipole locations for the N<sub>1</sub>m were not significantly different from those for the ARN measured in the second phase of the experiment (<italic>F</italic><sub>(2,22)</sub> = 0.64; <italic>p</italic> = 0.5264), pointing to a generator of the ARN and N<sub>1</sub>m in the auditory cortex (<xref ref-type="table" rid="pbio-0060138-t001">Table 1</xref>).</p>
      </sec>
      <sec id="s2e">
        <title>Experiment 2: Auditory SSR to Detected and Undetected Targets</title>
        <p>If informational masking were completely pre-cortical, neural correlates of target detection should be readily observed in the earliest cortical responses. To address this prediction in experiment 2, we added sinusoidal amplitude modulation (AM) to the target tones in the left ear at a rate of 40 Hz. This allowed us to selectively record the middle-latency SSR evoked by the target tones, which has been identified in earlier studies as an index of early processing in the auditory core region of Heschl's gyrus [<xref ref-type="bibr" rid="pbio-0060138-b021">21</xref>–<xref ref-type="bibr" rid="pbio-0060138-b023">23</xref>].</p>
        <p>Compared to the ARN results reported above, fundamentally different findings were obtained for the SSR evoked by the 40-Hz AM of the target tones (<xref ref-type="fig" rid="pbio-0060138-g005">Figure 5</xref>). First, the SSR was present in both phases of the experiment, regardless of which ear the listener was attending. Second, when the listeners were attending to the target tones (second phase of the experiment), the SSR was observed regardless of whether or not the target tones were detected. The lack of significant SSR in the masker-only condition (gray waves in <xref ref-type="fig" rid="pbio-0060138-g005">Figure 5</xref>B) confirms the specificity of this measure for the target tones. The masker-evoked SSR was successfully canceled out by the averaging procedure, because the AM frequencies and onset phases of the masker tones were randomized. Overall, the SSR in response to the target tones was not significantly affected by either target detection (<italic>F</italic><sub>(1,11)</sub> = 0.14; <italic>p</italic> = 0.7125) or attention (<italic>F</italic><sub>(1,11)</sub> = 0.02; <italic>p</italic> = 0.9008). There were no significant hemisphere effects in the presence of multitone masking, but the SSR was larger in the contralateral (right) hemisphere for AM tones presented in silence (<italic>F</italic><sub>(1,11)</sub> = 22.57; <italic>p</italic> = 0.0006).</p>
        <fig id="pbio-0060138-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0060138.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Experiment 2: SSR</title>
            <p>(A) Mean source amplitudes (± 1 s.e.m.) calculated from peak to peak for the SSR.</p>
            <p>(B) Grand average source waveforms of the SSR elicited by the amplitude-modulated targets in the presence of the masker. Confidence intervals represent bootstrap based <italic>t</italic>-intervals. The SSR was evoked irrespective of target-tone awareness and side of attention.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.g005" xlink:type="simple"/>
        </fig>
        <p>Using the SSR, we detected no differences in early processing of detected and undetected target tones in the AC. This negative finding does not exclude the possibility of differential early processing of detected and undetected targets by mechanisms in or before the AC that are not reflected in this particular analysis. Nevertheless, the SSR data do show that the target tones are represented in the AC, even when they are not consciously perceived by the listener.</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <sec id="s3a">
        <title>The Role of the AC in Perceptual Awareness</title>
        <p>The present results demonstrate a clear co-variation between late neural responses from the human AC and listeners' awareness of sounds presented well above their detection threshold in quiet, and not masked in the sensory periphery. At the same time, the results demonstrate earlier neural responses in the AC to tones that remain undetected by the listener.</p>
        <p>The two MEG components studied here, the SSR and the long latency ARN, are both generated in the AC but reflect different processing stages. Conventional averaging of the SSR was used to maximize early phase-locked activity, and suppress later and non–phase-locked gamma-band activity [<xref ref-type="bibr" rid="pbio-0060138-b024">24</xref>,<xref ref-type="bibr" rid="pbio-0060138-b025">25</xref>], to ensure that the SSR was specifically evoked by the target tones. The phase-locked SSR is tonotopically organized [<xref ref-type="bibr" rid="pbio-0060138-b021">21</xref>,<xref ref-type="bibr" rid="pbio-0060138-b026">26</xref>], and is related to the middle-latency (20–50 ms) response [<xref ref-type="bibr" rid="pbio-0060138-b022">22</xref>,<xref ref-type="bibr" rid="pbio-0060138-b023">23</xref>,<xref ref-type="bibr" rid="pbio-0060138-b027">27</xref>], which, like the SSR, is mainly generated in the auditory core area [<xref ref-type="bibr" rid="pbio-0060138-b021">21</xref>,<xref ref-type="bibr" rid="pbio-0060138-b023">23</xref>,<xref ref-type="bibr" rid="pbio-0060138-b024">24</xref>,<xref ref-type="bibr" rid="pbio-0060138-b028">28</xref>,<xref ref-type="bibr" rid="pbio-0060138-b029">29</xref>]. Thus, the presence of the SSR during undetected tones provides a dissociation between the early activity in the AC and perceptual awareness, suggesting that although early activity in the auditory core may be necessary for perceptual awareness [<xref ref-type="bibr" rid="pbio-0060138-b030">30</xref>], it is not sufficient [<xref ref-type="bibr" rid="pbio-0060138-b031">31</xref>].</p>
        <p>In contrast to the SSR, the ARN appears to be closely related to the listeners' perceptual awareness of the target tones, as it was not observed for undetected or unattended targets. Source analyses performed on these data clearly indicate that the ARN is generated in the AC, around Heschl's gyrus. However, the dipole source analysis does not permit us to estimate the extent of the ARN source. Based on its latency and polarity, the ARN might be related to the auditory evoked N<sub>1</sub>m and Nd components. In contrast to the SSR, these components have been shown to be generated across multiple fields of the AC, including lateral Heschl's gyrus, planum temporale, and the superior temporal gyrus [<xref ref-type="bibr" rid="pbio-0060138-b017">17</xref>–<xref ref-type="bibr" rid="pbio-0060138-b019">19</xref>,<xref ref-type="bibr" rid="pbio-0060138-b032">32</xref>–<xref ref-type="bibr" rid="pbio-0060138-b034">34</xref>], comprising the secondary or “belt” regions of the AC [<xref ref-type="bibr" rid="pbio-0060138-b035">35</xref>,<xref ref-type="bibr" rid="pbio-0060138-b036">36</xref>].</p>
        <p>In summary, the present data indicate that the neural correlates of auditory perceptual awareness, as measured in the context of a relatively simple informational masking paradigm, can be found between early and late processing stages in the AC. In a finer anatomical view, these processes might be situated in core and belt areas of the AC [<xref ref-type="bibr" rid="pbio-0060138-b035">35</xref>,<xref ref-type="bibr" rid="pbio-0060138-b036">36</xref>], respectively, although there is only indirect evidence for the latter hypothesis at present.</p>
      </sec>
      <sec id="s3b">
        <title>Previous Electroencephalography Studies of Masking and Detection</title>
        <p>In comparing the present findings to those of earlier studies, it is important to distinguish between the two forms of masking—“energetic masking” and “informational masking”—outlined in the introduction. Earlier studies have shown that auditory evoked electroencephalography (EEG) and MEG responses, including subcortical as well as cortical responses, can be strongly attenuated or abolished by the addition of masking noise [<xref ref-type="bibr" rid="pbio-0060138-b037">37</xref>–<xref ref-type="bibr" rid="pbio-0060138-b039">39</xref>]. The type of masking used in these studies corresponds to energetic masking, involving noise that overlaps in frequency and time with the target, which is commonly thought to originate at a peripheral level, reflecting direct physical interactions between the signal and the masking noise within the cochlea [<xref ref-type="bibr" rid="pbio-0060138-b002">2</xref>]. Using energetic masking and selective averaging based on listeners' responses, previous EEG studies have shown that waves P<sub>3</sub> and N<sub>1</sub> were observed over the vertex for detected targets only [<xref ref-type="bibr" rid="pbio-0060138-b040">40</xref>,<xref ref-type="bibr" rid="pbio-0060138-b041">41</xref>]. The P<sub>3</sub> is currently thought to reflect activity in frontal and parietal cortex [<xref ref-type="bibr" rid="pbio-0060138-b042">42</xref>], usually related to active task performance and novelty detection [<xref ref-type="bibr" rid="pbio-0060138-b043">43</xref>]. The AC might have additionally contributed to the N<sub>1</sub> observed in one study [<xref ref-type="bibr" rid="pbio-0060138-b041">41</xref>], but this was not investigated.</p>
        <p>In contrast to these earlier findings, the present results cannot be explained in terms of peripheral interactions between signal and masker, or in terms of novelty-detection or task-performance effects. First, the use of a protected spectral region around the target tones greatly reduced the influence of peripheral interactions between signal and masker. Second, the use of stimulus sequences containing multiple tone bursts, combined with a task that required listeners to report only the first detected target-tone repetition in an ongoing stream, dissociated perceptual detection from task-performance, and novelty effects. Finally, our finding that the ARN can be modulated by cueing listeners to the target tones, even when they were not actively performing the detection task, rules out an explanation in terms of task-performance effects.</p>
      </sec>
      <sec id="s3c">
        <title>Possible Mechanisms in the AC Related to Informational Masking</title>
        <p>The finding of early cortical activity that is independent of detection on the one hand, and of a strong relationship between the longer-latency ARN and listeners' detection on the other hand, strongly suggests a neural correlate of detection within the AC for the multi-tone informational masking paradigm used here.</p>
        <p>A number of processes within the AC may determine whether a target is subject to informational multi-tone masking or not. One factor likely to play an important role is selective attention. The ARN had a similar source location to that of the N<sub>1</sub>m, which is evoked by target tones in the absence of the masker, and the two responses largely overlapped in time. The N<sub>1</sub>m has traditionally been considered an “automatic” component, which does not critically depend on overt attention [<xref ref-type="bibr" rid="pbio-0060138-b044">44</xref>]. However, this view is based mostly on results obtained under very low attentional loads, where the sounds evoking the N<sub>1</sub>m were not accompanied by other, competing sounds (as in the target-only control in experiment 1). In experiments with higher processing loads, where multiple sound streams are present, selective attention has been found to modulate responses in the AC [<xref ref-type="bibr" rid="pbio-0060138-b033">33</xref>,<xref ref-type="bibr" rid="pbio-0060138-b034">34</xref>,<xref ref-type="bibr" rid="pbio-0060138-b045">45</xref>–<xref ref-type="bibr" rid="pbio-0060138-b047">47</xref>]. However, a salient N<sub>1</sub>m is still observed in such settings (as in the target-only control in experiment 2), and listeners are usually aware of the presence of the unattended sound stream. It seems that only at very high processing loads, such as under the informational masking paradigm used here, is this response suppressed to the point where it is not measurable if the target is unattended or remains otherwise undetected.</p>
        <p>Taking our results together with those of earlier studies, we suggest that the degree to which selective attention affects later AC activity (like the N<sub>1</sub>m) may be explained by attentional load, with higher load leading to greater attentional modulation of the evoked responses. This explanation seems consistent with findings in the visual system, where selective attention has been shown to influence the competition for neural representation in cortex [<xref ref-type="bibr" rid="pbio-0060138-b048">48</xref>,<xref ref-type="bibr" rid="pbio-0060138-b049">49</xref>].</p>
        <p>In our experiments, listeners were not able to attend selectively to the target tones from the beginning of each sequence, because the frequency at which the target tones were presented differed across presentations. Recent work has shown that under such circumstances, the detection of the target tones nonetheless occurs more rapidly than predicted by a serial search model, indicating additional bottom-up processes, such as an auditory “pop-out” effect [<xref ref-type="bibr" rid="pbio-0060138-b014">14</xref>]. This pop-out effect is expected to be closely related to automatic auditory-scene-analysis mechanisms, which are thought to parse acoustic stimuli based on low-level features (such as frequency distance, temporal proximity, or spectral continuity over time) and contribute to the formation of auditory streams [<xref ref-type="bibr" rid="pbio-0060138-b011">11</xref>,<xref ref-type="bibr" rid="pbio-0060138-b050">50</xref>]. Recent studies have identified neural phenomena that might subserve the formation of auditory streams in the AC [<xref ref-type="bibr" rid="pbio-0060138-b051">51</xref>–<xref ref-type="bibr" rid="pbio-0060138-b054">54</xref>], and these streaming mechanisms may then again interact with mechanisms of selective attention via bottom-up activation of the ventral fronto-parietal attention system [<xref ref-type="bibr" rid="pbio-0060138-b055">55</xref>].</p>
        <p>Based on these considerations, we suggest that, subsequent to early activation of the auditory core, limited processing resources in the AC [<xref ref-type="bibr" rid="pbio-0060138-b056">56</xref>] are a cause of informational masking, once a certain processing load is exceeded. Bottom-up mechanisms subserving stream segregation [<xref ref-type="bibr" rid="pbio-0060138-b011">11</xref>,<xref ref-type="bibr" rid="pbio-0060138-b050">50</xref>], on the one hand, and top-down mechanisms of selective attention [<xref ref-type="bibr" rid="pbio-0060138-b055">55</xref>], on the other hand, may bias the competition between auditory streams. This in turn may help determine the processing resources allocated to different streams within the AC, starting after 50–70 ms, in a manner that appears to be critical for auditory perceptual awareness.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>Materials and Methods</title>
      <sec id="s4a">
        <title>Listeners.</title>
        <p>Thirty-three listeners without history of hearing disorders participated in the study. Three groups of 12 listeners each (six male, six female) participated in experiments 1A and 1B (one group), 1C, and 2. One listener participated in all three experiments, and another one in all parts of experiment 1; the other listeners were different in each experiment. The study protocol was approved by the institutional review board of the University of Heidelberg Medical School; all participants provided written informed consent.</p>
      </sec>
      <sec id="s4b">
        <title>Stimuli and procedure.</title>
        <p><italic>Experiment 1</italic>: All stimuli were generated using a set of 18 frequency bands, whose center frequencies were spaced equally on a logarithmic scale between 239 and 5,000 Hz (239, 286, 342, 409, <bold>489</bold>, 585, <bold>699</bold>, 836, <bold>1,000</bold>, 1,196, <bold>1,430</bold>, 1,710, <bold>2,045</bold>, 2,445, <bold>2,924</bold>, 3,497, 4,181, and 5,000 Hz). The target tones were selected from the six frequencies shown in bold, and remained constant throughout a 10.4-s sequence. Target tones were 100 ms in duration, including 10-ms on and off cosine-shaped ramps, and were repeated 12 times with a constant SOA of 800 ms.</p>
        <p>Two frequency bands on either side of the target frequency were excluded, as a “protected region,” such that the masker comprised the remaining 13 frequency bands. Within each frequency band, the masker-tone frequency was chosen randomly around the center frequency (<italic>f</italic><sub>c</sub>) within the width of one estimated equivalent rectangular bandwidths [ERB = 24.7 × (4.37 × <italic>f</italic><sub> c</sub> + 1)], where <italic>f</italic><sub>c</sub> is in kHz [<xref ref-type="bibr" rid="pbio-0060138-b001">1</xref>]. The masker started 800 ms before the target, resulting in a 10.4-s total duration for the sequence. The SOA between tones was randomized in the range of 100–300 ms or 100–1,500 ms, yielding average SOAs of 200 ms (experiment 1A) or 800 ms (experiments 1B and 1C; the tone density and overall masker energy was accordingly lower in this case).</p>
        <p>Each of the six target frequencies was presented together with ten differently randomized masker sequences. Five of the ten masker sequences were also presented without the target tones. The resulting 90 different sequences were presented in random order, separated by silent intervals of 1.6 s. Five repetitions of the targets alone (without the masker) were presented as a control condition at the end of the session. All tone sequences were presented diotically (to both ears). The level of the target tones was 40 dB sensation level (SL) per tone, and the level per tone of the masker was set 18 dB higher.</p>
        <p>In experiments 1A and 1B, listeners were familiarized with the stimuli before MEG recordings, and they were informed that the regularly repeating tones would not always be present (although they were not told on what proportion of trials, or whether they would start and end at the same or different times). They were instructed to press the left button of the computer mouse whenever, and as soon as, they detected the repeating target tones. Listeners were encouraged to respond as quickly as possible after the onset of a new sequence, and they were told to press the right mouse button if the sequence ended before the masker, or if they had pressed the left button in error.</p>
        <p>In experiment 1C, listeners were instructed to listen passively to four types of stimulus sequences presented in random order. The first three were similar to the conditions of experiment 1B, but comprised only six consecutive target tones (yielding a total duration of 4.8 s). The fourth type of stimulus sequence was obtained by adding three target tones in front of the original target sequence. The unmasked tones at the beginning of the target sequence provided listeners with a cue to the frequency of the target and decreased informational masking. Ten different maskers were generated for each of the six target frequencies. These same 60 masker sequences were used in the masker-only, uncued-target-plus-masker, and cued-target-plus-masker conditions.</p>
        <p><italic>Experiment 2</italic>: Listeners were presented with target-plus-masker and masker-alone sequences similar to those used in the previous experiment. However, in this experiment, the target and masker tones were presented to the left ear only. Also, all tones were sinusoidally modulated in amplitude (AM depth = 100%). For the target tones, an AM rate of 40 Hz was used to allow recording of the auditory 40-Hz SSR. For the masker tones, the AM rate was randomized between 20 and 50 Hz to maintain perceptual similarity, while avoiding interference between the target and masker evoked SSR [<xref ref-type="bibr" rid="pbio-0060138-b026">26</xref>].</p>
        <p>Target tone duration was 250 ms, yielding ten modulation cycles per tone. The target tones were repeated at a constant SOA of 800 ms. The six target-tone frequencies were restricted to the range of 699 to 1,710 Hz (frequency bands 7–12, see also experiment 1). The level of the masker tones was set 6 dB higher than that of the target tones. The masker-tone SOA varied between 250 and 1,350 ms (average SOA = 800 ms).</p>
        <p>In their right ear, listeners were presented with a sequence of 100-ms AM tones (10-ms on and off ramps, AM rate = 100 Hz), the frequency of which was randomized between 700 and 1,700 Hz, and the SOA between 250 and 1,350 ms (average SOA = 800 ms). The AM depth was 100% for the standards and 18 dB less for the 10% deviants, which were randomly interspersed among standards. The tone sequence in the right ear continued through the 1.6-s silent gaps separating consecutive stimulus sequences in the left ear.</p>
        <p>In a first phase, listeners were instructed to ignore the sounds in their left ear, attend to the sounds in their right ear, and press the right mouse button whenever (and as precisely as possible after) they detected a deviant in that ear. They were not informed that the stimuli presented in their left ear would sometimes contain repeating tones. In a second phase, listeners were instructed to ignore the sounds in their right ear, and to indicate the presence of the target sequence in their left ear, as in experiment 1. In a final phase, the repeating target tones were presented to the listeners' left ear without any masker, while the listeners received the same instructions as in phase 1 (attend right, ignore left).</p>
      </sec>
      <sec id="s4c">
        <title>Data acquisition.</title>
        <p>The MEG was recorded with a Neuromag-122 whole-head system. Data were recorded continuously with a 1,000-Hz sampling rate, in direct coupled mode. Stimuli were presented via foam ear pieces connected to ER-3 earphones (Etymotic research) by 1-m-long plastic tubes. Structural MRI scans (T1 weighted, MPRAGE, voxel size 1 × 1 × 1.3 mm) were obtained from each listener with a 3-T (Siemens Trio) whole-body scanner.</p>
      </sec>
      <sec id="s4d">
        <title>Data analysis.</title>
        <p>MEG activity was averaged relative to the target tones. For sequences containing only maskers, MEG activity was averaged relative to times at which the target tones occurred in the combined sequences. Because the onset times of the masker tones were randomized independently from those of masker tones at other frequencies and from those of the target tones, the activity evoked by the masker tones canceled out in the averaging. In experiment 2, the right-ear task (phase 1 and 3) caused a low-frequency baseline fluctuation that was apparent during the masker-alone condition. Therefore, the average response to masker-alone sequences was subtracted from the average response to the other conditions in experiment 2. In experiments and conditions where listeners indicated when they heard the targets, MEG activity recorded during epochs where listeners had detected the target tones were averaged separately from epochs where the listeners had not detected the target tones. Assuming that the target tones could only be identified after at least two such tones had been heard, the two tones prior to the response were also considered detected. Spatio-temporal dipole source analysis [<xref ref-type="bibr" rid="pbio-0060138-b019">19</xref>] was performed on the averaged data using brain electrical source analysis (BESA). The data were low-pass filtered at 20 Hz (6 dB, zero-phase shift Butterworth filter). A baseline was set 25 ms prior to sound onset, and drifts and slow activity in the subsequent baseline epoch were removed by PCA-based spatial filtering. Dipole analysis of the detected condition was performed in a 100-ms analysis window encompassing the ARN peak. Two dipoles, one in each AC, were fitted to the data. This dipole model was then used as a spatial filter to explore the activation of the AC in the other conditions. For analysis of the 40-Hz SSR in experiment 2, the data were band-pass filtered between 28 and 48 Hz (6 and 12 dB/octave, zero-phase Butterworth filter). The dipole model was fitted to the SSR of the unmasked targets from the control run. These dipoles were used as a fixed spatial filter to generate source waveforms of the SSR for conditions where the masker was present.</p>
        <p>The combined data of experiment 1 A and B were also averaged selectively for (a) each of the 12 target presentations, and (b) for each of the six target frequency bands used. Source waveforms were derived with the same dipole model as used for the above analysis (additional 1-Hz high pass filter).</p>
        <p>Amplitudes and latencies were measured in the individual source waveforms. ARN and N<sub>1</sub>m amplitudes were measured as the average in the time window 75–175 ms, unless mentioned otherwise. Latencies were measured at the maximum in the time interval 75–275 ms. The peak-to-peak amplitude of the 40-Hz steady-state response was measured after averaging over the ten 25-ms cycles of modulation contained in the 250-ms target-tone duration. Confidence intervals for source waveforms were estimated by calculating <italic>t</italic>-intervals based on standard errors derived with the bootstrap technique based on 1,000 resamples [<xref ref-type="bibr" rid="pbio-0060138-b057">57</xref>]. Dipole positions were co-registered to the individual MRI morphology, and transformed into Talairach space using Brain Voyager.</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pbio-0060138-su001" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.sa001" xlink:type="simple">
        <label>Audio S1</label>
        <caption>
          <title>Example of a Target Embedded in an Informational Masker</title>
          <p>Audio example of a target sequence combined with an informational masker. Listen to these example over headphones in a quiet room. The stimulus is taken from experiment 1B (1,000-Hz target frequency, presented 18 dB below the level of the masker tones; SOA of target and average SOA within each masker stream = 800 ms). You may or may not hear the slowly but regularly repeating target sequence on your first attempt. If you don't hear out the target stream, try listening to the target alone (<xref ref-type="supplementary-material" rid="pbio-0060138-su002">Audio S2</xref>), and, if necessary, adjust volume to an audible, but low and comfortable level, and then return to this example.</p>
          <p>(236 KB MP3)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio-0060138-su002" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.sa002" xlink:type="simple">
        <label>Audio S2</label>
        <caption>
          <title>The Isolated Target of the Example <xref ref-type="supplementary-material" rid="pbio-0060138-su001">Audio S1</xref></title>
          <p>Audio example of the target sequence alone. This target is buried among the random informational masker tones of example <xref ref-type="supplementary-material" rid="pbio-0060138-su001">Audio S1</xref>.</p>
          <p>(236 KB MP3)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio-0060138-su003" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.sa003" xlink:type="simple">
        <label>Audio S3</label>
        <caption>
          <title>The Isolated Informational Masker of the Example <xref ref-type="supplementary-material" rid="pbio-0060138-su001">Audio S1</xref></title>
          <p>Audio example of the informational masker from example <xref ref-type="supplementary-material" rid="pbio-0060138-su001">Audio S1</xref> without the target tones. This represents the “catch trials” from the experiment, in which no target was present.</p>
          <p>(236 KB MP3)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pbio-0060138-sg001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.0060138.sg001" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <title>Detectability (<italic>d'</italic>) of Targets in Multitone Masking</title>
          <p>The detectability, <italic>d'</italic>, was calculated based on the behavioral data of (A) experiment 1A (200-ms SOA) and 1B (800-ms SOA) and (B) experiment 2 (phase 2). In all three conditions, <italic>d'</italic> increases over the first 4 s and remains relatively stable thereafter. In this context, <italic>d'</italic> is a measure of the amount of informational masking. There was no significant difference between the two SOA conditions in experiment 1. Experiment 2 produced overall a higher amount of informational masking in comparison to experiment 1.</p>
          <p>(522 KB PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors are grateful to Josh McDermott for helpful comments on an earlier version of the manuscript.</p>
    </ack>
    
    <glossary>
      <title>Abbreviations</title>
      <def-list>
        <def-item>
          <term>AC</term>
          <def>
            <p>auditory cortex</p>
          </def>
        </def-item>
        <def-item>
          <term>AM</term>
          <def>
            <p>amplitude modulation</p>
          </def>
        </def-item>
        <def-item>
          <term>ARN</term>
          <def>
            <p>awareness related negativity</p>
          </def>
        </def-item>
        <def-item>
          <term>MEG</term>
          <def>
            <p>magnetoencephalography</p>
          </def>
        </def-item>
        <def-item>
          <term>MRI</term>
          <def>
            <p>magnetic resonance imaging</p>
          </def>
        </def-item>
        <def-item>
          <term>SOA</term>
          <def>
            <p>stimulus-onset asynchrony</p>
          </def>
        </def-item>
        <def-item>
          <term>SSR</term>
          <def>
            <p>steady-state response</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
    <ref-list>
      <title>References</title>
      <ref id="pbio-0060138-b001">
        <label>1</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Moore</surname><given-names>BCJ</given-names></name></person-group>
					<year>1995</year>
					<article-title>Frequency analysis and masking.</article-title>
					<comment>In:</comment>
					<person-group person-group-type="editor"><name name-style="western"><surname>Moore</surname><given-names>BCJ</given-names></name></person-group>
					<source>Handbook of perception and cognition, Volume 6: Hearing</source>
					<publisher-loc>Orlando (Florida)</publisher-loc>
					<publisher-name>Academic Press</publisher-name>
					<fpage>161</fpage>
					<lpage>205</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b002">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Delgutte</surname><given-names>B</given-names></name></person-group>
					<year>1990</year>
					<article-title>Physiological mechanisms of psychophysical masking: observations from auditory-nerve fibers.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>87</volume>
					<fpage>791</fpage>
					<lpage>809</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b003">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Wegel</surname><given-names>RL</given-names></name><name name-style="western"><surname>Lane</surname><given-names>CE</given-names></name></person-group>
					<year>1924</year>
					<article-title>The auditory masking of one pure tone by another and its possible relation to the dynamics of the inner ear.</article-title>
					<source>Physics Rev</source>
					<volume>23</volume>
					<fpage>266</fpage>
					<lpage>285</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b004">
        <label>4</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Evans</surname><given-names>EF</given-names></name></person-group>
					<year>2001</year>
					<article-title>Latest comparisons between physiological and behavioural frequency selectivity.</article-title>
					<comment>In:</comment>
					<source>Physiological and psychophysical bases of auditory function</source>
					<comment>In:</comment>
					<person-group person-group-type="editor"><name name-style="western"><surname>Breebaart</surname><given-names>J</given-names></name><name name-style="western"><surname>Houtsma</surname><given-names>AJM</given-names></name><name name-style="western"><surname>Kohlrausch</surname><given-names>A</given-names></name><name name-style="western"><surname>Prijs</surname><given-names>VF</given-names></name><name name-style="western"><surname>Schoonhoven</surname><given-names>R</given-names></name></person-group>
					<publisher-loc>Maastricht (The Netherlands)</publisher-loc>
					<publisher-name>Shaker</publisher-name>
					<fpage>382</fpage>
					<lpage>387</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b005">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Shera</surname><given-names>CA</given-names></name><name name-style="western"><surname>Guinan</surname><given-names>JJ</given-names><suffix>Jr.</suffix></name><name name-style="western"><surname>Oxenham</surname><given-names>AJ</given-names></name></person-group>
					<year>2002</year>
					<article-title>Revised estimates of human cochlear tuning from otoacoustic and behavioral measurements.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>99</volume>
					<fpage>3318</fpage>
					<lpage>3323</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b006">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Watson</surname><given-names>CS</given-names></name><name name-style="western"><surname>Wroton</surname><given-names>HW</given-names></name><name name-style="western"><surname>Kelly</surname><given-names>WJ</given-names></name><name name-style="western"><surname>Benbassat</surname><given-names>CA</given-names></name></person-group>
					<year>1975</year>
					<article-title>Factors in the discrimination of tonal patterns. I. Component frequency, temporal position, and silent intervals.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>57</volume>
					<fpage>1175</fpage>
					<lpage>1185</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b007">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Neff</surname><given-names>DL</given-names></name></person-group>
					<year>1986</year>
					<article-title>Confusion effects with sinusoidal and narrow-band noise forward maskers.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>79</volume>
					<fpage>1519</fpage>
					<lpage>1529</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b008">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Brungart</surname><given-names>DS</given-names></name></person-group>
					<year>2001</year>
					<article-title>Informational and energetic masking effects in the perception of two simultaneous talkers.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>109</volume>
					<fpage>1101</fpage>
					<lpage>1109</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b009">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Durlach</surname><given-names>NI</given-names></name><name name-style="western"><surname>Mason</surname><given-names>CR</given-names></name><name name-style="western"><surname>Kidd</surname><given-names>G</given-names><suffix>Jr.</suffix></name><name name-style="western"><surname>Arbogast</surname><given-names>TL</given-names></name><name name-style="western"><surname>Colburn</surname><given-names>HS</given-names></name><etal/></person-group>
					<year>2003</year>
					<article-title>Note on informational masking.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>113</volume>
					<fpage>2984</fpage>
					<lpage>2987</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b010">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Neff</surname><given-names>DL</given-names></name><name name-style="western"><surname>Green</surname><given-names>DM</given-names></name></person-group>
					<year>1987</year>
					<article-title>Masking produced by spectral uncertainty with multicomponent maskers.</article-title>
					<source>Percept Psychophys</source>
					<volume>41</volume>
					<fpage>409</fpage>
					<lpage>415</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b011">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kidd</surname><given-names>G</given-names><suffix>Jr.</suffix></name><name name-style="western"><surname>Mason</surname><given-names>CR</given-names></name><name name-style="western"><surname>Richards</surname><given-names>VM</given-names></name></person-group>
					<year>2003</year>
					<article-title>Multiple bursts, multiple looks, and stream coherence in the release from informational masking.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>114</volume>
					<fpage>2835</fpage>
					<lpage>2845</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b012">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Neff</surname><given-names>DL</given-names></name><name name-style="western"><surname>Dethlefs</surname><given-names>TM</given-names></name><name name-style="western"><surname>Jesteadt</surname><given-names>W</given-names></name></person-group>
					<year>1993</year>
					<article-title>Informational masking for multicomponent maskers with spectral gaps.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>94</volume>
					<fpage>3112</fpage>
					<lpage>3126</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b013">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kidd</surname><given-names>G</given-names><suffix>Jr.</suffix></name><name name-style="western"><surname>Mason</surname><given-names>CR</given-names></name><name name-style="western"><surname>Deliwala</surname><given-names>PS</given-names></name><name name-style="western"><surname>Woods</surname><given-names>WS</given-names></name><name name-style="western"><surname>Colburn</surname><given-names>HS</given-names></name></person-group>
					<year>1994</year>
					<article-title>Reducing informational masking by sound segregation.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>95</volume>
					<fpage>3475</fpage>
					<lpage>3480</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b014">
        <label>14</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Micheyl</surname><given-names>C</given-names></name><name name-style="western"><surname>Shamma</surname><given-names>S</given-names></name><name name-style="western"><surname>Oxenham</surname><given-names>AJ</given-names></name></person-group>
					<year>2007</year>
					<article-title>Hearing out repeating elements in randomly varying multitone sequences: a case of streaming.</article-title>
					<comment>In:</comment>
					<person-group person-group-type="editor"><name name-style="western"><surname>Kollmeier</surname><given-names>B</given-names></name><name name-style="western"><surname>Klump</surname><given-names>GM</given-names></name><name name-style="western"><surname>Hohmann</surname><given-names>V</given-names></name><name name-style="western"><surname>Langemann</surname><given-names>U</given-names></name><name name-style="western"><surname>Mauermann</surname><given-names>M</given-names></name><etal/></person-group>
					<source>Hearing - from basic research to application</source>
					<publisher-loc>Berlin: Springer</publisher-loc>
					<fpage>267</fpage>
					<lpage>274</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b015">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Leonard</surname><given-names>CM</given-names></name><name name-style="western"><surname>Puranik</surname><given-names>C</given-names></name><name name-style="western"><surname>Kuldau</surname><given-names>JM</given-names></name><name name-style="western"><surname>Lombardino</surname><given-names>LJ</given-names></name></person-group>
					<year>1998</year>
					<article-title>Normal variation in the frequency and location of human auditory cortex landmarks. Heschl's gyrus: where is it.</article-title>
					<source>Cereb Cortex</source>
					<volume>8</volume>
					<fpage>397</fpage>
					<lpage>406</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b016">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Rademacher</surname><given-names>J</given-names></name><name name-style="western"><surname>Morosan</surname><given-names>P</given-names></name><name name-style="western"><surname>Schormann</surname><given-names>T</given-names></name><name name-style="western"><surname>Schleicher</surname><given-names>A</given-names></name><name name-style="western"><surname>Werner</surname><given-names>C</given-names></name><etal/></person-group>
					<year>2001</year>
					<article-title>Probabilistic mapping and volume measurement of human primary auditory cortex.</article-title>
					<source>Neuroimage</source>
					<volume>13</volume>
					<fpage>669</fpage>
					<lpage>683</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b017">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Gutschalk</surname><given-names>A</given-names></name><name name-style="western"><surname>Patterson</surname><given-names>RD</given-names></name><name name-style="western"><surname>Scherg</surname><given-names>M</given-names></name><name name-style="western"><surname>Uppenkamp</surname><given-names>S</given-names></name><name name-style="western"><surname>Rupp</surname><given-names>A</given-names></name></person-group>
					<year>2004</year>
					<article-title>Temporal dynamics of pitch in human auditory cortex.</article-title>
					<source>Neuroimage</source>
					<volume>22</volume>
					<fpage>755</fpage>
					<lpage>766</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b018">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Godey</surname><given-names>B</given-names></name><name name-style="western"><surname>Schwartz</surname><given-names>D</given-names></name><name name-style="western"><surname>de Graaf</surname><given-names>JB</given-names></name><name name-style="western"><surname>Chauvel</surname><given-names>P</given-names></name><name name-style="western"><surname>Liegeois-Chauvel</surname><given-names>C</given-names></name></person-group>
					<year>2001</year>
					<article-title>Neuromagnetic source localization of auditory evoked fields and intracerebral evoked potentials: a comparison of data in the same patients.</article-title>
					<source>Clin Neurophysiol</source>
					<volume>112</volume>
					<fpage>1850</fpage>
					<lpage>1859</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b019">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Scherg</surname><given-names>M</given-names></name><name name-style="western"><surname>Von Cramon</surname><given-names>D</given-names></name></person-group>
					<year>1985</year>
					<article-title>Two bilateral sources of the late AEP as identified by a spatio-temporal dipole model.</article-title>
					<source>Electroencephalogr Clin Neurophysiol</source>
					<volume>62</volume>
					<fpage>32</fpage>
					<lpage>44</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b020">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Richards</surname><given-names>VM</given-names></name><name name-style="western"><surname>Neff</surname><given-names>DL</given-names></name></person-group>
					<year>2004</year>
					<article-title>Cuing effects for informational masking.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>115</volume>
					<fpage>289</fpage>
					<lpage>300</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b021">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Romani</surname><given-names>GL</given-names></name><name name-style="western"><surname>Williamson</surname><given-names>SJ</given-names></name><name name-style="western"><surname>Kaufman</surname><given-names>L</given-names></name></person-group>
					<year>1982</year>
					<article-title>Tonotopic organization of the human auditory cortex.</article-title>
					<source>Science</source>
					<volume>216</volume>
					<fpage>1339</fpage>
					<lpage>1340</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b022">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hari</surname><given-names>R</given-names></name><name name-style="western"><surname>Hamalainen</surname><given-names>M</given-names></name><name name-style="western"><surname>Joutsiniemi</surname><given-names>SL</given-names></name></person-group>
					<year>1989</year>
					<article-title>Neuromagnetic steady-state responses to auditory stimuli.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>86</volume>
					<fpage>1033</fpage>
					<lpage>1039</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b023">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Gutschalk</surname><given-names>A</given-names></name><name name-style="western"><surname>Mase</surname><given-names>R</given-names></name><name name-style="western"><surname>Roth</surname><given-names>R</given-names></name><name name-style="western"><surname>Ille</surname><given-names>N</given-names></name><name name-style="western"><surname>Rupp</surname><given-names>A</given-names></name><etal/></person-group>
					<year>1999</year>
					<article-title>Deconvolution of 40 Hz steady-state fields reveals two overlapping source activities of the human auditory cortex.</article-title>
					<source>Clin Neurophysiol</source>
					<volume>110</volume>
					<fpage>856</fpage>
					<lpage>868</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b024">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Pantev</surname><given-names>C</given-names></name><name name-style="western"><surname>Elbert</surname><given-names>T</given-names></name><name name-style="western"><surname>Makeig</surname><given-names>S</given-names></name><name name-style="western"><surname>Hampson</surname><given-names>S</given-names></name><name name-style="western"><surname>Eulitz</surname><given-names>C</given-names></name><etal/></person-group>
					<year>1993</year>
					<article-title>Relationship of transient and steady-state auditory evoked fields.</article-title>
					<source>Electroencephalogr Clin Neurophysiol</source>
					<volume>88</volume>
					<fpage>389</fpage>
					<lpage>396</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b025">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Steinschneider</surname><given-names>M</given-names></name><name name-style="western"><surname>Fishman</surname><given-names>YI</given-names></name><name name-style="western"><surname>Arezzo</surname><given-names>JC</given-names></name></person-group>
					<year>2008</year>
					<article-title>Spectrotemporal analysis of evoked and induced electroencephalographic responses in primary auditory cortex (A1) of the awake monkey.</article-title>
					<source>Cereb Cortex</source>
					<volume>18</volume>
					<fpage>610</fpage>
					<lpage>625</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b026">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Lins</surname><given-names>OG</given-names></name><name name-style="western"><surname>Picton</surname><given-names>TW</given-names></name></person-group>
					<year>1995</year>
					<article-title>Auditory steady-state responses to multiple simultaneous stimuli.</article-title>
					<source>Electroencephalogr Clin Neurophysiol</source>
					<volume>96</volume>
					<fpage>420</fpage>
					<lpage>432</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b027">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Galambos</surname><given-names>R</given-names></name><name name-style="western"><surname>Makeig</surname><given-names>S</given-names></name><name name-style="western"><surname>Talmachoff</surname><given-names>PJ</given-names></name></person-group>
					<year>1981</year>
					<article-title>A 40-Hz auditory potential recorded from the human scalp.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>78</volume>
					<fpage>2643</fpage>
					<lpage>2647</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b028">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Liegeois-Chauvel</surname><given-names>C</given-names></name><name name-style="western"><surname>Musolino</surname><given-names>A</given-names></name><name name-style="western"><surname>Chauvel</surname><given-names>P</given-names></name></person-group>
					<year>1991</year>
					<article-title>Localization of the primary auditory area in man.</article-title>
					<source>Brain</source>
					<volume>114</volume>
					<issue>(Pt 1A)</issue>
					<fpage>139</fpage>
					<lpage>151</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b029">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bidet-Caulet</surname><given-names>A</given-names></name><name name-style="western"><surname>Fischer</surname><given-names>C</given-names></name><name name-style="western"><surname>Besle</surname><given-names>J</given-names></name><name name-style="western"><surname>Aguera</surname><given-names>PE</given-names></name><name name-style="western"><surname>Giard</surname><given-names>MH</given-names></name><etal/></person-group>
					<year>2007</year>
					<article-title>Effects of selective attention on the electrophysiological representation of concurrent sounds in the human auditory cortex.</article-title>
					<source>J Neurosci</source>
					<volume>27</volume>
					<fpage>9252</fpage>
					<lpage>9261</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b030">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Pockett</surname><given-names>S</given-names></name></person-group>
					<year>1999</year>
					<article-title>Anesthesia and the electrophysiology of auditory consciousness.</article-title>
					<source>Conscious Cogn</source>
					<volume>8</volume>
					<fpage>45</fpage>
					<lpage>61</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b031">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kanwisher</surname><given-names>N</given-names></name></person-group>
					<year>2001</year>
					<article-title>Neural events and perceptual awareness.</article-title>
					<source>Cognition</source>
					<volume>79</volume>
					<fpage>89</fpage>
					<lpage>113</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b032">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Jääskeläinen</surname><given-names>IP</given-names></name><name name-style="western"><surname>Ahveninen</surname><given-names>J</given-names></name><name name-style="western"><surname>Bonmassar</surname><given-names>G</given-names></name><name name-style="western"><surname>Dale</surname><given-names>AM</given-names></name><name name-style="western"><surname>Ilmoniemi</surname><given-names>RJ</given-names></name><etal/></person-group>
					<year>2004</year>
					<article-title>Human posterior auditory cortex gates novel sounds to consciousness.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>101</volume>
					<fpage>6809</fpage>
					<lpage>6814</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b033">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Rif</surname><given-names>J</given-names></name><name name-style="western"><surname>Hari</surname><given-names>R</given-names></name><name name-style="western"><surname>Hamalainen</surname><given-names>MS</given-names></name><name name-style="western"><surname>Sams</surname><given-names>M</given-names></name></person-group>
					<year>1991</year>
					<article-title>Auditory attention affects two different areas in the human supratemporal cortex.</article-title>
					<source>Electroencephalogr Clin Neurophysiol</source>
					<volume>79</volume>
					<fpage>464</fpage>
					<lpage>472</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b034">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Woldorff</surname><given-names>MG</given-names></name><name name-style="western"><surname>Gallen</surname><given-names>CC</given-names></name><name name-style="western"><surname>Hampson</surname><given-names>SA</given-names></name><name name-style="western"><surname>Hillyard</surname><given-names>SA</given-names></name><name name-style="western"><surname>Pantev</surname><given-names>C</given-names></name><etal/></person-group>
					<year>1993</year>
					<article-title>Modulation of early sensory processing in human auditory cortex during auditory selective attention.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>90</volume>
					<fpage>8722</fpage>
					<lpage>8726</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b035">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Galaburda</surname><given-names>A</given-names></name><name name-style="western"><surname>Sanides</surname><given-names>F</given-names></name></person-group>
					<year>1980</year>
					<article-title>Cytoarchitectonic organization of the human auditory cortex.</article-title>
					<source>J Comp Neurol</source>
					<volume>190</volume>
					<fpage>597</fpage>
					<lpage>610</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b036">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Rivier</surname><given-names>F</given-names></name><name name-style="western"><surname>Clarke</surname><given-names>S</given-names></name></person-group>
					<year>1997</year>
					<article-title>Cytochrome oxidase, acetylcholinesterase, and NADPH-diaphorase staining in human supratemporal and insular cortex: evidence for multiple auditory areas.</article-title>
					<source>Neuroimage</source>
					<volume>6</volume>
					<fpage>288</fpage>
					<lpage>304</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b037">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Galambos</surname><given-names>R</given-names></name><name name-style="western"><surname>Makeig</surname><given-names>S</given-names></name></person-group>
					<year>1992</year>
					<article-title>Physiological studies of central masking in man. I: The effects of noise on the 40-Hz steady-state response.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>92</volume>
					<fpage>2683</fpage>
					<lpage>2690</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b038">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Oates</surname><given-names>PA</given-names></name><name name-style="western"><surname>Purdy</surname><given-names>SC</given-names></name></person-group>
					<year>2001</year>
					<article-title>Frequency specificity of the human auditory brainstem and middle latency responses using notched noise masking.</article-title>
					<source>J Acoust Soc Am</source>
					<volume>110</volume>
					<fpage>995</fpage>
					<lpage>1009</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b039">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Androulidakis</surname><given-names>AG</given-names></name><name name-style="western"><surname>Jones</surname><given-names>SJ</given-names></name></person-group>
					<year>2006</year>
					<article-title>Detection of signals in modulated and unmodulated noise observed using auditory evoked potentials.</article-title>
					<source>Clin Neurophysiol</source>
					<volume>117</volume>
					<fpage>1783</fpage>
					<lpage>1793</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b040">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hillyard</surname><given-names>SA</given-names></name><name name-style="western"><surname>Squires</surname><given-names>KC</given-names></name><name name-style="western"><surname>Bauer</surname><given-names>JW</given-names></name><name name-style="western"><surname>Lindsay</surname><given-names>PH</given-names></name></person-group>
					<year>1971</year>
					<article-title>Evoked potential correlates of auditory signal detection.</article-title>
					<source>Science</source>
					<volume>172</volume>
					<fpage>1357</fpage>
					<lpage>1360</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b041">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Parasuraman</surname><given-names>R</given-names></name><name name-style="western"><surname>Beatty</surname><given-names>J</given-names></name></person-group>
					<year>1980</year>
					<article-title>Brain events underlying detection and recognition of weak sensory signals.</article-title>
					<source>Science</source>
					<volume>210</volume>
					<fpage>80</fpage>
					<lpage>83</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b042">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bledowski</surname><given-names>C</given-names></name><name name-style="western"><surname>Prvulovic</surname><given-names>D</given-names></name><name name-style="western"><surname>Hoechstetter</surname><given-names>K</given-names></name><name name-style="western"><surname>Scherg</surname><given-names>M</given-names></name><name name-style="western"><surname>Wibral</surname><given-names>M</given-names></name><etal/></person-group>
					<year>2004</year>
					<article-title>Localizing P300 generators in visual target and distractor processing: a combined event-related potential and functional magnetic resonance imaging study.</article-title>
					<source>J Neurosci</source>
					<volume>24</volume>
					<fpage>9353</fpage>
					<lpage>9360</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b043">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Picton</surname><given-names>TW</given-names></name></person-group>
					<year>1992</year>
					<article-title>The P300 wave of the human event-related potential.</article-title>
					<source>J Clin Neurophysiol</source>
					<volume>9</volume>
					<fpage>456</fpage>
					<lpage>479</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b044">
        <label>44</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Näätänen</surname><given-names>R</given-names></name><name name-style="western"><surname>Picton</surname><given-names>T</given-names></name></person-group>
					<year>1987</year>
					<article-title>The N1 wave of the human electric and magnetic response to sound: a review and an analysis of the component structure.</article-title>
					<source>Psychophysiology</source>
					<volume>24</volume>
					<fpage>375</fpage>
					<lpage>425</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b045">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Hillyard</surname><given-names>SA</given-names></name><name name-style="western"><surname>Hink</surname><given-names>RF</given-names></name><name name-style="western"><surname>Schwent</surname><given-names>VL</given-names></name><name name-style="western"><surname>Picton</surname><given-names>TW</given-names></name></person-group>
					<year>1973</year>
					<article-title>Electrical signs of selective attention in the human brain.</article-title>
					<source>Science</source>
					<volume>182</volume>
					<fpage>177</fpage>
					<lpage>180</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b046">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Alain</surname><given-names>C</given-names></name><name name-style="western"><surname>Woods</surname><given-names>DL</given-names></name></person-group>
					<year>1994</year>
					<article-title>Signal clustering modulates auditory cortical activity in humans.</article-title>
					<source>Percept Psychophys</source>
					<volume>56</volume>
					<fpage>501</fpage>
					<lpage>516</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b047">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Okamoto</surname><given-names>H</given-names></name><name name-style="western"><surname>Stracke</surname><given-names>H</given-names></name><name name-style="western"><surname>Wolters</surname><given-names>CH</given-names></name><name name-style="western"><surname>Schmael</surname><given-names>F</given-names></name><name name-style="western"><surname>Pantev</surname><given-names>C</given-names></name></person-group>
					<year>2007</year>
					<article-title>Attention improves population-level frequency tuning in human auditory cortex.</article-title>
					<source>J Neurosci</source>
					<volume>27</volume>
					<fpage>10383</fpage>
					<lpage>10390</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b048">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Desimone</surname><given-names>R</given-names></name><name name-style="western"><surname>Duncan</surname><given-names>J</given-names></name></person-group>
					<year>1995</year>
					<article-title>Neural mechanisms of selective visual attention.</article-title>
					<source>Annu Rev Neurosci</source>
					<volume>18</volume>
					<fpage>193</fpage>
					<lpage>222</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b049">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Lavie</surname><given-names>N</given-names></name></person-group>
					<year>2006</year>
					<article-title>The role of perceptual load in visual awareness.</article-title>
					<source>Brain Res</source>
					<volume>1080</volume>
					<fpage>91</fpage>
					<lpage>100</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b050">
        <label>50</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bregman</surname><given-names>AS</given-names></name></person-group>
					<year>1990</year>
					<source>Auditory scene analysis</source>
					<publisher-loc>Cambridge (MA)</publisher-loc>
					<publisher-name>MIT Press</publisher-name>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b051">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Fishman</surname><given-names>YI</given-names></name><name name-style="western"><surname>Reser</surname><given-names>DH</given-names></name><name name-style="western"><surname>Arezzo</surname><given-names>JC</given-names></name><name name-style="western"><surname>Steinschneider</surname><given-names>M</given-names></name></person-group>
					<year>2001</year>
					<article-title>Neural correlates of auditory stream segregation in primary auditory cortex of the awake monkey.</article-title>
					<source>Hear Res</source>
					<volume>151</volume>
					<fpage>167</fpage>
					<lpage>187</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b052">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Micheyl</surname><given-names>C</given-names></name><name name-style="western"><surname>Tian</surname><given-names>B</given-names></name><name name-style="western"><surname>Carlyon</surname><given-names>RP</given-names></name><name name-style="western"><surname>Rauschecker</surname><given-names>JP</given-names></name></person-group>
					<year>2005</year>
					<article-title>Perceptual organization of tone sequences in the auditory cortex of awake macaques.</article-title>
					<source>Neuron</source>
					<volume>48</volume>
					<fpage>139</fpage>
					<lpage>148</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b053">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Snyder</surname><given-names>JS</given-names></name><name name-style="western"><surname>Alain</surname><given-names>C</given-names></name><name name-style="western"><surname>Picton</surname><given-names>TW</given-names></name></person-group>
					<year>2006</year>
					<article-title>Effects of attention on neuroelectric correlates of auditory stream segregation.</article-title>
					<source>J Cogn Neurosci</source>
					<volume>18</volume>
					<fpage>1</fpage>
					<lpage>13</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b054">
        <label>54</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Gutschalk</surname><given-names>A</given-names></name><name name-style="western"><surname>Oxenham</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Micheyl</surname><given-names>C</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>EC</given-names></name><name name-style="western"><surname>Melcher</surname><given-names>JR</given-names></name></person-group>
					<year>2007</year>
					<article-title>Human cortical activity during streaming without spectral cues suggests a general neural substrate for auditory stream segregation.</article-title>
					<source>J Neurosci</source>
					<volume>27</volume>
					<fpage>13074</fpage>
					<lpage>13081</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b055">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Corbetta</surname><given-names>M</given-names></name><name name-style="western"><surname>Shulman</surname><given-names>GL</given-names></name></person-group>
					<year>2002</year>
					<article-title>Control of goal-directed and stimulus-driven attention in the brain.</article-title>
					<source>Nat Rev Neurosci</source>
					<volume>3</volume>
					<fpage>201</fpage>
					<lpage>215</lpage>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b056">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Overath</surname><given-names>T</given-names></name><name name-style="western"><surname>Cusack</surname><given-names>R</given-names></name><name name-style="western"><surname>Kumar</surname><given-names>S</given-names></name><name name-style="western"><surname>von Kriegstein</surname><given-names>K</given-names></name><name name-style="western"><surname>Warren</surname><given-names>JD</given-names></name><etal/></person-group>
					<year>2007</year>
					<article-title>An information theoretic characterisation of auditory encoding.</article-title>
					<source>PLoS Biol</source>
					<volume>5</volume>
					<issue>11</issue>
					<elocation-id>e288</elocation-id>
					<comment>doi:<ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pbio.0050288" xlink:type="simple">10.1371/journal.pbio.0050288</ext-link></comment>
				</element-citation>
      </ref>
      <ref id="pbio-0060138-b057">
        <label>57</label>
        <element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Efron</surname><given-names>B</given-names></name><name name-style="western"><surname>Tibshirani</surname><given-names>RJ</given-names></name></person-group>
					<year>1993</year>
					<source>An introduction to the bootstrap</source>
					<publisher-loc>New York</publisher-loc>
					<publisher-name>Chapman and Hall</publisher-name>
				</element-citation>
      </ref>
    </ref-list>
  </back>
</article>
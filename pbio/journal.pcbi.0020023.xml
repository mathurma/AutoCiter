<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN"><front><journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pcbi</journal-id><journal-id journal-id-type="flc">plcb</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="epub">1553-7358</issn><issn pub-type="ppub">1553-734X</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1371/journal.pcbi.0020023</article-id><article-id pub-id-type="publisher-id">05-PLCB-RA-0211R3</article-id><article-id pub-id-type="sici">plcb-02-03-07</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology</subject><subject>Neuroscience</subject><subject>Computational Biology/Systems Biology</subject></subj-group><subj-group subj-group-type="System Taxonomy"><subject>None</subject></subj-group></article-categories><title-group><article-title>The Emergence of Up and Down States in Cortical Networks </article-title><alt-title alt-title-type="running-head">Up and Down States in Cortical Networks</alt-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Holcman</surname><given-names>David</given-names></name><xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref><xref ref-type="fn" rid="n105">
            <sup>¤</sup>
          </xref><xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref></contrib><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Tsodyks</surname><given-names>Misha</given-names></name><xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref><xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref></contrib></contrib-group><aff id="aff1">
				<label>1</label><addr-line> Department of Mathematics, Weizmann Institute of Science, Rehovot, Israel
			</addr-line></aff><aff id="aff2">
				<label>2</label><addr-line> Department of Neurobiology, Weizmann Institute of Science, Rehovot, Israel
			</addr-line></aff><aff id="aff3">
				<label>3</label><addr-line> Departement d'etudes cognitives, Ecole Normale Superieure, Paris, France
			</addr-line></aff><contrib-group><contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes><fn fn-type="con" id="ack1"><p>DM and MT conceived and designed the experiments, performed the experiments, analyzed the data, contributed reagents/materials/analysis tools, and wrote the paper.</p></fn><corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">david.holcman@weizmann.ac.il</email></corresp><fn fn-type="current-aff" id="n105"><p>¤ Current address: Departement de Biologie, INSERM 497, Ecole Normale Supérieure, Paris, France</p></fn><fn fn-type="conflict" id="ack3"><p> The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="ppub"><month>3</month><year>2006</year></pub-date><pub-date pub-type="epub"><day>24</day><month>3</month><year>2006</year></pub-date><pub-date pub-type="epreprint"><day>10</day><month>2</month><year>2006</year></pub-date><volume>2</volume><issue>3</issue><elocation-id>e23</elocation-id><history><date date-type="received"><day>24</day><month>8</month><year>2005</year></date><date date-type="accepted"><day>10</day><month>2</month><year>2006</year></date></history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2006</copyright-year><copyright-holder>Holcman and Tsodyks</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract><p>The cerebral cortex is continuously active in the absence of external stimuli. An example of this spontaneous activity is the voltage transition between an Up and a Down state, observed simultaneously at individual neurons. Since this phenomenon could be of critical importance for working memory and attention, its explanation could reveal some fundamental properties of cortical organization. To identify a possible scenario for the dynamics of Up–Down states, we analyze a reduced stochastic dynamical system that models an interconnected network of excitatory neurons with activity-dependent synaptic depression. The model reveals that when the total synaptic connection strength exceeds a certain threshold, the phase space of the dynamical system contains two attractors, interpreted as Up and Down states. In that case, synaptic noise causes transitions between the states. Moreover, an external stimulation producing a depolarization increases the time spent in the Up state, as observed experimentally. We therefore propose that the existence of Up–Down states is a fundamental and inherent property of a noisy neural ensemble with sufficiently strong synaptic connections.</p></abstract><abstract abstract-type="synopsis"><title>Synopsis</title><p>The cerebral cortex is continuously active in the absence of sensory stimuli. An example of this spontaneous activity is the phenomenon of voltage transitions between two distinct levels, called Up and Down states, observed simultaneously when recoding from many neurons. This phenomenon could be of a critical importance for working memory and attention. Thus, uncovering its biological mechanism could reveal fundamental properties of the cortical organization. In this theoretical contribution, Holcman and Tsodyks propose a mathematical model of cortical dynamics that exhibits spontaneous transitions between Up and Down states. The model describes an activity of a network of interconnected neurons. A crucial component of the model is synaptic depression of interneuronal connections, which is a well-known effect that characterizes many types of synaptic connections in the cortex. Despite its simplicity, the model reproduces many properties of Up–Down transitions that were experimentally observed, and makes several intriguing predictions for future experiments. In particular, the model predicts that the time that a network spends in the Up state is highly variable, changing from a fraction of a second to more than ten seconds, which could have some interesting implications for the temporal characteristics of working memory.</p></abstract><funding-group><funding-statement>DH is the incumbent to the Haas Russell Career Chair in Development at the Weizmann Institute of Science and is partially supported by the French ministry program Chaire d'Excellence. MT is the incumbent to the Gerald and Hedy Oliven Professorial Chair in Brain Research and is partially supported by the Israeli Science Foundation and the Irving B. Harris Foundation.</funding-statement></funding-group><counts><page-count count="8"/></counts><!--===== Restructure custom-meta-wrap to custom-meta-group =====--><custom-meta-group><custom-meta><meta-name>Citation:</meta-name><meta-value>Holcman D, Tsodyks M (2006) The emergence of Up and Down states in cortical networks. PLoS Comput Biol 2(3): e23.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><title>Introduction</title><p>In the absence of sensory inputs, cortical neural networks can exhibit complex patterns of intrinsic activity. The origin of this spontaneous activity in the cortex is still unclear, but recent studies have reported some important characteristics of the dynamics. For example, it has been demonstrated [<xref ref-type="bibr" rid="pcbi-0020023-b003">3</xref>] that the spontaneous population activity in the visual cortex is highly correlated with organized patterns, called orientation map, occurring usually during some specific visual stimulation. In a parallel direction, the studies [<xref ref-type="bibr" rid="pcbi-0020023-b001">1</xref>] using two-photon calcium imaging and [<xref ref-type="bibr" rid="pcbi-0020023-b002">2</xref>] extracellular recordings have reported that single neuron membrane potentials in slice preparations can spontaneously transit between two states, called the Up and Down states. The origin of this phenomenon, originally described in [<xref ref-type="bibr" rid="pcbi-0020023-b004">4</xref>] and [<xref ref-type="bibr" rid="pcbi-0020023-b005">5</xref>], is not precisely known, but the transitions have been ascribed to the intrinsic network property [<xref ref-type="bibr" rid="pcbi-0020023-b006">6</xref>]. Transitions are almost abolished by pharmacological blockers such as glutamate receptor antagonists [<xref ref-type="bibr" rid="pcbi-0020023-b001">1</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b002">2</xref>] and totally abolished by glutamate and GABA receptor antagonists [<xref ref-type="bibr" rid="pcbi-0020023-b001">1</xref>]. As a consequence, the Up and Down state transitions are a good example of how a connected network exhibits a complex correlated dynamic in the absence of any external inputs.</p><p>In previous models based on [<xref ref-type="bibr" rid="pcbi-0020023-b007">7</xref>], the Up to Down state transition was attributed to the effect of neuronal adaptation due the building up activity of <italic>K</italic><sup>+</sup> channels. In [<xref ref-type="bibr" rid="pcbi-0020023-b008">8</xref>], numerical simulations are presented, where the somatic voltage of a neural population shows an Up and Down state activity. However, no arguments are given to explain why there is a unique Up state and why this Up state is stable. Actually, the authors “hypothesized that recurrent synaptic excitation produces a network bistability with an active Up state and an inactive Down state,” where the <italic>I<sub>K−NA</sub></italic> current is responsible for the switching between states. Their picture of the Up and Down state dynamics is explained by a hysteresis loop, which requires a current injection for a specific range of the parameters.</p><p>We propose here to investigate the role of the spontaneous activity in the generation of the Up and Down state transitions, using a modeling approach. We attribute the spontaneous fluctuations to the external noise at the level of neural populations. We demonstrate that in a sufficiently interconnected network which shows activity-dependent synaptic depression, two nonsymmetric attractors emerge. Due to the particular geometry of those attractors, the noise generates a bistability regime (two-state regime) but this is achieved in a very different way, compared with the case of symmetric attractors. When inhibitory connections are included into the model, the results are not changed qualitatively, thus to extract the main ingredients of the Up–Down states phenomena, we have decided to restrict the present analysis to a model containing only excitatory connections. Due to the activity-dependent synaptic depression, which was observed in neocortical slices [<xref ref-type="bibr" rid="pcbi-0020023-b009">9</xref>], the network dynamic does not reach a saturation value. Our model is formulated with a reduced set of two equations (Equation 1) describing the mean activity of a homogeneous population of neurons. The first variable represents the mean activity of the whole population and can be scaled to represent locally the average membrane potential, while the second variable is the mean rate of synaptic depression in the network. This simplified “mean-field” description allows us to analyze the network in the low-dimensional space of these two variables (phase space).</p><p>Our analysis reveals that for certain values of the parameters of the model that characterize the strength of network connectivity, the phase space of the network contains two stable fixed points (attractors) that correspond to the stable stationary values of activity and depression of the network. One of the attractors corresponds to the state of zero activity, and the other one corresponds to higher activity. The basin of attraction associated with the first fixed point (all the initial values of the variables that dynamically flow to this fixed point) corresponds to the Down state of activity, and the basin of attraction of the second fixed point corresponds to the Up state of activity. Noise activity produces random transition between the basins, which generates the Up–Down state dynamics. The model predicts in particular that transition to the Up state is always associated with a spike generated in the network population.</p></sec><sec id="s2"><title>Results</title><sec id="s2a"><title>Dynamics of the Network</title><p>The analysis of the deterministic autonomous dynamical system 1 described in Materials and Methods (when σ = 0 and <italic>I(t)</italic> = 0) reveals that for small values of <italic>w<sub>T</sub></italic>, the phase diagram of the system contains one stable fixed point only, corresponding to zero value of activity (P1: <italic>V</italic> = 0, <italic>μ</italic> = 1). At some minimal value of <italic>w<sub>T</sub></italic>, two more fixed points appear: one saddle point (P3, see <xref ref-type="fig" rid="pcbi-0020023-g001">Figure 1</xref>) and another one—repulsor. If the synaptic strength <italic>w<sub>T</sub></italic> becomes even larger, at a certain critical value <italic>w<sub>c</sub></italic> of the average synaptic weight, a Hopf bifurcation occurs, the repulsor becomes an attractor (P2, see <xref ref-type="fig" rid="pcbi-0020023-g001">Figure 1</xref>), and an unstable limit cycle appears around it (<xref ref-type="fig" rid="pcbi-0020023-g001">Figure 1</xref>A). This analysis was carried out in [<xref ref-type="bibr" rid="pcbi-0020023-b013">13</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b015">15</xref>] and is briefly recapitulated in <xref ref-type="supplementary-material" rid="pcbi-0020023-sd001">Protocol S1</xref>. Intuitively, the Hopf bifurcation occurs when recurrent connections are sufficiently strong to overcome synaptic depression to produce enough recurrent excitation to sustain a persistent Up state. Numerically, <italic>w<sub>c</sub></italic> can be estimated as the value <italic>w<sub>T</sub></italic> where the real part of the linearized matrix of the system 1 crosses 0 from negative to positive, at the critical point <italic>P</italic><sub>2</sub>. Since the dynamical system is smooth near the Up state attractor, the existence of the limit cycle <italic>C</italic>, i.e., the periodic solution to the network equations (Equation 1) corresponding to oscillatory behavior of the network, is guaranteed by the standard theory of Hopf's bifurcation (see [<xref ref-type="bibr" rid="pcbi-0020023-b016">16</xref>]). The critical point <italic>P</italic><sub>1</sub> = (0,1) is always an attractor of the system. To study the role of noise in a depressing neural network, the equations in Equation 1 are analyzed using the phase diagram of the system, represented in <xref ref-type="fig" rid="pcbi-0020023-g001">Figure 1</xref>. <xref ref-type="fig" rid="pcbi-0020023-g001">Figure 1</xref>B represents a trajectory in the phase space. Due to the noise activity, the mean potential V can escape from the basin of attraction of the point <italic>P</italic><sub>1</sub>. This phenomena is the well-known exit problem for a dynamical system perturbed by random noise in general [<xref ref-type="bibr" rid="pcbi-0020023-b017">17</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b018">18</xref>] and for nonuniformly random noise perturbations in a few cases [<xref ref-type="bibr" rid="pcbi-0020023-b019">19</xref>]. When the deterministic system has two basins of attraction, the noise (which only appears in one variable) can lead to transitions between the two states. When the network dynamics relax in the Down state, it approaches closer to the separatrix, where a small fluctuation due to the noise might be enough to produce a transition. However, this transition across the separatrix is not sufficient to produce an Up state, because this region is characterized by an unstable limit cycle. Consequently, further noise fluctuation is necessary to push the network inside the Up state region (which is defined as the region inside the unstable limit cycle, see <xref ref-type="fig" rid="pcbi-0020023-g001">Figure 1</xref>A). In this intermediate region, between the separatrix and the unstable limit cycle, the dynamic is mainly driven by the deterministic part, leading to a fast rotation around the unstable limit cycle. This rotation generates a fast spike of the population voltage. In the more realistic model, the population spike would correspond to a synchronous discharge of many neurons. This peculiar property of the network dynamics was analyzed in detail in [<xref ref-type="bibr" rid="pcbi-0020023-b014">14</xref>], where it was shown that the underlying reason for the emergence of population spikes is the separation of time scales between the voltage dynamics and synaptic depression (<italic>t<sub>r</sub>≫τ</italic>). Under this condition, the population spikes have amplitudes that are much larger than the voltage in the Up state, and a duration that is much faster than the typical duration of Up and Down states.</p><fig id="pcbi-0020023-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020023.g001</object-id><label>Figure 1</label><caption><title>Schematic Representation of the Phase Space (<italic>μ,V</italic>)</title><p>(A) The depression <italic>μ</italic> is plotted on the <italic>x</italic>-axis, while the variable <italic>V</italic> is on the <italic>y</italic>-axis (for the schematic representation, no scale is given). The recurrent sets are the attractor points <italic>P</italic><sub>1</sub> (the Down state), the saddle point <italic>P</italic><sub>3</sub><bold>,</bold> and the attractor <italic>P</italic><sub>2</sub> (the Up state), separated by an unstable limit cycle C (dashed line). The region inside the unstable limit cycle is the basin of attraction of <italic>P</italic><sub>2</sub>. By definition, it is the Up state. For a specific value of the parameter, an homoclinic curve can appear. The unstable branch of the separatrix starting from <italic>P</italic><sub>3</sub> terminates inside the basin of attraction of the Down state. The noise drives the dynamics beyond the separatrices (lines with arrow converging to <italic>P</italic><sub>3</sub>) but a second transition is necessary for a stochastic trajectory to enter inside the Up state delimited by C. However a single noise transition is enough to destabilize the dynamics from the Up to the Down state.</p><p>(B) Example of a trajectory in the phase space.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.g001" xlink:type="simple"/></fig><p>This spike generation in the network population always occurs during a transition from a Down to an Up state, which is a prediction of our model. When the rotation is performed in the phase space, any noise fluctuation can push the dynamics inside the Up state region. The two consecutive transitions are reasonably probable because compared with the amplitude of the noise, the separatrices are located very close to the unstable limit cycle C, as can be seen from a more careful analysis of simulations (unpublished data).</p><p><xref ref-type="fig" rid="pcbi-0020023-g002">Figure 2</xref>A shows the results of simulations in the case when the deterministic system has two basins of attraction (<italic>w<sub>T</sub> &gt; w<sub>c</sub></italic>). The parameters of the model are presented in <xref ref-type="table" rid="pcbi-0020023-t001">Table 1</xref> (for these values of parameters, numerical analysis outlined above produces <italic>w<sub>c</sub></italic> ≈ 10.3). The voltage difference between the Up and Down state is about 15 mV. Such value is approximated by<inline-formula id="pcbi-0020023-ex001"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0020023.ex001" xlink:type="simple"/></inline-formula>
					, as can be seen by finding the steady-state solutions of Equation 1. The population activity in the Down state is much lower than in the Up state but still non-zero, as was observed experimentally (see, e.g., [<xref ref-type="bibr" rid="pcbi-0020023-b027">27</xref>]).
				</p><fig id="pcbi-0020023-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020023.g002</object-id><label>Figure 2</label><caption><title>Up–Down State Dynamics under Normal and Clamp Conditions</title><p>(A) A typical realization of Up–Down transition dynamics in the stochastic model with <italic>w<sub>T</sub></italic> = 12.6.</p><p>Top graph: (Up) average population voltage (mV), baseline at 0 mV; (Down) plot of the depression variable <italic>μ</italic> as a function of time: when the system arrives in the Down state, it is depressed. Then the depression recovers slowly toward 1. Usually the noise is able to produce a transition, before full recovery is achieved.</p><p>Bottom graph: Histogram of the population voltage: fraction of the time spent in a given state. Units are in ms on the <italic>y</italic>-axis and in mV on the <italic>x</italic>-axis: the fraction of total time spent in the Up and Down state is about the same during the 20 s of simulations. The maximum time in the Up state is about 500 ms but the mean maximum time is about 3 s.</p><p>Right column graph of (A): histogram of the duration of the Up states.</p><p>(B) Effect of an external stimulation: depolarization. When a constant external input (I = 0.8) is added into the model, the neural network spends on average more time in the Up state than in Down state. In that case, the attractor point <italic>P</italic><sub>1</sub> is shifted and is now closer to the separatrix.</p><p>(C) Hyperpolarization, simulated by a current injection<italic>.</italic> A hyperpolarization (I = −0.3) drives the ensemble of neurons at a lower mean potential, and as a result the neural network spends on average more time in the Down state.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.g002" xlink:type="simple"/></fig><table-wrap content-type="1col" id="pcbi-0020023-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020023.t001</object-id><label>Table 1</label><caption><p>Values of Parameters Used in the Simulation</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.t001" xlink:type="simple"/><!-- <table-wrap-foot><fn id="nt101"><p>Relative laminar thickness for 21 prefrontal areas was obtained as a fraction of the total cortical depth (see <xref ref-type="sec" rid="s4">Materials and Methods</xref>). Values for layer IV were computed for the subset of areas in which a distinctive granular layer IV existed (13 areas). Probabilities are uncorrected for multiple comparisons.</p></fn></table-wrap-foot> --><!-- <table frame="hsides" rules="none"><colgroup><col id="tb2col1" align="left" charoff="0" char=""/><col id="tb2col2" align="left" charoff="0" char=""/><col id="tb2col3" align="left" charoff="0" char=""/></colgroup><thead><tr><td align="left"><hr/>Gyral</td><td><hr/>Intermediate</td><td><hr/>Sulcal</td></tr></thead><tbody><tr><td>M9, M10, 32, OPro, 13g, D8g, V8g</td><td>11, O12, D46r<sup>a</sup>, M14, OPAll, 24ar, 24ac, M25, 13s</td><td>V46r, D46c, V46c, D8s, V8s</td></tr></tbody></table> --></table-wrap><p>The time course of the voltage is comparable to the Up–Down state dynamics observed experimentally [<xref ref-type="bibr" rid="pcbi-0020023-b001">1</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b002">2</xref>], and in particular each transition from Down to Up is associated with a spiking event. This peak of synchrony was reported using two-photon calcium imaging and it was associated with the time when nearby neurons fire [<xref ref-type="bibr" rid="pcbi-0020023-b001">1</xref>], revealing a transition from a Down to an Up state.</p><p>The transition from the Down to the Up state can be understood as follows: the noise can lead the system to cross the border between the basin of attractions (the separatrix), but not necessarily the limit cycle. In that case, a fast spiking event is generated, as can be observed in <xref ref-type="fig" rid="pcbi-0020023-g002">Figure 2</xref>A, when the dynamic comes back into the Down state. When the dynamic succeeds in getting into the Up state, by a second transition due to noise, it stays there for a certain mean time, which can be approximated by the mean first passage time to the unstable limit cycle. Once the limit cycle is crossed, the dynamic relaxes exponentially to the Down state. This analysis indicates that the consecutive Up state durations are independent from each other, as conjectured in [<xref ref-type="bibr" rid="pcbi-0020023-b020">20</xref>]. Note also that the network undergoes oscillations during the Up state due to the presence of the limit cycle around the attractor P2 (see above). Similar oscillations in the Up state have been observed in the potential trace of single neuron recordings from the barrel cortex of anesthetized rats (I. Lampl, personal communication). Similarly, under whole cell recording of layer 2/3 pyramidal neuron of the barrel cortex, large fluctuations of the membrane potential in the Up state were also reported in [<xref ref-type="bibr" rid="pcbi-0020023-b021">21</xref>]. Since there is no limit cycle around the attractor P1, no oscillations are observed while the network is in the Down state.</p></sec><sec id="s2b"><title>Effects of External Inputs on Up–Down Dynamics</title><p>We study the sensitivity of the Up–Down dynamics to changes in the average value of the external input. To this end, we repeated the simulations of the network dynamics for different average values of <italic>I</italic> (see Equation 1). The results of these simulations are shown in <xref ref-type="fig" rid="pcbi-0020023-g002">Figure 2</xref>A in the absence of any external input. Adding a positive input, which is the equivalent of adding a current injection that depolarizes the cells, increases the time spent in the Up state compared with the control case, as seen in <xref ref-type="fig" rid="pcbi-0020023-g002">Figure 2</xref>B. This result is compatible with the experimental studies, where a similar shift was reported in the response to sensory inputs [<xref ref-type="bibr" rid="pcbi-0020023-b022">22</xref>–<xref ref-type="bibr" rid="pcbi-0020023-b024">24</xref>]. In contrast, adding negative input changes the dynamics in the opposite direction, to the point where the Up state disappears completely, as shown in <xref ref-type="fig" rid="pcbi-0020023-g002">Figure 2</xref>C. We also computed the distribution of the durations of the individual Up state epochs for these three cases (<xref ref-type="fig" rid="pcbi-0020023-g002">Figure 2</xref>, column 3). Surprisingly, we observed the presence of exceptionally long Up state epochs, as reflected in the long tail of the distribution. To complete the analysis, we show the dependency of the mean duration of the Up state and the frequency of Down–Up transitions as a function of external input (<xref ref-type="fig" rid="pcbi-0020023-g003">Figure 3</xref>). While the mean duration increases with the input, as expected, the transition frequency has a unique maximum.</p><fig id="pcbi-0020023-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020023.g003</object-id><label>Figure 3</label><caption><title>Frequency and Duration of the Mean Time Spent in the Up State as a Function of I</title><p>The top graph represents the frequency of Up states as a function of Input I. Hyperpolarizing the neurons is generated for <italic>I</italic> &lt; 0, while depolarization is generated for <italic>I</italic> &gt; 0. The result suggests that there is a unique value of I for which the frequency of the Up state is maximal. In the bottom graph, the mean duration of the Up states is plotted as a function of I.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.g003" xlink:type="simple"/></fig></sec><sec id="s2c"><title>Effects of Changing the Total Synaptic Connections</title><p>When the total synaptic weight <italic>w<sub>T</sub></italic> is changed, it affects the Up and Down state dynamics: increasing <italic>w<sub>T</sub></italic> increases the mean time spent in the Up state and its activity level (<xref ref-type="fig" rid="pcbi-0020023-g004">Figure 4</xref>A), while decreasing <italic>w<sub>T</sub></italic> reduces the time spent in the Up state and the activity level (<xref ref-type="fig" rid="pcbi-0020023-g004">Figure 4</xref>B). Increasing <italic>w<sub>T</sub></italic> can be interpreted as the result of long-term potentiation (LTP), which is known to reinforce the synaptic connections. Qualitatively similar effects were obtained when we changed the value of <italic>U</italic> (unpublished data). Since changes in <italic>w<sub>T</sub></italic> are usually associated with the postsynaptic mechanism of LTP, while changes in <italic>U</italic> are associated with the presynaptic mechanism [<xref ref-type="bibr" rid="pcbi-0020023-b025">25</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b026">26</xref>], these results show that both mechanisms have similar effects on the distribution of network activity between the Up states and Down states.</p><fig id="pcbi-0020023-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020023.g004</object-id><label>Figure 4</label><caption><title>Effect of Synaptic Plasticity on Up–Down State Dynamics</title><p>(A) Effect of increasing <italic>w<sub>T</sub></italic>, which is equivalent to the LTP effect. The effect of LTP is obtained by increasing the total synaptic connections <italic>w<sub>T</sub></italic> to a value of 15. The effect is similar to a depolarization injection current.</p><p>(B) Effect of LTD on Up–Down state dynamics<italic>.</italic> The effect of LTD is obtained by decreasing the total synaptic connections <italic>w<sub>T</sub></italic> to a value of 11. The effect is similar to hyperpolarizing the ensemble of neurons.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.g004" xlink:type="simple"/></fig></sec><sec id="s2d"><title>Interaction between the Network State and the Stimulus</title><p>The functional significance of the spontaneous dynamics is revealed by considering the effect on the cortical response to sensory stimulation. Several experimental studies [<xref ref-type="bibr" rid="pcbi-0020023-b021">21</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b024">24</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b027">27</xref>] reported that neurons respond more strongly if the stimulus arrives during the Down state of activity. To check whether our model can reproduce this effect, we applied brief excitatory pulses with the frequency of 1 Hz and computed the average voltage response separately for stimuli that fell on Up and Down states of the network. The resulting responses are shown in <xref ref-type="fig" rid="pcbi-0020023-g005">Figure 5</xref>. As one can see, the response is much weaker for the Up state, because the synapses are very depressed, making the interactions within the network weaker. If the amplitude of the stimulus, applied during the Up state, is increased, it may trigger a transition to the Down state (unpublished data). This effect was also predicted in [<xref ref-type="bibr" rid="pcbi-0020023-b028">28</xref>] and observed experimentally in [<xref ref-type="bibr" rid="pcbi-0020023-b002">2</xref>].</p><fig id="pcbi-0020023-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0020023.g005</object-id><label>Figure 5</label><caption><title>Average Response to a Brief Excitatory Pulse Which Produces a Small Depolarization in Each State</title><p>The average voltage response is computed. The blue curve shows the response in the Down state. The red curve shows the response in the Up state. The horizontal black bar indicates the duration of the stimulus (starting at <italic>t</italic> = 0 ms). The time response is different in each state, and in agreement with the experimental results of [<xref ref-type="bibr" rid="pcbi-0020023-b027">27</xref>].</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.g005" xlink:type="simple"/></fig></sec></sec><sec id="s3"><title>Discussion</title><p>We conclude that the Up–Down state dynamics can be generated from a stochastic dynamical system that describes the mean activity of a recurrent excitatory network with synaptic depression. Depending on the average <italic>w<sub>T</sub></italic> strength of connections, the dynamical system presents various recurrent sets (<xref ref-type="fig" rid="pcbi-0020023-g001">Figure 1</xref>) that include two stable attractors. The two attractors appear only when a minimal synaptic strength <italic>w<sub>c</sub></italic> is reached. In the absence of synaptic depression, the Up state could only exist at the level of saturation (i.e., at a very high firing rate). This follows easily from the equations, and can be understood intuitively, too, since without depression nothing would prevent the system with recurrent excitation to increase its activity until it reaches saturation. Thus, dynamic fluctuations in the synaptic weights that are due to activity-dependent synaptic depression counterbalance the activity fluctuations and prevent them from growing in amplitude. The role of the intrinsic noise is to produce stochastic transitions from one attractor to another. Thus, if the noise amplitude is small, spontaneous transitions will be rare, but the Up state could still be evoked by an external trigger. This phenomenology could be relevant for working memory. We do not know how to convert <italic>w<sub>c</sub></italic> into a precise measurable quantity, such as the minimum number of synaptic connections that will guarantee the existence of the two states. The model that we presented here is the “mean-field” approximation for the average activity of a large network of spiking neurons. As shown in the literature, it usually provides a qualitatively good description of the network activity (see, e.g., [<xref ref-type="bibr" rid="pcbi-0020023-b014">14</xref>]). In order to have a significant source of noise in the mean-field model (after averaging), the network should receive a spatially correlated noise, e.g., due to common input to different neurons.</p><sec id="s3a"><title>Transition from the Different States</title><p>As predicted in the model, the Up and Down state transition of the network activity from one basin of attraction to another is the result of the noise activity. Since even in the Down state, the network is far from equilibrium (the synapses are always depressed), the mean time the network spends in the Down state is not approximated by the mean first passage to the separatrix, starting near the attractor of the Down state, rather it is comparable to the mean time it takes for the synapses to recover from a certain depressed activity. This deterministic relaxation is not much affected by how strong the noise is. In the Down state, the synaptic depression fluctuates much more than in the Up state. As long as the network is in the Down state, the depression recovers exponentially, until a transition in the Up state is produced.</p><p>A transition from the Up to the Down state is achieved when the noise pushes the dynamics outside the Up state region. The mean time spent in the Up state is the mean first passage time from any point inside of the basin of attraction to the unstable limit cycle and is exponentially long as a function of the amplitude of the noise [<xref ref-type="bibr" rid="pcbi-0020023-b018">18</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b029">29</xref>]. Thus, when the noise amplitude is changed in the numerical simulations, the time spent in the Up state changed (unpublished data).</p><p>When the noise amplitude is increased, the time spent in the Up state decreases and more transition between states occurs. As a consequence, the Up states occurring in slices (where the noise amplitude is supposed to be less than in vivo) should last longer than in vivo.</p><p>The present model does not include any channel activity, which affects the dynamics of the membrane potential. Activation of <italic>K<sup>+</sup></italic> conductances in neostriatal spiny neurons was suggested to produce a stable Up state [<xref ref-type="bibr" rid="pcbi-0020023-b004">4</xref>], and this conductance activity has been used in some models [<xref ref-type="bibr" rid="pcbi-0020023-b008">8</xref>] to explain the transition from the Up to the Down state. Other factors, such as feedback inhibition and synaptic facilitation, could also be involved in the Up–Down state dynamics. However, in our case, we find it remarkable that many of the experimental observations about Up–Down dynamics can be reproduced here within the reduced model, suggesting that synaptic depression could be a dominating mechanism.</p></sec><sec id="s3b"><title>Steady State of the Network and Synaptic Depression</title><p>Analysis of <xref ref-type="fig" rid="pcbi-0020023-g002">Figure 2</xref>A (lower left) shows that synapses are highly depressed most of the time. This suggests that even in the absence of external stimuli, the synaptic noise is sufficient to keep the system far from equilibrium, including the Down state. It is interesting to note that synapses are not functioning near equilibrium, but far from the steady state. As a consequence, the firing rate driven by the noise activity produces synaptic depression. Interestingly, the Up and Down states do not disappear if weak inhibition is added by simulating the extra inhibitory population with linear synapses from and to the excitatory one (unpublished data), rather we found that the main role of inhibition is to decrease the mean time that the system stays in the Up state.</p><p>The assumption that synaptic depression can be a possible mechanism underlying the Up and Down state dynamics has already been suggested in [<xref ref-type="bibr" rid="pcbi-0020023-b021">21</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b024">24</xref>]. As a possible prediction of the model, using the results shown in <xref ref-type="fig" rid="pcbi-0020023-g004">Figure 4</xref>, when <italic>w<sub>T</sub></italic> increases to a certain value, we expect that the Up and Down state dynamics should appear in an ensemble of neurons, as a result of LTP induction. In the opposite direction (<xref ref-type="fig" rid="pcbi-0020023-g004">Figure 4</xref>B), any decrease in the total synaptic weight should lead to an equilibrium state where the Up and Down states completely disappear. We predict that an intermediate stage should appear, where the ensemble generates synchronous spikes, but cannot sustain any Up states. It is conceivable that LTP experiments will increase local connections among only a few neurons, which will generate an Up and Down state activity only for them.</p></sec><sec id="s3c"><title>Up State and Adaptation to Large Stimuli</title><p>Because in the Up state the response of the network to external stimulus is weaker compared with the Down state (see <xref ref-type="fig" rid="pcbi-0020023-g005">Figure 5</xref>), it is conceivable that a neuron makes a transition in the Up state to decrease the amplitude of the response to a large number of action potentials. This transition can be seen as a possible mechanism for adaptation: by decreasing the response in the Up state, the network filters some spikes, but it continues to generate action potential. If the network had stayed in the Down state, a similar spiking activity would have led to a large response, possibly to a saturated regime. Because in the Up state, the mean depression μ is lower than in the Down state, individual neurons become synaptically isolated from the rest of the network. This mechanism of isolation in an Up state provides a possible explanation for the smaller response of individual neurons to stimulus in the Up state compared with the Down state. This was shown theoretically in <xref ref-type="fig" rid="pcbi-0020023-g005">Figure 5</xref> and described experimentally in [<xref ref-type="bibr" rid="pcbi-0020023-b021">21</xref>]). This mechanism is also helpful in understanding the lack of response propagation in the network, as reported in [<xref ref-type="bibr" rid="pcbi-0020023-b021">21</xref>].</p><p>This transition process can be compared with the phenomena of adaptation in cone photoreceptors, appearing when light is increased by several orders of magnitude: cone photoreceptors can continue to modulate light, where usually without adaptation the photoresponse would have been negligible. Conceivably, the dynamics associated with synaptic depression in the Up state is a mechanism of adaptation and has a global effect on the voltage sensitive channels, regulating the firing rate in the Up state.</p></sec><sec id="s3d"><title>Processing Information with Up and Down States</title><p>In [<xref ref-type="bibr" rid="pcbi-0020023-b001">1</xref>], it was reported that independent or weakly coupled small neuronal ensembles generate Up and Down state dynamics. Subsets of neurons are in an Up state while others are in a Down state. Refinement of the present model can be made by considering many neuron ensembles which present each Up and Down state dynamics, and by adding a correlation term in the system of Equation 1 to correlate each independent subsets of neurons. In that case, the temporal sequence of activation of each subnetwork can code information in a more robust manner, rather than would be the case for a single neuron. Thus, those subsets of neurons where Up and Down states are observed may be considered as a second integrated structure, beyond the level of individual neurons. As a consequence, subnetworks that present Up and Down states might be needed to guarantee reliable storage of information. The genesis of such subnetworks might also be considered at an intermediate level between synaptic and cortical plasticity.</p></sec></sec><sec id="s4"><title>Materials and Methods</title><p>We consider a neural network connected by excitatory connections, described by the mean firing rate, which is the average of the firing rate over the population. We do not present here the equations where inhibition connections are added to the model. The change of the mean activity is modeled as a stochastic process. Neurons are connected with depressing synapses, and the state of a synapse is described by the depression parameter <italic>μ</italic> [<xref ref-type="bibr" rid="pcbi-0020023-b010">10</xref>,<xref ref-type="bibr" rid="pcbi-0020023-b012">12</xref>]. The mean activity of such a network can be approximated by the following dynamical system [<xref ref-type="bibr" rid="pcbi-0020023-b011">11</xref>]</p><disp-formula id="pcbi-0020023-e001"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.e001" xlink:type="simple"/><!-- <table-wrap-foot><fn id="nt201"><p>In the designations of architectonic areas the following conventions apply: D, dorsal; M, medial; O, orbital; V, ventral; a, anterior; c, caudal; g, gyral, r, rostral; s, sulcal.</p></fn><fn id="nt202"><p><sup>a</sup>The rostral part of dorsal area 46 (D46r) is situated in the shallow part of the upper bank of the principal sulcus anteriorly, reaching up to the adjacent gyral surface above the sulcus; the rostral part of ventral area 46 (V46r), on the other hand, is situated entirely within the lower bank of the principal sulcus.</p></fn></table-wrap-foot> --><!-- <mml:math display='block'><mml:mrow><mml:mi>x</mml:mi><mml:mi>l</mml:mi><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&minus;</mml:mo><mml:mi>&pi;</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mtext>&ensp;(layer 1),&emsp;</mml:mtext><mml:mrow><mml:mi>x</mml:mi><mml:mi>l</mml:mi><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&minus;</mml:mo><mml:mi>&pi;</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mtext>&ensp;(layer 2).</mml:mtext></mml:math> --><!-- <mml:math display='block'><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&equals;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mtext>&ensp;(layer 1),&emsp;</mml:mtext><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&equals;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mtext>&ensp;(layer 2).</mml:mtext></mml:math> --></disp-formula><p>where <italic>V</italic> is an average synaptic input (measured in mV with a base line at 0 mV), <italic>w<sub>T</sub></italic> measures the average synaptic strength in the network, <italic>I(t)</italic> is an external input, <italic>U</italic> and <italic>t<sub>γ</sub></italic> are utilization parameter and recovery time constants of synaptic depression (see [<xref ref-type="bibr" rid="pcbi-0020023-b012">12</xref>–<xref ref-type="bibr" rid="pcbi-0020023-b014">14</xref>] for a derivation of the auditory cortex). The first term on the right-hand side of the first equation of Equation 1 represents the effect of the intrinsic decay. The second term on the right side represents the synaptic input, which is scaled by the synaptic depression parameter <italic>μ</italic>. The third term on the right side summarizes all uncorrelated sources of noise, with amplitude σ. <italic>R(V</italic>) is an average firing rate (in Hz) given by the threshold-linear dependence on the voltage:</p><disp-formula id="pcbi-0020023-e002"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.e002" xlink:type="simple"/><!-- <mml:math display='block'><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>x</mml:mi><mml:mi>l</mml:mi><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&minus;</mml:mo><mml:mi>&pi;</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&minus;</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mtext>&ensp;(layer 1),</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>x</mml:mi><mml:mi>l</mml:mi><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&minus;</mml:mo><mml:mi>&pi;</mml:mi><mml:msubsup><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&minus;</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&minus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy='false'>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&equals;</mml:mo><mml:mi>&pi;</mml:mi><mml:msub><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy='false'>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&plus;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy='false'>)</mml:mo></mml:mrow><mml:mtext>&ensp;(layer 2).</mml:mtext></mml:mtd></mml:mtr></mml:mtable></mml:math> --></disp-formula><p>where <italic>T</italic> &gt; 0 is a threshold and <italic>α</italic> = 1<italic>HZ/mV</italic> is a conversion factor. The second equation in Equation 1 describes the activity-dependent dynamics of the synaptic depression parameter according to the phenomenological model proposed in [<xref ref-type="bibr" rid="pcbi-0020023-b012">12</xref>]. Briefly, every incoming spike leads to abrupt decrease in the instantaneous synaptic efficacy (by a utilization factor <italic>U</italic>) due to depletion of the neurotransmitter. Between the spikes, synaptic efficacy recovers to its original state (<italic>μ</italic> = 1) with the time constant <italic>t<sub>r</sub></italic>.</p></sec><sec id="s5"><title>Supporting Information</title><supplementary-material id="pcbi-0020023-sd001" mimetype="application/x-tex" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0020023.sd001" xlink:type="simple"><label>Protocol S1</label><caption><title>Fixed Points Analysis</title><p>(2 KB TEX)</p></caption></supplementary-material></sec></body><back><ack><p>We would like to thank R. Cossart, I. Lampl, and B. Gutkin for fruitful discussions and for their comments on the manuscript.</p></ack><glossary><title>Abbreviations</title><def-list><def-item><term>LTP</term><def><p>long-term potentiation</p></def></def-item></def-list></glossary><ref-list><title>References</title><ref id="pcbi-0020023-b001"><label>1</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Cossart</surname><given-names>R</given-names></name><name name-style="western"><surname>Aronov</surname><given-names>D</given-names></name><name name-style="western"><surname>Yuste</surname><given-names>R</given-names></name></person-group>
					<year>2003</year>
					<article-title>Attractor dynamics of network UP states in the neocortex.</article-title>
					<source>Nature</source>
					<volume>423</volume>
					<fpage>283</fpage>
					<lpage>288</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b002"><label>2</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Shu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Hasenstaub</surname><given-names>A</given-names></name><name name-style="western"><surname>McCormick</surname><given-names>DA</given-names></name></person-group>
					<year>2003</year>
					<article-title>Turning on and off recurrent balanced cortical activity.</article-title>
					<source>Nature</source>
					<volume>423</volume>
					<fpage>288</fpage>
					<lpage>293</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b003"><label>3</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kenet</surname><given-names>T</given-names></name><name name-style="western"><surname>Bibitchkov</surname><given-names>D</given-names></name><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name><name name-style="western"><surname>Grinvald</surname><given-names>A</given-names></name><name name-style="western"><surname>Arieli</surname><given-names>A</given-names></name></person-group>
					<year>2003</year>
					<article-title>Spontaneously emerging cortical representations of visual attributes.</article-title>
					<source>Nature</source>
					<volume>425</volume>
					<fpage>954</fpage>
					<lpage>956</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b004"><label>4</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Cowan</surname><given-names>RL</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>CJ</given-names></name></person-group>
					<year>1994</year>
					<article-title>Spontaneous firing patterns and axonal projections of single corticostriatal neurons in the rat medial agranular cortex.</article-title>
					<source>J Neurophysiol</source>
					<volume>71</volume>
					<fpage>17</fpage>
					<lpage>32</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b005"><label>5</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Steriade</surname><given-names>M</given-names></name><name name-style="western"><surname>Nunez</surname><given-names>A</given-names></name><name name-style="western"><surname>Amzica</surname><given-names>F</given-names></name></person-group>
					<year>1993</year>
					<article-title>Intracellular analysis of relations between the slow (&lt;1 Hz) neocortical oscillation and other sleep rhythms of the electroencephalogram.</article-title>
					<source>J Neurosci</source>
					<volume>13</volume>
					<fpage>3266</fpage>
					<lpage>3283</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b006"><label>6</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Lampl</surname><given-names>I</given-names></name><name name-style="western"><surname>Reichova</surname><given-names>I</given-names></name><name name-style="western"><surname>Ferster</surname><given-names>D</given-names></name></person-group>
					<year>1999</year>
					<article-title>Synchronous membrane potential fluctuations in neurons of the cat visual cortex.</article-title>
					<source>Neuron</source>
					<volume>22</volume>
					<fpage>361</fpage>
					<lpage>374</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b007"><label>7</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Sanchez-Vives</surname><given-names>MV</given-names></name><name name-style="western"><surname>McCormick</surname><given-names>DA</given-names></name></person-group>
					<year>2000</year>
					<article-title>Cellular and network mechanisms of rhythmic recurrent activity in neocortex.</article-title>
					<source>Nat Neurosci</source>
					<volume>3</volume>
					<fpage>1027</fpage>
					<lpage>1034</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b008"><label>8</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Compte</surname><given-names>A</given-names></name><name name-style="western"><surname>Sanchez-Vives</surname><given-names>MV</given-names></name><name name-style="western"><surname>McCormick</surname><given-names>DA</given-names></name><name name-style="western"><surname>Wang</surname><given-names>XJ</given-names></name></person-group>
					<year>2003</year>
					<article-title>Cellular and network mechanisms of slow oscillatory activity (&lt;1Hz) and wave propagations in a cortical network model.</article-title>
					<source>J Neurophysiol</source>
					<volume>89</volume>
					<fpage>2707</fpage>
					<lpage>2725</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b009"><label>9</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Thomson</surname><given-names>AM</given-names></name><name name-style="western"><surname>Deuchars</surname><given-names>J</given-names></name></person-group>
					<year>1994</year>
					<article-title>Temporal and spatial properties of local circuits in neocortex.</article-title>
					<source>Trends Neurosci</source>
					<volume>17</volume>
					<fpage>119</fpage>
					<lpage>126</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b010"><label>10</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name><name name-style="western"><surname>Varela</surname><given-names>JA</given-names></name><name name-style="western"><surname>Sen</surname><given-names>K</given-names></name><name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name></person-group>
					<year>1997</year>
					<article-title>Synaptic depression and cortical gain control.</article-title>
					<source>Science</source>
					<volume>275</volume>
					<fpage>179</fpage>
					<lpage>180</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b011"><label>11</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name></person-group>
					<year>2005</year>
					<source>Theoretical neuroscience: Computational and mathematical modeling of neural systems</source>
					<publisher-loc>Cambridge (Massachusetts)</publisher-loc>
					<publisher-name>The MIT Press</publisher-name>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">576</size>
					<comment>p.</comment>
				</element-citation></ref><ref id="pcbi-0020023-b012"><label>12</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Tsodyks</surname><given-names>MV</given-names></name><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name></person-group>
					<year>1997</year>
					<article-title>The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability. Proc Natl Acad Sci U S A 94: 719–723.</article-title>
					<source>Erratum in: Proc Natl Acad Sci U S A</source>
					<volume>94</volume>
					<fpage>5495</fpage>
				</element-citation></ref><ref id="pcbi-0020023-b013"><label>13</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Bart</surname><given-names>E</given-names></name><name name-style="western"><surname>Bao</surname><given-names>S</given-names></name><name name-style="western"><surname>Holcman</surname><given-names>D</given-names></name></person-group>
					<year>2006</year>
					<article-title>Modeling the spontaneous activity of the auditory cortex.</article-title>
					<source>J Comput Neurosci</source>
					<comment>In press.</comment>
				</element-citation></ref><ref id="pcbi-0020023-b014"><label>14</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Loebel</surname><given-names>A</given-names></name><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name></person-group>
					<year>2002</year>
					<article-title>Computation by ensemble synchronization in recurrent networks with synaptic depression.</article-title>
					<source>J Comput Neurosci</source>
					<volume>13</volume>
					<fpage>111</fpage>
					<lpage>124</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b015"><label>15</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name><name name-style="western"><surname>Pawelzik</surname><given-names>K</given-names></name><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name></person-group>
					<year>1998</year>
					<article-title>Neural networks with dynamic synapses.</article-title>
					<source>Neural Comput</source>
					<volume>10</volume>
					<fpage>821</fpage>
					<lpage>835</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b016"><label>16</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Kuznetsov</surname></name><name name-style="western"><surname>Yu</surname><given-names>A</given-names></name></person-group>
					<year>2004</year>
					<source>Elements of applied bifurcation theory. Third edition</source>
					<publisher-loc>New York</publisher-loc>
					<publisher-name>Springer-Verlag</publisher-name>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">631</size>
					<comment>p.</comment>
				</element-citation></ref><ref id="pcbi-0020023-b017"><label>17</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Freidlin</surname><given-names>MI</given-names></name><name name-style="western"><surname>Wentzell</surname><given-names>AD</given-names></name></person-group>
					<year>1984</year>
					<source>Random perturbations of dynamical systems</source>
					<publisher-loc>New York</publisher-loc>
					<publisher-name>Springer-Verlag</publisher-name>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">260</size>
					<comment>p.</comment>
				</element-citation></ref><ref id="pcbi-0020023-b018"><label>18</label><element-citation publication-type="other" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Schuss</surname><given-names>Z</given-names></name></person-group>
					<year>1980</year>
					<source>Theory and applications of stochastic differential equations. Wiley Series in Probability and Statistics</source>
					<publisher-loc>New York</publisher-loc>
					<publisher-name>John Wiley &amp; Sons</publisher-name>
					<!--===== Restructure page-count as size[@units="page"] =====--><size units="page">321</size>
					<comment>p.</comment>
				</element-citation></ref><ref id="pcbi-0020023-b019"><label>19</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Klosek-Dygas</surname><given-names>MM</given-names></name><name name-style="western"><surname>Matkowsky</surname><given-names>BJ</given-names></name><name name-style="western"><surname>Schuss</surname><given-names>Z</given-names></name></person-group>
					<year>1988</year>
					<article-title>Colored noise in dynamical systems.</article-title>
					<source>SIAM J Appl Math</source>
					<volume>48</volume>
					<fpage>425</fpage>
					<lpage>441</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b020"><label>20</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Stern</surname><given-names>EA</given-names></name><name name-style="western"><surname>Kincaid</surname><given-names>AE</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>CJ</given-names></name></person-group>
					<year>1997</year>
					<article-title>Spontaneous subthreshold membrane potential fluctuations and action potential variability of rat corticostriatal and striatal neurons in vivo.</article-title>
					<source>J Neurophysiol</source>
					<volume>77</volume>
					<fpage>1697</fpage>
					<lpage>1715</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b021"><label>21</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Petersen</surname><given-names>CC</given-names></name><name name-style="western"><surname>Hahn</surname><given-names>TT</given-names></name><name name-style="western"><surname>Mehta</surname><given-names>M</given-names></name><name name-style="western"><surname>Grinvald</surname><given-names>A</given-names></name><name name-style="western"><surname>Sakmann</surname><given-names>B</given-names></name></person-group>
					<year>2003</year>
					<article-title>Interaction of sensory responses with spontaneous depolarization in layer 2/3 barrel cortex.</article-title>
					<source>Proc Natl Acad Sci U S A</source>
					<volume>100</volume>
					<fpage>13638</fpage>
					<lpage>13643</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b022"><label>22</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Anderson</surname><given-names>J</given-names></name><name name-style="western"><surname>Lampl</surname><given-names>I</given-names></name><name name-style="western"><surname>Reichova</surname><given-names>I</given-names></name><name name-style="western"><surname>Carandini</surname><given-names>M</given-names></name><name name-style="western"><surname>Ferster</surname><given-names>D</given-names></name></person-group>
					<year>2000</year>
					<article-title>Stimulus dependence of two-state fluctuations of membrane potential in cat visual cortex.</article-title>
					<source>Nat Neurosci</source>
					<volume>3</volume>
					<fpage>617</fpage>
					<lpage>621</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b023"><label>23</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Anderson</surname><given-names>JS</given-names></name><name name-style="western"><surname>Lampl</surname><given-names>I</given-names></name><name name-style="western"><surname>Gillespie</surname><given-names>DC</given-names></name><name name-style="western"><surname>Ferster</surname><given-names>D</given-names></name></person-group>
					<year>2000</year>
					<article-title>The contribution of noise to contrast invariance of orientation tuning in cat visual cortex.</article-title>
					<source>Science</source>
					<volume>290</volume>
					<fpage>1968</fpage>
					<lpage>1972</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b024"><label>24</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Sachdev</surname><given-names>RN</given-names></name><name name-style="western"><surname>Ebner</surname><given-names>FF</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>CJ</given-names></name></person-group>
					<year>2004</year>
					<article-title>Effect of subthreshold up and down states on the whisker-evoked response in somatosensory cortex.</article-title>
					<source>J Neurophysiol</source>
					<volume>92</volume>
					<fpage>3511</fpage>
					<lpage>3521</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b025"><label>25</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Markram</surname><given-names>H</given-names></name><name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name></person-group>
					<year>1996</year>
					<article-title>Redistribution of synaptic efficacy between neocortical pyramidal neurons.</article-title>
					<source>Nature</source>
					<volume>382</volume>
					<fpage>807</fpage>
					<lpage>810</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b026"><label>26</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Selig</surname><given-names>DK</given-names></name><name name-style="western"><surname>Nicoll</surname><given-names>RA</given-names></name><name name-style="western"><surname>Malenka</surname><given-names>RC</given-names></name></person-group>
					<year>1999</year>
					<article-title>Hippocampal long-term potentiation preserves the fidelity of postsynaptic responses to presynaptic bursts.</article-title>
					<source>J Neurosci</source>
					<volume>19</volume>
					<fpage>1236</fpage>
					<lpage>1246</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b027"><label>27</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Leger</surname><given-names>JF</given-names></name><name name-style="western"><surname>Stern</surname><given-names>EA</given-names></name><name name-style="western"><surname>Aertsen</surname><given-names>A</given-names></name><name name-style="western"><surname>Heck</surname><given-names>D</given-names></name></person-group>
					<year>2005</year>
					<article-title>Synaptic integration in rat frontal cortex shaped by network activity.</article-title>
					<source>J Neurophysiol</source>
					<volume>93</volume>
					<fpage>281</fpage>
					<lpage>293</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b028"><label>28</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Gutkin</surname><given-names>BS</given-names></name><name name-style="western"><surname>Laing</surname><given-names>CR</given-names></name><name name-style="western"><surname>Colby</surname><given-names>CL</given-names></name><name name-style="western"><surname>Chow</surname><given-names>CC</given-names></name><name name-style="western"><surname>Ermentrout</surname><given-names>GB</given-names></name></person-group>
					<year>2001</year>
					<article-title>Turning on and off with excitation: The role of spike-timing asynchrony and synchrony in sustained neural activity.</article-title>
					<source>J Comput Neurosci</source>
					<volume>11</volume>
					<fpage>121</fpage>
					<lpage>134</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b029"><label>29</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Naeh</surname><given-names>T</given-names></name><name name-style="western"><surname>Klosek</surname><given-names>MM</given-names></name><name name-style="western"><surname>Matkowsky</surname><given-names>BJ</given-names></name><name name-style="western"><surname>Schuss</surname><given-names>Z</given-names></name></person-group>
					<year>1990</year>
					<article-title>A direct approach to the exit problem.</article-title>
					<source>SIAM J Appl Math</source>
					<volume>50</volume>
					<fpage>595</fpage>
					<lpage>627</lpage>
				</element-citation></ref><ref id="pcbi-0020023-b030"><label>30</label><element-citation publication-type="journal" xlink:type="simple">
					<person-group person-group-type="author"><name name-style="western"><surname>Malenka</surname><given-names>RC</given-names></name><name name-style="western"><surname>Nicoll</surname><given-names>RA</given-names></name></person-group>
					<year>1999</year>
					<article-title>Long-term potentiation—A decade of progress?</article-title>
					<source>Science</source>
					<volume>285</volume>
					<fpage>1870</fpage>
					<lpage>1874</lpage>
				</element-citation></ref></ref-list></back></article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id><journal-title-group>
<journal-title>PLoS Computational Biology</journal-title></journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-13-00498</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1003439</article-id>
<article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Consequences of Converting Graded to Action Potentials upon Neural Information Coding and Energy Efficiency</article-title>
<alt-title alt-title-type="running-head">Signal Encoding and Efficiency</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Sengupta</surname><given-names>Biswa</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>Simon Barry</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Niven</surname><given-names>Jeremy Edward</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
</contrib-group>
<aff id="aff1"><label>1</label><addr-line>Wellcome Trust Centre for Neuroimaging, University College London, London, United Kingdom</addr-line></aff>
<aff id="aff2"><label>2</label><addr-line>Centre for Neuroscience, Indian Institute of Science, Bangalore, India</addr-line></aff>
<aff id="aff3"><label>3</label><addr-line>Department of Zoology, University of Cambridge, Cambridge, United Kingdom</addr-line></aff>
<aff id="aff4"><label>4</label><addr-line>School of Life Sciences and Centre for Computational Neuroscience and Robotics, University of Sussex, Falmer, Brighton, United Kingdom</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Sporns</surname><given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, United States of America</addr-line></aff>
<author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">b.sengupta@ucl.ac.uk</email> (BS); <email xlink:type="simple">J.E.Niven@sussex.ac.uk</email> (JEN)</corresp>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn>
<fn fn-type="con"><p>Conceived and designed the experiments: BS SBL JEN. Performed the experiments: BS. Analyzed the data: BS SBL JEN. Contributed reagents/materials/analysis tools: BS SBL JEN. Wrote the paper: BS SBL JEN.</p></fn>
</author-notes>
<pub-date pub-type="collection"><month>1</month><year>2014</year></pub-date>
<pub-date pub-type="epub"><day>23</day><month>1</month><year>2014</year></pub-date>
<volume>10</volume>
<issue>1</issue>
<elocation-id>e1003439</elocation-id>
<history>
<date date-type="received"><day>25</day><month>3</month><year>2013</year></date>
<date date-type="accepted"><day>2</day><month>12</month><year>2013</year></date>
</history>
<permissions>
<copyright-year>2014</copyright-year>
<copyright-holder>Sengupta et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
<abstract>
<p>Information is encoded in neural circuits using both graded and action potentials, converting between them within single neurons and successive processing layers. This conversion is accompanied by information loss and a drop in energy efficiency. We investigate the biophysical causes of this loss of information and efficiency by comparing spiking neuron models, containing stochastic voltage-gated Na<sup>+</sup> and K<sup>+</sup> channels, with generator potential and graded potential models lacking voltage-gated Na<sup>+</sup> channels. We identify three causes of information loss in the generator potential that are the by-product of action potential generation: (1) the voltage-gated Na<sup>+</sup> channels necessary for action potential generation increase intrinsic noise and (2) introduce non-linearities, and (3) the finite duration of the action potential creates a ‘footprint’ in the generator potential that obscures incoming signals. These three processes reduce information rates by ∼50% in generator potentials, to ∼3 times that of spike trains. Both generator potentials and graded potentials consume almost an order of magnitude less energy per second than spike trains. Because of the lower information rates of generator potentials they are substantially less energy efficient than graded potentials. However, both are an order of magnitude more efficient than spike trains due to the higher energy costs and low information content of spikes, emphasizing that there is a two-fold cost of converting analogue to digital; information loss and cost inflation.</p>
</abstract>
<abstract abstract-type="summary"><title>Author Summary</title>
<p>As in electronics, many of the brain's neural circuits convert continuous time signals into a discrete-time binary code. Although some neurons use only graded voltage signals, most convert these signals into discrete-time action potentials. Yet the costs and benefits associated with such a switch in signalling mechanism are largely unexplored. We investigate why the conversion of graded potentials to action potentials is accompanied by substantial information loss and how this changes energy efficiency. Action potentials are generated by a large cohort of noisy Na<sup>+</sup> channels. We show that this channel noise and the added non-linearity of Na<sup>+</sup> channels destroy input information provided by graded generator potentials. Furthermore, action potentials themselves cause information loss due to their finite widths because the neuron is oblivious to the input that is arriving during an action potential. Consequently, neurons with high firing rates lose a large amount of the information in their inputs. The additional cost incurred by voltage-gated Na<sup>+</sup> channels also means that action potentials can encode less information per unit energy, proving metabolically inefficient, and suggesting penalisation of high firing rates in the nervous system.</p>
</abstract>
<funding-group><funding-statement>BS was supported by a Wellcome Trust Early Career Fellowship, JEN was supported by a Royal Society University Research Fellowship. This work made use of the facilities of HECToR, the UK's national high-performance computing service, which is provided by UoE HPCx Ltd at the University of Edinburgh, Cray Inc and NAG Ltd, and funded by the Office of Science and Technology through EPSRC's High End Computing Programme. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="18"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Information is encoded, processed and transmitted in neural circuits both as graded potentials (continuous, analogue) and action potentials (pulsatile, digital). Although sensory and chemical synaptic inputs to neurons are graded <xref ref-type="bibr" rid="pcbi.1003439-Roberts1">[1]</xref>, in most neurons these are converted into a train of action potentials. This conversion overcomes the attenuation of graded signals that occurs as they are propagated over long distances within the nervous system <xref ref-type="bibr" rid="pcbi.1003439-Jack1">[2]</xref>, and may prevent noise accumulation in neural networks because pulsatile signals are restored at each successive processing stage <xref ref-type="bibr" rid="pcbi.1003439-Laughlin1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Sarpeshkar1">[4]</xref>. However, because spike trains use discrete pulses of finite precision they have a lower dimensionality than analogue voltage signals, reducing their signal entropy <xref ref-type="bibr" rid="pcbi.1003439-Sarpeshkar1">[4]</xref>. Consequently, spike trains can encode fewer states within a given time period than analogue voltage signals. This is borne out by experimental measurements that show the conversion of the graded generator potential into a spike train reduces the information rate <xref ref-type="bibr" rid="pcbi.1003439-DiCaprio1">[5]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-Juusola1">[7]</xref>. Thus, non-spiking neurons that encode information as graded potentials typically have much higher information rates than spiking neurons <xref ref-type="bibr" rid="pcbi.1003439-DiCaprio1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1003439-vanSteveninck1">[8]</xref>,<xref ref-type="bibr" rid="pcbi.1003439-Theunissen1">[9]</xref>.</p>
<p>A drop in the energy efficiency of information coding has also been suggested to accompany the conversion of graded to action potentials <xref ref-type="bibr" rid="pcbi.1003439-Laughlin1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Niven1">[10]</xref>. Neuronal energy consumption is dominated by the influx/efflux of ions, which must be pumped back across the cell membrane by the Na<sup>+</sup>/K<sup>+</sup> ATPase consuming ATP <xref ref-type="bibr" rid="pcbi.1003439-Laughlin1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Sengupta1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Attwell1">[12]</xref>. These ion movements can incur substantial energy costs even in graded potential neurons <xref ref-type="bibr" rid="pcbi.1003439-Laughlin1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Niven2">[13]</xref>. However, the large Na<sup>+</sup> influx during action potentials requires additional cellular energy to extrude, though the precise energy cost will vary among neuron types <xref ref-type="bibr" rid="pcbi.1003439-Sengupta1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Alle1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-Hasenstaub1">[16]</xref>.</p>
<p>Our aim is to identify the causes of the loss of information and energy efficiency when graded potentials are converted to action potentials. Although some causes of information loss in spiking neurons have been studied previously, such as channel noise <xref ref-type="bibr" rid="pcbi.1003439-White1">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-Manwani2">[19]</xref> or dimensionality reduction <xref ref-type="bibr" rid="pcbi.1003439-French1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-AguerayArcas1">[20]</xref>, in most cases their effects on information rates have not been quantified. We quantified both information rates and energy efficiency using single compartment models. We compared the information rates, energy consumptions and energy efficiencies of spike trains with those of the generator potentials that triggered the spike trains, and of the graded response produced in the absence of voltage-gated Na<sup>+</sup> channels. We find that three previously unreported effects reduce the information rate and efficiency of the generator potential by 50%; namely the finite durations of action potentials, and the noise and nonlinearity introduced by voltage-gated ion channels. The effect of channel noise on spike timing reduces the information rate and efficiency by &lt;10%. We conclude that the conversion of graded signals to “digital” action potentials imposes two penalties; spikes increase energy costs and both spike coding mechanisms and the spike code reduce information rates. As a result energy efficiency falls by well over 90%.</p>
</sec><sec id="s2">
<title>Results</title>
<p>We simulated the responses of a 100 µm<sup>2</sup> single compartment model containing stochastic voltage-gated Na<sup>+</sup> and K<sup>+</sup> channels to a 300 Hz band-limited white-noise current stimulus to assess information coding in a spiking neuron model (see <xref ref-type="sec" rid="s4">Methods</xref>) (<xref ref-type="fig" rid="pcbi-1003439-g001">Figure 1A,B</xref>). By altering the stimulus mean and standard deviation the model captured a wide range of neuronal activity patterns. Low mean, high standard deviation inputs produced voltage responses that resembled relay neurons, the activity of which is dominated by large post-synaptic potentials from relatively few pre-synaptic neurons, such as principle cells of the Medial Nucleus of the Trapezoid Body that receive synaptic inputs from the Calyx of Held <xref ref-type="bibr" rid="pcbi.1003439-Lenn1">[21]</xref>. High mean, low standard deviation inputs produced voltage responses that resembled those of integrator neurons, the activity of which is determined by a large number of small post-synaptic potentials, such as motor neurons <xref ref-type="bibr" rid="pcbi.1003439-Rekling1">[22]</xref>.</p>
<fig id="pcbi-1003439-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g001</object-id><label>Figure 1</label><caption>
<title>Voltage responses of spiking and graded potentials.</title>
<p>A. The band-limited 300 Hz filtered Gaussian white noise current stimulus. B. The probably density function (PDF) of the current stimulus shown in A. C. A voltage response of the spiking neuron model to the current stimulus shown in A. D. The PDF of the spiking neuron model's voltage response. E. A voltage response of the graded neuron model to the current stimulus shown in A. F. The PDF of the graded neuron model's voltage response. (Inset) A QQ plot showing departures from a Gaussian distribution (dotted red-line) for the time-series shown in E.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g001" position="float" xlink:type="simple"/></fig>
<p>By incorporating voltage-gated Na<sup>+</sup> and K<sup>+</sup> channels within the same compartment as a current input stimulus, we modelled the conversion of an analogue signal into a train of action potentials (APs or spikes), as would occur at the spike initiation zone of a neuron <xref ref-type="bibr" rid="pcbi.1003439-Koch1">[23]</xref>. No extrinsic noise was added to the current stimulus in most of our simulations, consequently stochastic fluctuations of the voltage-gated ion channels were the only noise source. This stimulus produced small, sub-threshold graded fluctuations in membrane potential as well as action potentials approximately 100 mV in amplitude (<xref ref-type="fig" rid="pcbi-1003439-g001">Figure 1C</xref>). These transient 100 mV excursions to the peak voltage produced a skewed probability density function (PDF) of the membrane potential with a long tail (<xref ref-type="fig" rid="pcbi-1003439-g001">Figure 1D</xref>).</p>
<p>We compared the information encoded by the spiking neuron model with that encoded by an equivalent analogue model in response to the same white-noise current stimuli with varying mean amplitudes and standard deviations (<xref ref-type="fig" rid="pcbi-1003439-g001">Figure 1E,F</xref>). The analogue model lacked voltage-gated Na<sup>+</sup> channels but was identical to the spiking neuron model in all other respects. In this model, current stimuli produced small, graded fluctuations in membrane potential with an approximately Gaussian PDF (<xref ref-type="fig" rid="pcbi-1003439-g001">Figure 1F</xref>). We extracted the power spectra of the signal and noise from these graded fluctuations and used them to calculate Shannon information rates <xref ref-type="bibr" rid="pcbi.1003439-Cover1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref> (<xref ref-type="sec" rid="s4">Methods</xref>). The rates at which spike trains coded information was calculated from the total entropy and noise entropy of the spikes using the direct method <xref ref-type="bibr" rid="pcbi.1003439-Strong1">[26]</xref>. Both models, graded and spiking, encoded the most information when stimulated by low mean, high standard deviation currents and the least information with high mean, low standard deviation currents (<xref ref-type="fig" rid="pcbi-1003439-g002">Figure 2A,B</xref>). Thus, the information rate of both neuron models is critically dependent upon the statistics of the input stimulus.</p>
<fig id="pcbi-1003439-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g002</object-id><label>Figure 2</label><caption>
<title>Information encoding in the spiking and graded neuron models.</title>
<p>A. Information rates (bits s<sup>−1</sup>) of the spiking neuron model evoked by white noise current stimuli with different means and standard deviations. B. Information rates (bits s<sup>−1</sup>) of the graded neuron model evoked by the same white noise current stimuli as in A.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g002" position="float" xlink:type="simple"/></fig>
<p>The information encoded by the graded neuron model for each input stimulus was greater than that of the spiking neuron model (<xref ref-type="fig" rid="pcbi-1003439-g002">Figure 2A,B</xref>). The highest information rate attained by the spiking neuron model was 235 bits/s, whereas the graded neuron model attained information rates of 2240 bits/s. Thus, the graded neuron model encodes almost an order of magnitude more information per second than the spiking neuron model, reproducing experimentally observed differences between graded and spiking neurons <xref ref-type="bibr" rid="pcbi.1003439-DiCaprio1">[5]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-vanSteveninck1">[8]</xref>.</p>
<p>Information coding in spiking neurons is dependent upon the rate and timing of the action potentials with which it samples the input stimulus <xref ref-type="bibr" rid="pcbi.1003439-MacKay1">[27]</xref>. We calculated the firing rate of the spiking neuron model in response to the same set of band-limited white noise current stimuli used previously to calculate information rates (see <xref ref-type="sec" rid="s4">Methods</xref>) (<xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3A</xref>). Increasing the stimulus mean or standard deviation increased the firing rate; low mean, high standard deviation or high mean, low standard deviation stimuli produced approximately 57 spikes/s whereas high mean, high standard deviation stimuli generated the highest spike rates of approximately 86 spikes/s (<xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3A</xref>). Because these firing rates are lower than the maximum firing rates that the spiking neuron model can achieve, the information rates are not limited by the absolute refractory period.</p>
<fig id="pcbi-1003439-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g003</object-id><label>Figure 3</label><caption>
<title>The effect of stimulus statistics upon the rate, timing and precision of action potentials.</title>
<p>A. Firing rates (spikes s<sup>−1</sup>) of the spiking neuron model evoked by white noise current stimuli with different means and standard deviations. The current stimuli used in A–D were identical to those in <xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3A</xref>. B. Total entropy (bits s<sup>−1</sup>), C. Noise entropy (bits s<sup>−1</sup>), and D. Information rate per spike (bits spike<sup>−1</sup>) of the spiking neuron model.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g003" position="float" xlink:type="simple"/></fig>
<p>The total entropy of a spike train reflects its total variability over time <xref ref-type="bibr" rid="pcbi.1003439-Strong1">[26]</xref>. The highest total entropy occurred with high mean, high standard deviation stimuli that produced the highest spike rates, conversely, the lowest total entropy occurred with low mean, low standard deviation stimuli that produced the lowest spike rates (<xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3B</xref>). However, noise prevents neurons from achieving the maximal information rates, as bounded by the total entropy <xref ref-type="bibr" rid="pcbi.1003439-Strong1">[26]</xref>. We quantified the differences in action potential reliability by calculating the noise entropy among spike trains generated by many repetitions of an identical current stimulus (<xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3C</xref>). Increasing the stimulus standard deviation increased the number of transients in the stimulus that cross the voltage threshold at high velocity. Consequently, high standard deviation stimuli generated spike trains that were both precise and reliable among trials with low noise entropy (<xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3C</xref>; <xref ref-type="supplementary-material" rid="pcbi.1003439.s001">Figure S1A</xref>) <xref ref-type="bibr" rid="pcbi.1003439-Mainen1">[28]</xref>. Conversely, as the mean increased the variance in the interspike interval influenced spike timing, reducing the reliability of the spike trains and increasing the noise entropy (<xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3C</xref>; <xref ref-type="supplementary-material" rid="pcbi.1003439.s001">Figure S1B</xref>).</p>
<p>The total and noise entropy together determine the information rate of the spiking neuron model for a particular input stimulus (<xref ref-type="fig" rid="pcbi-1003439-g002">Figure 2A</xref>). Low mean, high standard deviation stimuli generated spike trains that have only intermediate firing rates and total entropies but have the highest information rates due to their low noise entropy. High mean, high standard deviation stimuli generated spike trains with lower information rates despite their higher firing rates because noise entropy is higher. Consequently, the information per spike was highest (4 bits/spike) with low mean, high standard deviation stimuli that produced the highest information rates (235 bits/s) with only moderate firing rates (57 Hz), and lowest (0.2 bits/spike) with high mean, low standard deviation stimuli that produced the lowest information rates (10.2 bits/s), also with moderate firing rates (58 Hz) (<xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3D</xref>).</p>
<sec id="s2a">
<title>Channel noise and spiking</title>
<p>To determine the effect of noise generated by the voltage-gated Na<sup>+</sup> and K<sup>+</sup> channels on the information rates of the spiking neuron model, we replaced either the stochastic Na<sup>+</sup> or K<sup>+</sup> channels with deterministic channels thereby eliminating this component of the channel noise. In comparison to the stochastic model, the deterministic Na<sup>+</sup> channel model generated more reliable spike trains for a given stimulus (<xref ref-type="supplementary-material" rid="pcbi.1003439.s001">Figure S1A</xref>,S2A). Similarly, replacing the stochastic K<sup>+</sup> channels in the spiking neuron model with deterministic channels also generated more reliable spike trains for a given stimulus in comparison to the original spiking neuron model (<xref ref-type="supplementary-material" rid="pcbi.1003439.s001">Figure S1A</xref>,S2B).</p>
<p>We quantified differences in the reliability between the original stochastic spiking neuron model, the modified model with deterministic Na<sup>+</sup>/stochastic K<sup>+</sup> channels, and the modified model with stochastic Na<sup>+</sup>/deterministic K<sup>+</sup> channels. We compared the total entropy, noise entropy, information rate and information per spike for spike trains generated by low mean, high standard deviation stimuli or high mean, low standard deviation stimuli (<xref ref-type="fig" rid="pcbi-1003439-g004">Figure 4</xref>). All three models produced 50–57 spikes/s in response to the stimuli (<xref ref-type="fig" rid="pcbi-1003439-g004">Figure 4A</xref>). In comparison to the original spiking neuron model with stochastic Na<sup>+</sup> and K<sup>+</sup> channels, the total entropy of the deterministic K<sup>+</sup> channel model was lower by 1–7%, whereas the total entropy of the deterministic Na<sup>+</sup> model was almost identical (<xref ref-type="fig" rid="pcbi-1003439-g004">Figure 4B</xref>). The deterministic K<sup>+</sup> channel model also had the lowest noise entropy, making the APs more reliable (<xref ref-type="fig" rid="pcbi-1003439-g004">Figure 4C</xref>). Both models with deterministic ion channels had higher information rates than the original model because of their lower noise entropy, but the difference was just 7%, irrespective of the stimulus statistics (<xref ref-type="fig" rid="pcbi-1003439-g004">Figure 4D</xref>). This suggests that channel noise has relatively little impact on the information rate of the 100 µm<sup>2</sup> single compartments we modelled. Thus, in addition to channel noise and dimensionality reduction, there must be other sources of information loss.</p>
<fig id="pcbi-1003439-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g004</object-id><label>Figure 4</label><caption>
<title>The information rates of the spiking neuron model are robust to voltage-gated ion channel noise.</title>
<p>A. The firing rates of the spiking neuron model (stochastic voltage-gated Na<sup>+</sup> and K<sup>+</sup> channels), a modified model with stochastic voltage-gated Na<sup>+</sup> and deterministic voltage-gated K<sup>+</sup> channels and a modified model with deterministic voltage-gated Na<sup>+</sup> and stochastic voltage-gated K<sup>+</sup> channels evoked by low mean, high standard deviation or high mean, low standard deviation input stimuli. B. The total entropy, C. The noise entropy, and D. The mutual information rates of the same models shown in A evoked by the same stimuli.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g004" position="float" xlink:type="simple"/></fig></sec><sec id="s2b">
<title>Information encoded in the generator potential</title>
<p>The information in the spike train comes from the generator potential (<xref ref-type="fig" rid="pcbi-1003439-g005">Figure 5A</xref>). However, the generator potential is not equivalent to the voltage signals produced by the graded potential model, which lacks voltage-gated Na<sup>+</sup> channels. We constructed an approximation of the generator potential, the pseudo-generator potential, by removing the action potentials from spike trains and replacing them with a 6 ms linear interpolation of the membrane potential, corresponding to the maximum action potential width (<xref ref-type="fig" rid="pcbi-1003439-g005">Figure 5A</xref>). The pseudo-generator potential probability density function is distorted in comparison to the graded potential being narrower with a more pronounced peak because voltage excursions beyond threshold are truncated, the action potential being replaced with an interpolated response (<xref ref-type="fig" rid="pcbi-1003439-g005">Figure 5A,B</xref>). For a particular stimulus the information rate of the pseudo-generator potential was intermediate between that of the spike trains and that of the graded potential model (<xref ref-type="fig" rid="pcbi-1003439-g005">Figure 5C</xref>). The information rates of the pseudo-generator potential were highest (1094 bits/s) with low mean, high standard deviation stimuli, 860 bits/s (366%) higher than that of the corresponding spike trains but 1146 bits/s (51%) lower than that of the corresponding graded potential (<xref ref-type="fig" rid="pcbi-1003439-g005">Figure 5C</xref>). The information rates of the pseudo-generator potential were lowest (188 bits/s) with low mean, low standard deviation stimuli. This lowest value was 158 bits/s (531%) higher than that of the corresponding spike trains, but 352 bits/s (65%) lower than that of the corresponding graded potential (<xref ref-type="fig" rid="pcbi-1003439-g005">Figure 5C</xref>).</p>
<fig id="pcbi-1003439-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g005</object-id><label>Figure 5</label><caption>
<title>The information encoded in the pseudo-generator potentials of the spiking neuron model.</title>
<p>A. Action potentials (top black trace) evoked by white noise current stimuli (bottom red trace). Upper grey trace: The same voltage response with the action potentials removed and replaced with a linear interpolation of the voltage. This is the pseudo-generator potential, which is an approximation of the generator potential. Lower blue trace: A voltage response of the graded neuron model to the current stimulus shown in the bottom trace. B. The PDF of the pseudo-generator voltage response. (Inset) A QQ plot showing departures from a Gaussian distribution (dotted red-line) for the time-series shown in A (upper grey trace). C. Information rates (bits s<sup>−1</sup>) of pseudo-generator potentials evoked by white noise current stimuli with different means and standard deviations. The stimuli are identical to those in <xref ref-type="fig" rid="pcbi-1003439-g002">Figures 2</xref> and <xref ref-type="fig" rid="pcbi-1003439-g003">3</xref>.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g005" position="float" xlink:type="simple"/></fig>
<p>What reduces the information rate of the pseudo-generator potential relative to the graded potential? We identify three processes: the duration of the action potential and associated refractory period, and two effects caused by the presence of voltage-gated Na<sup>+</sup> channels, noise and non-linearity. We will assess each of these processes, in turn.</p>
</sec><sec id="s2c">
<title>Information loss during the action potential</title>
<p>The action potential and accompanying refractory period creates a ‘footprint’ on the generator potential during which information is lost (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6A</xref>). To assess the impact of this ‘footprint’ on the information rate, we stimulated the graded model with a white noise stimulus (<xref ref-type="fig" rid="pcbi-1003439-g001">Figure 1A,B</xref>) to generate a set of graded responses from which we could estimate the signal, noise and information rate. These graded responses produced a high information rate (1427 bits/s). We then inserted 6 ms long sections of linear interpolation spaced at least 10 ms apart into the individual graded responses to mimic action potential footprints (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6B</xref>). We added between 10 and 80 linear interpolations per second into each response to represent the spike footprints at different firing rates and re-calculated the Shannon information rate (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6B</xref>) <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref>. Interpolations were added at exactly the same positions in all responses, termed <italic>deterministic</italic> interpolation (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6B</xref>), to represent the footprints of noise-free spikes and give an upper bound on signal entropy. The placement of the interpolations was then jittered by up to 4 ms (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6B</xref>), termed <italic>jittered</italic> interpolation, to represent reliable spike trains with low noise entropy. Finally, interpolations were placed randomly in each response (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6B</xref>), termed <italic>random</italic> interpolation, to resemble unreliable spike trains with high noise entropy.</p>
<fig id="pcbi-1003439-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g006</object-id><label>Figure 6</label><caption>
<title>The action potential ‘footprint’ reduces the information encoded in a graded voltage response.</title>
<p>A. White noise current (blue) elicits a train of action potentials in the spiking neuron model (black). The same voltage response with the action potentials removed and replaced with a linear interpolation of the voltage (red). B. Sections of the graded voltage response were replaced with a linear interpolation to mimic the ‘footprint’ each action potentials creates when any information contained in the graded response is obscured. The graded responses are shown in black and the interpolated sections in red. The 3 replacement regimes deterministic (upper), jittered (middle) and random (lower) mimicked spiking statistics with different current stimuli (see main text for details). C. The random insertion of 6 ms sections of linear interpolation into graded voltage responses reduces the Shannon information rate. The drop in information rate is greater with more interpolations. Insertion of interpolations in the same (deterministic) or nearly the same (jittered) positions does not affect the Shannon information rate. D. The random insertion of 6 ms sections of linear interpolation into graded voltage responses reduces the coherence-based information rate. The drop in information rate is greater with more interpolations. The insertion of interpolations in the same (deterministic) or nearly the same (jittered) positions have the same effect upon the coherence-based information rate as the random insertion. Insertion of interpolations into the same positions within the stimulus as well as the response reduces the effect upon the coherence-based information rate.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g006" position="float" xlink:type="simple"/></fig>
<p>The Shannon information rate <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref> was unaffected by the <italic>deterministic</italic> or <italic>jittered</italic> interpolation, irrespective of the number of interpolations inserted (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6C</xref>) because it depends only upon the signal-to-noise ratio (SNR) and the response bandwidth <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref>. Thus, inserting increasing numbers of interpolations, even when jittered, does not affect the Shannon information rate because these interpolations are inserted in identical (<italic>deterministic</italic>) or similar (<italic>jittered</italic>) positions, leaving the regions between the interpolations unaffected. Conversely, increasing the number of <italic>random</italic> interpolations reduced the Shannon information rate from 1427 to 485 bits/s (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6C</xref>) because these interpolations add noise to the responses, thereby reducing the SNR.</p>
<p>In addition to the Shannon information rate <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref>, we calculated coherence-based information rates to determine the effect of the footprint on information loss from the stimulus (see <xref ref-type="sec" rid="s4">Methods</xref>). The coherence-based estimate of the information rate is a measure of linear dependence between the stimulus and the response, and describes different forms of signal corruption including non-linear distortion <xref ref-type="bibr" rid="pcbi.1003439-Bendat1">[29]</xref>. The coherence-based information rate decreased as the number of interpolations inserted increased for all three types of interpolation, <italic>deterministic</italic>, <italic>jittered</italic> and <italic>random</italic> (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6D</xref>). The coherence-based information rate dropped from 1148 bits/s with no interpolations to 346 bits/s with 80 interpolations.</p>
<p>Although we inserted linear interpolations into the voltage responses, there is still a fluctuation at the corresponding position in the current stimulus. The mismatch between the interpolations and the stimulus may reduce the coherence-based information rate by inflating the non-linearity. To determine whether this is the case, we added linear interpolations at exactly the same positions to both the stimulus and the response, and recalculated the coherence-based information rate (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6D</xref>). This difference between the coherence-based information rates calculated with or without interpolations added to the stimulus as well as the response is the information lost due to the action potential footprint. For the same number of interpolations, all three types of interpolation, <italic>deterministic</italic>, <italic>jittered</italic> and <italic>random</italic>, had higher information rates (between 177 and 516 bits/s) with interpolations added to the stimulus than without (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6D</xref>). These coherence-based information rates were dependent upon the number of interpolations inserted. For example, inserting 10 interpolations reduced the information rate from 1148 bits/s to 1090 bits/s but inserting 80 interpolations reduced the information rate to 860 bits/s. Thus, the coherence-based method demonstrates that the action potential footprint blanks out information about the stimulus. This loss of information increases with spike rate from 5.3% at 10 Hz to 33.5% at 80 Hz.</p>
</sec><sec id="s2d">
<title>Sub-threshold noise</title>
<p>Channel noise affects sub-threshold potentials as well as spike timing and reliability <xref ref-type="bibr" rid="pcbi.1003439-Steinmetz1">[30]</xref>. We measured the standard deviation of the voltage noise at sub-threshold membrane potentials for the spiking neuron model, the deterministic Na<sup>+</sup>/stochastic K<sup>+</sup> channel model, the stochastic Na<sup>+</sup>/deterministic K<sup>+</sup> channel model and the graded neuron model (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7A</xref>). In the absence of an input stimulus, the voltage noise was generated entirely by the spontaneous opening and closing of the voltage-gated ion channels. The noise standard deviation of all the models was highest at the most depolarised potentials and dropped as the membrane potential was hyperpolarised towards the reversal potential of the K<sup>+</sup> ions (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7A</xref>). Between −74 to −70 mV the voltage noise standard deviation was highest for the spiking neuron model and lowest for the stochastic Na<sup>+</sup>/deterministic K<sup>+</sup> channel model.</p>
<fig id="pcbi-1003439-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g007</object-id><label>Figure 7</label><caption>
<title>The effects of channel noise upon sub-threshold and graded voltage signals.</title>
<p>A. The standard deviation of the voltage of the spiking neuron model (stochastic voltage-gated Na<sup>+</sup> and K<sup>+</sup> channels), a modified model with stochastic voltage-gated Na<sup>+</sup> and deterministic voltage-gated K<sup>+</sup> channels, a modified model with deterministic voltage-gated Na<sup>+</sup> and stochastic voltage-gated K<sup>+</sup> channels, and the graded neuron model (stochastic voltage-gated K<sup>+</sup> channels) over a 16 mV range of holding potentials. B. Shannon information rates of all four models shown in A evoked by low mean, high standard deviation current stimuli at sub-threshold holding potentials. C. Coherence-based information rates of all four models shown in A evoked by low mean, high standard deviation current stimuli at sub-threshold holding potentials. D. Normalized mean square error (nRMSE) information rates of all four models shown in A evoked by low mean, high standard deviation current stimuli at sub-threshold holding potentials.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g007" position="float" xlink:type="simple"/></fig>
<p>The voltage noise of the deterministic Na<sup>+</sup>/stochastic K<sup>+</sup> was close to that of the spiking neuron model (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7A</xref>). However, near the K<sup>+</sup> reversal potential of −77 mV the voltage noise of all three models containing stochastic K<sup>+</sup> channels dropped as the driving force on K<sup>+</sup> ions approached zero. The drop was less pronounced in the spiking neuron model because stochastic Na<sup>+</sup> channels continued to produce noise. Below the K<sup>+</sup> reversal potential, the voltage noise of all three models containing stochastic K<sup>+</sup> channels increased (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7A</xref>), with the driving force on K<sup>+</sup> ions.</p>
<p>The voltage noise of the deterministic K<sup>+</sup> channel model dropped as the membrane potential was hyperpolarised, even below K<sup>+</sup> reversal potential, because the probability of spontaneous Na<sup>+</sup> channel opening, the only source of channel noise, drops at hyperpolarised potentials. Indeed, the deterministic K<sup>+</sup> channel model had the lowest voltage noise at holding potentials more depolarised than ∼−74 mV and more hyperpolarised than ∼−80 mV (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7A</xref>). Thus, although the noise generated by the spontaneous opening of both Na<sup>+</sup> and K<sup>+</sup> channels contributes to the voltage noise of the spiking neuron model, the K<sup>+</sup> channel noise apparently makes the greater contribution at potentials between −74 to −70 mV. Note that the voltage noise standard deviation with both channel types together is less than the sum of the standard deviations of the individual channel types because their variances add.</p>
<p>We assessed the impact of the sub-threshold voltage noise on the Shannon information rate by stimulating each model with a white noise current with a zero mean and low standard deviation (μ = 0, σ = 1, τ<sub>c</sub> = 3.3 ms). An additional tonic current was injected and adjusted to hold the mean membrane potential at either −77 or −70 mV. This tonic current prevented the models containing voltage-gated Na<sup>+</sup> channels from reaching threshold, permitting a direct comparison of the effects of stochastic and deterministic channel combinations upon sub-threshold information coding.</p>
<p>We calculated the Shannon information rate <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref> of each model at the two mean potentials, −77 and −70 mV (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7B</xref>). The highest information rates of all the models occurred at the more hyperpolarised potential because the voltage noise was lower. Due to a distinct drop in voltage noise near the K<sup>+</sup> reversal potential, the deterministic Na<sup>+</sup>/stochastic K<sup>+</sup> channel model and the graded neuron model, attain the highest information rates of 3123 bits/s at −77 mV. These information rates were ∼30% greater than those of the sub-threshold spiking neuron model and the stochastic Na<sup>+</sup>/deterministic K<sup>+</sup> channel model, which are lower because of voltage-gated Na<sup>+</sup> channel noise. At −70 mV the increased voltage noise in all the models reduces their information rates (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7B</xref>). The information rate of the sub-threshold spiking neuron model dropped 86% to 321 bits/s. The sub-threshold information rates of both models with stochastic K<sup>+</sup> channels dropped 63% to 1142–1168 bits/s, whilst the stochastic Na<sup>+</sup>/deterministic K<sup>+</sup> channel model has the lowest voltage noise and, consequently, the highest sub-threshold information rate of 1288 bits/s. The drop in the information rates of all the models at the more depolarised holding potential shows the substantial effect of channel noise upon the sub-threshold and graded potentials. The combination of both stochastic Na<sup>+</sup> and stochastic K<sup>+</sup> ion channels in the spiking neuron model reduce the information content of the sub-threshold potential relative to the graded neuron model by 24% at −77 mV to 73% at −70 mV.</p>
</sec><sec id="s2e">
<title>Sub-threshold non-linearity</title>
<p>Voltage-gated ion channels introduce non-linearities <xref ref-type="bibr" rid="pcbi.1003439-Curti1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Desmaisons1">[32]</xref> that could reduce the information content of the generator potential by distorting the voltage signal. We assessed the sub-threshold effect of non-linearity on each of the models, at −77 mV and −70 mV, using the coherence-based information rates we previously calculated to assess the impact of the action potential footprint (<xref ref-type="fig" rid="pcbi-1003439-g006">Figure 6D</xref>). Higher coherence-based information rates indicate better reconstruction of the original stimulus, based solely on linear decoding principles <xref ref-type="bibr" rid="pcbi.1003439-Bendat1">[29]</xref>. In the spiking neuron model the coherence-based information rates dropped by more than 63% as the holding potential becomes more depolarised i.e., from 1027 bits/s at −77 mV to 382 bits/s at −70 mV (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7C</xref>). This fall indicates a decline in the quality of linear reconstruction. By comparison, the stochastic Na<sup>+</sup>/deterministic K<sup>+</sup> model was the least affected by depolarisation, the coherence-based information rates dropping by just 1.5%. For the model with deterministic Na<sup>+</sup>/stochastic K<sup>+</sup> and the model with only stochastic K<sup>+</sup> channels, the coherence-based information rates drop ∼4.2–4.8% at the more depolarised potential (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7C</xref>). Increasing the holding potential to −68 mV causes all three models containing voltage-gated Na<sup>+</sup> channels to produce spikes, making them increasingly non-linear (data not shown).</p>
<p>In addition to coherence-based information rates, we used the normalised root mean squared error (nRMSE) between the original stimulus and the reconstructed stimulus to assess the effect of non-linearity. An nRMSE value that tends towards zero represents perfect reconstruction <xref ref-type="bibr" rid="pcbi.1003439-Bendat1">[29]</xref>. The nRMSE increased as the membrane potential increased indicating a drop in the quality of reconstruction (<xref ref-type="fig" rid="pcbi-1003439-g007">Figure 7D</xref>); the increase in nRMSE was largest for the sub-threshold spiking model (67%) but the nRMSE of the three other models also increased by 8–13%. This decline in reconstruction quality is due to an increase in the open channel probability with depolarization. For the models containing voltage-gated Na<sup>+</sup> channels, the voltage threshold for eliciting an action potential is close to −68 mV. At −70 mV the increase in the numbers of open voltage-gated Na<sup>+</sup> channels increases positive-feedback and, consequently, the magnitude of the non-linearity. A fluctuating input stimulus superimposed upon the holding current also reduces the distance from the voltage threshold, though the effect of this on reconstruction will depend on the magnitude and polarity of the fluctuations.</p>
</sec><sec id="s2f">
<title>Linear decoding accuracy in the suprathreshold regime</title>
<p>Using linear systems analysis (see <xref ref-type="sec" rid="s4">Methods</xref>), we assessed how much of the input (current) can be predicted from the response (voltage) by reconstructing the input stimulus current. We find that when the graded voltage response was used for the reconstruction based on linear decoding the predicted input stimuli were most coherent, with the lowest nRMSE (<xref ref-type="supplementary-material" rid="pcbi.1003439.s003">Figure S3C</xref>,D) and the highest coherence-based information rates (<xref ref-type="supplementary-material" rid="pcbi.1003439.s003">Figure S3C</xref>,E). The reconstruction accuracy (nRMSE and coherence based information) of the pseudo-generator potentials was lower than that of the graded potentials (<xref ref-type="supplementary-material" rid="pcbi.1003439.s003">Figure S3B</xref>,D,E). The highest nRMSE and, consequently, the lowest coherence-based information rate was obtained from reconstructions based on action potentials (<xref ref-type="supplementary-material" rid="pcbi.1003439.s003">Figure S3A</xref>,D,E), although these were only marginally worse than reconstructions based on pseudo-generator potentials (<xref ref-type="supplementary-material" rid="pcbi.1003439.s003">Figure S3</xref>). Thus, voltage-gated Na<sup>+</sup> channels distort both the subthreshold (pseudo-generator) and suprathreshold responses so that the incoming stimulus current cannot be accurately reconstructed using just a linear decoder.</p>
</sec><sec id="s2g">
<title>Extrinsic noise</title>
<p>Neuronal information rates are constrained by extrinsic noise in the input stimuli, as well as by intrinsic noise generated by ion channels <xref ref-type="bibr" rid="pcbi.1003439-Dodge1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Lillywhite1">[34]</xref>. To investigate this constraint, we added broadband Gaussian noise to the white noise input stimulus. This enabled us to quantify and compare the effect of extrinsic noise upon the information rates of the spiking model, the pseudo-generator potentials from the spiking model and the graded model. In our simulations, although the presence of the extrinsic noise source facilitates a marginal increase in precision of the APs for inputs with low standard deviations, it does not alter the variability of the APs, consequently noise-aided enhancement of mutual information is absent (<italic>cf.</italic> McDonnell et al. <xref ref-type="bibr" rid="pcbi.1003439-McDonnell1">[35]</xref>).</p>
<p>The amount of extrinsic noise was altered to produce an input stimulus with either a low or a high SNR input stimulus (<xref ref-type="disp-formula" rid="pcbi.1003439.e012">Equations 2</xref> and <xref ref-type="disp-formula" rid="pcbi.1003439.e013">3</xref>; SNR = 2 or 20). The SNR is defined as the ratio of the signal power to the noise power. In our simulations, we decreased the SNR by increasing the noise power (see <xref ref-type="sec" rid="s4">Methods</xref>; <xref ref-type="disp-formula" rid="pcbi.1003439.e013">Equation 3</xref>). For the spiking model, increasing the input noise produces a relatively small increase in total entropy (∼5%, SNR = 2; ∼2%, SNR = 20) (<xref ref-type="supplementary-material" rid="pcbi.1003439.s004">Figure S4A</xref>) but a relatively large increase in noise entropy (∼180%, SNR = 2; ∼50%, SNR = 20) (<xref ref-type="supplementary-material" rid="pcbi.1003439.s004">Figure S4B</xref>), and this produces a significant drop in the mutual information (∼40%, SNR = 2; ∼10%, SNR = 20) (<xref ref-type="supplementary-material" rid="pcbi.1003439.s004">Figure S4C</xref>,S5A).</p>
<p>The information rates of the pseudo-generator potentials also decrease with increased extrinsic noise (<xref ref-type="supplementary-material" rid="pcbi.1003439.s005">Figure S5B</xref>). The loss in relation to the noise-less stimulus is greater in the pseudo-generator potentials (∼69%, SNR = 2; ∼29%, SNR = 20) with higher standard deviation input signals. A 10-fold increase in the input SNR caused a 133% increase in information rate, from 335 bits/sec (SNR = 2) to 780 bits/sec (SNR = 20), compared to 1094 bit/sec in the absence of extrinsic noise. Likewise, the information rates of the graded model were reduced by up to 73% for low SNR input signals (SNR = 2) and by up to 36% for high SNR input signals (SNR = 20) (<xref ref-type="supplementary-material" rid="pcbi.1003439.s004">Figure S4C</xref>), the higher quality input signal (SNR = 20) causing the information rate to increase from 595 to 1422 bits/sec. Thus, the information rates of the spiking model were the least affected by the extrinsic noise whilst those of the graded model were the most affected (<xref ref-type="supplementary-material" rid="pcbi.1003439.s005">Figure S5A</xref>–C).</p>
</sec><sec id="s2h">
<title>Energy consumption</title>
<p>The energy consumption of each model was determined from the K<sup>+</sup> ion fluxes across the membrane needed to generate the voltage signals, as the number of ATP molecules hydrolyzed by the Na<sup>+</sup>/K<sup>+</sup> pump <xref ref-type="bibr" rid="pcbi.1003439-Attwell1">[12]</xref>. This pump maintains the ionic concentration gradients that generate electrical responses and operates stoichiometrically, pumping back 2 K<sup>+</sup> ions for every ATP molecule that it consumes <xref ref-type="bibr" rid="pcbi.1003439-Skou1">[36]</xref>. The energy consumption of the spiking neuron model is strongly correlated with its firing rate (<xref ref-type="fig" rid="pcbi-1003439-g008">Figure 8A</xref>) because the energy consumption of an action potential is high compared to the consumption between action potentials. Higher standard deviation stimuli evoke larger membrane potential fluctuations, eliciting more action potentials and, therefore, consuming more energy. Consequently, the high mean, high standard deviation stimuli that evoked the highest firing rates also incurred the highest energy consumption, 3.9*10<sup>8</sup> ATP molecules/s (<xref ref-type="fig" rid="pcbi-1003439-g008">Figure 8A</xref>). Low mean stimuli with high standard deviations consume 3.1 times more energy than stimuli with low standard deviations but for high mean stimuli it is just 1.4 times more (<xref ref-type="fig" rid="pcbi-1003439-g008">Figure 8A</xref>). This is because the standard deviation of signal fluctuations has less of an effect upon the average firing rate with high mean input stimuli.</p>
<fig id="pcbi-1003439-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g008</object-id><label>Figure 8</label><caption>
<title>The energy consumption of spike trains, pseudo-generator potentials and graded potentials.</title>
<p>A. Energy consumption (ATP molecules s<sup>−1</sup>) of the spiking neuron model, B. the pseudo-generator potentials, and C. the graded potential model evoked by white noise current stimuli with different means and standard deviations.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g008" position="float" xlink:type="simple"/></fig>
<p>Pseudo-generator membrane potentials consume less energy than the spiking neuron model. Indeed the maximum energy consumption of the pseudo-generator potentials is 6.4*10<sup>7</sup> ATP molecules/s, almost an order of magnitude less than the spiking neuron model (<xref ref-type="fig" rid="pcbi-1003439-g008">Figure 8B</xref>). Like the spiking model, when the pseudo-generator potential model is driven with a high mean stimulus, increasing the stimulus standard deviation increases energy consumption. But, unlike the spiking model, when the stimulus mean is low, increasing its standard deviation reduces energy consumption. Low mean, high standard deviation stimuli consume less energy because they hyperpolarise the membrane potential by 10 mV or more below the resting potential, and this reduces the number of open K<sup>+</sup> channels (<xref ref-type="supplementary-material" rid="pcbi.1003439.s006">Figure S6A</xref>,B). Conversely, with high mean stimuli the maximum peak-to-peak voltage of the compartment is approximately the same, irrespective of the standard deviation (<xref ref-type="supplementary-material" rid="pcbi.1003439.s006">Figure S6A</xref>,B). The greater energy consumption of the high standard deviation is due to the 1.6-fold greater numbers of open K<sup>+</sup> channels, which cause a doubling of the mean K<sup>+</sup> current at equivalent membrane potentials, thereby inflating the energy consumption.</p>
<p>The energy consumption of the graded model showed the same trends as the pseudo-generator potentials (<xref ref-type="fig" rid="pcbi-1003439-g008">Figure 8C</xref>). Again, less energy is consumed in response to low mean high standard deviation stimuli than to low standard deviation stimuli, due to an 85% decrease in the number of open K<sup>+</sup> channels (<xref ref-type="supplementary-material" rid="pcbi.1003439.s007">Figure S7A</xref>,B). In contrast, at high means, high standard deviation stimuli consumed 64% more energy than low standard deviation stimuli (<xref ref-type="fig" rid="pcbi-1003439-g008">Figure 8C</xref>) because high input standard deviations open greater numbers of K<sup>+</sup> channels (<xref ref-type="supplementary-material" rid="pcbi.1003439.s007">Figure S7A</xref>,B).</p>
</sec><sec id="s2i">
<title>Energy efficiency</title>
<p>We calculated the energy efficiency of information coding by dividing the information rates of the spiking neuron model, the pseudo-generator potentials and the graded neuron model by their corresponding energy consumptions. The energy efficiency of the spiking neuron model was highest (8.4*10<sup>−7</sup> bits/ATP molecule) for low mean, high standard deviation stimuli and lowest (3.8*10<sup>−8</sup> bits/ATP molecule) for high mean, low standard deviation stimuli (<xref ref-type="fig" rid="pcbi-1003439-g009">Figure 9A</xref>). This 22-fold difference in energy efficiency was accompanied by a 23-fold difference in information rate. Thus the coding of low mean, high standard deviation stimuli was most efficient because these stimuli generated the highest information rates with firing rates, and therefore energy costs, similar to high mean, low standard deviation stimuli (<xref ref-type="fig" rid="pcbi-1003439-g009">Figure 9A</xref>). In other words, energy efficiency rises with information per spike.</p>
<fig id="pcbi-1003439-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003439.g009</object-id><label>Figure 9</label><caption>
<title>The energy efficiency of information encoding in spike trains, pseudo-generator potentials and graded potentials.</title>
<p>A. Energy efficiency of information processing (bits ATP molecule<sup>−1</sup>) with (thick lines; SNR = 2) and without (thin lines) extrinsic noise in the spiking neuron model and the model containing the pseudo-generator potentials, and B. the graded potential model evoked by white noise current stimuli with different means and standard deviations.</p>
</caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003439.g009" position="float" xlink:type="simple"/></fig>
<p>Indeed, in all models, spiking, pseudo-generator potential, and graded, increasing input stimulus mean reduced energy efficiency because it increased the mean level of response without introducing more information (<xref ref-type="fig" rid="pcbi-1003439-g009">Figure 9A,B</xref>). As expected, the energy efficiency of all three models improved when the information rate increased in response to an increase in stimulus standard deviation at a given stimulus mean (<xref ref-type="fig" rid="pcbi-1003439-g009">Figure 9A,B</xref>). For example at low means, the spiking model's information rate increased by 689% with a concomitant increase in efficiency of 151%. For the pseudo-generator potentials information increased by 482%, and efficiency increased by 889% and in the graded neuron efficiency increased by 363% and information increased by 315%.</p>
<p>Both pseudo-generator (8.0*10<sup>−5</sup> bits/ATP) and graded potential (1.3*10<sup>−4</sup> bits/ATP) models were 95–156 times as energy efficient as the spiking model (8.4*10<sup>−7</sup> bits/ATP), when all models were compared with low mean, high standard deviation inputs. At higher information rates the energy efficiency of both the pseudo-generator and graded potentials improved substantially (<xref ref-type="fig" rid="pcbi-1003439-g009">Figure 9B</xref>). However, the graded potentials achieved higher information rates than the pseudo-generator potentials and in this regime they were as much as 1.6 times more energy efficient at 1.3*10<sup>−4</sup> bits/ATP molecule.</p>
<p>The addition of extrinsic noise did not affect this general pattern of relationships between input stimuli, information rate and energy efficiency in the three models. However, by reducing the information rates of all three models the extrinsic noise reduced the energy efficiency for any given input stimulus (<xref ref-type="fig" rid="pcbi-1003439-g009">Figure 9A,B</xref>). For example, adding noise to the inputs reduced the efficiencies of the pseudo-generator potentials by 71% for a low quality input (SNR = 2) and by 26% for a high quality input (SNR = 20). Similarly, the efficiency of the graded potential model dropped by 74% at low SNR and by 36% for high input SNR. Given that extrinsic noise only marginally altered the energy consumption, it decreases efficiency by decreasing the amount of information that can be coded.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<p>Analogue voltage signals in non-spiking neurons and generator potentials in spiking neurons typically have higher information rates than spike trains <xref ref-type="bibr" rid="pcbi.1003439-DiCaprio1">[5]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-Theunissen1">[9]</xref>. This information loss is a consequence of a change in coding strategy; non-spiking neurons and generator potentials encode information as a continuous analogue voltage signal whereas spiking neurons use discrete pulses of finite precision and width, limiting the number of states that can be coded within a given time period. However, there are also biophysical causes of this information loss, and these were the focus of our study. Spiking neurons can be lossless encoders of band-limited inputs if their spike rates exceed the Nyquist limit <xref ref-type="bibr" rid="pcbi.1003439-Lazar1">[37]</xref>, both at the level of a single neuron or across a population of neurons <xref ref-type="bibr" rid="pcbi.1003439-Lazar2">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Lazar3">[39]</xref>. But below this limit information loss occurs and is affected by the factors we have examined.</p>
<p>Our simulations show that voltage-gated Na<sup>+</sup> channels, which are necessary for action potential generation, are the primary biophysical cause of information loss in sub-threshold potentials because they increase intrinsic noise and introduce non-linearities. Indeed, this information loss in sub-threshold potentials is greater than the information loss in spike generation attributable to voltage-gated Na<sup>+</sup> channels. Further information loss in the sub-threshold potential occurs because each action potential obscures the generator potential, reducing its information content. This suggests that the biophysical factors we identify have their major impact upon sub-threshold information processing. Comparing the energy efficiencies of our models, spike trains consume an order of magnitude more energy than graded or pseudo-generator potentials for a given stimulus. This result emphasizes the two-fold penalty of action potentials on coding efficiency; lower information rates and higher energy costs. Graded and generator potentials consume similar amounts of energy, the primary determinant of which is the input mean, but due to their lower information rates generator potentials are less energy efficient than graded potentials.</p>
<p>Our models contained voltage-gated ion channels with the same biophysical properties as those found in the squid giant axon because well-established kinetic models exist for them <xref ref-type="bibr" rid="pcbi.1003439-Hodgkin1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Skaugen1">[41]</xref>. Different channel kinetics will alter channel noise <xref ref-type="bibr" rid="pcbi.1003439-White2">[42]</xref>, affect the shape of the action potential <xref ref-type="bibr" rid="pcbi.1003439-Sengupta1">[11]</xref> and alter the information rates of a spiking model <xref ref-type="bibr" rid="pcbi.1003439-Sengupta2">[43]</xref>. However the main effects of channel noise in our models are on the graded and generator potentials. Previous modeling studies have used squid voltage-gated Na<sup>+</sup> channels to show that they increase sub-threshold noise <xref ref-type="bibr" rid="pcbi.1003439-Steinmetz1">[30]</xref>, but did not quantify their effect on sub-threshold information rates. We find that the noise from voltage-gated Na<sup>+</sup> channels and voltage-gated K<sup>+</sup> channel noise substantially decreases the information rate of the generator potential. This finding suggests that the high densities of voltage-gated Na<sup>+</sup> channels at the spike initiation zone <xref ref-type="bibr" rid="pcbi.1003439-Kole1">[44]</xref>, as well as voltage-gated Na<sup>+</sup> channels and Ca<sup>2+</sup> channels in dendrites and dendritic spines <xref ref-type="bibr" rid="pcbi.1003439-Stuart1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Laurent1">[46]</xref> could also reduce the information rate of sub-threshold signals, and this could have a deleterious effect on information processing.</p>
<p>Our models suggest that action potential duration (including the absolute refractory period) is an important source of information loss, imposing a lower limit on the interspike interval and preventing the spike initiation zone from integrating new information for a brief period. <italic>In vivo</italic> many neurons have considerably higher spike rates than our models, which had moderate spike rates below approximately 90 Hz. At these high spike rates, substantial portions of the information would be lost from the generator potential, promoting narrower action potentials and sparse codes that require relatively few action potentials <xref ref-type="bibr" rid="pcbi.1003439-Olshausen1">[47]</xref>. However, many neurons use signals that are considerably longer than typical action potentials such as bursts and plateau potentials <xref ref-type="bibr" rid="pcbi.1003439-Izhikevich1">[48]</xref> that obscure far more of the generator potential and incur a greater information loss. This emphasizes the importance of these long-duration signals as indicators of high salience signals.</p>
<p>The non-linearity of all the models incorporating voltage-gated Na<sup>+</sup> channels increases with the sub-threshold depolarization because the positive feedback generated by the Na<sup>+</sup> channels increases as the threshold approaches. Thus, at sub-threshold levels the Na<sup>+</sup> channels distort the voltage waveform. This distortion could reduce the information content of the sub-threshold potentials, though this depends upon whether the transformation of any synaptic metric (current, conductance, etc.) into the voltage waveform is linear in the sub-threshold regime. Linear as well as non-linear mapping may occur between the synaptic input and the resultant voltage waveform <xref ref-type="bibr" rid="pcbi.1003439-AguerayArcas1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Tishby1">[49]</xref>. Voltage-gated Na<sup>+</sup> channels may constitute one such non-linearity, distorting the synaptic input <xref ref-type="bibr" rid="pcbi.1003439-Koch2">[50]</xref>. In such cases, although a linear decoder cannot fully represent and recover the input information, a decoder relying on higher order features of the membrane potential may prevent any information loss (also see <xref ref-type="bibr" rid="pcbi.1003439-Lazar3">[39]</xref>).</p>
<p>Our use of current rather than conductance as the input stimulus ignores the energy cost associated with conductance inputs, which will reduce the energy efficiency of information coding of all the models. Conductance inputs close to the spike initiation zone will also alter the membrane time constant and affect action potential initiation <xref ref-type="bibr" rid="pcbi.1003439-Williams1">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Larkum1">[52]</xref>. Consequently, conductance inputs will affect the bandwidth and temporal precision of all the models and the maximum spike rate of the spiking neuron model <xref ref-type="bibr" rid="pcbi.1003439-Sengupta3">[53]</xref>. The synaptic channels needed to implement the conductance changes will also contribute noise to the models <xref ref-type="bibr" rid="pcbi.1003439-Destexhe1">[54]</xref>, reducing their information rates. By incorporating extrinsic noise, however, we have shown that the relationships we have found will remain qualitatively similar.</p>
<p>The squid giant axon action potentials that we modeled consume substantially more energy than other vertebrate and invertebrate action potentials <xref ref-type="bibr" rid="pcbi.1003439-Sengupta1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Alle1">[14]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-Hasenstaub1">[16]</xref>, inflating the energy consumption of the spiking neuron model and reducing its efficiency. Nevertheless, the efficiency drop that occurs when generator potentials are converted to action potentials is substantial and will remain, albeit with a smaller difference. The topological class of model (e.g. Type I or Type II) may also influence energy consumption through the dynamics and time course of the ionic and synaptic currents determining the threshold manifold <xref ref-type="bibr" rid="pcbi.1003439-Stemmler1">[55]</xref>. Indeed, minimizing metabolic consumption in single compartment models <xref ref-type="bibr" rid="pcbi.1003439-Stemmler1">[55]</xref> leads to the leak and the inward currents competing with each other even before reaching the spiking threshold, via a Hopf bifurcation (Type II). This causes an increase in energy consumption forcing the optimal action potentials to steer away from such bifurcations; gradient descent on metabolic consumption leads to saddle-node bifurcations as in Type I cortical neurons (unpublished observation – BS, personal communication – Martin Stemmler, <xref ref-type="bibr" rid="pcbi.1003439-Stemmler1">[55]</xref>). The energy consumption of the graded potential neurons will also be affected by changes in the biophysical properties of voltage-gated ion channels, though this is unlikely to substantially affect the relationship between the input stimuli and the energy consumption.</p>
<p>Our models systematically explored combinations of the mean and standard deviation of a Gaussian input. Those spike trains with the lowest information rates and bits per spike were evoked by low standard deviation stimuli, whereas high standard deviation stimuli evoked consistently higher information rates for a given mean stimulus. Consequently, across all our models there was no systematic relationship between the mean spike rate and the information rate, total entropy, noise entropy or coding efficiency (bits per spike). Indeed, the highest and lowest information rates and coding efficiencies were found at similar spike rates. However, these findings are specific to the type of stimuli we used, a randomly varying input signal superimposed on an offset. It is more usual to find that the information rate increases with spike rate whilst the coding efficiency declines because the entropy per spike falls <xref ref-type="bibr" rid="pcbi.1003439-Rieke1">[56]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Koch3">[57]</xref>. Non-Gaussian naturalistic stimuli vary more widely than do Gaussians. These larger excursions make the voltage response more nonlinear and engage adaptation mechanisms that, if they affect the signal and noise differently, can change the information rates of both graded potentials and the spike trains they generate <xref ref-type="bibr" rid="pcbi.1003439-Niven3">[58]</xref>. Although there are methods that could allow us to compare the coding and metabolic efficiency of analogue and spiking responses to natural stimuli <xref ref-type="bibr" rid="pcbi.1003439-French1">[6]</xref>, each modality has its own statistics. Even within a modality different classes of neuron have distinctive firing patterns because they select different components of the input (e.g. retinal ganglion cells <xref ref-type="bibr" rid="pcbi.1003439-Koch3">[57]</xref>). Faced with many particular cases, we chose to start with a general stimulus that identifies factors, such as input signal to noise, that are widely applicable.</p>
<p>As a case in point, in many neurons the mean and standard deviation of the input stimuli and the extrinsic noise are often correlated <xref ref-type="bibr" rid="pcbi.1003439-Singer1">[59]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-Gawne1">[61]</xref>. For example, extrinsic noise in synaptic inputs is often correlated with their number and strength, and hence signal amplitude <xref ref-type="bibr" rid="pcbi.1003439-Shadlen1">[62]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-Bernander1">[64]</xref>. Thus, the stimulus space investigated with our models exposes relationships between energy efficiency and information rate that are broadly applicable to a number of different types of neuron. In particular, our models demonstrate that the energy efficiency of spiking neurons can be improved by reducing the mean input and increasing the standard deviation of the signal. Graded neurons achieve this by using predictive coding to eliminate the mean and amplify the remaining signal to fill their output range <xref ref-type="bibr" rid="pcbi.1003439-Srinivasan1">[65]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Laughlin2">[66]</xref> and these procedures increase both their coding efficiency and their energy efficiency <xref ref-type="bibr" rid="pcbi.1003439-Laughlin1">[3]</xref>. Our findings demonstrate that spiking neurons can do likewise.</p>
<p>Taken together, our analyses show that the biophysical mechanisms involved in action potential generation contribute significantly to the information loss that accompanies the conversion of a graded input to a spike train. Although we cannot directly relate the proportions of information loss to specific mechanisms, it seems likely that the action potential ‘footprint’ and sub-threshold voltage-gated Na<sup>+</sup> channel noise are the major sources of information loss. Viewed as a cost-benefit trade-off, action potentials incur penalties (information loss and energy cost) that are, presumably, balanced against being able to transmit information over considerable distances and preventing noise accumulation during successive processing stages. Reducing the distances over which information is transmitted in the nervous system may favor less conversion of graded signals into spike trains <xref ref-type="bibr" rid="pcbi.1003439-Niven4">[67]</xref>. However, problems associated with accumulating noise during successive processing stages <xref ref-type="bibr" rid="pcbi.1003439-Sarpeshkar1">[4]</xref> may remain severe. Thus, even in some highly miniaturized nervous systems, neurons with action potentials are likely to be necessary <xref ref-type="bibr" rid="pcbi.1003439-Niven4">[67]</xref>.</p>
<p>In conclusion, our modeling of single compartment neurons confirms that a critical step in neural coding, the conversion of an analogue sub-threshold signal to a series of discrete “digital” pulses, is accompanied by substantial information loss. We show that voltage-gated Na<sup>+</sup> channels, critical components for the conversion of analogue to digital, reduce the information in sub-threshold analogue signals substantially, and that this loss is compounded by interference from action potentials. Thus, the first step in a hybrid processing strategy to increase efficiency <xref ref-type="bibr" rid="pcbi.1003439-Sarpeshkar1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Sengupta4">[68]</xref>, the analogue processing of inputs, is compromised by mechanism used for the second step, the conversion of analogue to digital, and this calls for strategic placement of the spike initiation zone <xref ref-type="bibr" rid="pcbi.1003439-Grubb1">[69]</xref>. Some neurons appear to mitigate a small fraction of the loss of information that accompanies the conversion of analogue to digital by transmitting both analogue and digital <xref ref-type="bibr" rid="pcbi.1003439-Marder1">[70]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-Shu1">[72]</xref>. Information may be encoded in the height and width of action potentials <xref ref-type="bibr" rid="pcbi.1003439-Alle2">[71]</xref>–<xref ref-type="bibr" rid="pcbi.1003439-dePolavieja1">[74]</xref> suggesting that spiking neurons may transmit more information than is calculated by treating them as digital pulses. Even in these cases, however, the ‘footprint’ of the action potentials and sub-threshold voltage-gated Na<sup>+</sup> channel noise are still likely to cause substantial information loss.</p>
</sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Single compartment model</title>
<p>We used a single compartment stochastic Hodgkin-Huxley model of the squid giant axon for our simulations <xref ref-type="bibr" rid="pcbi.1003439-Hodgkin1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Skaugen1">[41]</xref>. The model supporting spiking contained two voltage-gated ion channels, transient Na<sup>+</sup> and a delayed rectifier K<sup>+</sup> along with the leak conductance, while the model producing purely graded signals contained delayed rectifier K<sup>+</sup> and leak conductances. The dynamics of the membrane potential is governed by a set of activation and inactivation variables <italic>m</italic>, <italic>h and n</italic> with the current balance equation,<disp-formula id="pcbi.1003439.e001"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e001" xlink:type="simple"/><label>(1)</label></disp-formula><italic>C<sub>m</sub></italic> is the membrane capacitance, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e002" xlink:type="simple"/></inline-formula> are the conductance of the Na<sup>+</sup>, K<sup>+</sup> and leak channels respectively, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e003" xlink:type="simple"/></inline-formula> are the respective reversal potentials, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e004" xlink:type="simple"/></inline-formula> is a time dependent current stimulus and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e005" xlink:type="simple"/></inline-formula> is the input (extrinsic) stimulus noise current. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e006" xlink:type="simple"/></inline-formula> is zero for no input noise simulations. The variables <italic>m</italic>, <italic>h and n</italic> follow first order kinetics of the form <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e007" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e008" xlink:type="simple"/></inline-formula> is the steady-state (in) activation function and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e009" xlink:type="simple"/></inline-formula> is the voltage-dependent time constant. The model was driven using a time dependent current – <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e010" xlink:type="simple"/></inline-formula>, a 300 Hz Gaussian white noise, filtered using a 40<sup>th</sup> order Butterworth filter. The voltage resonant frequency of the squid axon model can vary between 100 Hz at 10°C to 250 Hz at 20°C <xref ref-type="bibr" rid="pcbi.1003439-Guttman1">[75]</xref>. Therefore, we selected the input cut-off frequency at 300 Hz that is slightly more than the output 3 dB cut-off frequency encompassing the frequency response expected out of an underdamped second-order response (see <xref ref-type="fig" rid="pcbi-1003439-g003">Figure 3</xref> in Guttman et al. <xref ref-type="bibr" rid="pcbi.1003439-Guttman1">[75]</xref>). The mean and the standard deviations of the stimulus were varied in the range 1–10 µ<italic>A</italic>/<italic>cm</italic><sup>2</sup>, enabling comparison to earlier work studying channel noise and its effects on information rates <xref ref-type="bibr" rid="pcbi.1003439-Schneidman1">[76]</xref>. The stimulus was presented for 1 second and each set of simulations consisted of 60 such trials. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e011" xlink:type="simple"/></inline-formula> is an unfiltered broad-band Gaussian white noise with,<disp-formula id="pcbi.1003439.e012"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e012" xlink:type="simple"/><label>(2)</label></disp-formula>where noise variance is computed using<disp-formula id="pcbi.1003439.e013"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e013" xlink:type="simple"/><label>(3)</label></disp-formula>Ω denotes the signal-to-noise ratio (SNR).</p>
<p>All Gaussian random numbers were generated using the Marsaglia's Ziggurat algorithm <xref ref-type="bibr" rid="pcbi.1003439-Marsaglia1">[77]</xref>; uniform random numbers were generated using Mersenne Twister algorithm <xref ref-type="bibr" rid="pcbi.1003439-Matsumoto1">[78]</xref>. Deterministic equations were integrated using the Euler-algorithm while stochastic differential equations were integrated using the Euler-Maruyama method, both with a step size of 10 µ<italic>s</italic>. Parameter values are given in <xref ref-type="supplementary-material" rid="pcbi.1003439.s009">Table S1</xref>.</p>
</sec><sec id="s4b">
<title>Gillespie algorithm for simulating channel noise</title>
<p>Our simulations incorporate Na<sup>+</sup> and the K<sup>+</sup> voltage-gated ion channels without cooperativity (<xref ref-type="supplementary-material" rid="pcbi.1003439.s008">Figure S8</xref>) so that the state transition matrix evolves according to a Markov process <xref ref-type="bibr" rid="pcbi.1003439-Chow1">[79]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Sengupta5">[80]</xref>. We track the numbers of channels that were either closed or open <xref ref-type="bibr" rid="pcbi.1003439-Chow1">[79]</xref> using the Gillespie algorithm <xref ref-type="bibr" rid="pcbi.1003439-Gillespie1">[81]</xref>. The Na<sup>+</sup> and the K<sup>+</sup> channels had 13 states with 28 possible transitions among these states −20 transitions for the Na<sup>+</sup> channels and 8 for the K<sup>+</sup> channels. As an example, in time interval <italic>δt</italic>, the probability that the K<sup>+</sup> channel remains in state <italic>k</italic> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e014" xlink:type="simple"/></inline-formula>, where <italic>γ<sub>k</sub></italic> depicts the sum of all transition rates from state <italic>k</italic> to any possible successive state. During the interval <italic>δt</italic> no other ion channel changes its state such that the probability of the ion channels remaining in the same state in the time interval <italic>δt</italic> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e015" xlink:type="simple"/></inline-formula>,<disp-formula id="pcbi.1003439.e016"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e016" xlink:type="simple"/><label>(4)</label></disp-formula><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e017" xlink:type="simple"/></inline-formula> is the number of Na<sup>+</sup> voltage-gated ion channels in state [<italic>i</italic>, <italic>j</italic>], [<italic>n<sub>k</sub></italic>] is the number of K<sup>+</sup> voltage-gated ion channels in state [<italic>k</italic>], <italic>γ<sub>ij</sub></italic> is the total transition rate from state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e018" xlink:type="simple"/></inline-formula> and <italic>γ<sub>k</sub></italic> is the total transition rate from state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e019" xlink:type="simple"/></inline-formula>. The transition rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e020" xlink:type="simple"/></inline-formula> for a particular ion channel state is chosen by drawing a pseudo-random number <italic>r</italic><sub>1</sub> from a uniform distribution [0, 1] and defining <italic>t<sub>trans</sub></italic> as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e021" xlink:type="simple"/></inline-formula>. The Gillespie algorithm then selects which of the 28 possible transitions occur in the time interval <italic>t<sub>trans</sub></italic> <xref ref-type="bibr" rid="pcbi.1003439-Chow1">[79]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Gillespie1">[81]</xref>. The conditional probability of a particular transition <italic>j</italic> that occurs in the time interval <italic>δt</italic> is given by,<disp-formula id="pcbi.1003439.e022"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e022" xlink:type="simple"/><label>(5)</label></disp-formula>Here, <italic>a<sub>j</sub></italic> is the product of transition rate associated with transition <italic>j</italic> and the number of channels in the original state of that transition. The denominator in <xref ref-type="disp-formula" rid="pcbi.1003439.e022">Eqn. (5)</xref> is equal to <italic>λ</italic>. The particular transition rate is selected by drawing a random number <italic>r</italic><sub>2</sub> from the uniform distribution [0, 1] and fixing <italic>ψ</italic> as,<disp-formula id="pcbi.1003439.e023"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e023" xlink:type="simple"/><label>(6)</label></disp-formula>The number of voltage-gated ion channels in each state was updated and the membrane potential calculated. An identical algorithm was used for the channel noise in the compartment containing only K<sup>+</sup> voltage-gated channels.</p>
</sec><sec id="s4c">
<title>Information-theoretic and linear systems analyses</title>
<p>Both information-theoretic and linear system analysis are a common place in neuroscience <xref ref-type="bibr" rid="pcbi.1003439-Borst1">[82]</xref>, but before providing a detailed exposition for each of these methods, we justify our use of them. The channel capacity for a Gaussian channel <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Rieke1">[56]</xref> allows us to place an upper bound on the Shannon information encoded in the generator potentials under the assumption of an additive Gaussian noise. On the other hand, the “direct method” <xref ref-type="bibr" rid="pcbi.1003439-Strong1">[26]</xref> is a minimal assumption method to derive an estimate of the reduction in entropy per unit time per spike. Although these two calculations enable us to quantify the information loss separately within each domain (graded and spiking), a more appropriate comparison would employ the same metric permitting direct comparison between domains. The Wiener filter <xref ref-type="bibr" rid="pcbi.1003439-Theunissen1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Rieke1">[56]</xref> permits such a comparison, allowing us to test the fidelity of both the analog and the pulsatile signals using identical linear optimal filtering, giving a lower bound on the information present in the response (e.g. to linearly decode the input stimulus). Thus, if inputs were linearly mapped onto outputs then the information rates from “direct method” and the “Wiener filter” analysis would be identical <xref ref-type="bibr" rid="pcbi.1003439-Borst1">[82]</xref>. The lower our reconstruction error the better our generative model of the output is.</p>
</sec><sec id="s4d">
<title>Information rates for spiking neuron models</title>
<p>There are several methods that have been used to quantify information rates in spiking neurons. These include histogram based “direct method” <xref ref-type="bibr" rid="pcbi.1003439-Strong1">[26]</xref>, context-tree Markov Chain Monte Carlo (MCMC) <xref ref-type="bibr" rid="pcbi.1003439-Kennel1">[83]</xref>, metric space method <xref ref-type="bibr" rid="pcbi.1003439-Victor1">[84]</xref>, binless method <xref ref-type="bibr" rid="pcbi.1003439-Victor2">[85]</xref>, compression entropy <xref ref-type="bibr" rid="pcbi.1003439-French1">[6]</xref>, among others. We have used the widely employed “direct method” to measure the entropy of the responses, primarily due to its simplicity and the separation of mutual information into separate terms capturing variability (spike train entropy) and reproducibility (noise entropy) <xref ref-type="bibr" rid="pcbi.1003439-Strong1">[26]</xref>. The spike train entropy quantifies the variability of the spike train across time. The noise entropy on the other hand, measured the reproducibility of the spike train across trials. These quantities were dependent upon the temporal resolution with which the spikes were sampled, Δ<italic>t</italic> and the size of time window, <italic>T</italic>. We present a different stimulus current in each subsequent trial (unfrozen noise) to calculate the spike train entropy, while using presentations of the same stimulus current in each subsequent trial (frozen noise) to calculate the noise correlation. We divided the spike train to form K-letter words (K = 2, 4, 6, 8, 12, 16, 24, 32, 48 or 64), where <italic>K</italic> = <italic>T</italic>/Δ<italic>t</italic>. We used the responses from the unfrozen noise session, to estimate the probability of occurrence of particular word, <italic>P</italic>(<italic>W</italic>). We estimated the total entropy as,<disp-formula id="pcbi.1003439.e024"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e024" xlink:type="simple"/><label>(7)</label></disp-formula>We estimated the probability distribution of each word at specified time durations, <italic>t</italic> so as to obtain <italic>P</italic>(<italic>W</italic>|<italic>t</italic>). Entropy estimates were then calculated from these distributions and the average of the distributions at all times were computed to yield the noise entropy as,<disp-formula id="pcbi.1003439.e025"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e025" xlink:type="simple"/><label>(8)</label></disp-formula>〈〉 indicates average over time. The information was then computed as,<disp-formula id="pcbi.1003439.e026"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e026" xlink:type="simple"/><label>(9)</label></disp-formula>The spike train entropy and the conditional noise entropy diverge in the limit of Δ<italic>τ</italic>→0, their difference converges to the true finite information rate in this limit <xref ref-type="bibr" rid="pcbi.1003439-Strong1">[26]</xref>. Therefore, we used bias correction methods such that the estimation of entropy was less prone to sampling errors <xref ref-type="bibr" rid="pcbi.1003439-Treves1">[86]</xref>. Using Δt = 1 <italic>ms</italic>, we varied the spike trains to form words of different lengths. Using these entropy estimates, we extrapolated to infinite word length from four most linear values of the curve of entropy against the inverse of word length.</p>
</sec><sec id="s4e">
<title>Information rates for nonspiking neuron models</title>
<p>We used an upper-bound method to calculate the maximum information transferable by the nonspiking responses <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Rieke1">[56]</xref>. This method assumes that the neuronal response and the neuronal noise had independent Gaussian probability distributions in the frequency domain and the noise was additive in nature. In the presence of additive non-Gaussian noise such a method provides us with an upper bound on the channel capacity that is dependent on the entropy power of the non-Gaussian noise distribution <xref ref-type="bibr" rid="pcbi.1003439-Shannon1">[25]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Pinsker1">[87]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Prelov1">[88]</xref>. We defined the stimulus <italic>S</italic> as the mean neuronal response obtained from a frozen noise experiment. The noise in each trial was calculated by removing the average response from the individual responses <italic>R<sub>i</sub></italic>. Owing to Gaussian assumptions, it required enough data to estimate the mean and variance of the Gaussian probabilities. The actual information might be lower than this bound because a Gaussian distribution has the highest entropy for a given variance. In our simulations, both the response and the noise had an approximately Gaussian distribution. We obtained the mean response power spectrum and the noise power spectrum using the multi-taper spectral estimator and computed their ratio to be the signal-to-noise ratio (SNR) <xref ref-type="bibr" rid="pcbi.1003439-Bendat1">[29]</xref>. This is then used to compute the information for the Gaussian channel as,<disp-formula id="pcbi.1003439.e027"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e027" xlink:type="simple"/><label>(10)</label></disp-formula>For our simulations, the limits of the integral were taken from <italic>k</italic><sub>1</sub> = 0 Hz to <italic>k</italic><sub>2</sub> = 300 Hz. The integral was evaluated using trapezoidal rule.</p>
</sec><sec id="s4f">
<title>Stimulus reconstruction</title>
<p>We performed stimulus reconstruction to test how noise affects the coherence of a linear system <xref ref-type="bibr" rid="pcbi.1003439-Theunissen1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003439-Rieke1">[56]</xref>. The method involved finding a linear temporal filter to minimize the difference between the real and the reconstructed stimulus. We followed Haag and Borst <xref ref-type="bibr" rid="pcbi.1003439-Haag1">[89]</xref> in the derivation of this filter using Gaussian unfrozen noise as the stimulus set. We used 60 trials that consisted of 1 second period of unfrozen white noise <italic>s<sub>i</sub></italic>(<italic>t</italic>) to obtain the spike trains <italic>r<sub>i</sub></italic>(<italic>t</italic>) in the form of 1's and 0's with 10 µ<italic>s</italic> resolution. These time domain signals were Fourier-transformed to obtain complex functions <italic>S<sub>i</sub></italic>(<italic>f</italic>) and <italic>R<sub>i</sub></italic>(<italic>f</italic>). Two filters were obtained, either by normalizing the cross-power spectral densities (CPSD) of the stimulus and the spike response by the stimulus power spectral density (PSD) (<italic>forward filter</italic>) or the spike power spectral density (<italic>reverse filter</italic>) as demonstrated below, with angle brackets (&lt; &gt;) indicating averages over trials,<disp-formula id="pcbi.1003439.e028"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e028" xlink:type="simple"/><label>(11)</label></disp-formula><disp-formula id="pcbi.1003439.e029"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e029" xlink:type="simple"/><label>(12)</label></disp-formula>Using the reverse filter, we estimated the stimulus, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003439.e030" xlink:type="simple"/></inline-formula> as the product between <italic>R<sub>i</sub></italic>(<italic>f</italic>) and <italic>G<sub>reverse</sub></italic>(<italic>f</italic>),<disp-formula id="pcbi.1003439.e031"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e031" xlink:type="simple"/><label>(13)</label></disp-formula>The quality of the estimate was evaluated by computing a filter between the original stimulus and the reconstructed stimulus; this is simply the coherence function (<italic>γ</italic><sup>2</sup>(f)) as shown below,<disp-formula id="pcbi.1003439.e032"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e032" xlink:type="simple"/><label>(14)</label></disp-formula><disp-formula id="pcbi.1003439.e033"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e033" xlink:type="simple"/><label>(15)</label></disp-formula>The coherence results have been cross-validated using a 65–35 split between the training set and the test set i.e., we used the first 65% of the trials to calculate the reverse filter and then checked its validity on the next 35% of the trials by computing the final filter (<italic>G</italic><sub>fnal</sub>(<italic>f</italic>)) or the actual coherence (<italic>γ</italic><sup>2</sup>(<italic>f</italic>)).</p>
<p>Reconstruction quality was measured using two metrics. First, normalized root mean squared error (nRMSE) between the original stimulus and the reconstructed stimulus was calculated as,<disp-formula id="pcbi.1003439.e034"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e034" xlink:type="simple"/><label>(16)</label></disp-formula>A nRMSE value that tends towards zero represents perfect reconstruction. Second, we calculated a coherence based information rate where a higher value indicates better reconstruction,<disp-formula id="pcbi.1003439.e035"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1003439.e035" xlink:type="simple"/><label>(17)</label></disp-formula></p>
</sec><sec id="s4g">
<title>Calculation of energy</title>
<p>Energy consumption in our model is defined as the amount of ATP expended during the encoding of the band-limited stimulus current. The Na<sup>+</sup>–K<sup>+</sup> pump hydrolyses one ATP molecule for three Na<sup>+</sup> ions extruded out and two K<sup>+</sup> ions imported into the cell <xref ref-type="bibr" rid="pcbi.1003439-Sengupta1">[11]</xref>. We determined the total K<sup>+</sup> current by separating the leak current into a K<sup>+</sup> permeable leak current and adding it to the delayed rectifier K<sup>+</sup> current. We computed the number of K<sup>+</sup> ions by integrating the area under the total K<sup>+</sup> current curve for the duration of stimulus presentation. In order to derive the energy consumption we calculated the number of ATP molecules used by multiplying the total K<sup>+</sup> charge by N<sub>A</sub>/(2F), where N<sub>A</sub> is the Avogadro's constant and F is the Faraday's constant.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1003439.s001" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s001" position="float" xlink:type="simple"><label>Figure S1</label><caption>
<p><bold>Input stimulus statistics affect the reliability of action potentials generated by the spiking neuron model.</bold> A. An example of a low mean, high standard deviation current stimulus (upper trace) and the action potentials evoked in the spiking neuron model with stochastic voltage-gated Na<sup>+</sup> channels and stochastic voltage-gated K<sup>+</sup> channels (middle trace). A raster plot (lower graph) of the action potentials evoked by presenting the same current stimulus 60 times. B. An example of a high mean, low standard deviation current stimulus (upper trace) and the action potentials evoked in the spiking neuron model with stochastic voltage-gated Na<sup>+</sup> channels and stochastic voltage-gated K<sup>+</sup> channels (middle trace). A raster plot (lower graph) of the action potentials evoked by presenting the same current stimulus 60 times.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003439.s002" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s002" position="float" xlink:type="simple"><label>Figure S2</label><caption>
<p><bold>The effect of voltage-gated Na<sup>+</sup> or K<sup>+</sup> channel noise on action potentials generated by the spiking neuron model.</bold> A. An example of a low mean, high standard deviation current stimulus (upper trace) and the action potentials evoked in the spiking neuron model with stochastic voltage-gated Na<sup>+</sup> channels and deterministic voltage-gated K<sup>+</sup> channels (middle trace). A raster plot (lower graph) of the action potentials evoked by presenting the same current stimulus 60 times. B. An example of the action potentials evoked in the spiking neuron model with deterministic voltage-gated Na<sup>+</sup> channels and stochastic voltage-gated K<sup>+</sup> channels (middle trace) in response the same current stimulus (upper trace) as in A. A raster plot (lower graph) of the action potentials evoked by presenting the same current stimulus 60 times.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003439.s003" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s003" position="float" xlink:type="simple"><label>Figure S3</label><caption>
<p><bold>Linear decoding performance using action potentials, generator potentials and graded voltage responses.</bold> A. The blue trace represents the input stimulus current while the red trace represents linear reconstruction based entirely on the spiking response. The current input had a mean and standard deviation set at 0 µA/cm<sup>2</sup> and 5 µA/cm<sup>2</sup> respectively. B. The blue trace represents the input stimulus current and the red trace represents linear reconstruction based entirely on the pseudo-analog response. C. The blue trace represents the input stimulus current while the red trace represents linear reconstruction based entirely on the graded response. D. Normalized mean squared error (nRMSE) between the original and the reconstructed input. The mean and standard deviation of the inputs were sampled from N(0, 2), N(0, 5), N(0, 10), N(5, 5), N(10, 5) <italic>and</italic> N(10, 10). E. Coherence based mutual information for the inputs in D.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003439.s004" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s004" position="float" xlink:type="simple"><label>Figure S4</label><caption>
<p><bold>The effect of extrinsic noise on action potentials generated by the spiking neuron model.</bold> A. Total entropy, B. noise entropy, and C. mutual information of the spike trains generated in response to white noise current stimuli with different means and standard deviations. The Signal-to-Noise ratio (SNR) of the input was fixed at 2.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003439.s005" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s005" position="float" xlink:type="simple"><label>Figure S5</label><caption>
<p><bold>Extrinsic noise reduces mutual information in spike trains, pseudo-generator potentials and graded potentials.</bold> A. <xref ref-type="sec" rid="s1">Introduction</xref> of extrinsic noise with SNR = 2 causes a 40% decrease in mutual information in the spiking responses. B. Similarly, there is a decrease of up to 60% in the pseudo-generator potentials in response to inputs with SNR = 2. C. Over a wide variety of inputs, the mutual information is decreased up to 70% in the graded potentials with the introduction of extrinsic noise.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003439.s006" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s006" position="float" xlink:type="simple"><label>Figure S6</label><caption>
<p><bold>The numbers of open K<sup>+</sup> channels and the membrane potential range determines the energy consumption of pseudo-generator potentials.</bold> A. Joint kernel density estimates of open K<sup>+</sup> channels and the membrane potential in response to low mean, low standard deviation stimulus, and B. low mean, high standard deviation stimulus. C. Joint kernel density estimates of open K<sup>+</sup> channels and the membrane potential in response to high mean, low standard deviation stimulus, and D. high mean, high standard deviation stimulus.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003439.s007" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s007" position="float" xlink:type="simple"><label>Figure S7</label><caption>
<p><bold>The numbers of open K<sup>+</sup> channels and the membrane potential range determines the energy consumption of graded potentials.</bold> A. Joint kernel density estimates of open K<sup>+</sup> channels and the membrane potential in response to low mean, low standard deviation stimulus, and B. low mean, high standard deviation stimulus. C. Joint kernel density estimates of open K<sup>+</sup> channels and the membrane potential in response to high mean, low standard deviation stimulus, and D. high mean, high standard deviation stimulus.</p>
<p>(PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003439.s008" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s008" position="float" xlink:type="simple"><label>Figure S8</label><caption>
<p><bold>The gating scheme for the voltage-gated ion channels.</bold> A. State transition diagram for Na<sup>+</sup> channel. B. State transition diagram for K<sup>+</sup> channel.</p>
<p>(EPS)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1003439.s009" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pcbi.1003439.s009" position="float" xlink:type="simple"><label>Table S1</label><caption>
<p><bold>Parameters for the stochastic Hodgkin-Huxley model.</bold></p>
<p>(DOCX)</p>
</caption></supplementary-material></sec></body>
<back><ref-list>
<title>References</title>
<ref id="pcbi.1003439-Roberts1"><label>1</label>
<mixed-citation publication-type="book" xlink:type="simple">Roberts A, Bush BMH (1981) Neurones without impulses: their significance for vertebrate and invertebrate nervous systems. Cambridge: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Jack1"><label>2</label>
<mixed-citation publication-type="book" xlink:type="simple">Jack JJB, Noble D, Tsien RW (1975) Electric current flow in excitable cells. Oxford: Clarendon Press.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Laughlin1"><label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>JC</given-names></name> (<year>1998</year>) <article-title>The metabolic cost of neural information</article-title>. <source>Nat Neurosci</source> <volume>1</volume>: <fpage>36</fpage>–<lpage>41</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Sarpeshkar1"><label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sarpeshkar</surname><given-names>R</given-names></name> (<year>1998</year>) <article-title>Analog Versus Digital: Extrapolating from Electronics to Neurobiology</article-title>. <source>Neural Comp</source> <volume>10</volume>: <fpage>1601</fpage>–<lpage>1638</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-DiCaprio1"><label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DiCaprio</surname><given-names>RA</given-names></name>, <name name-style="western"><surname>Billimoria</surname><given-names>CP</given-names></name>, <name name-style="western"><surname>Ludwar</surname><given-names>B</given-names></name> (<year>2007</year>) <article-title>Information rate and spike-timing precision of proprioceptive afferents</article-title>. <source>J Neurophysiol</source> <volume>98</volume>: <fpage>1706</fpage>–<lpage>1717</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-French1"><label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>French</surname><given-names>AS</given-names></name>, <name name-style="western"><surname>Pfeiffer</surname><given-names>K</given-names></name> (<year>2011</year>) <article-title>Measuring entropy in continuous and digitally filtered neural signals</article-title>. <source>J Neurosci Methods</source> <volume>196</volume>: <fpage>81</fpage>–<lpage>87</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Juusola1"><label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Juusola</surname><given-names>M</given-names></name>, <name name-style="western"><surname>French</surname><given-names>AS</given-names></name> (<year>1997</year>) <article-title>The efficiency of sensory information coding by mechanoreceptor neurons</article-title>. <source>Neuron</source> <volume>18</volume>: <fpage>959</fpage>–<lpage>968</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-vanSteveninck1"><label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Steveninck</surname><given-names>RRdR</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name> (<year>1996</year>) <article-title>The rate of information transfer at graded-potential synapses</article-title>. <source>Nature</source> <volume>379</volume>: <fpage>642</fpage>–<lpage>645</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Theunissen1"><label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Theunissen</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Roddey</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Stufflebeam</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Clague</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Miller</surname><given-names>JP</given-names></name> (<year>1996</year>) <article-title>Information theoretic analysis of dynamical encoding by four identified primary sensory interneurons in the cricket cercal system</article-title>. <source>J Neurophysiol</source> <volume>75</volume>: <fpage>1345</fpage>–<lpage>1364</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Niven1"><label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name> (<year>2008</year>) <article-title>Energy limitation as a selective pressure on the evolution of sensory systems</article-title>. <source>J Exp Biol</source> <volume>211</volume>: <fpage>1792</fpage>–<lpage>1804</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Sengupta1"><label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengupta</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Stemmler</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name> (<year>2010</year>) <article-title>Action potential energy efficiency varies among neuron types in vertebrates and invertebrates</article-title>. <source>PLoS Comput Biol</source> <volume>6</volume>: <fpage>e1000840</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Attwell1"><label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Attwell</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name> (<year>2001</year>) <article-title>An energy budget for signaling in the grey matter of the brain</article-title>. <source>J Cereb Blood Flow Metab</source> <volume>21</volume>: <fpage>1133</fpage>–<lpage>1145</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Niven2"><label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Anderson</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name> (<year>2007</year>) <article-title>Fly photoreceptors demonstrate energy-information trade-offs in neural coding</article-title>. <source>PLoS Biol</source> <volume>5</volume>: <fpage>e116</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Alle1"><label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alle</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Roth</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Geiger</surname><given-names>JR</given-names></name> (<year>2009</year>) <article-title>Energy-efficient action potentials in hippocampal mossy fibers</article-title>. <source>Science</source> <volume>325</volume>: <fpage>1405</fpage>–<lpage>1408</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Carter1"><label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carter</surname><given-names>BC</given-names></name>, <name name-style="western"><surname>Bean</surname><given-names>BP</given-names></name> (<year>2009</year>) <article-title>Sodium entry during action potentials of mammalian neurons: incomplete inactivation and reduced metabolic efficiency in fast-spiking neurons</article-title>. <source>Neuron</source> <volume>64</volume>: <fpage>898</fpage>–<lpage>909</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Hasenstaub1"><label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hasenstaub</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Otte</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Callaway</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>2010</year>) <article-title>Metabolic cost as a unifying principle governing neuronal biophysics</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>107</volume>: <fpage>12329</fpage>–<lpage>12334</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-White1"><label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Rubinstein</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Kay</surname><given-names>AR</given-names></name> (<year>2000</year>) <article-title>Channel noise in neurons</article-title>. <source>Trends Neurosci</source> <volume>23</volume>: <fpage>131</fpage>–<lpage>137</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Manwani1"><label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manwani</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Steinmetz</surname><given-names>PN</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name> (<year>2002</year>) <article-title>The impact of spike timing variability on the signal-encoding performance of neural spiking models</article-title>. <source>Neural Comput</source> <volume>14</volume>: <fpage>347</fpage>–<lpage>367</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Manwani2"><label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manwani</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name> (<year>1999</year>) <article-title>Detecting and estimating signals in noisy cable structure, I: neuronal noise sources</article-title>. <source>Neural Comput</source> <volume>11</volume>: <fpage>1797</fpage>–<lpage>1829</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-AguerayArcas1"><label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aguera y Arcas</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name> (<year>2003</year>) <article-title>Computation in a single neuron: Hodgkin and Huxley revisited</article-title>. <source>Neural Comput</source> <volume>15</volume>: <fpage>1715</fpage>–<lpage>1749</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Lenn1"><label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lenn</surname><given-names>NJ</given-names></name>, <name name-style="western"><surname>Reese</surname><given-names>TS</given-names></name> (<year>1966</year>) <article-title>The fine structure of nerve endings in the nucleus of the trapezoid body and the ventral cochlear nucleus</article-title>. <source>Am J Anat</source> <volume>118</volume>: <fpage>375</fpage>–<lpage>389</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Rekling1"><label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rekling</surname><given-names>JC</given-names></name>, <name name-style="western"><surname>Funk</surname><given-names>GD</given-names></name>, <name name-style="western"><surname>Bayliss</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Dong</surname><given-names>XW</given-names></name>, <name name-style="western"><surname>Feldman</surname><given-names>JL</given-names></name> (<year>2000</year>) <article-title>Synaptic control of motoneuronal excitability</article-title>. <source>Physiol Rev</source> <volume>80</volume>: <fpage>767</fpage>–<lpage>852</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Koch1"><label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Douglas</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Wehmeier</surname><given-names>U</given-names></name> (<year>1990</year>) <article-title>Visibility of synaptically induced conductance changes: theory and simulations of anatomically characterized cortical pyramidal cells</article-title>. <source>J Neurosci</source> <volume>10</volume>: <fpage>1728</fpage>–<lpage>1744</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Cover1"><label>24</label>
<mixed-citation publication-type="other" xlink:type="simple">Cover TM, Thomas JA (2006) Elements of Information Theory Wiley-Interscience.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Shannon1"><label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shannon</surname><given-names>C</given-names></name> (<year>1948</year>) <article-title>A Mathematical Theory of Communication</article-title>. <source>Bell System Technical Journal</source> <volume>27</volume>: <fpage>379</fpage>–<lpage>423</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Strong1"><label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Strong</surname><given-names>SP</given-names></name>, <name name-style="western"><surname>de Ruyter van Steveninck</surname><given-names>RR</given-names></name>, <name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Koberle</surname><given-names>R</given-names></name> (<year>1998</year>) <article-title>On the application of information theory to neural spike trains</article-title>. <source>Proceedings of the Pac Symp Biocomput</source> <fpage>621</fpage>–<lpage>632</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-MacKay1"><label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>MacKay</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>McCulloch</surname><given-names>WS</given-names></name> (<year>1952</year>) <article-title>The limiting capacity of a neuronal link</article-title>. <source>Bull Math Phys</source> <volume>14</volume>: <fpage>127</fpage>–<lpage>135</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Mainen1"><label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mainen</surname><given-names>ZF</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>1995</year>) <article-title>Reliability of spike timing in neocortical neurons</article-title>. <source>Science</source> <volume>268</volume>: <fpage>1503</fpage>–<lpage>1506</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Bendat1"><label>29</label>
<mixed-citation publication-type="book" xlink:type="simple">Bendat JS, Piersol AG (2010) Random data: analysis and measurement procedures: John Wiley &amp; Sons.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Steinmetz1"><label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Steinmetz</surname><given-names>PN</given-names></name>, <name name-style="western"><surname>Manwani</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>, <name name-style="western"><surname>London</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Segev</surname><given-names>I</given-names></name> (<year>2000</year>) <article-title>Subthreshold voltage noise due to channel fluctuations in active neuronal membranes</article-title>. <source>J Comput Neurosci</source> <volume>9</volume>: <fpage>133</fpage>–<lpage>148</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Curti1"><label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Curti</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Gomez</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Budelli</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Pereda</surname><given-names>AE</given-names></name> (<year>2008</year>) <article-title>Subthreshold sodium current underlies essential functional specializations at primary auditory afferents</article-title>. <source>J Neurophysiol</source> <volume>99</volume>: <fpage>1683</fpage>–<lpage>1699</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Desmaisons1"><label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Desmaisons</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Vincent</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Lledo</surname><given-names>PM</given-names></name> (<year>1999</year>) <article-title>Control of action potential timing by intrinsic subthreshold oscillations in olfactory bulb output neurons</article-title>. <source>J Neurosci</source> <volume>19</volume>: <fpage>10727</fpage>–<lpage>10737</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Dodge1"><label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dodge</surname><given-names>FA</given-names><suffix>Jr</suffix></name>, <name name-style="western"><surname>Knight</surname><given-names>BW</given-names></name>, <name name-style="western"><surname>Toyoda</surname><given-names>J</given-names></name> (<year>1968</year>) <article-title>Voltage noise in Limulus visual cells</article-title>. <source>Science</source> <volume>160</volume>: <fpage>88</fpage>–<lpage>90</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Lillywhite1"><label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lillywhite</surname><given-names>PG</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name> (<year>1979</year>) <article-title>Transducer noise in a photoreceptor</article-title>. <source>Nature</source> <volume>277</volume>: <fpage>569</fpage>–<lpage>572</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-McDonnell1"><label>35</label>
<mixed-citation publication-type="book" xlink:type="simple">McDonnell MD, Stocks NG, Pearce CEM, Abbott D (2008) Stochastic resonance: from suprathreshold stochastic resonance to stochastic signal quantization: Cambridge University Press.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Skou1"><label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Skou</surname><given-names>JC</given-names></name> (<year>1957</year>) <article-title>The influence of some cations on an adenosine triphosphatase from peripheral nerves</article-title>. <source>Biochim Biophys Acta</source> <volume>23</volume>: <fpage>394</fpage>–<lpage>401</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Lazar1"><label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lazar</surname><given-names>AA</given-names></name>, <name name-style="western"><surname>Toth</surname><given-names>LT</given-names></name> (<year>2004</year>) <article-title>Perfect recovery and sensitivity analysis of time encoded bandlimited signals</article-title>. <source>Circuits and Systems I: Regular Papers, IEEE Transactions on</source> <volume>51</volume>: <fpage>2060</fpage>–<lpage>2073</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Lazar2"><label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lazar</surname><given-names>AA</given-names></name>, <name name-style="western"><surname>Pnevmatikakis</surname><given-names>EA</given-names></name> (<year>2008</year>) <article-title>Faithful Representation of Stimuli with a Population of Integrate-and-Fire Neurons</article-title>. <source>Neural Computation</source> <volume>20</volume>: <fpage>2715</fpage>–<lpage>2744</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Lazar3"><label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lazar</surname><given-names>AA</given-names></name> (<year>2009</year>) <article-title>Population encoding with Hodgkin-Huxley neurons</article-title>. <source>IEEE Trans Inf Theor</source> <volume>56</volume>: <fpage>821</fpage>–<lpage>837</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Hodgkin1"><label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hodgkin</surname><given-names>AL</given-names></name>, <name name-style="western"><surname>Huxley</surname><given-names>AF</given-names></name> (<year>1952</year>) <article-title>A quantitative description of membrane current and its application to conduction and excitation in nerve</article-title>. <source>J Physiol</source> <volume>117</volume>: <fpage>500</fpage>–<lpage>544</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Skaugen1"><label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Skaugen</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Walloe</surname><given-names>L</given-names></name> (<year>1979</year>) <article-title>Firing behaviour in a stochastic nerve membrane model based upon the Hodgkin-Huxley equations</article-title>. <source>Acta Physiol Scand</source> <volume>107</volume>: <fpage>343</fpage>–<lpage>363</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-White2"><label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>White</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Klink</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Alonso</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kay</surname><given-names>AR</given-names></name> (<year>1998</year>) <article-title>Noise from voltage-gated ion channels may influence neuronal dynamics in the entorhinal cortex</article-title>. <source>J Neurophysiol</source> <volume>80</volume>: <fpage>262</fpage>–<lpage>269</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Sengupta2"><label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengupta</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Faisal</surname><given-names>AA</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name> (<year>2013</year>) <article-title>The effect of cell size and channel density on neuronal information encoding and energy efficiency</article-title>. <source>J Cereb Blood Flow Metab</source> <volume>33</volume>: <fpage>1465</fpage>–<lpage>1473</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Kole1"><label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kole</surname><given-names>MH</given-names></name>, <name name-style="western"><surname>Ilschner</surname><given-names>SU</given-names></name>, <name name-style="western"><surname>Kampa</surname><given-names>BM</given-names></name>, <name name-style="western"><surname>Williams</surname><given-names>SR</given-names></name>, <name name-style="western"><surname>Ruben</surname><given-names>PC</given-names></name>, <etal>et al</etal>. (<year>2008</year>) <article-title>Action potential generation requires a high sodium channel density in the axon initial segment</article-title>. <source>Nat Neurosci</source> <volume>11</volume>: <fpage>178</fpage>–<lpage>186</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Stuart1"><label>45</label>
<mixed-citation publication-type="book" xlink:type="simple">Stuart G, Spruston N, Häusser M (2007) Dendrites. Oxford; New York: Oxford University Press. xv, 560 p. p.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Laurent1"><label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laurent</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Seymour-Laurent</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>K</given-names></name> (<year>1993</year>) <article-title>Dendritic excitability and a voltage-gated calcium current in locust nonspiking local interneurons</article-title>. <source>J Neurophysiol</source> <volume>69</volume>: <fpage>1484</fpage>–<lpage>1498</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Olshausen1"><label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>2004</year>) <article-title>Sparse coding of sensory inputs</article-title>. <source>Curr Opin Neurobiol</source> <volume>14</volume>: <fpage>481</fpage>–<lpage>487</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Izhikevich1"><label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Izhikevich</surname><given-names>EM</given-names></name> (<year>2004</year>) <article-title>Which model to use for cortical spiking neurons?</article-title> <source>IEEE Trans Neural Netw</source> <volume>15</volume>: <fpage>1063</fpage>–<lpage>1070</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Tishby1"><label>49</label>
<mixed-citation publication-type="other" xlink:type="simple">Tishby N, Pereira F, Bialek W (1999) The Information Bottleneck Method. The 37th annual Allerton Conference on Communication, Control, and Computing.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Koch2"><label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Segev</surname><given-names>I</given-names></name> (<year>2000</year>) <article-title>The role of single neurons in information processing</article-title>. <source>Nat Neurosci</source> <volume>3 Suppl</volume>: <fpage>1171</fpage>–<lpage>1177</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Williams1"><label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Williams</surname><given-names>SR</given-names></name>, <name name-style="western"><surname>Stuart</surname><given-names>GJ</given-names></name> (<year>2002</year>) <article-title>Dependence of EPSP efficacy on synapse location in neocortical pyramidal neurons</article-title>. <source>Science</source> <volume>295</volume>: <fpage>1907</fpage>–<lpage>1910</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Larkum1"><label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Larkum</surname><given-names>ME</given-names></name>, <name name-style="western"><surname>Zhu</surname><given-names>JJ</given-names></name>, <name name-style="western"><surname>Sakmann</surname><given-names>B</given-names></name> (<year>2001</year>) <article-title>Dendritic mechanisms underlying the coupling of the dendritic with the axonal action potential initiation zone of adult rat layer 5 pyramidal neurons</article-title>. <source>J Physiol</source> <volume>533</volume>: <fpage>447</fpage>–<lpage>466</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Sengupta3"><label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengupta</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name> (<year>2013</year>) <article-title>Balanced excitatory and inhibitory synaptic currents promote efficient coding and metabolic efficiency</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>: <fpage>e1003263</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Destexhe1"><label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Destexhe</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Rudolph</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Pare</surname><given-names>D</given-names></name> (<year>2003</year>) <article-title>The high-conductance state of neocortical neurons in vivo</article-title>. <source>Nat Rev Neurosci</source> <volume>4</volume>: <fpage>739</fpage>–<lpage>751</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Stemmler1"><label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Stemmler</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Sengupta</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name> (<year>2012</year>) <article-title>Energetically Optimal Action Potentials</article-title>. <source>Advances in NIPS</source> <fpage>1566</fpage>–<lpage>1574</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Rieke1"><label>56</label>
<mixed-citation publication-type="book" xlink:type="simple">Rieke F (1997) Spikes: exploring the neural code: MIT Press.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Koch3"><label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Koch</surname><given-names>K</given-names></name>, <name name-style="western"><surname>McLean</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Segev</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Freed</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Berry</surname><given-names>MJ</given-names><suffix>2nd</suffix></name>, <etal>et al</etal>. (<year>2006</year>) <article-title>How much the eye tells the brain</article-title>. <source>Curr Biol</source> <volume>16</volume>: <fpage>1428</fpage>–<lpage>1434</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Niven3"><label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Vahasoyrinki</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Juusola</surname><given-names>M</given-names></name>, <name name-style="western"><surname>French</surname><given-names>AS</given-names></name> (<year>2004</year>) <article-title>Interactions between light-induced currents, voltage-gated currents, and input signal properties in Drosophila photoreceptors</article-title>. <source>J Neurophysiol</source> <volume>91</volume>: <fpage>2696</fpage>–<lpage>2706</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Singer1"><label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Singer</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Gray</surname><given-names>CM</given-names></name> (<year>1995</year>) <article-title>Visual feature integration and the temporal correlation hypothesis</article-title>. <source>Annu Rev Neurosci</source> <volume>18</volume>: <fpage>555</fpage>–<lpage>586</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Lee1"><label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lee</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Port</surname><given-names>NL</given-names></name>, <name name-style="western"><surname>Kruse</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Georgopoulos</surname><given-names>AP</given-names></name> (<year>1998</year>) <article-title>Variability and correlated noise in the discharge of neurons in motor and parietal areas of the primate cortex</article-title>. <source>J Neurosci</source> <volume>18</volume>: <fpage>1161</fpage>–<lpage>1170</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Gawne1"><label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gawne</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Richmond</surname><given-names>BJ</given-names></name> (<year>1993</year>) <article-title>How independent are the messages carried by adjacent inferior temporal cortical neurons?</article-title> <source>J Neurosci</source> <volume>13</volume>: <fpage>2758</fpage>–<lpage>2771</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Shadlen1"><label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shadlen</surname><given-names>MN</given-names></name>, <name name-style="western"><surname>Newsome</surname><given-names>WT</given-names></name> (<year>1998</year>) <article-title>The variable discharge of cortical neurons: implications for connectivity, computation, and information coding</article-title>. <source>J Neurosci</source> <volume>18</volume>: <fpage>3870</fpage>–<lpage>3896</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Salinas1"><label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Salinas</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>2000</year>) <article-title>Impact of correlated synaptic input on output firing rate and variability in simple neuronal models</article-title>. <source>J Neurosci</source> <volume>20</volume>: <fpage>6193</fpage>–<lpage>6209</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Bernander1"><label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bernander</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Koch</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Usher</surname><given-names>M</given-names></name> (<year>1994</year>) <article-title>The effect of synchronized inputs at the single neuron level</article-title>. <source>Neural Comput</source> <volume>6</volume>: <fpage>622</fpage>–<lpage>641</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Srinivasan1"><label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Srinivasan</surname><given-names>MV</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Dubs</surname><given-names>A</given-names></name> (<year>1982</year>) <article-title>Predictive coding: a fresh view of inhibition in the retina</article-title>. <source>Proc R Soc Lond B Biol Sci</source> <volume>216</volume>: <fpage>427</fpage>–<lpage>459</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Laughlin2"><label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>S</given-names></name> (<year>1981</year>) <article-title>A simple coding procedure enhances a neuron's information capacity</article-title>. <source>Z Naturforsch C</source> <volume>36</volume>: <fpage>910</fpage>–<lpage>912</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Niven4"><label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Farris</surname><given-names>SM</given-names></name> (<year>2012</year>) <article-title>Miniaturization of nervous systems and neurons</article-title>. <source>Curr Biol</source> <volume>22</volume>: <fpage>R323</fpage>–<lpage>329</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Sengupta4"><label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengupta</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Stemmler</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Friston</surname><given-names>K</given-names></name> (<year>2013</year>) <article-title>Information and efficiency in the nervous system</article-title>. <source>PloS Computational Biology</source> <volume>9</volume>: <fpage>e1003157</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Grubb1"><label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grubb</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Burrone</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>Activity-dependent relocation of the axon initial segment fine-tunes neuronal excitability</article-title>. <source>Nature</source> <volume>465</volume>: <fpage>1070</fpage>–<lpage>1074</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Marder1"><label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marder</surname><given-names>E</given-names></name> (<year>2006</year>) <article-title>Neurobiology: extending influence</article-title>. <source>Nature</source> <volume>441</volume>: <fpage>702</fpage>–<lpage>703</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Alle2"><label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Alle</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Geiger</surname><given-names>JR</given-names></name> (<year>2006</year>) <article-title>Combined analog and action potential coding in hippocampal mossy fibers</article-title>. <source>Science</source> <volume>311</volume>: <fpage>1290</fpage>–<lpage>1293</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Shu1"><label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Hasenstaub</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Duque</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Yu</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>McCormick</surname><given-names>DA</given-names></name> (<year>2006</year>) <article-title>Modulation of intracortical synaptic potentials by presynaptic somatic membrane potential</article-title>. <source>Nature</source> <volume>441</volume>: <fpage>761</fpage>–<lpage>765</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Niven5"><label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name>, <name name-style="western"><surname>Burrows</surname><given-names>M</given-names></name> (<year>2003</year>) <article-title>Spike width reduction modifies the dynamics of short-term depression at a central synapse in the locust</article-title>. <source>J Neurosci</source> <volume>23</volume>: <fpage>7461</fpage>–<lpage>7469</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-dePolavieja1"><label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>de Polavieja</surname><given-names>GG</given-names></name>, <name name-style="western"><surname>Harsch</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kleppe</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Robinson</surname><given-names>HP</given-names></name>, <name name-style="western"><surname>Juusola</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>Stimulus history reliably shapes action potential waveforms of cortical neurons</article-title>. <source>J Neurosci</source> <volume>25</volume>: <fpage>5657</fpage>–<lpage>5665</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Guttman1"><label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guttman</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Feldman</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Lecar</surname><given-names>H</given-names></name> (<year>1974</year>) <article-title>Squid axon membrane response to white noise stimulation</article-title>. <source>Biophys J</source> <volume>14</volume>: <fpage>941</fpage>–<lpage>955</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Schneidman1"><label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Freedman</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Segev</surname><given-names>I</given-names></name> (<year>1998</year>) <article-title>Ion channel stochasticity may be critical in determining the reliability and precision of spike timing</article-title>. <source>Neural Comput</source> <volume>10</volume>: <fpage>1679</fpage>–<lpage>1703</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Marsaglia1"><label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Marsaglia</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Tsang</surname><given-names>W</given-names></name> (<year>2000</year>) <article-title>The Ziggurat method for generating random variables</article-title>. <source>Journal of Statistical Software</source> <volume>1</volume>: <fpage>1</fpage>–<lpage>7</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Matsumoto1"><label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Matsumoto</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Nishimura</surname><given-names>T</given-names></name> (<year>1998</year>) <article-title>Mersenne twister: a 623-dimensionally equidistributed uniform pseudo-random number generator</article-title>. <source>ACM Trans Model Comput Simul</source> <volume>8</volume>: <fpage>3</fpage>–<lpage>30</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Chow1"><label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chow</surname><given-names>CC</given-names></name>, <name name-style="western"><surname>White</surname><given-names>JA</given-names></name> (<year>1996</year>) <article-title>Spontaneous action potentials due to channel fluctuations</article-title>. <source>Biophys J</source> <volume>71</volume>: <fpage>3013</fpage>–<lpage>3021</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Sengupta5"><label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sengupta</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name>, <name name-style="western"><surname>Niven</surname><given-names>JE</given-names></name> (<year>2010</year>) <article-title>Comparison of Langevin and Markov channel noise models for neuronal signal generation</article-title>. <source>Phys Rev E Stat Nonlin Soft Matter Phys</source> <volume>81</volume>: <fpage>011918</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Gillespie1"><label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gillespie</surname><given-names>DT</given-names></name> (<year>1977</year>) <article-title>Exact stochastic simulation of coupled chemical reactions</article-title>. <source>The Journal of Physical Chemistry</source> <volume>81</volume>: <fpage>2340</fpage>–<lpage>2361</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Borst1"><label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Borst</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>1999</year>) <article-title>Information theory and neural coding</article-title>. <source>Nat Neurosci</source> <volume>2</volume>: <fpage>947</fpage>–<lpage>957</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Kennel1"><label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kennel</surname><given-names>MB</given-names></name>, <name name-style="western"><surname>Shlens</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Abarbanel</surname><given-names>HD</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname><given-names>EJ</given-names></name> (<year>2005</year>) <article-title>Estimating entropy rates with Bayesian confidence intervals</article-title>. <source>Neural Comput</source> <volume>17</volume>: <fpage>1531</fpage>–<lpage>1576</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Victor1"><label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name>, <name name-style="western"><surname>Purpura</surname><given-names>K</given-names></name> (<year>1997</year>) <article-title>Metric-space analysis of spike trains: theory, algorithms, and application</article-title>. <source>Network</source> <volume>8</volume>: <fpage>127</fpage>–<lpage>164</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Victor2"><label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Victor</surname><given-names>JD</given-names></name> (<year>2002</year>) <article-title>Binless strategies for estimation of information from neural data</article-title>. <source>Phys Rev E Stat Nonlin Soft Matter Phys</source> <volume>66</volume>: <fpage>051903</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Treves1"><label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Treves</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Panzeri</surname><given-names>S</given-names></name> (<year>1995</year>) <article-title>The upward bias in measures of information derived from limited data</article-title>. <source>Neural Computation</source> <volume>7</volume>: <fpage>399</fpage>–<lpage>407</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Pinsker1"><label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Pinsker</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Prelov</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Verdú</surname><given-names>S</given-names></name> (<year>1995</year>) <article-title>Sensitivity of channel capacity</article-title>. <source>IEEE Trans Inform Theory</source> <volume>41</volume>: <fpage>1877</fpage>–<lpage>1888</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Prelov1"><label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Prelov</surname><given-names>V</given-names></name> (<year>1968</year>) <article-title>Asymptotic behavior of a continuous channel with small additive noise</article-title>. <source>Probl Inform Transm</source> <volume>4</volume>: <fpage>31</fpage>–<lpage>37</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1003439-Haag1"><label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Haag</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Borst</surname><given-names>A</given-names></name> (<year>1997</year>) <article-title>Encoding of visual motion information and reliability in spiking and graded potential neurons</article-title>. <source>J Neurosci</source> <volume>17</volume>: <fpage>4809</fpage>–<lpage>4819</lpage>.</mixed-citation>
</ref>
</ref-list></back>
</article>
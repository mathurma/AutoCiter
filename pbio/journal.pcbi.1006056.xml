<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-01535</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006056</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Random variables</subject><subj-group><subject>Covariance</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Network analysis</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain mapping</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Diagnostic medicine</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Radiology and imaging</subject><subj-group><subject>Diagnostic radiology</subject><subj-group><subject>Magnetic resonance imaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Imaging techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional magnetic resonance imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Operator theory</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Particle physics</subject><subj-group><subject>Colliders</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Linear algebra</subject><subj-group><subject>Eigenvalues</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject></subj-group></subj-group></article-categories>
<title-group>
<article-title>From correlation to causation: Estimating effective connectivity from zero-lag covariances of brain signals</article-title>
<alt-title alt-title-type="running-head">Estimating effective connectivity from zero-lag covariances of brain signals</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Schiefer</surname> <given-names>Jonathan</given-names></name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Niederbühl</surname> <given-names>Alexander</given-names></name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7629-1009</contrib-id>
<name name-style="western">
<surname>Pernice</surname> <given-names>Volker</given-names></name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Lennartz</surname> <given-names>Carolin</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-2273-3497</contrib-id>
<name name-style="western">
<surname>Hennig</surname> <given-names>Jürgen</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0514-6522</contrib-id>
<name name-style="western">
<surname>LeVan</surname> <given-names>Pierre</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3534-6530</contrib-id>
<name name-style="western">
<surname>Rotter</surname> <given-names>Stefan</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Bernstein Center Freiburg, Freiburg, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Faculty of Biology, University of Freiburg, Freiburg, Germany</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Radiology, Medical Physics, Medical Center - University of Freiburg, Freiburg, Germany</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Faculty of Medicine, University of Freiburg, Freiburg, Germany</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Jbabdi</surname> <given-names>Saad</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Oxford University, UNITED KINGDOM</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">stefan.rotter@biologie.uni-freiburg.de</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>3</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>26</day>
<month>3</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>3</issue>
<elocation-id>e1006056</elocation-id>
<history>
<date date-type="received">
<day>12</day>
<month>9</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>2</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Schiefer et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006056"/>
<abstract>
<p>Knowing brain connectivity is of great importance both in basic research and for clinical applications. We are proposing a method to infer directed connectivity from zero-lag covariances of neuronal activity recorded at multiple sites. This allows us to identify causal relations that are reflected in neuronal population activity. To derive our strategy, we assume a generic linear model of interacting continuous variables, the components of which represent the activity of local neuronal populations. The suggested method for inferring connectivity from recorded signals exploits the fact that the covariance matrix derived from the observed activity contains information about the existence, the direction and the sign of connections. Assuming a sparsely coupled network, we disambiguate the underlying causal structure via <italic>L</italic><sup>1</sup>-minimization, which is known to prefer sparse solutions. In general, this method is suited to infer effective connectivity from resting state data of various types. We show that our method is applicable over a broad range of structural parameters regarding network size and connection probability of the network. We also explored parameters affecting its activity dynamics, like the eigenvalue spectrum. Also, based on the simulation of suitable Ornstein-Uhlenbeck processes to model BOLD dynamics, we show that with our method it is possible to estimate directed connectivity from zero-lag covariances derived from such signals. In this study, we consider measurement noise and unobserved nodes as additional confounding factors. Furthermore, we investigate the amount of data required for a reliable estimate. Additionally, we apply the proposed method on full-brain resting-state fast fMRI datasets. The resulting network exhibits a tendency for close-by areas being connected as well as inter-hemispheric connections between corresponding areas. In addition, we found that a surprisingly large fraction of more than one third of all identified connections were of inhibitory nature.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>Changes in brain connectivity are considered an important biomarker for certain brain diseases. This directly raises the question of accessibility of connectivity from measured brain signals. Here we show how directed effective connectivity can be inferred from continuous brain signals, like fMRI. The main idea is to extract the connectivity from the inverse zero-lag covariance matrix of the measured signals. This is done using <italic>L</italic><sup>1</sup>-minimization via gradient descent algorithm on the manifold of unitary matrices. This ensures that the resulting network always fits the same covariance structure as the measured data, assuming a canonical linear model. Applying the estimation method on noise-free covariance matrices shows that the method works nicely on sparsely coupled networks with more than 40 nodes, provided network interaction is strong enough. Applying the estimation on simulated Ornstein-Uhlenbeck processes supposed to model BOLD signals demonstrates robustness against observation noise and unobserved nodes. In general, the proposed method can be applied to time-resolved covariance matrices in the frequency domain (cross-spectral densities), leading to frequency-resolved networks. We are able to demonstrate that our method leads to reliable results, if the sampled signals are long enough.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution>Deutsche Forschungsgemeinschaft (DE)</institution>
</funding-source>
<award-id>EXC 1086</award-id>
</award-group>
<funding-statement>Supported by the DFG (grant EXC 1086). The HPC facilities are funded by the state of Baden-Württemberg through bwHPC and DFG grant INST 39/963-1 FUGG. The article processing charge was covered by the open access publication fund of the University of Freiburg. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="8"/>
<table-count count="3"/>
<page-count count="18"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2018-04-05</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All data analysis and simulation software files are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/jonathanschiefer/connFinder" xlink:type="simple">https://github.com/jonathanschiefer/connFinder</ext-link>. The fast fMRI data files are available from the Open Science Framework at <ext-link ext-link-type="uri" xlink:href="https://osf.io/52mf4/" xlink:type="simple">https://osf.io/52mf4/</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The networks of the brain are key to understanding its function and dysfunction [<xref ref-type="bibr" rid="pcbi.1006056.ref001">1</xref>]. Depending on the methods employed to assess structure and to record activity, networks may be defined at different levels of resolution. Their nodes may be individual neurons, linked by chemical or electrical synapses. Alternatively, nodes may also be conceived as populations of neurons, with links represented by the net effect of all synaptic connections that exist between two populations. In any case, this defines the structural substrate of brain connectivity, representing the physical (causal) basis of neuronal interactions. Nodes in a brain network influence each other by sending signals. For example, the activities of nodes in a network are generally not independent, and neuronal dynamics are characterized by correlations among the nodes involved in the network. This suggests an alternative perspective on active brain networks: Functional connectivity assigns a link to a pair of nodes to the degree to which their activities are correlated. It has been argued that this concept emphasizes connections that “matter”, including the possibility that the same substrate may give rise to different networks, depending on how they are used. As a consequence, functional connectivity and structural connectivity are not equivalent. A well-known phenomenon is that two nodes may be correlated, even if there is no direct anatomical link between them. For example, a shared source of input to both nodes may generate such a correlation, which does not correspond to a direct interaction between the two nodes. Apart from that, correlation is a symmetric relation between two nodes, whereas a physical connection implies a cause-effect relation that is directed. There have, in fact, been multiple attempts to overcome the shortcomings of functional connectivity, especially the lack of directed interaction. The term <italic>effective connectivity</italic> has been suggested for this [<xref ref-type="bibr" rid="pcbi.1006056.ref002">2</xref>]. The idea is to bring the networks, inferred from activity measurements, closer to structural connectivity, which can only be inferred with anatomical methods. The dichotomy between structural and functional aspects of connectivity raises the general question whether it is possible to infer brain networks from recorded activity. We are only beginning to understand the forward link between structural connectivity and functional connectivity. As a consequence, it is possible to compute correlations from connectivity in certain simplified network scenarios [<xref ref-type="bibr" rid="pcbi.1006056.ref003">3</xref>]. The correspondence between connectivity and correlation, however, is not one-to-one. Networks with different connectivity may lead to exactly the same correlations between nodes. As a consequence, the inverse problem of inferring connectivity from correlation is generally ill-defined. As we will demonstrate in this paper, additional assumptions about the connectivity can help to resolve the ambiguity. Specifically, we search for the network with the lowest number of nonzero edges (via <italic>L</italic><sup>1</sup>-minimization) to disambiguate the problem. Structural, functional and effective connectivity are not equally well accessible. Some aspects of the anatomical structure can be assessed <italic>post mortem</italic> by invasive tracing methods, or non-invasively by Diffusion Tensor Imaging, DTI. In contrast, functional connectivity is based on statistical relationships between the activity of neuronal populations and can be easily estimated from recorded signals. For estimating effective connectivity there are methods like Dynamic Causal Modelling, DCM [<xref ref-type="bibr" rid="pcbi.1006056.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1006056.ref005">5</xref>], Granger causality [<xref ref-type="bibr" rid="pcbi.1006056.ref006">6</xref>] and others [<xref ref-type="bibr" rid="pcbi.1006056.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1006056.ref013">13</xref>]. Only few methods to infer effective connectivity, however, can deal with large numbers of nodes (40 or more) based on zero-lag correlation only. However, they are either limited to small networks [<xref ref-type="bibr" rid="pcbi.1006056.ref014">14</xref>], or to directed acyclic graphs [<xref ref-type="bibr" rid="pcbi.1006056.ref015">15</xref>]. Here, we are proposing a new method for the estimation of effective connectivity from population activity in the brain, especially BOLD-related signals. The new method is a variant of the procedure described in [<xref ref-type="bibr" rid="pcbi.1006056.ref016">16</xref>], based on a <italic>L</italic><sup>1</sup>-minimization. For the method proposed here it is sufficient to use zero-lag covariances to estimate directed effective connectivity.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and methods</title>
<sec id="sec003">
<title>Estimation method</title>
<p>The main idea of our estimation method is inspired by the finding, “that the key to determining the direction of the causal relationship between <italic>X</italic> and <italic>Y</italic> lies in ‘the presence of a third variable <italic>Z</italic> that correlates with <italic>Y</italic> but not with X,’ as in the collider <italic>X</italic> → <italic>Y</italic> ← <italic>Z</italic>…” [<xref ref-type="bibr" rid="pcbi.1006056.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1006056.ref018">18</xref>]. Similarly, assuming a linear interaction model, the presence of a collider structure in a network (see <xref ref-type="fig" rid="pcbi.1006056.g001">Fig 1</xref>) produces specific entries in the corresponding inverse covariance (precision) matrix. <xref ref-type="fig" rid="pcbi.1006056.g001">Fig 1</xref> shows a disconnected network in the left column, and a network which induces the same covariance matrix if all links have opposite direction in the middle column. In the latter case an estimation of the direction is impossible, because there is simply no information about it in the covariance matrix. Whenever a collider structure is present, however, the entry in the inverse covariance matrix for the two source nodes (here, 2 and 3) is non-zero. This is due to the fact that in a linear model the entry in the inverse covariance matrix depends not only on the connections of the nodes 2 and 3, but also whether these nodes have a common target. This means the presence of a collider structure allows us to disambiguate the direction of this particular connection.</p>
<fig id="pcbi.1006056.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Collider structures are encoded in the inverse covariance matrix.</title>
<p>Upper row: Three simple network architectures. Lower row: The corresponding inverse covariance matrices, red color represents positive entries, blue color stands for negative ones. In the left and middle column, the entries (2, 3) and (3, 2) are 0. The only difference between the right column and the middle column is that the connection between node 1 and 2 is flipped, such that nodes 1, 2 and 3 form a collider structure. Although there is still only an indirect connection between node 2 and 3, the entry in the corresponding inverse covariance matrix is now non-zero.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.g001" xlink:type="simple"/>
</fig>
<p>We consider here a scenario, where the interaction between nodes is described by a generic linear model. Assuming stationarity, let the neural activity <italic>x</italic>(<italic>t</italic>) be implicitly defined by the consistency equation
<disp-formula id="pcbi.1006056.e001"><alternatives><graphic id="pcbi.1006056.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>*</mml:mo> <mml:mi>x</mml:mi> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>+</mml:mo> <mml:mi>v</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>G</italic>(<italic>t</italic>) is a matrix of causal interaction kernels and <italic>v</italic>(<italic>t</italic>) denotes fluctuating external inputs (“driving noise”). All variables are also listed in <xref ref-type="table" rid="pcbi.1006056.t001">Table 1</xref>. Fourier transformation of <xref ref-type="disp-formula" rid="pcbi.1006056.e001">Eq (1)</xref> yields
<disp-formula id="pcbi.1006056.e002"><alternatives><graphic id="pcbi.1006056.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mover accent="true"><mml:mi>v</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and simple rearrangement leads to
<disp-formula id="pcbi.1006056.e003"><alternatives><graphic id="pcbi.1006056.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mover accent="true"><mml:mi>v</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1006056.e004"><alternatives><graphic id="pcbi.1006056.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mover accent="true"><mml:mi>x</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> denotes the Fourier transform of <italic>x</italic>. The cross spectral density of the signals is then given by
<disp-formula id="pcbi.1006056.e005"><alternatives><graphic id="pcbi.1006056.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e005" xlink:type="simple"/><mml:math display="block" id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mover accent="true"><mml:mi>Z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1006056.e006"><alternatives><graphic id="pcbi.1006056.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:mover accent="true"><mml:mi>Z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the cross-spectral density of the external inputs. It follows
<disp-formula id="pcbi.1006056.e007"><alternatives><graphic id="pcbi.1006056.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>Z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msup><mml:mi>B</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>B</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
with <inline-formula id="pcbi.1006056.e008"><alternatives><graphic id="pcbi.1006056.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:mi>B</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>Z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt> <mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. In our model, we assume that the components of the external fluctuating input are pairwise stochastically independent for all nodes. Then, <inline-formula id="pcbi.1006056.e009"><alternatives><graphic id="pcbi.1006056.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mover accent="true"><mml:mi>Z</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is a diagonal matrix, and we make the additional assumption that <inline-formula id="pcbi.1006056.e010"><alternatives><graphic id="pcbi.1006056.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:mover accent="true"><mml:mi>Z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. For the linear model considered here, there is a relation between covariance and connectivity, which can be exploited for the estimation of connectivity from correlation. In the case <inline-formula id="pcbi.1006056.e011"><alternatives><graphic id="pcbi.1006056.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:mover accent="true"><mml:mi>Z</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> it is given by
<disp-formula id="pcbi.1006056.e012"><alternatives><graphic id="pcbi.1006056.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where the last term contributes the information of the collider structures. If the matrix product <inline-formula id="pcbi.1006056.e013"><alternatives><graphic id="pcbi.1006056.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> has a non-zero off-diagonal entry the corresponding nodes have outgoing connections terminating at the same node, which means these nodes form a collider. It is clear that for any unitary matrix <inline-formula id="pcbi.1006056.e014"><alternatives><graphic id="pcbi.1006056.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:mi>U</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">U</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> the product <italic>UB</italic> is still a solution of <xref ref-type="disp-formula" rid="pcbi.1006056.e007">Eq (2)</xref>, as <inline-formula id="pcbi.1006056.e015"><alternatives><graphic id="pcbi.1006056.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:msup><mml:mi>U</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mi>U</mml:mi> <mml:mo>=</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. We will resolve this ambiguity with an <italic>L</italic><sup>1</sup> minimization which is known to prefer sparse solutions under certain conditions [<xref ref-type="bibr" rid="pcbi.1006056.ref019">19</xref>]. In order to find <italic>G</italic> from a given <italic>C</italic> we first fix an initial matrix <italic>B</italic>, and then search for a unitary matrix <inline-formula id="pcbi.1006056.e016"><alternatives><graphic id="pcbi.1006056.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:mi>U</mml:mi> <mml:mo>∈</mml:mo> <mml:mi mathvariant="script">U</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> such that ‖<italic>UB</italic>‖<sub>1</sub> is minimal, so we are minimizing the function
<disp-formula id="pcbi.1006056.e017"><alternatives><graphic id="pcbi.1006056.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e017" xlink:type="simple"/><mml:math display="block" id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mo>Γ</mml:mo> <mml:mo>:</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="script">U</mml:mi> <mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo> <mml:mo>⟶</mml:mo> <mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mi>U</mml:mi> <mml:mo>⟼</mml:mo> <mml:msub><mml:mrow><mml:mo>∥</mml:mo> <mml:mi>U</mml:mi> <mml:mi>B</mml:mi> <mml:mo>∥</mml:mo></mml:mrow> <mml:mn>1</mml:mn></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula></p>
<table-wrap id="pcbi.1006056.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.t001</object-id>
<label>Table 1</label>
<caption>
<title>Variables used for the estimation method and simulation.</title>
</caption>
<alternatives>
<graphic id="pcbi.1006056.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Variable name</th>
<th align="right">Symbol</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="background-color:#E5E5E5">node activity</td>
<td align="right" style="background-color:#E5E5E5"><italic>x</italic>(<italic>t</italic>)</td>
</tr>
<tr>
<td align="left">network connectivity</td>
<td align="right"><italic>G</italic></td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5">external inputs</td>
<td align="right" style="background-color:#E5E5E5"><italic>v</italic>(<italic>t</italic>)</td>
</tr>
<tr>
<td align="left">cross-spectral density</td>
<td align="right">
<inline-formula id="pcbi.1006056.e018">
<alternatives>
<graphic id="pcbi.1006056.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e018" xlink:type="simple"/>
<mml:math display="inline" id="M18">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>C</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>f</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5">covariance of external input</td>
<td align="right" style="background-color:#E5E5E5">
<inline-formula id="pcbi.1006056.e019">
<alternatives>
<graphic id="pcbi.1006056.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e019" xlink:type="simple"/>
<mml:math display="inline" id="M19">
<mml:mrow>
<mml:mover accent="true">
<mml:mi>Z</mml:mi>
<mml:mo>^</mml:mo>
</mml:mover>
<mml:mrow>
<mml:mo>(</mml:mo>
<mml:mi>f</mml:mi>
<mml:mo>)</mml:mo>
</mml:mrow>
</mml:mrow>
</mml:math>
</alternatives>
</inline-formula>
</td>
</tr>
<tr>
<td align="left">unitary matrix</td>
<td align="right"><italic>U</italic></td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5"><italic>L</italic><sup>1</sup>-norm cost function</td>
<td align="right" style="background-color:#E5E5E5">Γ</td>
</tr>
<tr>
<td align="left">gradient</td>
<td align="right"><italic>d</italic></td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5">initial matrix</td>
<td align="right" style="background-color:#E5E5E5"><italic>B</italic><sub>0</sub></td>
</tr>
<tr>
<td align="left">Wiener process</td>
<td align="right"><italic>w</italic>(<italic>t</italic>)</td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5">stationary covariance matrix</td>
<td align="right" style="background-color:#E5E5E5"><italic>σ</italic></td>
</tr>
<tr>
<td align="left">simulation step</td>
<td align="right">Δ<italic>t</italic></td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5">time constant of activity</td>
<td align="right" style="background-color:#E5E5E5"><italic>τ</italic></td>
</tr>
<tr>
<td align="left">regularisation-controlling parameter for regularized ICOV</td>
<td align="right"><italic>λ</italic></td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
<sec id="sec004">
<title>Gradient descent</title>
<p>To estimate the connectivity matrix from the covariance matrix we use a conjugate gradient descent algorithm similar to [<xref ref-type="bibr" rid="pcbi.1006056.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1006056.ref021">21</xref>] for minimizing the function Γ(<italic>U</italic>) given in <xref ref-type="disp-formula" rid="pcbi.1006056.e017">Eq (3)</xref>, implemented in Python. For details please see <xref ref-type="supplementary-material" rid="pcbi.1006056.s001">S1 Text</xref>. For the gradient
<disp-formula id="pcbi.1006056.e020"><alternatives><graphic id="pcbi.1006056.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>d</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo>Γ</mml:mo> <mml:mo>(</mml:mo> <mml:mi>U</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi>U</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
of the cost function Γ(<italic>U</italic>), <inline-formula id="pcbi.1006056.e021"><alternatives><graphic id="pcbi.1006056.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mi>a</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>d</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>d</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is skew-hermitian, and the matrix exponential of a skew-hermitian matrix is unitary. This means, starting in a point <italic>U</italic><sub>act</sub> and choosing an appropriate step size <italic>δ</italic>, we obtain a point <italic>U</italic><sub>new</sub> = exp(−<italic>δa</italic>)<italic>U</italic><sub>act</sub> with Γ(<italic>U</italic><sub>new</sub>) &lt; Γ(<italic>U</italic><sub>act</sub>). In other words, the new point has a smaller <italic>L</italic><sup>1</sup>-norm than the old one and still satisfies the condition <inline-formula id="pcbi.1006056.e022"><alternatives><graphic id="pcbi.1006056.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mi>B</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:msubsup><mml:mi>U</mml:mi> <mml:mtext>new</mml:mtext> <mml:mo>*</mml:mo></mml:msubsup> <mml:msub><mml:mi>U</mml:mi> <mml:mtext>new</mml:mtext></mml:msub> <mml:mi>B</mml:mi></mml:mrow></mml:math></alternatives></inline-formula>. Iterating this procedure until convergence leads to a point with locally minimal <italic>L</italic><sup>1</sup>-norm. The two conditions for convergence are inspired by [<xref ref-type="bibr" rid="pcbi.1006056.ref021">21</xref>]. The first one is a condition on the norm of the gradient. In each step, it is checked if
<disp-formula id="pcbi.1006056.e023"><alternatives><graphic id="pcbi.1006056.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>∥</mml:mo><mml:mi>d</mml:mi><mml:mo>−</mml:mo><mml:mi>U</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mi>U</mml:mi><mml:msub><mml:mo>∥</mml:mo><mml:mi>F</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true" mathsize="140%"><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>U</mml:mi><mml:msup><mml:mi>d</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mi>U</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt><mml:mo>&lt;</mml:mo><mml:mtext>gtol</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives></disp-formula>
is fulfilled, where ‖…‖<sub><italic>F</italic></sub> is the Frobenius norm and gtol &gt; 0 is the convergence tolerance. As a second (alternative) condition, it is checked whether simultaneously
<disp-formula id="pcbi.1006056.e024"><alternatives><graphic id="pcbi.1006056.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e024" xlink:type="simple"/><mml:math display="block" id="M24"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mrow><mml:mo>∥</mml:mo> <mml:mi>U</mml:mi> <mml:mo>-</mml:mo></mml:mrow> <mml:msub><mml:mi>U</mml:mi> <mml:mtext>old</mml:mtext></mml:msub> <mml:msub><mml:mrow><mml:mo>∥</mml:mo></mml:mrow> <mml:mi>F</mml:mi></mml:msub></mml:mrow> <mml:msqrt><mml:mi>N</mml:mi></mml:msqrt></mml:mfrac> <mml:mo>&lt;</mml:mo> <mml:mtext>xtol</mml:mtext> <mml:mspace width="2.em"/><mml:mtext>and</mml:mtext> <mml:mspace width="2.em"/><mml:mfrac><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mo>Γ</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>U</mml:mi> <mml:mtext>old</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mo>Γ</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>U</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>Γ</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mi>U</mml:mi> <mml:mtext>old</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo> <mml:mo>|</mml:mo></mml:mrow></mml:mfrac> <mml:mo>&lt;</mml:mo> <mml:mtext>ftol</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
are fulfilled. The values used are listed in <xref ref-type="table" rid="pcbi.1006056.t002">Table 2</xref>. Before convergence the cost function typically oscillates around a certain value. To avoid stopping at a random phase of this oscillation, as a final step we apply a line-search, for details see <xref ref-type="supplementary-material" rid="pcbi.1006056.s001">S1 Text</xref>. The described gradient descent algorithm provides an efficient way for minimizing <xref ref-type="disp-formula" rid="pcbi.1006056.e017">Eq (3)</xref>. When calculating the gradient, we neglect the diagonal. Consequently, we also neglect the diagonal of the resulting estimated matrix, so we are not able to study self connections of the nodes.</p>
<table-wrap id="pcbi.1006056.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.t002</object-id>
<label>Table 2</label>
<caption>
<title>Parameter used for estimation.</title>
</caption>
<alternatives>
<graphic id="pcbi.1006056.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="right">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="background-color:#E5E5E5">xtol</td>
<td align="right" style="background-color:#E5E5E5">0.7 ⋅ 10<sup>−2</sup></td>
</tr>
<tr>
<td align="left">ftol</td>
<td align="right">0.7 ⋅ 10<sup>−4</sup></td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5">gtol</td>
<td align="right" style="background-color:#E5E5E5">0.7 ⋅ 10<sup>−2</sup></td>
</tr>
<tr>
<td align="left"><italic>κ</italic></td>
<td align="right">500</td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5"><italic>λ</italic></td>
<td align="right" style="background-color:#E5E5E5">5</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
<sec id="sec005">
<title>Initial condition</title>
<p>As starting condition for the gradient descent we use a matrix <italic>B</italic><sub>0</sub>(<italic>f</italic>) such that
<disp-formula id="pcbi.1006056.e025"><alternatives><graphic id="pcbi.1006056.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi>B</mml:mi> <mml:mn>0</mml:mn> <mml:mo>*</mml:mo></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>B</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>There are many ways to choose a <italic>B</italic><sub>0</sub> with this property, we found the following choice efficient: As <inline-formula id="pcbi.1006056.e026"><alternatives><graphic id="pcbi.1006056.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the cross-spectral density it is positive definite, and so is <inline-formula id="pcbi.1006056.e027"><alternatives><graphic id="pcbi.1006056.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>. Thus, there is exactly one positive definite square root of <inline-formula id="pcbi.1006056.e028"><alternatives><graphic id="pcbi.1006056.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> [<xref ref-type="bibr" rid="pcbi.1006056.ref022">22</xref>] which can be calculated by
<disp-formula id="pcbi.1006056.e029"><alternatives><graphic id="pcbi.1006056.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>B</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:msqrt><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:msqrt> <mml:mo>=</mml:mo> <mml:mi>W</mml:mi> <mml:msqrt><mml:mi>E</mml:mi></mml:msqrt> <mml:msup><mml:mi>W</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
where the columns of <italic>W</italic> are the eigenvectors of <inline-formula id="pcbi.1006056.e030"><alternatives><graphic id="pcbi.1006056.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>, and <italic>E</italic> is the matrix with the corresponding eigenvalues of <inline-formula id="pcbi.1006056.e031"><alternatives><graphic id="pcbi.1006056.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> on the diagonal. Thus we initialize the gradient descent with <inline-formula id="pcbi.1006056.e032"><alternatives><graphic id="pcbi.1006056.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mrow><mml:msub><mml:mi>U</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <italic>B</italic><sub>0</sub> given by <xref ref-type="disp-formula" rid="pcbi.1006056.e029">Eq (4)</xref>.</p>
</sec>
<sec id="sec006">
<title>Step size selection</title>
<p>A critical part of the optimization is the selection of an appropriate step size. If the step size is too large, one might miss the minimum. If the step size is too small, the optimization converges very slowly. For the gradient descent, we use an adaptive scheme inspired by [<xref ref-type="bibr" rid="pcbi.1006056.ref020">20</xref>], where the step-size depends on the largest eigenvalue of the actual gradient: Let <italic>λ</italic><sub>max</sub> be the largest eigenvalue of <italic>d</italic><sub>act</sub>, the step size is given by
<disp-formula id="pcbi.1006056.e033"><alternatives><graphic id="pcbi.1006056.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mtext>act</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:msub><mml:mo>λ</mml:mo><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub></mml:mrow> <mml:mo>|</mml:mo></mml:mrow><mml:mo>·</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></disp-formula>
where <italic>κ</italic> is constant. The intuition behind that, is that smooth cost functions along a geodesic on the unitary manifold are almost periodic. So the step size should be a fraction of the period of this function. This is achieved by the scaling with the largest eigenvalue, which allows us to take a scale-invariant fraction of this period.</p>
</sec>
</sec>
<sec id="sec007">
<title>Validation methods</title>
<sec id="sec008">
<title>Noise-free covariance matrices</title>
<p>We assume that the interactions among neuronal populations can be described by a linear model, see <xref ref-type="disp-formula" rid="pcbi.1006056.e007">Eq (2)</xref> with <inline-formula id="pcbi.1006056.e034"><alternatives><graphic id="pcbi.1006056.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:mi>Z</mml:mi> <mml:mo>=</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. This model allows us to derive a relation between the connectivity matrix of the network <italic>G</italic> and the inverse cross-spectral density matrix <inline-formula id="pcbi.1006056.e035"><alternatives><graphic id="pcbi.1006056.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> of the measured activity
<disp-formula id="pcbi.1006056.e036"><alternatives><graphic id="pcbi.1006056.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e036" xlink:type="simple"/><mml:math display="block" id="M36"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo> <mml:mo>(</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mover accent="true"><mml:mi>G</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula></p>
<p>Given a sampled connectivity matrix <italic>G</italic> we can calculate the inverse covariance matrix directly using <xref ref-type="disp-formula" rid="pcbi.1006056.e036">Eq (5)</xref>. For all simulations, half of the connections were negative (inhibitory) connections, the absolute strength was the same for all connections and 20 repetitions were simulated. As connectivity profiles we used random Erdős-Rényi networks.</p>
</sec>
<sec id="sec009">
<title>Ornstein-Uhlenbeck processes</title>
<p>To validate our inference procedure before applying it to the network inference from measurements of neuronal activity we simulated stationary signals. Since there is no gold-standard for simulations of fMRI data [<xref ref-type="bibr" rid="pcbi.1006056.ref023">23</xref>], we based our simulations on the Ornstein-Uhlenbeck process [<xref ref-type="bibr" rid="pcbi.1006056.ref024">24</xref>], which provides a simple linear model for neural activity.
<disp-formula id="pcbi.1006056.e037"><alternatives><graphic id="pcbi.1006056.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e037" xlink:type="simple"/><mml:math display="block" id="M37"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>d</mml:mi> <mml:mi>x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>A</mml:mi> <mml:mi>x</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>d</mml:mi> <mml:mi>W</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
where <italic>A</italic> is a matrix and <italic>W</italic> a Wiener process. In our applications, we parametrize this matrix as <inline-formula id="pcbi.1006056.e038"><alternatives><graphic id="pcbi.1006056.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:mi>A</mml:mi> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>G</mml:mi> <mml:mo>-</mml:mo> <mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> with real-valued connectivity matrix <italic>G</italic> and time constant <italic>τ</italic>. For this process, it is possible to calculate the stationary covariance matrix Σ from the continuous Lyapunov equation
<disp-formula id="pcbi.1006056.e039"><alternatives><graphic id="pcbi.1006056.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mn mathvariant="double-struck">1</mml:mn> <mml:mo>=</mml:mo> <mml:mi>A</mml:mi> <mml:mo>Σ</mml:mo> <mml:mo>+</mml:mo> <mml:mo>Σ</mml:mo> <mml:msup><mml:mi>A</mml:mi> <mml:mi>T</mml:mi></mml:msup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p>
<p>In fact, we simulated the process in discrete time. In analogy with [<xref ref-type="bibr" rid="pcbi.1006056.ref025">25</xref>] we use a multivariate version of the exact update formula
<disp-formula id="pcbi.1006056.e040"><alternatives><graphic id="pcbi.1006056.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mi>A</mml:mi> <mml:mo>Δ</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mi>x</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>n</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
where <italic>n</italic>(<italic>t</italic>) ∼ <italic>N</italic>(0, Σ) is normally distributed, with Σ being the stationary covariance matrix described above. As a final step, we filter the time series <italic>x</italic>(<italic>t</italic>) with the canonical hemodynamic response function (HRF) [<xref ref-type="bibr" rid="pcbi.1006056.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1006056.ref027">27</xref>]. To match the data obtained in brain scans sampled at a temporal resolution of Δ<italic>t</italic> = 0.1 s, we used random connectivity profiles <italic>G</italic> with a connection probability <italic>p</italic> = 0.1 (Erdős-Rényi model), 50% negative entries, and a spectral radius of <italic>ρ</italic> = 0.3. All parameters used are listed, once more, in <xref ref-type="table" rid="pcbi.1006056.t003">Table 3</xref>. Before calculating the covariance <italic>C</italic>, the data is standardized such that the mean is 0 and the variance is 1 for all components of the time series. We add normally distributed observation noise <italic>u</italic><sub>obs</sub> with a <inline-formula id="pcbi.1006056.e041"><alternatives><graphic id="pcbi.1006056.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:msub><mml:mi>σ</mml:mi> <mml:mtext>obs</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> distribution to the simulated signal. After the simulation we calculated the signal-to-noise ratio according to
<disp-formula id="pcbi.1006056.e042"><alternatives><graphic id="pcbi.1006056.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>SNR</mml:mtext> <mml:mo>=</mml:mo> <mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>X</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mtext>obs</mml:mtext></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1006056.e043"><alternatives><graphic id="pcbi.1006056.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:msubsup><mml:mi>σ</mml:mi> <mml:mi>X</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula> denotes the variance of the signal.</p>
<table-wrap id="pcbi.1006056.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.t003</object-id>
<label>Table 3</label>
<caption>
<title>Parameter used for simulations.</title>
</caption>
<alternatives>
<graphic id="pcbi.1006056.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.t003" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left">Parameter</th>
<th align="right">Value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left" style="background-color:#E5E5E5">repetitions</td>
<td align="right" style="background-color:#E5E5E5">20</td>
</tr>
<tr>
<td align="left">network type</td>
<td align="right">Erdős-Rényi</td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5">N</td>
<td align="right" style="background-color:#E5E5E5">100</td>
</tr>
<tr>
<td align="left">p</td>
<td align="right">0.1</td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5">T</td>
<td align="right" style="background-color:#E5E5E5">350000 s</td>
</tr>
<tr>
<td align="left">dt</td>
<td align="right">0.1 s</td>
</tr>
<tr>
<td align="left" style="background-color:#E5E5E5"><italic>τ</italic></td>
<td align="right" style="background-color:#E5E5E5">0.1 s</td>
</tr>
<tr>
<td align="left"><italic>ρ</italic></td>
<td align="right">0.3</td>
</tr>
</tbody>
</table>
</alternatives>
</table-wrap>
</sec>
</sec>
<sec id="sec010">
<title>Performance measures</title>
<p>When estimating connectivity from simulations with known underlying network structure (ground truth), one can quantify the performance of the estimation. For measuring the accuracy of our estimation we employ three different methods. First, we use the area under the ROC-curve (AUC). The ROC (receiver operating characteristic) curve is obtained as following: For each possible parameter value (in our case the threshold for the existence of a connection), the number of true-positives (TP) and false-positives (FP) is used to calculate the true-positive rate (or recall) TP/(TP+ FN) and the false-positive rate FP/(FP+ TN). The ROC curve is then obtained by plotting the true-positive-rate against the false-positive rate. Secondly, we use the average precision score (PRS) which is the area under the precision-recall curve. This also includes the false-negatives (FN) (precision: <inline-formula id="pcbi.1006056.e044"><alternatives><graphic id="pcbi.1006056.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mfrac><mml:mtext>TP</mml:mtext> <mml:mrow><mml:mtext>TP</mml:mtext> <mml:mo>+</mml:mo> <mml:mtext>FP</mml:mtext></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>). If both AUC and PRS are equal to 1, the connections in the network are perfectly estimated. Sample curves are shown in <xref ref-type="fig" rid="pcbi.1006056.g002">Fig 2D</xref>. Thirdly, we calculate the Pearson Correlation Coefficient (PCC) which in contrast to the measures defined before also take the strength and the sign of the interactions into account. This also means that this measure is less suited to assess whether a connection exists or not. It rather measures whether the estimated connections have the same strength as the original ones. We consider all three performance measures simultaneously to establish the quality of our estimates.</p>
<fig id="pcbi.1006056.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Networks inferred from a simulated Ornstein-Uhlenbeck process.</title>
<p><bold>A</bold> shows the original network. <bold>B</bold> shows the network inferred with our new method from the zero-lag covariances. White and black entries indicate true negative (TN) and true positive (TP) connections, blue and red entries indicate false negative (FN) and false positive (FP) connections, respectively. In this example, the performance measures are AUC = 0.98, PRS = 0.97 and PCC = 0.95. <bold>C</bold> depicts the sample covariance (functional connectivity) matrix directly estimated from the data. In <bold>C</bold>, as a consequence of symmetry, the number of wrongly estimated connections is quite high, the performance measures are AUC = 0.93, PRS = 0.54, and PCC = 0.29. <bold>D</bold> shows the Receiver Operating Characteristic Curve and the Precision Recall Curve for the networks estimated from zero-lag covariance <italic>G</italic><sub>est</sub> in blue/orange and of the functional connectivity <italic>C</italic> in red/cyan. The areas under these curves are the AUC and PRS, respectively.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec011">
<title>Experimental fMRI data</title>
<p>Seven healthy subjects underwent a 20-minute resting-state fMRI experiment on a 3 T Siemens Prisma scanner. The data was acquired using the MREG sequence [<xref ref-type="bibr" rid="pcbi.1006056.ref028">28</xref>], yielding a high temporal resolution (TR = 0.1 s, 12000 time points) that facilitates functional connectivity analyses [<xref ref-type="bibr" rid="pcbi.1006056.ref029">29</xref>]. The other sequence parameters were TE = 36 ms, FA = 25°, 64 × 64 × 50 matrix and 3mm isotropic voxel size. Additionally, cardiac and respiratory signals were recorded with the ECG and abdominal breathing band from the scanner’s physiological monitoring unit. Motion correction was done with FSL and physiological noise correction was performed with RETROICOR [<xref ref-type="bibr" rid="pcbi.1006056.ref030">30</xref>]. Average CSF and white matter signals were regressed out, but no global signal regression was performed. Following image normalization to MNI space, voxels were parcellated according to the AAL atlas (excluding the cerebellum), and the mean activity within each atlas region was calculated. The connectivity was then estimated using zero-lag covariances of the standardized signals.</p>
<sec id="sec012">
<title>Ethics statement</title>
<p>The experiments have been approved by the Ethics Committee of the University Medical Center Freiburg.</p>
</sec>
</sec>
</sec>
<sec id="sec013" sec-type="results">
<title>Results</title>
<sec id="sec014">
<title>Noise-free covariance matrices</title>
<p>Intrinsic properties of our new estimation procedure can be identified by studying the performance of the method for perfectly estimated (noise-free) covariance matrices. This way we address properties that do not depend on any particular feature of the underlying data, and that are not due to the success of the measurement process. In particular, we show for which types of networks our estimation procedure gives good results on technical grounds, with a wide range of networks hopefully including those arising in applications. We used random Erdős-Rényi connectivity profiles for all simulations. The macro-connectivity between neuronal populations has to satisfy certain conditions in order to be tractable by our methods. Two of these conditions concern the dynamic stability of the network and the strength of the interactions. There is a trade-off between the number of physical links and the resulting strength of macro-connections, and the dynamic stability of the network. To study the performance of our method in these various regimes, we separately varied the network size <italic>N</italic>, the connection probability <italic>p</italic>, and the absolute strength of connections |<italic>J</italic>| in the connectivity matrix <italic>G</italic>, while the fraction of inhibitory couplings was kept at 50%. The spectral radius <italic>ρ</italic> of the bulk eigenvalue spectrum is approximately given by
<disp-formula id="pcbi.1006056.e045"><alternatives><graphic id="pcbi.1006056.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e045" xlink:type="simple"/><mml:math display="block" id="M45"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mi>J</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>p</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>N</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula></p>
<p>The default values of the parameters used in our study were <italic>N</italic> = 100, <italic>p</italic> = 0.1 and <italic>ρ</italic> = 0.7, where only one of them at a time was systematically varied. Low values of the spectral radius <italic>ρ</italic> correspond to networks with weak recurrent interaction and high values to networks with strong interaction, respectively. According to the model of network interaction assumed here, the networks need to have a spectral radius <italic>ρ</italic> &gt; 0 for network interaction to be present and <italic>ρ</italic> &lt; 1 for the dynamics to be stable. First, our results in <xref ref-type="fig" rid="pcbi.1006056.g003">Fig 3A</xref> indicate that a certain minimal level of interaction is necessary to be able to estimate the connections reliably. Above a value of <italic>ρ</italic><sub>min</sub> = 0.2, the influence of the spectral radius on the performance of the estimation is weak, but the larger the spectral radius is the better the estimation gets.</p>
<fig id="pcbi.1006056.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Effects of spectral radius <italic>ρ</italic>, connection probability <italic>p</italic> and network size <italic>N</italic>.</title>
<p>Here we consider the case of noise-free covariance matrices, which were created based on the theory of the underlying model. The quantities considered are the area under the ROC curve (AUC; green), the precision recall score (PRS; orange) and the Pearson correlation coefficient (PCC; purple). The shaded areas indicate the mean ± standard deviation computed over 20 realizations. <bold>A</bold> If the network interaction is larger than <italic>ρ</italic><sub>min</sub>, it has relatively little effect on the performance of the estimation. Even in the extreme case, where <italic>ρ</italic> is close to 1, the estimation works well. <bold>B</bold> Performance of the estimation for different sparsity levels, encoded by the respective connection probabilities <italic>p</italic>. As expected, for non-sparse networks the performance of the algorithm degrades dramatically. <bold>C</bold> Performance of the estimation for increasing network size. Our results indicate clearly that bigger networks can be better reconstructed. Applicability may be limited by the numerical effort associated with the optimization. <bold>D</bold> Performance of the estitmation in presence of weak background connections. It is nevertheless possible to infer the skeleton of strong connections with high fidelity.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.g003" xlink:type="simple"/>
</fig>
<p>Secondly, the connection probability of the network influences the quality of the estimation. For all connection probabilities tested here the network size was kept constant at <italic>N</italic> = 100 nodes. The networks were constructed such that the strength |<italic>J</italic>| of all connections was the same and such that the spectral radius <italic>ρ</italic> was constant according to <xref ref-type="disp-formula" rid="pcbi.1006056.e045">Eq (8)</xref>. <xref ref-type="fig" rid="pcbi.1006056.g003">Fig 3B</xref> shows that the estimation works very well for sparse matrices with a connection probability in the range between 5% and 15%. For networks with higher connection probability and equally strong connections, the performance decreases as expected, due to the bias associated with <italic>L</italic><sup>1</sup>-minimization. But even for a connection probability of <italic>p</italic> = 0.21, a fraction of 14.2% of the estimated connections are false negative, and 3.3% are false positive. More than 90% of the correctly estimated connections have the correct sign. In applications, the focus of the estimation often lies on the strongest connections in the network. In networks with a background of weak connections and a sparse skeleton of stronger connections, it is possible to selectively estimate these strong links although, strictly, the assumption of a sparse network is violated. <xref ref-type="fig" rid="pcbi.1006056.g003">Fig 3D</xref> shows the performance of our method for such networks: the networks consist of a skeleton of strong connections with connection probability <italic>p</italic> = 10% and a connection strength derived from <xref ref-type="disp-formula" rid="pcbi.1006056.e045">Eq (8)</xref> for <italic>ρ</italic> = 0.7. Additionally, we created a second network with weaker connections for various connection probabilities <italic>q</italic>. The two networks were combined by adding the connectivity matrices. The connection strength of this weaker connections is also derived from <xref ref-type="disp-formula" rid="pcbi.1006056.e045">Eq (8)</xref>, with a spectral radius of the background network being 20% of the spectral radius of the skeleton network. Then the performance of the estimation is calculated with respect to the skeleton of strong connections.</p>
<p>Thirdly, to be applicable to a broad range of data types, a method of connectivity estimation should perform stable for different network sizes <italic>N</italic>. For most common types of non-invasive recordings of population activity the number of nodes considered is in the range between 30 and 150. It is, of course, possible to consider larger networks, although the estimation becomes computationally more expensive. The runtime of the algorithm for networks with 200 nodes still in the range of seconds on a state-of-the-art desktop computer, but even networks with 1000 nodes or more are tractable. The strength of the connections |<italic>J</italic>| are set such that the spectral radius <italic>ρ</italic> of <italic>G</italic> is constant; the connection probability is constant at <italic>p</italic> = 0.1. <xref ref-type="fig" rid="pcbi.1006056.g003">Fig 3C</xref> shows that our method performs better for bigger networks. We have observed that the <italic>L</italic><sup>1</sup> cost landscape becomes smoother for larger networks.</p>
</sec>
<sec id="sec015">
<title>Ornstein-Uhlenbeck processes as model for BOLD signals</title>
<p>In order to create surrogate data which fit fast fMRI data [<xref ref-type="bibr" rid="pcbi.1006056.ref028">28</xref>], we simulated interacting stochastic processes known as Ornstein-Uhlenbeck processes. In this case, the performance of the network inference depends on how well the inverse covariance matrix, which is the basis of the estimation, can be derived from the data. In addition to finite size effects, we studied the impact of observation noise on the performance, see <xref ref-type="fig" rid="pcbi.1006056.g004">Fig 4</xref>. We used <italic>N</italic> = 100, <italic>p</italic> = 0.1, dt = 0.1 s, <italic>ρ</italic> = 0.74 and <italic>τ</italic> = 0.1 s as default values of the parameters. Generally, it seems natural to use Welch’s method to calculate cross-spectral densities directly, and then to estimate the connectivity for each frequency band separately. For the data described here, however, we can estimate the connectivity from zero-lag sample covariances in the time domain. This is possible when the mass of the covariance function is concentrated very close around lag 0. Then lag 0 is the only one contributing to the integral of the covariance function, which corresponds to the cross-spectral density <inline-formula id="pcbi.1006056.e046"><alternatives><graphic id="pcbi.1006056.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006056.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:mover accent="true"><mml:mi>C</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. As shown in <xref ref-type="fig" rid="pcbi.1006056.g004">Fig 4A</xref>, with noisy data the AUC is still good, but the PRS is lower than in the case, where the covariance is known without error. However, for a signal-to-noise ratio above 1 the performance improves very quickly.</p>
<fig id="pcbi.1006056.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Performance of network inference based on simulated Ornstein-Uhlenbeck processes.</title>
<p>Same colors as in <xref ref-type="fig" rid="pcbi.1006056.g003">Fig 3</xref>. <bold>A</bold> Performance of the estimation when measurement noise is added. <bold>B</bold> Performance of the estimation if only parts of the network are observable. The fraction of observed nodes in a network are indicated on the <italic>x</italic>-axis. The total number of nodes in the network was <italic>N</italic> = 180.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.g004" xlink:type="simple"/>
</fig>
<p>In the case of fMRI usually the whole brain is scanned, and there are no unobserved nodes in the network. However, for other data types (e.g. fNIRS) only parts of the brain can be observed. The question then is, whether this sub-network can nevertheless be reconstructed from the recorded signals. To model this scenario, we took simulated data and removed randomly a certain subset of components from the dataset. The interaction of the removed nodes is then not part of the covariance matrix of the reduced dataset, although the unobserved nodes of course still exert their influence on the observed ones. The performance of the estimation of the sub-network based on the reduced dataset is shown in <xref ref-type="fig" rid="pcbi.1006056.g004">Fig 4B</xref>. Our analysis shows very clearly that the estimation still leads to reasonable results under these conditions. In fact, we can demonstrate that we are inferring causal connections only: For unconnected observed nodes <italic>X</italic>, <italic>Y</italic> and a latent node <italic>L</italic> connected to both <italic>X</italic> and <italic>Y</italic>, our method does not erroneously indicate a link between <italic>X</italic> and <italic>Y</italic>. One key factor for a reliable estimation of the covariance matrix is the amount of data available. This depends on the length of the measurement or simulation, and on the sampling rate. Since fast fMRI time series are obtained by measuring the BOLD response as a proxy of neuronal activity, the time scale of the measured data is relatively slow compared to the time scale of the underlying neuronal activity. <xref ref-type="fig" rid="pcbi.1006056.g005">Fig 5</xref> shows the performance of network inference depending on the amount of data available, and on the time-scale of the neuronal activity. Not surprisingly, the more voluminous the dataset is, the better the estimation gets. On the other hand, it shows that the estimation generally leads to better results for slower temporal dynamics. Also, for data of sufficient length with a fairly good signal-to-noise ratio, the estimation of the connectivity is possible even when only a part of the network is observed. To allow comparison of our new method with other known methods for network inference [<xref ref-type="bibr" rid="pcbi.1006056.ref031">31</xref>–<xref ref-type="bibr" rid="pcbi.1006056.ref033">33</xref>], we applied it to the <italic>NetSim</italic> dataset provided by [<xref ref-type="bibr" rid="pcbi.1006056.ref034">34</xref>]. For details on the result of this, please see Fig A in <xref ref-type="supplementary-material" rid="pcbi.1006056.s001">S1 Text</xref>.</p>
<fig id="pcbi.1006056.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Performance (color coded) of the estimation depending on data length (<italic>y</italic>-axis) and time scale of the activity (<italic>x</italic>-axis).</title>
<p>Both scales are logarithmic. For interpolation a bilinear method is used.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec016">
<title>fMRI data</title>
<p>We estimated connectivity from seven fast fMRI datasets, for details see the methods section. The resulting networks, after a threshold of 10% was applied, consist of 810 connections for each dataset. The threshold of 10% was chosen arbitrarily. In Fig B in <xref ref-type="supplementary-material" rid="pcbi.1006056.s001">S1 Text</xref> we show the histogram of estimated connection strengths for all seven reconstructed networks before thresholding. The threshold is derived from the 10% strongest connections, disregarding their signs. As there is generally no full ground truth for the connectivity inferred from human fMRI recordings available [<xref ref-type="bibr" rid="pcbi.1006056.ref031">31</xref>, <xref ref-type="bibr" rid="pcbi.1006056.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1006056.ref035">35</xref>], we cannot definitely assess the degree to which the result of our inference are correct. We can, however, establish whether they are plausible. One representative connectivity matrix is shown in <xref ref-type="fig" rid="pcbi.1006056.g006">Fig 6</xref>. On average, 34% of the connections were inhibitory, with negligible variability across subjects. Of all connections found, 301(37%) were found in four subjects or more, and 4872 out of 8100 possible connections were absent in all subjects. On average, 245 of the connections were bi-directional and 565 connections were identified only for one direction. In general, close-by areas are more likely to be connected than more distant ones. This fact is (approximately) represented by a concentration of connections along secondary diagonals in the within-hemisphere blocks. Also, there are frequent inter-hemispheric connections between corresponding areas. This fact is represented by the diagonal entries in the across-hemisphere blocks.</p>
<fig id="pcbi.1006056.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Left panel: Directed connectivity estimated with our new method from one sample MREG data set.</title>
<p>Voxels were parceled using the AAL90-atlas. In the top-left block of the connectivity matrix connections within the left hemisphere are shown, in the lower-right block connections within the right hemisphere. The off-diagonal blocks represent the inter-hemispheric connections from the left to the right hemisphere (lower left) and from the right to the left hemisphere (top right). The strength of all connections is color coded, with red representing positive (excitatory) connections and blue representing negative (inhibitory) connections. Only the strongest 10% of connections are shown. Right panel: Functional connectivity matrix derived from the same data.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec017">
<title>Comparison with the Regularized Inverse Covariance (RIC) method</title>
<p>As mentioned above, different heuristics have been suggested to reconstruct networks from neuronal signals. In <xref ref-type="fig" rid="pcbi.1006056.g007">Fig 7</xref> we compare the performance of the new method we propose here and the established method of Regularized Inverse Covariance [<xref ref-type="bibr" rid="pcbi.1006056.ref034">34</xref>], based on the implementation provided at <ext-link ext-link-type="uri" xlink:href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets" xlink:type="simple">https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FSLNets</ext-link>. Our comparison clearly shows that our new method performs significantly better than the Regularized Inverse Covariance method, mainly, because the latter cannot establish the direction of connections. The superior performance of the new method is reflected in higher values for all three performance measures, in particular PRS and PCC. As regularization parameter required by the software toolbox, we used <italic>λ</italic> = 5.</p>
<fig id="pcbi.1006056.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Comparison of performance with the Regularized Inverse Covariance (RIC) method based on numerical simulations of Ornstein-Uhlenbeck processes.</title>
<p>Shown are the results from the reconstruction of 20 different networks with Erdős-Rényi connectivity profiles as described before (cf. <xref ref-type="fig" rid="pcbi.1006056.g002">Fig 2</xref>). AUC, PRS and PCC of our new method and of the RIC method, respectively, are shown side-by-side.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.g007" xlink:type="simple"/>
</fig>
<p>Furthermore, we applied the RIC method on all seven MREG datasets described before. A threshold was applied, such that only the 10% strongest connections are retained. To compare the outcome of both methods, we only condidered the existence of connections (binary and symmetric connectivity) and disregarded weights and directions (weighted nonsymmetric connectivity). One representative example of the comparison of both methods is shown in <xref ref-type="fig" rid="pcbi.1006056.g008">Fig 8</xref>. For RIC, 376 out of 810 possible connections where identified in four subjects or more out of seven, the corresponding number for our method is 392 out of 810 possible connections. If any method produced directed networks with 10% connection probability at random, this would yield an average count of less than 25 connections (3% of 810 connections) that agree for least four out of seven independently generated networks. On average, 290.5 out of 4050 possible connections (undirected) are identified by both methods, 3530.5 connections were found by neither of the methods. This means that both methods agree on 3821 out of 4050 connections on average. The two methods disagreed on the remaining 229 connections.</p>
<fig id="pcbi.1006056.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006056.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Estimated networks for one representative MREG dataset.</title>
<p>The left panel shows the symmetrized network reconstructed with our estimation method, the middle panel shows the network found with the RIC method. The right panel shows the connections which are identified by both methods (EB, black), by none of the methods (EN, white), the connections found only by the RIC (ERIC, blue) and the connections found only by our method, but not by the RIC method (NERIC, red).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.g008" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec018" sec-type="conclusions">
<title>Discussion</title>
<p>With the described method we can estimate directed and signed effective connectivity between neural populations from measured brain signals, based on zero-lag covariances only. To investigate the reliability of our estimated connections we used simulations of Ornstein-Uhlenbeck processes mimicking BOLD-related signals generated by interacting neuronal populations. Our method shows very good performance, if enough data is available and the observation noise is not too strong. Also, even in cases with relatively poor performance (e.g. if the network is too dense) more than 90% of the estimated connections have the correct sign. Applying the method on measured fast fMRI data, we found that about 34% of all identified connections have an inhibitory effect on their respective target population. In general, inhibitory synapses are mainly formed within local populations, and typically do not project to distant targets. An inhibitory connection between populations, however, can also be achieved by excitatory neurons preferentially terminating on the inhibitory neurons of the target region. The comparison with the Regularized Inverse Covariance (RIC) method shows good agreement with regard to the existence of connections. Directions cannot be disambiguated with the RIC method. Our results based on simulated surrogate data reflect what one would expect from the design of an estimation procedure. For large, sparse networks with sufficiently strong interaction, our network estimation procedure works reliably. However, as expected if the network is not sparse, or the time series is too short, the quality of the estimate drops. Nevertheless, in most cases the main interest lies on the strongest connections, which can be reliably estimated with our method even when the network is not sparse. For the experimental data shown, individual connections may be unreliable because of the limited size of the dataset. Also, it is unclear whether the biological network to be analyzed is really sparse, and if the assumption of pairwise independent external input is really justified. On the other hand, due to the higher likelihood of a coupling between close-by areas and between inter-hemispheric counterparts, the resulting network looks plausible. For interpreting individual connections longer recordings would certainly be beneficial. Also, one could then use temporal information from additional frequency bands. Of high interest is also the comparison with structural measures as the ones obtained by diffusion tensor imaging. To the best knowledge of the authors, this is the first time that effective whole-brain connectivity has been estimated from zero-lag covariances. Other methods [<xref ref-type="bibr" rid="pcbi.1006056.ref008">8</xref>] rely on lagged covariances, where the correct lag parameter is critical, and needs to be inferred from the exponential decay of the observed auto-covariances. Also, our proposed method is the only one that can detect directed inhibitory connections on the whole-brain scale. The estimation procedure is fast and easy to apply. As it uses no temporal information, our method can also be applied on other data types that rely on the BOLD effect, e.g. fNIRS, but also data types measuring electrical population activity directly. This makes it a good candidate for, among other things, studying changing connectivity in neurodegenerative diseases, like Parkinson’s or Alzheimer’s.</p>
<sec id="sec019">
<title>Conclusion</title>
<p>With the presented method we can estimate directed effective connectivity on a whole-brain scale. Also we are able to detect whether connections are excitatory or inhibitory. The estimation is possible based on zero-lag covariances, but can also be applied to frequency-resolved cross spectral densities.</p>
</sec>
</sec>
<sec id="sec020">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006056.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006056.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Supporting information.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Uwe Grauer from the Bernstein Center Freiburg as well as Bernd Wiebelt and Michael Janczyk from the Freiburg University Computing Center for their assistance with HPC issues.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006056.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Li</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Razi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Editorial: Mapping Psychopathology with fMRI and Effective Connectivity Analysis</article-title>. <source>Front. Hum. Neurosci</source>. <year>2017</year>; <volume>11</volume>:<fpage>151</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnhum.2017.00151" xlink:type="simple">10.3389/fnhum.2017.00151</ext-link></comment> <object-id pub-id-type="pmid">28408874</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Functional and effective connectivity: a review</article-title>. <source>Brain connectivity</source>. <year>2011</year>;<volume>1</volume>(<issue>1</issue>):<fpage>13</fpage>–<lpage>36</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1089/brain.2011.0008" xlink:type="simple">10.1089/brain.2011.0008</ext-link></comment> <object-id pub-id-type="pmid">22432952</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pernice</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Staude</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Cardanobile</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>How structure determines correlations in neuronal networks</article-title>. <source>PLoS Comput. Biol</source>. <year>2011</year>;<volume>7</volume>,. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002059" xlink:type="simple">10.1371/journal.pcbi.1002059</ext-link></comment> <object-id pub-id-type="pmid">21625580</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Havlicek</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Roebroeck</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Gardumi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ivanov</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Uludag</surname> <given-names>K</given-names></name>. <article-title>On the importance of modeling fMRI transients when estimating e ff ective connectivity: A dynamic causal modeling study using ASL data</article-title>. <source>NeuroImage</source>. <year>2017</year>;<volume>155</volume>(<issue>July 2016</issue>):<fpage>217</fpage>–<lpage>233</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2017.03.017" xlink:type="simple">10.1016/j.neuroimage.2017.03.017</ext-link></comment> <object-id pub-id-type="pmid">28323165</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Analyzing effective connectivity with fMRI</article-title>. <source>Wiley interdisciplinary reviews Cognitive science</source>. <year>2010</year>;<volume>1</volume>(<issue>3</issue>):<fpage>446</fpage>–<lpage>459</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/wcs.58" xlink:type="simple">10.1002/wcs.58</ext-link></comment> <object-id pub-id-type="pmid">21209846</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smith</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Pillai</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Horwitz</surname> <given-names>B</given-names></name>. <article-title>Identification and validation of effective connectivity networks in functional magnetic resonance imaging using switching linear dynamic systems</article-title>. <source>NeuroImage</source>. <year>2010</year>;<volume>52</volume>(<issue>3</issue>):<fpage>1027</fpage>–<lpage>1040</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.11.081" xlink:type="simple">10.1016/j.neuroimage.2009.11.081</ext-link></comment> <object-id pub-id-type="pmid">19969092</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Freestone</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Karoly</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Nešić</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Aram</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Cook</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Grayden</surname> <given-names>DB</given-names></name>. <article-title>Estimation of effective connectivity via data-driven neural modeling</article-title>. <source>Front. Neurosci</source>. <year>2014</year>; <volume>8</volume>:<fpage>383</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnins.2014.00383" xlink:type="simple">10.3389/fnins.2014.00383</ext-link></comment> <object-id pub-id-type="pmid">25506315</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gilson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Moreno-Bote</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ponce-Alvarez</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ritter</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Deco</surname> <given-names>G</given-names></name>. <article-title>Estimation of Directed Effective Connectivity from fMRI Functional Connectivity Hints at Asymmetries of Cortical Connectome</article-title>. <source>PLoS computational biology</source>. <year>2016</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004762" xlink:type="simple">10.1371/journal.pcbi.1004762</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ting</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Seghouane</surname> <given-names>AK</given-names></name>, <name name-style="western"><surname>Member</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Salleh</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Noor</surname> <given-names>AM</given-names></name>. <article-title>Estimating Effective Connectivity from fMRI Data Using Factor-based Subspace Autoregressive Models</article-title>. <source>IEEE Signal Processing Letters</source>. <year>2015</year>;<volume>22</volume>(<issue>6</issue>):<fpage>757</fpage>–<lpage>761</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/LSP.2014.2365634" xlink:type="simple">10.1109/LSP.2014.2365634</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roebroeck</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Formisano</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Goebel</surname> <given-names>R</given-names></name>. <article-title>The identification of interacting networks in the brain using fMRI: Model selection, causality and deconvolution</article-title>. <source>NeuroImage</source>. <year>2011</year>;<volume>58</volume>(<issue>2</issue>):<fpage>296</fpage>–<lpage>302</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.09.036" xlink:type="simple">10.1016/j.neuroimage.2009.09.036</ext-link></comment> <object-id pub-id-type="pmid">19786106</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mehta-Pandejee</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Henderson</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Aquino</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Sarkar</surname> <given-names>S</given-names></name>. <article-title>Inference of direct and multistep effective connectivities from functional connectivity of the brain and of relationships to cortical geometry</article-title>. <source>Journal of Neuroscience Methods</source>. <year>2017</year>;<volume>283</volume>:<fpage>42</fpage>–<lpage>54</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2017.03.014" xlink:type="simple">10.1016/j.jneumeth.2017.03.014</ext-link></comment> <object-id pub-id-type="pmid">28342831</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Marrelec</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Krainik</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Duffau</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Doyon</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Benali</surname> <given-names>H</given-names></name>. <article-title>Partial correlation for functional brain interactivity investigation in functional MRI</article-title>. <source>NeuroImage</source>. <year>2006</year>;<volume>32</volume>:<fpage>228</fpage>–<lpage>237</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2005.12.057" xlink:type="simple">10.1016/j.neuroimage.2005.12.057</ext-link></comment> <object-id pub-id-type="pmid">16777436</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Timme</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Casadiego</surname> <given-names>J</given-names></name>. <article-title>Revealing networks from dynamics: an introduction</article-title>. <source>Journal of Physics A: Mathematical and Theoretical</source>. <year>2014</year>;<volume>47</volume>(<issue>34</issue>):<fpage>343001</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/1751-8113/47/34/343001" xlink:type="simple">10.1088/1751-8113/47/34/343001</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gates</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Molenaar</surname> <given-names>PCM</given-names></name>. <article-title>Group search algorithm recovers effective connectivity maps for individuals in homogeneous and heterogeneous samples</article-title>. <source>NeuroImage</source>. <year>2012</year>; <volume>63</volume>(<issue>1</issue>):<fpage>310</fpage>–<lpage>319</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2012.06.026" xlink:type="simple">10.1016/j.neuroimage.2012.06.026</ext-link></comment> <object-id pub-id-type="pmid">22732562</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ramsey</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Glymour</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Sanchez-Romero</surname></name>, <name name-style="western"><surname>Glymour</surname> <given-names>C</given-names></name>. <article-title>A million variables and more: the Fast Greedy Equivalence Search algorithm for learning high-dimensional graphical causal models, with an application to functional magnetic resonance images</article-title>. <source>International Journal of Data Science and Analytics</source>. <year>2016</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s41060-016-0032-z" xlink:type="simple">10.1007/s41060-016-0032-z</ext-link></comment> <object-id pub-id-type="pmid">28393106</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pernice</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Rotter</surname> <given-names>S</given-names></name>. <article-title>Reconstruction of sparse connectivity in neural networks from spike train covariances</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>. <year>2013</year>;<volume>2013</volume>(<issue>03</issue>):<fpage>P03008</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/1742-5468/2013/03/P03008" xlink:type="simple">10.1088/1742-5468/2013/03/P03008</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref017">
<label>17</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Pearl</surname> <given-names>J</given-names></name>. <source>Causality: Models, Reasoning, and Inference</source>. <publisher-loc>New York, NY, USA</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>; <year>2000</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006056.ref018">
<label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Rebane G, Pearl J. The recovery of causal poly-trees from statistical data. Proceedings of the Third Workshop on Uncertainty in AI; 1987; 222–228</mixed-citation>
</ref>
<ref id="pcbi.1006056.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Candes</surname> <given-names>EJ</given-names></name>, <name name-style="western"><surname>Tao</surname> <given-names>T</given-names></name>. <article-title>Decoding by Linear Programming</article-title>. <source>IEEE Trans Inf Theor</source>. <year>2005</year>;<volume>51</volume>(<issue>12</issue>):<fpage>4203</fpage>–<lpage>4215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TIT.2005.858979" xlink:type="simple">10.1109/TIT.2005.858979</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Abrudan</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Eriksson</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Koivunen</surname> <given-names>V</given-names></name>. <article-title>Conjugate Gradient Algorithm for Optimization Under Unitary Matrix Constraint</article-title>. <source>Signal Processing</source>. <year>2009</year>;<volume>89</volume>:<fpage>1704</fpage>–<lpage>1714</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.sigpro.2009.03.015" xlink:type="simple">10.1016/j.sigpro.2009.03.015</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wen</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Yin</surname> <given-names>W</given-names></name>. <article-title>A feasible method for optimization with orthogonality constraints</article-title>. <source>Mathematical Programming</source>. <year>2013</year>;<volume>142</volume>(<issue>1</issue>):<fpage>397</fpage>–<lpage>434</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10107-012-0584-1" xlink:type="simple">10.1007/s10107-012-0584-1</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref022">
<label>22</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Horn</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>CR</given-names></name>. <source>Matrix Analysis</source>. <publisher-name>Cambridge University Press</publisher-name>, <publisher-loc>Cambridge, MA</publisher-loc>, <year>1985</year></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Welvaert</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rosseel</surname> <given-names>Y</given-names></name>. <article-title>A review of fMRI simulation studies</article-title>. <source>PLoS ONE</source>. <year>2014</year>;<volume>9</volume>(<issue>7</issue>):<fpage>e101953</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0101953" xlink:type="simple">10.1371/journal.pone.0101953</ext-link></comment> <object-id pub-id-type="pmid">25048024</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref024">
<label>24</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Gardiner</surname> <given-names>CW</given-names></name>. <source>Handbook of stochastic methods for physics, chemistry and the natural sciences. vol. 13 of Springer Series in Synergetics</source>. <edition>3rd ed</edition>. <publisher-loc>Berlin</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>; <year>2004</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006056.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gillespie</surname> <given-names>DT</given-names></name>. <article-title>Exact numerical simulation of the Ornstein-Uhlenbeck process and its integral</article-title>. <source>Phys Rev E</source>. <year>1996</year>;<volume>54</volume>:<fpage>2084</fpage>–<lpage>2091</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevE.54.2084" xlink:type="simple">10.1103/PhysRevE.54.2084</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Fletcher</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Josephs</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Holmes</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rugg</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>R</given-names></name>. <article-title>Event-Related fMRI: Characterizing Differential Responses</article-title>. <source>NeuroImage</source>. <year>1998</year>;<volume>7</volume>(<issue>1</issue>):<fpage>30</fpage>–<lpage>40</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.1997.0306" xlink:type="simple">10.1006/nimg.1997.0306</ext-link></comment> <object-id pub-id-type="pmid">9500830</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Glover</surname> <given-names>GH</given-names></name>. <article-title>Deconvolution of Impulse Response in Event-Related BOLD fMRI1</article-title>. <source>NeuroImage</source>. <year>1999</year>;<volume>9</volume>(<issue>4</issue>):<fpage>416</fpage>–<lpage>429</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1006/nimg.1998.0419" xlink:type="simple">10.1006/nimg.1998.0419</ext-link></comment> <object-id pub-id-type="pmid">10191170</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Assländer</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zahneisen</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Hugger</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Reisert</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>LeVan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Hennig</surname> <given-names>J</given-names></name>. <article-title>Single shot whole brain imaging using spherical stack of spirals trajectories</article-title>. <source>NeuroImage</source>. <year>2013</year>;<volume>73</volume>:<fpage>59</fpage>–<lpage>70</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.01.065" xlink:type="simple">10.1016/j.neuroimage.2013.01.065</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>LeVan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Akin</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Hennig</surname> <given-names>J</given-names></name>. <article-title>Fast imaging for mapping dynamic networks</article-title>. <source>NeuroImage</source>. <year>2017</year> <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2017.08.029" xlink:type="simple">10.1016/j.neuroimage.2017.08.029</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Glover</surname> <given-names>GH</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>TQ</given-names></name>, <name name-style="western"><surname>Ress</surname> <given-names>D</given-names></name>. <article-title>Image-based method for retrospective correction of physiological motion effects in fMRI: RETROICOR</article-title>. <source>Magnetic Resonance in Medicine</source>. <year>2000</year>;<volume>44</volume>(<issue>1</issue>):<fpage>162</fpage>–<lpage>167</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/1522-2594(200007)44:1%3C162::AID-MRM23%3E3.0.CO;2-E" xlink:type="simple">10.1002/1522-2594(200007)44:1%3C162::AID-MRM23%3E3.0.CO;2-E</ext-link></comment> <object-id pub-id-type="pmid">10893535</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nie</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Matthews</surname> <given-names>PM</given-names></name>, <name name-style="western"><surname>Xu</surname> <given-names>ZW</given-names></name>, and <name name-style="western"><surname>Guo</surname> <given-names>YK</given-names></name>. <article-title>Inferring functional connectivity in fMRI using minimum partial correlation</article-title>. <source>International Journal of Automation and Computing</source>, <volume>14</volume>:<fpage>371</fpage>–<lpage>385</lpage>, <year>2017</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s11633-017-1084-9" xlink:type="simple">10.1007/s11633-017-1084-9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ryali</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Supekar</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Tu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kochalka</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cai</surname> <given-names>W</given-names></name> and <name name-style="western"><surname>Menon</surname> <given-names>V</given-names></name>. <article-title>Multivariate dynamical systems-based estimation of causal brain interactions in fMRI: Group-level validation using benchmark data, neurophysiological models and human connectome project data</article-title>. <source>Journal of Neuroscience Methods</source>, <volume>268</volume>:<fpage>142</fpage>–<lpage>153</lpage>, <year>2016</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2016.03.010" xlink:type="simple">10.1016/j.jneumeth.2016.03.010</ext-link></comment> <object-id pub-id-type="pmid">27015792</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hyvärinen</surname> <given-names>A</given-names></name> and <name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>. <article-title>Pairwise likelihood ratios for estimation of non-gaussian structural equation models</article-title>. <source>Journal of Machine Learning Research</source>, <volume>14</volume>(<issue>1</issue>):<fpage>111</fpage>–<lpage>152</lpage>, <year>2013</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006056.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smith</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KL</given-names></name>, <name name-style="western"><surname>Salimi-Khorshidi</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Webster</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Beckmann</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Nichols</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Ramsey</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Woolrich</surname> <given-names>MW</given-names></name>. <article-title>Network modelling methods for fMRI</article-title>. <source>NeuroImage</source> <year>2011</year>;<volume>54</volume>;<issue>2</issue>:<fpage>875</fpage>–<lpage>891</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2010.08.063" xlink:type="simple">10.1016/j.neuroimage.2010.08.063</ext-link></comment> <object-id pub-id-type="pmid">20817103</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006056.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zaghlool</surname> <given-names>SB</given-names></name> and <name name-style="western"><surname>Wyatt</surname> <given-names>CL</given-names></name>. <article-title>Missing data estimation in fMRI dynamic causal modeling</article-title>. <source>Frontiers in Neuroscience</source>, <volume>8</volume>:<fpage>191</fpage>, <year>2014</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnins.2014.00191" xlink:type="simple">10.3389/fnins.2014.00191</ext-link></comment> <object-id pub-id-type="pmid">25071435</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
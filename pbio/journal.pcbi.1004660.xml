<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004660</article-id>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-00836</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Spontaneous Decoding of the Timing and Content of Human Object Perception from Cortical Surface Recordings Reveals Complementary Information in the Event-Related Potential and Broadband Spectral Change</article-title>
<alt-title alt-title-type="running-head">Spontaneous Decoding of Human Object Perception</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Miller</surname>
<given-names>Kai J.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Schalk</surname>
<given-names>Gerwin</given-names>
</name>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Hermes</surname>
<given-names>Dora</given-names>
</name>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Ojemann</surname>
<given-names>Jeffrey G.</given-names>
</name>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
<xref ref-type="aff" rid="aff007"><sup>7</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Rao</surname>
<given-names>Rajesh P. N.</given-names>
</name>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff007"><sup>7</sup></xref>
<xref ref-type="aff" rid="aff008"><sup>8</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Departments of Neurosurgery, Stanford University, Stanford, California, United States of America</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>NASA—Johnson Space Center, Houston, Texas, United States of America</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>Program in Neurobiology and Behavior, University of Washington, Seattle, Washington, United States of America</addr-line></aff>
<aff id="aff004"><label>4</label> <addr-line>National Center for Adaptive Neurotechnologies, Wadsworth Center, New York State Department of Health, Albany, New York, United States of America</addr-line></aff>
<aff id="aff005"><label>5</label> <addr-line>Psychology, Stanford University, Stanford, California, United States of America</addr-line></aff>
<aff id="aff006"><label>6</label> <addr-line>Department of Neurological Surgery, University of Washington, Seattle, Washington, United States of America</addr-line></aff>
<aff id="aff007"><label>7</label> <addr-line>Center for Sensorimotor Neural Engineering, University of Washington, Seattle, Washington, United States of America</addr-line></aff>
<aff id="aff008"><label>8</label> <addr-line>Computer Science and Engineering, University of Washington, Seattle, Washington, United States of America</addr-line></aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Sporns</surname>
<given-names>Olaf</given-names>
</name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1"><addr-line>Indiana University, UNITED STATES</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: KJM JGO RPNR. Performed the experiments: KJM JGO. Analyzed the data: KJM DH. Contributed reagents/materials/analysis tools: KJM. Wrote the paper: KJM GS DH JGO RPNR.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">kai.miller@stanford.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<day>28</day>
<month>1</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>1</month>
<year>2016</year>
</pub-date>
<volume>12</volume>
<issue>1</issue>
<elocation-id>e1004660</elocation-id>
<history>
<date date-type="received">
<day>26</day>
<month>5</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>17</day>
<month>11</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Miller et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004660"/>
<abstract>
<p>The link between object perception and neural activity in visual cortical areas is a problem of fundamental importance in neuroscience. Here we show that electrical potentials from the ventral temporal cortical surface in humans contain sufficient information for spontaneous and near-instantaneous identification of a subject’s perceptual state. Electrocorticographic (ECoG) arrays were placed on the subtemporal cortical surface of seven epilepsy patients. Grayscale images of faces and houses were displayed rapidly in random sequence. We developed a template projection approach to decode the continuous ECoG data stream spontaneously, predicting the occurrence, timing and type of visual stimulus. In this setting, we evaluated the independent and joint use of two well-studied features of brain signals, broadband changes in the frequency power spectrum of the potential and deflections in the raw potential trace (event-related potential; ERP). Our ability to predict both the timing of stimulus onset and the type of image was best when we used a combination of both the broadband response and ERP, suggesting that they capture different and complementary aspects of the subject’s perceptual state. Specifically, we were able to predict the timing and type of 96% of all stimuli, with less than 5% false positive rate and a ~20ms error in timing.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>We describe a new technique for decoding perception from electrical potentials measured from the human brain surface. All previous attempts have focused on the identification of classes of stimuli or behavior where the timing of experimental parameters is known or pre- designated. However, real world experience is spontaneous, and to this end we describe an experiment predicting the occurrence, timing, and types of visual stimuli perceived by human subjects from the continuous brain signal. In this experiment, human patients with electrodes implanted on the underside of the temporal lobe were shown pictures of faces and houses in rapid sequence. We developed a novel template-projection method for analyzing the electrical potentials, where, for the first time, broadband spectral changes and raw potential changes could be contrasted as well as combined. Our analyses revealed that they carry different physiological information, and, when used together, allow for unprecedented accuracy and precision in decoding human perception.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by National Aeronautics and Space Administration Graduate Student Research Program (KJM), the NIH (R01-NS065186 (KJM, JGO, RPNR), T32-EY20485 (DH), R01-EB00856 (GS) and P41-EB018783 (GS)), the NSF (EEC-1028725 (RPNR)), and the US Army Research Office (W911NF-14-1-0440 (GS)). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="0"/>
<page-count count="20"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The authors confirm that all data underlying the findings are fully available without restriction. All data and analyses are available at <ext-link ext-link-type="uri" xlink:href="https://purl.stanford.edu/xd109qh3109" xlink:type="simple">https://purl.stanford.edu/xd109qh3109</ext-link></meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>How does a two-dimensional pattern of pixels measured by our retina get transformed into the percept of a friend’s face or a famous landmark? It is known that the ventral temporal cortex represents different classes of complex visual stimuli within distinct regions. For example, category-selective areas have been established unambiguously at scale of several millimeters using functional imaging and macroscale field potentials [<xref ref-type="bibr" rid="pcbi.1004660.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1004660.ref004">4</xref>]. Similar results have also been demonstrated at the single-unit level in epileptic human patients [<xref ref-type="bibr" rid="pcbi.1004660.ref005">5</xref>] and non-human primates [<xref ref-type="bibr" rid="pcbi.1004660.ref006">6</xref>]. More recently, high frequency electrocorticographic (ECoG) changes from these same ventral temporal regions have been shown to increase while viewing images of faces, places, and other objects [<xref ref-type="bibr" rid="pcbi.1004660.ref007">7</xref>–<xref ref-type="bibr" rid="pcbi.1004660.ref010">10</xref>]. However, rather than reflecting a discrete range of frequencies, &gt;40Hz ECoG changes have been shown to instead be a reflection of broadband fluctuations across the entire frequency domain [<xref ref-type="bibr" rid="pcbi.1004660.ref011">11</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref012">12</xref>], and these broadband changes show robust increases across ventral temporal cortex during object perception [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>].</p>
<p>Object-category specific responses in inferotemporal cortex were initially identified using event-related potentials (ERPs) in ECoG [<xref ref-type="bibr" rid="pcbi.1004660.ref014">14</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref015">15</xref>] or functional magnetic resonance imaging (fMRI) [<xref ref-type="bibr" rid="pcbi.1004660.ref001">1</xref>–<xref ref-type="bibr" rid="pcbi.1004660.ref004">4</xref>] although little spatial overlap was found between the ERP and the fMRI response [<xref ref-type="bibr" rid="pcbi.1004660.ref016">16</xref>]. In contrast, increases in high-frequency broadband power in cortical surface potentials recorded using ECoG matched well with the category-specific fMRI responses in the inferior temporal cortex [<xref ref-type="bibr" rid="pcbi.1004660.ref017">17</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref018">18</xref>]. The ERP and broadband signals show distinct, and partially overlapping, responses to faces [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref019">19</xref>] (<xref ref-type="fig" rid="pcbi.1004660.g001">Fig 1</xref>), but it is unclear whether the information content is itself distinct between the two. While both the ERP and the raw ECoG potential have previously been used to classify object categories [<xref ref-type="bibr" rid="pcbi.1004660.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1004660.ref022">22</xref>], these studies required knowledge about the time of stimulus onset, rather than determining them spontaneously. Furthermore, the ability of the algorithms to establish object category from neural data was well below that of human performance (both in terms of accuracy and temporal fidelity).</p>
<fig id="pcbi.1004660.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004660.g001</object-id>
<label>Fig 1</label>
<caption>
<title>The basic face and house discrimination task, and the polymorphic nature of the electrophysiologic response.</title>
<p><bold>(A)</bold> Subdural electrocorticographic (ECoG) electrode strips were placed through burrholes in the skull onto ventral temporal brain surface. 4 adjacent sites are shown for subject 1. <bold>(B)</bold> Simple luminance- and contrast-matched grayscale faces and houses that were displayed in random order for 400ms each, with 400ms blank gray screen inter-stimulus interval between each picture. Subjects were asked to report a simple target (an upside-down house, which was rejected from analyses). From the raw potential, the time course of broadband spectral change was extracted from each brain site (here sites 1&amp;4 from (A)). Blue = faces; pink = houses. <bold>(C)</bold> The averaged raw potential (ERP) following face (blue) and house (pink) stimuli for the 4 sites in (A). <bold>(D)</bold> The averaged broadband power following different stimuli (ERBB–a reflection of averaged neuronal firing rate), from sites 1–4 in (A). <bold>(E-G)</bold> ERBB and ERP for 2 sites over fusiform gyrus in subjects 2–4. Note that the responses are highly polymorphic for the event-related potentials, and that there are ERP face-selective sites that do not have the classic N200 shape. As seen for site 2 in Subject 4, the classic N200, when present, does not guarantee face-selectivity in the ERBB.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.g001" xlink:type="simple"/>
</fig>
<p>A significant methodological obstacle to this type of macroscale physiology has been the difficulty interpreting heterogeneity in response morphologies. As illustrated in <xref ref-type="fig" rid="pcbi.1004660.g001">Fig 1</xref>, face-selective ERPs may have wide structural variation, with “peaks” and “troughs” that are very different in shape, latency, and duration, even when measured from brain sites separated by only 1cm. It remains unclear what the ERP shape actually corresponds to. Furthermore, methodology has not previously been developed to naively place morphologically-diverse ERPs in a common feature space. In contrast, broadband spectral changes in the ECoG signal have been shown to correlate with neuronal firing rate [<xref ref-type="bibr" rid="pcbi.1004660.ref023">23</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref024">24</xref>], although it has been unclear how ERPs relate to this, or what the best way to attempt such a comparison is [<xref ref-type="bibr" rid="pcbi.1004660.ref019">19</xref>]. Our work begins by describing a template-projection technique, where templates of averaged raw potentials (ERPs) and broadband changes (ERBB) from a training period are projected into the data from a testing period. This places ERP and ERBB features from different brain sites into a common feature space, where they can be directly compared with one another, and used together for decoding brain function.</p>
<p>To date, decoding of perceptual content has relied upon designated information about external stimuli, where the frequency of occurance and precise timing are known to the decoder. We propose that in addition to identifying the perceptual content (e.g. image type), decoding of the brain state should evolve to spontaneously identify whether a perceptual event has happened from the datastream, and, if so, predict the timing as accurately as possible. We denote this practice as “spontaneous decoding”.</p>
<p>Here we show that the ECoG signal contains sufficient information to allow near-instantaneous identification of object categories with an accuracy comparable to that of human behavioral performance. Our experiments measured ECoG recordings from several inferior temporal visual areas simultaneously while subjects viewed randomly interleaved images of faces or houses. We achieved the best results by combining broadband changes with raw potential changes (rather than with either independently), using a template projection approach. This shows that the two types of signals capture complementary aspects of the physiology reflecting a human subject’s perceptual state. With this combination, we were able to predict 96% of all stimuli correctly as face, house, or neither, with only ~20 ms error in timing.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec003">
<title>Ethics statement</title>
<p>All patients participated in a purely voluntary manner, after providing informed written consent, under experimental protocols approved by the Institutional Review Board of the University of Washington (#12193). All patient data was anonymized according to IRB protocol, in accordance with HIPAA mandate. A portion of this data appears in a different context in [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>]. All data and analyses are publically available at <ext-link ext-link-type="uri" xlink:href="http://purl.stanford.edu/xd109qh3109" xlink:type="simple">http://purl.stanford.edu/xd109qh3109</ext-link>.</p>
</sec>
<sec id="sec004">
<title>Subjects and recordings</title>
<p>All 7 subjects in the study were epileptic patients (<xref ref-type="supplementary-material" rid="pcbi.1004660.s001">S1 Table</xref>) at Harborview Hospital in Seattle, WA. Subdural grids and strips of platinum electrodes (Ad-Tech, Racine, WI) were clinically placed over frontal, parietal, temporal, and occipital cortex for extended clinical monitoring and localization of seizure foci. Lateral frontoparietal electrode grids were discarded from analysis, and only strip electrodes were further considered. The electrodes had 4 mm diameter (2.3 mm exposed), 1 cm inter-electrode distance, and were embedded in silastic. Electrode locations relative to gyral surface anatomy were determined by projection of the post-implant CT to the pre-operative axial T1 using normalized mutual information in SPM, and the CTMR package, with Freesurfer-extracted cortical surface mesh reconstructions [<xref ref-type="bibr" rid="pcbi.1004660.ref025">25</xref>–<xref ref-type="bibr" rid="pcbi.1004660.ref028">28</xref>]. When the MRI or CT was of insufficient quality, hybrid techniques were used [<xref ref-type="bibr" rid="pcbi.1004660.ref029">29</xref>].</p>
<p>Experiments were performed at the bedside, using Synamps2 amplifiers (Neuroscan, El Paso, TX) in parallel with clinical recording. Stimuli were presented with a monitor at the bedside using the general-purpose BCI2000 stimulus and acquisition program [<xref ref-type="bibr" rid="pcbi.1004660.ref030">30</xref>]. The electrocorticographic potentials were measured with respect to a scalp reference and ground, subjected to an instrument-imposed bandpass filter from 0.15 to 200 Hz, and sampled at 1000 Hz.</p>
<p>To reduce common artifacts, the potential, <inline-formula id="pcbi.1004660.e001"><alternatives><graphic id="pcbi.1004660.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>n</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, measured at time <italic>t</italic> in each electrode <italic>n</italic>, was re-referenced with respect to the common average of all <italic>N</italic> electrodes, <inline-formula id="pcbi.1004660.e002"><alternatives><graphic id="pcbi.1004660.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>V</mml:mi><mml:mi>n</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>. Electrodes with significant artifact or epileptiform activity were rejected prior to common averaging. There was no rejection of epochs of time within the data. Ambient line noise was rejected by notch filtering between 58–62 Hz using a 3<sup>rd</sup>-order Butterworth filter [<xref ref-type="bibr" rid="pcbi.1004660.ref031">31</xref>].</p>
</sec>
<sec id="sec005">
<title>Face-House discrimination task</title>
<p>Subjects performed a basic face and house stimulus discrimination task. They were presented with grayscale pictures of faces and houses (luminance- and contrast-matched) that were displayed in random order for 400ms each, with 400ms blank screen inter-stimulus interval (ISI) between the pictures. The 10cm-wide pictures were displayed at ~1m from the patients while they were seated at the bedside (<xref ref-type="fig" rid="pcbi.1004660.g001">Fig 1</xref>). There were 3 experimental runs with each patient, with 50 house pictures and 50 face pictures in each run (for a total of 300 stimuli). In order to maintain fixation on the stimuli, patients were asked to verbally report a simple target (an upside-down house), which appeared once during each run (1/100 stimuli). There were few errors in reporting the upside-down target house in any run (approximately 2–3 across all 21 experimental runs).</p>
</sec>
<sec id="sec006">
<title>Power spectral analysis, and decoupling the dynamic power spectrum to obtain the timecourse of broadband spectral change (fully detailed in the Supplemental material, <xref ref-type="supplementary-material" rid="pcbi.1004660.s004">S1 Text</xref> and <xref ref-type="supplementary-material" rid="pcbi.1004660.s005">S2 Text</xref>)</title>
<p>Following previously described methodology [<xref ref-type="bibr" rid="pcbi.1004660.ref011">11</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref032">32</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref033">33</xref>], we perform discrete estimates of the windowed power spectrum, as well as a time-frequency approximation of the dynamic power spectrum from <italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>). We then perform a “decoupling process” to identify underlying motifs in power-spectral change, isolating the timecourse of broadband spectral change, <italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>). This process was originally described and illustrated in full detail for ECoG recordings from motor cortex [<xref ref-type="bibr" rid="pcbi.1004660.ref011">11</xref>], and later illustrated specifically for this face-house context [<xref ref-type="bibr" rid="pcbi.1004660.ref012">12</xref>]. Broadband changes have been shown to robustly characterize the magnitude and latency of cortical dynamics from ventral temporal cortex, in single trials, during this face and house viewing experiment [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>]. Generically, the broadband power time course is meant to function as a time-varying estimate of changes in a multiplicative factor of the population firing rate [<xref ref-type="bibr" rid="pcbi.1004660.ref011">11</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref024">24</xref>].</p>
</sec>
<sec id="sec007">
<title>Decoding</title>
<sec id="sec008">
<title>Cross-validation</title>
<p>Prior to further analysis, the data were divided into thirds temporally (e.g. divided into experimental runs). Subsequent analyses were then performed in a 3-fold fashion. In each cross-fold, two thirds (two runs) of the data were assigned to a <bold>“training” set</bold>, and the remaining third was assigned to a <bold>“testing” set</bold> (In bold throughout for emphasis). In this way, all data could be used for both testing as well as training, but never at the same time (to maximize use without “double-dipping”, which is simultaneously testing and training on the same data). However, the spectral decoupling process was performed only once, across all data, rather than cross-folded (the decoupling process is ignorant of class-labels, or timepoint selection).</p>
</sec>
<sec id="sec009">
<title>Template projection technique</title>
<p><italic>Stimulus triggered averaged raw potential and broadband template</italic>: In each electrode <italic>n</italic>, stimulus-triggered averages of the training data were obtained for the common-averaged electric potential for the face (<italic>S</italic> → <italic>F</italic>) and house (<italic>S</italic> → <italic>H</italic>) stimuli independently (<inline-formula id="pcbi.1004660.e003"><alternatives><graphic id="pcbi.1004660.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> denotes the <italic>k</italic><sup><italic>th</italic></sup> of <italic>N</italic><sub><italic>S</italic></sub> total instances of stimulus type <italic>S</italic> in the training set):
<disp-formula id="pcbi.1004660.e004">
<alternatives>
<graphic id="pcbi.1004660.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e004" xlink:type="simple"/>
<mml:math display="block" id="M4">
<mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>〈</mml:mi><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>〉</mml:mi></mml:mrow></mml:mrow><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>This quantity is only calculated on the peri-stimulus interval −199 &lt; <italic>t</italic>' ≤ 400 ms (where <italic>t</italic>' denotes time with respect to stimulus start). It is then re-centered by subtracting the average potential peri-stimulus baseline on the interval −199 &lt; <italic>t</italic>' ≤ 50, (50ms post-stimulus is chosen to correspond with ERP and broadband ECoG latency to primary visual cortex [<xref ref-type="bibr" rid="pcbi.1004660.ref033">33</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref034">34</xref>]) to obtain 〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub>:
<disp-formula id="pcbi.1004660.e005">
<alternatives>
<graphic id="pcbi.1004660.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>〈</mml:mi><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>〉</mml:mi></mml:mrow></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mrow><mml:mi>〈</mml:mi><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>〉</mml:mi></mml:mrow></mml:mrow><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>250</mml:mn></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi>"</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>199</mml:mn></mml:mrow><mml:mrow><mml:mn>50</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msubsup><mml:mrow><mml:mrow><mml:mi>〈</mml:mi><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mi>"</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>〉</mml:mi></mml:mrow></mml:mrow><mml:mi>S</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mstyle></mml:mrow>
</mml:math>
</alternatives>
</disp-formula></p>
<p>We perform the same averaging over the <bold>training data</bold> for the broadband signal to obtain 〈<italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub>. Examples of these response templates, 〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> and 〈<italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> are illustrated throughout the manuscript.</p>
</sec>
<sec id="sec010">
<title>Projection of templates into pre-defined times of stimuli onset (illustrated in <xref ref-type="fig" rid="pcbi.1004660.g002">Fig 2</xref>)</title>
<p>〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> and 〈<italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> were generated from the <bold>training period</bold>.</p>
<fig id="pcbi.1004660.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004660.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Decoding the stimulus class in single trials when the onset of a stimulus is known, subject 3.</title>
<p><bold>(A)</bold> Squared cross-correlation values at each electrode. <bold>Training feature points</bold> were obtained by back-projecting the event triggered broadband, 〈<italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>F</italic></sub> (see <xref ref-type="sec" rid="sec002">Methods</xref>), into the training data and comparing projected face, <inline-formula id="pcbi.1004660.e006"><alternatives><graphic id="pcbi.1004660.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>→</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and inter-stimulus interval (ISI), <inline-formula id="pcbi.1004660.e007"><alternatives><graphic id="pcbi.1004660.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>→</mml:mo><mml:mi>o</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, points. These <inline-formula id="pcbi.1004660.e008"><alternatives><graphic id="pcbi.1004660.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> values are scaled by color, and plotted on an axial MRI slice with scaling shown in the colored bar beneath. The electrodes meeting acceptance criteria <inline-formula id="pcbi.1004660.e009"><alternatives><graphic id="pcbi.1004660.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&gt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> were selected as features for classification for the face template. <bold>(B)</bold> As in (A), but for house stimuli from the training period. <bold>(C)</bold> Event-triggered broadband templates from the training period for face, 〈<italic>B</italic><sub>1</sub>(<italic>t</italic>')〉<sub><italic>F</italic></sub>, and house, 〈<italic>B</italic><sub>1</sub>(<italic>t</italic>')〉<sub><italic>H</italic></sub> stimuli, from the electrode noted with a green arrow in (A-B). <bold>(D)</bold> As in (C), but from the electrode noted with an orange arrow. (<bold>E)</bold> Projection of event-triggered face template from (C) into <bold>testing data</bold>: The top black trace shows a portion of the broadband time course from the electrode noted with a green arrow, during the testing period, <italic>B</italic><sub>1</sub>(<italic>t</italic>). The 〈<italic>B</italic><sub>1</sub>(<italic>t</italic>')〉<sub><italic>F</italic></sub> face template is shown in light blue at each stimulus time, irrespective of class, at event testing times <italic>τ</italic><sub><italic>p</italic></sub>. The result of projecting the face template 〈<italic>B</italic><sub>1</sub>(<italic>t</italic>')〉<sub><italic>F</italic></sub> to <italic>B</italic><sub>1</sub>(<italic>t</italic>) is shown in the green background trace, <inline-formula id="pcbi.1004660.e010"><alternatives><graphic id="pcbi.1004660.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, with testing points at defined face stimulus times, <inline-formula id="pcbi.1004660.e011"><alternatives><graphic id="pcbi.1004660.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>→</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, shown with blue circles, and defined house stimulus times, <inline-formula id="pcbi.1004660.e012"><alternatives><graphic id="pcbi.1004660.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>→</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, shown with red circles. <bold>(F)</bold> As with (E), but for the orange-arrow electrode, <italic>B</italic><sub>2</sub>(<italic>t</italic>), and using the house template from (D), 〈<italic>B</italic><sub>2</sub>(<italic>t</italic>')〉<sub><italic>H</italic></sub>. <bold>(G)</bold> The subspace <inline-formula id="pcbi.1004660.e013"><alternatives><graphic id="pcbi.1004660.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> vs <inline-formula id="pcbi.1004660.e014"><alternatives><graphic id="pcbi.1004660.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, is used to illustrate discrete classification approach. Here the back-projected training points <inline-formula id="pcbi.1004660.e015"><alternatives><graphic id="pcbi.1004660.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> are shown with dots (blue for <italic>q</italic> → <italic>F</italic> and red for <italic>q</italic> → <italic>H</italic>), along with the testing feature points <inline-formula id="pcbi.1004660.e016"><alternatives><graphic id="pcbi.1004660.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> shown with circles. One may see that a simple decision line (purple) in this subspace would result in only 1 error.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.g002" xlink:type="simple"/>
</fig>
<p><bold>Training feature points</bold> were obtained by <bold>back-projecting</bold> 〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> and 〈<italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> into the <bold>training period</bold> to obtain sets <inline-formula id="pcbi.1004660.e017"><alternatives><graphic id="pcbi.1004660.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004660.e018"><alternatives><graphic id="pcbi.1004660.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for each event <italic>q</italic> at time <italic>τ</italic><sub><italic>q</italic></sub>:</p>
<p><inline-formula id="pcbi.1004660.e019"><alternatives><graphic id="pcbi.1004660.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>'</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>199</mml:mn></mml:mrow><mml:mrow><mml:mn>400</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>〈</mml:mi><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>〉</mml:mi></mml:mrow></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>q</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1004660.e020"><alternatives><graphic id="pcbi.1004660.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> represents an “instantaneous” baseline surrounding time <italic>τ</italic><sub><italic>q</italic></sub>: <inline-formula id="pcbi.1004660.e021"><alternatives><graphic id="pcbi.1004660.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>n</mml:mi><mml:mi>b</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>199</mml:mn></mml:mrow><mml:mrow><mml:mn>50</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>. <inline-formula id="pcbi.1004660.e022"><alternatives><graphic id="pcbi.1004660.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> were obtained in the same fashion. The training event types <italic>q</italic> were face picture stimulus onset (<italic>q</italic> → <italic>F</italic>), house picture stimulus onset (<italic>q</italic> → <italic>H</italic>), or randomly chosen points during the inter-stimulus interval (ISI, <italic>q</italic> → <italic>o</italic>), with 4 during each ISI period, at least 100ms from stimulus offset/onset and 50ms from one another.</p>
<p><bold>Testing feature points for discrete classification,</bold> <inline-formula id="pcbi.1004660.e023"><alternatives><graphic id="pcbi.1004660.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1004660.e024"><alternatives><graphic id="pcbi.1004660.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, were similarly obtained by <bold>forward-projecting</bold> 〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> and 〈<italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> into the <bold>testing period</bold> for pre-defined times of face or house picture stimuli onset events, <italic>p</italic>, at times <italic>τ</italic><sub><italic>p</italic></sub>. These results are illustrated in <xref ref-type="fig" rid="pcbi.1004660.g003">Fig 3</xref>.</p>
<fig id="pcbi.1004660.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004660.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Classification accuracy when the onset of a stimulus is known, using ERP, ERBB, or both template types.</title>
<p>In some subjects, 100% accuracy was reached. All accuracies were above 90% when both raw potential and broadband templates were used.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.g003" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec011">
<title>Projection of templates into continuous data stream (illustrated in Figs <xref ref-type="fig" rid="pcbi.1004660.g004">4</xref>–<xref ref-type="fig" rid="pcbi.1004660.g006">6</xref>)</title>
<p>To quantify how well the averaged raw potential 〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> is represented in the voltage time series of the testing data at time <italic>t</italic>, it is directly forward-projected onto the continuous time series at each millisecond: <inline-formula id="pcbi.1004660.e025"><alternatives><graphic id="pcbi.1004660.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>'</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>199</mml:mn></mml:mrow><mml:mrow><mml:mn>400</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mi>〈</mml:mi><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>〉</mml:mi></mml:mrow></mml:mrow><mml:mi>S</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>n</mml:mi><mml:mi>τ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1004660.e026"><alternatives><graphic id="pcbi.1004660.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msubsup><mml:mi>V</mml:mi><mml:mi>n</mml:mi><mml:mi>τ</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> was obtained in the same fashion as above. The same projection is performed for the broadband template 〈<italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub>, to obtain <inline-formula id="pcbi.1004660.e027"><alternatives><graphic id="pcbi.1004660.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<fig id="pcbi.1004660.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004660.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Decoding stimulus class and onset time from a continuous data stream in single trials: Illustration of two electrodes and the continuous classifier using 2 broadband features (subject 2).</title>
<p><bold>(A)</bold> Two cortical sites (3 cm from one another) on the fusiform (green) and lingual (orange) gyri are examined. <bold>(B)</bold> Broadband <bold>training</bold> templates from the green electrode for faces (blue, 〈<italic>B</italic><sub>1</sub>(<italic>t</italic>')〉<sub><italic>F</italic></sub>) and houses (pink, 〈<italic>B</italic><sub>1</sub>(<italic>t</italic>')〉<sub><italic>H</italic></sub>) are shown on the axes to the left. <bold>Testing</bold> time course of green electrode broadband spectral change, <italic>B</italic><sub>1</sub>(<italic>t</italic>), is shown to the right in black, with the projection of the face template 〈<italic>B</italic><sub>1</sub>(<italic>t</italic>')〉<sub><italic>F</italic></sub> into <italic>B</italic><sub>1</sub>(<italic>t</italic>) to produce <inline-formula id="pcbi.1004660.e028"><alternatives><graphic id="pcbi.1004660.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, shown in the green trace beneath. <bold>(C)</bold> As in B, but for the orange electrode site, using projections of a house template 〈<italic>B</italic><sub>2</sub>(<italic>t</italic>')〉<sub><italic>H</italic></sub> to produce <inline-formula id="pcbi.1004660.e029"><alternatives><graphic id="pcbi.1004660.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. <bold>(D)</bold> The classification feature subspace is defined by back-projection of the templates on the left in (B-C), to obtain <bold>training</bold> points <inline-formula id="pcbi.1004660.e030"><alternatives><graphic id="pcbi.1004660.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> for face, house, and ISI events at <bold>training</bold> times <italic>τ</italic><sub><italic>q</italic></sub> shown. <bold>(E)</bold> In order to illustrate the multi-dimensional trajectory of the brain state that emerges when different channels and features are brought into a common space, the 2D trace of <inline-formula id="pcbi.1004660.e031"><alternatives><graphic id="pcbi.1004660.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> from the green electrode (B) versus <inline-formula id="pcbi.1004660.e032"><alternatives><graphic id="pcbi.1004660.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> from the orange electrode (C), are shown in black in the same subspace as D. The predicted onsets for face (blue) and house (red) stimuli are shown as plus symbols while actual onsets are shown as open circles. Note that the classifier was applied to the entire broadband feature space, not just this 2D subspace. <bold>(F)</bold> The trajectory of the face onset posterior probability from the classifier Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>F</italic>} (blue) is shown alongside Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>H</italic>} (pink), with predicted (plus symbols) and actual (open circles) times shown.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.g004" xlink:type="simple"/>
</fig>
<fig id="pcbi.1004660.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004660.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Decoding the single trial stimulus class and onset time from a continuous data stream using ERP: Illustration of three electrodes and the continuous classifier using 3 ERP-templates-to-voltage-timeseries projections (subject 4).</title>
<p><bold>(A)</bold> Three cortical sites are shown for illustration (purple, orange, and green). The axes on the right show the <inline-formula id="pcbi.1004660.e033"><alternatives><graphic id="pcbi.1004660.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (blue asterisk, r<sup>2</sup> of faces-vs-ISI) and <inline-formula id="pcbi.1004660.e034"><alternatives><graphic id="pcbi.1004660.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (pink box, r<sup>2</sup> of houses-vs-ISI) of ERP-voltage <bold>training projections</bold> show that these purple/orange/green sites are highly selective for faces or houses during the <bold>training period</bold> (from the 1<sup>st</sup> cross-fold). Features falling below the black line were not used for decoding. <bold>(B)</bold> Averaged face and house ERPs, 〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>F</italic></sub> &amp; 〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>H</italic></sub>, from each site are shown on the left axes. These are projected into the raw voltage traces from the <bold>testing period</bold> (<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>), black) to obtain continuous projection weight traces (<inline-formula id="pcbi.1004660.e035"><alternatives><graphic id="pcbi.1004660.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>; green–face projection from green electrode, orange–house projection from orange electrode, and purple–face projection purple electrode). These traces are fed into a feature space and classified continuously to obtain posterior probability of a face, Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>F</italic>} (blue), or house stimulus, Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>H</italic>} (pink) (bottom plot). <bold>(C)</bold> A 3-dimensional subspace (from the sites in A and B) is illustrated, with training points from the training period shown with dots, and the subspace trajectory of the brain state, Γ(<italic>t</italic>), shown with a black line. Predicted and actual timing and type of stimulus are shown along this trajectory.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.g005" xlink:type="simple"/>
</fig>
<fig id="pcbi.1004660.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004660.g006</object-id>
<label>Fig 6</label>
<caption>
<title>A combined ERBB-broadband and ERP-voltage projection feature space for classification (subject 5).</title>
<p><bold>(A)</bold> Two cortical sites (orange and green dots) are examined. <bold>(B)</bold> The axes show the <inline-formula id="pcbi.1004660.e036"><alternatives><graphic id="pcbi.1004660.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (blue asterisk) and <inline-formula id="pcbi.1004660.e037"><alternatives><graphic id="pcbi.1004660.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> (pink box) for <bold>ERP-voltage training</bold> projections show that these orange and green sites are highly selective during the training period (from first cross-fold). <bold>(C)</bold> <inline-formula id="pcbi.1004660.e038"><alternatives><graphic id="pcbi.1004660.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> for <bold>ERBB-Broadband training</bold> projections. <bold>(D)</bold> Averaged face and house ERP templates from the green site are shown on the left axes (olive green). The face-ERP templates are projected into the raw voltage trace (black) to obtain continuous a projection weight trace (olive green trace). <bold>(E)</bold> As in (D), but for ERBB-broadband templates in the green electrode site (neon green). <bold>(F&amp;G)</bold> As in (D&amp;E), except for the orange electrode site in (A), using house ERP (brown) and ERBB (burned orange) templates. <bold>(H)</bold> Green electrode, face ERP vs ERBB subspace projections. <bold>(I)</bold> Orange electrode house ERP vs ERBB subspace projections. <bold>(J)</bold> ERBB projection subspace (orange-electrode house-template projection vs green-electrode face-template projection). <bold>(K)</bold> As in (J), for ERP projection subspace. <bold>(L)</bold> A 3-d subspace projection (features from D,E,G). <bold>(M)</bold> Posterior probability of a face, Pr{Γ<sub><italic>m</italic></sub>(<italic>t</italic>)|<italic>q</italic> → <italic>F</italic>} (blue), or house stimulus, Pr{Γ<sub><italic>m</italic></sub>(<italic>t</italic>)|<italic>q</italic> → <italic>F</italic>} (pink), having been presented (where <italic>m</italic> → ERP, ERBB or both features for the projection space).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.g006" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec012">
<title>Generation of a projection feature space</title>
<p>The full feature space for classification, consisting of the union of projections of the stimulus triggered average raw potentials (<italic>V</italic>) or broadband (<italic>B</italic>) across all electrodes (<italic>n</italic>), for faces (<italic>F</italic>) and houses (<italic>H</italic>) independently, is the combination of <inline-formula id="pcbi.1004660.e039"><alternatives><graphic id="pcbi.1004660.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1004660.e040"><alternatives><graphic id="pcbi.1004660.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>V</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, <inline-formula id="pcbi.1004660.e041"><alternatives><graphic id="pcbi.1004660.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, and <inline-formula id="pcbi.1004660.e042"><alternatives><graphic id="pcbi.1004660.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>H</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. For notational brevity, we can combine the notation to denote each feature as Γ<sub><italic>m</italic></sub>, where <italic>m</italic> represents a unique combination of electrode <italic>n</italic>, <italic>V</italic> or <italic>B</italic>, and <italic>F</italic> or <italic>H</italic>. Many of these features will not be particularly informative about when and how the brain is processing these visual stimuli, and reduce classification in the setting of a limited number of training measurements [<xref ref-type="bibr" rid="pcbi.1004660.ref035">35</xref>]. Therefore, features were individually downselected by independently assessing their squared cross-correlation between events of each stimulus type (e.g. face or house) and events drawn from the ISI during the training period, and rejecting those which fell beneath a pre-defined threshold <inline-formula id="pcbi.1004660.e043"><alternatives><graphic id="pcbi.1004660.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>. For example, for projections of the face event-related feature, Γ<sub><italic>n</italic>,<italic>F</italic></sub> (<italic>V</italic> / <italic>B</italic> label dropped here) we can denote the average of face stimuli as <inline-formula id="pcbi.1004660.e044"><alternatives><graphic id="pcbi.1004660.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mi>F</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover accent="true"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>=</mml:mo><mml:mi>o</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="true">¯</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>F</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mspace width="0.15em"/><mml:mi>*</mml:mi><mml:mspace width="0.15em"/><mml:msub><mml:mi>N</mml:mi><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mi>o</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula>, where <italic>σ</italic><sub><italic>n</italic>,<italic>Fo</italic></sub> is the standard deviation of the joint distribution for face and ISI events Γ<sub><italic>n</italic>,<italic>F</italic></sub>(<italic>q</italic> = <italic>F</italic>,<italic>o</italic>), <italic>N</italic><sub><italic>F</italic></sub> is the number of face events, <italic>N</italic><sub><italic>o</italic></sub> is the number of ISI events, and <italic>N</italic><sub><italic>Fo</italic></sub> = <italic>N</italic><sub><italic>F</italic></sub> + <italic>N</italic><sub><italic>o</italic></sub>. In this study, we consider feature spaces consisting of projections of all types (e.g. ERP and ERBB together), and also selectively assess <italic>B</italic>(<italic>t</italic>) and <italic>V</italic>(<italic>t</italic>) independently. Example feature (sub)spaces are illustrated in Figs <xref ref-type="fig" rid="pcbi.1004660.g002">2G</xref> and <xref ref-type="fig" rid="pcbi.1004660.g004">4D and 4E</xref> and <xref ref-type="fig" rid="pcbi.1004660.g005">5C</xref> and <xref ref-type="fig" rid="pcbi.1004660.g006">6H–6L</xref>.</p>
</sec>
<sec id="sec013">
<title>Classifier type and relation to feature space</title>
<p>We begin with the feature set of training points (<italic>q</italic>, drawn from only the training period), Γ<sub><italic>m</italic></sub>(<italic>q</italic>), where each <italic>m</italic> is a dimension in the feature space, and represents a particular combination of electrode, broadband or raw potential time series, and face or house template. For the sake of simplicity, Fisher linear discriminant analysis (LDA) was used for classification [<xref ref-type="bibr" rid="pcbi.1004660.ref036">36</xref>]. This characterizes the full distribution and the training period sub-distributions Γ<sub><italic>m</italic></sub>(<italic>q</italic> → <italic>F</italic>), Γ<sub><italic>m</italic></sub>(<italic>q</italic> → <italic>H</italic>), Γ<sub><italic>m</italic></sub>(<italic>q</italic> → <italic>o</italic>), by their means and covariances only (i.e., as if they are normally distributed). LDA assumes that the covariances of the sub-distributions are the same. Given these training distributions, data from the testing set can be assigned a posterior probability of belonging to each distribution. While we used simple LDA, one could, in principle, apply more sophisticated kernel-based or non-linear methods. Our choice of LDA was meant to simplify interpretation of our approach, which is centered on the generation of “projection feature spaces”, and provide a clear demonstration of how one may decode a continuous datastream spontaneously, rather than exploring the library of existing machine learning and classifier techniques, which is deferred to future study.</p>
</sec>
<sec id="sec014">
<title>Classification of discrete events with known onset time (<xref ref-type="fig" rid="pcbi.1004660.g003">Fig 3</xref>)</title>
<p>We began with the case where we identify the timing of testing visual stimuli, and attempt to classify whether a face or a house picture was shown. Only the face and house training point distributions (e.g. Γ<sub><italic>m</italic></sub>(<italic>q</italic> → <italic>F</italic>) and Γ<sub><italic>m</italic></sub>(<italic>q</italic> → <italic>H</italic>)) were used to train the classifier for this discrete case. For each testing point, <italic>p</italic>, the assigned class was whichever posterior probability Pr{Γ(<italic>p</italic>)|<italic>q</italic> → <italic>F</italic>}, or Pr{Γ(<italic>p</italic>)|<italic>q</italic> → <italic>H</italic>}, was higher.</p>
</sec>
<sec id="sec015">
<title>Spontaneous decoding of the continuous datastream (<xref ref-type="fig" rid="pcbi.1004660.g007">Fig 7</xref>)</title>
<p>For the prediction of type and timing of visual stimulus from continuous signal, we trained the classifier using the face (Γ<sub><italic>m</italic></sub>(<italic>q</italic> → <italic>F</italic>)), house (Γ<sub><italic>m</italic></sub>(<italic>q</italic> → <italic>H</italic>)), and ISI (Γ<sub><italic>m</italic></sub>(<italic>q</italic> → <italic>o</italic>)), training point distributions. Then, the LDA posterior probability that a face or house stimulus has been shown at any point in time can be measured from the testing data at each millisecond <italic>t</italic> as Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>F</italic>} or Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>H</italic>}. We then smooth each of these posterior probabilities with a σ = 80ms Gaussian filter, for well-behaved estimation of local maxima. From this, we assign predicted times for stimuli onset as follows: The posterior probability must be a local maximum, with value &gt;0.51. There must be at least 320 ms between any point and the nearest assigned point (of either stimulus type–the larger posterior probability ‘wins’). A guess is considered correct if it lies within 160ms of an event. The probability of the null case, Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>o</italic>} = 1 − Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>F</italic>} − Pr{Γ(<italic>t</italic>)|<italic>q</italic> → <italic>H</italic>}, is &gt;0.50 at all other times, signifying that a picture has not just been shown.</p>
<fig id="pcbi.1004660.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004660.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Classification accuracy for decoding stimulus class and onset in a continuous data stream.</title>
<p>When both features were used (red bars), approximately 96% of all stimuli were captured correctly in every subject, with 15–20 ms error. An average of 4% of predictions using both features were incorrect (i.e., predicted stimuli at the wrong time, or as the wrong class). One should not confuse the fraction of guesses incorrect with the fraction of stimuli that were not captured (the bars on the top and bottom axes do not sum to 1)–it is a coincidence that also 4% of stimuli were missed.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.g007" xlink:type="simple"/>
</fig>
<p>While no information was given about the frequency of the stimuli, it was assumed that visual events were neuronally and behaviorally separable and a minimum difference of 320 ms was used. We picked 320ms as the “collision time” because we expect the neuronal response to take approximately that long [<xref ref-type="bibr" rid="pcbi.1004660.ref037">37</xref>], it makes for a random hit rate of 20% (e.g. 2.5 guesses per 800ms stimulus-to-stimulus interval, with 2 stimulus classes), and it roughly correlates with the mean broadband latencies-to-peak across single trials in these brain areas, which were found in other studies to be 269±52ms for face-selective ventral temporal sites and 299±66ms for house-selective sites [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>]. This threshold for the classifier is also based in the following known aspects of the time scales of neuronal responses and face perception. First, when visual stimuli are shown in rapid order, it becomes impossible to visually distinguish each stimulus at specific rates for different stimulus classes [<xref ref-type="bibr" rid="pcbi.1004660.ref038">38</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref039">39</xref>]. For face perception this behavioral rate lies around 5–10Hz [<xref ref-type="bibr" rid="pcbi.1004660.ref040">40</xref>]. At faster rates, backward masking and temporal integration become issues. Second, the duration of a neuronal response in higher order visual areas is around 300 ms [<xref ref-type="bibr" rid="pcbi.1004660.ref041">41</xref>]. When stimuli are presented at faster rates than 300 ms each, neuronal responses from these brain areas would be expected start overlapping. Supporting information (<xref ref-type="supplementary-material" rid="pcbi.1004660.s006">S1 Fig</xref>) empirically shows that this choice of 320ms does not inform the classifier about frequency of stimuli shown.</p>
<p>In the case of spontaneous decoding of the continuous timeseries, if one were to make random guesses for events at the maximum permissible temporal density of guesses (using the rules we picked in the methodology), each guess would have a 20% chance of being correct, and 50% of stimuli would be deemed “captured”, with an 80% false positive rate, and an average temporal error of 80ms. Instead, 96% of stimuli (300 per subject) were captured, with a 4% false positive rate, and an average temporal error of 20ms.</p>
<p>When examining timecourses of the projections (Γ<sub><italic>n</italic></sub>(<italic>t</italic>)), as well as the resulting posterior probabilities (Pr{Γ(<italic>t</italic>)|<italic>q</italic>}), it is important to keep in mind that the templates (〈<italic>V</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub> and 〈<italic>B</italic><sub><italic>n</italic></sub>(<italic>t</italic>')〉<sub><italic>S</italic></sub>) contain temporal information up to ~400ms later (illustrated in Figs <xref ref-type="fig" rid="pcbi.1004660.g002">2</xref>–<xref ref-type="fig" rid="pcbi.1004660.g006">6</xref>). The local maximum of the posterior probability is the assumed to be roughly the time at <bold><italic>which the templates align</italic></bold> with the average response in such a way that the average response would be at the time of stimulus presentation. The portion of the signal that contributes the most to the cross-correlation is likely to be in the 150–350ms following the timepoint, <italic>t</italic> (based upon visual inspection of the templates and raw timecourses in Figs <xref ref-type="fig" rid="pcbi.1004660.g001">1</xref>–<xref ref-type="fig" rid="pcbi.1004660.g006">6</xref>, as well as measured latencies in [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>]).</p>
</sec>
</sec>
</sec>
<sec id="sec016" sec-type="results">
<title>Results</title>
<p>ECoG signals were measured in seven subjects from electrodes implanted on the inferior temporal visual areas for the purpose of epilepsy monitoring. Subjects were presented with pictures of faces and houses (similar to those in <xref ref-type="fig" rid="pcbi.1004660.g001">Fig 1</xref>). We attempted to spontaneously identify the timing of face and house visual stimuli.</p>
<sec id="sec017">
<title>Signal features for decoding: Event-related broadband (ERBB) and event-related potential (ERP)</title>
<p>To test whether the ERBB and ERP provide useful information to decode whether, when and which class of stimulus was presented, we extracted the ERBB and ERP for all electrodes. Some electrodes show a classical face-specific N200 response [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>–<xref ref-type="bibr" rid="pcbi.1004660.ref015">15</xref>]. Other electrodes show face-specific ERPs with very different shapes (<xref ref-type="fig" rid="pcbi.1004660.g001">Fig 1</xref>).</p>
</sec>
<sec id="sec018">
<title>Decoding the stimulus class in single trials when the onset of a stimulus is known</title>
<p>We first investigated whether the stimulus class could be decoded in single trials when the onset of the stimulus is given. We calculated template ERBB and ERP responses from training data, which consisted of 2/3 of the recorded data (two experimental runs). The test data (for the classifier) consisted of the other 1/3 (the remaining experimental run; i.e., 3-fold cross validation, or “leave-one-run-out” cross-validation). <xref ref-type="fig" rid="pcbi.1004660.g002">Fig 2</xref> shows examples of the template ERBB responses for a face- and a house-specific site. Even in a two-dimensional subspace of the full feature space, a simple line serves as a good classification boundary between the two classes of stimuli (<xref ref-type="fig" rid="pcbi.1004660.g002">Fig 2G</xref>).</p>
<p>Using either the ERP or the ERBB feature, stimuli could be robustly and reliably categorized in all cases. The average prediction accuracy using the ERBB alone was 97% across all 7 subjects, while using the ERP alone, it was 90% (<xref ref-type="fig" rid="pcbi.1004660.g003">Fig 3</xref>). Using a combination of the two features, 97% of stimuli could accurately be classified as face or house. It is important to note that, in subjects 1 and 3, the addition of the ERP feature actually resulted in a decrease in classification accuracy, when compared with the ERBB alone, and subject 7 shows no change. This is because of what is known as the “bias-variance tradeoff” [<xref ref-type="bibr" rid="pcbi.1004660.ref042">42</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref043">43</xref>]. For a finite number of datapoints in a training set, the inclusion of features with higher amounts of noise (ERP features in this case) can hurt overall classification. The classifier overfits noise in the mediocre features (ERP), at the expense of a tight fit to high-yield (lower noise) features (e.g. ERBB), while simultaneously expanding the size of the feature space.</p>
</sec>
<sec id="sec019">
<title>Spontaneous decoding of stimulus class and onset from a continuous cortical data stream</title>
<p>Figs <xref ref-type="fig" rid="pcbi.1004660.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1004660.g003">3</xref> demonstrate that our analyses can accurately determine the stimulus class when given the timing of stimulus presentation. However, this type of decoding has been employed before in other experimental settings, albeit with less accuracy [<xref ref-type="bibr" rid="pcbi.1004660.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1004660.ref022">22</xref>]. The more interesting technical question is: Can one spontaneously determine both the class and the onset of the stimuli from a continuous stream of ECoG signal features?</p>
<p>Our approach to the continuous decoding problem is illustrated in Figs <xref ref-type="fig" rid="pcbi.1004660.g004">4</xref>–<xref ref-type="fig" rid="pcbi.1004660.g006">6</xref>, where template responses from a training period were applied to a period of testing data. The result of plotting the projection timeseries trajectory in a 2-dimensional subspace, Γ<sup><italic>B</italic></sup>(<italic>t</italic>), can be seen alongside training points <inline-formula id="pcbi.1004660.e045"><alternatives><graphic id="pcbi.1004660.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> in <xref ref-type="fig" rid="pcbi.1004660.g004">Fig 4</xref>. Even in this 2-dimensional subspace projection, the furthest excursions of Γ<sup><italic>B</italic></sup>(<italic>t</italic>) into the face or house training clouds, <inline-formula id="pcbi.1004660.e046"><alternatives><graphic id="pcbi.1004660.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:msubsup><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mi>B</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, correlate with the times of predicted stimulus onset. <xref ref-type="fig" rid="pcbi.1004660.g005">Fig 5</xref> shows an example similar to that in <xref ref-type="fig" rid="pcbi.1004660.g004">Fig 4</xref>, but for the ERP feature. <xref ref-type="fig" rid="pcbi.1004660.g006">Fig 6</xref> shows an example of the synthesis between ERP and ERBB features when used together.</p>
<p>A combination between ERP and ERBB projections can be used to predict the onset timing and class of stimuli more accurately than either independently. The spontaneous classification of onset time and stimulus class was robust: 92% of stimuli were captured using the ERBB, 92% when using the ERP, and 96% of all stimuli were captured spontaneously when using a combination of both ERP and ERBB (<xref ref-type="fig" rid="pcbi.1004660.g007">Fig 7</xref>, top row). Furthermore, timing of stimulus onset could be predicted with approximately 20ms error when the ERP or a combination between the ERP and ERBB was used (<xref ref-type="fig" rid="pcbi.1004660.g007">Fig 7</xref>, middle row). The portion of incorrect predictions (e.g. false positive rate) was smallest (4%) when we used a combination of both the ERP and ERBB (i.e., predicted stimuli occured at &gt;160ms from stimulus onset, or as the wrong class; <xref ref-type="fig" rid="pcbi.1004660.g007">Fig 7</xref>, bottom row).</p>
<p>In order to evaluate whether using both features together (ERP and ERBB) was significantly better than either independently, the labels of mean values (ERP vs ERBB vs ERP+ERBB) were randomly reshuffled (within each subject) 10<sup>4</sup> times to obtain a surrogate distribution of difference in means averaged across all subjects. The 96% of events captured using both features was significantly greater than the 92% when using either independently (p = 0.0015). The timing error for correct predictions was not significantly different for both features (19ms) vs ERP (20ms, p = 0.17), but was significantly better than ERBB alone (32ms, p&lt;0.0001). The false positive rate using both features (0.04) was significantly less than either independently (ERP 0.11; ERBB 0.09; p = 0.0012). The fact that the overall best prediction performance was reached by a combination of ERBB and ERP suggests that these two cortical features convey complementary information about a subject’s perceptual state.</p>
<p>Note that our 20ms estimate of the temporal fidelity of the signals may actually be an underestimate. There may be instrumentation temporal error introduced due to frame-jitter on the refresh rate of the amplifiers, sample jitter during alignment to the stimulus, and/or the granularity of sample block size of the signals imported to BCI2000 program [<xref ref-type="bibr" rid="pcbi.1004660.ref030">30</xref>]. Furthermore, there are known variations in the magnitude and timing broadband responses that are related to semantic properties (such as novelty [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>]), that are disregarded in this manuscript.</p>
<p>We designate this technique as “Spontaneous decoding” of the ECoG datastream. Our technique processes the data, without foreknowledge of the frequency of external stimuli, nor their timing, nor their content. It then produces predictions about the occurrence, timing, and content of external stimuli, based upon a simple set of internal rules. “Spontaneous” is defined as [<xref ref-type="bibr" rid="pcbi.1004660.ref044">44</xref>]: “performed or occurring as a result of a sudden inner impulse or inclination and without premeditation or external stimulus”, and so we feel that this term is the most specific way to describe this analysis approach. While “endogenous” or “intrinsic” decoding might also have been chosen, since these are used to describe internal brain states (which is an aspect of we are actually decoding), we chose not to use them–we feel that these terms convey assumptions about the role of the temporal lobe which have yet to be proven.</p>
</sec>
</sec>
<sec id="sec020" sec-type="conclusions">
<title>Discussion</title>
<p>In human experience, environmental stimuli arrive continuously, producing a sequentially evolving perceptual state. It has remained unknown whether the brain surface electrical potential has sufficient spatiotemporal fidelity to capture this dynamically changing perceptual state. Our results demonstrate that a sparse sample of the cortical surface potential contains sufficient information to reliably predict <italic>whether</italic> and <italic>when</italic> a particular stimulus occurred, with approximately the fidelity of conscious perception. It has also remained unknown whether the mesoscale neurophysiologies of event-related potentials and broadband spectral changes reflect the same information.</p>
<p>Previous studies aimed at decoding perception have all pre-defined the onset time of each stimulus [<xref ref-type="bibr" rid="pcbi.1004660.ref006">6</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1004660.ref022">22</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref045">45</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref046">46</xref>]. In the first-stage of our analysis, we performed this type of classification using pre-defined onset time, with 97% accuracy (Figs <xref ref-type="fig" rid="pcbi.1004660.g002">2</xref> and <xref ref-type="fig" rid="pcbi.1004660.g003">3</xref>). Similar prior studies attained representative peak accuracies of 72% with MEG/fMRI [<xref ref-type="bibr" rid="pcbi.1004660.ref022">22</xref>], 89% with EEG [<xref ref-type="bibr" rid="pcbi.1004660.ref020">20</xref>], and 94% with MEG [<xref ref-type="bibr" rid="pcbi.1004660.ref021">21</xref>]. However, real-world perception rarely occurs at pre-defined times, and approaches to decoding perceptual experience should be extracted spontaneously from continuous cortical recordings.</p>
<p>We have developed a technique to do just this, applying a novel template projection technique that enabled us to capture some aspects of the neural response that have previously been difficult or impossible to capture. First, the ERP in face-selective regions in the fusiform gyrus is classically associated with a negative peak at ~200ms (“N200”). Our data show that the actual shape of face-selective fusiform ERPs can vary widely, even at fusiform sites 1 cm from one another (<xref ref-type="fig" rid="pcbi.1004660.g001">Fig 1</xref>). The template projection technique captures these diverse response patterns, allowing them to be exploited for classification of perceptual state. Second, broadband responses show variability in the pattern of response in every individual trial. The template projection method relies on a superposition of the single trial characteristic shape and a probability density function for modeling different shapes, offering a robust prediction of perceptual state in spite of the variability across single trials. Examination of the features separately demonstrated that broadband changes are more robust and reliable reflections of perceptual content than raw-voltage changes, but that projection of ERP into raw voltage changes produces sharper temporal precision. Together, these two measures complement one another, providing independent information that results in more accurate and temporally precise prediction of the perceptual state than either measure on its’ own.</p>
<p>Our decoding fidelity approaches that of conscious thought, correctly capturing 96% of all stimuli from a sparsely-sampled stream of cortical potentials. The missed 4% (as well as the &lt;5% false positive rate) approaches what might be expected for rates of inattention by hospital patients viewing multiple stimuli each second (note that random guessing at the maximum rate in this spontaneous decoding would result in a 20% chance of each guess being correct, and 50% of stimuli deemed “captured”, with an 80% false positive rate). A temporal precision of ~20ms (<xref ref-type="fig" rid="pcbi.1004660.g007">Fig 7</xref>, middle row) is of the same order as the post-retinal temporal granularity of the visual system [<xref ref-type="bibr" rid="pcbi.1004660.ref047">47</xref>]. These ECoG measurements show that some electrodes in early visual cortex already display some stimulus-selective responses (e.g., <xref ref-type="fig" rid="pcbi.1004660.g005">Fig 5</xref>, purple site). This agrees with observations that fast eye movements can be made just based upon the Fourier spectrum of the images of different classes [<xref ref-type="bibr" rid="pcbi.1004660.ref048">48</xref>], and that people saccade towards a scene containing an animal or face within 140 ms [<xref ref-type="bibr" rid="pcbi.1004660.ref049">49</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref050">50</xref>]. By demonstrating that object categories can be decoded from a continuous image stream with accuracies matching expected human behavior (e.g. attentional lapses expected at a rate of approximately 5% in a task of this type [<xref ref-type="bibr" rid="pcbi.1004660.ref051">51</xref>]), our study lays the groundwork for capturing human perceptual states in a natural environment.</p>
<p>Although we applied this template-projection technique to prediction, the framework may be used in a wide variety of experimental settings. ERPs from adjacent cortical regions may be highly polymorphic, complicating cross-comparison of timing and magnitude effects. In this projection space, however, trial-to-trial ERP variations from different cortical sites may be compared directly, opening a new family of analyses that might be applied to cognitive settings, where image content and context are experimentally manipulated on single trials. Similarly, one might optimize the differential strengths of each feature, such as broadband for magnitude of response and ERP for timing of response, comparing these to stimulus properties to learn about subtleties of functional specialization in each brain region.</p>
<p>An important feature of this template projection approach is that it provides a robust, continuous, measure that is a summary statistic for how well the brain state at every point in time reflects the expected response (e.g. as if a perceptual event or action had occurred at that time–note that the shape of the expected physiological response, however idiosyncratic, is built into the method). This could be extremely useful in settings where the cortical dynamics and latency differ by region, yet a global behavior of a distributed visual [<xref ref-type="bibr" rid="pcbi.1004660.ref052">52</xref>], auditory [<xref ref-type="bibr" rid="pcbi.1004660.ref053">53</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref054">54</xref>], motor [<xref ref-type="bibr" rid="pcbi.1004660.ref055">55</xref>], or other network must be characterized. In emerging work, this technique is implemented in a different way, to generate broadband ECoG templates from a low-noise localizer task, and apply them to a visual discrimination task at the perceptual threshold, quantifying single trial variation in cortical physiology (neuronal response magnitude and timing) [<xref ref-type="bibr" rid="pcbi.1004660.ref056">56</xref>].</p>
<p>Our results beg the question: What is the underlying neural basis for the increased accuracies obtained by combining ERPs with broadband activity? A direct connection between neuronal population firing rate and broadband ECoG spectral change has been established with experimental and modeling work [<xref ref-type="bibr" rid="pcbi.1004660.ref011">11</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref023">23</xref>,<xref ref-type="bibr" rid="pcbi.1004660.ref024">24</xref>]. Each clinical ECoG electrode averages over approximately 5x10<sup>6</sup> neurons in the cortex beneath. Careful experimentation has shown that the broadband changes follow a power law in the power spectral density, implying that it reflects <italic>asynchronous</italic> spiking elements in the underlying population of neurons. The broadband measure may be loosely thought of as a real-time summation of this population’s firing raster (i.e., intrinsically averaged across the population of neurons). Increases in spike transmission within neurons in the population add in quadrature (e.g., proportional to the square root of the number of spikes), appearing as a “speeding up” of a random walk in the electrical potential time series, <italic>are difficult to see when looking at the raw potential</italic>, but apparent as broadband, <inline-formula id="pcbi.1004660.e047"><alternatives><graphic id="pcbi.1004660.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004660.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:mrow><mml:mi>P</mml:mi><mml:mo>∼</mml:mo><mml:mfrac bevelled="true"><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>f</mml:mi><mml:mi>χ</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> power-law, changes when inspecting in the frequency domain [<xref ref-type="bibr" rid="pcbi.1004660.ref024">24</xref>]. Recent work has shown that, in these data, the broadband timing is subtle enough to capture variational effects at the order of ~50ms due to context-dependent processing, such as sequential novelty [<xref ref-type="bibr" rid="pcbi.1004660.ref013">13</xref>].</p>
<p>Synchronized inputs, by contrast, add linearly and <italic>can be easily seen in the raw tracing of the electrical potential</italic>. Even if the synchronization is relatively weak, averaging across the neural population augments the synchronized portion, while the other aspects, such as broadband spectral change, are relatively diminished. Event-locked inputs, from subcortical nuclei, or other cortical regions, can trigger a synchronized physiologic cascade, evident at the macroscale as an ERP. It remains unclear whether the polyphasic ERP is a result of interplay between coordinated excitatory pyramidal neuron depolarization followed by interneuronal lateral inhibition, or whether it results from synaptic integration followed by characteristic depolarization and repolarization of cortical laminar dipoles [<xref ref-type="bibr" rid="pcbi.1004660.ref057">57</xref>]. The polymorphic nature of different ERPs from adjacent cortical regions may (perhaps) then relate to different pyramidal neuron morphologies, different milieus of neuronal subtypes, or different laminar organization; our projection technique unfolds these polymorphic ERPs into a common space for comparison. In this light, the improved decoding accuracy may be the result of multi-location timing information conveyed by ERP during the initial feed-forward wave of neural activation [<xref ref-type="bibr" rid="pcbi.1004660.ref058">58</xref>], complemented by the broadband response reflecting subsequent local recurrent and longer-range cortico-cortical processing of the visual stimulus.</p>
</sec>
<sec id="sec021">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1004660.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.s001" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Participant characteristics, and number of selected electrodes by r<sup>2</sup>&lt;0.05 criteria (from first fold only).</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004660.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.s002" xlink:type="simple">
<label>S2 Table</label>
<caption>
<title>Correct classifications, when the timing of events is pre-designated.</title>
<p>Sorted by stimulus type (note that each number is out of a possible 150 correct).</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004660.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.s003" xlink:type="simple">
<label>S3 Table</label>
<caption>
<title>Errors for Spontaneous Predictions.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004660.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.s004" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Power spectral analysis.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004660.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.s005" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Decoupling the cortical spectrum.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1004660.s006" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004660.s006" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Choice of collision time does not inform classifier about timing of events.</title>
<p>Number of false predictions as a function of the choice of maximum distance between predicted event times (Collision time), for classification using both ERP and ERBB. The monotonic decay form and lack of “dips” or “peaks” shows that the collision time chosen did not inform the classifier about timing of stimuli. Of note, subject 5, who had the most early visual electrodes, was unaffected by even very low collusion times. The number of events correctly predicted was the same for every choice of collision time, so those data are not shown.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We are grateful to the patients and staff at Harborview Hospital in Seattle. Discussions with Kalanit Grill-Spector, Nick Ramsey, David Heeger, Bharathi Jagadeesh, Nathan Witthoft, and Brian Wandell were extremely helpful. Sara Webb created the stimuli and generously shared them with us.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004660.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>McDermott</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Chun</surname> <given-names>MM</given-names></name> (<year>1997</year>) <article-title>The fusiform face area: a module in human extrastriate cortex specialized for face perception</article-title>. <source>The Journal of neuroscience: the official journal of the Society for Neuroscience</source> <volume>17</volume>: <fpage>4302</fpage>–<lpage>4311</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Epstein</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Kanwisher</surname> <given-names>N</given-names></name> (<year>1998</year>) <article-title>A cortical representation of the local visual environment</article-title>. <source>Nature</source> <volume>392</volume>: <fpage>598</fpage>–<lpage>601</lpage>. <object-id pub-id-type="pmid">9560155</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref003"><label>3</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aguirre</surname> <given-names>GK</given-names></name>, <name name-style="western"><surname>Zarahn</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>D'Esposito</surname> <given-names>M</given-names></name> (<year>1998</year>) <article-title>An area within human ventral cortex sensitive to "building" stimuli: evidence and implications</article-title>. <source>Neuron</source> <volume>21</volume>: <fpage>373</fpage>–<lpage>383</lpage>. <object-id pub-id-type="pmid">9728918</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Puce</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Allison</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Gore</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name> (<year>1995</year>) <article-title>Face-sensitive regions in human extrastriate cortex studied by functional MRI</article-title>. <source>Journal of neurophysiology</source> <volume>74</volume>: <fpage>1192</fpage>–<lpage>1199</lpage>. <object-id pub-id-type="pmid">7500143</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kreiman</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Koch</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name> (<year>2000</year>) <article-title>Category-specific visual responses of single neurons in the human medial temporal lobe</article-title>. <source>Nat Neurosci</source> <volume>3</volume>: <fpage>946</fpage>–<lpage>953</lpage>. <object-id pub-id-type="pmid">10966627</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kiani</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Esteky</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Mirpour</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>K</given-names></name> (<year>2007</year>) <article-title>Object category structure in response patterns of neuronal population in monkey inferior temporal cortex</article-title>. <source>J Neurophysiol</source> <volume>97</volume>: <fpage>4296</fpage>–<lpage>4309</lpage>. <object-id pub-id-type="pmid">17428910</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ghuman</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Brunet</surname> <given-names>NM</given-names></name>, <name name-style="western"><surname>Li</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Konecky</surname> <given-names>RO</given-names></name>, <name name-style="western"><surname>Pyles</surname> <given-names>JA</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Dynamic encoding of face information in the human fusiform gyrus</article-title>. <source>Nat Commun</source> <volume>5</volume>: <fpage>5672</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/ncomms6672" xlink:type="simple">10.1038/ncomms6672</ext-link></comment> <object-id pub-id-type="pmid">25482825</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Privman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Fisch</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Neufeld</surname> <given-names>MY</given-names></name>, <name name-style="western"><surname>Kramer</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Kipervasser</surname> <given-names>S</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Antagonistic relationship between gamma power and visual evoked potentials revealed in human visual cortex</article-title>. <source>Cereb Cortex</source> <volume>21</volume>: <fpage>616</fpage>–<lpage>624</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhq128" xlink:type="simple">10.1093/cercor/bhq128</ext-link></comment> <object-id pub-id-type="pmid">20624838</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref009"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vidal</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Ossandon</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Jerbi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dalal</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Minotti</surname> <given-names>L</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Category-Specific Visual Responses: An Intracranial Study Comparing Gamma, Beta, Alpha, and ERP Response Selectivity</article-title>. <source>Front Hum Neurosci</source> <volume>4</volume>: <fpage>195</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2010.00195" xlink:type="simple">10.3389/fnhum.2010.00195</ext-link></comment> <object-id pub-id-type="pmid">21267419</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref010"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kadipasaoglu</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Baboyan</surname> <given-names>VG</given-names></name>, <name name-style="western"><surname>Conner</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Saad</surname> <given-names>ZS</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Surface-based mixed effects multilevel analysis of grouped human electrocorticography</article-title>. <source>Neuroimage</source> <volume>101</volume>: <fpage>215</fpage>–<lpage>224</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2014.07.006" xlink:type="simple">10.1016/j.neuroimage.2014.07.006</ext-link></comment> <object-id pub-id-type="pmid">25019677</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Zanos</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Fetz</surname> <given-names>EE</given-names></name>, <name name-style="western"><surname>den Nijs</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Ojemann</surname> <given-names>JG</given-names></name> (<year>2009</year>) <article-title>Decoupling the Cortical Power Spectrum Reveals Real-Time Representation of Individual Finger Movements in Humans</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>3132</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5506-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5506-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19279250</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Honey</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Rao</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>denNijs</surname> <given-names>M</given-names></name>, <etal>et al</etal>. (<year>2014</year>) <article-title>Broadband changes in the cortical surface potential track activation of functionally diverse neuronal populations</article-title>. <source>Neuroimage 85 Pt</source> <volume>2</volume>: <fpage>711</fpage>–<lpage>720</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Witthoft</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Rao</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>Ojemann</surname> <given-names>JG</given-names></name> (<year>2015</year>) <article-title>The physiology of perception in human temporal lobe is specialized for contextual novelty</article-title>. <source>J Neurophysiol</source> <volume>114</volume>: <fpage>256</fpage>–<lpage>263</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00131.2015" xlink:type="simple">10.1152/jn.00131.2015</ext-link></comment> <object-id pub-id-type="pmid">25972581</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Allison</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ginter</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Nobre</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Puce</surname> <given-names>A</given-names></name>, <etal>et al</etal>. (<year>1994</year>) <article-title>Face recognition in human extrastriate cortex</article-title>. <source>Journal of neurophysiology</source> <volume>71</volume>: <fpage>821</fpage>–<lpage>825</lpage>. <object-id pub-id-type="pmid">8176446</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Allison</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Nobre</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Puce</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Belger</surname> <given-names>A</given-names></name> (<year>1994</year>) <article-title>Human extrastriate visual cortex and the perception of faces, words, numbers, and colors</article-title>. <source>Cerebral cortex</source> <volume>4</volume>: <fpage>544</fpage>–<lpage>554</lpage>. <object-id pub-id-type="pmid">7833655</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Huettel</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>McKeown</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Song</surname> <given-names>AW</given-names></name>, <name name-style="western"><surname>Hart</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Spencer</surname> <given-names>DD</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>Linking hemodynamic and electrophysiological measures of brain activity: evidence from functional MRI and intracranial field potentials</article-title>. <source>Cerebral cortex</source> <volume>14</volume>: <fpage>165</fpage>–<lpage>173</lpage>. <object-id pub-id-type="pmid">14704213</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Engell</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>Huettel</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name> (<year>2012</year>) <article-title>The fMRI BOLD signal tracks electrophysiological spectral perturbations, not event-related potentials</article-title>. <source>NeuroImage</source> <volume>59</volume>: <fpage>2600</fpage>–<lpage>2606</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2011.08.079" xlink:type="simple">10.1016/j.neuroimage.2011.08.079</ext-link></comment> <object-id pub-id-type="pmid">21925278</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jacques</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Witthoft</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Weiner</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Foster</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Rangarajan</surname> <given-names>V</given-names></name>, <etal>et al</etal>. (<year>2015</year>) <article-title>Corresponding ECoG and fMRI category-selective signals in Human ventral temporal cortex</article-title>. <source>Neuropsychologia</source>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Engell</surname> <given-names>AD</given-names></name>, <name name-style="western"><surname>McCarthy</surname> <given-names>G</given-names></name> (<year>2011</year>) <article-title>The Relationship of Gamma Oscillations and Face-Specific ERPs Recorded Subdurally from Occipitotemporal Cortex</article-title>. <source>Cerebral cortex</source> <volume>21</volume>: <fpage>1213</fpage>–<lpage>1221</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/bhq206" xlink:type="simple">10.1093/cercor/bhq206</ext-link></comment> <object-id pub-id-type="pmid">20961973</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simanova</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>van Gerven</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Oostenveld</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Hagoort</surname> <given-names>P</given-names></name> (<year>2010</year>) <article-title>Identifying object categories from event-related EEG: toward decoding of conceptual representations</article-title>. <source>PloS one</source> <volume>5</volume>: <fpage>e14465</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0014465" xlink:type="simple">10.1371/journal.pone.0014465</ext-link></comment> <object-id pub-id-type="pmid">21209937</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van de Nieuwenhuijzen</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Backus</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Bahramisharif</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Doeller</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Jensen</surname> <given-names>O</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>MEG-based decoding of the spatiotemporal dynamics of visual category perception</article-title>. <source>NeuroImage</source> <volume>83</volume>: <fpage>1063</fpage>–<lpage>1073</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroimage.2013.07.075" xlink:type="simple">10.1016/j.neuroimage.2013.07.075</ext-link></comment> <object-id pub-id-type="pmid">23927900</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cichy</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Pantazis</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Oliva</surname> <given-names>A</given-names></name> (<year>2014</year>) <article-title>Resolving human object recognition in space and time</article-title>. <source>Nat Neurosci</source> <volume>17</volume>: <fpage>455</fpage>–<lpage>462</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3635" xlink:type="simple">10.1038/nn.3635</ext-link></comment> <object-id pub-id-type="pmid">24464044</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Manning</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Jacobs</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Fried</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Kahana</surname> <given-names>MJ</given-names></name> (<year>2009</year>) <article-title>Broadband shifts in local field potential power spectra are correlated with single-neuron spiking in humans</article-title>. <source>Journal of Neuroscience</source> <volume>29</volume>: <fpage>13613</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2041-09.2009" xlink:type="simple">10.1523/JNEUROSCI.2041-09.2009</ext-link></comment> <object-id pub-id-type="pmid">19864573</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Sorensen</surname> <given-names>LB</given-names></name>, <name name-style="western"><surname>Ojemann</surname> <given-names>JG</given-names></name>, <name name-style="western"><surname>den Nijs</surname> <given-names>M</given-names></name> (<year>2009</year>) <article-title>Power-law scaling in the brain surface electric potential</article-title>. <source>PLoS Comput Biol</source> <volume>5</volume>: <fpage>e1000609</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000609" xlink:type="simple">10.1371/journal.pcbi.1000609</ext-link></comment> <object-id pub-id-type="pmid">20019800</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref025"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ashburner</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name> (<year>2005</year>) <article-title>Unified segmentation</article-title>. <source>NeuroImage</source> <volume>26</volume>: <fpage>839</fpage>–<lpage>851</lpage>. <object-id pub-id-type="pmid">15955494</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref026"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wells</surname> <given-names>WM</given-names> <suffix>3rd</suffix></name>, <name name-style="western"><surname>Viola</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Atsumi</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Nakajima</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Kikinis</surname> <given-names>R</given-names></name> (<year>1996</year>) <article-title>Multi-modal volume registration by maximization of mutual information</article-title>. <source>Med Image Anal</source> <volume>1</volume>: <fpage>35</fpage>–<lpage>51</lpage>. <object-id pub-id-type="pmid">9873920</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref027"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Noordmans</surname> <given-names>HJ</given-names></name>, <name name-style="western"><surname>Vansteensel</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Ramsey</surname> <given-names>NF</given-names></name> (<year>2010</year>) <article-title>Automated electrocorticographic electrode localization on individually rendered brain surfaces</article-title>. <source>Journal of neuroscience methods</source> <volume>185</volume>: <fpage>293</fpage>–<lpage>298</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jneumeth.2009.10.005" xlink:type="simple">10.1016/j.jneumeth.2009.10.005</ext-link></comment> <object-id pub-id-type="pmid">19836416</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref028"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dale</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Fischl</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Sereno</surname> <given-names>MI</given-names></name> (<year>1999</year>) <article-title>Cortical surface-based analysis. I. Segmentation and surface reconstruction</article-title>. <source>Neuroimage</source> <volume>9</volume>: <fpage>179</fpage>–<lpage>194</lpage>. <object-id pub-id-type="pmid">9931268</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref029"><label>29</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Hebb</surname> <given-names>AO</given-names></name>, <name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Nijs</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Ojemann</surname> <given-names>JG</given-names></name>, <etal>et al</etal>. <chapter-title>Brain surface electrode co-registration using MRI and x-ray</chapter-title>; <year>2010</year>. <publisher-name>IEEE</publisher-name>. pp. <fpage>6015</fpage>–<lpage>6018</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref030"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Schalk</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>McFarland</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Hinterberger</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Birbaumer</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Wolpaw</surname> <given-names>JR</given-names></name> (<year>2004</year>) <article-title>BCI2000: a general-purpose brain-computer interface (BCI) system</article-title>. <source>IEEE Trans Biomed Eng</source> <volume>51</volume>: <fpage>1034</fpage>–<lpage>1043</lpage>. <object-id pub-id-type="pmid">15188875</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref031"><label>31</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Porat</surname> <given-names>B</given-names></name> (<year>1997</year>) <chapter-title>A course in digital signal processing</chapter-title>: <publisher-name>Wiley</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref032"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Honey</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Hebb</surname> <given-names>AO</given-names></name>, <name name-style="western"><surname>Ramsey</surname> <given-names>NF</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Human motor cortical activity is selectively phase-entrained on underlying rhythms</article-title>. <source>PLoS computational biology</source> <volume>8</volume>: <fpage>e1002655</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002655" xlink:type="simple">10.1371/journal.pcbi.1002655</ext-link></comment> <object-id pub-id-type="pmid">22969416</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref033"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Honey</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Sharma</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Rao</surname> <given-names>RP</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Dynamic modulation of local population activity by rhythm phase in human occipital cortex during a visual search task</article-title>. <source>Frontiers in human neuroscience</source> <volume>4</volume>: <fpage>197</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnhum.2010.00197" xlink:type="simple">10.3389/fnhum.2010.00197</ext-link></comment> <object-id pub-id-type="pmid">21119778</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref034"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hermes</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Wandell</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Winawer</surname> <given-names>J</given-names></name> (<year>2014</year>) <article-title>Stimulus Dependence of Gamma Oscillations in Human Visual Cortex</article-title>. <source>Cereb Cortex</source>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref035"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Guyon</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Elisseeff</surname> <given-names>A</given-names></name> (<year>2003</year>) <article-title>An Introduction to Variable and Feature Selection</article-title>. <source>Journal of Machine Learning Research</source> <volume>3</volume>: <fpage>1157</fpage>–<lpage>1182</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref036"><label>36</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Bishop</surname> <given-names>CM</given-names></name> (<year>1995</year>) <chapter-title>Neural networks for pattern recognition</chapter-title>: <publisher-name>Oxford university press</publisher-name>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref037"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Keysers</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Xiao</surname> <given-names>DK</given-names></name>, <name name-style="western"><surname>Foldiak</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Perrett</surname> <given-names>DI</given-names></name> (<year>2001</year>) <article-title>The speed of sight</article-title>. <source>J Cogn Neurosci</source> <volume>13</volume>: <fpage>90</fpage>–<lpage>101</lpage>. <object-id pub-id-type="pmid">11224911</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref038"><label>38</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Burr</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Santoro</surname> <given-names>L</given-names></name> (<year>2001</year>) <article-title>Temporal integration of optic flow, measured by contrast and coherence thresholds</article-title>. <source>Vision research</source> <volume>41</volume>: <fpage>1891</fpage>–<lpage>1899</lpage>. <object-id pub-id-type="pmid">11412882</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref039"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Holcombe</surname> <given-names>AO</given-names></name> (<year>2009</year>) <article-title>Seeing slow and seeing fast: two limits on perception</article-title>. <source>Trends in cognitive sciences</source> <volume>13</volume>: <fpage>216</fpage>–<lpage>221</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2009.02.005" xlink:type="simple">10.1016/j.tics.2009.02.005</ext-link></comment> <object-id pub-id-type="pmid">19386535</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref040"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>McKeeff</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Remus</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Tong</surname> <given-names>F</given-names></name> (<year>2007</year>) <article-title>Temporal limitations in object processing across the human ventral visual pathway</article-title>. <source>J Neurophysiol</source> <volume>98</volume>: <fpage>382</fpage>–<lpage>393</lpage>. <object-id pub-id-type="pmid">17493920</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref041"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rolls</surname> <given-names>ET</given-names></name>, <name name-style="western"><surname>Tovee</surname> <given-names>MJ</given-names></name> (<year>1994</year>) <article-title>Processing speed in the cerebral cortex and the neurophysiology of visual masking</article-title>. <source>Proc Biol Sci</source> <volume>257</volume>: <fpage>9</fpage>–<lpage>15</lpage>. <object-id pub-id-type="pmid">8090795</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref042"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Geman</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Bienenstock</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Doursat</surname> <given-names>R</given-names></name> (<year>1992</year>) <article-title>Neural networks and the bias/variance dilemma</article-title>. <source>Neural computation</source> <volume>4</volume>: <fpage>1</fpage>–<lpage>58</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref043"><label>43</label><mixed-citation publication-type="book" xlink:type="simple"><name name-style="western"><surname>Geurts</surname> <given-names>P</given-names></name> (<year>2010</year>) <chapter-title>Bias vs Variance Decomposition for Regression and Classification</chapter-title>. <source>Data Mining and Knowledge Discovery Handbook</source>: <publisher-name>Springer</publisher-name>. pp. <fpage>733</fpage>–<lpage>746</lpage>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref044"><label>44</label><mixed-citation publication-type="other" xlink:type="simple">Apple (2011) Dictionary.</mixed-citation></ref>
<ref id="pcbi.1004660.ref045"><label>45</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hung</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Kreiman</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Poggio</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>DiCarlo</surname> <given-names>JJ</given-names></name> (<year>2005</year>) <article-title>Fast readout of object identity from macaque inferior temporal cortex</article-title>. <source>Science</source> <volume>310</volume>: <fpage>863</fpage>–<lpage>866</lpage>. <object-id pub-id-type="pmid">16272124</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref046"><label>46</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Liu</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Agam</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Madsen</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Kreiman</surname> <given-names>G</given-names></name> (<year>2009</year>) <article-title>Timing, timing, timing: fast decoding of object information from intracranial field potentials in human visual cortex</article-title>. <source>Neuron</source> <volume>62</volume>: <fpage>281</fpage>–<lpage>290</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.02.025" xlink:type="simple">10.1016/j.neuron.2009.02.025</ext-link></comment> <object-id pub-id-type="pmid">19409272</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref047"><label>47</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thor</surname> <given-names>DH</given-names></name> (<year>1967</year>) <article-title>Dichoptic viewing and temporal discrimination: an attempted replication</article-title>. <source>Science</source> <volume>158</volume>: <fpage>1704</fpage>–<lpage>1705</lpage>. <object-id pub-id-type="pmid">6059654</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref048"><label>48</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honey</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Kirchner</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>VanRullen</surname> <given-names>R</given-names></name> (<year>2008</year>) <article-title>Faces in the cloud: Fourier power spectrum biases ultrarapid face detection</article-title>. <source>Journal of vision</source> <volume>8</volume>: <fpage>9</fpage> 1–13.</mixed-citation></ref>
<ref id="pcbi.1004660.ref049"><label>49</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kirchner</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Thorpe</surname> <given-names>SJ</given-names></name> (<year>2006</year>) <article-title>Ultra-rapid object detection with saccadic eye movements: visual processing speed revisited</article-title>. <source>Vision research</source> <volume>46</volume>: <fpage>1762</fpage>–<lpage>1776</lpage>. <object-id pub-id-type="pmid">16289663</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref050"><label>50</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Crouzet</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Kirchner</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Thorpe</surname> <given-names>SJ</given-names></name> (<year>2010</year>) <article-title>Fast saccades toward faces: face detection in just 100 ms</article-title>. <source>Journal of vision</source> <volume>10</volume>: <fpage>16</fpage> 11–17.</mixed-citation></ref>
<ref id="pcbi.1004660.ref051"><label>51</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smallwood</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Davies</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Heim</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Finnigan</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Sudberry</surname> <given-names>M</given-names></name>, <etal>et al</etal>. (<year>2004</year>) <article-title>Subjective experience and the attentional lapse: task engagement and disengagement during sustained attention</article-title>. <source>Conscious Cogn</source> <volume>13</volume>: <fpage>657</fpage>–<lpage>690</lpage>. <object-id pub-id-type="pmid">15522626</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref052"><label>52</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Honey</surname> <given-names>CJ</given-names></name>, <name name-style="western"><surname>Thesen</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Donner</surname> <given-names>TH</given-names></name>, <name name-style="western"><surname>Silbert</surname> <given-names>LJ</given-names></name>, <name name-style="western"><surname>Carlson</surname> <given-names>CE</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Slow cortical dynamics and the accumulation of information over long timescales</article-title>. <source>Neuron</source> <volume>76</volume>: <fpage>423</fpage>–<lpage>434</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.08.011" xlink:type="simple">10.1016/j.neuron.2012.08.011</ext-link></comment> <object-id pub-id-type="pmid">23083743</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref053"><label>53</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mesgarani</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Cheung</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Chang</surname> <given-names>EF</given-names></name> (<year>2014</year>) <article-title>Phonetic feature encoding in human superior temporal gyrus</article-title>. <source>Science</source> <volume>343</volume>: <fpage>1006</fpage>–<lpage>1010</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1245994" xlink:type="simple">10.1126/science.1245994</ext-link></comment> <object-id pub-id-type="pmid">24482117</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref054"><label>54</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Abel</surname> <given-names>TJ</given-names></name>, <name name-style="western"><surname>Rhone</surname> <given-names>AE</given-names></name>, <name name-style="western"><surname>Nourski</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Kawasaki</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Oya</surname> <given-names>H</given-names></name>, <etal>et al</etal>. (<year>2015</year>) <article-title>Direct physiologic evidence of a heteromodal convergence region for proper naming in human left anterior temporal lobe</article-title>. <source>J Neurosci</source> <volume>35</volume>: <fpage>1513</fpage>–<lpage>1520</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3387-14.2015" xlink:type="simple">10.1523/JNEUROSCI.3387-14.2015</ext-link></comment> <object-id pub-id-type="pmid">25632128</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref055"><label>55</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sun</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Blakely</surname> <given-names>TM</given-names></name>, <name name-style="western"><surname>Darvas</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Wander</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>LA</given-names></name>, <etal>et al</etal>. (<year>2015</year>) <article-title>Sequential activation of premotor, primary somatosensory and primary motor areas in humans during cued finger movements</article-title>. <source>Clin Neurophysiol</source>.</mixed-citation></ref>
<ref id="pcbi.1004660.ref056"><label>56</label><mixed-citation publication-type="other" xlink:type="simple">Miller KJ, Hermes D, Pestilli F, Wig GS, Rao RPN, et al. (2015) Face percept formation in human ventral temporal cortex. In submission.</mixed-citation></ref>
<ref id="pcbi.1004660.ref057"><label>57</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mitzdorf</surname> <given-names>U</given-names></name> (<year>1985</year>) <article-title>Current Source-Density Method and Application in Cat Cerebral-Cortex—Investigation of Evoked-Potentials and Eeg Phenomena</article-title>. <source>Physiological Reviews</source> <volume>65</volume>: <fpage>37</fpage>–<lpage>100</lpage>. <object-id pub-id-type="pmid">3880898</object-id></mixed-citation></ref>
<ref id="pcbi.1004660.ref058"><label>58</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>VanRullen</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Thorpe</surname> <given-names>SJ</given-names></name> (<year>2002</year>) <article-title>Surfing a spike wave down the ventral stream</article-title>. <source>Vision Res</source> <volume>42</volume>: <fpage>2593</fpage>–<lpage>2615</lpage>. <object-id pub-id-type="pmid">12446033</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
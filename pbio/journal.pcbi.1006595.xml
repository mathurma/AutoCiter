<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-18-00392</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006595</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuronal tuning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical models</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Computational biology</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Computational neuroscience</subject><subj-group><subject>Coding mechanisms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Sensory physiology</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory systems</subject><subj-group><subject>Auditory system</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Brain</subject><subj-group><subject>Auditory cortex</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Organisms</subject><subj-group><subject>Eukaryota</subject><subj-group><subject>Animals</subject><subj-group><subject>Vertebrates</subject><subj-group><subject>Amniotes</subject><subj-group><subject>Mammals</subject><subj-group><subject>Ferrets</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Software engineering</subject><subj-group><subject>Preprocessing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and technology</subject><subj-group><subject>Software engineering</subject><subj-group><subject>Preprocessing</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Acoustics</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>STRFs in primary auditory cortex emerge from masking-based statistics of natural sounds</article-title>
<alt-title alt-title-type="running-head">STRFs emerge from masking-based sound statistics</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Sheikh</surname> <given-names>Abdul-Saboor</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="fn" rid="econtrib001"><sup>‡</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7851-4840</contrib-id>
<name name-style="western">
<surname>Harper</surname> <given-names>Nicol S.</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="fn" rid="econtrib001"><sup>‡</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Drefs</surname> <given-names>Jakob</given-names></name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4480-0574</contrib-id>
<name name-style="western">
<surname>Singer</surname> <given-names>Yosef</given-names></name>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Software</role>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dai</surname> <given-names>Zhenwen</given-names></name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Software</role>
<xref ref-type="aff" rid="aff005"><sup>5</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Turner</surname> <given-names>Richard E.</given-names></name>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<xref ref-type="aff" rid="aff006"><sup>6</sup></xref>
<xref ref-type="aff" rid="aff007"><sup>7</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9921-2529</contrib-id>
<name name-style="western">
<surname>Lücke</surname> <given-names>Jörg</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Project administration</role>
<role content-type="http://credit.casrai.org/">Resources</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Research Center Neurosensory Science, Cluster of Excellence Hearing4all, Department of Medical Physics and Acoustics, University of Oldenburg, Oldenburg, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Zalando Research, Zalando SE, Berlin, Germany</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Institute of Biomedical Engineering, Department of Engineering Science, University of Oxford, Oxford, United Kingdom</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>Department of Physiology, Anatomy and Genetics, University of Oxford, Oxford, United Kingdom</addr-line>
</aff>
<aff id="aff005">
<label>5</label>
<addr-line>Department of Computer Science, University of Sheffield, Sheffield, United Kingdom</addr-line>
</aff>
<aff id="aff006">
<label>6</label>
<addr-line>Department of Engineering, University of Cambridge, Cambridge, United Kingdom</addr-line>
</aff>
<aff id="aff007">
<label>7</label>
<addr-line>Microsoft Research, Cambridge, United Kingdom</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Theunissen</surname> <given-names>Frédéric E.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of California at Berkeley, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>While the study was conducted, the authors AS and RT were co-affiliated with Zalando SE and Microsoft Research, respectively. These non-academic affiliations had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. All data used for the study was collected by the academic affiliations of the authors. All authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="other" id="econtrib001">
<p>‡ These authors are joint first authors on this work.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">joerg.luecke@uol.de</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>1</month>
<year>2019</year>
</pub-date>
<pub-date pub-type="epub">
<day>17</day>
<month>1</month>
<year>2019</year>
</pub-date>
<volume>15</volume>
<issue>1</issue>
<elocation-id>e1006595</elocation-id>
<history>
<date date-type="received">
<day>9</day>
<month>3</month>
<year>2018</year>
</date>
<date date-type="accepted">
<day>23</day>
<month>10</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2019</copyright-year>
<copyright-holder>Sheikh et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006595"/>
<abstract>
<p>We investigate how the neural processing in auditory cortex is shaped by the statistics of natural sounds. Hypothesising that auditory cortex (A1) represents the structural primitives out of which sounds are composed, we employ a statistical model to extract such components. The input to the model are cochleagrams which approximate the non-linear transformations a sound undergoes from the outer ear, through the cochlea to the auditory nerve. Cochleagram components do not superimpose linearly, but rather according to a rule which can be approximated using the max function. This is a consequence of the compression inherent in the cochleagram and the sparsity of natural sounds. Furthermore, cochleagrams do not have negative values. Cochleagrams are therefore not matched well by the assumptions of standard linear approaches such as sparse coding or ICA. We therefore consider a new encoding approach for natural sounds, which combines a model of early auditory processing with maximal causes analysis (MCA), a sparse coding model which captures both the non-linear combination rule and non-negativity of the data. An efficient truncated EM algorithm is used to fit the MCA model to cochleagram data. We characterize the generative fields (GFs) inferred by MCA with respect to <italic>in vivo</italic> neural responses in A1 by applying reverse correlation to estimate spectro-temporal receptive fields (STRFs) implied by the learned GFs. Despite the GFs being non-negative, the STRF estimates are found to contain both positive and negative subfields, where the negative subfields can be attributed to explaining away effects as captured by the applied inference method. A direct comparison with ferret A1 shows many similar forms, and the spectral and temporal modulation tuning of both ferret and model STRFs show similar ranges over the population. In summary, our model represents an alternative to linear approaches for biological auditory encoding while it captures salient data properties and links inhibitory subfields to explaining away effects.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>The information carried by natural sounds enters the cortex of mammals in a specific format: the cochleagram. Instead of representing the original pressure waveforms, the inner ear represents how the energy in a sound is distributed across frequency bands and how the energy distribution evolves over time. The generation of cochleagrams is highly non-linear resulting in the dominance of one sound source per time-frequency bin under natural conditions (masking). Auditory cortex is believed to decompose cochleagrams into structural primitives, i.e., reappearing regular spectro-temporal subpatterns that make up cochleagram patterns (similar to edges in images). However, such a decomposition has so far only been modeled without considering masking and non-negativity. Here we apply a novel non-linear sparse coding model that can capture masking non-linearities and non-negativities. When trained on cochleagrams of natural sounds, the model gives rise to an encoding primarily based-on spectro-temporally localized components. If stimulated by a sound, the encoding units compete to explain its contents. The competition is a direct consequence of the statistical sound model, and it results in neural responses being best described by spectro-temporal receptive fields (STRFs) with positive and negative subfields. The emerging STRFs show a higher similarity to experimentally measured STRFs than a model without masking, which provides evidence for cortical encoding being consistent with the masking based sound statistics of cochleagrams. Furthermore, and more generally, our study suggests for the first time that negative subfields of STRFs may be direct evidence for explaining away effects resulting from performing inference in an underlying statistical model.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
<institution>Deutsche Forschungsgemeinschaft</institution>
</institution-wrap>
</funding-source>
<award-id>EXC 1077/1 (PI of subprojects)</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9921-2529</contrib-id>
<name name-style="western">
<surname>Lücke</surname> <given-names>Jörg</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
<institution>Deutsche Forschungsgemeinschaft</institution>
</institution-wrap>
</funding-source>
<award-id>LU 1196/5-1</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9921-2529</contrib-id>
<name name-style="western">
<surname>Lücke</surname> <given-names>Jörg</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>WT082692</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7851-4840</contrib-id>
<name name-style="western">
<surname>Harper</surname> <given-names>Nicol S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>WT076508AIA</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7851-4840</contrib-id>
<name name-style="western">
<surname>Harper</surname> <given-names>Nicol S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award005">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100004440</institution-id>
<institution>Wellcome Trust</institution>
</institution-wrap>
</funding-source>
<award-id>WT108369/Z/2015/Z</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7851-4840</contrib-id>
<name name-style="western">
<surname>Harper</surname> <given-names>Nicol S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award006">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100000268</institution-id>
<institution>Biotechnology and Biological Sciences Research Council</institution>
</institution-wrap>
</funding-source>
<award-id>BB/H008608/1</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-7851-4840</contrib-id>
<name name-style="western">
<surname>Harper</surname> <given-names>Nicol S.</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award007">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
<institution>Deutsche Forschungsgemeinschaft</institution>
</institution-wrap>
</funding-source>
<award-id>SFB 1330 (HAPPAA)</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Drefs</surname> <given-names>Jakob</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award008">
<funding-source>
<institution>Clarendon Fund</institution>
</funding-source>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4480-0574</contrib-id>
<name name-style="western">
<surname>Singer</surname> <given-names>Yosef</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>ASS, JD and JL were funded by the DFG in the Cluster of Excellence EXC 1077/1 ‘Hearing4all’, grant LU 1196/5-1, and grant 352015383 - SFB 1330 (B2). NH was supported by a Sir Henry Wellcome Postdoctoral Fellowship (WT082692) and other Wellcome Trust funding (WT076508AIA, WT108369/Z/2015/Z), by the Department of Physiology, Anatomy and Genetics at the University of Oxford, by Action on Hearing Loss (PA07), and by the Biotechnology and Biological Sciences Research Council (BB/H008608/1). YS was supported by the Clarendon Fund. RT was supported by EPSRC grants EP/M0269571 and EP/L000776/1. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="6"/>
<table-count count="0"/>
<page-count count="23"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2019-02-20</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>The data on the model STRF estimates, model generative fields, and the STRF measurements is part of the submission. The dataset used for training the model is publicly available as detailed in the submitted manuscript.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>The goal of this paper is to understand the computational principles which underpin neural processing in auditory cortex. In particular, we investigate the hypothesis that neural processing is shaped by the statistics of natural sounds, the physical rules governing how those sounds combine, and the form of the initial processing performed by the ear.</p>
<p>It is well known that the outer, middle and inner ear transform an incoming sound pressure waveform into a representation at the auditory nerve which can be approximately described by a filtering stage (in which the sound is broken into subbands), followed by an envelope extraction and compression stage. This approximation to the auditory nerve’s representation of a sound is called a cochleagram and intuitively it can be thought of as revealing the spectro-temporal variations in the energy of the input waveform. It is believed that subsequent stages of auditory processing might decompose this representation into basic “structural primitives”, i.e., components or building blocks from which natural sounds are composed. Such a representation would provide a basis to support more complex computation at higher levels in the system (compare, e.g., [<xref ref-type="bibr" rid="pcbi.1006595.ref001">1</xref>]). The idea of representations in terms of primitives is supported to some extent by <italic>in vivo</italic> recordings in the primary auditory cortex of mammals which suggests that neurons are most sensitive to structures that are localized in time and frequency [<xref ref-type="bibr" rid="pcbi.1006595.ref002">2</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref006">6</xref>], but the hypothesis still lacks convincing evidence.</p>
<p>One way of investigating the hypothesis that auditory cortex is representing the components of natural sounds is to learn their form from a corpus of natural sounds. A particularly popular approach, which has been used for great success for visual data [<xref ref-type="bibr" rid="pcbi.1006595.ref007">7</xref>] and subsequently for audio data [<xref ref-type="bibr" rid="pcbi.1006595.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>], is based on the idea that the stimulus is formed by a linear combination of components which are sparsely activated. However, for auditory stimuli, this “sparse coding” approach is arguably not the most natural one to take for three main reasons. First, a linear mixture of sound pressure waveforms (formed either from multiple sources in the environment or from a single source comprising a linear mixture of primitive components) results in a non-linear mixture at the level of the auditory nerve and it seems likely that downstream processing would respect this fact. Second, the cochleagram is non-negative which is not reflected by the standard form of the sparse coding model. Third, sparse coding (or ICA) operates most effectively on whitened data (although this might be due to current algorithmic limitations, rather than a general feature of the approach).</p>
<p>In the visual system it has been argued that the lateral geniculate nucleus (LGN) performs such a whitening step [<xref ref-type="bibr" rid="pcbi.1006595.ref010">10</xref>] but the initial transformations employed in the auditory system are quite different, making this sort of preprocessing harder to justify. Whitening for cochleagrams would essentially mean that neural activities do not encode energies in frequency bands but deviations from a mean energy relative to energy variances. Adaptation effects to mean and variances over time are well known for regions upstream of the cortex such as the auditory nerve and inferior colliculus [<xref ref-type="bibr" rid="pcbi.1006595.ref011">11</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref014">14</xref>]. However, this adaptation should not be equated with whitening. If it was this would imply that the absence of any signal energy should lead to (on average) equally strong responses as energies above the mean. If we do not assume a whitening stage for cochleagrams or a similar preprocessing to obtain mean-free stimuli, then we are confronted with the question: How do measured STRFs with their positive and negative subfields emerge? In vision, after an assumed whitening stage, stimuli contain positive and negative parts which directly result in components extracted by sparse coding to have negative and positive subfields. For the non-negative energy representation of cochleagrams it is so far unclear how negative subfields can emerge without a whitening stage. Statistical data models not requiring whitening suggest alternative mechanisms commonly referred to as “explaining away effects” which have so far not been linked to negative subfields of neural response properties. As an example for “explaining away” consider the situation of sitting in a park. It is a nice warm day, you have your eyes closed, and are just listening to the sounds around you. There is a small orchestra somewhere with musicians practicing for a concert, and there are birds in the trees. If you now perceive a very short melodic sequence, it may have been generated by a bird or by a musician’s flute. As you are too far away from any of the sources, and as the perceived sequence is too short and unspecific, it is not possible for you to say for sure which of the potential sources may have generated the sound. But you do know that a high probability for one source, e.g. the flute, would mean a low probability for the other. This dependency between the probabilities for the two potential sources given a sound is called “explaining away”. If you were more certain that it was the flute playing (e.g., by getting additional visual input), the flute would “explain away” the alternative explanation of the sound having been generated by a bird. The statistical models investigated here will have similar explaining away effects but on a lower level of sound processing (<xref ref-type="fig" rid="pcbi.1006595.g006">Fig 6</xref> will give a low level example later on). The primary statistical model investigated here assumes the data to be non-negative (and not whitened), and it assumes the structural primitives to combine non-linearly. More concretely, we assume structural primitives to combine such that the maximal energy in each time-frequency interval determines the superimposed signal (<xref ref-type="fig" rid="pcbi.1006595.g001">Fig 1</xref> shows an illustration).</p>
<fig id="pcbi.1006595.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006595.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Illustration of the log-max approximation.</title>
<p>The figure shows the generation of cochleagrams according to the used preprocessing model and the different combination models (sum and max). First the cochleagrams generated from two different waveforms are shown (middle column, top and middle) as well as the cochleagram generated from the linear mixture of the two waveforms (bottom). On the right at the top, a cochleagram resulting from a linear mixture of the two individual cochleagrams is shown. On the right at the bottom, a cochleagram resulting from a point-wise maximum is shown. The non-linear maximum is much more closely aligned with the cochleagram of the actual mixed waveforms (dotted arrow).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.g001" xlink:type="simple"/>
</fig>
<p>To summarize our goal, instead of using the dominating approach of standard sparse coding as statistical model to study neural representation in auditory cortex [<xref ref-type="bibr" rid="pcbi.1006595.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>], we investigate for the first time a non-linear and non-negative alternative. Our approach is motivated by the observation that alternatives to the assumptions of linear superposition and whitening may be more natural for acoustic data, and it offers an alternative explanation for the inhibitory subfields of STRFs which were previously closely linked to signal whitening.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Methods</title>
<p>We will now describe how we change the previously used assumptions of statistical models as discussed above. Engineers have known for a long time that representations such as the cochleagrams result from a non-linear interaction of primitive auditory components. Such non-linear interactions give rise to psychoacoustic masking effects, which have been successfully exploited in technical applications such as source separation (e.g., [<xref ref-type="bibr" rid="pcbi.1006595.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref017">17</xref>]). Underlying such masking effects are that natural sound energies tend to be sparsely distributed across frequencies and time, and that high energies dominate low energies in any spectro-temporal interval of a cochleagram. In practice this property is exploited by assigning each time-frequency interval to the one sound source or component that exhibits maximal energy [<xref ref-type="bibr" rid="pcbi.1006595.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref017">17</xref>], a procedure sometimes referred to as <italic>log-max</italic> approximation. This assumption is widely used in probabilistic models for auditory data processing [<xref ref-type="bibr" rid="pcbi.1006595.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref018">18</xref>] and finds application in denoising and source separation problems. Here we will also assume a combination rule of this form. Unfortunately, the audio-processing models mentioned above can only handle a small number of components (typically fewer than 10, compare [<xref ref-type="bibr" rid="pcbi.1006595.ref016">16</xref>]). In contrast, we expect the number of structural primitives required to explain natural sounds to be much larger (similar to a large number of edge-like components required to explain natural images). Therefore, we use instead the relatively novel model of Maximal Causes Analysis (MCA; [<xref ref-type="bibr" rid="pcbi.1006595.ref019">19</xref>]) that can be scaled to handle hundreds or up to a few thousands of components [<xref ref-type="bibr" rid="pcbi.1006595.ref020">20</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref022">22</xref>]. Not only does this model incorporate the non-linear max combination rule, it also comprises non-negative components much like a non-linear version of non-negative matrix factorization. Importantly, the method performs effectively without need for whitening and so it can be applied directly to non-negative cochleagrams as computed by auditory preprocessing models. The MCA approach, hence, matches those salient features of natural sound statistics previously not captured, making it to a more sensible alternative model for auditory processing in mammals.</p>
<sec id="sec003">
<title>Ethics statement</title>
<p>Animal experiments were done at the Department of Physiology, Anatomy, and Genetics, University of Oxford, performed under license from the United Kingdom Home Office and were approved by the ethical review committee of the University of Oxford. The electrophysiological recordings were made from an adult pigmented ferret under ketamine (5 mg/kg/h) and medetomidine (0.022 mg/kg/h) anesthesia. After recording, the animal was killed with 1ml/kg i.v. Pentoject.</p>
</sec>
<sec id="sec004">
<title>Models of acoustic preprocessing in mammals</title>
<p>In the inner ear, sound pressure waves are considered to be broken-down into their frequency components by the cochlea, which then also compresses the frequency response amplitudes to form log-spectrograms resembling cochleagram representations of the input signal. The cochleagrams are then further communicated via the auditory nerve for neural processing and as they arrive in higher brain areas such as the primary auditory cortex, the cochleagrams are believed to get decomposed into elementary components for higher-level processing.</p>
<sec id="sec005">
<title>Cochlear model and spectrogram generation</title>
<p>We model the cochlea of the inner ear as a gammatone filterbank as proposed by Johannesma [<xref ref-type="bibr" rid="pcbi.1006595.ref023">23</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref025">25</xref>]. The time domain impulse function of a gammatone filter is defined as:
<disp-formula id="pcbi.1006595.e001"><alternatives><graphic id="pcbi.1006595.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>g</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi> <mml:msup><mml:mi>t</mml:mi> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:mi>b</mml:mi> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo form="prefix">cos</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mi>π</mml:mi> <mml:msub><mml:mi>f</mml:mi> <mml:mi>c</mml:mi></mml:msub> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>ϕ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>a</italic> is the amplitude, <italic>b</italic> is the duration of the response, <italic>f</italic><sub><italic>c</italic></sub> a filter’s center frequency, <italic>ϕ</italic> is the phase and <italic>n</italic> determines the order of the filter. The center frequencies for constructing filterbanks are chosen according to the Equivalent Rectangular Bandwith (ERB) scale, which is proposed by Glasberg [<xref ref-type="bibr" rid="pcbi.1006595.ref026">26</xref>] based on the physiology of the human ear.</p>
<p>To obtain auditory representations that resemble cochleagrams, we compute the root mean square (RMS) gammatone responses <xref ref-type="disp-formula" rid="pcbi.1006595.e001">(1)</xref> to sound waveforms over a sliding temporal window with an overlapping shift. The RMS energies <inline-formula id="pcbi.1006595.e002"><alternatives><graphic id="pcbi.1006595.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:msub><mml:mover><mml:mi>x</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>f</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> are then passed through a compressive function (i.e., <inline-formula id="pcbi.1006595.e003"><alternatives><graphic id="pcbi.1006595.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:mn>10</mml:mn> <mml:msub><mml:mo form="prefix">log</mml:mo> <mml:mn>10</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:msubsup><mml:mover><mml:mi>x</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mrow><mml:mi>f</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>) to generate the representations.</p>
</sec>
</sec>
<sec id="sec006">
<title>Log-max encoding of cochleagrams</title>
<p>We assume that a cochleagram representation <inline-formula id="pcbi.1006595.e004"><alternatives><graphic id="pcbi.1006595.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> can be composed as a combination of a (small) number of primitive auditory components <inline-formula id="pcbi.1006595.e005"><alternatives><graphic id="pcbi.1006595.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>h</mml:mi></mml:msub> <mml:mo>∈</mml:mo> <mml:msup><mml:mi mathvariant="double-struck">R</mml:mi> <mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, which form elements of a large dictionary <inline-formula id="pcbi.1006595.e006"><alternatives><graphic id="pcbi.1006595.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:mi>W</mml:mi> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>H</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> of <italic>H</italic> components. For such a multi-component encoding scheme, classical modeling approaches such as standard sparse coding [<xref ref-type="bibr" rid="pcbi.1006595.ref007">7</xref>] or ICA [<xref ref-type="bibr" rid="pcbi.1006595.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref028">28</xref>] assume a linear interaction of the components to define a data generation process:
<disp-formula id="pcbi.1006595.e007"><alternatives><graphic id="pcbi.1006595.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="false" scriptlevel="0"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:msub><mml:mo>∑</mml:mo> <mml:mi>h</mml:mi></mml:msub> <mml:msub><mml:mi>s</mml:mi> <mml:mi>h</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>h</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:mo>+</mml:mo> <mml:mspace width="0.166667em"/><mml:mover accent="true"><mml:mi>η</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <inline-formula id="pcbi.1006595.e008"><alternatives><graphic id="pcbi.1006595.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>h</mml:mi></mml:msub> <mml:mo>∈</mml:mo> <mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:math></alternatives></inline-formula> determines the mixing factors for components <inline-formula id="pcbi.1006595.e009"><alternatives><graphic id="pcbi.1006595.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>h</mml:mi></mml:msub></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006595.e010"><alternatives><graphic id="pcbi.1006595.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mover accent="true"><mml:mi>η</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> denotes added noise in the generative process (which usually is assumed to be zero for ICA). However, cochleagrams are a representation of a non-linear interaction between the auditory components, for which a more accurate generative process can be derived from the log-max approximation [<xref ref-type="bibr" rid="pcbi.1006595.ref015">15</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref017">17</xref>]. The log-max approximation implies that the cochleagram of a linear mixture of sound waves can be well approximated by taking the pointwise maximum of cochleagrams computed from the individual waveforms. <xref ref-type="fig" rid="pcbi.1006595.g001">Fig 1</xref> illustrates the approximation based on the cochleagram model used in this study. The example shows a better match by the point-wise maximum than by a linear combination. Hence, based on the approximation, we can define the following probabilistic generative model for cochleagrams:
<disp-formula id="pcbi.1006595.e011"><alternatives><graphic id="pcbi.1006595.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munder><mml:mo>∏</mml:mo> <mml:mi>h</mml:mi></mml:munder> <mml:msup><mml:mi>π</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mi>h</mml:mi></mml:msub></mml:msup> <mml:mspace width="0.166667em"/><mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>π</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:msup> <mml:mphantom><mml:mi>m</mml:mi></mml:mphantom> <mml:mtext>(Bernoulli)</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula> <disp-formula id="pcbi.1006595.e012"><alternatives><graphic id="pcbi.1006595.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>;</mml:mo> <mml:mspace width="4pt"/><mml:munder><mml:mo form="prefix" movablelimits="true">max</mml:mo> <mml:mi>h</mml:mi></mml:munder> <mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>h</mml:mi></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>h</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi mathvariant="normal">I</mml:mi> <mml:mo>)</mml:mo> <mml:mspace width="0.166667em"/><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where the max operation is applied element-wise, i.e., <inline-formula id="pcbi.1006595.e013"><alternatives><graphic id="pcbi.1006595.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mi>h</mml:mi></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>d</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow><mml:mi>h</mml:mi></mml:msub><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, and where I denotes the identity matrix. Here we assume the factors <italic>s</italic><sub><italic>h</italic></sub> ∈ {0, 1} to be Bernoulli distributed, whereas the observed noise is assumed to be Gaussian. Eqs <xref ref-type="disp-formula" rid="pcbi.1006595.e011">2</xref> and <xref ref-type="disp-formula" rid="pcbi.1006595.e012">3</xref> are a version of the MCA generative model [<xref ref-type="bibr" rid="pcbi.1006595.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref020">20</xref>]. Parameters of the model are: the frequency <italic>π</italic> with which a component is activated, the variance of the observation noise <italic>σ</italic><sup>2</sup>, and the generative components or fields <inline-formula id="pcbi.1006595.e014"><alternatives><graphic id="pcbi.1006595.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>h</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, which we will later relate to STRFs. For notational convenience Θ = (<italic>π</italic>, <italic>σ</italic>, <italic>W</italic>) denotes the set of all these parameters.</p>
<p>As a control for later numerical experiments with the MCA model, we will also consider a model assuming a standard linear combination of structural primitives. More concretely, we use a model that shares preprocessing, prior, and noise assumption with the MCA model but uses a linear superposition model instead of the point-wise max:
<disp-formula id="pcbi.1006595.e015"><alternatives><graphic id="pcbi.1006595.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mo>=</mml:mo></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>;</mml:mo> <mml:mspace width="4pt"/><mml:munder><mml:mo>∑</mml:mo> <mml:mi>h</mml:mi></mml:munder> <mml:msub><mml:mi>s</mml:mi> <mml:mi>h</mml:mi></mml:msub> <mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>h</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mi mathvariant="normal">I</mml:mi> <mml:mo>)</mml:mo> <mml:mspace width="0.166667em"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula></p>
<p><xref ref-type="disp-formula" rid="pcbi.1006595.e015">Eq 4</xref> has the standard form of linear sparse coding approaches [<xref ref-type="bibr" rid="pcbi.1006595.ref007">7</xref>], and is because of the prior <xref ref-type="disp-formula" rid="pcbi.1006595.e011">(2)</xref> a form of Binary Sparse Coding (BSC; [<xref ref-type="bibr" rid="pcbi.1006595.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref030">30</xref>]).</p>
</sec>
<sec id="sec007">
<title>Efficient likelihood optimization</title>
<p>Given a set of <italic>N</italic> cochleagrams <inline-formula id="pcbi.1006595.e016"><alternatives><graphic id="pcbi.1006595.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:msub><mml:mrow><mml:mo>{</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>}</mml:mo></mml:mrow> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:mi>N</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> computed as in Section Cochlear model and spectrogram generation., we now seek parameters Θ* that optimally fit the MCA model to the data. We use likelihood maximization to find the optimal parameters and apply an approximate version of expectation maximization (EM; [<xref ref-type="bibr" rid="pcbi.1006595.ref031">31</xref>]) for their efficient estimation.</p>
<p>The application of standard maximum a-posteriori (MAP) based approximations is prohibitively suboptimal for the MCA model because the non-linear interaction of components typically results in multi-modal posteriors. An efficient approximate EM approach which can capture multi-modal posterior structure is, however, provided by Expectation Truncation (ET; [<xref ref-type="bibr" rid="pcbi.1006595.ref020">20</xref>]). ET can be regarded as a variational EM approach, and it has successfully been applied to MCA [<xref ref-type="bibr" rid="pcbi.1006595.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref032">32</xref>] and many other generative models [<xref ref-type="bibr" rid="pcbi.1006595.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref034">34</xref>]. ET approximates the computationally intractable full posterior <inline-formula id="pcbi.1006595.e017"><alternatives><graphic id="pcbi.1006595.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> by a truncated one [<xref ref-type="bibr" rid="pcbi.1006595.ref020">20</xref>]:
<disp-formula id="pcbi.1006595.e018"><alternatives><graphic id="pcbi.1006595.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>;</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∼</mml:mo> <mml:mrow/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mspace width="0.166667em"/><mml:mi>δ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">K</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
where <italic>δ</italic> is an indicator function (i.e., <inline-formula id="pcbi.1006595.e019"><alternatives><graphic id="pcbi.1006595.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:mi>δ</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">K</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> if <inline-formula id="pcbi.1006595.e020"><alternatives><graphic id="pcbi.1006595.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>∈</mml:mo> <mml:msub><mml:mi mathvariant="script">K</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and zero otherwise). If <inline-formula id="pcbi.1006595.e021"><alternatives><graphic id="pcbi.1006595.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:msub><mml:mi mathvariant="script">K</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is chosen to be small but such that it contains the states with most posterior probability mass, the computation of the expectations in <xref ref-type="disp-formula" rid="pcbi.1006595.e018">Eq 5</xref> becomes tractable while a high accuracy of the approximations can be maintained [<xref ref-type="bibr" rid="pcbi.1006595.ref020">20</xref>]. The set <inline-formula id="pcbi.1006595.e022"><alternatives><graphic id="pcbi.1006595.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:msub><mml:mi mathvariant="script">K</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula> is, therefore, chosen to consider the subset of the <italic>H</italic>′ most relevant hidden units for a patch <inline-formula id="pcbi.1006595.e023"><alternatives><graphic id="pcbi.1006595.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>. Furthermore, at most <italic>γ</italic> of these <italic>H</italic>′ units are assumed to be active simultaneously <inline-formula id="pcbi.1006595.e024"><alternatives><graphic id="pcbi.1006595.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>|</mml:mo> <mml:mo>≤</mml:mo> <mml:mi>γ</mml:mi></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Please see Efficient Likelihood Optimization in Supporting Information for a formal definition of <inline-formula id="pcbi.1006595.e025"><alternatives><graphic id="pcbi.1006595.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:msub><mml:mi mathvariant="script">K</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula>.</p>
<p>Parameter update equations for the MCA model have been derived earlier [<xref ref-type="bibr" rid="pcbi.1006595.ref019">19</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref032">32</xref>]. They are given by:
<disp-formula id="pcbi.1006595.e026"><alternatives><graphic id="pcbi.1006595.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e026" xlink:type="simple"/><mml:math display="block" id="M26"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi>W</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>h</mml:mi></mml:mrow> <mml:mrow><mml:mtext>new</mml:mtext></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mstyle displaystyle="true" mathsize="140%"><mml:munder><mml:mo>∑</mml:mo><mml:mi>n</mml:mi></mml:munder></mml:mstyle> <mml:msubsup><mml:mi mathvariant="script">A</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>h</mml:mi></mml:mrow> <mml:mi>ρ</mml:mi></mml:msubsup> <mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mi>W</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msup><mml:mi>q</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msub> <mml:msubsup><mml:mi>y</mml:mi> <mml:mi>d</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow> <mml:mrow><mml:mstyle displaystyle="true" mathsize="140%"><mml:munder><mml:mo>∑</mml:mo><mml:mi>n</mml:mi></mml:munder></mml:mstyle> <mml:msubsup><mml:mi mathvariant="script">A</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>h</mml:mi></mml:mrow> <mml:mi>ρ</mml:mi></mml:msubsup> <mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mi>W</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msup><mml:mi>q</mml:mi> <mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mi mathvariant="script">A</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>h</mml:mi></mml:mrow> <mml:mi>ρ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mi>W</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mfrac><mml:mo>∂</mml:mo> <mml:mrow><mml:mo>∂</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac> <mml:msubsup><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>d</mml:mi> <mml:mi>ρ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mi>W</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>6</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mi>d</mml:mi> <mml:mi>ρ</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mi>W</mml:mi></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mstyle displaystyle="true" mathsize="140%"><mml:munder><mml:mo>∑</mml:mo> <mml:mi>h</mml:mi></mml:munder></mml:mstyle> <mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mi>h</mml:mi></mml:msub> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>d</mml:mi> <mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mi>ρ</mml:mi></mml:msup></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>ρ</mml:mi></mml:mfrac></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>7</mml:mn> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives></disp-formula>
<disp-formula id="pcbi.1006595.e027"><alternatives><graphic id="pcbi.1006595.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e027" xlink:type="simple"/><mml:math display="block" id="M27"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msup><mml:mi>σ</mml:mi> <mml:mtext>new</mml:mtext></mml:msup></mml:mtd> <mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>N</mml:mi> <mml:mi>D</mml:mi></mml:mrow></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>n</mml:mi></mml:munder> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:msup><mml:mrow><mml:mo>∥</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:munder><mml:mtext>max</mml:mtext> <mml:mi>h</mml:mi></mml:munder> <mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>h</mml:mi></mml:msub> <mml:mspace width="0.166667em"/><mml:msub><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mi>h</mml:mi></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>∥</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:msup><mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:msub></mml:mrow></mml:msqrt> <mml:mo>,</mml:mo> <mml:mphantom><mml:mi>i</mml:mi> <mml:mi>i</mml:mi> <mml:mi>i</mml:mi> <mml:mi>i</mml:mi></mml:mphantom> <mml:msup><mml:mi>π</mml:mi> <mml:mtext>new</mml:mtext></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mi>H</mml:mi> <mml:mspace width="0.166667em"/><mml:mi>N</mml:mi></mml:mrow></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mi>n</mml:mi></mml:munder> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:mrow/><mml:mo>|</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mspace width="0.166667em"/><mml:mo>|</mml:mo> <mml:mo>⟩</mml:mo></mml:mrow> <mml:msup><mml:mi>q</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
where the parameter <italic>ρ</italic> in <xref ref-type="disp-formula" rid="pcbi.1006595.e026">Eq 7</xref> is set to a large value (we used <italic>ρ</italic> = 20) and ‖⋅‖ in <xref ref-type="disp-formula" rid="pcbi.1006595.e027">Eq 8</xref> denotes the <italic>L</italic><sub>2</sub>-norm. The learning algorithm for the MCA generative model is thus given by the equations above with expectation values computed w.r.t. the approximate posterior in <xref ref-type="disp-formula" rid="pcbi.1006595.e018">Eq 5</xref>. The linear BSC model, Eqs <xref ref-type="disp-formula" rid="pcbi.1006595.e011">2</xref> and <xref ref-type="disp-formula" rid="pcbi.1006595.e015">4</xref> is trained analogously to the MCA model with parameter update equations as derived earlier (e.g., [<xref ref-type="bibr" rid="pcbi.1006595.ref030">30</xref>]). Please see “Efficient Likelihood Optimization” in Supporting Information for more details.</p>
</sec>
</sec>
<sec id="sec008" sec-type="results">
<title>Results</title>
<sec id="sec009">
<title>Encoding of artificial and natural sounds</title>
<p>We applied our method to male and female anechoic speeches in English, Japanese, Italian, and German. The data also included recordings of natural sounds such as rustling leaves, clattering stones and breaking twigs. More details about the data acquisition procedure are given in Natural Sound Recordings in Supporting Information.</p>
<p>We cut the waveforms of the recordings sampled at 44.1 kHz into snippets of 160 ms with a 32 ms overlap. The snippets were then transformed to cochleagram representations following section “Cochlear Model and Spectrogram Generation”. For the gammatone preprocessing we used a 32−channel filterbank with center frequencies ranging between 1000 and 22050 Hz. In this work we used Slaney’s implementation [<xref ref-type="bibr" rid="pcbi.1006595.ref035">35</xref>] to apply a 4<sup><italic>th</italic></sup> order gammatone filter. The outputs of the filter were averaged over a 20 ms sliding window with a 10 ms step size. The averaged energies were then compressed through the logarithm (as described earlier) to generate 32 × 15 cochleagrams, that is the energy at 32 center frequencies over 15 consecutive time windows.</p>
<p>We applied the MCA learning algorithm using <italic>H</italic> = 1000 generative fields to a set of <italic>N</italic> = 72800 cochleagrams. Individual cochleagrams were normalized by the <italic>L</italic><sub>2</sub>-norm of their energies. To find the maximum likelihood parameters Θ approximately, we performed 70 EM iterations of the ET based learning algorithm described in “Efficient Likelihood Optimization”. The truncation parameters <italic>H</italic>′ and <italic>γ</italic> were set to 10 and 6, respectively. We initialized each of the components in the <italic>W</italic> matrix with the mean of the data perturbed by standard Gaussian noise with zero mean and variance set to 1/4th of the variance of the data.</p>
<p>Parameter <italic>σ</italic> was initialized to the square root of the variance of the data and <italic>π</italic> was set to 30/<italic>H</italic> where <italic>H</italic> = 1000. To minimize the possibility of running into local optima, we applied deterministic simulated annealing [<xref ref-type="bibr" rid="pcbi.1006595.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref037">37</xref>] for the first half of the EM iterations with a linearly decreasing temperature from 10 to 1 (compare [<xref ref-type="bibr" rid="pcbi.1006595.ref020">20</xref>]). As a control, we also trained the linear BSC model analogously to MCA, i.e., using the same data preprocessing and initialization details as for MCA.</p>
<p>
<xref ref-type="fig" rid="pcbi.1006595.g002">Fig 2C</xref> shows 100 of the 1000 learned generative fields after the 70 EM iterations. As can be observed, most of the fields are very localized in time and frequency. The generative fields resulting from applying the BSC model are provided in Supplementary <xref ref-type="supplementary-material" rid="pcbi.1006595.s008">S2 Fig</xref>.</p>
<fig id="pcbi.1006595.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006595.g002</object-id>
<label>Fig 2</label>
<caption>
<title/>
<p><bold>A-C</bold>: Generative fields learned from the spectrograms of the natural sound data. <bold>A-B</bold>: The vertical axis of the fields are gammatone frequencies with lowest frequency band at the bottom and the horizontal axis spans over 160 ms from left to right. Each generative field is displayed as a 32 × 15 matrix. Fields in panels <bold>A-B</bold> were randomly selected. <bold>C</bold>: Every 5<sup><italic>th</italic></sup> of the 500 most-frequently used fields is shown (ordered w.r.t. their marginal posterior probability from left to right and top to bottom). In total <italic>H</italic> = 1000 fields were learned. <bold>D</bold>: STRF estimates corresponding to the generative fields shown in panel <bold>C</bold>. A larger number of most-frequently employed fields can be found in the supplement, <xref ref-type="supplementary-material" rid="pcbi.1006595.s007">S1 Fig</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.g002" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec010">
<title>Neuronal receptive fields and the encoding in the primary auditory cortex</title>
<p>In order to relate the MCA encoding of cochleagrams to neurons in the auditory cortex, we estimate <italic>spectro-temporal receptive fields</italic> (STRFs) from the inference results of the trained MCA model on the natural sound data. In physiological studies, an STRF is the numerically computed estimation of the linear mapping from sound cochleagrams that best predicts a neuron’s response. Similarly we compute STRFs that we consider to be tuned to individual latent components that we learn. To estimate STRFs <inline-formula id="pcbi.1006595.e028"><alternatives><graphic id="pcbi.1006595.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:msup><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup></mml:math></alternatives></inline-formula> for the MCA model, we seek parameters that minimize the following function:
<disp-formula id="pcbi.1006595.e029"><alternatives><graphic id="pcbi.1006595.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>N</mml:mi></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>∈</mml:mo> <mml:mrow/><mml:msub><mml:mi mathvariant="script">K</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:munder> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:mo>|</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mspace width="4pt"/><mml:mo>∥</mml:mo></mml:mrow> <mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:msup><mml:mrow><mml:mo>∥</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mo>λ</mml:mo> <mml:msup><mml:mrow><mml:mo>∥</mml:mo> <mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>∥</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
where <inline-formula id="pcbi.1006595.e030"><alternatives><graphic id="pcbi.1006595.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula> is the <italic>n</italic>th stimuli, <inline-formula id="pcbi.1006595.e031"><alternatives><graphic id="pcbi.1006595.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> is the row-dominated matrix of predicted STRFs, and λ is the coefficient for L2 regularization. Here we assume that the neural response to a stimulus will be a sample from <inline-formula id="pcbi.1006595.e032"><alternatives><graphic id="pcbi.1006595.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:mo>|</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, in which case the experimentally measured STRFs will minimize the squared error between <inline-formula id="pcbi.1006595.e033"><alternatives><graphic id="pcbi.1006595.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006595.e034"><alternatives><graphic id="pcbi.1006595.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:msup><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></alternatives></inline-formula>. Our assumption is consistent with interpreting neural responses as posterior samples [<xref ref-type="bibr" rid="pcbi.1006595.ref038">38</xref>], and the regularization term corresponds to assuming a zero-mean Gaussian hyperprior for the weights (compare ridge regression, e.g., as discussed in [<xref ref-type="bibr" rid="pcbi.1006595.ref039">39</xref>]). The intractable posterior over the latent factors <inline-formula id="pcbi.1006595.e035"><alternatives><graphic id="pcbi.1006595.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:mo>|</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1006595.e029">Eq 9</xref> is truncated to only cover the subspace <inline-formula id="pcbi.1006595.e036"><alternatives><graphic id="pcbi.1006595.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:msub><mml:mi mathvariant="script">K</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:math></alternatives></inline-formula>, as defined by the variational approximation technique in Efficient likelihood optimization. By setting the derivative of the cost function (<xref ref-type="disp-formula" rid="pcbi.1006595.e029">9</xref>) to zero, <inline-formula id="pcbi.1006595.e037"><alternatives><graphic id="pcbi.1006595.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> can be estimated as:
<disp-formula id="pcbi.1006595.e038"><alternatives><graphic id="pcbi.1006595.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e038" xlink:type="simple"/><mml:math display="block" id="M38"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>W</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mo>(</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msub><mml:mrow><mml:mo>⟨</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>⟩</mml:mo></mml:mrow> <mml:msub><mml:mi>q</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mo>λ</mml:mo> <mml:mi>N</mml:mi> <mml:mi mathvariant="normal">I</mml:mi> <mml:mo>+</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
where I is the <italic>D</italic> × <italic>D</italic> identity matrix and where <inline-formula id="pcbi.1006595.e039"><alternatives><graphic id="pcbi.1006595.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mo>·</mml:mo> <mml:mo>〉</mml:mo></mml:mrow> <mml:msub><mml:mi>q</mml:mi> <mml:mi>n</mml:mi></mml:msub></mml:msub></mml:math></alternatives></inline-formula> denotes the expectation value w.r.t. the approximation <inline-formula id="pcbi.1006595.e040"><alternatives><graphic id="pcbi.1006595.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mrow><mml:msub><mml:mi>q</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>;</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> of the posterior <inline-formula id="pcbi.1006595.e041"><alternatives><graphic id="pcbi.1006595.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mspace width="0.166667em"/><mml:mo>|</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> of the MCA model. The additional term λNI results from a <italic>L</italic><sub>2</sub>-regularization for <italic>W</italic> in the cost function. Without regularization, the eigenvalues of the data covariance matrix <inline-formula id="pcbi.1006595.e042"><alternatives><graphic id="pcbi.1006595.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:msub><mml:mo>∑</mml:mo> <mml:mi>n</mml:mi></mml:msub> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>n</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> were frequently very close to zero causing numerical instabilities. For the regularization parameter λ, we empirically found that a value in the mid-range of the minimum and the maximum eigenvalues of the data covariance matrix was sufficient to resolve the numerical instability.</p>
<p>Corresponding to the generative fields shown in <xref ref-type="fig" rid="pcbi.1006595.g002">Fig 2C</xref>, <xref ref-type="fig" rid="pcbi.1006595.g002">Fig 2D</xref> illustrates the STRF estimates computed from <xref ref-type="disp-formula" rid="pcbi.1006595.e038">(10)</xref>. We will refer to these estimates as <italic>model STRFs</italic> from now on. Observe first that many of the model STRFs are localized in time and frequency, a very common feature of receptive fields in the A1 [<xref ref-type="bibr" rid="pcbi.1006595.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref041">41</xref>]. Receptive fields produced by earlier sparse coding models do not as extensively have this punctate character [<xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref043">43</xref>]. Observe also that many of the model STRFs show flanking inhibition both spectrally and temporally, which is likewise a common feature of A1 receptive fields. However, a difference is that receptive fields of auditory cortical neurons tend to show asymmetry in their temporally flanking inhibition, most inhibition being found in the past relative to the excitatory region.</p>
<p>In <xref ref-type="fig" rid="pcbi.1006595.g003">Fig 3</xref> (left) let us first consider 9 exemplary model STRFs, that illustrate various features which are also seen in experimentally recorded A1 STRFs as illustrated on the right-hand-side of <xref ref-type="fig" rid="pcbi.1006595.g003">Fig 3</xref> (for how the STRFs were recorded from ferret cortex and estimated see the Supplement). Reading the <xref ref-type="fig" rid="pcbi.1006595.g003">Fig 3</xref> (left) from left to right, the first unit shows punctate high frequency excitation, the second two units show punctate mid frequency excitation, and the next two units show punctate low frequency excitation. This illustrates that the units’ spectral tuning are spread over the frequency range, as found in physiology, as shown in <xref ref-type="fig" rid="pcbi.1006595.g003">Fig 3</xref> (right). The sixth unit illustrates an upward sweep in frequency, and the seventh a downward sweep. The eighth and ninth units illustrate receptive fields that are spread out over frequency and time respectively. Again these four types of STRF are found in A1, as show in <xref ref-type="fig" rid="pcbi.1006595.g003">Fig 3</xref> (right).</p>
<fig id="pcbi.1006595.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006595.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Example receptive fields from the model (left), and similar receptive fields as recorded in ferret A1 (right).</title>
<p>The times axis is the x-axis and is from -160 to 0 ms (left) and respectively -125 to 0 ms (right). The frequency axis is the y-axis and is from 1000-22050 Hz (left) and respectively 381-35618 Hz (right), in both cases with lowest frequency at the bottom.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.g003" xlink:type="simple"/>
</fig>
<p>To quantitatively compare the model STRFs and auditory cortical STRFs across the population we took 244 experimentally recorded STRFs from Ferret A1 and AAF (taken from [<xref ref-type="bibr" rid="pcbi.1006595.ref045">45</xref>], see Supporting Information: “Neural Recordings and Real STRFs”) and compared them to the most frequently used model STRFs (i.e., to those fields which were the most probable to be activated across all stimuli). For the comparison, a 2D-Fourier transform was applied to each model receptive field and STRF, this provided the modulation transfer function of each receptive field and STRF (3 STRFs were excluded as all their values were zero, see <xref ref-type="sec" rid="sec002">Methods</xref>). Then, for each of the 241 remaining real STRFs and model STRFs the frequency modulation and temporal modulation at which the highest value occurred was taken (the best scale and best rate, respectively). A histogram of distribution of best scale and rate is plotted for the real A1 STRFs in <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4A and 4B</xref> (left), and for the MCA model STRFs in <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4A and 4B</xref> (middle). The histogram for the BSC model STRFs is shown in <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4A and 4B</xref> (right). For <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref> we used (to match the number of neurons we recorded from) the 241 most frequently used model fields, which represent ≈80% of the overall posterior mass for the MCA model. For comparison, the same histogram but using the 600 most frequently used model fields is shown in the Supplementary <xref ref-type="supplementary-material" rid="pcbi.1006595.s009">S3 Fig</xref> (capturing 97% of the posterior mass for the MCA model). <xref ref-type="supplementary-material" rid="pcbi.1006595.s009">S3A Fig</xref> (middle) is similar to <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4A</xref> (middle) but with more model fields at rate zero. The additional fields of <xref ref-type="supplementary-material" rid="pcbi.1006595.s009">Fig S3</xref> which make up the difference to <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref> are, however, four times less likely to be active, which makes <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4A</xref> (middle) more representative for a comparison, see Supplement “Generative Fields and Estimated Model STRFs” for details. In contrast, the histograms for the 241 and the 600 most frequently used BSC fields show comparable percentages of STRFs close to rate zero.</p>
<fig id="pcbi.1006595.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006595.g004</object-id>
<label>Fig 4</label>
<caption>
<title/>
<p><bold>A</bold>: Histogram of best spectral and temporal modulation frequencies for 241 experimentally recorded STRFs (left) and 241 model receptive fields for the MCA and BSC model (middle and right, respectively). 3/244 recorded STRFs were excluded (see <xref ref-type="sec" rid="sec002">Methods</xref>) as they had an L2 norm of zero. Yellow—high density, blue—low density. Histograms are scaled individually to fill the color scale (max is 104 fields for the experimental data, 67 fields for the MCA Model, and 46 fields for the BSC Model). <bold>B</bold>: Histogram shown for a wider range of scales and computed with a bin size of 8 instead of 12 Hz (as used in <bold>A</bold>). Histograms are scaled individually to fill the color scale (max is 78 fields for the experimental data, 36 fields for the MCA Model, and 35 fields for the BSC Model). <bold>C</bold>: For the histograms in <bold>B</bold> a dissimilarity measurement between data and MCA as well as between data and BSC was performed using <italic>χ</italic><sup>2</sup> statistics as described in [<xref ref-type="bibr" rid="pcbi.1006595.ref044">44</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.g004" xlink:type="simple"/>
</fig>
<p>Considering <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref>, observe that the real STRFs and the receptive fields of the MCA model span a similar range of temporal modulations (rates) and a similar range of spectral modulations (scales). Fields tuned to higher scales and fields with higher and lower magnitudes of rate are a bit more frequent for the MCA model than for the experimental data. For the BSC model, the difference of the histogram to the measured data is larger. Significantly more fields have the best rates around zero or at higher magnitudes than the experimental data. The better match of histogram for the MCA model compared to the linear BSC model can be quantified using a <italic>χ</italic><sup>2</sup> test (<xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4C</xref>). In conclusion, the receptive fields of the MCA model and real STRFs span a similar range of temporal modulations (rates) and a similar range of spectral modulations (scales). The model STRFs of the BSC model also span similar ranges of temporal and spectral modulation but this similarity is less pronounced than for the masking-based MCA model.</p>
<p>We also examined the tuning width, over frequency and over time, of the excitatory and inhibitory fields of the real and model STRFs. We used the same most frequently active model fields as for <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref>, and a tuning width measurement method modified from [<xref ref-type="bibr" rid="pcbi.1006595.ref046">46</xref>]. For the measurement of frequency tuning width of the excitatory fields, the negative values of the STRFs were set to zero, then the STRF was squared in an element-wise manner and then the STRF was summed over the time bins to give a weighting vector over frequency bands. The excitatory frequency tuning width was then measured as span of frequencies (in octaves) whose weighting was ≥ 50% of the highest weighted frequency channel. For the measurement of temporal tuning width of the excitatory fields, the negative values of the STRFs were set to zero, then the STRF was squared in an element-wise manner, and then the STRF was summed over frequencies, to give a weighting vector over time bins. The excitatory temporal tuning width was measured as the number of time bins that were ≥ 50% of the maximum value of the resulting vector, multiplied by the time bin size of 10 ms. The inhibitory frequency and temporal tuning widths were measured similarly but instead the positive values of the STRF were set to zero, rather than the negative values. For a visualization of how they are measured see Supplementary <xref ref-type="supplementary-material" rid="pcbi.1006595.s010">S4 Fig</xref>.</p>
<p>Observe that for frequency, for the inhibition and to a lesser extent the excitation, the tuning widths of the MCA model STRFs match relatively well the tuning widths of the STRFs of real neurons. For the temporal dimension we see more strongly diverging properties which may have been expected by considering the statistical modeling approach: Like sparse coding or ICA we do focus on the composition of the data points in terms of structural primitives. Our model itself does not contain statistical dependencies in time unlike hidden Markov models or linear dynamical systems would do. As acoustic data does contain such dependencies on multiple time scales, it is likely that neural processing reflects also these dependencies. The discrepancy of temporal modulation in contrast to frequency modulation may therefore be taken as evidence for the auditory cortex capturing the intricate statistical dependencies over time which neither sparse coding, ICA nor the here studied MCA model addresses. The control experiments using BSC support this interpretation. Also for BSC no asymmetry similar to the one of the measured ferret STRFs is observed. Histograms for BSC computed analogously to <xref ref-type="fig" rid="pcbi.1006595.g005">Fig 5</xref> are given in the Supplementary <xref ref-type="supplementary-material" rid="pcbi.1006595.s011">S5 Fig</xref>. In contrast to the histograms of best modulation frequencies, no notable differences between MCA and BSC histograms were observed.</p>
<fig id="pcbi.1006595.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006595.g005</object-id>
<label>Fig 5</label>
<caption>
<title/>
<p><bold>A</bold>: Distribution over neurons of temporal tuning widths of excitatory fields of the real (pink) and MCA model (grey) neurons. <bold>B</bold>: Distribution of temporal tuning widths of inhibitory fields. <bold>C</bold>: Distribution of frequency tuning widths of excitatory fields. <bold>D</bold>: Distribution of frequency tuning widths of inhibitory fields. For an illustration on how the tuning widths are computed see Supplementary <xref ref-type="supplementary-material" rid="pcbi.1006595.s010">S4 Fig</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.g005" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec011" sec-type="conclusions">
<title>Discussion</title>
<p>We have investigated a computational model of auditory processing of sound waveforms in mammals that respects three key constraints. First, that a linear mixture of waveform components results in a non-linear mixing of cochleagram components, which is well approximated by the log-max non-linearity [<xref ref-type="bibr" rid="pcbi.1006595.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref016">16</xref>]. Second, that the components in the model are positive and sparse. Third, that the statistical model operates on a stimulus closely aligned with biologically processing (cochleagram representation). As such the here followed maximal causes analysis (MCA) approach is arguably a more sensible approach than that provided by linear sparse coding methods that have previously been related to neural STRFs (e.g., [<xref ref-type="bibr" rid="pcbi.1006595.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref047">47</xref>]), and also of non-negative matrix factorization (NMF; [<xref ref-type="bibr" rid="pcbi.1006595.ref048">48</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref049">49</xref>]). Perhaps surprisingly, whilst frequently used for sound processing tasks, to the best of our knowledge NMF has not been related to STRF recordings. In fact a relatively recent contribution explicitly states that NMF “does not allow for STRFs with inhibitory subfields” due to the positivity constraint [<xref ref-type="bibr" rid="pcbi.1006595.ref049">49</xref>].</p>
<sec id="sec012">
<title>Results and predictions</title>
<p>We have shown that the MCA model exhibits a close correspondence to some of the STRF properties of neurons in ferret primary auditory cortex. Like STRFs of the real neurons, the MCA model STRFs show one or a few excitatory regions that are often punctate, being restricted over frequency and often over time. The excitatory regions of the MCA model STRFs are also often flanked by inhibition in frequency and/or time, consistent with real STRFs. The real neurons of our dataset and another ferret cortical dataset [<xref ref-type="bibr" rid="pcbi.1006595.ref050">50</xref>] show diverse STRFs, likewise the MCA model captures a similar diversity of STRFs with some model STRF broadly tuned over frequency or time, some narrowly tuned, some complex with multiple excitatory regions and some directional with diagonally oriented fields. However, the model STRFs do not capture the fact that inhibitory regions that flank in time tend to occur predominately after excitatory regions, rather than on both sides. This is unsurprising as the MCA model does not have the capacity to reflect causal statistical dependencies in time. MCA shares this property with other ICA-like and sparse coding models (including BSC). It may be noteworthy at this point that already in short-time STRFs, such as we use or are often measured in physiology, the limits of approaches that do not explicitly model dependencies in time are apparent. Measurements and analysis of neural responses in the auditory forebrain of birds [<xref ref-type="bibr" rid="pcbi.1006595.ref051">51</xref>] suggest that short-time STRFs do represent regularities important for capturing sound regularities over time. There, different types of STRFs have been linked to the processing of different sound properties such as spectral-pitch, rhythm, timbre or periodicity-pitch. Notably, specific functional roles of broad-band STRFs, and of STRFs with inhibition after excitation as well as STRFs with excitation after inhibition have been discussed in this context [<xref ref-type="bibr" rid="pcbi.1006595.ref051">51</xref>]. Also, the ‘noisy’ type STRFs of Carlin et al [<xref ref-type="bibr" rid="pcbi.1006595.ref050">50</xref>] with very disordered field structure are not notable in the models here considered.</p>
<p>The control model (BSC) produces STRFs with many properties similar to the MCA model, and most quantitative differences are relatively small. A main difference is that whereas the MCA model reproduces fairly well the distribution of best spectral and temporal modulation frequencies of real neurons, albeit somewhat overestimating the span of rates and scales, the BSC model shows significantly greater overestimation. On other measures they are similar. The MCA model captures fairly well the frequency tuning widths of real neurons, if underestimating to a degree, however in this capacity it did not perform noticeably better than the BSC model. Curiously, although in ferret data and our models the distribution of frequency tuning widths appears unimodal, in bird auditory forebrain [<xref ref-type="bibr" rid="pcbi.1006595.ref051">51</xref>] the distribution of frequency tuning widths is bimodal, we speculate as a consequence of the statistics of birdsong. Regarding temporal tuning, birds [<xref ref-type="bibr" rid="pcbi.1006595.ref051">51</xref>], our ferret data, and our models all show apparent unimodal distributions of temporal tuning widths. Both the MCA model and the BSC model substantially overestimate the temporal tuning widths of the STRFs of real neurons, which is again unsurprising as neither model has the capacity to reflect causal statistical dependencies in time.</p>
<p>Furthermore it should be noted that STRFs are far from a complete description of the tuning properties of auditory cortical neurons. Firstly, auditory cortical neurons show many non-linear properties [<xref ref-type="bibr" rid="pcbi.1006595.ref052">52</xref>] such as conjunctive AND-gate-like behavior [<xref ref-type="bibr" rid="pcbi.1006595.ref046">46</xref>], or amplitude modulation phase invariance [<xref ref-type="bibr" rid="pcbi.1006595.ref053">53</xref>]. Secondly, neural tuning properties, including STRFs, can also depend to an extent on stimuli used to gather them [<xref ref-type="bibr" rid="pcbi.1006595.ref045">45</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref054">54</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref059">59</xref>]. Finally, STRFs can also show rapid plasticity depending on the task performed by an awake animal [<xref ref-type="bibr" rid="pcbi.1006595.ref005">5</xref>].</p>
<p>More generally, it is important to acknowledge that comparing normative models such as MCA to real data is difficult and depends on a number of factors including: details of the training corpus, details of different models of preprocessing and details of the STRF estimation. Any of these factors has an influence on quantitative comparisons as those made in this study. For instance, the data used to optimize a statistical model is unlikely to perfectly match the acoustic statistics experienced by the animals used to obtain the experimental data. Or different STRF estimation techniques applied to meet the requirements of experimental recordings or of the used models will effect the quantitative properties of estimated STRFs. Likewise, different preprocessing models (which we have not explored) influence STRF properties (see [<xref ref-type="bibr" rid="pcbi.1006595.ref060">60</xref>] for a discussion), and have also affected previous work on this topic [<xref ref-type="bibr" rid="pcbi.1006595.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>]. Any preprocessing scheme will, however, agree on cochleagrams being representations of acoustic waveform energies in time-frequency intervals. While such representations may be computed by very complex functions, any energy representations will assume non-negative values. Also strong masking non-linearities of the combination of structural primitives within cochleagram representations are widely agreed on in the literature. Notably, although the generative model here considered incorporates the positivity constraint (which we believe is biologically important), the recognition model nevertheless exhibits inhibitory subfields that arise due to explaining away effects among the components. This result indicates, perhaps counter intuitively, that models with positive generative components can still show inhibitory subfields if STRFs for these components’ generative fields are estimated—a finding which has implications beyond the specific model studied here and beyond the auditory system. More precisely, our study shows that inhibitory subfields can be a direct consequence of the statistical model assumed for explaining the data. Even if the data is non-negative and if the used model assumes non-negative generative fields and non-negative latent activities, inhibitory subfields can emerge directly from explaining away effects, without any additional assumptions. Similar to the introductory example, “explaining away” refers to a dependency between alternative explanations for a given stimulus. For our statistical models, possible explanations of a given stimulus take the form of combinations of generative fields (which are typically localized in time and/or frequency). The co-activation of two similar fields is unlikely (because of sparsity) which means that a high probability for one field results in a low probability for the other (and visa versa). <xref ref-type="fig" rid="pcbi.1006595.g006">Fig 6</xref> aims at providing an intuition why inhibitory subfields emerge because of “explaining away”. Note that the fact that inhibitory subfields do emerge is independent, e.g., of the combination rule assumed by the statistical model, i.e., inhibitory subfields can be obtained for non-linear models of generative field combinations (MCA but also, e.g., noisy-OR models [<xref ref-type="bibr" rid="pcbi.1006595.ref061">61</xref>]) as well as for linear models. For the linear BSC model, we verified such an emergence of negative subfields also for non-negative weights by running additional experiments. While the BSC model we used for controls showed essentially positive weights, negative entries close to zero of the <italic>W</italic> matrix could be obtained and were obtained in our experiments. To ensure that negative subfields of STRFs also emerge for non-negative weights, we artificially enforced all <italic>W</italic> entries for BSC to be non-negative in our additional numerical experiments. Also in that case STRF estimation by <xref ref-type="disp-formula" rid="pcbi.1006595.e038">Eq 10</xref> resulted in negative subfields (see Supplement “Efficient Likelihood Optimization” for details).</p>
<fig id="pcbi.1006595.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006595.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Illustration of the emergence of inhibitory subfields.</title>
<p><bold>A</bold>: Feedforward mapping from an input <inline-formula id="pcbi.1006595.e043"><alternatives><graphic id="pcbi.1006595.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula> to two neural units <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub>. The mapping is defined by two receptive fields with only positive entries. In this case, any strong activation of unit <italic>s</italic><sub>2</sub> does not negatively effect unit <italic>s</italic><sub>1</sub>. For overlapping positive subfields, a stronger activation of <italic>s</italic><sub>2</sub> will even result in a stronger activation of <italic>s</italic><sub>1</sub> as well. <bold>B</bold>: Activations of neural units <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub> according to a statistical model with non-negative generative fields (GFs). Both units compete to explain a presented input <inline-formula id="pcbi.1006595.e044"><alternatives><graphic id="pcbi.1006595.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover></mml:math></alternatives></inline-formula>. A high probability for <italic>s</italic><sub>2</sub> decreases the probability of <italic>s</italic><sub>1</sub> and vica versa. This effect is known as “explaining away”, and it depends on the assumed model including the model for the combination of primitives, noise model, and prior. <bold>C</bold>: Illustration of an optimal feedforward mapping to approximate neural responses according to the statistical model in <bold>B</bold>. The stronger mutual suppression caused by explaining away is approximated by the introduction of inhibitory subfields. If the input is, e.g., now made stronger or less diffuse, then unit <italic>s</italic><sub>2</sub> can increase while unit <italic>s</italic><sub>1</sub> can simultaneously decrease, which is in accordance with probabilistic inference for a statistical model. <bold>D</bold>: Example of STRFs estimated from artificial data. The top row shows non-negative GFs. If the corresponding STRFs are now estimated using <xref ref-type="disp-formula" rid="pcbi.1006595.e038">Eq 10</xref>, then negative subfields emerge (bottom row). For fields which do compete little with other fields (e.g., field three) the effect is the weakest. The strongest effects are observed for fields with large overlap (e.g. fields four and six). In general, explaining away effects increase with overcompleteness, i.e., with the number of GFs compared to input size. Color scales for all subfigures as in <xref ref-type="fig" rid="pcbi.1006595.g002">Fig 2A</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.g006" xlink:type="simple"/>
</fig>
<p>If measured inhibitory subfields are a consequence of explaining away, then their shapes and the predicted dependencies among hidden neurons change depending on the assumed statistical model. By providing strong evidence for inhibitory subfields to be solely obtainable as a consequence of explaining away, our study offers novel ways of neuro-physiologically evaluating statistical models of neural processing.</p>
<p>Here we have compared spectral and temporal modulation as well as temporal and frequency tuning in order to compare different statistical models with data. Comparison of models is made difficult due to the above discussed factors. Significant differences of predicted STRFs can, nevertheless, be obtained if directly comparing statistical models with and without masking non-linearity (e.g., <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref>) while all other model properties, training, and preprocessing remained fixed. A step further in the direction of neural evaluation would be represented by a direct <italic>in vivo</italic> comparison of neural responses to specifically designed stimuli. Given a set of neurons with previously measured STRFs, their responses could be predicted based on different statistical models. These different models will predict different response distributions, and artificial stimuli could be designed to be maximally discriminative between any two statistical models. Based on the results of this study, we predict responses for neurons in A1 which compete to explain an acoustic stimulus to <italic>not</italic> show a linear anti-correlation (as predicted by linear models). Explaining away resulting from a masking-based model (such as MCA), in contrast, would predict that neurons explaining the same stimulus compete rather in a k-winner-take-all manner, i.e., small sets of neurons suppress activity in the other neurons with only the maximally active neuron being relevant. For a comparison of explaining away effects between linear models and MCA see e.g. [<xref ref-type="bibr" rid="pcbi.1006595.ref062">62</xref>], for k-winner-take-all neural circuits see e.g. [<xref ref-type="bibr" rid="pcbi.1006595.ref063">63</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref064">64</xref>]. In this context, let us, furthermore, remark that any neural activity distribution predicated by a model will not only depend on the model for generative field combinations but also on assumed priors, noise model and on the applied approximate inference approach. Furthermore, it will be important which variables of the model are assumed to match any measured neural activity best. Progress in neural recordings, simultaneous recording and stimulus generation, and refined neural modeling may make a direct comparison of statistical models feasible in the intermediate future.</p>
</sec>
<sec id="sec013">
<title>Comparison to other normative models</title>
<p>A number of normative approaches have been taken to understand auditory spectro-temporal receptive fields as a consequence of stimulus statistics (e.g. [<xref ref-type="bibr" rid="pcbi.1006595.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref050">50</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref065">65</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref066">66</xref>]). Before discussing similarities and differences in relation to the models used here, let us stress that the capturing of stimulus statistics is not the only constraint of importance governing the structure of the nervous system. Biophysical constraints such as energy costs or wiring length are also important, as well as other functional constraints such as the role of particular sounds in an animal’s behavior.</p>
<p>Among the stimulus-statistics-based models, the most common approach has been the encoding of spectrogram-like representations of natural sounds subject to a sparsity constraint on the activity of the encoding units. Some sparse normative models balance a constraint for sparsity (or temporal slowness, [<xref ref-type="bibr" rid="pcbi.1006595.ref050">50</xref>]) while forcing dispersal [<xref ref-type="bibr" rid="pcbi.1006595.ref043">43</xref>] or decorrelation [<xref ref-type="bibr" rid="pcbi.1006595.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref050">50</xref>] between the unit responses, and then learn the encoding receptive fields. More relevant for our study are those models which demand sparsity of unit responses while also generatively estimating the spectrograms from the unit activity via learned generative fields [<xref ref-type="bibr" rid="pcbi.1006595.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref047">47</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref065">65</xref>]. All the above sparsity and slowness models show some capacity to capture certain characteristics of STRFs. We have made explicit comparison of our model to a linear sparse model in the results (<xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref>), as it is the standard leading normative model of sensory coding, and we indicate the particular strengths of our model. The model of Carlin et al. [<xref ref-type="bibr" rid="pcbi.1006595.ref050">50</xref>] is less directly comparable to our model as it does not involve an explicit generative model. While it does in some ways better explain auditory cortical STRFs than a sparse coding model, it is clear that the MCA model captures certain aspects of the neural data that the slowness model of Carlin et al. does not address. Notably, the Carlin et al. model shows a near uniform distribution of best scales up to 2.5 cycles/octave, this is in contrast to our neural data (and that of Carlin et al.) and the MCA model where the density decays as scale increases (<xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref>).</p>
<p>In general, masking-based non-linearities, i.e., the dominance of one source in any time-frequency bin, is a property of acoustic data that has frequently been used for acoustic data processing (e.g. [<xref ref-type="bibr" rid="pcbi.1006595.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref067">67</xref>]). In contrast, however, for the task of generatively explaining acoustic data by statistically learned structural primitives, almost all contributions in the literature rely on standard linear models. This applies for studies with functional focus (e.g., NMF-like [<xref ref-type="bibr" rid="pcbi.1006595.ref068">68</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref069">69</xref>]) as well as for studies explaining neural response properties [<xref ref-type="bibr" rid="pcbi.1006595.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref065">65</xref>]. The main reason for this strong focus on linear models is presumably related to the challenge of scaling strongly non-linear models to the large sizes required for sensory data. While linear models, e.g. for visual data, are routinely used with hundreds of generative fields / basis functions since about two decades [<xref ref-type="bibr" rid="pcbi.1006595.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref070">70</xref>–<xref ref-type="bibr" rid="pcbi.1006595.ref072">72</xref>], non-linear models have been trained at large scales only relatively recently [<xref ref-type="bibr" rid="pcbi.1006595.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref062">62</xref>]. Earlier non-linear models, e.g., based on a noisy-OR non-linearity [<xref ref-type="bibr" rid="pcbi.1006595.ref061">61</xref>] or the maximum [<xref ref-type="bibr" rid="pcbi.1006595.ref019">19</xref>], have not been sufficiently efficient for learning with large numbers of generative fields.</p>
<p>While the approach used here does model masking, we do (as discussed above) not employ a statistical model that captures regularities in time. Other approaches do consider this important aspect of neural processing [<xref ref-type="bibr" rid="pcbi.1006595.ref066">66</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref073">73</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref074">74</xref>] e.g., to model longer term amplitude modulation structure of acoustic signals [<xref ref-type="bibr" rid="pcbi.1006595.ref073">73</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref074">74</xref>]. Moreover, incorporating additional temporal statistical regularities is clearly important for acoustic synthesis [<xref ref-type="bibr" rid="pcbi.1006595.ref075">75</xref>] and might therefore be expected to have a strong effect on the neural representation of sound.</p>
<p>Among the approaches using assumptions formulated in terms of a statistical model, recent work by Yildiz et al. [<xref ref-type="bibr" rid="pcbi.1006595.ref047">47</xref>] is closely related to the linear models used in our study. That study, like our approach, seeks to explain acoustic stimuli by combinations of structural primitives. The focus by Yildiz et al. is a specific neural circuit implementation for probabilistic inference and learning. The derivation of the neural circuit relies on a <italic>mean field</italic> approximation for efficient inference, an adaptive Markovian dynamics, and a divisive inhibitory interaction among neurons representing structural primitives. The interaction of these mechanisms are shown to result in a stimulus representation with the underlying goal of providing a Bayes optimal explanation using combinations of learned generative fields. While this goal is shared with our approach, the assumed linear combination of primitives is the crucial difference of Yildiz et al. 2016 to our non-linear approach, i.e., they do not model masking. The generative data model underlying Yildiz et al. consequently more closely corresponds to the Binary Sparse Coding (BSC) model which we used as a control (Eqs <xref ref-type="disp-formula" rid="pcbi.1006595.e011">2</xref> and <xref ref-type="disp-formula" rid="pcbi.1006595.e015">4</xref>). However, while Yildiz et al. infer STRFs from the circuit approximation of probabilistic inference, the results of <xref ref-type="supplementary-material" rid="pcbi.1006595.s008">S2 Fig</xref> of our study are based on directly inferring model STRFs from the linear BSC model itself. This makes the emergence of inhibitory subfields a direct consequence of the used generative data model, while Yildiz et al. first motivate a divisive form of inhibition to implement approximate probabilistic inference by their suggested circuit. On the other hand, both the here presented study and the study by Yildiz et al., 2016, provide evidence for auditory STRFs emerging from probabilistic inference and learning. Also both studies may be regarded as providing evidence for inhibitory subfields being a consequence of explaining away effects, as first hypothesizes by preliminary results obtained for our study [<xref ref-type="bibr" rid="pcbi.1006595.ref076">76</xref>]. In terms of concrete neural circuits that may realize such inference and learning, the study by Yildiz et al. 2016 goes very significantly beyond the research questions addressed here. On the other hand, in terms of showing that inhibitory subfields are a direct consequence of probabilistic inference, and in terms of using such fields to discriminate between different statistical models, our study significantly goes beyond the work by Yildiz et al. 2016.</p>
<p>Finally, note further technical but potentially import differences of approximate probabilistic inference applied to our and related approaches. The dominating approach for learning representations in terms of structural primitives are <italic>maximum a posteriori</italic> (MAP) approximations [<xref ref-type="bibr" rid="pcbi.1006595.ref007">7</xref>], i.e., the stimulus is represented by the latent state (i.e., by the neuron activities) with the highest posterior probability (highest <inline-formula id="pcbi.1006595.e045"><alternatives><graphic id="pcbi.1006595.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006595.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>→</mml:mo></mml:mover><mml:mo>|</mml:mo><mml:mover accent="true"><mml:mi>y</mml:mi> <mml:mo>→</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mo>Θ</mml:mo> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> in our case). MAP approximations are both scalable and relatively straight-forward to apply, which makes them being very frequently used also for statistical models of acoustic data (e.g., [<xref ref-type="bibr" rid="pcbi.1006595.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref009">9</xref>]). However, with only maintaining the most probable hidden state for inference, no rich posterior structure is represented: neither correlations, multiple-modes nor any other type of the here very important explaining away effects is captured. In contrast, for our study and for other recent approaches (e.g., [<xref ref-type="bibr" rid="pcbi.1006595.ref047">47</xref>]) richer posterior representations play an important role. The observation that no previous study using MAP approximations has related inhibitory subfields of STRFs to explaining away effects, indicates that richer posterior representations seem to be required. However, while Yildiz et al. [<xref ref-type="bibr" rid="pcbi.1006595.ref047">47</xref>] as well as the BSC model used here maintain non-trivial posterior structures, the types of approximations used are different. Yildiz et al. 2016 employ a fully factored variational approximation (i.e., mean field). Such an approximation essentially assumes <italic>a posteriori</italic> independence of neural units, which has (given a stimulus) a direct impact on the activity dependencies among the stimulus encoding neurons. In contrast, the BSC model (as well as the MCA model) uses a truncated EM approximation which does <italic>not</italic> assume <italic>a posteriori</italic> independence [<xref ref-type="bibr" rid="pcbi.1006595.ref020">20</xref>]. The <italic>a posteriori</italic> independence of mean field has been criticized for introducing biases during learning [<xref ref-type="bibr" rid="pcbi.1006595.ref077">77</xref>, <xref ref-type="bibr" rid="pcbi.1006595.ref078">78</xref>] while approaches that use truncated EM instead have been favorably compared with mean field [<xref ref-type="bibr" rid="pcbi.1006595.ref034">34</xref>].</p>
</sec>
<sec id="sec014">
<title>Conclusion</title>
<p>To summarize, we have here shown that statistical models reflecting challenging data properties such as masking-based combinations of structural primitives and non-negativity are applicable to complex sensory data such as cochleagrams. Furthermore, we have found that inhibitory subfields of estimated model STRFs can directly emerge from explaining away effects of the assumed statistical model. This observation may lead to novel tools for the investigation of assumptions underlying probabilistic inference in the auditory cortex, in other sensory areas, and beyond.</p>
</sec>
</sec>
<sec id="sec015">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006595.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s001" xlink:type="simple">
<label>S1 File</label>
<caption>
<title>Details about the Methods and Results sections can be found in this file.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s002" mimetype="text/plain" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s002" xlink:type="simple">
<label>S2 File</label>
<caption>
<title>File descriptions and Matlab code can be found in this file.</title>
<p>(TXT)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s003" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s003" xlink:type="simple">
<label>S3 File</label>
<caption>
<title>MCA generative fields can be found in this file.</title>
<p>(MAT)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s004" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s004" xlink:type="simple">
<label>S4 File</label>
<caption>
<title>STRF estimates of MCA can be found in this file.</title>
<p>(MAT)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s005" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s005" xlink:type="simple">
<label>S5 File</label>
<caption>
<title>Generative fields and STRF estimates of the BSC model can be found in this file.</title>
<p>(MAT)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s006" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s006" xlink:type="simple">
<label>S6 File</label>
<caption>
<title>STRF estimates based on measurements in A1 of ferrets can be found in this file.</title>
<p>(MAT)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s007" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s007" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>600 most-frequently used generative and corresponding receptive field estimates obtained with the MCA model.</title>
<p>600 most-frequently used generative and corresponding receptive field estimates obtained with the MCA model. The fields are ordered w.r.t. their marginal posterior probability from left to right and top to bottom.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s008" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s008" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>600 most-frequently used generative and corresponding receptive field estimates obtained with the BSC model.</title>
<p>600 most-frequently used generative and corresponding receptive field estimates obtained with the BSC model. The fields are ordered w.r.t. their marginal posterior probability from left to right and top to bottom.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s009" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s009" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>Histogram of best spectral and temporal modulation frequencies for experimentally recorded STRFs and BSC model receptive fields.</title>
<p>Histogram of best spectral and temporal modulation frequencies for all the 600 model receptive fields shown in <xref ref-type="supplementary-material" rid="pcbi.1006595.s007">S1 Fig</xref> (left) and <xref ref-type="supplementary-material" rid="pcbi.1006595.s008">S2 Fig</xref> (left), respectively. Model receptive fields were analyzed as in <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref> with the same set of measured STRFs for comparison (panel <bold>B</bold> left). Note different y-axis scale in <bold>C</bold>. Color legend as in <xref ref-type="fig" rid="pcbi.1006595.g004">Fig 4</xref>: In <bold>A</bold> max equal to 141 for MCA and 123 for BSC. In <bold>B</bold> max equal to 85 for MCA and 87 for BSC.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s010" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s010" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Measuring tuning width.</title>
<p>Measuring tuning width for <xref ref-type="fig" rid="pcbi.1006595.g005">Fig 5</xref>. <bold>A</bold>: To measure frequency tuning width for the excitatory part of the STRF first an STRF is taken. <bold>B</bold>: Then STRF is element-wise positively rectified and then squared. <bold>C</bold>: Finally the rectified squared STRF is summed over time, and the (not necessarily contiguous) span above half the height is measured to give the frequency tuning width. The frequency tuning width of the inhibitory part is measured the same way, but using negative rectification instead of positive rectification. The temporal tuning width of the excitatory or inhibitory part of the STRF is measured the same way, but with summing over frequency rather than time, and using positive or negative rectification accordingly.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006595.s011" mimetype="application/eps" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006595.s011" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Distribution over experimentally recorded and BSC model neurons of temporal and frequency tuning widths.</title>
<p><bold>A</bold>: Distribution over neurons of temporal tuning widths of excitatory fields of the real (pink) and BSC model (grey) neurons. <bold>B</bold>: Distribution of temporal tuning widths of inhibitory fields. <bold>C</bold>: Distribution of frequency tuning widths of excitatory fields. <bold>D</bold>: Distribution of frequency tuning widths of inhibitory fields.</p>
<p>(EPS)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ref-list>
<title>References</title>
<ref id="pcbi.1006595.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Młynarski</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>McDermott</surname> <given-names>JH</given-names></name>. <article-title>Learning midlevel auditory codes from natural sound statistics</article-title>. <source>Neural Computation</source>. <year>2018</year>;<volume>30</volume>(<issue>3</issue>):<fpage>631</fpage>–<lpage>669</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco_a_01048" xlink:type="simple">10.1162/neco_a_01048</ext-link></comment> <object-id pub-id-type="pmid">29220308</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Christopher deCharms</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Blake</surname> <given-names>DT</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Optimizing sound features for cortical neurons</article-title>. <source>Science</source>. <year>1998</year>;<volume>280</volume>(<issue>5368</issue>):<fpage>1439</fpage>–<lpage>1444</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.280.5368.1439" xlink:type="simple">10.1126/science.280.5368.1439</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Liu</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Spectrotemporal structure of receptive fields in areas AI and AAF of mouse auditory cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2003</year>;<volume>90</volume>(<issue>4</issue>):<fpage>2660</fpage>–<lpage>2675</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00751.2002" xlink:type="simple">10.1152/jn.00751.2002</ext-link></comment> <object-id pub-id-type="pmid">12815016</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Miller</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Escabí</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Read</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Spectrotemporal receptive fields in the lemniscal auditory thalamus and cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2002</year>;<volume>87</volume>(<issue>1</issue>):<fpage>516</fpage>–<lpage>527</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00395.2001" xlink:type="simple">10.1152/jn.00395.2001</ext-link></comment> <object-id pub-id-type="pmid">11784767</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fritz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>D</given-names></name>. <article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title>. <source>Nature neuroscience</source>. <year>2003</year>;<volume>6</volume>(<issue>11</issue>):<fpage>1216</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1141" xlink:type="simple">10.1038/nn1141</ext-link></comment> <object-id pub-id-type="pmid">14583754</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gourévitch</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Noreña</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Shaw</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Eggermont</surname> <given-names>JJ</given-names></name>. <article-title>Spectrotemporal receptive fields in anesthetized cat primary auditory cortex are context dependent</article-title>. <source>Cerebral Cortex</source>. <year>2008</year>;<volume>19</volume>(<issue>6</issue>):<fpage>1448</fpage>–<lpage>1461</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhn184" xlink:type="simple">10.1093/cercor/bhn184</ext-link></comment> <object-id pub-id-type="pmid">18854580</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Olshausen</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>D</given-names></name>. <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source>. <year>1996</year>;<volume>381</volume>:<fpage>607</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/381607a0" xlink:type="simple">10.1038/381607a0</ext-link></comment> <object-id pub-id-type="pmid">8637596</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref008">
<label>8</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Saxe</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Bhand</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mudur</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Suresh</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Ng</surname> <given-names>AY</given-names></name>. <chapter-title>Unsupervised learning models of primary cortical receptive fields and receptive field plasticity</chapter-title>. In: <name name-style="western"><surname>Shawe-Taylor</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Zemel</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Bartlett</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Pereira</surname> <given-names>FCN</given-names></name>, <name name-style="western"><surname>Weinberger</surname> <given-names>KQ</given-names></name>, editors. <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 24</volume>; <year>2011</year>. p. <fpage>1971</fpage>–<lpage>1979</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carlson</surname> <given-names>NL</given-names></name>, <name name-style="western"><surname>Ming</surname> <given-names>VL</given-names></name>, <name name-style="western"><surname>DeWeese</surname> <given-names>MR</given-names></name>. <article-title>Sparse codes for speech predict spectrotemporal receptive fields in the inferior colliculus</article-title>. <source>PLoS Computational Biology</source>. <year>2012</year>;<volume>8</volume>(<issue>7</issue>):<fpage>e1002594</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002594" xlink:type="simple">10.1371/journal.pcbi.1002594</ext-link></comment> <object-id pub-id-type="pmid">22807665</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>, <name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>. <article-title>Natural image statistics and neural representation</article-title>. <source>Annual review of neuroscience</source>. <year>2001</year>;<volume>24</volume>(<issue>1</issue>):<fpage>1193</fpage>–<lpage>1216</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.neuro.24.1.1193" xlink:type="simple">10.1146/annurev.neuro.24.1.1193</ext-link></comment> <object-id pub-id-type="pmid">11520932</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wen</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>GI</given-names></name>, <name name-style="western"><surname>Dean</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Delgutte</surname> <given-names>B</given-names></name>. <article-title>Dynamic range adaptation to sound level statistics in the auditory nerve</article-title>. <source>Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>44</issue>):<fpage>13797</fpage>–<lpage>13808</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.5610-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5610-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19889991</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wen</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>GI</given-names></name>, <name name-style="western"><surname>Dean</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Delgutte</surname> <given-names>B</given-names></name>. <article-title>Time course of dynamic range adaptation in the auditory nerve</article-title>. <source>Journal of Neurophysiology</source>. <year>2012</year>;<volume>108</volume>(<issue>1</issue>):<fpage>69</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00055.2012" xlink:type="simple">10.1152/jn.00055.2012</ext-link></comment> <object-id pub-id-type="pmid">22457465</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dean</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>McAlpine</surname> <given-names>D</given-names></name>. <article-title>Neural population coding of sound level adapts to stimulus statistics</article-title>. <source>Nature Neuroscience</source>. <year>2005</year>;<volume>8</volume>(<issue>12</issue>):<fpage>1684</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1541" xlink:type="simple">10.1038/nn1541</ext-link></comment> <object-id pub-id-type="pmid">16286934</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dean</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>BL</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>McAlpine</surname> <given-names>D</given-names></name>. <article-title>Rapid neural adaptation to sound level statistics</article-title>. <source>Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>25</issue>):<fpage>6430</fpage>–<lpage>6438</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.0470-08.2008" xlink:type="simple">10.1523/JNEUROSCI.0470-08.2008</ext-link></comment> <object-id pub-id-type="pmid">18562614</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref015">
<label>15</label>
<mixed-citation publication-type="other" xlink:type="simple">Varga AP, Moore RK. Hidden markov model decomposition of speech and noise. In: ICASSP. IEEE Press; 1990. p. 845–848.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref016">
<label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Roweis</surname> <given-names>ST</given-names></name>. <chapter-title>Factorial models and refiltering for speech separation and denoising</chapter-title>. In: <source>Proc. Eurospeech</source>. <volume>vol. 7</volume>; <year>2003</year>. p. <fpage>1009</fpage>–<lpage>1012</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref017">
<label>17</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Brown</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>D</given-names></name>. <chapter-title>Separation of Speech by Computational Auditory Scene Analysis</chapter-title>. In: <source>Speech Enhancement. Signals and Communication Technology</source>. <publisher-name>Springer</publisher-name> <publisher-loc>Berlin Heidelberg</publisher-loc>; <year>2005</year>. p. <fpage>371</fpage>–<lpage>402</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref018">
<label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Ma N, Barker J. Coupling identification and reconstruction of missing features for noise-robust automatic speech recognition. Proceedings of INTERSPEECH. 2012;p. 2638–2641.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <article-title>Maximal Causes for Non-linear Component Extraction</article-title>. <source>Journal of Machine Learning Research</source>. <year>2008</year>;<volume>9</volume>:<fpage>1227</fpage>–<lpage>67</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Eggert</surname> <given-names>J</given-names></name>. <article-title>Expectation Truncation And the Benefits of Preselection in Training Generative Models</article-title>. <source>Journal of Machine Learning Research</source>. <year>2010</year>;<volume>11</volume>:<fpage>2855</fpage>–<lpage>900</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bornschein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Henniges</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>. <article-title>Are V1 receptive fields shaped by low-level visual occlusions? A comparative study</article-title>. <source>PLOS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>6</issue>):<fpage>e1003062</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003062" xlink:type="simple">10.1371/journal.pcbi.1003062</ext-link></comment> <object-id pub-id-type="pmid">23754938</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shelton</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Gasthaus</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dai</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gretton</surname> <given-names>A</given-names></name>. <article-title>GP-select: Accelerating EM using adaptive subspace preselection</article-title>. <source>Neural Computation</source>. <year>2017</year>;<volume>29</volume>(<issue>8</issue>):<fpage>2177</fpage>–<lpage>2202</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/NECO_a_00982" xlink:type="simple">10.1162/NECO_a_00982</ext-link></comment> <object-id pub-id-type="pmid">28562214</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref023">
<label>23</label>
<mixed-citation publication-type="other" xlink:type="simple">Johannesma P. The pre-response stimulus ensemble of neurons in the cochlear nucleus. In: Symposium on Hearing Theory; 1972.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Meddis</surname> <given-names>R</given-names></name>. <article-title>Simulation of mechanical to neural transduction in the auditory receptor</article-title>. <source>The Journal of the Acoustical Society of America</source>. <year>1986</year>;<volume>79</volume>:<fpage>702</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1121/1.393460" xlink:type="simple">10.1121/1.393460</ext-link></comment> <object-id pub-id-type="pmid">2870094</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hohmann</surname> <given-names>V</given-names></name>. <article-title>Frequency analysis and synthesis using a Gammatone filterbank</article-title>. <source>Acta Acustica United with Acustica</source>. <year>2002</year>;<volume>88</volume>(<issue>3</issue>):<fpage>433</fpage>–<lpage>442</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Glasberg</surname> <given-names>BR</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>BC</given-names></name>. <article-title>Derivation of auditory filter shapes from notched-noise data</article-title>. <source>Hearing research</source>. <year>1990</year>;<volume>47</volume>(<issue>1</issue>):<fpage>103</fpage>–<lpage>138</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0378-5955(90)90170-T" xlink:type="simple">10.1016/0378-5955(90)90170-T</ext-link></comment> <object-id pub-id-type="pmid">2228789</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bell</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>The “independent components” of natural scenes are edge filters</article-title>. <source>Vision Research</source>. <year>1997</year>;<volume>37</volume>(<issue>23</issue>):<fpage>3327</fpage>–<lpage>38</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(97)00121-1" xlink:type="simple">10.1016/S0042-6989(97)00121-1</ext-link></comment> <object-id pub-id-type="pmid">9425547</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hyvärinen</surname> <given-names>A</given-names></name>. <article-title>Fast and robust fixed-point algorithms for independent component analysis</article-title>. <source>IEEE transactions on Neural Networks</source>. <year>1999</year>;<volume>10</volume>(<issue>3</issue>):<fpage>626</fpage>–<lpage>634</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/72.761722" xlink:type="simple">10.1109/72.761722</ext-link></comment> <object-id pub-id-type="pmid">18252563</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haft</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hofman</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Tresp</surname> <given-names>V</given-names></name>. <article-title>Generative binary codes</article-title>. <source>Pattern Anal Appl</source>. <year>2004</year>;<volume>6</volume>:<fpage>269</fpage>–<lpage>84</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10044-003-0194-x" xlink:type="simple">10.1007/s10044-003-0194-x</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref030">
<label>30</label>
<mixed-citation publication-type="other" xlink:type="simple">Henniges M, Puertas G, Bornschein J, Eggert J, Lücke J. Binary Sparse Coding. In: Proceedings LVA/ICA. LNCS 6365. Springer; 2010. p. 450–57.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dempster</surname> <given-names>AP</given-names></name>, <name name-style="western"><surname>Laird</surname> <given-names>NM</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <article-title>Maximum Likelihood from Incomplete Data via the EM Algorithm (with discussion)</article-title>. <source>Journal of the Royal Statistical Society B</source>. <year>1977</year>;<volume>39</volume>:<fpage>1</fpage>–<lpage>38</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref032">
<label>32</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Puertas</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Bornschein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>. <chapter-title>The Maximal Causes of Natural Scenes are Edge Filters</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 23</volume>; <year>2010</year>. p. <fpage>1939</fpage>–<lpage>1947</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dai</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>. <article-title>Autonomous Document Cleaning—A Generative Approach to Reconstruct Strongly Corrupted Scanned Texts</article-title>. <source>IEEE Transactions on Pattern Analysis and Machine Intelligence</source>. <year>2014</year>;<volume>36</volume>(<issue>10</issue>):<fpage>1950</fpage>–<lpage>1962</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TPAMI.2014.2313126" xlink:type="simple">10.1109/TPAMI.2014.2313126</ext-link></comment> <object-id pub-id-type="pmid">26352627</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sheikh</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Shelton</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>. <article-title>A Truncated EM Approach for Spike-and-Slab Sparse Coding</article-title>. <source>Journal of Machine Learning Research</source>. <year>2014</year>;<volume>15</volume>:<fpage>2653</fpage>–<lpage>2687</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Slaney</surname> <given-names>M</given-names></name>. <article-title>Auditory toolbox</article-title>. <source>Interval Research Corporation, Tech Rep</source>. <year>1998</year>;<volume>10</volume>:<fpage>1998</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ueda</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Nakano</surname> <given-names>R</given-names></name>. <article-title>Deterministic annealing EM algorithm</article-title>. <source>Neural Networks</source>. <year>1998</year>;<volume>11</volume>(<issue>2</issue>):<fpage>271</fpage>–<lpage>82</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0893-6080(97)00133-0" xlink:type="simple">10.1016/S0893-6080(97)00133-0</ext-link></comment> <object-id pub-id-type="pmid">12662837</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref037">
<label>37</label>
<mixed-citation publication-type="other" xlink:type="simple">Sahani M. Latent variable models for neural data analysis. PhD Thesis. Caltech; 1999.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fiser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Berkes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Orban</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Lengyel</surname> <given-names>M</given-names></name>. <article-title>Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source>Trends in Cognitive Science</source>. <year>2010</year>;<volume>14</volume>:<fpage>119</fpage>–<lpage>130</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2010.01.003" xlink:type="simple">10.1016/j.tics.2010.01.003</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Park</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>. <article-title>Receptive Field Inference with Localized Priors</article-title>. <source>PLOS Computational Biology</source>. <year>2011</year> <month>10</month>;<volume>7</volume>(<issue>10</issue>):<fpage>1</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002219" xlink:type="simple">10.1371/journal.pcbi.1002219</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Depireux</surname> <given-names>DA</given-names></name>, <name name-style="western"><surname>Simon</surname> <given-names>JZ</given-names></name>, <name name-style="western"><surname>Klein</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Shamma</surname> <given-names>SA</given-names></name>. <article-title>Spectro-temporal response field characterization with dynamic ripples in ferret primary auditory cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2001</year>;<volume>85</volume>(<issue>3</issue>):<fpage>1220</fpage>–<lpage>1234</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.2001.85.3.1220" xlink:type="simple">10.1152/jn.2001.85.3.1220</ext-link></comment> <object-id pub-id-type="pmid">11247991</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Miller</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>Pinto</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Simons</surname> <given-names>DJ</given-names></name>. <article-title>Processing in layer 4 of the neocortical circuit: new insights from visual and somatosensory cortex</article-title>. <source>Current Opinion in Neurobiology</source>. <year>2001</year>;<volume>11</volume>:<fpage>488</fpage>–<lpage>497</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0959-4388(00)00239-7" xlink:type="simple">10.1016/S0959-4388(00)00239-7</ext-link></comment> <object-id pub-id-type="pmid">11502397</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Klein</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>König</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Körding</surname> <given-names>KP</given-names></name>. <article-title>Sparse spectrotemporal coding of sounds</article-title>. <source>EURASIP Journal on Advances in Signal Processing</source>. <year>2003</year>;(<issue>7</issue>):<fpage>659</fpage>–<lpage>667</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kozlov</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Gentner</surname> <given-names>TQ</given-names></name>. <article-title>Central auditory neurons have composite receptive fields</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2016</year>;<volume>113</volume>(<issue>5</issue>):<fpage>1441</fpage>–<lpage>1446</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1506903113" xlink:type="simple">10.1073/pnas.1506903113</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rubner</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Tomasi</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Guibas</surname> <given-names>LJ</given-names></name>. <article-title>The Earth Mover’s Distance as a Metric for Image Retrieval</article-title>. <source>International Journal of Computer Vision</source>. <year>2000</year>;<volume>40</volume>(<issue>2</issue>):<fpage>99</fpage>–<lpage>121</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1023/A:1026543900054" xlink:type="simple">10.1023/A:1026543900054</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Willmore</surname> <given-names>BD</given-names></name>, <name name-style="western"><surname>Schoppe</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>. <article-title>Incorporating midbrain adaptation to mean sound level improves models of auditory cortical processing</article-title>. <source>Journal of Neuroscience</source>. <year>2016</year>;<volume>36</volume>(<issue>2</issue>):<fpage>280</fpage>–<lpage>289</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2441-15.2016" xlink:type="simple">10.1523/JNEUROSCI.2441-15.2016</ext-link></comment> <object-id pub-id-type="pmid">26758822</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>, <name name-style="western"><surname>Schoppe</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BD</given-names></name>, <name name-style="western"><surname>Cui</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>. <article-title>Network receptive field modeling reveals extensive integration and multi-feature selectivity in auditory cortical neurons</article-title>. <source>PLoS Computational Biology</source>. <year>2016</year>;<volume>12</volume>(<issue>11</issue>):<fpage>e1005113</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005113" xlink:type="simple">10.1371/journal.pcbi.1005113</ext-link></comment> <object-id pub-id-type="pmid">27835647</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yildiz</surname> <given-names>IB</given-names></name>, <name name-style="western"><surname>Mesgarani</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>. <article-title>Predictive ensemble decoding of acoustical features explains context-dependent receptive fields</article-title>. <source>Journal of Neuroscience</source>. <year>2016</year>;<volume>36</volume>(<issue>49</issue>):<fpage>12338</fpage>–<lpage>12350</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.4648-15.2016" xlink:type="simple">10.1523/JNEUROSCI.4648-15.2016</ext-link></comment> <object-id pub-id-type="pmid">27927954</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref048">
<label>48</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Lee</surname> <given-names>DD</given-names></name>, <name name-style="western"><surname>Seung</surname> <given-names>HS</given-names></name>. <chapter-title>Algorithm for Non-negative Matrix Factorization</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>. <volume>vol. 13</volume>; <year>2001</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Blättler</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Hahnloser</surname> <given-names>RH</given-names></name>. <article-title>An efficient coding hypothesis links sparsity and selectivity of neural responses</article-title>. <source>PLoS One</source>. <year>2011</year>;<volume>6</volume>(<issue>10</issue>):<fpage>e25506</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0025506" xlink:type="simple">10.1371/journal.pone.0025506</ext-link></comment> <object-id pub-id-type="pmid">22022405</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carlin</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Elhilali</surname> <given-names>M</given-names></name>. <article-title>Sustained firing of model central auditory neurons yields a discriminative spectro-temporal representation of natural sounds</article-title>. <source>PLOS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>3</issue>):<fpage>e1002982</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002982" xlink:type="simple">10.1371/journal.pcbi.1002982</ext-link></comment> <object-id pub-id-type="pmid">23555217</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Woolley</surname> <given-names>SMN</given-names></name>, <name name-style="western"><surname>Gill</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Fremouw</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>Functional Groups in the Avian Auditory System</article-title>. <source>Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>9</issue>):<fpage>2780</fpage>–<lpage>2793</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2042-08.2009" xlink:type="simple">10.1523/JNEUROSCI.2042-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19261874</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref052">
<label>52</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Linden</surname> <given-names>JF</given-names></name>. <chapter-title>How linear are auditory cortical responses?</chapter-title> In: <source>Advances in neural information processing systems</source>; <year>2003</year>. p. <fpage>125</fpage>–<lpage>132</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lu</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Liang</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name>. <article-title>Temporal and rate representations of time-varying signals in the auditory cortex of awake primates</article-title>. <source>Nature Neuroscience</source>. <year>2001</year>;<volume>4</volume>(<issue>11</issue>):<fpage>1131</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn737" xlink:type="simple">10.1038/nn737</ext-link></comment> <object-id pub-id-type="pmid">11593234</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rauschecker</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Tian</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Hauser</surname> <given-names>M</given-names></name>. <article-title>Processing of complex sounds in the macaque nonprimary auditory cortex</article-title>. <source>Science</source>. <year>1995</year>;<volume>268</volume>(<issue>5207</issue>):<fpage>111</fpage>–<lpage>114</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.7701330" xlink:type="simple">10.1126/science.7701330</ext-link></comment> <object-id pub-id-type="pmid">7701330</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>, <name name-style="western"><surname>Beitel</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>. <article-title>Representation of a species-specific vocalization in the primary auditory cortex of the common marmoset: temporal and spectral characteristics</article-title>. <source>Journal of Neurophysiology</source>. <year>1995</year>;<volume>74</volume>(<issue>6</issue>):<fpage>2685</fpage>–<lpage>2706</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.1995.74.6.2685" xlink:type="simple">10.1152/jn.1995.74.6.2685</ext-link></comment> <object-id pub-id-type="pmid">8747224</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bieser</surname> <given-names>A</given-names></name>. <article-title>Processing of twitter-call fundamental frequencies in insula and auditory cortex of squirrel monkeys</article-title>. <source>Experimental Brain Research</source>. <year>1998</year>;<volume>122</volume>(<issue>2</issue>):<fpage>139</fpage>–<lpage>148</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s002210050501" xlink:type="simple">10.1007/s002210050501</ext-link></comment> <object-id pub-id-type="pmid">9776512</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>, <name name-style="western"><surname>Sen</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Doupe</surname> <given-names>AJ</given-names></name>. <article-title>Spectral-temporal receptive fields of nonlinear auditory neurons obtained using natural sounds</article-title>. <source>Journal of Neuroscience</source>. <year>2000</year>;<volume>20</volume>(<issue>6</issue>):<fpage>2315</fpage>–<lpage>2331</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.20-06-02315.2000" xlink:type="simple">10.1523/JNEUROSCI.20-06-02315.2000</ext-link></comment> <object-id pub-id-type="pmid">10704507</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nagarajan</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Cheung</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Bedenbaugh</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Beitel</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Schreiner</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Merzenich</surname> <given-names>MM</given-names></name>. <article-title>Representation of spectral and temporal envelope of twitter vocalizations in common marmoset primary auditory cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2002</year>;<volume>87</volume>(<issue>4</issue>):<fpage>1723</fpage>–<lpage>1737</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00632.2001" xlink:type="simple">10.1152/jn.00632.2001</ext-link></comment> <object-id pub-id-type="pmid">11929894</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cohen</surname> <given-names>YE</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Russ</surname> <given-names>BE</given-names></name>, <name name-style="western"><surname>Gill</surname> <given-names>P</given-names></name>. <article-title>Acoustic features of rhesus vocalizations and their representation in the ventrolateral prefrontal cortex</article-title>. <source>Journal of Neurophysiology</source>. <year>2007</year>;<volume>97</volume>(<issue>2</issue>):<fpage>1470</fpage>–<lpage>1484</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00769.2006" xlink:type="simple">10.1152/jn.00769.2006</ext-link></comment> <object-id pub-id-type="pmid">17135477</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gill</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Woolley</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Fremouw</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Theunissen</surname> <given-names>FE</given-names></name>. <article-title>Sound representation methods for spectro-temporal receptive field estimation</article-title>. <source>Journal of computational neuroscience</source>. <year>2006</year>;<volume>21</volume>(<issue>1</issue>):<fpage>5</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10827-006-7059-4" xlink:type="simple">10.1007/s10827-006-7059-4</ext-link></comment> <object-id pub-id-type="pmid">16633939</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref061">
<label>61</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Deneve</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lochmann</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ernst</surname> <given-names>U</given-names></name>. <chapter-title>Spike based inference in a network with divisive inhibition</chapter-title>. In: <source>Proceedings Neurocomp</source>. <publisher-loc>Marseille</publisher-loc>; <year>2008</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shelton</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Sheikh</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Bornschein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Sterne</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>. <article-title>Nonlinear Spike-And-Slab Sparse Coding for Interpretable Image Encoding</article-title>. <source>PLoS ONE</source>. <year>2015</year> <month>5</month>;<volume>10</volume>:<fpage>e0124088</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0124088" xlink:type="simple">10.1371/journal.pone.0124088</ext-link></comment> <object-id pub-id-type="pmid">25954947</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>O’Reilly</surname> <given-names>RC</given-names></name>. <article-title>Generalization in Interactive Networks: The Benefits of Inhibitory Competition and Hebbian Learning</article-title>. <source>Neural Computation</source>. <year>2001</year>;<volume>13</volume>:<fpage>1199</fpage>–<lpage>1241</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/08997660152002834" xlink:type="simple">10.1162/08997660152002834</ext-link></comment> <object-id pub-id-type="pmid">11387044</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lücke</surname> <given-names>J</given-names></name>. <article-title>Receptive Field Self-Organization in a Model of the Fine-Structure in V1 Cortical Columns</article-title>. <source>Neural Computation</source>. <year>2009</year>;<volume>21</volume>(<issue>10</issue>):<fpage>2805</fpage>–<lpage>45</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco.2009.07-07-584" xlink:type="simple">10.1162/neco.2009.07-07-584</ext-link></comment> <object-id pub-id-type="pmid">19548804</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brito</surname> <given-names>CS</given-names></name>, <name name-style="western"><surname>Gerstner</surname> <given-names>W</given-names></name>. <article-title>Nonlinear Hebbian learning as a unifying principle in receptive field formation</article-title>. <source>PLoS Computational Biology</source>. <year>2016</year>;<volume>12</volume>(<issue>9</issue>):<fpage>e1005070</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1005070" xlink:type="simple">10.1371/journal.pcbi.1005070</ext-link></comment> <object-id pub-id-type="pmid">27690349</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Singer</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Teramoto</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Willmore</surname> <given-names>BD</given-names></name>, <name name-style="western"><surname>Schnupp</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>King</surname> <given-names>AJ</given-names></name>, <name name-style="western"><surname>Harper</surname> <given-names>NS</given-names></name>. <article-title>Sensory cortex is optimized for prediction of future input</article-title>. <source>eLife</source>. <year>2018</year>;<volume>7</volume>:<fpage>e31557</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.31557" xlink:type="simple">10.7554/eLife.31557</ext-link></comment> <object-id pub-id-type="pmid">29911971</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref067">
<label>67</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>D</given-names></name>. <chapter-title>On ideal binary mask as the computational goal of auditory scene analysis</chapter-title>. In: <source>Speech separation by humans and machines</source>. <publisher-name>Springer</publisher-name>; <year>2005</year>. p. <fpage>181</fpage>–<lpage>197</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref068">
<label>68</label>
<mixed-citation publication-type="other" xlink:type="simple">Smaragdis P, Brown JC. Non-negative matrix factorization for polyphonic music transcription. In: IEEE workshop on applications of signal processing to audio and acoustics. vol. 3. New York; 2003. p. 177–180.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref069">
<label>69</label>
<mixed-citation publication-type="other" xlink:type="simple">Schmidt MN, Olsson RK. Single-channel speech separation using sparse non-negative matrix factorization. In: Ninth International Conference on Spoken Language Processing; 2006.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>DJ</given-names></name>. <article-title>Sparse coding with an overcomplete basis set: A strategy employed by V1?</article-title> <source>Vision Research</source>. <year>1997</year> <month>Dec</month>;<volume>37</volume>(<issue>23</issue>):<fpage>3311</fpage>–<lpage>3325</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(97)00169-7" xlink:type="simple">10.1016/S0042-6989(97)00169-7</ext-link></comment> <object-id pub-id-type="pmid">9425546</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref071">
<label>71</label>
<mixed-citation publication-type="other" xlink:type="simple">Olshausen BA, Cadieu CF, Warland DK. Learning real and complex overcomplete representations from the statistics of natural images. vol. 7446. SPIE; 2009. p. 74460S.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cadieu</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>. <article-title>Learning intermediate-level representations of form and motion from natural movies</article-title>. <source>Neural Computation</source>. <year>2012</year> <month>Apr</month>;<volume>24</volume>(<issue>4</issue>):<fpage>827</fpage>–<lpage>866</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/NECO_a_00247" xlink:type="simple">10.1162/NECO_a_00247</ext-link></comment> <object-id pub-id-type="pmid">22168556</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref073">
<label>73</label>
<mixed-citation publication-type="other" xlink:type="simple">Turner RE. Statistical Models for Natural Sounds. PhD Thesis. Gatsby Computational Neuroscience Unit, UCL; 2010.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Turner</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <article-title>Time-Frequency Analysis as Probabilistic Inference</article-title>. <source>IEEE Transactions on Signal Processing</source>. <year>2014</year> <month>Dec</month>;<volume>62</volume>(<issue>23</issue>):<fpage>6171</fpage>–<lpage>6183</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TSP.2014.2362100" xlink:type="simple">10.1109/TSP.2014.2362100</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006595.ref075">
<label>75</label>
<mixed-citation publication-type="other" xlink:type="simple">Van Den Oord A, Dieleman S, Zen H, Simonyan K, Vinyals O, Graves A, et al. Wavenet: A generative model for raw audio. CoRR abs/160903499. 2016;.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref076">
<label>76</label>
<mixed-citation publication-type="other" xlink:type="simple">Sheikh AS, Dai Z, Harper N, Turner R, Lücke J. Maximal causes for a masking based model of STRFs in primary auditory cortex; In: Proceedings COSYNE; 2015. p. II–47.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref077">
<label>77</label>
<mixed-citation publication-type="other" xlink:type="simple">Ilin A, Valpola H. On the effect of the form of the posterior approximation in variational learning of ICA models. In: Proceedings ICA; 2003. p. 915–920.</mixed-citation>
</ref>
<ref id="pcbi.1006595.ref078">
<label>78</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Turner</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <chapter-title>Two problems with variational expectation maximisation for time-series models</chapter-title>. In: <name name-style="western"><surname>Barber</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Cemgil</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Chiappa</surname> <given-names>S</given-names></name>, editors. <source>Bayesian Time Series Models</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>2011</year>. p. <fpage>1</fpage>–<lpage>23</lpage>.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
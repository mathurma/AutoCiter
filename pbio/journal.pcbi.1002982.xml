<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
      <journal-id journal-id-type="pmc">ploscomp</journal-id>
      <journal-title-group>
        <journal-title>PLoS Computational Biology</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1553-734X</issn>
      <issn pub-type="epub">1553-7358</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-01157</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pcbi.1002982</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
              <subj-group>
                <subject>Coding mechanisms</subject>
                <subject>Sensory systems</subject>
              </subj-group>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
              <subj-group>
                <subject>Coding mechanisms</subject>
                <subject>Sensory systems</subject>
              </subj-group>
            </subj-group>
            <subj-group>
              <subject>Sensory systems</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Engineering</subject>
          <subj-group>
            <subject>Signal processing</subject>
            <subj-group>
              <subject>Audio signal processing</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Computational Biology</subject>
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Sustained Firing of Model Central Auditory Neurons Yields a Discriminative Spectro-temporal Representation for Natural Sounds</article-title>
        <alt-title alt-title-type="running-head">Sustained Firing and the Representation of Sound</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Carlin</surname>
            <given-names>Michael A.</given-names>
          </name>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Elhilali</surname>
            <given-names>Mounya</given-names>
          </name>
          <xref ref-type="aff" rid="aff1"/>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <addr-line>Department of Electrical and Computer Engineering, The Center for Language and Speech Processing, Johns Hopkins University, Baltimore, Maryland, United States of America</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Sporns</surname>
            <given-names>Olaf</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>Indiana University, United States of America</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">mounya@jhu.edu</email></corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: MAC ME. Performed the experiments: MAC. Analyzed the data: MAC ME. Wrote the paper: MAC ME.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <month>3</month>
        <year>2013</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>28</day>
        <month>3</month>
        <year>2013</year>
      </pub-date>
      <volume>9</volume>
      <issue>3</issue>
      <elocation-id>e1002982</elocation-id>
      <history>
        <date date-type="received">
          <day>17</day>
          <month>7</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>25</day>
          <month>1</month>
          <year>2013</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2013</copyright-year>
        <copyright-holder>Carlin, Elhilali</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>The processing characteristics of neurons in the central auditory system are directly shaped by and reflect the statistics of natural acoustic environments, but the principles that govern the relationship between natural sound ensembles and observed responses in neurophysiological studies remain unclear. In particular, accumulating evidence suggests the presence of a code based on sustained neural firing rates, where central auditory neurons exhibit strong, persistent responses to their preferred stimuli. Such a strategy can indicate the presence of ongoing sounds, is involved in parsing complex auditory scenes, and may play a role in matching neural dynamics to varying time scales in acoustic signals. In this paper, we describe a computational framework for exploring the influence of a code based on sustained firing rates on the shape of the spectro-temporal receptive field (STRF), a linear kernel that maps a spectro-temporal acoustic stimulus to the instantaneous firing rate of a central auditory neuron. We demonstrate the emergence of richly structured STRFs that capture the structure of natural sounds over a wide range of timescales, and show how the emergent ensembles resemble those commonly reported in physiological studies. Furthermore, we compare ensembles that optimize a sustained firing code with one that optimizes a sparse code, another widely considered coding strategy, and suggest how the resulting population responses are not mutually exclusive. Finally, we demonstrate how the emergent ensembles contour the high-energy spectro-temporal modulations of natural sounds, forming a discriminative representation that captures the full range of modulation statistics that characterize natural sound ensembles. These findings have direct implications for our understanding of how sensory systems encode the informative components of natural stimuli and potentially facilitate multi-sensory integration.</p>
      </abstract>
      <abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>We explore a fundamental question with regard to the representation of sound in the auditory system, namely: what are the coding strategies that underlie observed neurophysiological responses in central auditory areas? There has been debate in recent years as to whether neural ensembles explicitly minimize their propensity to fire (the so-called sparse coding hypothesis) or whether neurons exhibit strong, sustained firing rates when processing their preferred stimuli. Using computational modeling, we directly confront issues raised in this debate, and our results suggest that not only does a sustained firing strategy yield a sparse representation of sound, but the principle yields emergent neural ensembles that capture the rich structural variations present in natural stimuli. In particular, spectro-temporal receptive fields (STRFs) have been widely used to characterize the processing mechanisms of central auditory neurons and have revealed much about the nature of sound processing in central auditory areas. In our paper, we demonstrate how neurons that maximize a sustained firing objective yield STRFs akin to those commonly measured in physiological studies, capturing a wide range of aspects of natural sounds over a variety of timescales, suggesting that such a coding strategy underlies observed neural responses.</p>
      </abstract>
      <funding-group>
        <funding-statement>This research is partly supported by a graduate fellowship from the JHU Human Language Technology Center of Excellence, and grants IIS-0846112 (NSF), 1R01AG036424-01 (NIH), N000141010278 and N00014-12-1-0740 (ONR). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript, except for the HLTCOE, which reviewed the manuscript to ensure no US government classified information was disclosed.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="18"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>It is widely believed that sensory representations are optimized to process the stimuli to which they are exposed in natural environments <xref ref-type="bibr" rid="pcbi.1002982-Simoncelli1">[1]</xref>. Of particular interest is understanding the computational principles that underlie the generation of observed neural firing patterns. A popular hypothesis explored in recent years assumes that neural populations optimize a sparse code. This means that at any given time, only a small subset of a neural population fires to encode a given stimulus <xref ref-type="bibr" rid="pcbi.1002982-Olshausen1">[2]</xref>. Such a representation is attractive for reasons of coding efficiency (see, e.g., <xref ref-type="bibr" rid="pcbi.1002982-Rosenblith1">[3]</xref>) and conservation of physiological resources <xref ref-type="bibr" rid="pcbi.1002982-Laughlin1">[4]</xref>. The sparse coding hypothesis has enjoyed particular success in studies of vision (e.g., <xref ref-type="bibr" rid="pcbi.1002982-Olshausen2">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Vinje1">[6]</xref>), and has also been supported more recently by both neurophysiological <xref ref-type="bibr" rid="pcbi.1002982-DeWeese1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Hromdka1">[8]</xref> and computational studies <xref ref-type="bibr" rid="pcbi.1002982-Klein1">[9]</xref>–<xref ref-type="bibr" rid="pcbi.1002982-Carlson1">[11]</xref> of the auditory system.</p>
      <p>However, it has also been observed that some central auditory neurons, when driven by their preferred stimuli, exhibit <italic>sustained</italic> firing rates. Measuring from auditory thalamus and primary auditory cortex, Wang <italic>et al.</italic> observed that sustained responses were not simply phase-locked to the fast dynamics of the stimulus, suggesting that this rate-based code represented a meaningful, non-isomorphic transformation of the stimulus <xref ref-type="bibr" rid="pcbi.1002982-Wang1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Wang2">[13]</xref>. Indeed, such a code is particularly important for audition since it directly addresses the issue of how to indicate the continued presence of a sound in a complex acoustic environment. Results from Petkov <italic>et al.</italic> have also illustrated how sustained responses play a role in auditory scene analysis, forming part of the neural basis for the perceptual restoration of foreground sounds against a cluttered background <xref ref-type="bibr" rid="pcbi.1002982-Petkov1">[14]</xref>. Moreover, Wang has argued that a rate-based representation is critical for matching fast temporal modulations present in natural sounds to slower rates found in higher cortical areas <xref ref-type="bibr" rid="pcbi.1002982-Wang3">[15]</xref>. Slower dynamics in acoustic signals are believed to be the main carrier of information in speech and music <xref ref-type="bibr" rid="pcbi.1002982-Elhilali1">[16]</xref>; are commensurate with temporal dynamics of stream formation and auditory grouping <xref ref-type="bibr" rid="pcbi.1002982-Elhilali2">[17]</xref>; and may play an important role in multi-modal sensory integration <xref ref-type="bibr" rid="pcbi.1002982-Wang3">[15]</xref>. Related computational studies in vision have suggested how this principle may underlie the shapes of simple and complex cell receptive fields in primary visual cortex <xref ref-type="bibr" rid="pcbi.1002982-Hurri1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Krding1">[19]</xref>. Importantly, a sustained firing rate, i.e., one that is persistent and therefore slowly changing over time, is related to slow feature analysis, a well-known method for extracting invariances from sensory signals <xref ref-type="bibr" rid="pcbi.1002982-Wiskott1">[20]</xref> (see <xref ref-type="sec" rid="s3">Discussion</xref>). To the best of our knowledge, however, there are no computational studies that explicitly consider the implications of a sustained firing-based code in central auditory areas.</p>
      <p>At first glance, the two coding schemes are seemingly at odds: on the one hand a sparse code seeks to minimize the activity of a neural population whereas a sustained firing-based code requires that neural responses persist over time but still form an efficient representation of the stimulus. However, it appears that central auditory responses can strike a balance between the two strategies, with a large, transient population response at the onset of a sound, and a sparse subset of preferentially driven neurons exhibiting a strong, sustained response throughout the sound's duration <xref ref-type="bibr" rid="pcbi.1002982-Wang3">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Middlebrooks1">[21]</xref>. This picture suggests a mechanism for detecting and tracking target sounds in noisy acoustic environments and for generating a persistent signal that facilitates a stable perceptual representation. From a computational perspective, a better understanding of these mechanisms can inform models of auditory scene analysis as well as signal processing schemes for hearing prosthetics and automated sound processing systems.</p>
      <p>A general computational approach for exploring the effects of particular coding strategies in sensory systems is based on optimizing a statistical objective criterion that quantifies the principle governing the transformation between stimulus and internal representation. Upon convergence, one then compares the emergent representation to known properties of the sensory system being studied <xref ref-type="bibr" rid="pcbi.1002982-Simoncelli1">[1]</xref>. Here, we apply this framework to explore how optimizing a sustained firing criterion influences the shapes of model auditory spectro-temporal receptive fields (STRFs) when processing natural sounds, and we compare the emergent ensembles to those obtained by optimizing a sparse coding objective. STRFs describe the linear mapping between a spectro-temporal stimulus and an instantaneous firing rate <xref ref-type="bibr" rid="pcbi.1002982-Aertsen1">[22]</xref>, and have proven useful not only for describing basic processing aspects of auditory neurons <xref ref-type="bibr" rid="pcbi.1002982-Depireux1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Miller1">[24]</xref>, but also for shedding light on the nature of task-driven plasticity <xref ref-type="bibr" rid="pcbi.1002982-Fritz1">[25]</xref>. <xref ref-type="fig" rid="pcbi-1002982-g001">Figure 1</xref> illustrates how a spectro-temporal stimulus is mapped to a set of instantaneous neural firing rates, whose ensemble response according to a desired coding strategy directly shapes the mapping.</p>
      <fig id="pcbi-1002982-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Schematic of the proposed framework.</title>
          <p>Panel (A) shows an example of an auditory spectrogram for the speech utterance “serve on frankfurter buns…” whereas panel (B) illustrates how spectro-temporal patches are mapped to an ensemble of instantaneous neural firing rates.</p>
        </caption>
        <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g001" position="float" xlink:type="simple"/>
      </fig>
      <p>In this paper, we show how this framework allows us to not only explore how the timescales of natural sounds are captured by and reflected in an emergent sensory representation, but reveal key similarities between choice of a sustained versus sparse code. Moreover, we demonstrate how a sustained firing-based code suggests a mechanism for an emergent discriminative representation for ensembles of natural stimuli.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <p>We defined a sustained neural response as one where firing rate energy changes relatively slowly and is consequently highly <italic>correlated</italic> over time. In particular, we were interested in the characteristics of ensembles of model STRFs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e001" xlink:type="simple"/></inline-formula> that promoted sustained responses over a specified time interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e002" xlink:type="simple"/></inline-formula>. Denoting the response of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e003" xlink:type="simple"/></inline-formula> neuron as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e004" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e005" xlink:type="simple"/></inline-formula> is the STRF and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e006" xlink:type="simple"/></inline-formula> is a spectro-temporal stimulus, we quantified this principle using the following objective function:<disp-formula id="pcbi.1002982.e007"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e007" xlink:type="simple"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e008" xlink:type="simple"/></inline-formula> denotes time average. Observe that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e009" xlink:type="simple"/></inline-formula> represents the sum of correlations between signal energies of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e010" xlink:type="simple"/></inline-formula> neuron over a time interval defined by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e011" xlink:type="simple"/></inline-formula> across an ensemble of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e012" xlink:type="simple"/></inline-formula> neurons. If a neuron yielded a sustained response, then each of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e013" xlink:type="simple"/></inline-formula> would vary smoothly over the specified interval and we expect <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e014" xlink:type="simple"/></inline-formula> to be large. Moreover, choice of the correlation interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e015" xlink:type="simple"/></inline-formula> allowed us to directly explore the effect of different timescales on the ensembles <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e016" xlink:type="simple"/></inline-formula> that <italic>maximized</italic> <xref ref-type="disp-formula" rid="pcbi.1002982.e007">Eq. 1</xref>. Finally, the weights <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e017" xlink:type="simple"/></inline-formula> were chosen to be linearly decaying for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e018" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e019" xlink:type="simple"/></inline-formula>, reflecting the intuition that recent activity of a neuron likely has more influence on the current output than the past. Note that these weights could be adapted to specifically model, for example, positive- or negative-monotonic sustained responses observed in physiological studies <xref ref-type="bibr" rid="pcbi.1002982-Wang2">[13]</xref>. Full details of the optimization procedure can be found in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
      <p>Alternatively, we explored an objective function that promoted sparsity. A natural way to induce sparsity in a population code is by enforcing a population response whose firing rate distribution is highly peaked near zero (representing frequent <italic>weak</italic> responses), but has long tails (representing infrequent <italic>large</italic> responses), i.e., a distribution with high <italic>kurtosis</italic> <xref ref-type="bibr" rid="pcbi.1002982-Willmore1">[26]</xref>. We quantified the sparsity of a population code using sample kurtosis:<disp-formula id="pcbi.1002982.e020"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e020" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e021" xlink:type="simple"/></inline-formula> is the fourth central moment at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e022" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e023" xlink:type="simple"/></inline-formula> is the population variance at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e024" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e025" xlink:type="simple"/></inline-formula> is the population mean at time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e026" xlink:type="simple"/></inline-formula>.</p>
      <p>For both <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e027" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e028" xlink:type="simple"/></inline-formula>, the basic problem was to find an ensemble of STRFs that <italic>maximized</italic> the respective objective function subject to constraints that (1) bounded the amplitude of the filter responses and (2) minimized redundancy among the learned ensemble. This was achieved by enforcing the responses have unit variance and be mutually uncorrelated, i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e029" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e030" xlink:type="simple"/></inline-formula> is the Kroenecker delta function (see <xref ref-type="sec" rid="s4">Methods</xref>); we refer to these as <italic>response</italic> constraints. These constraints ensured that the responses had a bounded magnitude and that the STRFs did not all converge to the same solution.</p>
      <sec id="s2a">
        <title>Emergence of richly structured STRFs</title>
        <p>We optimized both the sustained objective <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e031" xlink:type="simple"/></inline-formula> and sparsity objective <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e032" xlink:type="simple"/></inline-formula> using an ensemble of natural stimuli comprising speech, animal vocalizations, and ambient outdoor sounds. Each ensemble of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e033" xlink:type="simple"/></inline-formula> filters was initialized at random using zero-mean, unit variance Gaussian noise, and each STRF covered from 0–250 ms in time and 62.5–4000 Hz along the tonotopic axis.</p>
        <p>For the sustained objective, we considered a wide range of correlation intervals from very brief (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e034" xlink:type="simple"/></inline-formula>) to very long (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e035" xlink:type="simple"/></inline-formula>). Examples of emergent STRFs for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e036" xlink:type="simple"/></inline-formula> are shown in <xref ref-type="fig" rid="pcbi-1002982-g002">Figure 2A</xref>. For the spectro-temporal patches shown, red and blue colors indicate that the presence of energy in a particular spectro-temporal region yields excitatory and inhibitory responses, respectively. We observe a variety of STRFs that are highly localized, sensitive to narrowband spectral and temporal events, oriented, and some that are seemingly noise-like and not convergent to any particularly interesting shape. Importantly, such observations about these basic STRF classes align with those made in a number of previous physiological studies (see, e.g., <xref ref-type="bibr" rid="pcbi.1002982-Depireux1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Miller1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-David1">[27]</xref>). Moreover, coverage of the STRFs appears to span the full time-frequency space. These results suggest that the sustained firing objective may underlie part of the coding strategy used by central auditory neurons.</p>
        <fig id="pcbi-1002982-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Examples of emergent STRFs.</title>
            <p>Shown are STRFs learned by optimizing (A) the sustained objective function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e037" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e038" xlink:type="simple"/></inline-formula> and (B) the sparsity objective function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e039" xlink:type="simple"/></inline-formula>. The examples shown here were drawn at random from ensembles of 400 neurons. The sustained STRFs are shown in order of decreasing contribution to the overall objective function whereas the sparse STRFs are shown randomly ordered. Each spectro-temporal patch spans 0–250 ms in time and 62.5–4000 Hz in frequency. For these examples the dynamic range of the STRFs was compressed using a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e040" xlink:type="simple"/></inline-formula> nonlinearity.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g002" position="float" xlink:type="simple"/>
        </fig>
        <p>Shown in <xref ref-type="fig" rid="pcbi-1002982-g002">Figure 2B</xref> are examples of emergent STRFs obtained by optimizing the sparsity objective. Indeed, this particular objective yields STRFs that are highly localized and sparsely distributed, with sensitivity to bandlimited spectral and temporal events. While both objective criteria yield noisy STRFs, it is clear that the sparse ensemble is much more noisy, with a less extensive coverage of the basic sound classes as observed with the sustained ensemble.</p>
      </sec>
      <sec id="s2b">
        <title>Ensemble diversity varies smoothly with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e041" xlink:type="simple"/></inline-formula></title>
        <p>Since the information-bearing components of natural sounds vary concurrently across multiple timescales, it was expected that the structure of STRFs learned under the sustained objective would vary with the correlation interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e042" xlink:type="simple"/></inline-formula>. Indeed, inspection of the sustained ensembles for a range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e043" xlink:type="simple"/></inline-formula> suggested the presence of a number of latent classes whose membership varied smoothly from short to long correlation intervals. To quantify variations in population diversity over ecologically relevant timescales, we performed unsupervised clustering of the emergent STRFs and studied how class membership changed with objective function and correlation interval.</p>
        <p>We pooled STRFs from the sparse ensemble and from the sustained ensembles for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e044" xlink:type="simple"/></inline-formula>10, 25, 50, 125, 250, 500, 1000, and 2000 ms, yielding a total of 3600 STRFs. We then applied normalized spectral clustering to discover latent classes among the pooled STRFs. In general, spectral clustering algorithms require an affinity matrix that specifies pairwise similarities between the objects being clustered. Viewing this affinity matrix as an undirected graph, spectral clustering finds a partition of the graph into groups whose elements have common similarity with one another. A natural measure of similarity between STRFs can be derived from the two-dimensional cross-correlation between pairs of spectro-temporal patches. Such a measure is similar to that considered by Woolley <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002982-Wooley1">[28]</xref> and is desirable since it does not depend on subjective choice of spectro-temporal features to use for clustering. In this work, we defined the measure of similarity between pairs of STRFs as the <italic>absolute value</italic> of the maximum value of the two-dimensional cross-correlation matrix; we used absolute value since we wished to group similar STRFs regardless of whether they were excitatory or inhibitory. Furthermore, as the STRFs tended to be distributed with a variety of phases in the input space, we considered cross-correlations for arbitrary time-frequency shifts (see <xref ref-type="sec" rid="s4">Methods</xref> for details).</p>
        <p>Results obtained using normalized spectral clustering of the emergent ensembles into nine classes are shown in <xref ref-type="fig" rid="pcbi-1002982-g003">Figure 3</xref>. In the center panel of the figure, a stacked bar chart illustrates the the percentage of STRFs at a particular <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e045" xlink:type="simple"/></inline-formula> assigned to one of nine classes. Different segment colors correspond to each of the nine classes, and segment width is proportional to the number of STRFs assigned to that class. Surrounding the bar chart are examples from six classes that best illustrate how diversity varies with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e046" xlink:type="simple"/></inline-formula>, namely <italic>noisy</italic>, <italic>localized</italic>, <italic>spectral</italic>, <italic>complex</italic>, <italic>temporal</italic>, and <italic>directional</italic> classes. These labels are qualitative descriptors of each class and not quantitative assessments of the time-frequency characteristics of each category.</p>
        <fig id="pcbi-1002982-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Spectral clustering results.</title>
            <p>Shown are nine clusters obtained by pooling STRFs from the sparse as well as sustained ensembles for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e047" xlink:type="simple"/></inline-formula>10, 25, 50, 125, 250, 500, 1000, and 2500 ms. Shown in the center is a stacked bar chart where segment color corresponds to class label and segment width is proportional to the number of STRFs assigned to a particular class in a given ensemble. The surrounding panels show examples of STRFs drawn from six illustrative classes, namely, <italic>noisy</italic>, <italic>localized</italic>, <italic>spectral</italic>, <italic>complex</italic>, <italic>temporal</italic>, and <italic>directional</italic>.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g003" position="float" xlink:type="simple"/>
        </fig>
        <p>Inspection of the cluster groupings reveal rich structural variations over a wide range of correlation intervals. In particular, the STRFs labeled according to the <italic>noisy</italic> class are found to dominate the sparse ensemble, with a large presence in the sustained ensemble for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e048" xlink:type="simple"/></inline-formula>. Membership in this class drops for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e049" xlink:type="simple"/></inline-formula> between 10 and 125 ms, and begins to increase at 125 ms. We also observe that short correlation intervals (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e050" xlink:type="simple"/></inline-formula>10, 25, and 50 ms) have a large concentration of <italic>localized</italic> STRFs, with membership dropping with increasing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e051" xlink:type="simple"/></inline-formula>. While the <italic>temporal</italic> class holds relatively steady across the sustained ensembles, we find that membership in the <italic>directional</italic>, <italic>complex</italic>, and <italic>spectral</italic> classes varied smoothly across <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e052" xlink:type="simple"/></inline-formula>. In general, we find that ensemble diversity is maximized for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e053" xlink:type="simple"/></inline-formula> (max. entropy of 3.08 bits), but the overall trends suggest rich ensemble structure between 10 and 250 ms, which is notably in the range of the timescales of natural sounds <xref ref-type="bibr" rid="pcbi.1002982-Rosen1">[29]</xref>, . This is further supported by the increasing presence of <italic>noisy</italic> STRFs for large correlation intervals (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e054" xlink:type="simple"/></inline-formula>1000 and 2000 ms).</p>
        <p>In addition to studying structural variations in the <italic>shapes</italic> of the emergent STRFs, it is also of interest to examine the structure of the STRF <italic>outputs</italic> in response to natural sounds. In particular, we sought to address the extent to which enforcing sustained responses does indeed yield responses that persist over time. We defined the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e055" xlink:type="simple"/></inline-formula> neuron to be significantly “active” when its firing rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e056" xlink:type="simple"/></inline-formula> exceeded <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e057" xlink:type="simple"/></inline-formula>1 standard deviation over time. While this is not meant to be a precise measure of a neuron's activation (since, for instance, the firing rate is not used to modulate a Poisson spike generation process), such a measure nevertheless quantifies and characterizes a strong versus weak ensemble response to natural stimuli.</p>
        <p>Shown in <xref ref-type="fig" rid="pcbi-1002982-g004">Figure 4A</xref> are the distribution of activation times for individual neurons for ensembles of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e058" xlink:type="simple"/></inline-formula>10 and 125 ms in response to a held-out set of natural stimuli. The neurons are shown sorted according to decreasing median activation time, and the interquartile ranges of activation time are indicated by the shaded regions. We observed that the most diversity in median activation times across ensembles occurred in approximately the top 10% of the <italic>most persistent</italic> neurons. To summarize these observations, we considered the distribution of median activation times of the top 10% of neurons with most persistent responses (i.e., the top 40 neurons); these distributions are illustrated as boxplots in <xref ref-type="fig" rid="pcbi-1002982-g004">Figure 4B</xref>.</p>
        <fig id="pcbi-1002982-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Analysis of the temporal activations of emergent ensembles.</title>
            <p>Panel (A) shows the median activation time of individual neurons (solid lines, sorted in decreasing order) for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e059" xlink:type="simple"/></inline-formula>10 and 125 ms, respectively, for STRFs that optimize the sustained objective function. The shaded region illustrates the corresponding interquartile range. Panel (B) shows the distributions (as boxplots) of median activation times of the top 10% “most persistent” neurons for sparse and sustained ensembles for increasing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e060" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g004" position="float" xlink:type="simple"/>
        </fig>
        <p>As noted previously with the clustering results, shorter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e061" xlink:type="simple"/></inline-formula> values favor mostly localized and noisy STRFs and consequently it was expected that activations would be brief. Interestingly, however, we observe that with increasing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e062" xlink:type="simple"/></inline-formula>, median activations peak between 50 and 500 ms and fall off for large <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e063" xlink:type="simple"/></inline-formula> despite the STRFs being optimized to promote sustained responses over long intervals. This overall trend aligns with the previous clustering results that demonstrate how population diversity is maximized over intervals corresponding to timescales that predominate natural stimuli. The STRFs corresponding to the top 10% most persistent responses for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e064" xlink:type="simple"/></inline-formula> are shown in Supplementary Figure 1, and we find that they generally have a spectral tuning, but are fairly narrowband and localized.</p>
        <p>Additionally, we considered the responses of the top 40 most persistent responses obtained using the sparsity objective function; the distribution of median activations is in the first column of <xref ref-type="fig" rid="pcbi-1002982-g004">Figure 4B</xref>. We find that the sparse ensemble yields responses most similar to those for short <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e065" xlink:type="simple"/></inline-formula>.</p>
      </sec>
      <sec id="s2c">
        <title>Comparison of emergent sustained ensembles to physiology</title>
        <p>How do the emergent STRFs learned under the sustained firing objective compare to those observed in physiological studies? Broadly speaking, we find that the emergent STRFs share many of the trends with biological receptive fields typically observed in animal models. We explored this issue by comparing our model ensembles with a set of 1586 STRFs recorded from awake, non-behaving ferret primary auditory cortex using TORC <xref ref-type="bibr" rid="pcbi.1002982-Klein2">[31]</xref> and speech stimuli <xref ref-type="bibr" rid="pcbi.1002982-David1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Mesgarani1">[32]</xref> (see <xref ref-type="sec" rid="s4">Methods</xref> for more details). Where applicable, we also compared our results with reported results from anesthetized ferrets by Depireux <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002982-Depireux1">[23]</xref> and cats by Miller <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002982-Miller1">[24]</xref> in the literature.</p>
        <p>Illustrative examples of the types of STRFs found in the neural data are shown in <xref ref-type="fig" rid="pcbi-1002982-g005">Figure 5</xref>. In particular, we find neural STRFs that are qualitatively similar those found in the <italic>localized</italic>, <italic>complex</italic>, <italic>noisy</italic>, and <italic>directional</italic> clusters shown earlier in <xref ref-type="fig" rid="pcbi-1002982-g003">Figure 3</xref>. Because the temporal and spectral sampling rates used in our model are higher than those used in the physiological data, we did not find good matches with the <italic>temporal</italic> and <italic>spectral</italic> classes.</p>
        <fig id="pcbi-1002982-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Comparison of emergent STRFs learned according to the sustained objective function with examples estimated from ferret auditory cortex.</title>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g005" position="float" xlink:type="simple"/>
        </fig>
        <p>To visualize the overlap between the spectro-temporal modulation coverage of the neural and model STRFs, we used the ensemble modulation transfer function (eMTF). The eMTF is derived by averaging the magnitude of the 2D Fourier Transform of each neuron in a given ensemble, and jointly characterizes modulations in time (rate, in Hz) and in frequency (scale, in cyc/oct). We first applied normalized spectral clustering to the neural STRFs to obtain nine clusters. Next, we computed the eMTF for each cluster, extracted isoline contours at the 65% level, and overlaid these curves on the eMTF of the model STRFs for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e066" xlink:type="simple"/></inline-formula>. These results are shown in <xref ref-type="fig" rid="pcbi-1002982-g006">Figure 6</xref> and illustrate the overlap between the model and neural data, particularly at the “edges” of the neural STRF modulations. While the overlap is not complete, it is clear that the modulation spectra of each ensemble are not disjoint. Moreover, the model eMTF suggests a general ensemble sensitivity to relatively fast modulations; this point is explored further in a later section (“Emergent STRFs capture spectro-temporal modulation statistics of stimulus”).</p>
        <fig id="pcbi-1002982-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Cluster analysis of neural STRFs.</title>
            <p>Illustration of the overlap between the eMTFs of neural STRF clusters and that of the response-constrained sustained objective model STRFs; class 9 comprised mostly noisy STRFs with an exceedingly broad eMTF and its contour is omitted here for clarity. The white contour corresponds to the model eMTF at the 65% level.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g006" position="float" xlink:type="simple"/>
        </fig>
        <p>To better characterize the relationship between the neural and model data, we employed a statistical comparison of the distribution of the two datasets. If the models truly generated STRFs similar to those in physiological studies, then one might expect a nearest-neighbor (NN) similarity distribution akin to one derived from the neural ensemble we considered. We computed the symmetric KL-divergence between each of the model and within-physiology NN similarity distributions (shown in Supplemental Figure 2). We found that the sustained-response (presented here) and sustained-shape (presented later in this paper) distributions had KL divergences of 0.80 and 0.85, respectively, whereas the sparse distribution had a KL distance of 1.05. KL typically measures the expected number of bits required to code samples from one distribution using codes from the other. While these numbers are difficult to assess in absolute terms, they give a sense of how the different model optimizations and constraints compare to each other. These numbers reveal that the sustained ensembles are similarly comparable to the physiology, whereas the sparse ensemble has a somewhat worse match. Of course, caution must be taken with these numbers because the set of neural STRFs we analyzed represent only a subset of mappings that likely exist in central auditory areas.</p>
        <p>Next, we measured a variety of parameters from the neural and model STRFs (for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e067" xlink:type="simple"/></inline-formula>) that more fully characterized the extent of spectro-temporal coverage and modulation sensitivity of the ensembles (see <xref ref-type="sec" rid="s4">Methods</xref>), the results of which are summarized in <xref ref-type="fig" rid="pcbi-1002982-g007">Figure 7</xref>.</p>
        <fig id="pcbi-1002982-g007" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g007</object-id>
          <label>Figure 7</label>
          <caption>
            <title>Ensemble analysis of STRFs learned under the sustained objective function for </title>
            <p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e068" xlink:type="simple"/></inline-formula><bold>.</bold> In panels (A), (B), (C) and (E), the histograms show the distribution of model parameters whereas the thin green lines show the distribution of the physiological data. The black and green dashed vertical lines show population means for the model and neural data, respectively. In panels (D) and (F), the black and green lines correspond to the model and neural STRFs, respectively, with the dashed lines indicating 6-dB upper cutoff frequencies. Refer to the text for more details.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g007" position="float" xlink:type="simple"/>
        </fig>
        <p>Based on the distribution of directionality indices, shown in panel (A), we observe that the model STRFs are largely symmetric, with the majority of neurons having no preference for upward or downward moving input stimuli (mean<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e069" xlink:type="simple"/></inline-formula>0). As indicated by the tails of this distribution, however, a subset of neurons have a strong directional preference. This agrees with the neural STRFs, and similar observations have been made in MGB and primary auditory cortex of cats by Miller <italic>et al.</italic>, as well as in measurements by Depireux <italic>et al.</italic> from primary auditory cortex of ferrets. Furthermore, panel (B) illustrates that a large number of model STRFs are fairly separable, with a peak in the separability index (SPI) distribution around 0.10 and an average value of 0.26. This trend aligns with values reported in the literature by Depireux <italic>et al.</italic> in measurements from ferret auditory cortex (mean of approx. 0.25). However, it is worth noting that this low level of separability is not uniformly reported across physiological studies of receptive field of mammalian auditory cortex. For instance, the physiological data analyzed in the current study (examples of which are shown in <xref ref-type="fig" rid="pcbi-1002982-g005">Figure 5</xref>) do yield a higher average SPI (mean = 0.37).</p>
        <p>The temporal modulation statistics of the model STRFs, as quantified by best rate (BR), also align generally with results reported from mammalian thalamus and cortex. In panel (C) we observe a broad, bandpass distribution of best rates, with an average of 23.9 Hz. Reported physiological results from Miller <italic>et al.</italic> show similarly broad ranges of temporal tuning with preferences around 16 Hz and 30 Hz range for cortex and thalamus, respectively. The neural STRFs we analyzed show a somewhat slower tuning, with an average BR of 9.5 Hz. Furthermore, in panel (D), we computed the normalized average rate profile from the model STRFs. We observe a peak at 7.8 Hz, with an upper 6-dB cutoff of 34.4 Hz. Here we find a close overlap with the rate profile computed from the neural STRFs as well as with average profile results as reported by Miller <italic>et al.</italic> (peak at 12.8 Hz; upper 6-dB cutoff at 37.4 Hz).</p>
        <p>The spectral modulation statistics of the model STRFs, as quantified by best scale, are generally faster than those reported from studies of thalamic and cortical nuclei. The distribution of best scales shown in panel (E) is bandpass with a wide range of slow to fast spectral coverage, with an average tuning of 1.40 cyc/oct. The neural STRFs, in contrast, are tuned to much slower scales (mean = 0.47 cyc/oct). Similarly, results from Miller <italic>et al.</italic> in MGB indicate a generally slower tuning (0.58 cyc/oct), whereas measurements from cortical neurons, while having a similarly wide range of tunings as with the model, indicate a slower average value of 0.46 cyc/oct and an upper cutoff of approx. 2 cyc/oct.</p>
        <p>Finally, the ensemble average scale profile, shown in panel (F), is bandpass and exhibits a peak at 0.7 cyc/oct with an upper 6-dB cutoff of 2.9 cyc/oct. The neural STRFs, however, are much slower with peak at 0.2 cyc/oct and an upper cutoff of 1.9 cyc/oct. This is similar to observations from MGB by Miller <italic>et al.</italic>, where they reported that the ensemble average scale profile is generally low-pass, with average scale profile peaks and upper 6-dB cutoffs at 0 cyc/oct and 1.3 cyc/oct, respectively, with similar observations in cortex.</p>
        <p>In summary, while we cannot map the emergent STRFs to any exact synapse, they nevertheless reflect the general processing characteristics of various stations along in the central auditory pathway. There is good alignment with the neural STRFs and reported results in mammalian MGB and primary auditory cortex with respect to directional sensitivity and spectro-temporal separability. The temporal modulation statistics of the emergent sustained STRFs appear to be most similar to those measured from thalamus and cortex. Furthermore, the model STRFs are generally faster with regard to spectral modulations than those measured from thalamus and cortex.</p>
      </sec>
      <sec id="s2d">
        <title>Emergence of a sparse population code</title>
        <p>To explore the relationship between STRFs optimized to promote sustained responses and those that explicitly maximize population sparsity, we compared the average responses of the sustained ensemble for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e070" xlink:type="simple"/></inline-formula> with the sparse ensemble. Specifically, we used the converged STRFs to analyze a held-out set of natural stimuli, computed a histogram of the population responses at each time, and computed the average histogram across the entire test input (see <xref ref-type="sec" rid="s4">Methods</xref>). Since the sparse ensemble was optimized to yield a highly kurtotic firing rate distribution, it was of interest to examine the shape of the distribution when promoting sustained responses.</p>
        <p>Results comparing the average histograms of sustained versus sparse responses is shown in <xref ref-type="fig" rid="pcbi-1002982-g008">Figure 8</xref>, with log-probabilities shown on the vertical axis to emphasize differences between the tails of the distributions. The main observation is that both the sustained and sparse ensembles have distributions that have long tails and are are highly peaked around a firing rate of zero. For reference, we show the average histograms obtained by filtering the stimulus through the first 400 principal components of the stimulus (see Supplemental Figure 3) as well as through a set of 400 random STRFs; a zero-mean, unit variance Gaussian distribution is also shown. Therefore, despite promoting temporally persistent responses, the sustained responses yield a population response that is not altogether different from an ensemble that explicitly maximizes kurtosis. Interestingly, this observation was also made by Berkes and Wiscott in the context of complex cell processing in primary visual cortex (see Sec. 6 of <xref ref-type="bibr" rid="pcbi.1002982-Berkes1">[33]</xref>).</p>
        <fig id="pcbi-1002982-g008" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g008</object-id>
          <label>Figure 8</label>
          <caption>
            <title>Average population response histograms for STRFs learned under the sustained and sparse objectives subject to response constraints.</title>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g008" position="float" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2e">
        <title>Emergent STRFs capture spectro-temporal modulation statistics of stimulus</title>
        <p>Finally, we sought to explore the consequences of relaxing the constraint that the responses be mutually uncorrelated. Rather than directly constrain the <italic>responses</italic>, we considered constraints to the <italic>shapes</italic> of the model STRFs. This was achieved by solving<disp-formula id="pcbi.1002982.e071"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e071" xlink:type="simple"/></disp-formula>i.e., we require the STRFs to form an orthonormal basis. So long as the stimuli are bounded, this set of constraints meets our requirements that (1) the output of the STRFs be bounded and (2) we minimize redundancy in the learned ensemble. As before, the optimization is described in the <xref ref-type="sec" rid="s4">Methods</xref>. We consider an ensemble size of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e072" xlink:type="simple"/></inline-formula> STRFs initialized at random. Examples of shape-constrained STRFs that optimize the sustained objective function for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e073" xlink:type="simple"/></inline-formula> are shown in <xref ref-type="fig" rid="pcbi-1002982-g009">Figure 9</xref>. Again, we observe STRFs that are bandpass, localized, oriented, and sensitive to a variety of spectral and temporal input. However, there was an apparent difference between the speed of the spectro-temporal modulations and those from STRFs learned subject to the response constraints.</p>
        <fig id="pcbi-1002982-g009" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g009</object-id>
          <label>Figure 9</label>
          <caption>
            <title>Examples of STRFs learned under the sustained objective function (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e074" xlink:type="simple"/></inline-formula>) subject to orthonormality constraints on the shapes of the filters.</title>
            <p>The examples shown here were drawn at random from an ensemble of 400 neurons, and the STRFs are shown in order of decreasing contribution to the overall objective function. Each spectro-temporal patch spans 0–250 ms in time and 62.5–4000 Hz in frequency. For these examples the dynamic range of the STRFs was compressed using a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e075" xlink:type="simple"/></inline-formula> nonlinearity.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g009" position="float" xlink:type="simple"/>
        </fig>
        <p>It is well known that natural sound ensembles are composed largely of slow spectro-temporal modulations <xref ref-type="bibr" rid="pcbi.1002982-Rosen1">[29]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Singh1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Attias1">[34]</xref>. However, the emergent STRFs learned subject to <italic>response</italic> constraints appear to be tuned to relatively <italic>fast</italic> spectral and temporal modulations, whereas the STRFs learned subject to <italic>shape</italic> constraints appear to have a broader tuning. To further examine how both sets of constraints jointly capture and are related to the spectro-temporal modulations observed in stimulus, we compared the average 2D modulation profile of the stimulus to the eMTFs derived from both sets of constraints.</p>
        <p>An interesting view of how the emergent STRFs capture the spectro-temporal modulations of the stimulus is illustrated in <xref ref-type="fig" rid="pcbi-1002982-g010">Figure 10</xref> for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e076" xlink:type="simple"/></inline-formula>. Shown is the average 2D modulation profile of the stimulus overlaid with a single isoline contour (at the 65% level) of the eMTFs learned subject to response (thick red lines) and shape constraints (thick black lines). We also show the constellation of BR versus BS for each ensemble (indicated by ‘<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e077" xlink:type="simple"/></inline-formula>’ and ‘<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e078" xlink:type="simple"/></inline-formula>’ for response and shape constraints, respectively). As implied by the contours, the response constraints yield STRFs that follow the spectro-temporal “edge” of the stimulus, while the shape constraints explicitly capture most of the “slowness” of the stimulus. As mentioned previously, the response constraints effectively force the temporal response of the sustained ensemble to be sparse, which consequently results in highly selective STRFs that tend to be tuned to fast modulations. Nevertheless, they implicitly capture the spectro-temporal extent of the stimulus. Moreover, since the shape constraints effectively force the STRFs to form a basis that spans the input space, this results in neurons that explicitly capture the slow modulations of the stimulus. Similar observations were made across the range of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e079" xlink:type="simple"/></inline-formula>, and for each case it was clear that the spectro-temporal modulations of the stimulus are fully captured by the combination of both sets of constraints.</p>
        <fig id="pcbi-1002982-g010" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g010</object-id>
          <label>Figure 10</label>
          <caption>
            <title>Spectro-temporal modulations in the stimulus are fully captured by STRFs that promote sustained responses subject to response and shape constraints.</title>
            <p>Here, the average MTF of the stimulus is overlaid with contours (at the 65% level) of the ensemble MTFs for both constraints for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e080" xlink:type="simple"/></inline-formula>. For each ensemble we also show the constellations for best rate vs. best scale (marked by ‘<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e081" xlink:type="simple"/></inline-formula>’ and ‘<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e082" xlink:type="simple"/></inline-formula>’ for response and shape constraints, respectively). For the response constraints, we show the contour line and BR/BS constellations for STRFs that contribute to 99% of the objective function.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g010" position="float" xlink:type="simple"/>
        </fig>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>In this paper, we considered a framework for studying how choice of a sustained firing versus sparse coding objective affects the shapes of model spectro-temporal receptive fields in central auditory areas. The sparse coding objective considered here, namely that of maximizing population kurtosis, yields STRFs that are mostly noisy. Those that do converge are generally highly localized. In contrast, enforcing the sustained firing objective subject to the same response constraints yields richly structured ensembles of STRFs whose population diversity varies smoothly with the correlation interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e083" xlink:type="simple"/></inline-formula>. Of course, the observed structural variations are necessarily biased due to construction of the stimulus. Nevertheless, this diversity, as revealed by the results of the unsupervised clustering, paired with the responses of the most persistent STRFs, supports the notion that sustained neural firings are preferred in the range of timescales predominant in natural sounds. While we do not necessarily attribute the emergent sustained STRFs to any particular synapse in the auditory pathway, we instead note that the observed filters exhibit general similarities to physiological observations made in auditory thalamus and cortex.</p>
      <p>We also observed that enforcing the sustained firing objective with response constraints yields an ensemble firing rate distribution that is similar, on average, to one where population sparsity was explicitly enforced. This supports the proposal that the two coding objectives are not necessarily at odds, and that in some sense a sustained firing objective yields “sparsity for free.” Of course, the sustained firing and sparse coding objectives could be quantified in many different ways (see, e.g., Hashimoto <xref ref-type="bibr" rid="pcbi.1002982-HashimotoW1">[35]</xref> and Carlson <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002982-Carlson1">[11]</xref>), but the present study is a promising step in understanding their relationship in the central auditory system from a computational perspective.</p>
      <p>Finally, to explore the consequences of relaxing the constraint that the responses be mutually uncorrelated, we explored an alternative set of orthonormality constraints on the sustained firing objective. While still minimizing a notion of redundancy, we observed that the emergent ensembles are generally slower, potentially better capturing the slow spectro-temporal modulations known to be present in natural sounds. This experiment further demonstrated the utility of the considered framework for directly addressing questions about coding schemes and various sets of constraints in representing sound in central auditory areas.</p>
      <sec id="s3a">
        <title>Emergence of a discriminative spectro-temporal representation for natural sounds</title>
        <p>The combination of shape and response constraints on the sustained objective function yield STRF ensembles that appear to jointly capture the full range of spectro-temporal modulations in the stimulus. However, the distinct differences in MTF coverage illustrate the tradeoff between redundancy and efficiency in sensory representations. In particular, the shape constraints yield STRFs that are somewhat akin to the first few principal components of the stimulus (see Supplemental Figure 3). This is not surprising given that the objective function defines a notion of variance of linear projections, the component vectors of which are constrained to form an orthonormal basis. However, since the responses are not strictly enforced to be uncorrelated, orthonormality imposed on the filter shapes does not necessarily reduce redundancy in the resulting neural responses.</p>
        <p>In contrast, the response constraints yield STRFs that are highly selective to the input and are thus comparatively “fast” in the modulation domain. This representation can be thought of as more efficient since at any given time only a few neurons have a large response. However, while the shapes of individual STRFs fail to explicitly capture the slow spectro-temporal modulations predominant in natural sounds, it instead appears that the ensemble MTF of the response-constrained STRFs collectively forms a contour around the high-energy modulations of the stimulus that implicitly capture its spectro-temporal extent.</p>
        <p>Is this contouring of the average modulation spectrum of natural sounds something performed by the auditory system? The neural STRFs we considered certainly had an eMTF that reflects a tuning to slower modulations near the MTF origin. However, there is some evidence that the auditory system uses an “edge”-sensitive, discriminative modulation profile for analyzing sound. Woolley <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002982-Woolley1">[36]</xref>, in an avian study, showed that the eMTF of neurons from Field L (the avian A1 analog) has a bandpass temporal modulation profile (at low scales) that facilitates a discriminative tuning of temporal modulations among classes of natural sounds. Nagel and Doupe <xref ref-type="bibr" rid="pcbi.1002982-Nagel1">[37]</xref> have also shown examples of avian Field L STRFs that orient themselves near the spectro-temporal “edge” of the stimulus space. Moreover, Rodriguez <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002982-Rodriguez1">[38]</xref>, in a study of mammalian IC neurons, showed that neural bandwidths can scale to better capture fast, but less frequently occurring, modulations. In light of these observations, the modulation profiles observed from the sustained STRFs for both response and shape constraints are consistent with the notion that the auditory system makes an explicit effort to capture all modulations present in natural sounds: fast, feature-selective, and consequently <italic>discriminative</italic> modulations, as well as frequently occurring slow modulations.</p>
      </sec>
      <sec id="s3b">
        <title>A neural code for sensory processing</title>
        <p>The notion that sustained neural firings form part of the neural representation of sensory systems is not limited exclusively to the auditory modality. In fact, the sustained firing objective considered in this paper is related to a broad class of sensory coding strategies referred to collectively under the <italic>temporal slowness hypothesis</italic>. This concept proposes that the responses of sensory neurons reflect the time-course of the information-bearing components of the stimulus—which are often much slower with respect to the fast variations observed in the stimulus—and may therefore reflect invariant aspects of the sensory objects in the environment. Examples of early neural network models exploring slowness as a learning principle were considered by Földiák <xref ref-type="bibr" rid="pcbi.1002982-Fldik1">[39]</xref>, Mitchison <xref ref-type="bibr" rid="pcbi.1002982-Mitchison1">[40]</xref>, and Becker <xref ref-type="bibr" rid="pcbi.1002982-Becker1">[41]</xref>. More recently, a number of computational studies, particularly in vision, have established slowness as a general sensory coding strategy and have revealed relationships with a number of general machine learning techniques. Here we outline the connections between the sustained firing criterion considered in this study and previous work.</p>
        <p>Our definition of the sustained firing objective, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e084" xlink:type="simple"/></inline-formula>, was adapted from a notion of temporal stability proposed by Hurri and Hyvärinen termed <italic>temporal response strength correlation</italic> (TRSC) <xref ref-type="bibr" rid="pcbi.1002982-Hurri1">[18]</xref>. This study considered modeling of simple cells in primary visual cortex, and their objective function was defined as<disp-formula id="pcbi.1002982.e085"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e085" xlink:type="simple"/><label>(3)</label></disp-formula>for a single fixed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e086" xlink:type="simple"/></inline-formula>. By maximizing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e087" xlink:type="simple"/></inline-formula> subject to the decorrelation constraints <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e088" xlink:type="simple"/></inline-formula>, they showed the emergence of spatial receptive fields similar to those observed in simple cells in primary visual cortex. It is clear that the objective functions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e089" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e090" xlink:type="simple"/></inline-formula> are equivalent for a single time step, but the main difference between the two is that we sought to enforce temporal stability over a time <italic>interval</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e091" xlink:type="simple"/></inline-formula>, rather than between two <italic>distinct</italic> times <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e092" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e093" xlink:type="simple"/></inline-formula>. Interestingly, optimization of the TRSC objective was shown by Hyvärinen to yield a solution to the blind source separation problem <xref ref-type="bibr" rid="pcbi.1002982-Hyvrinen1">[42]</xref>, suggesting perhaps that in the auditory domain, such a criterion may underlie separation of overlapping acoustic sources.</p>
        <p>The sustained firing objective is also related to a well-known model of temporal slowness known as <italic>slow feature analysis</italic> (SFA) <xref ref-type="bibr" rid="pcbi.1002982-Wiskott1">[20]</xref>. The computational goal of SFA is to find a mapping of an input that extracts the slow, and presumably more invariant, information in the stimulus. Briefly, for an input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e094" xlink:type="simple"/></inline-formula>, linear SFA finds mappings <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e095" xlink:type="simple"/></inline-formula> that minimize<disp-formula id="pcbi.1002982.e096"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e096" xlink:type="simple"/><label>(4)</label></disp-formula>subject to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e097" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e098" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e099" xlink:type="simple"/></inline-formula>. Note that the input <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e100" xlink:type="simple"/></inline-formula> is not necessarily the raw stimulus but could represent a non-linear expansion of the input, akin to applying a kernel function in a support vector machine <xref ref-type="bibr" rid="pcbi.1002982-Bishop1">[43]</xref>. Therefore, SFA finds a mapping of the input that varies little over time and whose outputs are bounded and mutually uncorrelated. In the visual domain, Berkes and Wiskott found that SFA could explain a variety of complex cell phenomena in primary visual cortex such as the emergence of Gabor-like receptive fields, phase invariance, various forms of inhibition, and directional sensitivity <xref ref-type="bibr" rid="pcbi.1002982-Berkes1">[33]</xref>. Similar to our study, they also found the emergence of a sparse population code based on SFA. More importantly, however, they established a link between SFA at the level of complex cells and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e101" xlink:type="simple"/></inline-formula>, which in turn links to the sustained firing objective <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e102" xlink:type="simple"/></inline-formula> explored in our study. Specifically, they showed that when a complex cell output is expressed as a quadratic form <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e103" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002982-HashimotoW1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Berkes2">[44]</xref>, the SFA objective could be written as<disp-formula id="pcbi.1002982.e104"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e104" xlink:type="simple"/><label>(5)</label></disp-formula>which is equivalent to maximizing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e105" xlink:type="simple"/></inline-formula> (and thus <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e106" xlink:type="simple"/></inline-formula> for a single time-step) plus cross-correlation terms. As noted by Berkes and Wiskott, this relationship suggests that sustained firing rates at the level of simple cells are modulated as part of a hierarchical cortical processing scheme in primary visual cortex. Given the increasing understanding of such hierarchical circuits in the auditory system <xref ref-type="bibr" rid="pcbi.1002982-Sharpee1">[45]</xref>, the possibility that sustained firing rates are varied as part of a higher-order processing strategy in primary auditory areas is an exciting prospect worth further exploration.</p>
        <p>Other important relationships exist between SFA and a number of general machine learning principles. Blaschke <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002982-Blaschke1">[46]</xref> established a relationship between SFA and independent component analysis, a widely used method for blind source separation (see, e.g., <xref ref-type="bibr" rid="pcbi.1002982-Hyvrinen2">[47]</xref>). Klampfl and Maass <xref ref-type="bibr" rid="pcbi.1002982-Klampfl1">[48]</xref> showed that under certain slowness assumptions about the underlying class labels in observed data, SFA finds a discriminative projection of the input similar to Fisher's linear discriminant. Furthermore, SFA has links to methods for nonlinear dimensionality reduction: Creutzig and Sprekeler <xref ref-type="bibr" rid="pcbi.1002982-Creutzig1">[49]</xref> described the link between SFA and the information bottleneck whereas Sprekeler <xref ref-type="bibr" rid="pcbi.1002982-Sprekeler1">[50]</xref> showed a connection between SFA and Laplacian eigenmaps.</p>
        <p>In summary, the temporal slowness hypothesis forms a sound basis for learning a representation from data with rich temporal structure. Slowness as a learning principle has also been shown to explain the emergence of simple and complex cell properties in primary visual cortex. As described above, the sustained firing principle considered in this paper has fundamental links to SFA, which in turn is related to a number of general machine learning strategies. To the best of our knowledge, ours is the first thorough study that establishes a link between the temporal slowness hypothesis and an emergent spectro-temporal representation of sound in central auditory areas.</p>
      </sec>
      <sec id="s3c">
        <title>Implications for automated sound processing systems</title>
        <p>The ensemble modulation coverage results are particularly interesting since it is widely thought that “slow” spectro-temporal modulations carry much of the message-bearing information for human speech perception. Furthermore, it is known in the speech processing community that features that capture slow temporal <xref ref-type="bibr" rid="pcbi.1002982-Hermansky1">[51]</xref> and joint spectro-temporal modulations <xref ref-type="bibr" rid="pcbi.1002982-Nemala1">[52]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Nemala2">[53]</xref> are important for noise-robust automatic speech recognition. The observed contouring effect resulting from the sustained firing criterion may thus reflect a mechanism to detect the spectro-temporal “edges” of the message-bearing components of the stimulus, and possibly contribute to a noise-robust representation of sound. We have recently considered this principle and have demonstrated that 2D bandpass filters derived from eMTF contours learned from a speech-only stimulus yield state-of-the-art noise-robust acoustic features for automatic speech recognition <xref ref-type="bibr" rid="pcbi.1002982-Carlin1">[54]</xref>. Moreover, it is possible that the contour level may be chosen adaptively as a function of ambient signal-to-noise ratio to better capture variations in the high-energy modulations of the stimulus. Also, since the emergent STRFs capture general spectro-temporal patterns that characterize the stimulus, it is possible that ensembles of STRFs could be learned in various speech-plus-noise scenarios to perhaps better characterize noise-corrupted acoustic environments. Such hypotheses can be readily verified experimentally and may have practical impact to automated sound processing systems in noisy acoustic environments.</p>
      </sec>
      <sec id="s3d">
        <title>Concluding remarks</title>
        <p>Finally, the framework considered in this paper can be extended in a number of ways. For instance, to address the linearity limitation of the STRF, it is worthwhile to consider a model based on a linear-nonlinear cascade <xref ref-type="bibr" rid="pcbi.1002982-Calabrese1">[55]</xref>. As mentioned earlier, the auditory pathway is necessarily hierarchical, and warrants consideration of hierarchical computational models. Indeed, recent physiological evidence also indicates that the representation becomes increasingly complex and nonlinear as one moves from away thalamo-recipient layers in primary auditory cortex (for a review, see <xref ref-type="bibr" rid="pcbi.1002982-Sharpee1">[45]</xref>). Finally, a recent computational study in vision by Cadieu and Olshausen <xref ref-type="bibr" rid="pcbi.1002982-Cadieu1">[56]</xref> proposes a hierarchical generative model that explicitly unifies notions of sparse coding and temporal stability. In particular, a two-layer network learns a sparse input representation whose activations vary smoothly over time, whereas a second layer modulates the plasticity of the first layer, resulting in a smooth time-varying basis for image sequences. One can imagine that such a framework could be extended to spectro-temporal acoustic stimuli.</p>
      </sec>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <sec id="s4a">
        <title>Stimulus description and preparation</title>
        <p>An ensemble of natural sounds comprising segments of speech, animal vocalizations, and ambient outdoor noises was assembled for use as stimuli. Two sets were generated, one for training and one for evaluating the response characteristics of the STRFs. Phonetically balanced sentences read by male and female speakers were used <xref ref-type="bibr" rid="pcbi.1002982-Garofolo1">[57]</xref>. Examples of animal vocalizations included barking dogs, bleating goats, and chattering monkeys <xref ref-type="bibr" rid="pcbi.1002982-1">[58]</xref>. The ambient sounds included, for example, babbling creeks and blowing wind, and other outdoor noises. The speech utterances were approximately three seconds each and comprised 50% of the stimulus. The animal vocalizations and ambient sounds formed the remaining 50% of the stimulus (25% each), were broken into three-second segments, and were windowed using a raised cosine window to avoid transient effects. Finally, segments from each class were downsampled to 8 kHz, standardized to be zero-mean and unit variance, and randomly concatenated to yield a waveform approximately three minutes in overall length, i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e107" xlink:type="simple"/></inline-formula>90 seconds of speech, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e108" xlink:type="simple"/></inline-formula>45 seconds of animal vocalizations, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e109" xlink:type="simple"/></inline-formula>45 seconds of ambient outdoor noises.</p>
        <p>We used a computational model of peripheral processing to account for the transformation of a monaural acoustic stimulus to a joint time-frequency representation in the auditory midbrain; this representation is referred to as an <italic>auditory spectrogram</italic> <xref ref-type="bibr" rid="pcbi.1002982-Yang1">[59]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Chi1">[60]</xref>. The auditory spectrogram represents the time-varying spectral energy distribution on the (logarithmic) tonotopic axis, and accounts for the physiology of inner hair cell transduction and filtering on the auditory nerve, enhanced frequency selectivity in the cochlear nucleus via a lateral inhibitory network, and the loss of phase locking to stimuli observed in midbrain nuclei. The specific model details have been presented previously and as such we forego a detailed description here, except to note that we sampled the log-frequency axis over six octaves with ten equally spaced channels per octave, with a short-term integration interval of 5 ms, i.e., we obtained a 60 channel spectral vector every 5 ms. An example auditory spectrogram is shown for a segment of speech in <xref ref-type="fig" rid="pcbi-1002982-g001">Figure 1A</xref>.</p>
      </sec>
      <sec id="s4b">
        <title>Spectro-temporal receptive fields</title>
        <p>To quantify the relationship between a spectro-temporal stimulus and its corresponding response in central auditory areas, we used the spectro-temporal receptive field. Such a functional characterization of a neuron is useful for identifying the components of the stimulus to which it is most sensitive. An STRF models the linear transformation of a time-varying spectro-temporal input to an instantaneous firing rate, i.e.,<disp-formula id="pcbi.1002982.e110"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e110" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e111" xlink:type="simple"/></inline-formula> is an LTI filter that defines the STRF, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e112" xlink:type="simple"/></inline-formula> is a spectro-temporal stimulus, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e113" xlink:type="simple"/></inline-formula> is the average firing rate. Without loss of generality, we assume <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e114" xlink:type="simple"/></inline-formula>. Observe that the mapping represents convolution in time and integration across all frequencies, and we can interpret the STRF as a matched filter that acts on the input auditory spectrogram.</p>
        <p>For discrete-time signals and filters, and assuming that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e115" xlink:type="simple"/></inline-formula> has a finite impulse response, we can express <xref ref-type="disp-formula" rid="pcbi.1002982.e110">Eq. 6</xref> compactly in vector notation as<disp-formula id="pcbi.1002982.e116"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e116" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e117" xlink:type="simple"/></inline-formula> are column vectors denoting the stimulus and filter, respectively <xref ref-type="bibr" rid="pcbi.1002982-Theunissen1">[61]</xref>. Furthermore, to express the response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e118" xlink:type="simple"/></inline-formula> of an <italic>ensemble</italic> of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e119" xlink:type="simple"/></inline-formula> neurons, we concatenate the STRFs into a matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e120" xlink:type="simple"/></inline-formula> and write<disp-formula id="pcbi.1002982.e121"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e121" xlink:type="simple"/><label>(8)</label></disp-formula></p>
        <p>From the stimulus auditory spectrogram, we extracted 250 ms spectro-temporal segments once every 5 ms. Each segment was stacked columnwise into a vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e122" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e123" xlink:type="simple"/></inline-formula> (i.e., 50 vectors/segment <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e124" xlink:type="simple"/></inline-formula>60 channels). A total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e125" xlink:type="simple"/></inline-formula>30 k spectro-temporal vectors were extracted from the stimulus. We subtracted the local mean from each segment and scaled each vector to be unit norm <xref ref-type="bibr" rid="pcbi.1002982-Hurri1">[18]</xref>, and note that this pre-processing was also applied to the test stimulus used for evaluating the STRF response characteristics. Finally, each spectro-temporal input patch was processed by the ensemble of STRFs to yield a population response <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e126" xlink:type="simple"/></inline-formula>. <xref ref-type="fig" rid="pcbi-1002982-g001">Figure 1B</xref> illustrates the procedure for obtaining stimulus vectors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e127" xlink:type="simple"/></inline-formula> and response vector <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e128" xlink:type="simple"/></inline-formula>.</p>
      </sec>
      <sec id="s4c">
        <title>Optimization</title>
        <p>To constrain the responses of the STRFs to have unit variance and be mutually uncorrelated, we first note that the individual constraints can be written as<disp-formula id="pcbi.1002982.e129"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e129" xlink:type="simple"/></disp-formula>which can then be compactly expressed as an ensemble constraint<disp-formula id="pcbi.1002982.e130"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e130" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e131" xlink:type="simple"/></inline-formula> denotes the sample covariance matrix and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e132" xlink:type="simple"/></inline-formula> is the identity matrix. Since <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e133" xlink:type="simple"/></inline-formula> is real-symmetric, it is unitarily diagonalizable as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e134" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e135" xlink:type="simple"/></inline-formula> is a matrix of (columnwise) eigenvectors with corresponding eigenvalues along the diagonal of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e136" xlink:type="simple"/></inline-formula>. Substituting this decomposition into <xref ref-type="disp-formula" rid="pcbi.1002982.e130">Eq. 9</xref>, we obtained<disp-formula id="pcbi.1002982.e137"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e137" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e138" xlink:type="simple"/></inline-formula>. By recasting the constraints, we can rewrite the original matrix of STRFs as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e139" xlink:type="simple"/></inline-formula> and consequently<disp-formula id="pcbi.1002982.e140"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e140" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e141" xlink:type="simple"/></inline-formula> corresponds to a <italic>whitening</italic> of the input acoustic data, i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e142" xlink:type="simple"/></inline-formula> has a spherical covariance matrix. For computational efficiency, we reduced the dimensionality of the input using a subset of the principal components of the stimulus, i.e.,<disp-formula id="pcbi.1002982.e143"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e143" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e144" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e145" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e146" xlink:type="simple"/></inline-formula>, are the matrices of eigenvalues and eigenvectors, respectively, that captured 95% of the variance of the input. In this work, we found <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e147" xlink:type="simple"/></inline-formula>. Therefore, the core problem we wished to solve is:<disp-formula id="pcbi.1002982.e148"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e148" xlink:type="simple"/><label>(10)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e149" xlink:type="simple"/></inline-formula> corresponded to either the sustained firing or sparse coding objective function.</p>
        <p>To optimize this nonlinear program, we used the gradient projection method due to Rosen, the basic idea of which is as follows <xref ref-type="bibr" rid="pcbi.1002982-Rosen2">[62]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Luenberger1">[63]</xref>. Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e150" xlink:type="simple"/></inline-formula> denote the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e151" xlink:type="simple"/></inline-formula> update to the matrix of (rotated and scaled) STRFs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e152" xlink:type="simple"/></inline-formula>, let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e153" xlink:type="simple"/></inline-formula> be a learning rate, and let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e154" xlink:type="simple"/></inline-formula> be an integer used to adjust the learning rate. Assume <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e155" xlink:type="simple"/></inline-formula> is a matrix with orthonormal columns that is a feasible solution to the problem in <xref ref-type="disp-formula" rid="pcbi.1002982.e148">Eq. 10</xref>. We updated <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e156" xlink:type="simple"/></inline-formula> via gradient ascent as follows:<disp-formula id="pcbi.1002982.e157"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e157" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e158" xlink:type="simple"/></inline-formula> is a projection of the gradient update so that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e159" xlink:type="simple"/></inline-formula> satisfies the orthonormality constraint required in <xref ref-type="disp-formula" rid="pcbi.1002982.e148">Eq. 10</xref>. If the update was such that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e160" xlink:type="simple"/></inline-formula>, we set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e161" xlink:type="simple"/></inline-formula> and recomputed the projected gradient update, repeating until <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e162" xlink:type="simple"/></inline-formula> was non-decreasing. Finally, learning ceased when the relative change between <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e163" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e164" xlink:type="simple"/></inline-formula> fell below a threshold <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e165" xlink:type="simple"/></inline-formula> or a maximum number of iterations were reached; in our experiments, we stopped learning for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e166" xlink:type="simple"/></inline-formula> or a maximum number of 30 iterations. Upon convergence, the desired STRFs were obtained using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e167" xlink:type="simple"/></inline-formula>. Note that for the case of the sustained firing objective, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e168" xlink:type="simple"/></inline-formula> was formed from the sum of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e169" xlink:type="simple"/></inline-formula> independent terms, allowing us to directly sort the emergent STRFs according to their contribution to the overall objective function; such a sorting was not possible for the sparsity objective.</p>
        <p>Of course, the above procedure required a suitable projection <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e170" xlink:type="simple"/></inline-formula>, and one was derived as follows <xref ref-type="bibr" rid="pcbi.1002982-Horn1">[64]</xref>. In general, for a matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e171" xlink:type="simple"/></inline-formula>, we wish to find a matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e172" xlink:type="simple"/></inline-formula> with orthonormal columns that minimizes<disp-formula id="pcbi.1002982.e173"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e173" xlink:type="simple"/></disp-formula>Introducing a symmetric matrix of Lagrange multipliers <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e174" xlink:type="simple"/></inline-formula>, and recalling that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e175" xlink:type="simple"/></inline-formula>, we sought to find a stationary point of the Lagrangian<disp-formula id="pcbi.1002982.e176"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e176" xlink:type="simple"/></disp-formula>Computing the (elementwise) partial derivative of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e177" xlink:type="simple"/></inline-formula> w.r.t. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e178" xlink:type="simple"/></inline-formula> and setting it to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e179" xlink:type="simple"/></inline-formula> we obtained <xref ref-type="bibr" rid="pcbi.1002982-Horn2">[65]</xref><disp-formula id="pcbi.1002982.e180"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e180" xlink:type="simple"/></disp-formula>Observing that<disp-formula id="pcbi.1002982.e181"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e181" xlink:type="simple"/></disp-formula>we have that<disp-formula id="pcbi.1002982.e182"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e182" xlink:type="simple"/></disp-formula>Assuming <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e183" xlink:type="simple"/></inline-formula> had full column rank, then an optimal orthogonal matrix that minimized <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e184" xlink:type="simple"/></inline-formula> that can be used for the projection in <xref ref-type="disp-formula" rid="pcbi.1002982.e157">Eq. 11</xref> was found as<disp-formula id="pcbi.1002982.e185"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e185" xlink:type="simple"/><label>(12)</label></disp-formula></p>
        <p>Finally, to optimize a given objective function subject to the STRFs being orthonormal, i.e., <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e186" xlink:type="simple"/></inline-formula>, we solve<disp-formula id="pcbi.1002982.e187"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e187" xlink:type="simple"/></disp-formula>Here we can again use Rosen's projected gradient method in <xref ref-type="disp-formula" rid="pcbi.1002982.e157">Eq. 11</xref> along with the projection defined in <xref ref-type="disp-formula" rid="pcbi.1002982.e185">Eq. 12</xref>, but the only difference from before is that it <italic>does not</italic> require pre-whitening of the stimulus.</p>
      </sec>
      <sec id="s4d">
        <title>Characterizing individual STRFs</title>
        <p>We first characterized the emergent STRFs based on parameters that described their individual spectro-temporal and modulation tuning.</p>
        <sec id="s4d1">
          <title>Separability index</title>
          <p>We used a measure of separability to quantify how well an STRF <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e188" xlink:type="simple"/></inline-formula> could be decomposed into a product of purely temporal and spectral functions, i.e., as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e189" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002982-Depireux1">[23]</xref>. Generally speaking, by treating an STRF as a matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e190" xlink:type="simple"/></inline-formula>, separability can be assessed by considering the singular value decomposition of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e191" xlink:type="simple"/></inline-formula>:<disp-formula id="pcbi.1002982.e192"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e192" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e193" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e194" xlink:type="simple"/></inline-formula> are unitary, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e195" xlink:type="simple"/></inline-formula> is a matrix such that the <italic>singular values</italic> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e196" xlink:type="simple"/></inline-formula> lie along the “diagonal”, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e197" xlink:type="simple"/></inline-formula>. The separability index <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e198" xlink:type="simple"/></inline-formula> was defined as<disp-formula id="pcbi.1002982.e199"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e199" xlink:type="simple"/></disp-formula>If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e200" xlink:type="simple"/></inline-formula> is nearly rank-1, we expect <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e201" xlink:type="simple"/></inline-formula> to dominate and consequently <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e202" xlink:type="simple"/></inline-formula> is small, indicating that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e203" xlink:type="simple"/></inline-formula>, i.e., that the STRF is approximately separable as a product of only two functions. It was often the case that STRFs with a simpler structure, e.g., localized or purely spectral, had small values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e204" xlink:type="simple"/></inline-formula>. More complex STRFs, particularly those that were noisy, had larger values <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e205" xlink:type="simple"/></inline-formula> since they were poorly approximated by a low-rank decomposition.</p>
        </sec>
        <sec id="s4d2">
          <title>Modulation transfer function</title>
          <p>To characterize spectro-temporal modulation tuning in the Fourier domain, we computed the <italic>modulation transfer function</italic> (MTF) of an STRF, illustrated in <xref ref-type="fig" rid="pcbi-1002982-g011">Figure 11B</xref> <xref ref-type="bibr" rid="pcbi.1002982-Miller1">[24]</xref>. The MTF was obtained by computing the magnitude of the 2D Fourier transform of a thresholded STRF; here we set all values of the STRF that did not exceed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e206" xlink:type="simple"/></inline-formula> standard deviation to zero. The MTF summarizes the joint sensitivity of an STRF to temporal modulations (<italic>rate</italic>, in Hz) and spectral modulations (<italic>scale</italic>, in cyc/oct).</p>
          <fig id="pcbi-1002982-g011" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002982.g011</object-id>
            <label>Figure 11</label>
            <caption>
              <title>Extracting basic spectro-temporal parameters for an individual STRF.</title>
              <p>Panel (A) shows a typical STRF, with solid contour lines indicating those regions that exceed <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e207" xlink:type="simple"/></inline-formula> one standard deviation. The dashed red line shows the projected 10-dB ellipse from which we estimated spectral bandwidth. As indicated, the STRF is rather elongated with no strong directional preference, and the pattern is highly separable. Panel (B) shows the MTF computed from the magnitude of the 2D Fourier Transform of the STRF in (A); from here we estimate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e208" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e209" xlink:type="simple"/></inline-formula>. Panel (C) shows the normalized temporal and spectral modulation profiles obtained from the MTF.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002982.g011" position="float" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s4d3">
          <title>Best spectral and temporal modulation rates</title>
          <p>We selected the peak of the MTF to estimate best rate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e210" xlink:type="simple"/></inline-formula>) and best scale (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e211" xlink:type="simple"/></inline-formula>). We expected that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e212" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e213" xlink:type="simple"/></inline-formula> would summarize an STRF's preference for fast or slow temporal and spectral modulations.</p>
        </sec>
        <sec id="s4d4">
          <title>Average rate and scale profiles</title>
          <p>By folding the MTF along the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e214" xlink:type="simple"/></inline-formula> axis, we summarized the temporal and spectral modulation sensitivity of the STRF by summing along each axis, yielding rate and scale profiles; these are illustrated in <xref ref-type="fig" rid="pcbi-1002982-g011">Figure 11C</xref>. These profiles can also be averaged across an ensemble of neurons to yield a population rate or scale profile.</p>
        </sec>
        <sec id="s4d5">
          <title>Directionality index</title>
          <p>To characterize whether a neuron preferred upward vs. downward stimuli, we computed a directionality index by considering the relative difference in spectro-temporal modulation energy in the first and second quadrants in the Fourier domain. This was quantified as <xref ref-type="bibr" rid="pcbi.1002982-Depireux1">[23]</xref><disp-formula id="pcbi.1002982.e215"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e215" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e216" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e217" xlink:type="simple"/></inline-formula> denote the energy in the first and second quadrant, respectively. By convention, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e218" xlink:type="simple"/></inline-formula> indicates a preference for <italic>downward</italic> moving spectro-temporal patches whereas <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e219" xlink:type="simple"/></inline-formula> indicates a preference for <italic>upward</italic> moving spectro-temporal patches.</p>
        </sec>
        <sec id="s4d6">
          <title>Compactness</title>
          <p>To quantify a notion of compactness for an STRF, we used the <italic>isoperimetric quotient</italic>, which considers the ratio of the area of an ellipsoid to its perimeter, i.e.,<disp-formula id="pcbi.1002982.e220"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e220" xlink:type="simple"/></disp-formula>The area and perimeter were computed from the 10-dB excitatory ellipse which was derived by (1) performing a least-squares fit of a single Gaussian envelope to a thresholded STRF, (2) finding the isoline corresponding to a drop of 10-dB from the maximum of the envelope, and (3) projecting this ellipse onto the spectro-temporal plane. The compactness measure describes the degree to which the coverage of an STRF is spherical (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e221" xlink:type="simple"/></inline-formula>) versus elongated (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e222" xlink:type="simple"/></inline-formula>), and was used for characterizing localized vs. non-localized STRFs for the purpose of grouping STRF clusters (described below).</p>
        </sec>
      </sec>
      <sec id="s4e">
        <title>Characterizing STRF ensembles</title>
        <p>Next, we considered measures that characterized a variety of ensemble-based spectro-temporal and modulation properties.</p>
        <sec id="s4e1">
          <title>Ensemble modulation transfer function</title>
          <p>By averaging the MTF obtained from each STRF, we obtained an ensemble MTF (eMTF) that characterized the average spectro-temporal modulation sensitivity of a given ensemble <xref ref-type="bibr" rid="pcbi.1002982-Miller1">[24]</xref>. This representation was used to relate the average modulation tuning of an ensemble to the modulations present in the stimulus.</p>
        </sec>
        <sec id="s4e2">
          <title>Median activation of most persistent neurons</title>
          <p>In addition to analyzing the shapes of the emergent STRFs, we explored the ensemble firing rate characteristics of the emergent neurons. Using a held-out set of natural stimuli, we measured the activation of a neuron as the length of time a response was maintained above <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e223" xlink:type="simple"/></inline-formula> standard deviation (over time) for that particular neuron. We sorted each STRF according to its median activation time, and considered the median responses of the top 10% “most persistent” neurons for a given ensemble (as these subsets appeared to vary most across <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e224" xlink:type="simple"/></inline-formula>). The distributions of these activations were then used to study the extent to which enforcing a sustained response was reflected in a neuron's output.</p>
        </sec>
        <sec id="s4e3">
          <title>Average population response histogram</title>
          <p>In order to compare distributions of population responses across ensembles, we computed averaged response histograms as follows. Upon convergence of a given ensemble, we filtered a held-out set of natural sound stimuli through the emergent STRFs to obtain a population response. At each time <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e225" xlink:type="simple"/></inline-formula>, we computed a histogram of the population response, and computed the average histogram across the duration of the stimulus. These averaged histograms could then be used to compare the average population response characteristics across ensembles.</p>
          <p>When comparing the receptive field ensembles from the sparse and sustained sets, we only included the responses of highly structured, non-noisy STRFs as determined by the clustering results outlined next. This step was necessary to keep the comparison between objective functions fair since the sparse ensemble was dominated by noisy STRFs. This inclusion criterion resulted in 115 and 347 neurons for the sparse and sustained ensembles, respectively.</p>
          <p>For comparison, we also calculated the response histograms for stimuli filtered through the first 400 principal components of the stimulus (Supplemental Figure 3) as well as through a set of 400 random STRFs. Recall that the magnitudes of the emergent STRFs were constrained so that that their responses had unit variance over time. Accordingly, we normalized the responses of the principal components and random STRFs to also have unit variance to make a fair comparison.</p>
        </sec>
      </sec>
      <sec id="s4f">
        <title>Average stimulus 2D modulation profile</title>
        <p>To summarize the spectro-temporal modulations present in the natural sound stimulus, we averaged the magnitude of the 2D Fourier transform of 250 ms patches (non-overlapping) of the auditory spectrogram.</p>
      </sec>
      <sec id="s4g">
        <title>Grouping canonical classes of STRFs</title>
        <p>The optimization procedure resulted in a set of richly structured patterns that suggested the presence of a number of latent classes whose membership varied with both choice of objective function and correlation interval <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e226" xlink:type="simple"/></inline-formula>. To quantify these variations, we applied the normalized spectral clustering algorithm of Ng <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002982-Ng1">[66]</xref>.</p>
        <p>We defined the similarity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e227" xlink:type="simple"/></inline-formula> between a given pair of STRFs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e228" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e229" xlink:type="simple"/></inline-formula> by computing the normalized 2D cross-correlation matrix for arbitrary shifts in time and frequency and selecting the maximum of the <italic>absolute</italic> value of this matrix, i.e.,<disp-formula id="pcbi.1002982.e230"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e230" xlink:type="simple"/></disp-formula>where<disp-formula id="pcbi.1002982.e231"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002982.e231" xlink:type="simple"/></disp-formula>Importantly, the absolute value of the cross correlation was used here since we wished to group STRFs regardless of whether they were excitatory or inhibitory. Next, we pooled all STRFs we sought to cluster and constructed a pairwise similarity matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e232" xlink:type="simple"/></inline-formula>. Viewing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e233" xlink:type="simple"/></inline-formula> as a fully connected graph with edge weights specified by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e234" xlink:type="simple"/></inline-formula>, spectral clustering finds a partitioning of the graph into <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e235" xlink:type="simple"/></inline-formula> groups such that edges between groups have low similarity whereas edges within a group have high similarity.</p>
        <p>Defining the degree matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e236" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e237" xlink:type="simple"/></inline-formula> and unnormalized graph Laplacian <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e238" xlink:type="simple"/></inline-formula>, the normalized spectral clustering algorithm is as follows:</p>
        <list list-type="order">
          <list-item>
            <p>Compute the normalized Laplacian <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e239" xlink:type="simple"/></inline-formula>.</p>
          </list-item>
          <list-item>
            <p>Compute the first <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e240" xlink:type="simple"/></inline-formula> eigenvectors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e241" xlink:type="simple"/></inline-formula> corresponding to the largest <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e242" xlink:type="simple"/></inline-formula> eigenvalues of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e243" xlink:type="simple"/></inline-formula>.</p>
          </list-item>
          <list-item>
            <p>Let <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e244" xlink:type="simple"/></inline-formula> and form a matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e245" xlink:type="simple"/></inline-formula> from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e246" xlink:type="simple"/></inline-formula> by normalizing each row to have unit Euclidean norm.</p>
          </list-item>
          <list-item>
            <p>Denoting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e247" xlink:type="simple"/></inline-formula> as the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e248" xlink:type="simple"/></inline-formula>'th row of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e249" xlink:type="simple"/></inline-formula>, cluster the set of points <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e250" xlink:type="simple"/></inline-formula> using the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e251" xlink:type="simple"/></inline-formula>-means algorithm to obtain clusters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e252" xlink:type="simple"/></inline-formula>.</p>
          </list-item>
        </list>
        <p>We clustered the STRFs initially into 12 groups. While this number was necessarily an arbitrary choice, it was found to sufficiently capture variations in population diversity with <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e253" xlink:type="simple"/></inline-formula>. However, we found that (i) three of the resulting clusters could be reasonably labeled as <italic>noisy</italic>, whereas (ii) two of the resulting clusters could be reliably labeled as <italic>localized</italic>; merely reducing the number of initial classes did not merge the clusters, but instead blurred distinctions among the other major categories we sought to study. We interpreted <italic>noisy</italic> patterns as those with no obvious spectro-temporal structure and not indicative of any subset of the stimulus.</p>
        <p>Merging of the initial 12 classes was achieved by computing the average <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e254" xlink:type="simple"/></inline-formula> of STRFs from the initial class labels and ranking the classes in descending order. Indeed, the three <italic>noisy</italic> classes had the highest average <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e255" xlink:type="simple"/></inline-formula> and consequently resulted in a group with average <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e256" xlink:type="simple"/></inline-formula> greater than 0.5. Similarly, the localized STRFs were typically highly spherical and sorting the initial clusters by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e257" xlink:type="simple"/></inline-formula> resulted in the two <italic>localized</italic> classes to be ranked highest. Consequently, we grouped these two clusters that had an average <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e258" xlink:type="simple"/></inline-formula> of greater than 0.69. This resulted in a final cluster count of nine classes.</p>
      </sec>
      <sec id="s4h">
        <title>Analysis of Neural STRFs</title>
        <p>We obtained ensembles of neural STRFs estimated using TORC <xref ref-type="bibr" rid="pcbi.1002982-Klein2">[31]</xref> and speech stimuli <xref ref-type="bibr" rid="pcbi.1002982-David1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002982-Mesgarani1">[32]</xref>. There were 2145 TORC and 793 speech STRFs, and each STRF was pre-processed to cover 110 ms in time (sampling rate = 100 Hz) and span 5 octaves in frequency (sampling rate = 5 cyc/oct). For the spectral clustering analysis, we subsampled the TORC set by randomly selecting 793 STRFs and combined them with the speech STRFs, yielding a total of 1586 STRFs in the neural data set. In this way, the neural data analysis was not biased towards one stimulus type or the other.</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pcbi.1002982.s001" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1002982.s001" position="float" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <p><bold>STRFs corresponding to the top 10% “most persistent” responses for</bold> <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002982.e259" xlink:type="simple"/></inline-formula>.</p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002982.s002" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1002982.s002" position="float" xlink:type="simple">
        <label>Figure S2</label>
        <caption>
          <p>
            <bold>Distributions of nearest-neighbor similarities for the model ensembles (response- and shape-constrained sustained objective vs. the sparse objective) and the neural ensemble.</bold>
          </p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002982.s003" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1002982.s003" position="float" xlink:type="simple">
        <label>Figure S3</label>
        <caption>
          <p>
            <bold>Top 100 principal components of the natural stimulus ensemble.</bold>
          </p>
          <p>(TIF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We gratefully acknowledge Shihab Shamma (UMD) and Stephen David (OHSU) for providing the neural STRFs to facilitate the comparison of our modeling results with the physiology. We thank two anonymous reviewers for helpful comments on the manuscript.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002982-Simoncelli1">
        <label>1</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simoncelli</surname><given-names>EP</given-names></name>, <name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name> (<year>2001</year>) <article-title>Natural image statistics and neural representation</article-title>. <source>Annu Rev Neurosci</source> <volume>24</volume>: <fpage>1193</fpage>–<lpage>1216</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Olshausen1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>2004</year>) <article-title>Sparse coding of sensory inputs</article-title>. <source>Curr Op Neurobio</source> <volume>14</volume>: <fpage>481</fpage>–<lpage>487</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Rosenblith1">
        <label>3</label>
        <mixed-citation publication-type="other" xlink:type="simple">Rosenblith WA, editor (1961) Sensory Communication. Cambridge (Massachusetts): MIT Press.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Laughlin1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Laughlin</surname><given-names>SB</given-names></name> (<year>2001</year>) <article-title>Energy as a constraint on the coding and processing of sensory information</article-title>. <source>Curr Op Neurobio</source> <volume>11</volume>: <fpage>475</fpage>–<lpage>480</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Olshausen2">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name>, <name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name> (<year>1996</year>) <article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title>. <source>Nature</source> <volume>381</volume>: <fpage>607</fpage>–<lpage>609</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Vinje1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Vinje</surname><given-names>WE</given-names></name>, <name name-style="western"><surname>Gallant</surname><given-names>JL</given-names></name> (<year>2000</year>) <article-title>Sparse coding and decorrelation in primary visual cortex during natural vision</article-title>. <source>Science</source> <volume>287</volume>: <fpage>1273</fpage>–<lpage>1276</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-DeWeese1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>DeWeese</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Wehr</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Zador</surname><given-names>AM</given-names></name> (<year>2003</year>) <article-title>Binary spiking in auditory cortex</article-title>. <source>J Neurosci</source> <volume>23</volume>: <fpage>7940</fpage>–<lpage>7949</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Hromdka1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hromádka</surname><given-names>T</given-names></name>, <name name-style="western"><surname>DeWeese</surname><given-names>MR</given-names></name>, <name name-style="western"><surname>Zador</surname><given-names>AM</given-names></name> (<year>2008</year>) <article-title>Sparse representation of sounds in the unanesthetized auditory cortex</article-title>. <source>PLoS Bio</source> <volume>6</volume>: <fpage>e16</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Klein1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>König</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Körding</surname><given-names>KP</given-names></name> (<year>2003</year>) <article-title>Sparse spectrotemporal coding of sounds</article-title>. <source>EURASIP J Appl Sig Proc</source> <volume>2003</volume>: <fpage>659</fpage>–<lpage>667</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Smith1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smith</surname><given-names>EC</given-names></name>, <name name-style="western"><surname>Lewicki</surname><given-names>MS</given-names></name> (<year>2006</year>) <article-title>Effcient auditory coding</article-title>. <source>Nature</source> <volume>439</volume>: <fpage>978</fpage>–<lpage>982</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Carlson1">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Carlson</surname><given-names>NL</given-names></name>, <name name-style="western"><surname>Ming</surname><given-names>VL</given-names></name>, <name name-style="western"><surname>DeWeese</surname><given-names>MR</given-names></name> (<year>2012</year>) <article-title>Sparse codes for speech predict spectrotemporal receptive fields in the inferior colliculus</article-title>. <source>PLoS Comp Bio</source> <volume>8</volume>: <fpage>e1002594</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Wang1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Lu</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Snider</surname><given-names>RK</given-names></name>, <name name-style="western"><surname>Liang</surname><given-names>L</given-names></name> (<year>2005</year>) <article-title>Sustained firing in auditory cortex evoked by preferred stimuli</article-title>. <source>Nature</source> <volume>435</volume>: <fpage>341</fpage>–<lpage>346</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Wang2">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Lu</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Bendor</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Bartlett</surname><given-names>E</given-names></name> (<year>2008</year>) <article-title>Neural coding of temporal information in auditory thalamus and cortex</article-title>. <source>Neuroscience</source> <volume>157</volume>: <fpage>484</fpage>–<lpage>493</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Petkov1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Petkov</surname><given-names>CI</given-names></name>, <name name-style="western"><surname>O'Connor</surname><given-names>KN</given-names></name>, <name name-style="western"><surname>Sutter</surname><given-names>ML</given-names></name> (<year>2007</year>) <article-title>Encoding of illusory continuity in primary auditory cortex</article-title>. <source>Neuron</source> <volume>54</volume>: <fpage>153</fpage>–<lpage>165</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Wang3">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wang</surname><given-names>X</given-names></name> (<year>2007</year>) <article-title>Neural coding strategies in auditory cortex</article-title>. <source>Hearing Research</source> <volume>229</volume>: <fpage>81</fpage>–<lpage>93</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Elhilali1">
        <label>16</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elhilali</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Fritz</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Klein</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name> (<year>2004</year>) <article-title>Dynamics of precise spike timing in primary auditory cortex</article-title>. <source>J Neurosci</source> <volume>24</volume>: <fpage>1159</fpage>–<lpage>1172</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Elhilali2">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elhilali</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name> (<year>2008</year>) <article-title>A cocktail party with a cortical twist: how cortical mechanisms contribute to sound segregation</article-title>. <source>J Acoust Soc Am</source> <volume>124</volume>: <fpage>3751</fpage>–<lpage>3771</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Hurri1">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hurri</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name> (<year>2003</year>) <article-title>Simple-cell-like receptive fields maximize temporal coherence in natural video</article-title>. <source>Neural Comp</source> <volume>15</volume>: <fpage>663</fpage>–<lpage>691</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Krding1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Körding</surname><given-names>KP</given-names></name>, <name name-style="western"><surname>Kayser</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Einhäuser</surname><given-names>W</given-names></name>, <name name-style="western"><surname>König</surname><given-names>P</given-names></name> (<year>2004</year>) <article-title>How are complex cell properties adapted to the statistics of natural stimuli?</article-title> <source>J Neurophys</source> <volume>91</volume>: <fpage>206</fpage>–<lpage>212</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Wiskott1">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Sejnowski</surname><given-names>TJ</given-names></name> (<year>2002</year>) <article-title>Slow feature analysis: unsupervised learning of invariances</article-title>. <source>Neural Comp</source> <volume>14</volume>: <fpage>715</fpage>–<lpage>770</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Middlebrooks1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Middlebrooks</surname><given-names>JC</given-names></name> (<year>2005</year>) <article-title>Auditory cortex cheers the overture and listens through the finale</article-title>. <source>Nature Neurosci</source> <volume>8</volume>: <fpage>851</fpage>–<lpage>852</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Aertsen1">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Aertsen</surname><given-names>AMHJ</given-names></name>, <name name-style="western"><surname>Johannesma</surname><given-names>PIM</given-names></name> (<year>1981</year>) <article-title>The spectro-temporal receptive field</article-title>. <source>Biol Cybernetics</source> <volume>42</volume>: <fpage>133</fpage>–<lpage>143</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Depireux1">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Depireux</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name>, <name name-style="western"><surname>Klein</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>S</given-names></name> (<year>2001</year>) <article-title>Spectro-temporal response field characterization with dynamic ripples in ferret primary auditory cortex</article-title>. <source>J Neurophys</source> <volume>85</volume>: <fpage>1220</fpage>–<lpage>1234</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Miller1">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Miller</surname><given-names>LM</given-names></name>, <name name-style="western"><surname>Escabí</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Read</surname><given-names>HL</given-names></name>, <name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name> (<year>2002</year>) <article-title>Spectrotemporal receptive fields in the lemniscal auditory thalamus and cortex</article-title>. <source>J Neurophys</source> <volume>87</volume>: <fpage>516</fpage>–<lpage>527</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Fritz1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fritz</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Elhilali</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Klein</surname><given-names>D</given-names></name> (<year>2003</year>) <article-title>Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex</article-title>. <source>Nature Neurosci</source> <volume>6</volume>: <fpage>1216</fpage>–<lpage>1223</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Willmore1">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Willmore</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Tolhurst</surname><given-names>DJ</given-names></name> (<year>2001</year>) <article-title>Characterizing the sparseness of neural codes</article-title>. <source>Network: Computation in Neural Systems</source> <volume>12</volume>: <fpage>255</fpage>–<lpage>270</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-David1">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>David</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Mesgarani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Fritz</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name> (<year>2009</year>) <article-title>Rapid synaptic depression explains nonlinear modulation of spectro-temporal tuning in primary auditory cortex by natural stimuli</article-title>. <source>J Neurosci</source> <volume>29</volume>: <fpage>3374</fpage>–<lpage>3386</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Wooley1">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wooley</surname><given-names>SMN</given-names></name>, <name name-style="western"><surname>Gill</surname><given-names>PR</given-names></name>, <name name-style="western"><surname>Fremouw</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>2009</year>) <article-title>Functional groups in the avian auditory system</article-title>. <source>J Neurosci</source> <volume>20</volume>: <fpage>2780</fpage>–<lpage>2793</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Rosen1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosen</surname><given-names>S</given-names></name> (<year>1992</year>) <article-title>Temporal information in speech: acoustic, auditory, and linguistic aspects</article-title>. <source>Phil Trans R Soc Lond B</source> <volume>336</volume>: <fpage>367</fpage>–<lpage>373</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Singh1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Singh</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>2003</year>) <article-title>Modulation spectra of natural sounds and ethological theories of auditory processing</article-title>. <source>J Acoust Soc Am</source> <volume>114</volume>: <fpage>3394</fpage>–<lpage>3411</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Klein2">
        <label>31</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klein</surname><given-names>DJ</given-names></name>, <name name-style="western"><surname>Depireux</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Simon</surname><given-names>JZ</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name> (<year>2000</year>) <article-title>Robust spectrotemporal reverse correlation for the auditory system: Optimizing stimulus design</article-title>. <source>J Comp Neurosci</source> <volume>9</volume>: <fpage>85</fpage>–<lpage>111</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Mesgarani1">
        <label>32</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mesgarani</surname><given-names>N</given-names></name>, <name name-style="western"><surname>David</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Fritz</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name> (<year>2009</year>) <article-title>Inuence of context and behavior on stimulus reconstruction from neural activity in primary auditory cortex</article-title>. <source>J Neurosci</source> <volume>102</volume>: <fpage>3329</fpage>–<lpage>3339</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Berkes1">
        <label>33</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name> (<year>2005</year>) <article-title>Slow feature analysis yields a rich repertoire of complex cell properties</article-title>. <source>J Vision</source> <volume>5</volume>: <fpage>579</fpage>–<lpage>602</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Attias1">
        <label>34</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Attias</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name> (<year>1997</year>) <article-title>Temporal low-order statistics of natural sounds</article-title>. <source>Adv. Neural Inf. Proc. Sys</source> <volume>9</volume>: <fpage>27</fpage>–<lpage>33</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-HashimotoW1">
        <label>35</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><collab xlink:type="simple">HashimotoW</collab> (<year>2003</year>) <article-title>Quadratic forms in natural images</article-title>. <source>Network: Computation in Neural Systems</source> <volume>14</volume>: <fpage>765</fpage>–<lpage>788</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Woolley1">
        <label>36</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woolley</surname><given-names>SMN</given-names></name>, <name name-style="western"><surname>Fremouw</surname><given-names>TE</given-names></name>, <name name-style="western"><surname>Hsu</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name> (<year>2005</year>) <article-title>Tuning for spectro-temporal modulations as a mechanism for auditory discrimination of natural sounds</article-title>. <source>Nature Neurosci</source> <volume>8</volume>: <fpage>1371</fpage>–<lpage>1379</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Nagel1">
        <label>37</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nagel</surname><given-names>KI</given-names></name>, <name name-style="western"><surname>Doupe</surname><given-names>AJ</given-names></name> (<year>2008</year>) <article-title>Organizing principles of spectro-temporal encoding in the avian primary auditory area Field L</article-title>. <source>Neuron</source> <volume>58</volume>: <fpage>938</fpage>–<lpage>955</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Rodriguez1">
        <label>38</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rodriguez</surname><given-names>FA</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Read</surname><given-names>HL</given-names></name>, <name name-style="western"><surname>Escabí</surname><given-names>MA</given-names></name> (<year>2010</year>) <article-title>Neural modulation tuning characteristics scale to efficiently encode natural sound statistics</article-title>. <source>J Neurosci</source> <volume>30</volume>: <fpage>15969</fpage>–<lpage>15980</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Fldik1">
        <label>39</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Földiák</surname><given-names>P</given-names></name> (<year>1991</year>) <article-title>Learning invariances from transformational sequences</article-title>. <source>Neural Comp</source> <volume>3</volume>: <fpage>194</fpage>–<lpage>2000</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Mitchison1">
        <label>40</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mitchison</surname><given-names>G</given-names></name> (<year>1991</year>) <article-title>Removing time variation with the anti-Hebbian differential synapse</article-title>. <source>Neural Comp</source> <volume>3</volume>: <fpage>312</fpage>–<lpage>320</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Becker1">
        <label>41</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Becker</surname><given-names>S</given-names></name> (<year>1993</year>) <article-title>Learning to categorize objects using temporal coherence</article-title>. <source>Adv Neural Inf Proc Sys</source> <volume>5</volume>: <fpage>361</fpage>–<lpage>368</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Hyvrinen1">
        <label>42</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hyvärinen</surname><given-names>A</given-names></name> (<year>2001</year>) <article-title>Blind source separation by nonstationarity of variance: a cumulant-based approach</article-title>. <source>IEEE Trans Neural Networks</source> <volume>12</volume>: <fpage>1471</fpage>–<lpage>1474</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Bishop1">
        <label>43</label>
        <mixed-citation publication-type="other" xlink:type="simple">Bishop CM (2006) Pattern Recognition and Machine Learning. New York: Springer. 740 p.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Berkes2">
        <label>44</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name> (<year>2006</year>) <article-title>On the analysis and interpretation of inhomogeneous quadratic forms as receptive fields</article-title>. <source>Neural Comp</source> <volume>18</volume>: <fpage>1868</fpage>–<lpage>1895</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Sharpee1">
        <label>45</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sharpee</surname><given-names>TO</given-names></name>, <name name-style="western"><surname>Atencio</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Schreiner</surname><given-names>CE</given-names></name> (<year>2011</year>) <article-title>Hierarchical representations in the auditory cortex</article-title>. <source>Curr Op Neurobio</source> <volume>21</volume>: <fpage>761</fpage>–<lpage>767</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Blaschke1">
        <label>46</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Blaschke</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Berkes</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Wiskott</surname><given-names>L</given-names></name> (<year>2006</year>) <article-title>What is the relation between slow feature analysis and independent component analysis?</article-title> <source>Neural Comp</source> <volume>18</volume>: <fpage>2495</fpage>–<lpage>2508</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Hyvrinen2">
        <label>47</label>
        <mixed-citation publication-type="other" xlink:type="simple">Hyvärinen A, Karhunen J, Oja E (2001) Independent Component Analysis. New York: John Wiley and Sons. 504 p.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Klampfl1">
        <label>48</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Klampfl</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Maass</surname><given-names>W</given-names></name> (<year>2010</year>) <article-title>A theoretical basis for emergent pattern discrimination in neural systems through slow feature extraction</article-title>. <source>Neural Comp</source> <volume>22</volume>: <fpage>2979</fpage>–<lpage>3035</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Creutzig1">
        <label>49</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Creutzig</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Sprekeler</surname><given-names>H</given-names></name> (<year>2008</year>) <article-title>Predictive coding and the slowness principle: an informationtheoretic approach</article-title>. <source>Neural Comp</source> <volume>20</volume>: <fpage>1026</fpage>–<lpage>1041</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Sprekeler1">
        <label>50</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sprekeler</surname><given-names>H</given-names></name> (<year>2011</year>) <article-title>On the relation of slow feature analysis and Laplacian eigenmaps</article-title>. <source>Neural Comp</source> <volume>23</volume>: <fpage>3287</fpage>–<lpage>3302</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Hermansky1">
        <label>51</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hermansky</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Morgan</surname><given-names>N</given-names></name> (<year>1994</year>) <article-title>RASTA processing of speech</article-title>. <source>IEEE Trans Speech and Audio Process</source> <volume>2</volume>: <fpage>382</fpage>–<lpage>395</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Nemala1">
        <label>52</label>
        <mixed-citation publication-type="other" xlink:type="simple">Nemala SK, Patil K, Elhilali M (2011) Multistream bandpass modulation features for robust speech recognition. In: Interspeech 2011, 12<sup>th</sup> Annual Conference of the International Speech Communication Association; 27–31 August 2011; Florence, Italy.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Nemala2">
        <label>53</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nemala</surname><given-names>SK</given-names></name> (<year>2012</year>) <article-title>Robust Speech Recognition by Humans and Machines: The Role of Spectro-Temporal Modulations</article-title>. <source>Ph.D. thesis, Johns Hopkins University</source></mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Carlin1">
        <label>54</label>
        <mixed-citation publication-type="other" xlink:type="simple">Carlin MA, Patil K, Nemala SK, Elhilali M (2012) Robust phoneme recognition using biomimetic speech contours. In: Interspeech 2012, 13<sup>th</sup> Annual Conference of the International Speech Communication Association; 9–13 September 2012; Portland, Oregon.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Calabrese1">
        <label>55</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Calabrese</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Schumacher</surname><given-names>JW</given-names></name>, <name name-style="western"><surname>Schneider</surname><given-names>DM</given-names></name>, <name name-style="western"><surname>Paninski</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Wooley</surname><given-names>SMN</given-names></name> (<year>2011</year>) <article-title>A generalized linear model for estimating spectrotemporal receptive fields from responses to natural sounds</article-title>. <source>PLoS ONE</source> <volume>6</volume>: <fpage>e16104</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Cadieu1">
        <label>56</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cadieu</surname><given-names>CF</given-names></name>, <name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name> (<year>2009</year>) <article-title>Learning transformational invariants from natural movies</article-title>. <source>Adv Neural Inf Proc Sys</source> <volume>21</volume>: <fpage>209</fpage>–<lpage>216</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Garofolo1">
        <label>57</label>
        <mixed-citation publication-type="other" xlink:type="simple">Garofolo JS, Lamel LF, Fisher WM, Fiscus JG, Pallett DS, <etal>et al</etal>.. (1993) TIMIT Acoustic-Phonetic Continuous Speech Corpus, Linguistic Data Consortium, Philadelphia.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-1">
        <label>58</label>
        <mixed-citation publication-type="other" xlink:type="simple">(2006) The BBC Sound Effects Library Original Series, <ext-link ext-link-type="uri" xlink:href="http://www.soundideas.com" xlink:type="simple">http://www.soundideas.com</ext-link>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Yang1">
        <label>59</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yang</surname><given-names>X</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name> (<year>1992</year>) <article-title>Auditory representations of acoustic signals</article-title>. <source>IEEE Trans Information Theory</source> <volume>38</volume>: <fpage>824</fpage>–<lpage>839</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Chi1">
        <label>60</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Chi</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Ru</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Shamma</surname><given-names>SA</given-names></name> (<year>2005</year>) <article-title>Multiresolution spectrotemporal analysis of complex sounds</article-title>. <source>J Acoust Soc Am</source> <volume>118</volume>: <fpage>887</fpage>–<lpage>906</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Theunissen1">
        <label>61</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Theunissen</surname><given-names>FE</given-names></name>, <name name-style="western"><surname>David</surname><given-names>SV</given-names></name>, <name name-style="western"><surname>Singh</surname><given-names>NC</given-names></name>, <name name-style="western"><surname>Hsu</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Vinje</surname><given-names>WE</given-names></name>, <etal>et al</etal>. (<year>2001</year>) <article-title>Estimating spatio-temporal receptive fields of auditory and visual neurons from their responses to natural stimuli</article-title>. <source>Neuron: Computation in Neural Systems</source> <volume>12</volume>: <fpage>289</fpage>–<lpage>316</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Rosen2">
        <label>62</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rosen</surname><given-names>JB</given-names></name> (<year>1961</year>) <article-title>The gradient projection method for nonlinear programming: part II. Nonlinear constraints</article-title>. <source>J Soc Indust Appl Math</source> <volume>9</volume>: <fpage>514</fpage>–<lpage>532</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Luenberger1">
        <label>63</label>
        <mixed-citation publication-type="other" xlink:type="simple">Luenberger DG (1969) Optimization by Vector Space Methods. New York: Wiley.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Horn1">
        <label>64</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Horn</surname><given-names>BKP</given-names></name>, <name name-style="western"><surname>Hilden</surname><given-names>HM</given-names></name>, <name name-style="western"><surname>Negahdaripour</surname><given-names>S</given-names></name> (<year>1988</year>) <article-title>Closed form solution of absolute orientation using orthonormal matrices</article-title>. <source>J Optical Soc A</source> <volume>5</volume>: <fpage>1127</fpage>–<lpage>1135</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Horn2">
        <label>65</label>
        <mixed-citation publication-type="other" xlink:type="simple">Horn RA, Johnson CR (1985) Matrix Analysis. Cambridge Univ. Press.</mixed-citation>
      </ref>
      <ref id="pcbi.1002982-Ng1">
        <label>66</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ng</surname><given-names>AY</given-names></name>, <name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Weiss</surname><given-names>Y</given-names></name> (<year>2002</year>) <article-title>On spectral clustering: analysis and an algorithm</article-title>. <source>Adv Neural Inf Proc Sys</source> <volume>14</volume>: <fpage>849</fpage>–<lpage>856</lpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
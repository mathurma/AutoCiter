<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
      <journal-id journal-id-type="pmc">ploscomp</journal-id>
      <journal-title-group>
        <journal-title>PLoS Computational Biology</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1553-734X</issn>
      <issn pub-type="epub">1553-7358</issn>
      <publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-01231</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pcbi.1002960</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Computational biology</subject>
            <subj-group>
              <subject>Biochemical simulations</subject>
              <subject>Synthetic biology</subject>
              <subject>Systems biology</subject>
            </subj-group>
          </subj-group>
          <subj-group>
            <subject>Synthetic biology</subject>
          </subj-group>
          <subj-group>
            <subject>Systems biology</subject>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Engineering</subject>
          <subj-group>
            <subject>Bioengineering</subject>
            <subj-group>
              <subject>Biological systems engineering</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Genetics and Genomics</subject>
          <subject>Molecular Biology</subject>
          <subject>Computational Biology</subject>
          <subject>Biotechnology</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Combined Model of Intrinsic and Extrinsic Variability for Computational Network Design with Application to Synthetic Biology</article-title>
        <alt-title alt-title-type="running-head">Variability in Computational Design</alt-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Toni</surname>
            <given-names>Tina</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Tidor</surname>
            <given-names>Bruce</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <label>1</label>
        <addr-line>Department of Biological Engineering, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America</addr-line>
      </aff>
      <aff id="aff2">
        <label>2</label>
        <addr-line>Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America</addr-line>
      </aff>
      <aff id="aff3">
        <label>3</label>
        <addr-line>Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, Massachusetts, United States of America</addr-line>
      </aff>
      <contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Gabhann</surname>
            <given-names>Feilim Mac</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group>
      <aff id="edit1">
        <addr-line>Johns Hopkins University, United States of America</addr-line>
      </aff>
      <author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">ttoni@mit.edu</email> (TT); <email xlink:type="simple">tidor@mit.edu</email> (BT)</corresp>
        <fn fn-type="conflict">
          <p>The authors have declared that no competing interests exist.</p>
        </fn>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: TT BT. Performed the experiments: TT. Analyzed the data: TT BT. Contributed reagents/materials/analysis tools: TT. Wrote the paper: TT BT.</p>
        </fn>
      </author-notes>
      <pub-date pub-type="collection">
        <month>3</month>
        <year>2013</year>
      </pub-date>
      <pub-date pub-type="epub">
        <day>28</day>
        <month>3</month>
        <year>2013</year>
      </pub-date>
      <volume>9</volume>
      <issue>3</issue>
      <elocation-id>e1002960</elocation-id>
      <history>
        <date date-type="received">
          <day>28</day>
          <month>7</month>
          <year>2012</year>
        </date>
        <date date-type="accepted">
          <day>16</day>
          <month>1</month>
          <year>2013</year>
        </date>
      </history>
      <permissions>
        <copyright-year>2013</copyright-year>
        <copyright-holder>Toni and Tidor</copyright-holder>
        <license xlink:type="simple">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
        </license>
      </permissions>
      <abstract>
        <p>Biological systems are inherently variable, with their dynamics influenced by intrinsic and extrinsic sources. These systems are often only partially characterized, with large uncertainties about specific sources of extrinsic variability and biochemical properties. Moreover, it is not yet well understood how different sources of variability combine and affect biological systems in concert. To successfully design biomedical therapies or synthetic circuits with robust performance, it is crucial to account for uncertainty and effects of variability. Here we introduce an efficient modeling and simulation framework to study systems that are simultaneously subject to multiple sources of variability, and apply it to make design decisions on small genetic networks that play a role of basic design elements of synthetic circuits. Specifically, the framework was used to explore the effect of transcriptional and post-transcriptional autoregulation on fluctuations in protein expression in simple genetic networks. We found that autoregulation could either suppress or increase the output variability, depending on specific noise sources and network parameters. We showed that transcriptional autoregulation was more successful than post-transcriptional in suppressing variability across a wide range of intrinsic and extrinsic magnitudes and sources. We derived the following design principles to guide the design of circuits that best suppress variability: (i) high protein cooperativity and low miRNA cooperativity, (ii) imperfect complementarity between miRNA and mRNA was preferred to perfect complementarity, and (iii) correlated expression of mRNA and miRNA – for example, on the same transcript – was best for suppression of protein variability. Results further showed that correlations in kinetic parameters between cells affected the ability to suppress variability, and that variability in transient states did not necessarily follow the same principles as variability in the steady state. Our model and findings provide a general framework to guide design principles in synthetic biology.</p>
      </abstract>
      <abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>Variability is inherent in biological systems, and in order to understand them, we need to be able to model different sources of variability. Systems have evolved to harness and control the variability, and more recently, synthetic biologists are trying to learn how to control variability in engineered biological systems. Several sources of variability exist; they arise due to stochastic expression of genes, which is most pronounced when numbers of mRNA and protein molecules are low, as well as due to differences between individual cells. Here we propose a modeling framework that combines different sources of biological variability. Furthermore, current research seeks to control biological variability though robust design of synthetic biological circuits, for example for use in therapies and other biomedical or biotechnological applications. Here we apply our framework to guide design of synthetic circuits that use transcriptional and post-transcriptional regulation to suppress variability in the output protein of interest. We find that certain properties and network designs are better than others in their ability to control variability, and here we report on the design guidelines to aid synthetic circuit design to suppress variability, in spite of our uncertain knowledge of parameters.</p>
      </abstract>
      <funding-group>
        <funding-statement>This work was supported by the Wellcome Trust [090433/Z/09/Z] (TT); NIH [CA112967] (BT); and the Singapore-MIT Alliance for Research and Technology (BT). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
      <counts>
        <page-count count="17"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Biological systems are complex, inherently noisy and only partially understood <xref ref-type="bibr" rid="pcbi.1002960-Raj1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1002960-Balzsi1">[5]</xref>. Systems and synthetic biologists are striving to better understand these systems, as well as to discover generally applicable principles for controlling them in biomedical and biotechnological applications. For example, a branch of systems biology studies how to best interfere with variable and under-characterized signaling pathways to identify novel drug targets <xref ref-type="bibr" rid="pcbi.1002960-Butcher1">[6]</xref>–<xref ref-type="bibr" rid="pcbi.1002960-Iyengar1">[8]</xref>. In clinical pharmacology, decisions need to be made by using uncertain models of drug effects on the human body across populations and should ideally be robust to patient-to-patient differences <xref ref-type="bibr" rid="pcbi.1002960-Kim1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-vanderGraaf1">[10]</xref>. Synthetic biologists strive to build synthetic circuits that perform desired functions across a population of cells, despite their noisy nature, cell-to-cell variability, and changing environments <xref ref-type="bibr" rid="pcbi.1002960-Purnick1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Mukherji1">[12]</xref>.</p>
      <p>We are faced with a challenge of how to best represent, simulate, analyze, and carry out design for noisy systems with under-characterized biochemical properties, which are often represented as uncertain parameters. We propose a modeling and simulation framework as a tool to aid in meeting these challenges. In this manuscript we specifically focus on making design decisions for synthetic genetic networks, but the modeling technique is sufficiently general to be applicable to a wide range of problems in biology, biological engineering, and medicine. The framework accounts for different sources of variability and is computationally efficient, so that it allows screening across broad parameter ranges.</p>
      <p>Intrinsic variability (or intrinsic stochasticity) is a relatively well understood aspect of biological models. It arises from the probabilistic nature of the timing of collision events between reacting biological molecules, and its effect is most pronounced when the number of molecules in the system is small. Traditionally intrinsic variability is modeled by a stochastic master equation, which is the foundation for modeling stochastic dynamics in most physical, chemical, and biological phenomena <xref ref-type="bibr" rid="pcbi.1002960-vanKampen1">[13]</xref>. Unfortunately, its analytic solution can only be found for a few trivial models, and a good alternative for studying stochastic models is the exact simulation framework of Gillespie <xref ref-type="bibr" rid="pcbi.1002960-Gillespie1">[14]</xref>. However, to obtain a distribution resulting from the intrinsic variability, many trajectories of the Gillespie algorithm need to be simulated, which can be computationally expensive. A practical alternative is to use analytically tractable approximation schemes <xref ref-type="bibr" rid="pcbi.1002960-Wilkinson1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-GmezUribe1">[16]</xref>. In this manuscript we approximate stochastic dynamics by van Kampen's <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e001" xlink:type="simple"/></inline-formula>-expansion <xref ref-type="bibr" rid="pcbi.1002960-vanKampen1">[13]</xref> (also called the linear noise approximation or perturbation expansion; see <xref ref-type="sec" rid="s4">Methods</xref>), for its computational efficiency and analytic form. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e002" xlink:type="simple"/></inline-formula>-expansion separates the macroscopic dynamics from the fluctuations around it, describing each of these parts by a set of ordinary differential equations (ODEs). This model allows for efficient propagation of the first two moments of the intrinsic noise distribution through time using deterministic equations for mean, variances, and covariances. The model very accurately approximates stochastic dynamics for medium and large molecular numbers and when variability is small compared to the mean number of molecules, but can lose on accuracy when numbers of molecules are very small and the relative fluctuation size increases <xref ref-type="bibr" rid="pcbi.1002960-Kurtz1">[17]</xref>–<xref ref-type="bibr" rid="pcbi.1002960-Komorowski1">[19]</xref>; here we check using Gillespie simulations that the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e003" xlink:type="simple"/></inline-formula>-expansion distributions are accurate. Analytic studies of the accuracy of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e004" xlink:type="simple"/></inline-formula>-expansion and comparison with other traditional approaches for modeling intrinsic noise such as Fokker Planck equation and the chemical Langevin equation can be found in <xref ref-type="bibr" rid="pcbi.1002960-Kurtz1">[17]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Tomioka1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Grima1">[20]</xref> and a summary on validity of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e005" xlink:type="simple"/></inline-formula>-expansion in the Supplementary material of <xref ref-type="bibr" rid="pcbi.1002960-Komorowski1">[19]</xref>. Despite this caveat, and mainly due to its efficiency and possibility of analytic study, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e006" xlink:type="simple"/></inline-formula>-expansion has played an important role in advancing the understanding of intrinsic variability <xref ref-type="bibr" rid="pcbi.1002960-Paulsson1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Tomioka1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Elf1">[21]</xref>–<xref ref-type="bibr" rid="pcbi.1002960-Komorowski3">[24]</xref>. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e007" xlink:type="simple"/></inline-formula>-expansion can most conservatively be applied to models with a single steady state — in this manuscript we will only consider such models — but with certain limitations or modifications it can also be applied to multimodal and oscillatory models <xref ref-type="bibr" rid="pcbi.1002960-Jayanthi1">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Scott1">[25]</xref>–<xref ref-type="bibr" rid="pcbi.1002960-Ito1">[27]</xref>.</p>
      <p>Significant effort has been invested in modeling intrinsic variability in systems and synthetic biology, although it has been shown that extrinsic variability generally dominates, especially in eukaryotic systems <xref ref-type="bibr" rid="pcbi.1002960-Elowitz1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Raser1">[28]</xref>. Extrinsic variability arises due to varying components upstream of the system of interest; these components affect the system, varying stochastically in time themselves, and might be present in different amounts in cells due to differences such as size and stage of the cell cycle <xref ref-type="bibr" rid="pcbi.1002960-Elowitz1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Paulsson1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Waks1">[29]</xref>. For example, the numbers of ribosomes and the numbers of RNA polymerases vary in time and between cells. Another source of extrinsic variability is cell-to-cell variability of the gene copy number, which is common in synthetic biology applications when genes are delivered into cells by plasmid transfection, after which different numbers of plasmids are taken up by different cells. As a result of such sources of variability, single cells within a population possess distinct quantitative dynamic behaviors.</p>
      <p>As yet, there is no commonly accepted framework for modeling extrinsic variability. Despite several strong mathematical and theoretical studies of intrinsic and extrinsic variability <xref ref-type="bibr" rid="pcbi.1002960-Elowitz1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Paulsson1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Swain1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Hilfinger1">[31]</xref>, computational modeling efforts that combine intrinsic and extrinsic variability are still rare. Shahrezaei <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002960-Shahrezaei1">[32]</xref> proposed an extension to the Gillespie approach that includes kinetic parameter perturbations representing extrinsic variability; the downside of this method is that it is extremely costly. Scott <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002960-Scott2">[26]</xref> proposed a more efficient, approximate model for steady-state extrinsic variability that can account for variations of one parameter at a time. Zechner <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002960-Zechner1">[33]</xref> used low-order moments through the moment closure approach to approximate intrinsic and extrinsic distributions; this approach requires analytic derivation of a new model structure for each additional extrinsic factor. Hallen <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002960-Hallen1">[34]</xref> proposed a non-mechanistic method of modeling extrinsic variability by perturbing the steady-state intrinsic noise distribution, but without any mechanistic assumption regarding the sources of extrinsic variability. Singh <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002960-Singh1">[35]</xref> model extrinsic variability by adding noisy exogenous signals to an intrinsic stochastic model.</p>
      <p>Here we model extrinsic variability by introducing variability in model parameters and initial conditions; rather than considering them as point values, we consider them as distributions (<xref ref-type="fig" rid="pcbi-1002960-g001">Figures 1</xref>, <xref ref-type="supplementary-material" rid="pcbi.1002960.s001">S1</xref>). We propagate these distributions through a model to simulate model output distributions resulting from extrinsic variability. For computational convenience we work with normally distributed parameters, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e008" xlink:type="simple"/></inline-formula> (for simplicity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e009" xlink:type="simple"/></inline-formula> denotes a vector of all parameters and initial conditions). To simulate propagation of extrinsic variability through the model, we use the Unscented Transform (UT). The UT efficiently maps the first two moments of the variability distribution in the parameter space onto the first two moments of variability distribution in the output. Estimates of the mean and covariance matrix obtained by the UT are accurate to second order in the Taylor series expansion for any nonlinear function, which makes the algorithm very appealing for propagating distributions through nonlinear functions <xref ref-type="bibr" rid="pcbi.1002960-vanDerMerwe1">[36]</xref>. Nonlinearity is propagated through simulating the nonlinear function for a chosen set of parameters (called sigma-points, see <xref ref-type="sec" rid="s4">Methods</xref>) and reconstructing the output distribution from these individual simulations. This can capture nonlinearity such as a shifts in a mean, for example, when extrinsic variability increases.</p>
      <fig id="pcbi-1002960-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Framework overview.</title>
          <p>The framework combines intrinsic and extrinsic sources of variability and computes the total variability in model output. Extrinsic variability enters the model through variability in kinetic parameters and initial conditions. Intrinsic stochasticity is accounted for in the choice of a dynamical system; the master equation is the standard way of representing intrinsic variability, and due to its intractability we use an approximation of the master equation known as the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e010" xlink:type="simple"/></inline-formula>-expansion.</p>
        </caption>
        <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g001" position="float" xlink:type="simple"/>
      </fig>
      <p>Despite knowing that extrinsic variability contributes significantly to the total variability, little is known about its sources <xref ref-type="bibr" rid="pcbi.1002960-Snijder1">[37]</xref>. This creates a major caveat that arises when attempting to make informed design decisions. The second ubiquitous caveat on the way to building predictive models of stochastic systems is that kinetic parameters are often unknown. Here we are motivated by a question of how to make robust design choices, given these uncertainties and limited knowledge of extrinsic variability.</p>
      <p>In this paper we use our method to study variability in simple gene regulatory networks; such networks are a basis for transcription-based synthetic circuits. We first introduce a combined intrinsic and extrinsic modeling approach and derive the expression for the total variability. The framework is then used to explore the effect of self-repression on protein variability in simple genetic networks that are simultaneously under different sources of noise. We are interested in details related to how self-repression can be used as an element in synthetic circuits to reduce variability. We consider two types of self-repression, on a transcriptional and on a post-transcriptional level, and ask which is more successful in reducing protein variability. We are further interested in specific design principles that help optimally achieve the aim of noise suppression.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
        <title>Combined model of intrinsic and extrinsic variability, and derivation of total variability</title>
        <p>The central methodological advance of this manuscript is a method and efficient framework to model total variability as a combination of intrinsic and extrinsic sources. Here we formalize the framework (overview in <xref ref-type="fig" rid="pcbi-1002960-g001">Figure 1</xref>) and illustrate it on a simple model of transcription and translation of a single gene, with species mRNA, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e011" xlink:type="simple"/></inline-formula>, and protein, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e012" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002960-g002">Figure 2A</xref>) <xref ref-type="bibr" rid="pcbi.1002960-Thattai1">[38]</xref>. The parameters of the model are transcription rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e013" xlink:type="simple"/></inline-formula>, translation rate, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e014" xlink:type="simple"/></inline-formula>, and mRNA and protein degradation rates, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e015" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e016" xlink:type="simple"/></inline-formula>, respectively. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e017" xlink:type="simple"/></inline-formula> is the initial condition representing the copy number of genes encoding protein <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e018" xlink:type="simple"/></inline-formula>. We denote the vector of parameters and initial conditions by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e019" xlink:type="simple"/></inline-formula>.</p>
        <fig id="pcbi-1002960-g002" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g002</object-id>
          <label>Figure 2</label>
          <caption>
            <title>Framework illustrated on a single gene expression model.</title>
            <p>(A) Single gene expression model. (B) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e020" xlink:type="simple"/></inline-formula>-expansion equations (intrinsic stochasticity). (C) Simulation of intrinsic variability (fixed parameters). (D) Simulation of covariance of intrinsic distribution (fixed parameters). (E) Simulation of intrinsic and extrinsic variability. (F) Total variability.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g002" position="float" xlink:type="simple"/>
        </fig>
        <p>Here we represent intrinsic variability through the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e021" xlink:type="simple"/></inline-formula>-expansion, which provides a set of ordinary differential equations for the concentration means that are identical to a traditional ODE model without variability, plus an additional set of differential equations that describe time derivatives of the individual variances and covariances (<xref ref-type="fig" rid="pcbi-1002960-g002">Figure 2B</xref>). All equations together approximate the time evolution of the intrinsic noise distribution. Note that the ODEs for the means do not depend on the variances and covariances but that the ODEs for the variances and covariances depend on means, variances, and covariances. Note also that ODEs for propagating the variance and covariance do not introduce any additional rate constant parameters beyond those needed to propagate the concentration means, but that initial values for variance and covariance need to be introduced in order to integrate their differential equations. We express this as a system of ordinary differential equations<disp-formula id="pcbi.1002960.e022"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e022" xlink:type="simple"/><label>(1)</label></disp-formula><disp-formula id="pcbi.1002960.e023"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e023" xlink:type="simple"/><label>(2)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e024" xlink:type="simple"/></inline-formula> is a vector representing the mean numbers of mRNA and protein and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e025" xlink:type="simple"/></inline-formula> is the symmetric covariance matrix<disp-formula id="pcbi.1002960.e026"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e026" xlink:type="simple"/></disp-formula></p>
        <p>We simulated intrinsic variability in single gene expression using the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e027" xlink:type="simple"/></inline-formula>-expansion model. Time-course trajectories of mean number of mRNA and protein (red) and their variances (green) are shown in <xref ref-type="fig" rid="pcbi-1002960-g002">Figure 2C</xref>. The Figure also shows individual trajectories from stochastic simulation runs (blue) using the Gillespie algorithm (<xref ref-type="sec" rid="s4">Methods</xref>) <xref ref-type="bibr" rid="pcbi.1002960-Gillespie1">[14]</xref>, which are consistent with the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e028" xlink:type="simple"/></inline-formula>-expansion simulations. A more detailed comparison shows that the distributions from the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e029" xlink:type="simple"/></inline-formula>-expansion and the stochastic Gillespie simulations are nearly identical (<xref ref-type="supplementary-material" rid="pcbi.1002960.s002">Figure S2</xref>). The multivariate Gaussian distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e030" xlink:type="simple"/></inline-formula> is depicted by an ellipse with mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e031" xlink:type="simple"/></inline-formula> whose axes' directions are determined by eigenvectors and their sizes by eigenvalues of the covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e032" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002960-g002">Figure 2D</xref>, see <xref ref-type="sec" rid="s4">Methods</xref> for further details). This represents variability in mRNA and protein counts due to intrinsic noise only.</p>
        <p>We next introduced extrinsic variability into the model, by introducing parameters that follow a distribution with a probability density function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e033" xlink:type="simple"/></inline-formula>, rather than parameters fixed to a particular value. Operationally, the combined distribution is a superposition of intrinsic distributions for different parameter realizations sampled from the underlying parameter probability distribution, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e034" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002960-g002">Figure 2E</xref>). The resulting output distribution represents the <italic>total variability</italic> (i.e., variability resulting from intrinsic as well as extrinsic sources). Mathematically we represent this distribution with a mixture model with probability density function<disp-formula id="pcbi.1002960.e035"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e035" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e036" xlink:type="simple"/></inline-formula> is a probability density of the intrinsic noise distribution, in our specific case a normal distribution with mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e037" xlink:type="simple"/></inline-formula> and a covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e038" xlink:type="simple"/></inline-formula> resulting from the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e039" xlink:type="simple"/></inline-formula>-expansion model with parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e040" xlink:type="simple"/></inline-formula>. For single gene expression, the mixture model reads<disp-formula id="pcbi.1002960.e041"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e041" xlink:type="simple"/></disp-formula>and its steady state is schematically depicted in <xref ref-type="fig" rid="pcbi-1002960-g002">Figure 2E</xref>.</p>
        <p>This framework allows us to calculate the mean and variance of the total variability distribution; the mean of a random variable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e042" xlink:type="simple"/></inline-formula> drawn from the mixture model (3) was calculated as<disp-formula id="pcbi.1002960.e043"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e043" xlink:type="simple"/><label>(4)</label></disp-formula>and by using the law of total variance <xref ref-type="bibr" rid="pcbi.1002960-Weiss1">[39]</xref> we obtained the covariance matrix <xref ref-type="bibr" rid="pcbi.1002960-Swain1">[30]</xref><disp-formula id="pcbi.1002960.e044"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e044" xlink:type="simple"/><label>(5)</label></disp-formula></p>
        <p>This equation shows that the total variability is decomposable into two parts: variability due to intrinsic stochasticity, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e045" xlink:type="simple"/></inline-formula>, and variability due to extrinsic sources, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e046" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1002960-g002">Figure 2F</xref>).</p>
        <p>So far we have not restricted ourselves to any specific form of the parameter distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e047" xlink:type="simple"/></inline-formula>; in order to obtain a combined model and calculate the total variability, we generally need to exhaustively draw samples from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e048" xlink:type="simple"/></inline-formula> and simulate the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e049" xlink:type="simple"/></inline-formula>-expansion model for each sampled parameter. However, for normally distributed parameters, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e050" xlink:type="simple"/></inline-formula>, we can take a considerably more efficient approach, the Unscented Transform (UT, see <xref ref-type="sec" rid="s4">Methods</xref>). The UT selects a small collection of representative control points in the parameter space (called sigma points), propagates them through the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e051" xlink:type="simple"/></inline-formula>-expansion simulation model to obtain the output instance for each, and then reconstructs the first two moments of the output distribution (which is equivalent to the above mixture model distribution) by appropriate weighting of the sigma points. From the output distribution, the total mean and the total variance are easily computed. See <xref ref-type="supplementary-material" rid="pcbi.1002960.s012">Text S1</xref> for further details and an example for the single gene expression model.</p>
        <p>We checked that our novel combined simulation framework accurately approximates the exact total protein and mRNA distributions resulting from Gillespie simulation. We first introduced extrinsic variability into one parameter only, and then into four parameters. In the first case, approximate distributions resulting from the novel framework fit very well to exact distributions in both steady and transient states (<xref ref-type="supplementary-material" rid="pcbi.1002960.s003">Figure S3</xref>). In the second example with extrinsic variability in four parameters, the approximation was slightly worse; this is becasue the total variability distribution was not Gaussian, but skewed, and perhaps also to inexactness in the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e052" xlink:type="simple"/></inline-formula>-expansion (<xref ref-type="supplementary-material" rid="pcbi.1002960.s004">Figure S4</xref>). However, our approximation approximated well the distribution up to the second moment, i.e. the mean and the variance.</p>
        <p><xref ref-type="fig" rid="pcbi-1002960-g003">Figure 3</xref> shows examples of interplay between intrinsic and extrinsic variability for distinct amounts of extrinsic variability. In this example we considered parameters to be independent (i.e., the covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e053" xlink:type="simple"/></inline-formula> had zero for all off-diagonal entries), and all parameters were varied with the same coefficient of variation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e054" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Methods</xref>). When the variability in parameters was low, intrinsic variability was dominant in the system (<xref ref-type="fig" rid="pcbi-1002960-g003">Figure 3A</xref>); this can be seen from the sizes of the green ellipses (the “average” of the green ellipses corresponds to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e055" xlink:type="simple"/></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1002960.e044">Eq. 5</xref>), which are much larger than the size of the red ellipse (corresponding to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e056" xlink:type="simple"/></inline-formula>). On the other hand, for high parameter variability the extrinsic variability became dominant (<xref ref-type="fig" rid="pcbi-1002960-g003">Figure 3F</xref>; red ellipse is larger than the green ones). For intermediate parameter variability, both intrinsic and extrinsic sources contributed comparably to the overall variability. Notice also that with increasing extrinsic variability, the intrinsic components changed their size and shape; this corresponds to the observation that intrinsic variability can change with kinetic parameters <xref ref-type="bibr" rid="pcbi.1002960-Ozbudak1">[40]</xref>. The total variability is the combination of red and averaged green ellipses; with increasing extrinsic variability, the variability of the output increased. High extrinsic variability has also shifted the mean; for example protein mean has increased when extrinsic variability was increased (this can be seen by comparing the x-component of the red ellipse mean on <xref ref-type="fig" rid="pcbi-1002960-g003">Figures 3A and 3F</xref>, where the mean of the red ellipse represents the mean of the output – combined intrinsic and extrinsic noise – distribution).</p>
        <fig id="pcbi-1002960-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>Distributions of the total variability.</title>
            <p>Distributions of the total variability result from the combined effects of intrinsic stochasticity and extrinsic variability due to parameter fluctuations in time and across cells. The amount of parameter variability is determined by <xref ref-type="disp-formula" rid="pcbi.1002960.e252">Eqn. (13)</xref> in a diagonal covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e057" xlink:type="simple"/></inline-formula>. Variability in parameters is gradually increased: (A) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e058" xlink:type="simple"/></inline-formula>, (B) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e059" xlink:type="simple"/></inline-formula>, (C) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e060" xlink:type="simple"/></inline-formula>, (D) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e061" xlink:type="simple"/></inline-formula>, (E) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e062" xlink:type="simple"/></inline-formula>, and (F) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e063" xlink:type="simple"/></inline-formula>.</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g003" position="float" xlink:type="simple"/>
        </fig>
        <p>In the remainder of this paper we report results obtained by using this framework to study how different topologies of self-repressing genetic networks affect the total variability in proteins.</p>
      </sec>
      <sec id="s2b">
        <title>The role of transcriptional and post-transcriptional autoregulation in reducing variability</title>
        <p>Negative feedback and self-repression are recurrent motifs observed in gene regulatory networks. Their potential role in suppressing variability has identified them as promising design elements in synthetic biology <xref ref-type="bibr" rid="pcbi.1002960-Shahrezaei1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Becskei1">[41]</xref>–<xref ref-type="bibr" rid="pcbi.1002960-Voliotis1">[48]</xref>. Here we studied the effects of self-repression on variability of the output protein in a single gene model, while taking into account both intrinsic and extrinsic sources of variability. We compared a case of negative autoregulation on a transcriptional level with a case of post-transcriptional regulation. In the transcriptional autoregulation case, the output protein acts as a repressor that multimerizes and binds to its own promoter region to repress its own transcription (<xref ref-type="fig" rid="pcbi-1002960-g004">Figure 4A</xref>). In the post-transcriptional case, we model synthetic microRNA (miRNA) that binds to its cognate mRNA, simultaneously preventing translation and promoting degradation (<xref ref-type="fig" rid="pcbi-1002960-g005">Figure 5</xref>). In the remainder of this section we explore the effectiveness of these control mechanisms. The results provide specific guidelines for designing transcriptional and post-transcriptional autoregulatory networks for achieving best (or worst) suppression of protein variability.</p>
        <fig id="pcbi-1002960-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Results for the single gene expression model.</title>
            <p>(A) Single gene expression model with transcriptional self-repression. (B) Examples of protein distribution dynamics under no feedback (top-most) and under negative feedback. Increased feedback strength (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e064" xlink:type="simple"/></inline-formula> top to bottom) resulted in lower means and variances. Reported are the measures of variability calculated for the steady-state distribution with Hill coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e065" xlink:type="simple"/></inline-formula>. (C) Effect of self-repression on variability when intrinsic stochasticity is the only source of variability, for Hill coefficient values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e066" xlink:type="simple"/></inline-formula>. (D) Effect of self-repression on the system with both intrinsic and extrinsic variability. Extrinsic variability is introduced into the transcription rate. Extrinsic variability in parameters (<xref ref-type="disp-formula" rid="pcbi.1002960.e252">eqn. (13)</xref>): <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e067" xlink:type="simple"/></inline-formula> (red), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e068" xlink:type="simple"/></inline-formula> (blue), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e069" xlink:type="simple"/></inline-formula> (green), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e070" xlink:type="simple"/></inline-formula> (black), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e071" xlink:type="simple"/></inline-formula> (magenta) with Hill coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e072" xlink:type="simple"/></inline-formula> (full line; o), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e073" xlink:type="simple"/></inline-formula> (dashed line; +).</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g004" position="float" xlink:type="simple"/>
        </fig>
        <fig id="pcbi-1002960-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>Single gene expression model with post-transcriptional self-repression.</title>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g005" position="float" xlink:type="simple"/>
        </fig>
        <sec id="s2b1">
          <title>Transcriptional autoregulation: High protein cooperativity achieves best suppression of variability</title>
          <p>Simulations were made to study transcriptional autoregulation using the single gene regulatory network model in <xref ref-type="fig" rid="pcbi-1002960-g004">Figure 4A</xref>, in which the protein product represses its own transcription through a mechanism modeled by the Hill equation (which could represent protein oligomerization and DNA binding to block transcription); this is a common modeling framework in which binding is treated under a quasi-steady state assumption, and is valid when binding kinetics are substantially faster than the other reactions. We varied the Hill coefficient (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e074" xlink:type="simple"/></inline-formula>) and the dissociation constant (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e075" xlink:type="simple"/></inline-formula>) and observed the effect on the variability of the protein product. The quantity <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e076" xlink:type="simple"/></inline-formula> it is often associated with the feedback strength <xref ref-type="bibr" rid="pcbi.1002960-Singh1">[35]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Hooshangi1">[44]</xref>. Studies were made first with only intrinsic sources of variability and then with both intrinsic and extrinsic sources.</p>
          <p>The intrinsic only case was studied with varying amounts of feedback strength and values of the Hill coefficient. We quantified variability as the relative squared coefficient of variation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e077" xlink:type="simple"/></inline-formula>, which is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e078" xlink:type="simple"/></inline-formula> normalized by the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e079" xlink:type="simple"/></inline-formula> of the network without autoregulation (see <xref ref-type="sec" rid="s4">Methods</xref>). According to this measure, whenever variability is less than 1 (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e080" xlink:type="simple"/></inline-formula>), the negative feedback suppresses variability. <xref ref-type="fig" rid="pcbi-1002960-g004">Figure 4B</xref> shows the dynamics of protein numbers under the influence of intrinsic variability, which is represented by the means and standard deviations of the intrinsic noise distribution. For increasing feedback strength the means as well as the variances decreased. The measure of variability, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e081" xlink:type="simple"/></inline-formula>, however, showed a minimum for intermediate feedback strength due to competition between different rates of decrease of the mean and the variance with increasing feedback strength. Reported are the variabilities calculated at the steady state; the data is plotted more concisely in <xref ref-type="fig" rid="pcbi-1002960-g004">Figure 4C</xref> (case <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e082" xlink:type="simple"/></inline-formula>).</p>
          <p>We studied the effect of negative autoregulation on intrinsic protein variability under different Hill coefficients, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e083" xlink:type="simple"/></inline-formula>, and different feedback strengths (<xref ref-type="fig" rid="pcbi-1002960-g004">Figure 4C</xref>). Several observations were made. Firstly, an optimal suppression of variability occurs for intermediate values of feedback strength. Secondly, there is a window of feedback strength for which autoregulation is successful in suppressing variability. And thirdly, the negative feedback only suppresses variability for Hill coefficients greater than one, while in the absence of protein cooperativity, the variability increases relative to that in a circuit without the feedback loop. These observations are consistent with those of Singh <italic>et al.</italic>, who did related analysis on a simplified model <xref ref-type="bibr" rid="pcbi.1002960-Singh1">[35]</xref>.</p>
          <p>Next, we added extrinsic variability to the system by treating each parameter as a distribution across a population rather than as a constant value for all individuals. We studied the total protein variability resulting from a combination of intrinsic and extrinsic sources as a function of extrinsic variability. Initially, extrinsic variability was introduced in only the transcription rate (<xref ref-type="fig" rid="pcbi-1002960-g004">Figure 4D</xref>). Higher extrinsic variability led to greater suppression of expressed protein variability. This result is in agreement with Singh <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002960-Singh1">[35]</xref>. As above in the intrinsic-only setting, the results suggest that high cooperativity in the protein is preferred to low cooperativity in order to achieve best suppression of variability when both intrinsic and extrinsic sources are acting on the system. Then we introduced variability in all other parameters individually (<xref ref-type="supplementary-material" rid="pcbi.1002960.s005">Figure S5</xref>). When the main source of extrinsic variability was in the gene copy number, translation rate, or in any of the degradation rates, we observed a similar result, namely that under higher extrinsic variability, self-repression suppressed protein variability better than a circuit without self-repression. The opposite was found for extrinsic variability in feedback strength or Hill coefficient: the higher the extrinsic variability, the less successful the loop was in suppressing the protein variability. In other words, this means that a noisy feedback mechanism is less successful in repressing protein variability than the feedback mechanism that is not noisy; this can be seen from a simple mathematical argument: a mixture distribution of individual components has higher variability than one of its individual components; the mixture corresponds to the total protein variability when extrinsic noise is present in the feedback strength or Hill coefficient, while its individual component corresponds to the intrinsic protein variability when no extrinsic noise is present in either of these parameters. Interestingly, the Hill coefficient is a parameter that is generally thought of as relatively unvarying for a given wild type protein.</p>
          <p>In summary, transcriptional autoregulation is often thought of as a tool in synthetic biology to decrease, across a population of cells, the variability of the protein product of interest. Here we studied how to construct such an autoregulatory loop in order to achieve best suppression of variability. The results show that best suppression can be achieved when proteins are highly cooperative, and when extrinsic variability (either in transcription, translation, or degradation rates) across a population is large. Furthermore, there exists an optimal feedback strength that achieves best suppression.</p>
        </sec>
        <sec id="s2b2">
          <title>Transcriptional regulation suppresses variability better than post-transcriptional regulation when extrinsic variability in translation and protein degradation rates is high</title>
          <p>An important general problem in synthetic biology is to decide among candidate network topologies, and to select those with the best properties for implementation and potential tuning. Here we examine this question in the context of deciding between two topologies for suppression of variability of expressed protein. One topology incorporates transcriptional and the other post-transcriptional autoregulation. Crucially, we wanted our conclusions and design choices to be robust, in spite of our limited knowledge of extrinsic variability sources and network parameters.</p>
          <p>Transcriptional autoregulation was modeled as above (<xref ref-type="fig" rid="pcbi-1002960-g004">Figure 4A</xref>), and post-transcriptional regulation by a model shown in <xref ref-type="fig" rid="pcbi-1002960-g005">Figure 5</xref>, in which a copy of mRNA and a synthetic miRNA are transcribed from a synthetically engineered DNA molecule <xref ref-type="bibr" rid="pcbi.1002960-Bleris1">[47]</xref>. After mRNA and miRNA have been spliced and processed, miRNA can bind to a complementary binding sequence on the mRNA molecule. Once bound, it can unbind or trigger miRNA-induced mRNA degradation, after which miRNA is recycled and can bind to other mRNA molecules <xref ref-type="bibr" rid="pcbi.1002960-Bartel1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Mukherji2">[50]</xref>. Binding and unbinding rates are denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e084" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e085" xlink:type="simple"/></inline-formula>, respectively, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e086" xlink:type="simple"/></inline-formula> is the rate of miRNA-induced mRNA degradation, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e087" xlink:type="simple"/></inline-formula> is the degradation rate of miRNA.</p>
          <p>To compare the effects of transcriptional and post-transcriptional self-repression on suppression of expressed protein variability, we introduced different amounts of extrinsic variability to different parameters and initial conditions of both models. Results showing suppression of total variability for different feedback strengths are shown in <xref ref-type="fig" rid="pcbi-1002960-g006">Figure 6</xref>. Each row shows how total variability in both models changes for different feedback strengths when extrinsic variability enters through each parameter individually. Increasing amounts of parameter variability in the transcriptional control model reduced protein variability for a window of feedback strength for all four parameters. By contrast, increasing amounts of parameter variability in the post-transcriptional control model reduced protein variability only for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e088" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e089" xlink:type="simple"/></inline-formula> and increased it for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e090" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e091" xlink:type="simple"/></inline-formula>. This latter observation is in line with our intuition; any variability in protein numbers that is due to extrinsic variability in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e092" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e093" xlink:type="simple"/></inline-formula> can not be suppressed by the post-transcriptional self-repression loop as translation and protein degradation in this case lie outside the self-repression loop. Moreover, effects for transcriptional control occurred at significantly smaller feedback strength than for post-transcriptional control, although note that these were computed differently for the two models. These results are summarized in <xref ref-type="supplementary-material" rid="pcbi.1002960.s005">Figure S5</xref>.</p>
          <fig id="pcbi-1002960-g006" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g006</object-id>
            <label>Figure 6</label>
            <caption>
              <title>Comparison of total protein variability in transcriptional (solid line) and post-transcriptional (dashed line) self-repression circuits.</title>
              <p>Extrinsic variability in parameters (<xref ref-type="disp-formula" rid="pcbi.1002960.e226">eqn. (13)</xref>): <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e094" xlink:type="simple"/></inline-formula> (red), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e095" xlink:type="simple"/></inline-formula> (blue), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e096" xlink:type="simple"/></inline-formula> (green), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e097" xlink:type="simple"/></inline-formula> (black), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e098" xlink:type="simple"/></inline-formula> (magenta). Feedback strength in transcriptional self-repression model is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e099" xlink:type="simple"/></inline-formula>, in post-transcriptional <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e100" xlink:type="simple"/></inline-formula>.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g006" position="float" xlink:type="simple"/>
          </fig>
          <p>How can this knowledge help us choose between two designs of self-repression to suppress variability in the output of a synthetic circuit? Knowing that variability in translational parameters might be high <xref ref-type="bibr" rid="pcbi.1002960-Taniguchi1">[51]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Rinott1">[52]</xref>, our results suggest that the transcriptional self-regulation motif would be a “safer” choice to implement than post-transcriptional, if one aims to reduce the variability in the protein. However, if the sources and quantitative contributions of extrinsic variability were known and could be controled, one could make a more informed choice.</p>
        </sec>
        <sec id="s2b3">
          <title>Post-transcriptional self-repression: Imperfect complementarity between miRNA and mRNA preferred to perfect complementarity</title>
          <p>The mechanism of post-transcriptional regulation depends on the degree of complementarity between miRNA and mRNA <xref ref-type="bibr" rid="pcbi.1002960-Bartel1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Brown1">[53]</xref>; depending on complementarity, their interaction can either result in gene silencing through prevention of translation, or through induced mRNA degradation. If the complementarity is imperfect, binding and silencing will occur, but not mRNA degradation; perfect complementarity will lead to miRNA induced mRNA degradation. We model the effects of degree of complementarity in our post-transcriptional model (<xref ref-type="fig" rid="pcbi-1002960-g005">Figure 5</xref>) through the parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e101" xlink:type="simple"/></inline-formula>. In this section we studied what values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e102" xlink:type="simple"/></inline-formula> lead — and therefore what degree of complementarity leads — to best suppression of variability.</p>
          <p>The results are shown in <xref ref-type="fig" rid="pcbi-1002960-g007">Figure 7</xref>. The measure of intrinsic protein variability is plotted against different values of feedback strength. The results show that for low rates of miRNA-induced mRNA degradation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e103" xlink:type="simple"/></inline-formula>, there is wider and stronger window of reduced intrinsic stochasticity than for high rates of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e104" xlink:type="simple"/></inline-formula>. The same was observed also when high extrinsic variability was present in the system, although the differences were less pronounced (<xref ref-type="supplementary-material" rid="pcbi.1002960.s006">Figure S6</xref>). These results suggest that best noise suppression is achieved if miRNAs repress translation but do not promote mRNA degradation, and thus that imperfect complementarity between mRNA and miRNA is preferred to perfect complementarity.</p>
          <fig id="pcbi-1002960-g007" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g007</object-id>
            <label>Figure 7</label>
            <caption>
              <title>Variability in post-transcriptional circuit for different values of</title>
              <p><inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e105" xlink:type="simple"/></inline-formula><bold>.</bold> Parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e106" xlink:type="simple"/></inline-formula> depends on the level of complementarity between mRNA and miRNA. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e107" xlink:type="simple"/></inline-formula> (red), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e108" xlink:type="simple"/></inline-formula> (blue), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e109" xlink:type="simple"/></inline-formula> (green). Feedback strength <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e110" xlink:type="simple"/></inline-formula>. Intrinsic variability only was used.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g007" position="float" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s2b4">
          <title>miRNA and mRNA transcribed on a single transcript are best for suppression of protein variability</title>
          <p>In the post-transcriptional model so far, mRNA and miRNA were transcribed on the same transcript. We next compared the ability of post-transcriptional repression to suppress variability when mRNA and miRNA were transcribed together, to when they were transcribed on two separate transcripts (<xref ref-type="fig" rid="pcbi-1002960-g008">Figure 8</xref>). We chose the values of transcription rates of mRNA and miRNA to be equal in both models. The crucial difference between both circuits is that mRNA and miRNA molecules are produced in a correlated manner when encoded on the same transcript, and in an uncorrelated manner when encoded on different transcripts. <xref ref-type="fig" rid="pcbi-1002960-g009">Figure 9</xref> shows that for extrinsic variability in parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e111" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e112" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e113" xlink:type="simple"/></inline-formula>, lower variability was obtained for the “same-transcript design” compared to the “different-transcripts design”, with results for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e114" xlink:type="simple"/></inline-formula> especially dramatic. However, both designs were equally successful in reducing protein variability under extrinsic variability in parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e115" xlink:type="simple"/></inline-formula>. This suggests that the latter circuit was less successful in reducing variability than the former for most extrinsic sources; this observation is in agreement with Osella <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002960-Osella1">[46]</xref>. Furthermore, for the same-transcript design, variability in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e116" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e117" xlink:type="simple"/></inline-formula> are especially effective in suppressing protein variability.</p>
          <fig id="pcbi-1002960-g008" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g008</object-id>
            <label>Figure 8</label>
            <caption>
              <title>Post-transcriptional repression model with miRNA transcribed on a different transcript than mRNA.</title>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g008" position="float" xlink:type="simple"/>
          </fig>
          <fig id="pcbi-1002960-g009" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g009</object-id>
            <label>Figure 9</label>
            <caption>
              <title>Comparison of total protein variability in circuits with mRNA and miRNA on the same (o) or different (+) transcripts.</title>
              <p>Extrinsic variability in parameters (<xref ref-type="disp-formula" rid="pcbi.1002960.e226">eqn. (13)</xref>): <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e118" xlink:type="simple"/></inline-formula> (red), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e119" xlink:type="simple"/></inline-formula> (blue), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e120" xlink:type="simple"/></inline-formula> (green), <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e121" xlink:type="simple"/></inline-formula> (black), and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e122" xlink:type="simple"/></inline-formula> (magenta). Feedback strength is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e123" xlink:type="simple"/></inline-formula>.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g009" position="float" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s2b5">
          <title>Low cooperativity in miRNA achieves most robust suppression of variability</title>
          <p>It is currently unknown whether cooperativity between miRNA molecules exists, what its mechanism would be, or how one could go about designing it. Nevertheless, it has been suggested that cooperative models might be more appropriate for modeling regulation by miRNA than non-cooperative models <xref ref-type="bibr" rid="pcbi.1002960-Cuccato1">[54]</xref>. These models use a Hill function, which circumvents the need for modeling the precise molecular mechanism. Here we used one such model (<xref ref-type="fig" rid="pcbi-1002960-g010">Figure 10A</xref>) to study the effect of miRNA cooperativity on suppression of variability. High cooperativity was observed to reduce variability slightly more in magnitude; however, and more significantly, low cooperativity was successful in reducing variability for a much broader range of feedback strengths (<xref ref-type="fig" rid="pcbi-1002960-g010">Figure 10B</xref>). In other words, the suppression of noise in the absence of miRNA cooperativity was more robust to varying feedback strength. Therefore, depending on how difficult it is to design (or know) a precise feedback strength, low cooperativity might be preferred to high cooperativity.</p>
          <fig id="pcbi-1002960-g010" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g010</object-id>
            <label>Figure 10</label>
            <caption>
              <title>Results for post-transcriptional self-repression modeled by a Hill function.</title>
              <p>(A) Single gene expression model with post-transcriptional self-repression modeled by a Hill function. (B) Effect of self-repression on variability with only intrinsic sources of variability, for Hill coefficient values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e124" xlink:type="simple"/></inline-formula>.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g010" position="float" xlink:type="simple"/>
          </fig>
        </sec>
        <sec id="s2b6">
          <title>Correlated extrinsic variability</title>
          <p>Little knowledge exists for biological systems about the sources and amounts of extrinsic variability, which makes it uncertain how one should specify the covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e125" xlink:type="simple"/></inline-formula>. To this point of the current report, we have considered the covariance matrix to be diagonal, corresponding to independent parameter variation. However, some biological parameter variability might be correlated; for example, if differences in cell size drive protein variability through changes in concentration of the transcriptional, translational, and degradation machinery, then transcriptional, translational, and degradation rate-constant variability could be correlated. The framework introduced here allows arbitrary parameter correlations originating from extrinsic variability. While this may seem like “extra” parameters required by this framework, it is perhaps more accurate to say that they are required to properly describe the underlying biophysics, and the method we present exposes them explicitly.</p>
          <p>To explore how correlations in parameter variability affect overall gene expression variability, we next carried out model studies with different covariance matrices and analysed the results. We are interested in the question of how correlations in extrinsic variability affect the ability of autoregulatory circuits to suppress total variability in protein concentration. Are rate correlations important to understand and measure in order to understand total biological variability, or are they minor contributors? Are there particularly favorable correlation properties of kinetic rates across a population of cells that suppress (or enhance) variability? How robust is noise suppression in transcriptional relative to post-transcriptional self-repression circuits to different parameter distributions across cells?</p>
          <p>To answer these questions, we first generated covariance matrices with fixed diagonal elements but random off-diagonal elements. This corresponds to the same total variation for each parameter but different covariation among the parameters for each trial. We simulated the total variability in protein numbers in both transcriptional and post-transcriptional self-repression circuits using <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e126" xlink:type="simple"/></inline-formula> random matrices each. The variability of a system with independent extrinsic parameter variability (all zeros off the diagonal) is taken as a reference and is plotted as the solid line in <xref ref-type="fig" rid="pcbi-1002960-g011">Figure 11A</xref>. When we included correlated extrinsic variability, the suppression was better or worse (indicated by dashed lines appearing on both sides of the solid line). To address the question of what type of extrinsic variability allows for better or worse suppression, we compared the total variability resulting from correlated parameters to that from uncorrelated parameters for each pair of parameters (<xref ref-type="supplementary-material" rid="pcbi.1002960.s007">Figure S7</xref>). This allowed us to hypothesize that the following correlation matrix would result in strong suppression of variability in a transcriptional autoregulatory network (note the order of indices is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e127" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e128" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e129" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e130" xlink:type="simple"/></inline-formula> for rows and columns),<disp-formula id="pcbi.1002960.e131"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e131" xlink:type="simple"/><label>(6)</label></disp-formula>where a <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e132" xlink:type="simple"/></inline-formula> sign means the parameter pair is correlated and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e133" xlink:type="simple"/></inline-formula> sign that it is anti-correlated; likewise, the opposite correlation matrix was hypothesized to result in weak suppression (and even enhancement) of variability. This hypothesis was validated for randomly generated variances (i.e., diagonals of the covariance matrix). For every randomly generated variance vector, covariance matrices with correlation properties defined by (6) with symmetric off-diagonal elements choisen randomly between zero and one resulted in better suppression (red) than independent extrinsic variability (black), and correlation properties opposite to (6) resulted in worse suppression (blue; <xref ref-type="fig" rid="pcbi-1002960-g011">Figure 11B</xref>). This result suggests that transcriptional autoregulatory networks are best in suppressing variability in systems where (i) transcription and translation rates are correlated, (ii) mRNA degradation and protein degradation rates are correlated, and (iii) all other pairs of kinetic rates are anti-correlated.</p>
          <fig id="pcbi-1002960-g011" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g011</object-id>
            <label>Figure 11</label>
            <caption>
              <title>Total variability resulting from non-diagonal covariance matrices.</title>
              <p>(A) Simulations of total variability resulting from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e134" xlink:type="simple"/></inline-formula> representative random correlation matrices selected from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e135" xlink:type="simple"/></inline-formula> runs for visual clarity (dashed line) and a diagonal correlation matrix (solid line). (B) From a total of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e136" xlink:type="simple"/></inline-formula> random correlation matrices, those resulting from correlation matrix (<xref ref-type="disp-formula" rid="pcbi.1002960.e131">eqn. 6</xref>) are shown in red, and those correlated oppositely in blue. Simulation resulting from a diagonal correlation matrix is represented by a solid black line.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g011" position="float" xlink:type="simple"/>
          </fig>
          <p>Using the same approach we found that the post-transcriptional autoregulation circuit strongly suppressed variability if their extrinsic noise environment was determined by the following correlation matrix pattern<disp-formula id="pcbi.1002960.e137"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e137" xlink:type="simple"/><label>(7)</label></disp-formula>and weakly suppressed (and even enhanced) variability for the opposite correlation matrix pattern (<xref ref-type="supplementary-material" rid="pcbi.1002960.s008">Figure S8</xref>). Therefore, extrinsic variability with (i) positively correlated transcription and translation rates, (ii) positively correlated translation and mRNA degradation, (iii) positively correlated translation and protein degradation rates, and (iv) all other pairs anti-correlated, would allow for best suppression of variability in the post-transcriptional autoregulation circuit. This tells us that different circuits suppress variability better or worse depending on the intra-cellular environments that determine correlations between kinetic parameters.</p>
          <p>We next investigated the question whether particular patterns of parameter variability could control the effect of parameter covariation on overall protein variability. We were curious whether some diagonals could enhance or suppress the effect of off-diagonals in creating protein number variability. To address this question we sorted diagonals according to the similarity of the outputs they produced for different covariance matrices, and looked at which diagonal combinations resulted in small, medium, and large differences in total protein variability as the correlation pattern was varied (<xref ref-type="fig" rid="pcbi-1002960-g012">Figures 12A, B, C</xref>, respectively). For the transcriptional self-repression circuit, we observed that when extrinsic variability was dominated by variability in transcription or translation, with variability in all other parameters small, then different covariance matrices gave very similar total variability results (<xref ref-type="fig" rid="pcbi-1002960-g012">Figure 12A</xref> is one example; other examples are given in <xref ref-type="supplementary-material" rid="pcbi.1002960.s012">Text S1</xref>). In contrast, when extrinsic variability was a combination of small and intermediate sizes for different parameters, with none of them clearly dominating, then different covariance matrices gave very different total variability results. These results imply that, depending on the amount of extrinsic variability, it is either important to understand correlations between parameters (as they effect the ability to suppress variability, <xref ref-type="fig" rid="pcbi-1002960-g012">Figure 12C</xref>) or not important (as variability will be suppressed to the same extent regardless of the correlations between parameters, <xref ref-type="fig" rid="pcbi-1002960-g012">Figure 12A</xref>). For design purposes, where it may be difficult to even know and certainly to control covariation fully, it may be useful to explicitly choose combinations of variation that minimize the effect of covariation.</p>
          <fig id="pcbi-1002960-g012" position="float">
            <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g012</object-id>
            <label>Figure 12</label>
            <caption>
              <title>Small, medium and large differences in total protein variability resulting from different covariance matrices.</title>
              <p>Simulations of total variability resulting from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e138" xlink:type="simple"/></inline-formula> different random correlation matrices selected from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e139" xlink:type="simple"/></inline-formula> runs for visual clarity (dashed line) and a diagonal correlation matrix (solid line). The total variability shows different degrees of sensitivity to correlation matrices, depending on parameter variances: (A) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e140" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e141" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e142" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e143" xlink:type="simple"/></inline-formula> (B) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e144" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e145" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e146" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e147" xlink:type="simple"/></inline-formula> (C) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e148" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e149" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e150" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e151" xlink:type="simple"/></inline-formula>.</p>
            </caption>
            <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g012" position="float" xlink:type="simple"/>
          </fig>
          <p>The ability to specify arbitrary parameter correlations in extrinsic variability is a valuable property of this modeling framework. This property, combined with an efficient simulation framework, allows exploration of how total variability of the model output depends on different sources and properties of extrinsic variability. Questions that remain to be answered include what is the biological explanation for this phenomena, and how important a role it plays in the detailed workings of biological systems.</p>
        </sec>
        <sec id="s2b7">
          <title>Transient variability behaves differently than steady-state variability</title>
          <p>Up to this point in the current report, we have studied distributions of variability in the steady state; however, the framework allows the same analysis for any time point in the simulation. Our observations are consistent with those of Tao <italic>et al.</italic> <xref ref-type="bibr" rid="pcbi.1002960-Tao1">[55]</xref>, who showed theoretically that intrinsic stochasticity in transient states might behave differently than intrinsic stochasticity in the steady state. In addition, our calculations show that this result also holds for the combination of intrinsic and extrinsic variability. For example, while we saw earlier that transcriptional self-repression with Hill coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e152" xlink:type="simple"/></inline-formula> could not suppress variability in the steady state, the variability could be suppressed in transient states (<xref ref-type="supplementary-material" rid="pcbi.1002960.s009">Figure S9</xref>). Similarly, for higher Hill coefficients, especially under strong feedback, variability might be suppressed in the transient but not in the steady state (<xref ref-type="supplementary-material" rid="pcbi.1002960.s010">Figure S10</xref>). This phenomenon has recently been observed experimentally in the NF-<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e153" xlink:type="simple"/></inline-formula>B signaling pathway <xref ref-type="bibr" rid="pcbi.1002960-Cheong1">[56]</xref>. Interestingly, for both transcriptional and post-transcriptional self-repression, the qualitative effect of different levels of extrinsic variability on the system (results shown for transcriptional case in <xref ref-type="supplementary-material" rid="pcbi.1002960.s011">Figure S11</xref>) was the same in the steady and transient states (steady state in <xref ref-type="supplementary-material" rid="pcbi.1002960.s005">Figure S5</xref>). Taken together, these observations strongly caution that conclusions about steady-state variability properties cannot straightforwardly be extrapolated to transient states.</p>
        </sec>
      </sec>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>Variability is ubiquitous to biological systems, and yet it is not well understood. In order to engineer and intervene in such systems successfully, variability must be taken into account in planning and interpreting experiments and in designing synthetic networks. Here we have introduced a framework for modeling and simulation of dynamical systems under both intrinsic and extrinsic sources of variability. One reason that understanding and treating variability is so especially important for synthetic biology is that one seeks to design circuits and devices that can perform successfully across a population of cells and variety of experimental conditions; without understanding variability and fluctuations, one risks building devices or designing therapies that only perform well in a fraction of cells (or patients) or only under limited environmental conditions.</p>
      <p>Here we addressed the problem of constructing circuits that exhibit low variability across cells. We investigated transcriptional and post-transcriptional designs of self repression, and studied their relative promise for noise suppression. We explored their behavior for a range of feedback strengths and other design parameters, and for various hypothetical amounts and types of extrinsic variability. We derived a set of design principles for best noise suppression in a protein concentration of interest. We showed that transcriptional autoregulation is more successful than post-transcriptional in suppressing noise under a wide range of intrinsic and extrinsic variability levels and conditions. The following design principles were shown to best suppress protein concentration variability: (i) high cooperativity in protein binding to DNA and low cooperativity in miRNA binding to mRNA, (ii) imperfect complementarity between miRNA and mRNA was preferred to perfect complementarity, and (iii) correlated expression of mRNA and miRNA — for example, on the same transcript. We further showed that correlations in kinetic parameters between cells affected the ability to suppress variability, and that variability in transient states did not necessarily follow the same principles as variability in the steady state. Also, we note that biochemical design can not avoid fundamental limits on the lower bound of stochastic fluctuations <xref ref-type="bibr" rid="pcbi.1002960-Lestas1">[57]</xref>. In this work we have focused on one objective, which is to decrease variability of protein expression. In synthetic biology applications, one might be interested in additional objectives, such as maximizing the mean protein expression, or keeping the mean fixed while suppressing variability etc. The same analysis can be performed for such objectives, and could potentially lead to different guidelines.</p>
      <p>Our novel modeling and simulation framework combines intrinsic and extrinsic sources of variability by combining the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e154" xlink:type="simple"/></inline-formula>-expansion with the unscented transform. In contrast to few previous methods, our framework is based on a deterministic simulation with ordinary differential equations. One advantage of our method is that it incorporates extrinsic variability by repeated simulation of the same intrinsic model for carefully selected parameter combinations where the number of simulations increases linearly with the number of extrinsic factors (see <xref ref-type="sec" rid="s4">Methods</xref>), rather than generating a new model and exponentially increasing the model size for each new extrinsic factor <xref ref-type="bibr" rid="pcbi.1002960-Zechner1">[33]</xref>. This not only increases computational efficiency, but makes possible analysis with a wide variety of available tools. It also allows for screening across a large range of parameters (such as feedback strength, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e155" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e156" xlink:type="simple"/></inline-formula> rates, and unknown sources and quantities of extrinsic variability). The new approach is well suited to support the design of synthetic circuits from building blocks with partially unknown kinetic properties but that will perform desired functions robustly in variable intracellular and extracellular environments and across a population of cells. An important aspect of the framework is that it can be applied to study variability and dynamics at transient as well as steady states; we have shown that variability might behave differently in both regimes, which reiterates the importance of developing and using tools that are applicable beyond steady-state regimes.</p>
      <p>The computational efficiency of the framework, however, comes at a cost of approximation; macroscopic dynamics remain non-linear, but intrinsic and extrinsic variability distributions are both approximated by the first two moments. We have shown that transient and steady-state distributions resulting from our approximation framework closely fit to exact distributions simulated by a Gillespie algorithm and parameter sampling. We note once more that the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e157" xlink:type="simple"/></inline-formula>-expansion is derived under the assumption of large numbers of molecules and we recommend the results to be tested by more accurate methods, especially for low molecule numbers. For example, a sufficient number of Gillespie runs provides the exact distribution <xref ref-type="bibr" rid="pcbi.1002960-Gillespie1">[14]</xref>; another powerful technique, the Langevin approximation, can be used to obtain more accurate than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e158" xlink:type="simple"/></inline-formula>-expansion <xref ref-type="bibr" rid="pcbi.1002960-Grima1">[20]</xref>, although still approximate estimates of the variance at a steady state, and its disadvantage is that it requires monitoring of the convergence. An important point, however, is that we have focused less on calculating exact quantitative values of variability, and more on what changes in the network drive variability increases or decreases. Our approximation framework is sufficient for addressing this question, and due to computational efficiency in both steady and transient states it is even advantageous compared to exact simulation. We have applied the framework to systems with a single steady state, but there is scope for extending the framework to oscillatory and multimodal systems <xref ref-type="bibr" rid="pcbi.1002960-Scott1">[25]</xref>–<xref ref-type="bibr" rid="pcbi.1002960-Ito1">[27]</xref>. Derivation of improved versions of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e159" xlink:type="simple"/></inline-formula>-expansion is an area of active research, for example accounting for slow and fast variables <xref ref-type="bibr" rid="pcbi.1002960-Thomas1">[58]</xref> or increasing accuracy for small number of molecules <xref ref-type="bibr" rid="pcbi.1002960-Thomas2">[59]</xref>. By developing better approximation frameworks for intrinsic noise modeling, our combined intrinsic-extrinsic method will increase in accuracy, too. Furthermore, while the dynamics originating from intrinsic variability was modelled by the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e160" xlink:type="simple"/></inline-formula>-expansion approximation framework in this manuscript, a similar framework could be constructed based on other approximation modeling approaches for intrinsic variability, for example the moment closure method <xref ref-type="bibr" rid="pcbi.1002960-Gillespie2">[60]</xref> or mass fluctuation kinetics <xref ref-type="bibr" rid="pcbi.1002960-GmezUribe1">[16]</xref>. The extrinsic variability modeled through parameter distributions in this manuscript was assumed to be constant in time (i.e., static), and a natural extension would be to introduce time-varying parameter distributions (i.e., dynamic) <xref ref-type="bibr" rid="pcbi.1002960-Hilfinger1">[31]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Bowsher1">[61]</xref>. Because of this, for example, our method in its current form can not be used to quantify the dependence of the total output variation on the lifetime of extrinsic fluctuations <xref ref-type="bibr" rid="pcbi.1002960-Shahrezaei1">[32]</xref>.</p>
      <p>There are different sources of biological variability and uncertainty; a careful interpretation and appropriate inclusion in a mathematical model is crucial to elucidate the dynamics of biological variability and understanding of these different levels of biological complexity. Firstly, there are intrinsic and extrinsic sources of variability (discussed at length above). Secondly, there is parameter uncertainty, which encompasses our limited knowledge of kinetic rate values. This uncertainty is commonly included in biological models and simulations as a distribution of kinetic values, however, it is important to treat it separately from extrinsic variability, which is also modeled by treating parameters as distributions. An example of appropriate mathematical treatment is a hierarchical Bayesian model <xref ref-type="bibr" rid="pcbi.1002960-Zechner1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Woodcock1">[62]</xref>. A further type of uncertainty is model uncertainty, by which we refer to our uncertainty in model topology; the present manuscript does not address this type of uncertainty. And thirdly, when modeling or analyzing experimental biological data, one also needs to account for measurement noise (or measurement error). In order to infer sources of variability and reduce uncertainty in parameters, there is a need for inference techniques for models that account for these different levels of biological variability, uncertainty, and measurement noise.</p>
      <p>The presented modeling framework is only the first step in the systems biology cycle of modeling, designing experiments, and updating the model by inference from collected data. Based on this modeling framework, we are now developing tools that account for variability also in the experimental design stage, and for updating the models from noisy data through parameter inference and model selection algorithms. These techniques will allow us to better explore and account for biological variability in synthetic biology, a ubiquitous aspect of biological systems that is in practice often neglected.</p>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <sec id="s4a">
        <title>The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e161" xlink:type="simple"/></inline-formula>-expansion</title>
        <p>The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e162" xlink:type="simple"/></inline-formula>-expansion is an approximation of the master equation. It separates the macroscopic part of dynamics from the fluctuations around it, describing each of these parts by a set of ODEs <xref ref-type="bibr" rid="pcbi.1002960-vanKampen1">[13]</xref>. The resulting <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e163" xlink:type="simple"/></inline-formula>-expansion model approximates the first two moments of the intrinsic noise distribution in the form of ODEs for each mean, variance, and covariance; for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e164" xlink:type="simple"/></inline-formula> species in the model, the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e165" xlink:type="simple"/></inline-formula>-expansion generates <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e166" xlink:type="simple"/></inline-formula> equations for the means, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e167" xlink:type="simple"/></inline-formula> equations for variances, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e168" xlink:type="simple"/></inline-formula> equations for covariances between all pairs of species.</p>
        <p>Readers interested in a theoretical derivation of the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e169" xlink:type="simple"/></inline-formula>-expansion modeling framework are referred to van Kampen <xref ref-type="bibr" rid="pcbi.1002960-vanKampen1">[13]</xref>. As a brief summary we note that the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e170" xlink:type="simple"/></inline-formula>-expansion is derived assuming that the macroscopic part of dynamics can be separated from the fluctuations centred around it, and that the fluctuations scale as the square root of the number of molecules <xref ref-type="bibr" rid="pcbi.1002960-vanKampen2">[63]</xref>. This is captured by the following ansatz: <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e171" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e172" xlink:type="simple"/></inline-formula> is the number of molecules, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e173" xlink:type="simple"/></inline-formula> is the macroscopic concentration and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e174" xlink:type="simple"/></inline-formula> the fluctuations. Parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e175" xlink:type="simple"/></inline-formula> represents the system size and can be thought of as proportional to the volume. This ansatz is introduced into the master equation governing the evolution of probability distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e176" xlink:type="simple"/></inline-formula> and then the master equation is Taylor-expanded around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e177" xlink:type="simple"/></inline-formula>. The terms of order <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e178" xlink:type="simple"/></inline-formula> collected together determine equations governing macroscopic dynamics, and the terms of order <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e179" xlink:type="simple"/></inline-formula> the equations for dynamics of fluctuations.</p>
        <p>The resulting set of ordinary differential equations describing macroscopic (or average) behavior is<disp-formula id="pcbi.1002960.e180"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e180" xlink:type="simple"/><label>(8)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e181" xlink:type="simple"/></inline-formula> is the stoichiometry matrix and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e182" xlink:type="simple"/></inline-formula> are the reaction propensities of reactions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e183" xlink:type="simple"/></inline-formula>. The ODE for the covariance matrix of the fluctuations, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e184" xlink:type="simple"/></inline-formula>, centred around <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e185" xlink:type="simple"/></inline-formula> is<disp-formula id="pcbi.1002960.e186"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e186" xlink:type="simple"/><label>(9)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e187" xlink:type="simple"/></inline-formula> is a Jacobian of a deterministic system given by <xref ref-type="disp-formula" rid="pcbi.1002960.e180">equation (8)</xref>, evaluated along the macroscopic trajectory, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e188" xlink:type="simple"/></inline-formula> and is called the <italic>drift</italic>. Matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e189" xlink:type="simple"/></inline-formula> is the <italic>diffusion matrix</italic>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e190" xlink:type="simple"/></inline-formula>. <xref ref-type="disp-formula" rid="pcbi.1002960.e180">Equations (8)</xref> and <xref ref-type="disp-formula" rid="pcbi.1002960.e186">(9)</xref> together form the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e191" xlink:type="simple"/></inline-formula>-expansion model, which approximates the first two moments (mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e192" xlink:type="simple"/></inline-formula> and covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e193" xlink:type="simple"/></inline-formula>) of the distribution that solves the master equation. The <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e194" xlink:type="simple"/></inline-formula>-expansion model is a deterministic and approximate description of intrinsic noise distribution dynamics in time.</p>
      </sec>
      <sec id="s4b">
        <title>Visualizing multivariate normal distributions as ellipses</title>
        <p>We visualised the multivariate normal distributions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e195" xlink:type="simple"/></inline-formula> as ellipses. The ellipse is one of the contours that represent equal probability mass of the distribution. In general, these ellipses are constructed from eigenvalues <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e196" xlink:type="simple"/></inline-formula> and eigenvectors <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e197" xlink:type="simple"/></inline-formula> of the covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e198" xlink:type="simple"/></inline-formula>. They are centred at mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e199" xlink:type="simple"/></inline-formula>, their axis directions are determined by the eigenvectors and axis sizes by the eigenvalues, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e200" xlink:type="simple"/></inline-formula>. Different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e201" xlink:type="simple"/></inline-formula> specify different contours. In our figures we choose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e202" xlink:type="simple"/></inline-formula> unless otherwise specified. In particular, the ellipse determined by equation<disp-formula id="pcbi.1002960.e203"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e203" xlink:type="simple"/></disp-formula>represents the multivariate analogue of the “confidence interval” containing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e204" xlink:type="simple"/></inline-formula> of the probability mass of the distribution. For example, a bivariate (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e205" xlink:type="simple"/></inline-formula>) normal distribution represented by an ellipse with axes lengths <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e206" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e207" xlink:type="simple"/></inline-formula>, contains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e208" xlink:type="simple"/></inline-formula> of distribution, and an ellipse containing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e209" xlink:type="simple"/></inline-formula> of a distribution has axes of lengths <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e210" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e211" xlink:type="simple"/></inline-formula>.</p>
      </sec>
      <sec id="s4c">
        <title>The Unscented Transform</title>
        <p>The unscented transform (UT) is an algorithm that efficiently propagates normally distributed inputs through a nonlinear function to obtain a distribution on the function outputs. <xref ref-type="fig" rid="pcbi-1002960-g013">Figure 13</xref> provides an overview of the UT.</p>
        <fig id="pcbi-1002960-g013" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pcbi.1002960.g013</object-id>
          <label>Figure 13</label>
          <caption>
            <title>Schematic representation of the unscented transform.</title>
            <p>Adapted from ref. <xref ref-type="bibr" rid="pcbi.1002960-vanDerMerwe1">[36]</xref>. The UT provides a mechanism for approximating the output distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e212" xlink:type="simple"/></inline-formula> obtained by propagating the input parameter distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e213" xlink:type="simple"/></inline-formula> through the function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e214" xlink:type="simple"/></inline-formula>. It does this by deterministically choosing a minimal set of sample points (called sigma points; filled circles to left) from the parameter distribution, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e215" xlink:type="simple"/></inline-formula>. Sigma points are then propagated through function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e216" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e217" xlink:type="simple"/></inline-formula> (filled circles to right), and re-assembled into a Gaussian distribution on the output, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e218" xlink:type="simple"/></inline-formula>, which approximates the output distribution by the first two moments (ellipse to right).</p>
          </caption>
          <graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002960.g013" position="float" xlink:type="simple"/>
        </fig>
        <p>Here <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e219" xlink:type="simple"/></inline-formula> was the multivariate normal distribution on the space of parameters and initial conditions <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e220" xlink:type="simple"/></inline-formula> of dimension <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e221" xlink:type="simple"/></inline-formula>. We deterministically sampled from <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e222" xlink:type="simple"/></inline-formula> a set of <italic>sigma points</italic><disp-formula id="pcbi.1002960.e223"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e223" xlink:type="simple"/><label>(10a)</label></disp-formula><disp-formula id="pcbi.1002960.e224"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e224" xlink:type="simple"/><label>(10b)</label></disp-formula><disp-formula id="pcbi.1002960.e225"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e225" xlink:type="simple"/><label>(10c)</label></disp-formula>and assigned weights<disp-formula id="pcbi.1002960.e226"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e226" xlink:type="simple"/><label>(11a)</label></disp-formula><disp-formula id="pcbi.1002960.e227"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e227" xlink:type="simple"/><label>(11b)</label></disp-formula><disp-formula id="pcbi.1002960.e228"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e228" xlink:type="simple"/><label>(11c)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e229" xlink:type="simple"/></inline-formula>. See ref. <xref ref-type="bibr" rid="pcbi.1002960-vanDerMerwe1">[36]</xref> for guidelines on how to choose parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e230" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e231" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e232" xlink:type="simple"/></inline-formula>; we chose <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e233" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e234" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e235" xlink:type="simple"/></inline-formula>. The above weights define the <italic>scaled</italic> unscented transform, which is the generalized version of the unscented transform algorithm <xref ref-type="bibr" rid="pcbi.1002960-Julier1">[64]</xref>.</p>
        <p>Function <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e236" xlink:type="simple"/></inline-formula> was evaluated for every sigma point,<disp-formula id="pcbi.1002960.e237"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e237" xlink:type="simple"/></disp-formula></p>
        <p>The model outputs <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e238" xlink:type="simple"/></inline-formula> obtained were then reconstructed into a multivariate normal distribution with mean <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e239" xlink:type="simple"/></inline-formula> and covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e240" xlink:type="simple"/></inline-formula> determined by the following equations:<disp-formula id="pcbi.1002960.e241"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e241" xlink:type="simple"/><label>(12a)</label></disp-formula><disp-formula id="pcbi.1002960.e242"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e242" xlink:type="simple"/><label>(12b)</label></disp-formula><disp-formula id="pcbi.1002960.e243"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e243" xlink:type="simple"/><label>(12c)</label></disp-formula></p>
        <p>We note that the UT is computationally much more for efficient compared to random sampling; UT only requires 2L+1 simulations (one for each sigma point), while this number needs to be considerably higher for exhaustive sampling, especially for high dimensional parameter spaces. In terms of accuracy, the UT estimates the first two moments accurately to second order in the Taylor series expansion for any nonlinear function <xref ref-type="bibr" rid="pcbi.1002960-Julier2">[65]</xref>, <xref ref-type="bibr" rid="pcbi.1002960-Julier3">[66]</xref>. However, should one sample 2L+1 points randomly and propagate them, one will not achieve this accuracy and therefore exhaustive sampling is needed to achieve the same level of accuracy as the UT (the exact number of simulations needed depends on the specific system and space dimension of parameters and initial conditions).</p>
        <p>The UT can also be used to propagate log-normal distributions (see <xref ref-type="supplementary-material" rid="pcbi.1002960.s012">Text S1</xref> for details), and mixtures of (log-)normal distributions.</p>
      </sec>
      <sec id="s4d">
        <title>A measure of variability</title>
        <p>The variance of protein numbers is not by itself a good measure of variability, as it does not account for the protein mean; for example, with increasing feedback strength in an autoregulatory network, the fluctuations in protein numbers decrease, but the mean number decreases, too. If absolute numbers of proteins are small, then protein variance becomes relatively large compared to its mean. For most applications, both mean and variance of the protein numbers should be included in the measure of variability. Here we use the squared coefficient of variation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e244" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002960-Kaern1">[4]</xref>, normalised by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e245" xlink:type="simple"/></inline-formula>, the measure of variability without self-repression (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e246" xlink:type="simple"/></inline-formula> stands for no self-repression), to obtain the relative coefficient of variation, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e247" xlink:type="simple"/></inline-formula>. Therefore, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e248" xlink:type="simple"/></inline-formula> will have value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e249" xlink:type="simple"/></inline-formula> when no self-repression is present in the model. Whenever variability according to this measure is less than <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e250" xlink:type="simple"/></inline-formula>, self-repression is effective in suppressing variability.</p>
      </sec>
      <sec id="s4e">
        <title>Specifying extrinsic variability through parameter distribution</title>
        <p>Extrinsic variability is described by the covariance matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e251" xlink:type="simple"/></inline-formula> of parameters and initial conditions. Extrinsic variability can enter the system though variability in a single parameter or a combination of parameters, and parameters can be arbitrarily (anti-)correlated. A diagonal covariance matrix assumes independence between all pairs of parameters. (Anti-)correlations between parameters are modeled by including non-zero off-diagonal terms. The covariance matrix is symmetric by definition.</p>
        <p>We defined the amount of extrinsic variability by specifying a coefficient of variation for each parameter,<disp-formula id="pcbi.1002960.e252"><graphic position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1002960.e252" xlink:type="simple"/><label>(13)</label></disp-formula>and set the diagonal entries of the matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e253" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e254" xlink:type="simple"/></inline-formula>. The parameter dimension is denoted by <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e255" xlink:type="simple"/></inline-formula>. We chose different amounts of extrinsic variability <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e256" xlink:type="simple"/></inline-formula>, as noted in specific figure captions.</p>
        <p>When independence between parameters was assumed, the off-diagonal terms were set to zero. Additionally, we also created arbitrarily correlated parameter distributions by generating random covariance matrices in the following manner. We first generated a random correlation matrix of size <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e257" xlink:type="simple"/></inline-formula>, by generating a symmetric matrix with diagonal elements <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e258" xlink:type="simple"/></inline-formula> and off-diagonal elements sampled from a uniform distribution <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e259" xlink:type="simple"/></inline-formula>, and then finding the nearest valid correlation matrix <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e260" xlink:type="simple"/></inline-formula> by using Higham's algorithm <xref ref-type="bibr" rid="pcbi.1002960-Higham1">[67]</xref>. This correlation matrix was transformed to a covariance matrix by multiplying each element of the correlation matric by the standard deviations corresponding to its row and column, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e261" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e262" xlink:type="simple"/></inline-formula>, were the variances (i.e., diagonal elements of the covariance matrix).</p>
      </sec>
      <sec id="s4f">
        <title>Parameter values and units</title>
        <p>The units are in the form of number of molecules (or number of molecules/sec) rather than concentration (or concentration/sec). This allows us to more easily to compare the exact Gillespie simulation with the output of our approximation framework.</p>
        <p>Parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e263" xlink:type="simple"/></inline-formula> used in examples in figures were set to <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e264" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e265" xlink:type="simple"/></inline-formula>. Parameters that determine the feedback strength, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e266" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e267" xlink:type="simple"/></inline-formula>, were varied as indicated in the figures. The Hill coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e268" xlink:type="simple"/></inline-formula> took integer values between 1 and 4. The units of zeroth-order parameters were <italic>number of molecules per second</italic> (or <italic>molecules per second</italic>), first-order parameters <italic>per second</italic> and second-order parameters <italic>per molecule per second</italic>. The conclusions were checked to hold for other parameter combinations, in particular <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e269" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e270" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e271" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e272" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e273" xlink:type="simple"/></inline-formula>.</p>
      </sec>
    </sec>
    <sec id="s5">
      <title>Supporting Information</title>
      <supplementary-material id="pcbi.1002960.s001" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s001" position="float" xlink:type="simple">
        <label>Figure S1</label>
        <caption>
          <p>Combined framework using the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e274" xlink:type="simple"/></inline-formula>-expansion and the UT allows for efficient calculation of total variability.</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s002" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s002" position="float" xlink:type="simple">
        <label>Figure S2</label>
        <caption>
          <p>Comparison of distributions generated by 10,000 stochastic Gillespie runs (blue) with the <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e275" xlink:type="simple"/></inline-formula>-expansion simulation (green) at steady state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e276" xlink:type="simple"/></inline-formula> and a transient time point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e277" xlink:type="simple"/></inline-formula>. (A) Projected univariate mRNA and protein distributions. (B) Bivariate distribution between mRNA and protein. The inner green ellipse principal axis sizes correspond to sizes of eigenvalues of the covariance matrix (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e278" xlink:type="simple"/></inline-formula> and it contains <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e279" xlink:type="simple"/></inline-formula> of the probability mass; see <xref ref-type="sec" rid="s4">Methods</xref>). In the outer green ellipse, axis sizes have been scaled so that the ellipse represents the 95<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e280" xlink:type="simple"/></inline-formula>-confidence interval contour, i.e., the contour containing <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e281" xlink:type="simple"/></inline-formula> of the probability mass of the corresponding multivariate normal distribution.</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s003" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s003" position="float" xlink:type="simple">
        <label>Figure S3</label>
        <caption>
          <p>Comparison of distributions generated by 1,000,000 stochastic Gillespie runs with varying transcription rate <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e282" xlink:type="simple"/></inline-formula> with coefficient of variation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e283" xlink:type="simple"/></inline-formula>, i.e. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e284" xlink:type="simple"/></inline-formula> (black) with the combined <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e285" xlink:type="simple"/></inline-formula>-expansion and UT simulation (red) at steady state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e286" xlink:type="simple"/></inline-formula> (top row) and a transient time point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e287" xlink:type="simple"/></inline-formula> (bottom row).</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s004" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s004" position="float" xlink:type="simple">
        <label>Figure S4</label>
        <caption>
          <p>Comparison of distributions generated by 1,000,000 stochastic Gillespie runs with varying parameters <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e288" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e289" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e290" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e291" xlink:type="simple"/></inline-formula> independently with coefficient of variation <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e292" xlink:type="simple"/></inline-formula> (black) with the combined <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e293" xlink:type="simple"/></inline-formula>-expansion and UT simulation (red) at steady state <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e294" xlink:type="simple"/></inline-formula> (top row) and a transient time point <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e295" xlink:type="simple"/></inline-formula> (bottom row).</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s005" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s005" position="float" xlink:type="simple">
        <label>Figure S5</label>
        <caption>
          <p>The effects of extrinsic variability in individual parameters on the total protein variability. An arrow upwards (downwards) means that with increasing amount of extrinsic variability in the respective parameter, the total variability in the protein (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e296" xlink:type="simple"/></inline-formula>) increases (decreases).</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s006" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s006" position="float" xlink:type="simple">
        <label>Figure S6</label>
        <caption>
          <p>Comparing total protein variability in post-transcriptional circuit for different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e297" xlink:type="simple"/></inline-formula>, the parameter that depends on the level of complementarity between mRNA and miRNA. <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e298" xlink:type="simple"/></inline-formula> (solid line) <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e299" xlink:type="simple"/></inline-formula> (dashed line). Extrinsic variability in parameters: a = 0.01 (red), a = 0.03 (blue), a = 0.05 (green), a = 0.1 (black), and a = 0.2 (magenta). Feedback strength is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e300" xlink:type="simple"/></inline-formula>.</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s007" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s007" position="float" xlink:type="simple">
        <label>Figure S7</label>
        <caption>
          <p>Total variability of transcriptional self-repression resulting from different correlations of extrinsic variability. Lines depicting variability resulting from positively correlated (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e301" xlink:type="simple"/></inline-formula>) extrinsic variability in a specified parameter pair are colored in red, and lines resulting from anti-correlated (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e302" xlink:type="simple"/></inline-formula>) extrinsic variability between the parameter pair are colored in blue. Parameters determining the diagonal values of the covariance matrix used in this example were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e303" xlink:type="simple"/></inline-formula>. We note that for a few other sets of diagonal values, the distinction between blue and red for some parameter pairs was less clear than for this example.</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s008" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s008" position="float" xlink:type="simple">
        <label>Figure S8</label>
        <caption>
          <p>Total variability of post-transcriptional self-repression resulting from different correlations of extrinsic variability. Lines depicting variability resulting from positively correlated (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e304" xlink:type="simple"/></inline-formula>) extrinsic variability in a specified parameter pair are colored in red, and lines resulting from anti-correlated (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e305" xlink:type="simple"/></inline-formula>) extrinsic variability between the parameter pair are colored in blue. Parameters determining the diagonal values of the covariance matrix used in this example were <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e306" xlink:type="simple"/></inline-formula>. We note that for a few other sets of diagonal values, the distinction between blue and red for some parameter pairs was less clear than for this example.</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s009" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s009" position="float" xlink:type="simple">
        <label>Figure S9</label>
        <caption>
          <p>Intrinsic transient variability can be suppressed even when intrinsic steady-state variability cannot be suppressed. Shown is the total variability of the protein in the transcriptional autoregulatory network with Hill coefficient <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e307" xlink:type="simple"/></inline-formula> for different feedback strengths. At steady state (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e308" xlink:type="simple"/></inline-formula>) the autoregulatory motif cannot suppress variability, which we see from the fact that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e309" xlink:type="simple"/></inline-formula>. However, in transient states (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e310" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e311" xlink:type="simple"/></inline-formula>) the total variability is suppressed compared to that in a network without self-regulation. This follows from the fact that <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e312" xlink:type="simple"/></inline-formula> for certain feedback strengths.</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s010" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s010" position="float" xlink:type="simple">
        <label>Figure S10</label>
        <caption>
          <p>Transient variability can be suppressed better than steady-state variability. Across all feedback strengths the minimum variability reached in transient states (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e313" xlink:type="simple"/></inline-formula>) is lower than the minimum variability reached in the steady state (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e314" xlink:type="simple"/></inline-formula>). For high feedback strengths (<inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e315" xlink:type="simple"/></inline-formula>) the steady-state variability is greater than transient variability.</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s011" mimetype="application/postscript" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s011" position="float" xlink:type="simple">
        <label>Figure S11</label>
        <caption>
          <p>In transient states the qualitative effects of extrinsic variability on total variability agree with those in steady states (<xref ref-type="fig" rid="pcbi-1002960-g005">Figure 5</xref>). Results shown for 4 parameters in a transcriptional autoregulation. Extrinsic variability in parameters: a = 0.01 (red), a = 0.03 (blue), a = 0.05 (green), a = 0.1 (black), and a = 0.2 (magenta). Feedback strength is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1002960.e316" xlink:type="simple"/></inline-formula>.</p>
          <p>(EPS)</p>
        </caption>
      </supplementary-material>
      <supplementary-material id="pcbi.1002960.s012" mimetype="application/pdf" xlink:href="info:doi/10.1371/journal.pcbi.1002960.s012" position="float" xlink:type="simple">
        <label>Text S1</label>
        <caption>
          <p>Contains a more detailed description of the procedure for calculating total variability from the combined model with intrinsic and extrinsic sources of variability, examples of extrinsic variability that produce small and large differences in total variability, and notes on using the unscented transform to propagate log-normal distributions through a nonlinear function.</p>
          <p>(PDF)</p>
        </caption>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Ron Weiss, Zhen Xie, Liliana Wroblewska, David R. Hagen, Nirmala Paudel, Filipe Gracio, Thomas Gurry, Yuanyuan Cui, Jacob White, Daniel Silk and Michal Komorowski for fruitful discussions.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002960-Raj1">
        <label>1</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raj</surname><given-names>A</given-names></name>, <name name-style="western"><surname>van Oudenaarden</surname><given-names>A</given-names></name> (<year>2008</year>) <article-title>Nature, nurture, or chance: stochastic gene expression and its consequences</article-title>. <source>Cell</source> <volume>135</volume>: <fpage>216</fpage>–<lpage>226</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Elowitz1">
        <label>2</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elowitz</surname><given-names>MB</given-names></name>, <name name-style="western"><surname>Levine</surname><given-names>AJ</given-names></name>, <name name-style="western"><surname>Siggia</surname><given-names>ED</given-names></name>, <name name-style="western"><surname>Swain</surname><given-names>PS</given-names></name> (<year>2002</year>) <article-title>Stochastic gene expression in a single cell</article-title>. <source>Science</source> <volume>297</volume>: <fpage>1183</fpage>–<lpage>1186</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Paulsson1">
        <label>3</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Paulsson</surname><given-names>J</given-names></name> (<year>2004</year>) <article-title>Summing up the noise in gene networks</article-title>. <source>Nature</source> <volume>427</volume>: <fpage>415</fpage>–<lpage>418</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Kaern1">
        <label>4</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kaern</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Elston</surname><given-names>TC</given-names></name>, <name name-style="western"><surname>Blake</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>JJ</given-names></name> (<year>2005</year>) <article-title>Stochasticity in gene expression: from theories to phenotypes</article-title>. <source>Nat Rev Genet</source> <volume>6</volume>: <fpage>451</fpage>–<lpage>464</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Balzsi1">
        <label>5</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Balázsi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>van Oudenaarden</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Collins</surname><given-names>JJ</given-names></name> (<year>2011</year>) <article-title>Cellular decision making and biological noise: from microbes to mammals</article-title>. <source>Cell</source> <volume>144</volume>: <fpage>910</fpage>–<lpage>925</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Butcher1">
        <label>6</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Butcher</surname><given-names>EC</given-names></name>, <name name-style="western"><surname>Berg</surname><given-names>EL</given-names></name>, <name name-style="western"><surname>Kunkel</surname><given-names>EJ</given-names></name> (<year>2004</year>) <article-title>Systems biology in drug discovery</article-title>. <source>Nat Biotechnol</source> <volume>22</volume>: <fpage>1253</fpage>–<lpage>1259</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Gibbs1">
        <label>7</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gibbs</surname><given-names>JB</given-names></name> (<year>2000</year>) <article-title>Mechanism-based target identification and drug discovery in cancer research</article-title>. <source>Science</source> <volume>287</volume>: <fpage>1969</fpage>–<lpage>1973</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Iyengar1">
        <label>8</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Iyengar</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Zhao</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Chung</surname><given-names>SW</given-names></name>, <name name-style="western"><surname>Mager</surname><given-names>DE</given-names></name>, <name name-style="western"><surname>Gallo</surname><given-names>JM</given-names></name> (<year>2012</year>) <article-title>Merging systems biology with pharmacodynamics</article-title>. <source>Sci Transl Med</source> <volume>4</volume>: <fpage>126ps7</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Kim1">
        <label>9</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kim</surname><given-names>BS</given-names></name> (<year>2010</year>) <article-title>Robust Network Calibration and Therapy Design in Systems Biology [Ph.D. thesis]</article-title>. <source>Massachusetts Institute of Technology</source></mixed-citation>
      </ref>
      <ref id="pcbi.1002960-vanderGraaf1">
        <label>10</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van der Graaf</surname><given-names>PH</given-names></name>, <name name-style="western"><surname>Benson</surname><given-names>N</given-names></name> (<year>2011</year>) <article-title>Systems pharmacology: bridging systems biology and pharmacokinetics-pharmacodynamics (PKPD) in drug discovery and development</article-title>. <source>Pharm Res</source> <volume>28</volume>: <fpage>1460</fpage>–<lpage>1464</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Purnick1">
        <label>11</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Purnick</surname><given-names>PEM</given-names></name>, <name name-style="western"><surname>Weiss</surname><given-names>R</given-names></name> (<year>2009</year>) <article-title>The second wave of synthetic biology: from modules to systems</article-title>. <source>Nat Rev Mol Cell Biol</source> <volume>10</volume>: <fpage>410</fpage>–<lpage>422</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Mukherji1">
        <label>12</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mukherji</surname><given-names>S</given-names></name>, <name name-style="western"><surname>van Oudenaarden</surname><given-names>A</given-names></name> (<year>2009</year>) <article-title>Synthetic biology: understanding biological design from synthetic circuits</article-title>. <source>Nat Rev Genet</source> <volume>10</volume>: <fpage>859</fpage>–<lpage>871</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-vanKampen1">
        <label>13</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Kampen</surname><given-names>NG</given-names></name> (<year>2007</year>) <article-title>Stochastic Processes in Physics and Chemistry</article-title>. <source>North-Holland, 3rd edition</source></mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Gillespie1">
        <label>14</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gillespie</surname><given-names>D</given-names></name> (<year>1977</year>) <article-title>Exact stochastic simulation of coupled chemical reactions</article-title>. <source>J Phys Chem</source> <volume>81</volume>: <fpage>2340</fpage>–<lpage>2361</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Wilkinson1">
        <label>15</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Wilkinson</surname><given-names>DJ</given-names></name> (<year>2009</year>) <article-title>Stochastic modelling for quantitative description of heterogeneous biological systems</article-title>. <source>Nat Rev Genet</source> <volume>10</volume>: <fpage>122</fpage>–<lpage>133</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-GmezUribe1">
        <label>16</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gómez-Uribe</surname><given-names>CA</given-names></name>, <name name-style="western"><surname>Verghese</surname><given-names>GC</given-names></name> (<year>2007</year>) <article-title>Mass uctuation kinetics: capturing stochastic effects in systems of chemical reactions through coupled mean-variance computations</article-title>. <source>J Chem Phys</source> <volume>126</volume>: <fpage>024109</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Kurtz1">
        <label>17</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kurtz</surname><given-names>TG</given-names></name> (<year>1972</year>) <article-title>The Relationship between Stochastic and Deterministic Models for Chemical Reactions</article-title>. <source>J Chem Phys</source> <volume>57</volume>: <fpage>2976</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Tomioka1">
        <label>18</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tomioka</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Kimura</surname><given-names>H</given-names></name>, <name name-style="western"><surname>J Kobayashi</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Aihara</surname><given-names>K</given-names></name> (<year>2004</year>) <article-title>Multivariate analysis of noise in genetic regulatory networks</article-title>. <source>J Theor Biol</source> <volume>229</volume>: <fpage>501</fpage>–<lpage>521</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Komorowski1">
        <label>19</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Komorowski</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Finkenstädt</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Harper</surname><given-names>CV</given-names></name>, <name name-style="western"><surname>Rand</surname><given-names>DA</given-names></name> (<year>2009</year>) <article-title>Bayesian inference of biochemical kinetic parameters using the linear noise approximation</article-title>. <source>BMC Bioinformatics</source> <volume>10</volume>: <fpage>343</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Grima1">
        <label>20</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Grima</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Thomas</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Straube</surname><given-names>AV</given-names></name> (<year>2011</year>) <article-title>How accurate are the nonlinear chemical Fokker-Planck and chemical Langevin equations?</article-title> <source>J Chem Phys</source> <volume>135</volume>: <fpage>084103</fpage>–<lpage>084103–16</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Elf1">
        <label>21</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elf</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Ehrenberg</surname><given-names>M</given-names></name> (<year>2003</year>) <article-title>Fast evaluation of uctuations in biochemical networks with the linear noise approximation</article-title>. <source>Genome Res</source> <volume>13</volume>: <fpage>2475</fpage>–<lpage>2484</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Jayanthi1">
        <label>22</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jayanthi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Del Vecchio</surname><given-names>D</given-names></name> (<year>2009</year>) <article-title>On the compromise between retroactivity attenuation and noise amplification in gene regulatory networks</article-title>. <source>Proc of 48 IEEE CDC</source> <fpage>4565</fpage>–<lpage>4571</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Komorowski2">
        <label>23</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Komorowski</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Finkenstädt</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Rand</surname><given-names>D</given-names></name> (<year>2010</year>) <article-title>Using a single uorescent reporter gene to infer half-life of extrinsic noise and other parameters of gene expression</article-title>. <source>Biophys J</source> <volume>98</volume>: <fpage>2759</fpage>–<lpage>2769</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Komorowski3">
        <label>24</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Komorowski</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Costa</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>Rand</surname><given-names>DA</given-names></name>, <name name-style="western"><surname>Stumpf</surname><given-names>MPH</given-names></name> (<year>2011</year>) <article-title>Sensitivity, robustness, and identifiability in stochastic chemical kinetics models</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>108</volume>: <fpage>8645</fpage>–<lpage>8650</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Scott1">
        <label>25</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scott</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Hwa</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Ingalls</surname><given-names>B</given-names></name> (<year>2007</year>) <article-title>Deterministic characterization of stochastic genetic circuits</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>104</volume>: <fpage>7402</fpage>–<lpage>7407</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Scott2">
        <label>26</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scott</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ingalls</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Kaern</surname><given-names>M</given-names></name> (<year>2006</year>) <article-title>Estimations of intrinsic and extrinsic noise in models of nonlinear genetic networks</article-title>. <source>Chaos</source> <volume>16</volume>: <fpage>026107</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Ito1">
        <label>27</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ito</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Uchida</surname><given-names>K</given-names></name> (<year>2010</year>) <article-title>Formulas for intrinsic noise evaluation in oscillatory genetic networks</article-title>. <source>J Theor Biol</source> <volume>267</volume>: <fpage>223</fpage>–<lpage>234</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Raser1">
        <label>28</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Raser</surname><given-names>JM</given-names></name>, <name name-style="western"><surname>O'Shea</surname><given-names>EK</given-names></name> (<year>2004</year>) <article-title>Control of stochasticity in eukaryotic gene expression</article-title>. <source>Science</source> <volume>304</volume>: <fpage>1811</fpage>–<lpage>1814</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Waks1">
        <label>29</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Waks</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Silver</surname><given-names>PA</given-names></name> (<year>2010</year>) <article-title>Nuclear origins of cell-to-cell variability</article-title>. <source>Cold Spring Harb Symp Quant Biol</source> <volume>75</volume>: <fpage>87</fpage>–<lpage>94</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Swain1">
        <label>30</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Swain</surname><given-names>PS</given-names></name>, <name name-style="western"><surname>Elowitz</surname><given-names>MB</given-names></name>, <name name-style="western"><surname>Siggia</surname><given-names>ED</given-names></name> (<year>2002</year>) <article-title>Intrinsic and extrinsic contributions to stochasticity in gene expression</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>99</volume>: <fpage>12795</fpage>–<lpage>12800</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Hilfinger1">
        <label>31</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hilfinger</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Paulsson</surname><given-names>J</given-names></name> (<year>2011</year>) <article-title>Separating intrinsic from extrinsic uctuations in dynamic biological systems</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>108</volume>: <fpage>12167</fpage>–<lpage>12172</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Shahrezaei1">
        <label>32</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Shahrezaei</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Ollivier</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Swain</surname><given-names>PS</given-names></name> (<year>2008</year>) <article-title>Colored extrinsic uctuations and stochastic gene expression</article-title>. <source>Mol Syst Biol</source> <volume>4</volume>: <fpage>196</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Zechner1">
        <label>33</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Zechner</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Ruess</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Krenn</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Pelet</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Peter</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2012</year>) <article-title>Moment-based inference predicts bimodality in transient gene expression</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>109</volume>: <fpage>8340</fpage>–<lpage>8345</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Hallen1">
        <label>34</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hallen</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Tanouchi</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tan</surname><given-names>C</given-names></name>, <name name-style="western"><surname>West</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Computation of steady-state probability distributions in stochastic models of cellular networks</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1002209</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Singh1">
        <label>35</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Singh</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hespanha</surname><given-names>JP</given-names></name>, <name name-style="western"><surname>Hespanha</surname><given-names>JP</given-names></name> (<year>2009</year>) <article-title>Optimal feedback strength for noise suppression in autoregulatory gene networks</article-title>. <source>Biophys J</source> <volume>96</volume>: <fpage>4013</fpage>–<lpage>4023</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-vanDerMerwe1">
        <label>36</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Der Merwe</surname><given-names>R</given-names></name> (<year>2004</year>) <article-title>Sigma-point Kalman filters for probabilistic inference in dynamic statespace models [Ph.D. thesis]</article-title>. <source>Oregon Health &amp; Science University</source></mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Snijder1">
        <label>37</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Snijder</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Pelkmans</surname><given-names>L</given-names></name> (<year>2011</year>) <article-title>Origins of regulated cell-to-cell variability</article-title>. <source>Nat Rev Mol Cell Biol</source> <volume>12</volume>: <fpage>119</fpage>–<lpage>125</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Thattai1">
        <label>38</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thattai</surname><given-names>M</given-names></name>, <name name-style="western"><surname>van Oudenaarden</surname><given-names>A</given-names></name> (<year>2001</year>) <article-title>Intrinsic noise in gene regulatory networks</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>98</volume>: <fpage>8614</fpage>–<lpage>8619</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Weiss1">
        <label>39</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Weiss</surname><given-names>NA</given-names></name>, <name name-style="western"><surname>Holmes</surname><given-names>PT</given-names></name>, <name name-style="western"><surname>Hardy</surname><given-names>M</given-names></name> (<year>2005</year>) <article-title>A course in probability</article-title>. <source>Addison-Wesley</source></mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Ozbudak1">
        <label>40</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ozbudak</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Thattai</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kurtser</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Grossman</surname><given-names>AD</given-names></name>, <name name-style="western"><surname>Oudenaarden</surname><given-names>Av</given-names></name> (<year>2002</year>) <article-title>Regulation of noise in the expression of a single gene</article-title>. <source>Nat Genet</source> <volume>31</volume>: <fpage>69</fpage>–<lpage>73</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Becskei1">
        <label>41</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Becskei</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Serrano</surname><given-names>L</given-names></name> (<year>2000</year>) <article-title>Engineering stability in gene networks by autoregulation</article-title>. <source>Nature</source> <volume>405</volume>: <fpage>590</fpage>–<lpage>593</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Swain2">
        <label>42</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Swain</surname><given-names>PS</given-names></name> (<year>2004</year>) <article-title>Efficient attenuation of stochasticity in gene expression through posttranscriptional control</article-title>. <source>J Mol Biol</source> <volume>344</volume>: <fpage>965</fpage>–<lpage>976</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Dublanche1">
        <label>43</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dublanche</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Michalodimitrakis</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Küummerer</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Foglierini</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Serrano</surname><given-names>L</given-names></name> (<year>2006</year>) <article-title>Noise in transcription negative feedback loops: simulation and experimental analysis</article-title>. <source>Mol Syst Biol</source> <volume>2</volume>: <fpage>41</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Hooshangi1">
        <label>44</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hooshangi</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Weiss</surname><given-names>R</given-names></name> (<year>2006</year>) <article-title>The effect of negative feedback on noise propagation in transcriptional gene networks</article-title>. <source>Chaos</source> <volume>16</volume>: <fpage>026108</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Nevozhay1">
        <label>45</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Nevozhay</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Adams</surname><given-names>RM</given-names></name>, <name name-style="western"><surname>Murphy</surname><given-names>KF</given-names></name>, <name name-style="western"><surname>Josic</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Balazsi</surname><given-names>G</given-names></name> (<year>2009</year>) <article-title>Negative autoregulation linearizes the dose-response and suppresses the heterogeneity of gene expression</article-title>. <source>Proc Natl Acad Sci U S A</source> <volume>106</volume>: <fpage>5123</fpage>–<lpage>5128</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Osella1">
        <label>46</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Osella</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bosia</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Corá</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Caselle</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>The role of incoherent microRNA-mediated feedforward loops in noise buffering</article-title>. <source>PLoS Comput Biol</source> <volume>7</volume>: <fpage>e1001101</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Bleris1">
        <label>47</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bleris</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Xie</surname><given-names>Z</given-names></name>, <name name-style="western"><surname>Glass</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Adadey</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Sontag</surname><given-names>E</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Synthetic incoherent feedforward circuits show adaptation to the amount of their genetic template</article-title>. <source>Mol Syst Biol</source> <volume>7</volume>: <fpage>519</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Voliotis1">
        <label>48</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Voliotis</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Bowsher</surname><given-names>CG</given-names></name> (<year>2012</year>) <article-title>The magnitude and colour of noise in genetic negative feedback systems</article-title>. <source>Nucleic Acids Res</source> <volume>40</volume>: <fpage>7084</fpage>–<lpage>7095</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Bartel1">
        <label>49</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bartel</surname><given-names>D</given-names></name> (<year>2009</year>) <article-title>MicroRNAs: target recognition and regulatory functions</article-title>. <source>Cell</source> <volume>136</volume>: <fpage>215</fpage>–<lpage>233</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Mukherji2">
        <label>50</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mukherji</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Ebert</surname><given-names>MS</given-names></name>, <name name-style="western"><surname>Zheng</surname><given-names>GXY</given-names></name>, <name name-style="western"><surname>Tsang</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Sharp</surname><given-names>PA</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>MicroRNAs can generate thresholds in target gene expression</article-title>. <source>Nat Genet</source> <volume>43</volume>: <fpage>854</fpage>–<lpage>859</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Taniguchi1">
        <label>51</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Taniguchi</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Choi</surname><given-names>PJ</given-names></name>, <name name-style="western"><surname>Li</surname><given-names>GW</given-names></name>, <name name-style="western"><surname>Chen</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Babu</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2010</year>) <article-title>Quantifying E. coli proteome and transcriptome with single-molecule sensitivity in single cells</article-title>. <source>Science</source> <volume>329</volume>: <fpage>533</fpage>–<lpage>538</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Rinott1">
        <label>52</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rinott</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Jaimovich</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Friedman</surname><given-names>N</given-names></name> (<year>2011</year>) <article-title>Exploring transcription regulation through cell-to-cell variability</article-title>. <source>Proc Natl Acad Sci</source> <volume>108</volume>: <fpage>6329</fpage>–<lpage>6334</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Brown1">
        <label>53</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Brown</surname><given-names>BD</given-names></name>, <name name-style="western"><surname>Gentner</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Cantore</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Colleoni</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Amendola</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>Endogenous microRNA can be broadly exploited to regulate transgene expression according to tissue, lineage and differentiation state</article-title>. <source>Nat Biotechnol</source> <volume>25</volume>: <fpage>1457</fpage>–<lpage>1467</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Cuccato1">
        <label>54</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cuccato</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Polynikis</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Siciliano</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Graziano</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Di Bernardo</surname><given-names>M</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>Modeling RNA interference in mammalian cells</article-title>. <source>BMC Syst Biol</source> <volume>5</volume>: <fpage>19</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Tao1">
        <label>55</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tao</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Jia</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Dewey</surname><given-names>TG</given-names></name> (<year>2005</year>) <article-title>Stochastic uctuations in gene expression far from equilibrium: Omega expansion and linear noise approximation</article-title>. <source>J Chem Phys</source> <volume>122</volume>: <fpage>124108</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Cheong1">
        <label>56</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Cheong</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Rhee</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wang</surname><given-names>CJ</given-names></name>, <name name-style="western"><surname>Nemenman</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Levchenko</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>Information transduction capacity of noisy biochemical signaling networks</article-title>. <source>Science</source> <volume>334</volume>: <fpage>354</fpage>–<lpage>358</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Lestas1">
        <label>57</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lestas</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Vinnicombe</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Paulsson</surname><given-names>J</given-names></name> (<year>2010</year>) <article-title>Fundamental limits on the suppression of molecular uctuations</article-title>. <source>Nature</source> <volume>467</volume>: <fpage>174</fpage>–<lpage>178</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Thomas1">
        <label>58</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Thomas</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Straube</surname><given-names>AV</given-names></name>, <name name-style="western"><surname>Grima</surname><given-names>R</given-names></name> (<year>2012</year>) <article-title>The slow-scale linear noise approximation: an accurate, reduced stochastic description of biochemical networks under timescale separation conditions</article-title>. <source>BMC Syst Biol</source> <volume>6</volume>: <fpage>39</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Thomas2">
        <label>59</label>
        <mixed-citation publication-type="jorunal" xlink:type="simple">Thomas P, Matuschek H, Grima R (2012) Efficient uctuation analysis of biochemical pathways beyond the linear noise approximation using iNA. arXiv preprint: arXiv:12071631.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Gillespie2">
        <label>60</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gillespie</surname><given-names>CS</given-names></name> (<year>2009</year>) <article-title>Moment-closure approximations for mass-action models</article-title>. <source>IET Syst Biol</source> <volume>3</volume>: <fpage>52</fpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Bowsher1">
        <label>61</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bowsher</surname><given-names>CG</given-names></name>, <name name-style="western"><surname>Swain</surname><given-names>PS</given-names></name> (<year>2012</year>) <article-title>Identifying sources of variation and the ow of information in biochemical networks</article-title>. <source>Proc Natl Acad Sci</source> <volume>109</volume>: <fpage>E1320</fpage>–<lpage>8</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Woodcock1">
        <label>62</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Woodcock</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Komorowski</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Finkenstädt</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Harper</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Davis</surname><given-names>J</given-names></name>, <etal>et al</etal>. (<year>2011</year>) <article-title>A Bayesian hierarchical diffusion model for estimating kinetic parameters and cell-to-cell variability</article-title>. <source>Warwick Uni working Paper</source> <volume>No 11–10</volume>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-vanKampen2">
        <label>63</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Kampen</surname><given-names>N</given-names></name> (<year>1976</year>) <article-title>The expansion of the master equation</article-title>. <source>Adv Chem Phys</source> <volume>34</volume>: <fpage>245</fpage>–<lpage>308</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Julier1">
        <label>64</label>
        <mixed-citation publication-type="other" xlink:type="simple">Julier SJ (2002) The scaled unscented transformation. In: Proc ACC '02. American Automatic Control Council. pp. 4555–4559.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Julier2">
        <label>65</label>
        <mixed-citation publication-type="other" xlink:type="simple">Julier SJ, Uhlmann JK (1996) A general method for approximating nonlinear transformations of probability distributions. Technical Report, Robotics Research Group, Department of Engineering Science, University of Oxford.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Julier3">
        <label>66</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Julier</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Uhlmann</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Durrant-Whyte</surname><given-names>HF</given-names></name> (<year>2000</year>) <article-title>A new method for the nonlinear transformation of means and covariances in filters and estimators</article-title>. <source>IEEE Trans Automat Contr</source> <volume>45</volume>: <fpage>477</fpage>–<lpage>482</lpage>.</mixed-citation>
      </ref>
      <ref id="pcbi.1002960-Higham1">
        <label>67</label>
        <mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Higham</surname><given-names>NJ</given-names></name> (<year>2002</year>) <article-title>Computing the nearest correlation matrix – A problem from finance</article-title>. <source>IMA J Numer Anal</source> <volume>22</volume>: <fpage>329</fpage>–<lpage>343</lpage>.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
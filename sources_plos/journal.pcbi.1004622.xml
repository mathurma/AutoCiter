<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article article-type="research-article" dtd-version="3.0" xml:lang="en" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-15-01420</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1004622</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Tamping Ramping: Algorithmic, Implementational, and Computational Explanations of Phasic Dopamine Signals in the Accumbens</article-title>
<alt-title alt-title-type="running-head">Tamping Ramping: Explanations of Phasic Dopamine Signals in the Accumbens</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Lloyd</surname> <given-names>Kevin</given-names></name>
<xref ref-type="corresp" rid="cor001">*</xref>
<xref ref-type="aff" rid="aff001"/>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Dayan</surname> <given-names>Peter</given-names></name>
<xref ref-type="aff" rid="aff001"/>
</contrib>
</contrib-group>
<aff id="aff001">
<addr-line>Gatsby Computational Neuroscience Unit, London, United Kingdom</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Sporns</surname> <given-names>Olaf</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Indiana University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con" id="contrib001">
<p>Conceived and designed the experiments: KL PD. Performed the experiments: KL PD. Analyzed the data: KL PD. Wrote the paper: KL PD.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">klloyd@gatsby.ucl.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>12</month>
<year>2015</year>
</pub-date>
<pub-date pub-type="epub">
<day>23</day>
<month>12</month>
<year>2015</year>
</pub-date>
<volume>11</volume>
<issue>12</issue>
<elocation-id>e1004622</elocation-id>
<history>
<date date-type="received">
<day>24</day>
<month>8</month>
<year>2015</year>
</date>
<date date-type="accepted">
<day>25</day>
<month>10</month>
<year>2015</year>
</date>
</history>
<permissions>
<copyright-year>2015</copyright-year>
<copyright-holder>Lloyd, Dayan</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1004622"/>
<abstract>
<p>Substantial evidence suggests that the phasic activity of dopamine neurons represents reinforcement learning’s temporal difference prediction error. However, recent reports of ramp-like increases in dopamine concentration in the striatum when animals are about to act, or are about to reach rewards, appear to pose a challenge to established thinking. This is because the implied activity is persistently predictable by preceding stimuli, and so cannot arise as this sort of prediction error. Here, we explore three possible accounts of such ramping signals: (a) the resolution of uncertainty about the timing of action; (b) the direct influence of dopamine over mechanisms associated with making choices; and (c) a new model of discounted vigour. Collectively, these suggest that dopamine ramps may be explained, with only minor disturbance, by standard theoretical ideas, though urgent questions remain regarding their proximal cause. We suggest experimental approaches to disentangling which of the proposed mechanisms are responsible for dopamine ramps.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Dopamine has long been implicated in reward-motivated behaviour. Theory and experiments suggest that activity of dopamine-containing neurons resembles a temporally-sophisticated prediction error used to learn expectations of future reward. This account would appear to be inconsistent with recent observations of ‘ramps’, i.e., gradual increases in extracellular dopamine concentration prior to the execution of actions or the acquisition of rewards. We explore three different possible explanations of such ramping signals as arising: (a) when subjects experience uncertainty about when actions will be executed; (b) when dopamine itself influences the timecourse of choice; and (c) under a new model in which ‘quasi-tonic’ dopamine signals arise through a form of temporal discounting. We thereby show that dopamine ramps can be integrated with current theories, and also suggest experiments to clarify which mechanisms are involved.</p>
</abstract>
<funding-group>
<funding-statement>This work was supported by the Gatsby Charitable Foundation (KL and PD). The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="15"/>
<table-count count="0"/>
<page-count count="34"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Ideas from the field of reinforcement learning (RL) have played an important role in neuroscientific theories of how animals choose actions to gain rewards and avoid punishments. Prominently, it has been suggested [<xref ref-type="bibr" rid="pcbi.1004622.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref002">2</xref>] that the phasic responses of midbrain dopaminergic neurons resemble a temporal difference (TD) error, a learning signal which facilitates prediction and control of rewarding events [<xref ref-type="bibr" rid="pcbi.1004622.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref004">4</xref>]. Consistent with this notion, these neurons are activated by unpredicted primary rewards and by cues that predict such rewards, but not by rewards that are themselves reliably predicted. More recent experiments using fast scan cyclic voltammetry (FSCV) to measure rapid changes in extracellular dopamine concentration within projection areas, notably the nucleus accumbens (NAc), find transients which show similar TD-like properties [<xref ref-type="bibr" rid="pcbi.1004622.ref005">5</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref007">7</xref>] (<xref ref-type="fig" rid="pcbi.1004622.g001">Fig 1</xref>).</p>
<fig id="pcbi.1004622.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Phasic dopamine signals resemble a temporal difference error.</title>
<p>(A) Changes in extracellular dopamine concentration (Δ[DA]) in the nucleus accumbens (NAc) core before (left; single trial) and after (right; mean + SEM) experience of repeated pairings between a predictive cue (horizontal black bar) and a reward (inverted black triangle) delivered at cue offset. Initially, a phasic increase in dopamine is observed at the time of reward delivery. After repeated experience of the relationship between cue and reward, a phasic increase is observed at the time of cue onset, but not at the time of reward, which is still delivered. Adapted from [<xref ref-type="bibr" rid="pcbi.1004622.ref006">6</xref>], with permission. (B) Models based on temporal difference (TD) learning predict transfer of the TD error <italic>δ</italic><sub><italic>t</italic></sub> from the time of reward (‘R’; left) to time of predictive cue (‘CS’; right) over the course of learning for both trace and delay conditioning.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g001" xlink:type="simple"/>
</fig>
<p>However, recent reports of ramp-like increases in dopamine concentration preceding self-initiated instrumental responses [<xref ref-type="bibr" rid="pcbi.1004622.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref013">13</xref>] and during approach to spatial locations associated with reward [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>] appear to pose a challenge to established thinking. The central issue for TD accounts of dopamine is why such ramping should be observed at all, since TD provides a mechanism for predicting away later dopaminergic activity by earlier—as in the case of the transfer of activity from the time of reward to the time of predictive cues.</p>
<p>One possibility is that these signals have no functional importance, for instance being the result of a process of gated release [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref015">15</xref>]. In this, a form of ramping activity in the glutamatergic cortico-striatal input might cause the terminals of the dopamine neurons to discharge more of the neuromodulator. This would account for the excess release without any implication for the activity of dopamine neurons—and would mainly pose the question as to how the altered pattern of release could have no effect on striatal activity or plasticity. In the current paper, however, we consider three possible, non-mutually exclusive, functional explanations of NAc dopamine ramps. Firstly, we consider that increases in dopamine which precede an animal’s response may reflect resolution of uncertainty about the time of action. Secondly, we show that ramping may arise if dopamine plays a direct role in modulating the gain of a decision-making process in which value information is integrated over time. Finally, we introduce a discounted model of vigour which may explain the more macroscopic ramping signals observed in [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>].</p>
<p>We start by sketching what might be considered the ‘standard’ computational account of dopamine and examining the confounding experimental phenomena.</p>
<sec id="sec002">
<title>Phasic dopamine and TD error</title>
<p>In the main class of TD models of the phasic dopamine response [<xref ref-type="bibr" rid="pcbi.1004622.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref016">16</xref>], the computational goal of learning is to predict from each state <italic>s</italic> the expected discounted sum <italic>V</italic>(<italic>s</italic>) of the rewards that will be encountered during a trial
<disp-formula id="pcbi.1004622.e001"><alternatives><graphic id="pcbi.1004622.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e001" xlink:type="simple"/><mml:math display="block" id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>V</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mrow><mml:mo>{</mml:mo> <mml:msup><mml:mi>γ</mml:mi> <mml:mn>0</mml:mn></mml:msup> <mml:msub><mml:mi>r</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msup><mml:mi>γ</mml:mi> <mml:mn>1</mml:mn></mml:msup> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msup><mml:mi>γ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:mo>…</mml:mo> <mml:mo stretchy="false">|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>r</italic><sub><italic>t</italic></sub> is the reward delivered at time <italic>t</italic>, and 0 ≤ <italic>γ</italic> ≤ 1 is a discount factor that controls how much weight is given to future relative to immediate rewards. Crucially, the definition of this <italic>state value function</italic> satisfies a (Bellman) consistency condition with respect to each possible next state <italic>s</italic>′:
<disp-formula id="pcbi.1004622.e002"><alternatives><graphic id="pcbi.1004622.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e002" xlink:type="simple"/><mml:math display="block" id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>V</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="double-struck">E</mml:mi> <mml:mo>{</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>V</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi>s</mml:mi> <mml:mo>′</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>}</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
This leads to the idea of using local discrepancies in the value of sampled successive states to drive learning [<xref ref-type="bibr" rid="pcbi.1004622.ref003">3</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref017">17</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref018">18</xref>]. Thus, the TD error <italic>δ</italic><sub><italic>t</italic></sub> is defined as
<disp-formula id="pcbi.1004622.e003"><alternatives><graphic id="pcbi.1004622.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e003" xlink:type="simple"/><mml:math display="block" id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:mi>V</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>V</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
and can be used to improve estimates of <italic>V</italic>(<italic>s</italic>). It is exactly this TD error that phasic dopaminergic activity has been hypothesized to represent.</p>
<p>As noted, in this paper, we consider data on dopamine concentrations in target structures (denoted [DA]) rather than the phasic activity of dopaminergic neurons. These quantities are known to be related [<xref ref-type="bibr" rid="pcbi.1004622.ref019">19</xref>]; we assume this relationship is simple—a ‘dopamine response function’ (DRF) based qualitatively on the signal evoked in NAc by VTA stimulation (<xref ref-type="fig" rid="pcbi.1004622.g002">Fig 2</xref>). We model the DRF using an alpha function
<disp-formula id="pcbi.1004622.e004"><alternatives><graphic id="pcbi.1004622.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e004" xlink:type="simple"/><mml:math display="block" id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>t</mml:mi> <mml:mi>ξ</mml:mi></mml:mfrac> <mml:msup><mml:mi>e</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mi>t</mml:mi> <mml:mi>ξ</mml:mi></mml:mfrac></mml:mrow></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula>
with time constant <italic>ξ</italic> = 0.7s set to match experimental observations [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>]. In other words, dopaminergic activity at time <italic>t</italic>, which we tendentiously denote <inline-formula id="pcbi.1004622.e005"><alternatives><graphic id="pcbi.1004622.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:msubsup><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mi>p</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>— a phasic TD error —causes an increase in dopamine concentration that peaks after a delay of <italic>ξ</italic> seconds and then decays with time constant <italic>ξ</italic>. Thus, changes in dopamine concentration levels relative to baseline, Δ[DA], are acquired by convolving time-varying activity <inline-formula id="pcbi.1004622.e006"><alternatives><graphic id="pcbi.1004622.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:msubsup><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mi>p</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> with the DRF described in <xref ref-type="disp-formula" rid="pcbi.1004622.e004">Eq (4)</xref>:
<disp-formula id="pcbi.1004622.e007"><alternatives><graphic id="pcbi.1004622.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e007" xlink:type="simple"/><mml:math display="block" id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>Δ</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:mtext>DA</mml:mtext> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:msup><mml:mi>δ</mml:mi> <mml:mi>p</mml:mi></mml:msup> <mml:mo>*</mml:mo> <mml:mi>f</mml:mi> <mml:mo>≡</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>∞</mml:mi></mml:mrow> <mml:mrow><mml:mo>+</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msubsup> <mml:mi>d</mml:mi> <mml:mi>s</mml:mi> <mml:msup><mml:mi>δ</mml:mi> <mml:mi>p</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula>
We should note two important caveats to this model. First, there is evidence for richer temporal and non-linear structure in the DRF [<xref ref-type="bibr" rid="pcbi.1004622.ref020">20</xref>], albeit perhaps most affecting timescales and strengths of responding that are different from those considered here. Of more immediate note is that while there is evidence that fluctuations in dopamine concentration within NAc symmetrically encode positive and negative prediction errors [<xref ref-type="bibr" rid="pcbi.1004622.ref021">21</xref>], other studies do not show such clear negative deviations from baseline corresponding to a negative prediction error (e.g. [<xref ref-type="bibr" rid="pcbi.1004622.ref022">22</xref>]). Indeed, evidence suggests that negative prediction errors are represented differently from positive prediction errors in the activity of midbrain dopaminergic neurons: while positive prediction errors appear to correlate positively with the firing rates of dopaminergic neurons, the magnitude of negative prediction errors correlates rather with the duration of a <italic>pause</italic> in burst firing [<xref ref-type="bibr" rid="pcbi.1004622.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref024">24</xref>], though this itself generates additional complexities. To incorporate the possibility of an asymmetry in how positive and negative prediction errors affect dopamine concentration, below we also examine the effect on dopamine concentration of first asymmetrically scaling negative prediction errors by a factor of <italic>d</italic> = 1/6 [<xref ref-type="bibr" rid="pcbi.1004622.ref025">25</xref>].</p>
<fig id="pcbi.1004622.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Dopamine response function.</title>
<p>Left: Change in NAc extracellular dopamine concentration evoked by electrical stimulation of VTA (red boxes indicate points at which electrical stimulation began and ended). Adapted from [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>], with permission. Right: alpha function used to model the effect of a punctate, non-zero TD error (red triangle) on dopamine concentration (<xref ref-type="disp-formula" rid="pcbi.1004622.e004">Eq (4)</xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g002" xlink:type="simple"/>
</fig>
<p>The second caveat is that modulation of striatal dopamine concentrations can occur independently of changes in the observed firing rates of dopaminergic cells. Thus, tonic levels of striatal dopamine are thought to be controlled by the number of active dopaminergic cells rather than by the firing rates of a fixed pool of neurons [<xref ref-type="bibr" rid="pcbi.1004622.ref026">26</xref>]. Furthermore, a range of mechanisms local to the striatum are known to play a role in regulating dopamine release, including a host of other neurotransmitters such as glutamate, acetylcholine, and GABA (for recent reviews, see [<xref ref-type="bibr" rid="pcbi.1004622.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref028">28</xref>]).</p>
</sec>
<sec id="sec003">
<title>Actors and critics</title>
<p>In a case more general than that of learning purely to predict, animals may be allowed to select actions to achieve desired outcomes. A mapping from states to actions is usually referred to as a <italic>policy</italic>, denoted <italic>π</italic>, and the more general problem is to find a policy which maximizes some measure of reward. The TD error signal defined in <xref ref-type="disp-formula" rid="pcbi.1004622.e003">Eq (3)</xref> can be used to evaluate state values with respect to a given policy, <italic>V</italic><sup><italic>π</italic></sup>(<italic>s</italic>). Given this value function, the agent can potentially improve on its current policy by selecting actions that lead to successor states of higher value. Iteration between successive steps of policy evaluation and policy improvement characterises the <italic>policy iteration</italic> algorithm [<xref ref-type="bibr" rid="pcbi.1004622.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref030">30</xref>] which is a cornerstone of RL methods [<xref ref-type="bibr" rid="pcbi.1004622.ref004">4</xref>].</p>
<p>The <italic>actor-critic</italic> algorithm [<xref ref-type="bibr" rid="pcbi.1004622.ref031">31</xref>], an asynchronous version of policy iteration, is just one of a number of TD-based suggestions for RL [<xref ref-type="bibr" rid="pcbi.1004622.ref004">4</xref>]. However, it has played a particularly salient role in neural RL modelling [<xref ref-type="bibr" rid="pcbi.1004622.ref016">16</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref034">34</xref>]. In the actor-critic architecture, state values and policy are explicitly represented in different memory structures. The policy structure is known as the <italic>actor</italic>, since it is responsible for selecting actions; and the value structure is known as the <italic>critic</italic>, since it criticizes actions taken by the actor, where this critique takes the form of the TD error described above.</p>
<p>In terms of neural substrate, it has been suggested that the dual learning functions of the actor-critic map to a fundamental division in the functional anatomy of striatum into dorsal and ventral subregions [<xref ref-type="bibr" rid="pcbi.1004622.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref036">36</xref>]. In particular, the ventral striatum (NAc) is implicated in reward and motivation [<xref ref-type="bibr" rid="pcbi.1004622.ref037">37</xref>], while the dorsal striatum is implicated in motor and cognitive control [<xref ref-type="bibr" rid="pcbi.1004622.ref038">38</xref>]. This dissociation is consistent with an implementation of actor and critic components in the dorsal and ventral striatum, respectively [<xref ref-type="bibr" rid="pcbi.1004622.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref036">36</xref>].</p>
</sec>
<sec id="sec004">
<title>Tonic dopamine and vigour</title>
<p>Initial theorizing in neural RL focused on tasks involving a simple action or choice between different discrete actions in response to an explicit experimental cue. More recent modelling work has sought to extend standard RL models to other dimensions of choice, thereby making contact with the large experimental literature on free operant tasks in which subjects not only choose between different actions but also when and how quickly to act [<xref ref-type="bibr" rid="pcbi.1004622.ref039">39</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref041">41</xref>].</p>
<p>Two key differences from previous work have been involved in the first collection of models of free operant tasks. Firstly, the agent not only chooses an action <italic>a</italic> to perform, but also an associated latency <italic>τ</italic> with which to perform it. Formally, this entails moving from the usual discrete Markov decision process (MDP) model, in which agent-environment interactions progress at fixed time intervals, to a <italic>semi-Markov decision process</italic> (SMDP) [<xref ref-type="bibr" rid="pcbi.1004622.ref042">42</xref>], which permits the time spent in a particular state to follow an arbitrary probability distribution. Secondly, rather than assuming that the agent aims—at least approximately—to maximize an expected sum of discounted future rewards, models have assumed an average reward criterion. In this case, the aim is to find a policy that maximizes the long-run average reward rate
<disp-formula id="pcbi.1004622.e008"><alternatives><graphic id="pcbi.1004622.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e008" xlink:type="simple"/><mml:math display="block" id="M8"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>ρ</mml:mi> <mml:mi>π</mml:mi></mml:msup> <mml:mo>≡</mml:mo> <mml:munder><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:munder> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>π</mml:mi></mml:msub> <mml:mfenced close="
x007D;" open="
x007B;" separators=""><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>n</mml:mi></mml:mfrac> <mml:mspace width="2pt"/><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mi>n</mml:mi></mml:munderover> <mml:mspace width="1pt"/><mml:msub><mml:mi>r</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
which is independent of starting state, assuming ergodicity. The value of a state under policy <italic>π</italic> is now defined relative to the long-run average reward under that policy, <italic>ρ</italic><sup><italic>π</italic></sup>, and can be denoted <inline-formula id="pcbi.1004622.e009"><alternatives><graphic id="pcbi.1004622.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> to highlight that this is a <italic>relative</italic> value [<xref ref-type="bibr" rid="pcbi.1004622.ref004">4</xref>]:
<disp-formula id="pcbi.1004622.e010"><alternatives><graphic id="pcbi.1004622.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e010" xlink:type="simple"/><mml:math display="block" id="M10"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>π</mml:mi></mml:msub> <mml:mfenced close="
x007D;" open="
x007B;" separators=""><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mi>∞</mml:mi></mml:munderover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mi>π</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
Similarly, the relative action value <inline-formula id="pcbi.1004622.e011"><alternatives><graphic id="pcbi.1004622.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>Q</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> of taking action <italic>a</italic> in state <italic>s</italic> is defined as
<disp-formula id="pcbi.1004622.e012"><alternatives><graphic id="pcbi.1004622.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>Q</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>a</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="double-struck">E</mml:mi> <mml:mi>π</mml:mi></mml:msub> <mml:mfenced close="
x007D;" open="
x007B;" separators=""><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mi>∞</mml:mi></mml:munderover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>k</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mi>π</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:msub><mml:mi>a</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mi>a</mml:mi></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula>
For example, consider the case in which there is just a single action—a lever press—to perform, and the decision concerns the latency <italic>τ</italic> with which to perform it. For consistency with earlier results, we temporarily consider the case of continuous time. Assume that <italic>τ</italic> is selected, following presentation of an explicit cue, in an initial state ‘1’. After the selected time <italic>τ</italic>, there is a transition to a second state ‘2’ in which the lever press completes and reward is delivered. Subsequent transition back to state 1 follows immediately, and the process begins anew (<xref ref-type="fig" rid="pcbi.1004622.g003">Fig 3A</xref>). Niv et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref039">39</xref>] considered a hyperbolic cost structure in which a lever press of latency <italic>τ</italic> is more costly depending on its speed. In particular, they adopted the function form for the cost: <italic>a</italic>/<italic>τ</italic> + <italic>b</italic>, where <italic>b</italic> ≤ 0 is a unit cost for the press, and <italic>a</italic> ≤ 0 is a factor which determines the magnitude of hyperbolic dependence on <italic>τ</italic>. Each lever press is assumed to yield an immediate reward of utility <italic>r</italic> &gt; 0. As shown by Niv et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref039">39</xref>], the theory of average reward RL tells us to select the optimal lever-press latency <italic>τ</italic>* in state 1 that maximizes the optimal relative Q-value,
<disp-formula id="pcbi.1004622.e013"><alternatives><graphic id="pcbi.1004622.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e013" xlink:type="simple"/><mml:math display="block" id="M13"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>τ</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:msub><mml:mtext>argmax</mml:mtext> <mml:mi>τ</mml:mi></mml:msub> <mml:mfenced close="
x007D;" open="
x007B;" separators=""><mml:msup><mml:mover accent="true"><mml:mi>Q</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mo>=</mml:mo> <mml:msub><mml:mtext>argmax</mml:mtext> <mml:mi>τ</mml:mi></mml:msub> <mml:mfenced close="
x007D;" open="
x007B;" separators=""><mml:mfrac><mml:mi>a</mml:mi> <mml:mi>τ</mml:mi></mml:mfrac> <mml:mo>+</mml:mo> <mml:mi>b</mml:mi> <mml:mo>+</mml:mo> <mml:mi>r</mml:mi> <mml:mo>-</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mi>τ</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula>
where asterisks are used to indicate values corresponding to an optimal policy. As noted in [<xref ref-type="bibr" rid="pcbi.1004622.ref039">39</xref>], the optimal latency here is controlled by the opposing forces of the (negative) utility of acting quickly, <italic>a</italic>/<italic>τ</italic>, and the opportunity of cost of acting slowly, −<italic>ρ</italic>*<italic>τ</italic>. This latter term arises from <xref ref-type="disp-formula" rid="pcbi.1004622.e012">Eq (8)</xref> since <italic>ρ</italic>* (which is <italic>ρ</italic><sup><italic>π</italic></sup> when executing the optimal policy) is accumulated over all the timesteps comprising latency <italic>τ</italic>. Indeed we have
<disp-formula id="pcbi.1004622.e014"><alternatives><graphic id="pcbi.1004622.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e014" xlink:type="simple"/><mml:math display="block" id="M14"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>τ</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:msqrt><mml:mfrac><mml:mrow><mml:mo>-</mml:mo> <mml:mi>a</mml:mi></mml:mrow> <mml:msup><mml:mi>ρ</mml:mi> <mml:mo>*</mml:mo></mml:msup></mml:mfrac></mml:msqrt> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
which shows that the optimal latency decreases as the average utility rate <italic>ρ</italic>* increases. Since <italic>ρ</italic>* also depends on <italic>τ</italic>*, the problem is recursive, but techniques for finding the optimal solution exist [<xref ref-type="bibr" rid="pcbi.1004622.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref043">43</xref>].</p>
<fig id="pcbi.1004622.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Two conceptions of a cued lever press.</title>
<p>(A) A latency <italic>τ</italic> with which to press the lever is selected in an initial cued state (‘1’), leading to completion of the press <italic>τ</italic> seconds later (‘2’). (B) A latency <italic>τ</italic> with which to press the lever is selected in an initial cued state (‘1’), leading to a state of preparedness to press <italic>τ</italic> seconds later (‘2’). Completion of the press (‘3’) occurs only after a subsequent interval <italic>τ</italic><sub><italic>post</italic></sub>. After a further inter-trial interval <italic>τ</italic><sub><italic>I</italic></sub>, the process begins anew.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g003" xlink:type="simple"/>
</fig>
<p>The connection to current concerns is the proposal that the tonic level of dopamine, especially in NAc, represents the long-run average rate of reward <italic>ρ</italic><sup><italic>π</italic></sup>, effectively signalling an opportunity cost of sloth [<xref ref-type="bibr" rid="pcbi.1004622.ref039">39</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref044">44</xref>]. This suggestion is based on a long literature implicating dopamine in the modulation of behavioural vigour [<xref ref-type="bibr" rid="pcbi.1004622.ref045">45</xref>]. It has been further supported by recent human studies [<xref ref-type="bibr" rid="pcbi.1004622.ref046">46</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref047">47</xref>], albeit assuming that this long-run average rate arises as a slowly-changing running estimate. The equivalent of the dopamine response function for this signal is unexplored. Dayan [<xref ref-type="bibr" rid="pcbi.1004622.ref041">41</xref>] has recently broadened the theoretical study of instrumental vigour to include the case of acting to avoid punishment.</p>
</sec>
<sec id="sec005">
<title>Ramping dopamine concentrations</title>
<p>A first example of the phenomena of interest comes from an experiment by Roitman et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>] very similar in structure to the lever pressing case considered above. Following presentation of an explicit cue, a rat could press a lever at a time of its own choosing to receive a sucrose reward (<xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4A</xref>). Cue presentation evoked an increase in dopamine concentration in NAc (<xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4B</xref>, upper trace), but not in control animals for which a lever press did not yield reward (<xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4B</xref>, lower trace). The apparent decrease in signal in the latter case was found not to be caused by a change in dopamine concentration [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>]. However, Roitman et al. also observed that, when aligned to the time of lever pressing, average dopamine concentration began to increase a short time before the time of the lever press itself, reaching peak concentration around the time of pressing (<xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4C and 4D</xref>). Crucially, this occurred not only on the majority of the trials (83%) in which animals pressed the lever at relatively short latencies following the initial cue (&lt;5 s; <xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4C</xref>), but also on the smaller number of trials in which animals responded at longer latencies (&gt;5 s; <xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4D</xref>). Similar increases in extracellular dopamine just prior to response have been reported in other FSCV studies [<xref ref-type="bibr" rid="pcbi.1004622.ref008">8</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref011">11</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref013">13</xref>]. Roitman et al. also reported that while cue-aligned and press-aligned peak dopamine concentrations were indistinguishable for short-latency trials (68±19 nM vs. 73±23 nM), press-aligned peak dopamine was significantly larger than cue-aligned peak dopamine on long-latency trials (54±17 nM vs. 110±20 nM; <xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4D</xref>, inset).</p>
<fig id="pcbi.1004622.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Roitman et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>] reported increases in average NAc dopamine concentration that occur shortly before completion of a lever press for reward.</title>
<p>(A) Task: rats press a lever at a time of their own choosing for reward (intra-oral sucrose) following a cue indicating that reward is available. (B) Cue presentation (black triangle) evokes a phasic increase in dopamine concentration (mean + SEM) if the cue indicates that reward is available (upper trace), but not when there is no such cue-reward pairing (lower trace); the decrease in signal in the latter case is not caused by dopamine [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>]. (C;D) When aligned to time of lever press (vertical dashed line), dopamine concentration is observed to peak at the time of the press, beginning to increase shortly before this time. This is observed both for (C) short-latency trials, where presses are emitted shortly after presentation of the cue (&lt;5 s; average time of presentation indicated by black triangle, range represented by horizontal scale bar) and (D) long-latency trials, where there is a longer delay between cue and response (&gt;5 s). On long-latency trials, average peak dopamine concentration is higher around time of response than around time of cue (D, inset). A lever press leads to both sucrose infusion (black bar) and presentation of a tone-light stimulus (open bar). Figures B–D adapted from [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>], with permission.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g004" xlink:type="simple"/>
</fig>
<p>A second, perhaps more dramatic, example of dopamine ramping has recently been reported by Howe et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>] (<xref ref-type="fig" rid="pcbi.1004622.g005">Fig 5</xref>). In this study, dopamine concentrations in the striatum were measured using FSCV while rats navigated mazes to obtain remote rewards. It found a gradual increase in dopamine concentration that began at trial onset and ended after reaching the goal (<xref ref-type="fig" rid="pcbi.1004622.g005">Fig 5A</xref>). Whether rats took a relatively short or long time to reach the goal, dopamine peaked at similar concentrations at the goal (<xref ref-type="fig" rid="pcbi.1004622.g005">Fig 5B</xref>, upper). Similarly, dopamine peaked at comparable concentrations at the goal for mazes of different length (<xref ref-type="fig" rid="pcbi.1004622.g005">Fig 5B</xref>, lower). Single-trial examples in which rats paused mid-run showed a remarkable correspondence between proximity to the goal and dopamine concentration (<xref ref-type="fig" rid="pcbi.1004622.g005">Fig 5C</xref>). Furthermore, dopamine ramps scaled with size of reward, so that peak dopamine was higher for larger than smaller rewards (see [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>], figure 3).</p>
<fig id="pcbi.1004622.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Howe et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>] reported gradual increases in striatal dopamine concentration as rats approach reward in a maze.</title>
<p>(A) Following an initial warning click, a position-triggered tone indicates to rats which arm of the maze to visit in order to receive reward (upper). Changes in current (middle) and dopamine concentration (lower) measured by FSCV in ventromedial striatum during a single T-maze trial. (B) Average dopamine concentration (±SEM) reaches similar peak values on short vs. long trials for the same maze (upper) and for mazes of different length (lower). (C) Single-trial example showing a close correspondence between the rat’s proximity to the goal (upper) and striatal dopamine concentration (lower). All figures adapted from [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>], with permission.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g005" xlink:type="simple"/>
</fig>
<p>While we take both of these examples to be instances of dopamine ramping, their explanations may not be identical. Nevertheless, neither case seems to fit neatly with standard RL models because apparently reliable activity is not predicted away by earlier reliable cues.</p>
</sec>
</sec>
<sec id="sec006">
<title>Models and Results</title>
<p>We consider three possible, non-mutually exclusive, explanations of NAc dopamine ramps. First, we consider possible sources of predictive uncertainty arising within the actor-critic about when actions will be performed. We show that a TD account in which a prediction error is generated when such uncertainty is resolved just before the action itself may explain pre-response increases in dopamine such as those observed by Roitman et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>]. Second, we consider a more direct role for dopamine in decision-making, specifically in setting the gain of a diffusion-to-bound process of value integration. We show that both tonic and phasic fluctuations in dopamine concentration produce what look like average ramping signals in dopamine leading up to the time of decision. Third, we consider the possibility that the prolonged ramping signals observed by Howe et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>] may reflect an average reward-like signal that arises within the discounted reward framework. We show that the quasi-tonic signal suggested by our analysis has just the right properties to explain the ramping phenomena observed in [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>].</p>
<sec id="sec007">
<title>When will I act? Uncertainty about action timing within the actor-critic</title>
<p>Whether an animal faces a task in which it is free to respond as often and as quickly as it likes, or is limited to a single response within an interval following a cue, it typically has at least some freedom to choose its time of response. In the case of Roitman et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>] described above (<xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4A</xref>), rats were free to lever press at a time of their own choosing following a cue marking the start of a new trial. As reported in a number of similar studies, ramp-like increases in NAc dopamine concentration which preceded the time of lever-pressing were observed (<xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4C and 4D</xref>).</p>
<p>From a conventional TD perspective, phasic dopaminergic activity reflects a prediction error. Such errors can be occasioned by changes in latent states associated with the subject’s internal execution of the task, provided that there is some uncertainty associated with these changes. Such uncertainty can be generated by two forms of ignorance: what the critic fails to know about the actor’s choice of when to act, and what both actor and critic fail to know about the passage of time [<xref ref-type="bibr" rid="pcbi.1004622.ref048">48</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref049">49</xref>].</p>
<p>Consider first the critic’s knowledge about the temporal decisions of the actor (<xref ref-type="fig" rid="pcbi.1004622.g006">Fig 6</xref>). We assume, reminiscent of studies by Libet and colleagues [<xref ref-type="bibr" rid="pcbi.1004622.ref050">50</xref>], and consistent with both patterns of cortico-striatal connectivity [<xref ref-type="bibr" rid="pcbi.1004622.ref051">51</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref053">53</xref>] and observed patterns of discharge [<xref ref-type="bibr" rid="pcbi.1004622.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref055">55</xref>], that internal information proximal to the action, such as some form of motor preparation, is communicated to the critic via efference copy just before it is evident to the experimenter (<italic>a</italic>′′ in <xref ref-type="fig" rid="pcbi.1004622.g006">Fig 6</xref>). This resolves any uncertainty the critic may have about the time of the impending action. The question is what happens at the time that the actor makes its decision about the latency of lever pressing following the initial cue. There are two natural possibilities. One is that the actor <italic>also</italic> intimates its decision about when to act directly to the critic at that time, e.g., via a more indirect form of efference copy (<italic>a</italic>′ in <xref ref-type="fig" rid="pcbi.1004622.g006">Fig 6</xref>) which could be transmitted via interacting cortico-striatal loops or some more direct means [<xref ref-type="bibr" rid="pcbi.1004622.ref056">56</xref>]. This would then influence the critic’s predictions about future events. The other is that the critic has no such privileged access to the actor’s initial decision, implying that its predictions could be based only on its experience of downstream signals resulting from the actor’s choices.</p>
<fig id="pcbi.1004622.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Possible signals received by the critic about action timing.</title>
<p>We assume that the actor selects an action <italic>a</italic> (e.g., a latency to lever press) and communicates this choice to downstream pre-motor/motor areas for implementation. We also assume that the critic receives an ‘indirect’ signal <italic>a</italic>′′ via efference copy from downstream areas just prior to performance of the action itself. This latter signal resolves any uncertainty the critic may have about the time of action. The critic may also receive a ‘direct’ signal <italic>a</italic>′ from the actor which carries information about the selected action, and which is received immediately after the actor makes its decision.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g006" xlink:type="simple"/>
</fig>
<p>A second, related issue concerns the realization of timing. If the actor communicates its choice to the critic and the two share the same clock, then there seems to be little room for timing uncertainty to affect the critic’s predictions: regardless of whether the clock is fast, slow, or variable, actor and critic will be in synchrony. On the other hand, if the actor does not specify an exact time of action, or its decisions are subject to additional sources of what the critic will experience as uncontrolled variability (for instance if actor and critic employ different clocks), timing uncertainty may play a role in the critic’s predictions and resulting prediction errors [<xref ref-type="bibr" rid="pcbi.1004622.ref048">48</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref049">49</xref>].</p>
<p>To explore these issues, we consider the same lever-pressing task described previously (<xref ref-type="fig" rid="pcbi.1004622.g003">Fig 3A</xref>), though with a state space that is augmented to reflect the assumption that the critic may receive internal information about the lever press just before it occurs (<xref ref-type="fig" rid="pcbi.1004622.g003">Fig 3B</xref>). As before, an initial cue (‘1’) is observed, prompting selection of a latency <italic>τ</italic> with which to press the lever. After the selected duration <italic>τ</italic>, which may or may not be known by the critic, the animal transitions to a state of preparedness to press, assumed to be communicated to the critic via efference copy (‘2’; this corresponds to the time at which the critic receives signal <italic>a</italic>′′ in <xref ref-type="fig" rid="pcbi.1004622.g006">Fig 6</xref>). Note that this latter state is distinct from that corresponding to consummation of the lever press itself (‘3’) which is assumed to occur only after a further interval <italic>τ</italic><sub><italic>post</italic></sub>. We set <italic>τ</italic><sub><italic>post</italic></sub> = 500 ms to correspond roughly with the time with which the so-called ‘readiness potential’ is detected prior to self-initiated action [<xref ref-type="bibr" rid="pcbi.1004622.ref057">57</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref058">58</xref>]. A reward of utility <italic>r</italic> = 1 is delivered on press completion. Completion of the lever press and reward delivery is followed by a fixed inter-trial interval <italic>τ</italic><sub><italic>I</italic></sub> = 30 s, after which the process begins anew.</p>
<sec id="sec008">
<title>Actor</title>
<p>The role of the actor in this scenario is simply to make repeated choices about the latency to lever press. For convenience, we assume that this choice is always made immediately after presentation of the cue. What matters for present purposes is that either through stochastic selection or stochastic execution, there will be a distribution of times that it takes for proximal news of the action to be reported to the critic via efference copy (i.e. the time at which <italic>a</italic>′′ in <xref ref-type="fig" rid="pcbi.1004622.g006">Fig 6</xref> is transmitted to the critic). We therefore treat this efference copy time as a random variable <italic>T</italic> which, for convenience, we assume to follow a gamma distribution
<disp-formula id="pcbi.1004622.e015"><alternatives><graphic id="pcbi.1004622.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>,</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
where <italic>k</italic> and <italic>θ</italic> denote shape and scale parameters, respectively.</p>
<p>The source of randomness in <italic>T</italic> interacts with the source of the critic’s information about the lever press. At one extreme of stochastic execution, the latency <italic>τ</italic> could be fixed and variability in <italic>T</italic> is generated by factors not under the actor’s control. We assume the other extreme, in which the distributions of <italic>τ</italic> and <italic>T</italic> are identical, reflecting perfect implementation of the actor’s stochastic choice.</p>
</sec>
<sec id="sec009">
<title>Critic</title>
<p>The role of the critic is to learn the relative state values corresponding to the actor’s policy. In the case where the critic only receives indirect information about the actor’s choices, the critic will nevertheless have expectations about <italic>T</italic> based on past experience. Such expectations can be summarized in the form of a ‘prior’ distribution <italic>P</italic>(<italic>T</italic>). If the critic additionally receives direct information about the actor’s choice, the critic can update its beliefs about when engagement will occur based on this information. In the latter case, the critic’s expectations can be summarized as a posterior distribution <italic>P</italic>(<italic>T</italic>|<italic>τ</italic>).</p>
<p>In either case, how the critic’s beliefs evolve will depend on the passage of time according to the critic’s clock. We denote by <inline-formula id="pcbi.1004622.e016"><alternatives><graphic id="pcbi.1004622.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> the critic’s perceived time since the initial cue is presented. Within state 1, it will then be assumed that the critic estimates the relative values of ‘microstates’ <inline-formula id="pcbi.1004622.e017"><alternatives><graphic id="pcbi.1004622.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Whether or not the critic receives direct information about the actor’s choice, at time <inline-formula id="pcbi.1004622.e018"><alternatives><graphic id="pcbi.1004622.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> there are only two possibilities for the immediate future: either the critic receives notice (<italic>a</italic>′′) that the lever press is imminent, <inline-formula id="pcbi.1004622.e019"><alternatives><graphic id="pcbi.1004622.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>≤</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, or it doesn’t, <inline-formula id="pcbi.1004622.e020"><alternatives><graphic id="pcbi.1004622.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1004622.e021"><alternatives><graphic id="pcbi.1004622.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> denotes some short slice of critic time. The probabilities of these events are conditional on <inline-formula id="pcbi.1004622.e022"><alternatives><graphic id="pcbi.1004622.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula>, since it is assumed that the critic has not yet received any such signal. The conditional probability of the critic receiving notice of an imminent press in the immediate future <inline-formula id="pcbi.1004622.e023"><alternatives><graphic id="pcbi.1004622.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>≤</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is closely related to the <italic>hazard function</italic>. Two general cases are of particular interest and are explored below: <inline-formula id="pcbi.1004622.e024"><alternatives><graphic id="pcbi.1004622.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, in which case the hazard function is constant (i.e. the conditional probability of engagement at any time <inline-formula id="pcbi.1004622.e025"><alternatives><graphic id="pcbi.1004622.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> following the cue is the same), and all other cases—we focus on a <inline-formula id="pcbi.1004622.e026"><alternatives><graphic id="pcbi.1004622.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mrow><mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> distribution for convenience—where the hazard function changes over time (<xref ref-type="fig" rid="pcbi.1004622.g007">Fig 7</xref>).</p>
<fig id="pcbi.1004622.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Constant and variable hazard functions.</title>
<p>(A) Two different gamma densities of the time <italic>T</italic> at which the critic receives notification of an impending lever press. (B) Corresponding hazard functions <inline-formula id="pcbi.1004622.e027"><alternatives><graphic id="pcbi.1004622.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mrow><mml:mi>h</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mo form="prefix" movablelimits="true">lim</mml:mo> <mml:mrow><mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>→</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:msub> <mml:mrow><mml:mo>{</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>≤</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mspace width="4pt"/><mml:mo>|</mml:mo> <mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mspace width="4pt"/><mml:mo>)</mml:mo></mml:mrow> <mml:mo>/</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Note that the hazard function is constant in the <inline-formula id="pcbi.1004622.e028"><alternatives><graphic id="pcbi.1004622.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> case, but increases with time in the <inline-formula id="pcbi.1004622.e029"><alternatives><graphic id="pcbi.1004622.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mrow><mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> case.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g007" xlink:type="simple"/>
</fig>
<p>From these considerations, it is straightforward to write down expressions for the relative values of states <inline-formula id="pcbi.1004622.e030"><alternatives><graphic id="pcbi.1004622.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:mrow><mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. In the case where the critic only receives information about choice indirectly, these values satisfy
<disp-formula id="pcbi.1004622.e031"><alternatives><graphic id="pcbi.1004622.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo stretchy="false">|</mml:mo> <mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mo>+</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>≤</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo stretchy="false">|</mml:mo> <mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mi>π</mml:mi></mml:msup> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
which is a probability-weighted average of the relative values of remaining in state 1 and transitioning to state 2. The case in which the actor directly communicates information about its choice (<italic>a</italic>′) is slightly different due to the possibility of timing uncertainty. Based on the interval-timing literature [<xref ref-type="bibr" rid="pcbi.1004622.ref059">59</xref>], we assume that the uncertainty about <italic>T</italic> increases with choices of longer latency. For convenience, we consider this conditional distribution to be Gaussian with a standard deviation that scales with <italic>τ</italic>:
<disp-formula id="pcbi.1004622.e032"><alternatives><graphic id="pcbi.1004622.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>P</mml:mi> <mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo stretchy="false">|</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>;</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>,</mml:mo> <mml:mi>σ</mml:mi> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
where <italic>k</italic> is the scaling constant. The expression for relative values is identical in form to <xref ref-type="disp-formula" rid="pcbi.1004622.e031">Eq (12)</xref>, but these now depend on <italic>τ</italic>:
<disp-formula id="pcbi.1004622.e033"><alternatives><graphic id="pcbi.1004622.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo stretchy="false">|</mml:mo> <mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mo>+</mml:mo> <mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>≤</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo stretchy="false">|</mml:mo> <mml:mi>T</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mi>π</mml:mi></mml:msup> <mml:mo>Δ</mml:mo> <mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
In this case, we additionally consider that there is likely some delay between cue onset and the time at which the critic receives information about the actor’s choice. Assuming that the actor makes its decision immediately at cue onset (<italic>t</italic> = 0) and denoting by <italic>ϵ</italic> the delay in intimating this decision to the critic, the relative value of the initial state of ignorance is
<disp-formula id="pcbi.1004622.e034"><alternatives><graphic id="pcbi.1004622.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>0</mml:mn> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mi>π</mml:mi></mml:msup> <mml:mi>ϵ</mml:mi> <mml:mo>+</mml:mo> <mml:msub><mml:mo>∫</mml:mo> <mml:mi>τ</mml:mi></mml:msub> <mml:mi>d</mml:mi> <mml:mi>τ</mml:mi> <mml:mspace width="4pt"/><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>ϵ</mml:mi> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula>
Whether or not the actor directly reports its choice to the critic, the relative values of states 2 and 3 are straightforward since it is assumed that subsequent state transitions are independent of choice, and their occupation times (<italic>τ</italic><sub><italic>post</italic></sub>, <italic>τ</italic><sub><italic>I</italic></sub>) deterministic. A more general version of the model would also include uncertainty regarding occupation times <italic>τ</italic><sub><italic>post</italic></sub> and <italic>τ</italic><sub><italic>I</italic></sub> but we ignore this here since our main focus of interest is on the events occurring between cue and lever press.</p>
</sec>
<sec id="sec010">
<title>TD errors and dopamine concentration</title>
<p>Given the critic’s relative state values, we are particularly interested in TD errors and their dopaminergic instantiation. Note that TD errors are inevitable in all cases we consider, either due to the random nature of <italic>T</italic> in the case of indirect communication, or due to timing uncertainty in the case where there is additional direct communication of <italic>τ</italic>. Under the conventional average reward formulation described above, TD errors take the form [<xref ref-type="bibr" rid="pcbi.1004622.ref060">60</xref>]:
<disp-formula id="pcbi.1004622.e035"><alternatives><graphic id="pcbi.1004622.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e035" xlink:type="simple"/><mml:math display="block" id="M35"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:msub><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mi>π</mml:mi></mml:msup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msubsup><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mi>p</mml:mi></mml:msubsup> <mml:mo>-</mml:mo> <mml:msup><mml:mi>ρ</mml:mi> <mml:mi>π</mml:mi></mml:msup> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
where <inline-formula id="pcbi.1004622.e036"><alternatives><graphic id="pcbi.1004622.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:msubsup><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mi>p</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is assumed to constitute the phasic component of the error signal reflected in phasic dopaminergic activity, and average reward rate <italic>ρ</italic><sup><italic>π</italic></sup> is assumed to be reflected in a constant, tonic level of dopamine. For the moment, we ignore the tonic component of the error term, <italic>ρ</italic><sup><italic>π</italic></sup>, and only report signals arising from the varying phasic signal <inline-formula id="pcbi.1004622.e037"><alternatives><graphic id="pcbi.1004622.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msubsup><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mi>p</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. Changes in dopamine concentration Δ[DA] are therefore modelled by convolving <inline-formula id="pcbi.1004622.e038"><alternatives><graphic id="pcbi.1004622.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:msubsup><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mi>p</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>—either symmetrically or asymmetrically scaled—with the DRF, as per <xref ref-type="disp-formula" rid="pcbi.1004622.e004">Eq (4)</xref>.</p>
</sec>
</sec>
<sec id="sec011">
<title>Uncertainty resolution, TD errors, and the pre-response dopamine signal</title>
<p>Given the models described in the previous section, we consider results from three different cases: two in which the critic only receives information about the lever press indirectly, and one in which the critic additionally receives direct information from the actor. In each case, we consider the effect of the critic receiving notice of impending action at different times—<italic>T</italic> = {1, 3, 10} seconds—on the TD error <inline-formula id="pcbi.1004622.e039"><alternatives><graphic id="pcbi.1004622.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e039" xlink:type="simple"/><mml:math display="inline" id="M39"><mml:msubsup><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mi>p</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>, and evaluate the resulting change in dopamine concentration Δ[DA] under both symmetric and asymmetric encoding assumptions. Results for all the cases are summarized together in <xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8</xref>.</p>
<fig id="pcbi.1004622.g008" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g008</object-id>
<label>Fig 8</label>
<caption>
<title>Pattern of prediction errors depends on the nature of communication between actor and critic.</title>
<p>In each case (A–C), we consider signals for three particular times of <italic>T</italic> at which the critic receives notice of the impending lever press: 1 s (blue), 3 s (red), and 10 s (green). Parts of the signal where there is overlap between two or more different times of <italic>T</italic> are plotted in black. In each case, we plot TD errors (top), TD errors convolved with symmetric kernel (middle), and TD errors convolved with ‘asymmetric’ kernel (bottom). (A) Indirect communication (<italic>a</italic>′′) only, <inline-formula id="pcbi.1004622.e040"><alternatives><graphic id="pcbi.1004622.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. (B) Indirect communication (<italic>a</italic>′′) only, <inline-formula id="pcbi.1004622.e041"><alternatives><graphic id="pcbi.1004622.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. (C) Both direct and indirect communication (<italic>a</italic>′; <italic>a</italic>′′), <inline-formula id="pcbi.1004622.e042"><alternatives><graphic id="pcbi.1004622.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, with timing uncertainty (uncertainty scaling constant <italic>k</italic> = 0.1). Vertical dashed lines indicate times of observable events, i.e. cue presentation (<italic>t</italic> = 0, black) and lever presses (<italic>t</italic> = <italic>T</italic>+<italic>τ</italic><sub><italic>post</italic></sub>, coloured). Note the difference in <italic>y</italic>-axis scaling between (A;B) and (C). Model parameters: <italic>a</italic> = −1, <italic>b</italic> = 0, <italic>r</italic> = 1, <italic>τ</italic><sub><italic>post</italic></sub> = 0.5 s, <italic>τ</italic><sub><italic>I</italic></sub> = 30 s.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g008" xlink:type="simple"/>
</fig>
<sec id="sec012">
<title>Indirect communication only</title>
<p>We first consider the case in which the critic receives only indirect information about the actor’s choice. As mentioned above, there are two general cases of interest: where the hazard function is constant (i.e. the conditional probability of engagement at any time <inline-formula id="pcbi.1004622.e043"><alternatives><graphic id="pcbi.1004622.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mover accent="true"><mml:mi>t</mml:mi> <mml:mo>^</mml:mo></mml:mover></mml:math></alternatives></inline-formula> following the cue is the same), and where it changes over time.</p>
<p>In the case of a constant hazard function, corresponding to <inline-formula id="pcbi.1004622.e044"><alternatives><graphic id="pcbi.1004622.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:mi>T</mml:mi> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, the size of TD error occurring on transition to the state of preparedness does not vary with latency (<xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8A</xref>, upper). This is precisely because the conditional probability of this transition does not vary over time. Note also that after an initial positive TD error, the error signal remains at a constant negative value between the time of cue presentation and the time at which the critic receives efference copy. This constant negative TD error is again a consequence of the flat hazard function. Hazard-related suppression in the spiking activity of dopamine neurons before the occurrence of variably timed (external) reward-related events has been observed in a number of experimental studies [<xref ref-type="bibr" rid="pcbi.1004622.ref061">61</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref063">63</xref>], consistent with reporting of such a negative TD error. The initial positive TD error in response to the cue reflects a positive average value for each trial. Even though the TD error generated in response to the critic’s receiving notice of impending action is constant, differences are observed as to how dopamine concentrations [DA] change for different latencies (<xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8A</xref>, middle and lower). For example, on short-latency trials, TD errors in response to cue onset and receipt of efference copy can combine to produce a larger peak [DA] signal (<xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8A</xref>, lower).</p>
<p>In the <inline-formula id="pcbi.1004622.e045"><alternatives><graphic id="pcbi.1004622.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e045" xlink:type="simple"/><mml:math display="inline" id="M45"><mml:mrow><mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> case, the hazard rate is not constant. Then, efference-related TD errors decrease with longer latencies (<xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8B</xref>, upper). This is due to the monotonic increase in probability that the lever press will occur with the passage of time—the event is increasingly expected. The decrease in TD error for longer latencies is mirrored in a decrease in the peak [DA] signal (<xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8B</xref>, middle and lower). Interestingly, exactly this pattern of decreasing TD-related activity with time has recently been reported in dopaminergic neurons in response to presentation of a movement trigger signal, where presentation times were randomly drawn from a uniform distribution, while monkeys performed a reaching task [<xref ref-type="bibr" rid="pcbi.1004622.ref063">63</xref>].</p>
</sec>
<sec id="sec013">
<title>Direct and indirect communication</title>
<p>In the case that the critic additionally receives initial information about the actor’s choice of latency, exactly the opposite trend is observed in TD errors occurring just before pressing: they <italic>increase</italic> with latency (<xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8C</xref>, upper). This is due to the assumption that the critic is more uncertain about the time of engagement for longer choices of <italic>τ</italic>. Conversely, TD errors occurring just after the cue, corresponding to the time at which the critic receives initial information about the actor’s choice, <italic>decrease</italic> with <italic>τ</italic>. In particular, choice of a relatively long latency can generate a pronounced negative TD error due to the low relative value of long trials. There is in all cases, however, an initial, brief positive prediction error corresponding to the positive value of the critic’s state of ignorance prior to receiving information about the actor’s choice (c.f. <xref ref-type="disp-formula" rid="pcbi.1004622.e034">Eq (15)</xref>). Again, the pattern in TD errors is mirrored in the resulting [DA] signal, with the decrease in [DA] for a long <italic>τ</italic> being strongly dependent on whether the DRF is assumed to be symmetric or asymmetric (<xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8C</xref>, middle and lower).</p>
<p>It is this case, especially when positive and negative TD errors are differentially scaled (<xref ref-type="fig" rid="pcbi.1004622.g008">Fig 8C</xref>, lower), that seems to offer the best qualitative fit to the results in [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>] that are shown in <xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4</xref>. <xref ref-type="fig" rid="pcbi.1004622.g009">Fig 9</xref> shows simulated average dopamine concentrations, where the averages are aligned to the various key events in a trial (and separated by latency). Not only do we see a similar signal produced by presentation of the cue (<xref ref-type="fig" rid="pcbi.1004622.g009">Fig 9A</xref>), but we see a qualitative match in press-aligned average signal for short- and long- latency trials (<xref ref-type="fig" rid="pcbi.1004622.g009">Fig 9B and 9C</xref>). Thus, on short-latency trials, we see a pronounced ramping which peaks at the time of the press (<xref ref-type="fig" rid="pcbi.1004622.g009">Fig 9B</xref>). Furthermore, we observe no difference in peak signal when aligned to either cue or press events (<xref ref-type="fig" rid="pcbi.1004622.g009">Fig 9B</xref>, inset). On long-latency trials, just as seen in Roitman et al.’s data, ramping is somewhat less pronounced but similarly begins prior to the press and peaks around the time of press completion (<xref ref-type="fig" rid="pcbi.1004622.g009">Fig 9C</xref>). Furthermore, unlike short-latency trials, the peak [DA] signal is significantly larger around the time of the press than at the time of the cue (<xref ref-type="fig" rid="pcbi.1004622.g009">Fig 9C</xref>, inset).</p>
<fig id="pcbi.1004622.g009" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g009</object-id>
<label>Fig 9</label>
<caption>
<title>Simulated cue- and press-aligned changes in dopamine concentration, for comparison with <xref ref-type="fig" rid="pcbi.1004622.g004">Fig 4</xref>.</title>
<p>Simulated average changes (±SEM) in dopamine concentration for the case where the critic receives both direct and indirect communication, asymmetric convolution of TD errors. (A) Cue-aligned, all trials. (B) Press-aligned, short-latency (&lt;5 s) trials. (C) Press-aligned, long-latency (&gt;5 s) trials. Insets show average peak changes (+SEM) in dopamine around the time of cue presentation and time of lever press. Number of simulated trials <italic>N</italic> = 1000, realizations of <italic>T</italic> drawn <inline-formula id="pcbi.1004622.e046"><alternatives><graphic id="pcbi.1004622.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:mi mathvariant="script">G</mml:mi> <mml:mo>(</mml:mo> <mml:mn>2</mml:mn> <mml:mo>,</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Model parameters as before: <italic>a</italic> = −1, <italic>b</italic> = 0, <italic>r</italic> = 1, <italic>k</italic> = 0.1, <italic>τ</italic><sub><italic>post</italic></sub> = 0.5 s, <italic>τ</italic><sub><italic>I</italic></sub> = 30 s.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g009" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec014">
<title>A more direct role for dopamine: Setting the gain of value accumulation</title>
<p>Our first possible account of ramping, the TD account of pre-response signals described above, assigns dopamine a passive role in decision-making: increases in dopamine reflect a latent state transition arising from a decision to act which has already been made. However, experimental evidence suggests that accumbens dopamine could also play a more causal role. For example, Phillips et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref009">9</xref>] found that electrically-evoked dopamine transients in NAc increased the probability that rats would lever press for cocaine immediately afterwards, further commenting that videotaped behavioural records showed that stimulation led to immediate changes in behaviour, notably behavioural sequences up to and including lever approach. Relatedly, Nicola [<xref ref-type="bibr" rid="pcbi.1004622.ref064">64</xref>] found that blocking dopamine signalling in NAc impaired rats’ ability to approach and press a lever for food, but only when animals were likely to have to re-engage with the task by following a novel sequence of actions to approach the lever. Such findings have led to the suggestion that accumbens dopamine is necessary for ‘flexible approach’ [<xref ref-type="bibr" rid="pcbi.1004622.ref064">64</xref>]. In fact, models associating phasic dopamine with a TD error signal have long considered a dual role for dopamine in which indirect effects on behaviour, involving learning, are accompanied by direct ones [<xref ref-type="bibr" rid="pcbi.1004622.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref065">65</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref067">67</xref>]. We next explore a second potential mechanism for ramping signals. In particular, we show that a particular decision-making scheme which couples dopamine directly to the decision process also generates dopamine ramps.</p>
<p>A rich vein of work in psychology and neuroscience revolves around the idea that the brain implements some version of the sequential probability ratio test (SPRT), a sometimes optimal procedure for two-alternative forced-choice decisions under uncertainty [<xref ref-type="bibr" rid="pcbi.1004622.ref068">68</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref069">69</xref>]. While the SPRT and its close associates are usually considered in relation to decision making under state uncertainty, as when there is doubt about whether the overall motion of a random dot field is to the left or right [<xref ref-type="bibr" rid="pcbi.1004622.ref070">70</xref>], such models have also been applied with some success to memory-based [<xref ref-type="bibr" rid="pcbi.1004622.ref071">71</xref>] or value-based [<xref ref-type="bibr" rid="pcbi.1004622.ref072">72</xref>] decisions in which sensory information is absent or unambiguous. We consider the possibility that this arises from accumulation of value information, in which information stored in synapses is read out via spike trains in a temporally extended manner. A prominent realization of the SPRT is the so-called drift-diffusion model (DDM) which we describe in detail below [<xref ref-type="bibr" rid="pcbi.1004622.ref068">68</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref069">69</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref071">71</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref073">73</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref075">75</xref>]. In particular, this can be shown to be a suitable abstraction of a particular sort of neural circuit involving competition between two (or sometimes more) populations of neurons representing the choices [<xref ref-type="bibr" rid="pcbi.1004622.ref073">73</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref076">76</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref077">77</xref>].</p>
<p>One of the earliest computational suggestions for the role of dopamine and other catecholamines was that by influencing the excitability of neurons [<xref ref-type="bibr" rid="pcbi.1004622.ref078">78</xref>], they could influence gain control in such circuits, and thereby influence the course of decision-making [<xref ref-type="bibr" rid="pcbi.1004622.ref079">79</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref080">80</xref>]. Such models were originally conceived of in terms of cortical decision-making circuits; however, for instance, Frank’s [<xref ref-type="bibr" rid="pcbi.1004622.ref081">81</xref>] neural network model of the basal ganglia assumes that dopamine controls the relative excitability of direct (‘Go’) and indirect (‘Nogo’) pathways via different dopamine receptor subtypes, thereby influencing both the propensity and latency to act. Specifically, higher levels of dopamine shift the balance of activity in favour of the ‘Go’ pathway, leading to a greater propensity to act and faster reaction times. Dopaminergic modulation of excitability in this model can also be interpreted in terms of gain-setting [<xref ref-type="bibr" rid="pcbi.1004622.ref081">81</xref>].</p>
<p>Here we bring together these two ideas—of an accumulative decision-making process and dopaminergic gain control—to explore how a more direct coupling between dopamine and decision-making may explain ramping dopamine signals in striatum.</p>
<sec id="sec015">
<title>Decision-making process</title>
<p>In the DDM, (differential) evidence <italic>x</italic>(<italic>t</italic>) is accumulated according to
<disp-formula id="pcbi.1004622.e047"><alternatives><graphic id="pcbi.1004622.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e047" xlink:type="simple"/><mml:math display="block" id="M47"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>d</mml:mi> <mml:mi>x</mml:mi> <mml:mo>=</mml:mo> <mml:mi>A</mml:mi> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>c</mml:mi> <mml:mi>d</mml:mi> <mml:mi>W</mml:mi> <mml:mo>,</mml:mo> <mml:mspace width="1.em"/><mml:mi>x</mml:mi> <mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
where the constant drift <italic>A</italic> = <italic>Q</italic><sub>1</sub> − <italic>Q</italic><sub>2</sub> represents the average increase in evidence supporting the correct choice per unit time (<italic>Q</italic><sub>1</sub> could represent the value of pressing a lever and <italic>Q</italic><sub>2</sub> the value of the null action—no lever press—for example), and <italic>cdW</italic> represents white noise which is Gaussian-distributed with <italic>μ</italic> = 0, <italic>σ</italic><sup>2</sup> = <italic>c</italic><sup>2</sup> <italic>dt</italic>. In the free-response case of interest here, the process terminates (i.e. decision is made) when <italic>x</italic> reaches a fixed threshold ±<italic>z</italic>. Analytic expressions relating error rate and decision times to DDM parameters can be derived in this simple case [<xref ref-type="bibr" rid="pcbi.1004622.ref073">73</xref>].</p>
<p>We consider the slightly augmented DDM in which the drift and diffusion (i.e. noise strength) constants vary over time [<xref ref-type="bibr" rid="pcbi.1004622.ref082">82</xref>]:
<disp-formula id="pcbi.1004622.e048"><alternatives><graphic id="pcbi.1004622.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e048" xlink:type="simple"/><mml:math display="block" id="M48"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>d</mml:mi> <mml:mi>x</mml:mi> <mml:mo>=</mml:mo> <mml:mi>g</mml:mi> <mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo> <mml:mo>[</mml:mo> <mml:mi>A</mml:mi> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>c</mml:mi> <mml:mi>d</mml:mi> <mml:mi>W</mml:mi> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo> <mml:mspace width="1.em"/><mml:mi>x</mml:mi> <mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula>
where <italic>g</italic>(<italic>t</italic>) is the time-varying gain which controls the drift and noise, and which we assume directly reflects dopamine concentration.</p>
</sec>
<sec id="sec016">
<title>Dopamine dynamics</title>
<p>We consider the additive effects of two sorts of fluctuation in <italic>g</italic>(<italic>t</italic>): tonic and phasic. In the tonic case, dopamine is assumed to fluctuate in an autocorrelated manner around some constant level (<xref ref-type="fig" rid="pcbi.1004622.g010">Fig 10A</xref>). In particular, we assume that <italic>g</italic>(<italic>t</italic>) follows an Ornstein-Uhlenbeck process
<disp-formula id="pcbi.1004622.e049"><alternatives><graphic id="pcbi.1004622.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e049" xlink:type="simple"/><mml:math display="block" id="M49"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>d</mml:mi> <mml:mi>g</mml:mi> <mml:mo>=</mml:mo> <mml:mi>κ</mml:mi> <mml:mo>(</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>-</mml:mo> <mml:mi>g</mml:mi> <mml:mo>)</mml:mo> <mml:mi>d</mml:mi> <mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>σ</mml:mi> <mml:mi>d</mml:mi> <mml:mi>W</mml:mi> <mml:mo>,</mml:mo> <mml:mspace width="1.em"/><mml:mi>g</mml:mi> <mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(19)</label></disp-formula>
where <italic>θ</italic> is the long-term mean of the process, <italic>κ</italic> controls the rate of mean reversion, and <italic>σ</italic> controls the variance of the white noise process.</p>
<fig id="pcbi.1004622.g010" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g010</object-id>
<label>Fig 10</label>
<caption>
<title>Simulated tonic and phasic dopamine fluctuations.</title>
<p>(A) Simulated tonic fluctuations of dopamine concentration [DA] around a constant level (horizontal dashed line). (B) Addition of a comparatively large phasic fluctuation in dopamine concentration due to a TD error occurring at <italic>t</italic> = 1 s (vertical dashed line).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g010" xlink:type="simple"/>
</fig>
<p>In the phasic case, we consider the addition of a more dramatic change in dopamine concentration, notionally driven by TD-related phasic activity of dopamine cells occasioned either by an external cue or, as in the previous section, by a latent event internal to the animal (<xref ref-type="fig" rid="pcbi.1004622.g010">Fig 10B</xref>). Thus, tonic fluctuations are again assumed, as per <xref ref-type="disp-formula" rid="pcbi.1004622.e049">Eq (19)</xref>, but now a large phasic increase in dopamine is added to this signal. In particular, we assume phasic increases are driven by a TD response of random magnitude <italic>h</italic> drawn from a Gaussian distribution
<disp-formula id="pcbi.1004622.e050"><alternatives><graphic id="pcbi.1004622.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e050" xlink:type="simple"/><mml:math display="block" id="M50"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>h</mml:mi> <mml:mo>∼</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>T</mml:mi> <mml:mi>D</mml:mi></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>T</mml:mi> <mml:mi>D</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>)</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(20)</label></disp-formula>
As before, the TD response is converted to a transient change in extracellular dopamine concentration via the alpha function ‘DRF’ described in <xref ref-type="disp-formula" rid="pcbi.1004622.e004">Eq (4)</xref>.</p>
</sec>
</sec>
<sec id="sec017">
<title>Tonic and phasic dopamine fluctuations produce average ramping signals</title>
<sec id="sec018">
<title>Tonic fluctuations</title>
<p>
<xref ref-type="fig" rid="pcbi.1004622.g011">Fig 11A</xref> shows a single-trial example of how the decision-making variable <italic>x</italic>(<italic>t</italic>) and dopamine concentration <italic>g</italic>(<italic>t</italic>) co-evolve in the case of tonic dopamine fluctuations (upper and lower plots, respectively). Even though dopamine fluctuations here are driven purely by noise, averaging over dopamine signals aligned to the time of decision (i.e. threshold-crossing) reveals a clear ramping of this average signal towards decision time (<xref ref-type="fig" rid="pcbi.1004622.g011">Fig 11B</xref>). This averaging phenomenon is due to threshold-crossing events being more likely to occur when [DA] (i.e. the gain) is high, and also to the fact that the [DA] time series is autocorrelated.</p>
<fig id="pcbi.1004622.g011" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g011</object-id>
<label>Fig 11</label>
<caption>
<title>Tonic fluctuations generate average ramping signals.</title>
<p>(A) Single trial example showing evolution of the decision variable <italic>x</italic>(<italic>t</italic>) (upper) and dopamine concentration [DA] (lower) over time. (B) Average [DA] (±SEM) aligned to time of threshold crossing. Number of simulated trials <italic>N</italic> = 1000. [DA] process parameters: <italic>dt</italic> = 0.01 s, <italic>θ</italic> = 1, <italic>κ</italic> = 0.01, <italic>σ</italic> = 0.1. DDM parameters: <italic>A</italic> = 1, <italic>c</italic> = 1, <italic>z</italic> = 5.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g011" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec019">
<title>Phasic fluctuations</title>
<p>Unsurprisingly, the addition of strong phasic fluctuations, notionally driven by TD-related activity, also generates an average ramping signal (<xref ref-type="fig" rid="pcbi.1004622.g012">Fig 12A</xref>). Of note in this case is the negative correlation between the magnitude of the TD response <italic>h</italic> and latency (i.e. time of threshold crossing; <xref ref-type="fig" rid="pcbi.1004622.g012">Fig 12B</xref>). This is in accord with the finding that the size of phasic responses of dopaminergic cells to a trial-start cue in a reward-related task is negatively correlated with reaction time [<xref ref-type="bibr" rid="pcbi.1004622.ref083">83</xref>] (<xref ref-type="fig" rid="pcbi.1004622.g012">Fig 12C</xref>).</p>
<fig id="pcbi.1004622.g012" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g012</object-id>
<label>Fig 12</label>
<caption>
<title>Phasic fluctuations generate ramping signals.</title>
<p>(A) Average dopamine concentration [DA] (±SEM) aligned to time of threshold crossing. Number of simulated trials <italic>N</italic> = 1000. (B) Time of threshold-crossing (latency) is negatively correlated with size of TD error <italic>h</italic> in the model (<italic>ρ</italic> = −0.43). (C) Similarly, response magnitude of dopaminergic cells to a trial-start cue (upper plots, showing population response histograms by behavioural reaction time, RT) is negatively correlated with a monkey’s reaction time (lower) in an instrumental, reward-related task. Adapted from [<xref ref-type="bibr" rid="pcbi.1004622.ref083">83</xref>], with permission. [DA] process parameters: <italic>dt</italic> = 0.01 s, <italic>θ</italic> = 1, <italic>κ</italic> = 0.01, <italic>σ</italic> = 0.1. DDM parameters: <italic>A</italic> = 2, <italic>c</italic> = 0.1, <italic>z</italic> = 5. TD errors: <inline-formula id="pcbi.1004622.e051"><alternatives><graphic id="pcbi.1004622.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mrow><mml:msub><mml:mi>μ</mml:mi> <mml:mrow><mml:mi>T</mml:mi> <mml:mi>D</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mn>4</mml:mn> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>σ</mml:mi> <mml:mrow><mml:mi>T</mml:mi> <mml:mi>D</mml:mi></mml:mrow> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g012" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec020">
<title>Dopamine fluctuations and motivational state</title>
<p>While an obvious source of phasic fluctuations in dopamine concentration is the TD-related phasic activity of dopamine cells, the origins of the tonic fluctuations assumed here are perhaps less clear. Although these could simply be attributed to ‘intrinsic noise’, a psychologically richer possibility is that such fluctuations could be at least partially driven by changing motivational states. Indeed, Satoh et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref083">83</xref>] suggested that the relationship between phasic DA activity and response latency that they observed was driven by changes in motivation. Returning briefly to the average-reward RL framework, we can consider what to expect in terms of dopaminergic activity and response latencies in different motivational states. Taking the lever-pressing case of <xref ref-type="fig" rid="pcbi.1004622.g003">Fig 3B</xref>, and a critic that only receives indirect information about the actor’s choice of <italic>τ</italic>, we now assume that the utility of a fixed reward depends on motivational state. Further, it is assumed that the actor selects a latency <italic>τ</italic> with a probability which depends on its relative Q-value via the softmax function: <inline-formula id="pcbi.1004622.e052"><alternatives><graphic id="pcbi.1004622.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:mrow><mml:mi>P</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mo>(</mml:mo> <mml:mi>β</mml:mi> <mml:msup><mml:mover accent="true"><mml:mi>Q</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>π</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, <italic>β</italic> = 1. In this case, it is straightforward to show that the average utility rate and magnitude of prediction error in response to a trial-start cue will be positively correlated (<xref ref-type="fig" rid="pcbi.1004622.g013">Fig 13A</xref>), either predictively given model-based calculations, or through experience of model-free ones [<xref ref-type="bibr" rid="pcbi.1004622.ref084">84</xref>]. Furthermore, it will again be the case that latencies are anticorrelated with the magnitude of prediction errors (<xref ref-type="fig" rid="pcbi.1004622.g013">Fig 13B</xref>). This example not only illustrates a possible role for motivational state in driving changes in dopamine levels and correlated changes in behaviour, but flags the difficulty of disentangling the influences of phasic and tonic dopamine on behaviour. Indeed, within the particular implementation of the average-reward RL model suggested by Niv et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref039">39</xref>], the observed effect on latency is really determined by the tonic level of dopamine, which, in turn, is treated as being mechanistically independent of phasic dopamine. However, since changes in tonic level are correlated with changes in phasic response, what amounts to a spurious correlation between phasic activity and latency is observed.</p>
<fig id="pcbi.1004622.g013" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g013</object-id>
<label>Fig 13</label>
<caption>
<title>Correlation of average utility rate and size of TD error.</title>
<p>(A) As the utility <italic>r</italic> of a reward increases, putatively from a change in motivational state, both the average utility rate <italic>ρ</italic> (assumed to be signalled by tonic dopamine) and the size of TD error <inline-formula id="pcbi.1004622.e053"><alternatives><graphic id="pcbi.1004622.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e053" xlink:type="simple"/><mml:math display="inline" id="M53"><mml:mrow><mml:msubsup><mml:mi>δ</mml:mi> <mml:mi>t</mml:mi> <mml:mi>p</mml:mi></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> in response to a trial-start cue (phasic dopamine) increase. (B) A negative correlation between TD error and latency is observed. Here, we again assume the lever-pressing task depicted in <xref ref-type="fig" rid="pcbi.1004622.g003">Fig 3B</xref>. The critic is assumed to receive only indirect information about the actor’s choices. Model parameters: <italic>a</italic> = −0.05, <italic>b</italic> = 0, <italic>τ</italic><sub><italic>post</italic></sub> = 0.5 s, <italic>τ</italic><sub><italic>I</italic></sub> = 0 s, <italic>β</italic> = 1.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g013" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec021">
<title>Ramping as state prediction</title>
<p>We now consider a third account of dopamine ramps based on a new model of discounted vigour. Incorporating the observations and suggestions of Howe et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>], together with a partially free-operant experiment of his own, Berke and colleagues (personal communication, [<xref ref-type="bibr" rid="pcbi.1004622.ref085">85</xref>]) suggested that the concentration of dopamine measured by FSCV in the accumbens might be strongly influenced by the discounted value function <italic>V</italic>(<italic>s</italic>) of <xref ref-type="disp-formula" rid="pcbi.1004622.e001">Eq (1)</xref>. This will show evidence of ramping towards final goal states when the discount factor is less than 1, consistent with the observations of Howe et al. (<xref ref-type="fig" rid="pcbi.1004622.g005">Fig 5</xref>). We describe this signal as being <italic>quasi-tonic</italic> since, when there is no reward, it is a form of integral of the TD prediction error, which is phasic. However, one should bear in mind that when the state changes abruptly, the value can change abruptly too. The key question, though, is why we should expect to see any such quasi-tonic signal in this context?</p>
<p>We consider the possibility that this signal is the equivalent in the discounted case of the average reward <italic>ρ</italic> (for convenience, in this section, we omit the superscript <italic>π</italic>) which, as we have seen, has previously been argued to be (a) the comparison point for the phasic prediction error or the immediate reward; (b) the spur to instrumental vigour; and (c) represented by tonic levels of dopamine [<xref ref-type="bibr" rid="pcbi.1004622.ref039">39</xref>].</p>
<p>Indeed, consider afresh an apparent inconsistency in the definition of the TD prediction error between the cases of average and discounted reward. In the average case, the phasic component of the full prediction error (c.f. <xref ref-type="disp-formula" rid="pcbi.1004622.e035">Eq (16)</xref>), now denoted <italic>δ</italic><sup><italic>A</italic></sup>(<italic>s</italic><sub><italic>t</italic></sub>), is
<disp-formula id="pcbi.1004622.e054"><alternatives><graphic id="pcbi.1004622.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e054" xlink:type="simple"/><mml:math display="block" id="M54"><mml:mrow><mml:msup><mml:mi>δ</mml:mi> <mml:mi>A</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(21)</label></disp-formula>
and we expect the mean of this over the long run to be the overall mean reward rate
<disp-formula id="pcbi.1004622.e055"><alternatives><graphic id="pcbi.1004622.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e055" xlink:type="simple"/><mml:math display="block" id="M55"><mml:mrow><mml:mo>〈</mml:mo> <mml:msup><mml:mi>δ</mml:mi> <mml:mi>A</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mi>ρ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(22)</label></disp-formula>
which is a tonic signal that therefore acts as a comparison point for the phasic prediction error. Eqs (<xref ref-type="disp-formula" rid="pcbi.1004622.e054">21</xref>) and (<xref ref-type="disp-formula" rid="pcbi.1004622.e055">22</xref>) can also be seen as arising from the observation that the relative values <inline-formula id="pcbi.1004622.e056"><alternatives><graphic id="pcbi.1004622.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mover accent="true"><mml:mi>V</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> are expected undiscounted sums of the differences between <italic>r</italic>(<italic>s</italic><sub><italic>t</italic></sub>) and <italic>ρ</italic>. Unfortunately, even if the relationship in <xref ref-type="disp-formula" rid="pcbi.1004622.e055">Eq (22)</xref> actually holds, <italic>ρ</italic>, because it is stationary, is formally hard to measure with FSCV, whose measurements are typically referenced to a potentially ever-changing baseline.</p>
<p>By contrast, in the discounted case, the phasic prediction error <italic>δ</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic></sub>) is normally written as
<disp-formula id="pcbi.1004622.e057"><alternatives><graphic id="pcbi.1004622.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e057" xlink:type="simple"/><mml:math display="block" id="M57"><mml:mrow><mml:msup><mml:mi>δ</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>γ</mml:mi> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(23)</label></disp-formula>
now writing the discounted value function as <italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic>), and is expected on average to be 0:
<disp-formula id="pcbi.1004622.e058"><alternatives><graphic id="pcbi.1004622.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e058" xlink:type="simple"/><mml:math display="block" id="M58"><mml:mrow><mml:mo>〈</mml:mo> <mml:msup><mml:mi>δ</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
However, two considerations encourage us to write this expression slightly differently, with an <italic>undiscounted</italic> phasic TD prediction error just as in <xref ref-type="disp-formula" rid="pcbi.1004622.e054">Eq (21)</xref>:
<disp-formula id="pcbi.1004622.e059"><alternatives><graphic id="pcbi.1004622.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e059" xlink:type="simple"/><mml:math display="block" id="M59"><mml:mrow><mml:msup><mml:mi>δ</mml:mi> <mml:msub><mml:mi>A</mml:mi> <mml:mi>γ</mml:mi></mml:msub></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(24)</label></disp-formula>
which should, on average, take the value
<disp-formula id="pcbi.1004622.e060"><alternatives><graphic id="pcbi.1004622.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e060" xlink:type="simple"/><mml:math display="block" id="M60"><mml:mrow><mml:mo>〈</mml:mo> <mml:msup><mml:mi>δ</mml:mi> <mml:msub><mml:mi>A</mml:mi> <mml:mi>γ</mml:mi></mml:msub></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〈</mml:mo> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(25)</label></disp-formula>
Here, (1 − <italic>γ</italic>)〈<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + 1</sub>)〉, by analogy with the truly stationary signal <italic>ρ</italic>, would be represented as a quasi-tonic signal which acts as a target for a phasic TD prediction error signal that involves a discounted value function. Assuming that this baseline signal is represented in a quasi-tonic concentration signal would thus licence ramping.</p>
<p>The two considerations that encourage this interpretation of phasic and quasi-tonic dopamine signals are: (i) continuity between average and discounted cases as <italic>γ</italic> → 1; (ii) something of particular pertinence in the current context, namely the determinants of vigour for discounted problems. We discuss these in turn. There is also a rough analogy with the Hamilton-Jacobi-Bellman (HJB) equation [<xref ref-type="bibr" rid="pcbi.1004622.ref086">86</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref087">87</xref>], but as this requires considering continuous space and time, as well as a different sort of transition structure, we do not discuss it further.</p>
<sec id="sec022">
<title>Continuity</title>
<p>It is well known that, in convenient circumstances, there are very close links between the infinite horizon average and discounted reward cases for dynamic programming and control [<xref ref-type="bibr" rid="pcbi.1004622.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref086">86</xref>]. For instance, for a large class of suitable MDPs, there is a minimum discount factor 0 ≤ <italic>γ</italic>* &lt; 1 such that the optimal policy for the discounted problem with discount <italic>γ</italic> &gt; <italic>γ</italic>* is also optimal for the average case. Thus, we might expect the prediction errors and putative phasic and tonic signals to be continuous as <italic>γ</italic> → 1. This is patently not true of the single <xref ref-type="disp-formula" rid="pcbi.1004622.e057">Eq (23)</xref>, compared with the pair Eqs (<xref ref-type="disp-formula" rid="pcbi.1004622.e054">21</xref> and <xref ref-type="disp-formula" rid="pcbi.1004622.e055">22</xref>).</p>
<p>However, it is well known that this can be repaired by considering the term in <xref ref-type="disp-formula" rid="pcbi.1004622.e060">Eq (25)</xref> in the limit that <italic>γ</italic> → 1:
<disp-formula id="pcbi.1004622.e061"><alternatives><graphic id="pcbi.1004622.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e061" xlink:type="simple"/><mml:math display="block" id="M61"><mml:mrow><mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>γ</mml:mi> <mml:mo>→</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mfenced close="
x007D;" open="
x007B;" separators=""><mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow> <mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>γ</mml:mi> <mml:mo>→</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mfrac><mml:mrow><mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mfenced close="
x232A;" open="
x2329;" separators=""><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mrow><mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
where the denominator arises from the fact that <inline-formula id="pcbi.1004622.e062"><alternatives><graphic id="pcbi.1004622.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e062" xlink:type="simple"/><mml:math display="inline" id="M62"><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>y</mml:mi> <mml:mo>+</mml:mo> <mml:msup><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>+</mml:mo> <mml:mn>…</mml:mn> <mml:mo>=</mml:mo> <mml:mfrac bevelled="true"><mml:mn>1</mml:mn> <mml:mrow><mml:mo stretchy="false">(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>−</mml:mo> <mml:mi>y</mml:mi> <mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>,
<disp-formula id="pcbi.1004622.e063"><alternatives><graphic id="pcbi.1004622.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e063" xlink:type="simple"/><mml:math display="block" id="M63"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>γ</mml:mi> <mml:mo>→</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:mfrac><mml:msub><mml:mfenced close="
x232A;" open="
x2329;" separators=""><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:mfrac> <mml:mspace width="4pt"/><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
Thus, if the limits can be swapped (see [<xref ref-type="bibr" rid="pcbi.1004622.ref086">86</xref>] for conditions),
<disp-formula id="pcbi.1004622.e064"><alternatives><graphic id="pcbi.1004622.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e064" xlink:type="simple"/><mml:math display="block" id="M64"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>γ</mml:mi> <mml:mo>→</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mfrac><mml:msub><mml:mfenced close="
x232A;" open="
x2329;" separators=""><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>k</mml:mi></mml:msup> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>k</mml:mi></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mtext>lim</mml:mtext> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>→</mml:mo> <mml:mi>∞</mml:mi></mml:mrow></mml:msub> <mml:mfenced close="
x007D;" open="
x007B;" separators=""><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>N</mml:mi></mml:mfrac> <mml:msub><mml:mfenced close="
x232A;" open="
x2329;" separators=""><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>k</mml:mi> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:munderover> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>k</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>=</mml:mo> <mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>ρ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and so a formal continuity as <italic>γ</italic> → 1 does arise between the two pairs of phasic and tonic representations Eqs (<xref ref-type="disp-formula" rid="pcbi.1004622.e054">21</xref> and <xref ref-type="disp-formula" rid="pcbi.1004622.e055">22</xref>) and Eqs (<xref ref-type="disp-formula" rid="pcbi.1004622.e059">24</xref> and <xref ref-type="disp-formula" rid="pcbi.1004622.e060">25</xref>).</p>
</sec>
<sec id="sec023">
<title>Discounted vigour</title>
<p>As mentioned above, one of the main suggestions about the tonic release of dopamine associated with <italic>ρ</italic> is that it should determine the vigour of responding. This is shown in the average reward model discussed above by the influence of this factor in the latency of <xref ref-type="disp-formula" rid="pcbi.1004622.e014">Eq (10)</xref> that maximises the relative value <inline-formula id="pcbi.1004622.e065"><alternatives><graphic id="pcbi.1004622.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:mover accent="true"><mml:mi>Q</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> of <xref ref-type="disp-formula" rid="pcbi.1004622.e013">Eq (9)</xref>.</p>
<p>In the discounted case, the equivalent <italic>Q</italic><sup><italic>γ</italic></sup> equation to <xref ref-type="disp-formula" rid="pcbi.1004622.e013">Eq (9)</xref> is
<disp-formula id="pcbi.1004622.e066"><alternatives><graphic id="pcbi.1004622.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e066" xlink:type="simple"/><mml:math display="block" id="M66"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>Q</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>τ</mml:mi></mml:msup> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>τ</mml:mi></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
showing that the opportunity cost −<italic>ρτ</italic> encouraging quick actions has been replaced by the ever more negative value of −(1 − <italic>γ</italic><sup><italic>τ</italic></sup>)<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + <italic>τ</italic></sub>) as <italic>τ</italic> increases. As <italic>γ</italic> → 1, (1 − <italic>γ</italic><sup><italic>τ</italic></sup>) can usefully be written as <italic>τ</italic>(1 − <italic>γ</italic>) + <italic>O</italic>((1 − <italic>γ</italic>)<sup>2</sup>), so the portion of <italic>Q</italic><sup><italic>γ</italic></sup>(<italic>s</italic>, <italic>τ</italic>) that depends on <italic>τ</italic> becomes
<disp-formula id="pcbi.1004622.e067"><alternatives><graphic id="pcbi.1004622.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e067" xlink:type="simple"/><mml:math display="block" id="M67"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>Q</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>,</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mi mathvariant="script">K</mml:mi> <mml:mo>+</mml:mo> <mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msup><mml:mi>γ</mml:mi> <mml:mi>τ</mml:mi></mml:msup> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>≃</mml:mo> <mml:mi mathvariant="script">K</mml:mi> <mml:mo>+</mml:mo> <mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>τ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>γ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mi>V</mml:mi> <mml:mi>γ</mml:mi></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mi>τ</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and a comparison with <xref ref-type="disp-formula" rid="pcbi.1004622.e013">Eq (9)</xref> shows again how (1 − <italic>γ</italic>)<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + <italic>τ</italic></sub>) in the discounted reward model plays an equivalent role to <italic>ρ</italic> in the average model. The equations above extend this to the non-limiting case of <italic>γ</italic> &lt; 1.</p>
</sec>
</sec>
<sec id="sec024">
<title>A quasi-tonic dopamine signal</title>
<p>Insight into discounted vigour comes from numerical calculations of the optimal latencies <italic>τ</italic>* as a function of <italic>γ</italic> and for different values <italic>a</italic> &lt; 0 that control the hyperbolic cost of vigour <inline-formula id="pcbi.1004622.e068"><alternatives><graphic id="pcbi.1004622.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1004622.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:mrow><mml:mi>c</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>τ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mi>a</mml:mi> <mml:mi>τ</mml:mi></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> in two cases: a terminating chain with <italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + <italic>τ</italic></sub>) = 1, ∀<italic>τ</italic>, <italic>γ</italic> (roughly as in [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>]) and a continuing chain as in <xref ref-type="fig" rid="pcbi.1004622.g003">Fig 3</xref>. <xref ref-type="fig" rid="pcbi.1004622.g014">Fig 14A</xref> shows optimal latencies <italic>τ</italic>* in the terminating case. Generally, as <italic>γ</italic> decreases, the faster the weight given to future value <italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + <italic>τ</italic></sub>) decays with time, encouraging quicker latencies. This tendency is balanced by the greater cost of acting quickly that is then incurred. In fact, one can show that there there is a limit on the cost of acting of <italic>a</italic><sub>min</sub> = 4/(<italic>e</italic><sup>2</sup> log <italic>γ</italic>) below which there is no solution for <italic>τ</italic>* — crudely, the cost of acting quickly deems such a long latency that the resulting discounted value of the reward (from <italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + <italic>τ</italic></sub>) = 1) is insufficient to warrant action at all (<xref ref-type="fig" rid="pcbi.1004622.g014">Fig 14A</xref>, solid red line).</p>
<fig id="pcbi.1004622.g014" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g014</object-id>
<label>Fig 14</label>
<caption>
<title>Optimal latency <italic>τ</italic>* as a function of discount factor <italic>γ</italic> and cost <italic>a</italic>.</title>
<p>The optimal latency <italic>τ</italic>* tends to decrease as either the discount factor <italic>γ</italic> or the cost of acting quickly <italic>a</italic> decrease. (A) Terminating SMDP, <italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + <italic>τ</italic></sub>) = 1, ∀<italic>τ</italic>, <italic>γ</italic>. There exists a limit on the cost of acting <italic>a</italic><sub>lim</sub> below which there is no solution for <italic>τ</italic>* (solid red line). (B) Difference between the optimal <italic>τ</italic>* for the cases of continuing and terminating SMDP for the case that <italic>τ</italic><sub><italic>I</italic></sub> = 30 s. As <italic>τ</italic><sub><italic>I</italic></sub> is large relative to −1/log <italic>γ</italic>, there is little difference <italic>Δτ</italic>* from the terminating case. (C) Difference between the optimal <italic>τ</italic>* for the cases of continuing and terminating SMDP for the case that <italic>τ</italic><sub><italic>I</italic></sub> = 1 s. In this case, future rewards hasten lever pressing as seen in the more prevalent decreases in <italic>τ</italic>*.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g014" xlink:type="simple"/>
</fig>
<p>
<xref ref-type="fig" rid="pcbi.1004622.g014">Fig 14B and 14C</xref> show <italic>differences</italic> in <italic>τ</italic>* in the continuing compared to the terminating case. In the continuing SMDP, the result of pressing the lever includes a further opportunity to press the lever (without which, the infinite horizon average reward <italic>ρ</italic> would formally be 0). When the inter-trial interval <italic>τ</italic><sub><italic>I</italic></sub> is large relative to −1/log <italic>γ</italic>, there is little difference from the terminating case (<xref ref-type="fig" rid="pcbi.1004622.g014">Fig 14B</xref>); however, when it is not, the prospect of accelerating not only the immediate reward but also future rewards further hastens lever pressing, visible in greater decreases in <italic>τ</italic>* compared to the terminating case (<xref ref-type="fig" rid="pcbi.1004622.g014">Fig 14C</xref>).</p>
<p>Given the preceding analysis, it is straightforward to show that a quasi-tonic dopamine signal reflecting the quantity (1 − <italic>γ</italic>)<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + 1</sub>) would lead to the sort of ramping observed by Howe et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>] in their spatial reward task (c.f. <xref ref-type="fig" rid="pcbi.1004622.g005">Fig 5</xref>) for <italic>γ</italic> &lt; 1. Indeed, just as observed by Howe et al., [DA] gradually ramps up as the goal is approached and peaks at the same value regardless of the time taken to reach the goal or the distance travelled to reach it, assuming a fixed reward size (<xref ref-type="fig" rid="pcbi.1004622.g015">Fig 15A</xref>). Further, as observed experimentally, increasing the reward size leads peak [DA] to increase (<xref ref-type="fig" rid="pcbi.1004622.g015">Fig 15B</xref>) and, given a lack of progress towards the goal—for instance if the agent remains stationary or moves away from the goal—[DA] remains approximately stationary or decreases, respectively, as observed by Howe et al. on such trials (<xref ref-type="fig" rid="pcbi.1004622.g015">Fig 15C</xref>). One should note in this latter case that the single-trial examples shown by Howe et al. find dopamine concentrations tracking spatial proximity remarkably closely (see <xref ref-type="fig" rid="pcbi.1004622.g005">Fig 5C</xref>), while convolution of (1 − <italic>γ</italic>)<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + 1</sub>) with the DRF that we have assumed leads to a signal which looks comparatively over-smoothed (<xref ref-type="fig" rid="pcbi.1004622.g015">Fig 15C</xref>, right). However, given the heterogeneous nature of striatal dopamine release [<xref ref-type="bibr" rid="pcbi.1004622.ref088">88</xref>], how rapidly [DA] is observed to change may well depend on the exact positioning of the voltammetric sensor. Examination of further single-trial examples could help clarify this issue.</p>
<fig id="pcbi.1004622.g015" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1004622.g015</object-id>
<label>Fig 15</label>
<caption>
<title>Simulations replicate Howe et al. results.</title>
<p>(A) [DA] gradually increases as the goal is approached, peaking at the same values whether different times were taken to traverse a maze of fixed length, or in mazes of different lengths with a fixed magnitude of reward (time is taken as a proxy for distance in the latter case). (B) Peak [DA] is greater for larger rewards. (C) [DA] tracks proximity to the goal. In this example, goal proximity over time is non-monotonically increasing (left), and we plot both the corresponding scaled value quantity (1 − <italic>γ</italic>)<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + 1</sub>) (middle) and the convolution of the latter with the DRF which yields [DA] (right). Parameters: <italic>γ</italic> = 0.98, <italic>r</italic> = 1 (unless indicated otherwise).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1004622.g015" xlink:type="simple"/>
</fig>
</sec>
</sec>
<sec id="sec025" sec-type="conclusions">
<title>Discussion</title>
<p>The observation of ramp-like increases in dopamine concentration within the nucleus accumbens appears to pose a challenge to existing computational accounts of dopamine’s role. Here, we explored three different explanations for such signals: (a) resolution of uncertainty about the timing of action within an actor-critic, leading to a prediction error shortly preceding the action itself; (b) positive correlations between the time of action and dopamine levels generated by dopaminergic gain control of the decision-making process; and (c) a quasi-tonic signal replacing the average reward in the exponentially discounted setting. These explanations, along with the possibility mentioned earlier that release from dopamine axons might be directly occasioned by a form of spillover from cortico-striatal activity, are by no means mutually exclusive. This prompts a need for experimental test.</p>
<p>Note that the various cases of ramps may be caused by different, or combined, mechanisms. Indeed, the possible explanations that we considered mainly in the context of pre-response transients, in which ramp-like signals are observed leading up to completion of an instrumental action, were somewhat distinct from the explanation offered for ramping in the spatial reward task, in which the subjects are already engaged in acting. Nevertheless, the account of discounted vigour suggested in the latter case should be relevant in all contexts where some degree of discounting is probable (i.e. <italic>γ</italic> &lt; 1), such as in the temporally-extended tasks considered here, since it is in this case that the quantity (1 − <italic>γ</italic>)<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + 1</sub>) should be visible as a ramping signal.</p>
<sec id="sec026">
<title>TD accounts of pre-response dopamine signals</title>
<p>What TD accounts of pre-response dopamine signals predict depends on the assumptions made about the relationship between actor and critic. We considered three possibilities associated with different predictions of how a TD error occurring just prior to pressing, and the resulting change in dopamine concentration, should change as response latencies increase: remain constant, decrease, or increase.</p>
<p>The model in which the critic receives <italic>both</italic> direct and indirect information, but suffers from timing uncertainty, yielded results most consistent with the experimental data reported by Roitman et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref010">10</xref>]. In particular, this case replicated the observation that peak dopamine concentration around time of pressing was larger than at time of cue for long latency trials. This result relied on the assumption that the critic’s uncertainty about the time of action increases with choices of longer press latencies. This is consistent with the finding, in the equivalent Pavlovian circumstance, that the responses of dopaminergic neurons to a cue predicting reward delivery after a long delay are smaller than responses to cues predicting shorter delays; conversely, dopamine responses to the reward itself increase with longer delays [<xref ref-type="bibr" rid="pcbi.1004622.ref062">62</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref089">89</xref>], a finding that indeed has been suggested to arise through timing uncertainty.</p>
<p>This finding is apparently opposite, though, to an observation also mentioned above. This is that for the case of a single, non-exponential hazard function, which mandates a range of possible times at which a reward-related cue might be presented, relatively late presentations inspire <italic>smaller</italic> dopamine responses than early ones [<xref ref-type="bibr" rid="pcbi.1004622.ref063">63</xref>]. An obvious explanation of this finding is that as time goes by, presentation of the cue is more and more likely, and so less and less unexpected. This does not contradict our finding, which depends on many possible hazard functions, one for each choice of lever-press latency.</p>
<p>Two assumptions in the proposed TD account merit further comment. Firstly, while we assumed that the actor’s choice of when to press the lever immediately follows cue presentation, one can imagine variability in when the actor makes decisions about when to act. For example, it might be that the animal initially fails to notice the cue, or is otherwise engaged (even in instrumental leisure; [<xref ref-type="bibr" rid="pcbi.1004622.ref040">40</xref>]) when the cue arrives, only later resolving to engage with the lever. Secondly, and perhaps relatedly, while it was convenient to assume that latencies <italic>τ</italic>, and therefore times <italic>T</italic>, follow a gamma distribution, the reported distribution of press times appears to have heavier tails than we would expect if they were drawn from a single gamma distribution. Thus, Roitman et al. reported mean response times of 1.2 s and 26.2 s for short-latency (83%) and long-latency (17%) trials, respectively. Closer examination of the empirical response distribution in such studies would be of interest for future work.</p>
<p>A more general problem for a TD account of pre-response signals is that while there is abundant evidence of a systematic temporal relationship between the time at which a cue indicating reward availability is presented and subsequent phasic activity in dopaminergic neurons, there is little or no evidence of such a relationship between the time of the phasic response and when a subsequent instrumental action—necessary to obtain the reward—is emitted. For example, Ljungberg et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref090">90</xref>] found that when monkeys were exposed to cues that predicted when they could obtain food by reaching into a box, activity of dopaminergic neurons was time-locked to the predictive cue rather than movement onset. Whether this is also true for the timescale and nature of rodent movements is unclear. Even in monkeys, Romo and Schultz [<xref ref-type="bibr" rid="pcbi.1004622.ref091">91</xref>] reported gradual increases in the firing rates of some putative dopaminergic cells (12 out of 104 recorded) up to 1500 before onset of self-initiated arm movements to obtain food. However, this slow change in activity does not resemble the sort of bursting activity that might be associated with a phasic TD signal.</p>
<p>Suggestively, striatal (and cortical) neurons in monkeys show various patterns, including ramp-like increases in activity, before self-initiated movements [<xref ref-type="bibr" rid="pcbi.1004622.ref055">55</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref092">92</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref093">93</xref>]. Similarly, some neurons in rat ventral striatum show anticipatory increases in activity when approaching or waiting for food delivery [<xref ref-type="bibr" rid="pcbi.1004622.ref094">94</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref095">95</xref>]. Furthermore, simultaneous electrophysiological and FSCV recordings from the same electrode have revealed that changes in dopamine concentration and activity of specific subsets of accumbal cells can be temporally correlated [<xref ref-type="bibr" rid="pcbi.1004622.ref096">96</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref097">97</xref>]. Suppression of phasic activity in VTA dopaminergic cells appears to disrupt such time-locked activity, perhaps indicating that it is phasic activity of dopaminergic cells which drives such correlated activity [<xref ref-type="bibr" rid="pcbi.1004622.ref098">98</xref>]. So at the mechanistic level at least, there are multiple possibilities for the origins of pre-response signals beyond phasic dopaminergic activity: they may reflect the sort of slow change in activity of dopaminergic neurons observed in [<xref ref-type="bibr" rid="pcbi.1004622.ref091">91</xref>], or they may reflect increased dopamine release instigated more directly by the activity of other cells, such as reflected in cortico-striatal inputs.</p>
<p>A range of previous work has considered the vagaries of the representation and processing of time. We noted that possible sources of uncertainty included partial observability of the actor’s choices in the case where the critic does not have direct access to this information, and possible timing uncertainty in the case where it does. Implications of partial observability for TD models of dopamine have been explored in previous work, notably by Daw and colleagues [<xref ref-type="bibr" rid="pcbi.1004622.ref048">48</xref>], though that did not address the possibility of partial observability arising between distinct internal agencies, nor the possible relevance to self-initiated action envisaged here. The same study and a number of others [<xref ref-type="bibr" rid="pcbi.1004622.ref048">48</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref049">49</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref099">99</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref101">101</xref>] have addressed the issue of the representation of time, and how this representation may influence timing uncertainty (see [<xref ref-type="bibr" rid="pcbi.1004622.ref102">102</xref>] for a recent review). The implications for TD (and indeed different models of discounting) of the possible distinction between the animal’s ‘internal’ time and the experimenter’s ‘conventional’ time have been worked out in detail by Nakahara and Kaveri [<xref ref-type="bibr" rid="pcbi.1004622.ref049">49</xref>]; we also considered the possibility of separate internal clocks for actor and critic. Additional complexity, which we leave to future work, arises from the putative connection between dopamine and the speed of an internal clock, as inferred, for example, from the effects of dopamine manipulations on behaviour in interval-timing tasks [<xref ref-type="bibr" rid="pcbi.1004622.ref102">102</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref103">103</xref>].</p>
</sec>
<sec id="sec027">
<title>Dopaminergic gain control</title>
<p>We showed that ramping dopamine signals can be generated by a mechanistic decision-making model in which dopamine sets the gain of value-based accumulation. Furthermore, we saw that this direct coupling of dopamine to decision-making could generate a negative correlation between the size of TD error and decision time, consistent with the experimental observation that a larger phasic response of dopaminergic cells to a start cue is associated with a shorter latency of behavioural response [<xref ref-type="bibr" rid="pcbi.1004622.ref083">83</xref>].</p>
<p>This route to ramping signals is primarily statistical, arising from trial-averaging. On any individual trial, dopamine ramping towards the time of decision may or may not occur, though it is certainly more typical when dopamine fluctuations incorporate a strong, TD-related phasic component. To the best of our knowledge, whether pre-response transients in NAc reliably precede the animal’s response on individual trials, or may reflect trial-averaging, is unknown.</p>
<p>Mathematical analysis of the time-varying gain DDM that we described is given by Moehlis et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref082">82</xref>] and, indeed, the idea that dopamine could set this gain follows directly from previous work by Cohen and colleagues on catecholaminergic gain control [<xref ref-type="bibr" rid="pcbi.1004622.ref079">79</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref080">80</xref>]. For example, Shea-Brown et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref080">80</xref>] suggested that noradrenergic activity of cells in the locus coeruleus may help to optimize decision-making by adjusting the gain of an integrative decision process. Furthermore, they showed that their model could replicate the experimental finding that phasic responses of the locus coeruleus correlate more closely with time of behavioural response than with time of stimulus onset in a decision-making task [<xref ref-type="bibr" rid="pcbi.1004622.ref104">104</xref>].</p>
<p>Also of relevance is the biologically-detailed neural network model of the basal ganglia proposed by Frank [<xref ref-type="bibr" rid="pcbi.1004622.ref081">81</xref>] in which dopamine modulates the balance between direct and indirect pathways. Ratcliff and Frank [<xref ref-type="bibr" rid="pcbi.1004622.ref105">105</xref>] have recently explored the links between the latter’s neural network model and more abstract diffusion models, though without exploring a possible direct role for dopamine in the latter. Nevertheless, it is interesting to consider that, depending on the form of the DDM used to fit the data, dopaminergic modulation of a temporally-extended decision process may be manifest in different parameters. For example, a positive correlation between increased tonic dopamine levels and faster responding may also be captured by the assumption that dopamine modulates the threshold of a DDM where the gain is fixed [<xref ref-type="bibr" rid="pcbi.1004622.ref106">106</xref>], rather than modulating the gain under a fixed threshold. Additionally, one may consider potential effects of dopamine not only on the latency of response, but also on which choice is made, for instance due to asymmetries in how dopamine modulates direct and indirect pathways (M.J. Frank, personal communication; [<xref ref-type="bibr" rid="pcbi.1004622.ref107">107</xref>]). More generally, it would be of interest to know whether dopamine ramps would also be observed in Frank’s comparatively detailed model of the basal ganglia.</p>
</sec>
<sec id="sec028">
<title>Discounted vigour</title>
<p>We reconciled an apparent inconsistency between the definitions of TD errors in the cases of average and discounted reward via an analysis in which ramp-like signals would be expected to emerge. In particular, we suggested that the quantity (1 − <italic>γ</italic>)〈<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + 1</sub>)〉 in the discounted reward model plays an equivalent role to the average reward rate <italic>ρ</italic> in the average reward model. Since values often (though not always) change modestly as a result of the passage of time, this signal is quasi-tonic, and thus a candidate for what would be recorded using a technique such as FSCV. This signal can explain the ramping phenomena observed by Howe et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>] and also those observed in more recent experimental work [<xref ref-type="bibr" rid="pcbi.1004622.ref085">85</xref>]. We speculate below on its network or biophysical realization.</p>
<p>Potentially at odds with our suggestion that the quantity (1 − <italic>γ</italic>)〈<italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic><sub><italic>t</italic> + 1</sub>)〉 is appropriate for controlling vigour, changes in the running speed of rats in Howe et al.’s study do not show a close match to the temporal profile of dopamine concentrations. However, one would not necessarily expect a straightforward relationship between these variables, given that the subjects must negotiate environments without crashing into walls. Howe et al. used T-, M-, and S-shaped mazes, whose turns, unsurprisingly, led to decreases in velocity (see [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>], figure 3h–k).</p>
<p>Our analysis suggests that ramps are scaled by the discount factor <italic>γ</italic>, prompting the question of how this discount factor is set, whether it is variable or fixed, and indeed, whether it is unique. There is substantial evidence that human and animal discounting takes a hyperbolic form [<xref ref-type="bibr" rid="pcbi.1004622.ref108">108</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref109">109</xref>] rather than being exponential as considered here (which is rather ubiquitous in engineering and economic settings). This can arise from a combination of two or more exponentials, and it would be most interesting to extend our analysis to this case. From a formal viewpoint, the discount factor can be seen as the probability per unit time of task termination or, indeed, as a means of simplifying a problem en route to an ultimate solution [<xref ref-type="bibr" rid="pcbi.1004622.ref110">110</xref>].</p>
<p>In humans, there is evidence that discount rates can be manipulated experimentally [<xref ref-type="bibr" rid="pcbi.1004622.ref111">111</xref>] and that individuals can flexibly vary their discount rates to suit task demands [<xref ref-type="bibr" rid="pcbi.1004622.ref112">112</xref>]. It has also been suggested that some regions, notably the striatum, display a graded map of discount rates which serve reward prediction at different timescales [<xref ref-type="bibr" rid="pcbi.1004622.ref113">113</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref114">114</xref>]. Howe et al. observed ramping in dopamine concentration in both ventromedial and dorsolateral striatal areas, though ramping responses were reported to be more common in ventromedial striatum. Hints of steeper ramping are perhaps discernible in the average signals reported in ventromedial as opposed to dorsolateral striatum ([<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>], figure 1 and extended data figures 3a and 4). However, whether such ramping signals display systematic, graded differences across the striatum or otherwise change in response to experimental manipulation of discount factors remains an open question.</p>
</sec>
<sec id="sec029">
<title>Complexities of dopamine release: Phasic, tonic, and quasi-tonic</title>
<p>Whereas the TD account of pre-response transients naturally attributes the observed signal to the phasic activity of dopaminergic neurons [<xref ref-type="bibr" rid="pcbi.1004622.ref002">2</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref005">5</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref019">19</xref>], the sources of tonic and particularly ‘quasi-tonic’ dopamine signals are less clear. One long-standing suggestion is that phasic and tonic modes of firing in dopaminergic cells provide independent control of phasic and tonic dopamine levels within NAc [<xref ref-type="bibr" rid="pcbi.1004622.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref115">115</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref116">116</xref>]. Thus, burst firing of dopaminergic neurons is thought to mediate a fast, high-amplitude dopamine transient which is spatially-restricted to a region within or proximal to release terminals by dopamine reuptake. By contrast, the comparatively slow, irregular, ‘tonic’ mode of activity exhibited by a pool of dopaminergic neurons, potentially of varying size, is thought to control the more stable, tonic levels of extrasynaptic dopamine. If average reward rate is represented in tonic levels of dopamine [<xref ref-type="bibr" rid="pcbi.1004622.ref039">39</xref>], then a natural suggestion is that representation of this quantity is controlled by this tonic mode of activity.</p>
<p>Where does a quasi-tonic dopamine signal fit into this picture? It is not clear that the relatively short timescale of change of the ramping signals reported by Howe et al. could arise through mechanisms thought to modulate tonic activity. On the other hand, ramping in the phasic activity of dopaminergic neurons has seldom been reported. Fiorillo et al. [<xref ref-type="bibr" rid="pcbi.1004622.ref117">117</xref>] reported ramp-like increases in between-trial averaged activity under conditions of uncertain reward delivery, though interpretation of this result has been controversial [<xref ref-type="bibr" rid="pcbi.1004622.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref118">118</xref>]. While the paucity of such reports may simply be due to a lack of appropriate electrophysiological recordings in spatial tasks—which may also explain why ramping of dopamine concentrations has not been observed prior to [<xref ref-type="bibr" rid="pcbi.1004622.ref014">14</xref>]—an interesting alternative is that the gradual increase in dopamine concentration is partially- or fully- independent of the activity of dopaminergic cells [<xref ref-type="bibr" rid="pcbi.1004622.ref015">15</xref>]. As mentioned above, a number of local regulatory mechanisms are known to gate the probability of dopamine release [<xref ref-type="bibr" rid="pcbi.1004622.ref027">27</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref028">28</xref>], and there is evidence that striatal dopamine release can occur independently of dopamine cell firing [<xref ref-type="bibr" rid="pcbi.1004622.ref119">119</xref>]. An understanding of how these different mechanisms of dopamine release interrelate is of clear experimental and theoretical interest.</p>
<p>It should be noted that although we have referred throughout to dopamine signals in the nucleus accumbens generally, this should not be taken to suggest that dopamine release is homogeneous within this region. Indeed, FSCV measurements suggest substantial spatial heterogeneity [<xref ref-type="bibr" rid="pcbi.1004622.ref088">88</xref>]. Subregions of NAc have been segregated according to various anatomical features, classically into core and shell subregions [<xref ref-type="bibr" rid="pcbi.1004622.ref120">120</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref121">121</xref>]. Pre-response transients have typically been observed in NAc core [<xref ref-type="bibr" rid="pcbi.1004622.ref008">8</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref013">13</xref>]. Much interest centres on the functional significance of this core-shell distinction [<xref ref-type="bibr" rid="pcbi.1004622.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1004622.ref122">122</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref125">125</xref>] and, indeed, distinctions at a finer grain [<xref ref-type="bibr" rid="pcbi.1004622.ref126">126</xref>], including in relation to possible differences in dopaminergic release [<xref ref-type="bibr" rid="pcbi.1004622.ref127">127</xref>].</p>
</sec>
<sec id="sec030">
<title>Alternative accounts</title>
<p>We noted above that ramping ostensibly disrupts TD’s explanation for dopaminergic release, since it would have, oxymoronically, to be a predictable prediction error. Alternative accounts have been suggested according to which prediction errors indeed persist.</p>
<p>Gershman [<xref ref-type="bibr" rid="pcbi.1004622.ref128">128</xref>] considered the consequences of an unsuitable state representation. The idea is that the exponentially discounted value signal <italic>V</italic><sup><italic>γ</italic></sup>(<italic>s</italic>) cannot be captured in an error-free manner if the state (i.e., the position of the animal) is represented in particular, over-generalizing manners, for instance by units whose activity is governed by the square, rather than linear, distance to the goal. In this case, a ramping prediction error turns out to arise via persistent representational error. Place cells [<xref ref-type="bibr" rid="pcbi.1004622.ref129">129</xref>–<xref ref-type="bibr" rid="pcbi.1004622.ref131">131</xref>] provide an accessibility-sensitive representation of space, and the generalization afforded by the coarse-coding they imply is often useful [<xref ref-type="bibr" rid="pcbi.1004622.ref132">132</xref>]. However, it is also known that Bayesian decoding of even a modest number of such cells leads to surprisingly accurate localization of animals in their environments [<xref ref-type="bibr" rid="pcbi.1004622.ref133">133</xref>], and thus what would amount to a table-lookup representation that would not lead to persistent error. Of course, one must remember that this sort of decoding is <italic>in silico</italic>, rather than <italic>in vivo</italic>.</p>
<p>Morito and Kato [<xref ref-type="bibr" rid="pcbi.1004622.ref134">134</xref>] have also also suggested that the Howe et al. ramping signal reflects persistent prediction errors. In their proposal, these arise out of the assumption of a time-dependent decay of learned state values. One challenge for this model is that its generation of ramping signals qualitatively similar to that observed experimentally appears to be unstable to changes in reward magnitude [<xref ref-type="bibr" rid="pcbi.1004622.ref134">134</xref>], and indeed to the passage of more substantial periods of time.</p>
</sec>
<sec id="sec031">
<title>Experimental tests</title>
<p>The most pressing consideration is a set of experiments that can test and refine or reject these various mechanisms, and understand how they might work together. Perhaps the most straightforward to test is the last suggestion, since it is unique in its dependence on discounting. Given that the rate of this should be sensitive to things like the reliability of the environment [<xref ref-type="bibr" rid="pcbi.1004622.ref135">135</xref>], it would be interesting to manipulate these factors, determine the extent to which behaviour changes appropriately, and concurrently measure ramping. Similarly, it may be that individual differences in discounting, as measured by choices between immediate, smaller rewards and delayed, larger rewards, can be predicted by the rate of ramping. Although behaviour generally follows hyperbolic rather than exponential discounting [<xref ref-type="bibr" rid="pcbi.1004622.ref109">109</xref>], this would only make a modest difference at the timescales that appear relevant for the sort of ramping behaviour observed by Howe et al.</p>
<p>Testing the second suggestion could be accomplished using photo-uncaging of dopamine in the accumbens (for instance, using RuBi-Dopa [<xref ref-type="bibr" rid="pcbi.1004622.ref136">136</xref>]), since of the three mechanisms, it suggests the strongest coupling between dopamine and immediate behaviour. Optogenetically-stimulated release (using TH-CRE or DAT-CRE lines) could also be employed, although it would then be hard to distinguish the specifically dopaminergic component from any other influences of the (potentially antidromically-stimulated) activity of the dopamine neurons. It would be interesting to contrast the results of this with direct stimulation of D1-receptor-containing and D2-receptor-containing neurons [<xref ref-type="bibr" rid="pcbi.1004622.ref137">137</xref>] to try to assess downstream mechanisms.</p>
<p>Testing the relationship between actor and critic is particularly tricky, since we know so little about the implementation (or indeed existence) of either and, in particular, the micro- or nano-scopic nature of choice over time [<xref ref-type="bibr" rid="pcbi.1004622.ref040">40</xref>]. Nevertheless, it would certainly be interesting to compare the nature and magnitude of ramping when subjects are made to wait for shorter or longer times, with and without cues for the precise passage of time that could be exploited.</p>
<p>More generally, key issues surround the relationships between the number of dopamine cells that are active, the phasic and tonic activity of those neurons, the spatiotemporal profile of the concentration of dopamine at receptor targets in the accumbens, and the action of this dopamine on those receptors (along with the action on target neurons of other neurotransmitters co-released by the same neuronal activity). This information is key for making qualitative and ultimately quantitative progress.</p>
</sec>
</sec>
</body>
<back>
<ack>
<p>We are very grateful to Josh Berke, Michael Frank, Sam Gershman, Kyo Iigaya, Mehdi Keramati, and Hiro Nakahara for their helpful comments on previous versions of the manuscript.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1004622.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>A framework for mesencephalic dopamine systems based on predictive hebbian learning</article-title>. <source>The Journal of Neuroscience</source>. <year>1996</year>;<volume>16</volume>(<issue>5</issue>):<fpage>1936</fpage>–<lpage>1947</lpage>. <object-id pub-id-type="pmid">8774460</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A neural substrate of prediction and reward</article-title>. <source>Science</source>. <year>1997</year>;<volume>275</volume>:<fpage>1593</fpage>–<lpage>1599</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.275.5306.1593" xlink:type="simple">10.1126/science.275.5306.1593</ext-link></comment> <object-id pub-id-type="pmid">9054347</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>. <article-title>Learning to predict by the methods of temporal differences</article-title>. <source>Machine Learning</source>. <year>1988</year>;<volume>3</volume>(<issue>1</issue>):<fpage>9</fpage>–<lpage>44</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1023/A:1022633531479" xlink:type="simple">10.1023/A:1022633531479</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref004">
<label>4</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <source>Reinforcement learning: An introduction</source>. <publisher-name>MIT Press</publisher-name>; <year>1998</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clark</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Collins</surname> <given-names>AL</given-names></name>, <name name-style="western"><surname>Sanford</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>PEM</given-names></name>. <article-title>Dopamine encoding of Pavlovian incentive stimuli diminishes with extended training</article-title>. <source>The Journal of Neuroscience</source>. <year>2013</year>;<volume>33</volume>(<issue>8</issue>):<fpage>3526</fpage>–<lpage>3532</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5119-12.2013" xlink:type="simple">10.1523/JNEUROSCI.5119-12.2013</ext-link></comment> <object-id pub-id-type="pmid">23426680</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Day</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Roitman</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>R</given-names></name>. <article-title>Associative learning mediates dynamic shifts in dopamine signaling in the nucleus accumbens</article-title>. <source>Nature Neuroscience</source>. <year>2007</year>;<volume>10</volume>(<issue>8</issue>):<fpage>1020</fpage>–<lpage>1028</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1923" xlink:type="simple">10.1038/nn1923</ext-link></comment> <object-id pub-id-type="pmid">17603481</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Flagel</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Robinson</surname> <given-names>TE</given-names></name>, <name name-style="western"><surname>Mayo</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Czuj</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Willuhn</surname> <given-names>I</given-names></name>, <etal>et al</etal>. <article-title>A selective role for dopamine in stimulus-reward learning</article-title>. <source>Nature</source>. <year>2011</year>;<volume>469</volume>(<issue>7328</issue>):<fpage>53</fpage>–<lpage>57</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature09588" xlink:type="simple">10.1038/nature09588</ext-link></comment> <object-id pub-id-type="pmid">21150898</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Owesson-White</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Ariansen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Stuber</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Cleaveland</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Cheer</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>, <etal>et al</etal>. <article-title>Neural encoding of cocaine-seeking behavior is coincident with phasic dopamine release in the accumbens core and shell</article-title>. <source>European Journal of Neuroscience</source>. <year>2009</year>;<volume>30</volume>:<fpage>1117</fpage>–<lpage>1127</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1460-9568.2009.06916.x" xlink:type="simple">10.1111/j.1460-9568.2009.06916.x</ext-link></comment> <object-id pub-id-type="pmid">19735286</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Phillips</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>Stuber</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Heien</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>. <article-title>Subsecond dopamine release promotes cocaine seeking</article-title>. <source>Nature</source>. <year>2003</year>;<volume>422</volume>:<fpage>614</fpage>–<lpage>618</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature01476" xlink:type="simple">10.1038/nature01476</ext-link></comment> <object-id pub-id-type="pmid">12687000</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roitman</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Stuber</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>PEM</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>. <article-title>Dopamine operates as a subsecond modulator of food seeking</article-title>. <source>The Journal of Neuroscience</source>. <year>2004</year>;<volume>24</volume>(<issue>6</issue>):<fpage>1265</fpage>–<lpage>1271</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3823-03.2004" xlink:type="simple">10.1523/JNEUROSCI.3823-03.2004</ext-link></comment> <object-id pub-id-type="pmid">14960596</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stuber</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Roitman</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>PEM</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>. <article-title>Rapid dopamine signaling in the nucleus accumbens during contingent and noncontingent cocaine administration</article-title>. <source>Neuropsychopharmacology</source>. <year>2005</year>;<volume>30</volume>:<fpage>853</fpage>–<lpage>863</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/sj.npp.1300619" xlink:type="simple">10.1038/sj.npp.1300619</ext-link></comment> <object-id pub-id-type="pmid">15549053</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stuber</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>. <article-title>Extinction of cocaine self-administration reveals functionally and temporally distinct dopaminergic signals in the nucleus accumbens</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>46</volume>(<issue>4</issue>):<fpage>661</fpage>–<lpage>669</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2005.04.036" xlink:type="simple">10.1016/j.neuron.2005.04.036</ext-link></comment> <object-id pub-id-type="pmid">15944133</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wassum</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Ostlund</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Maidment</surname> <given-names>NT</given-names></name>. <article-title>Phasic mesolimbic dopamine signaling precedes and predicts performance of a self-initiated action sequence task</article-title>. <source>Biological Psychiatry</source>. <year>2012</year>;<volume>71</volume>:<fpage>846</fpage>–<lpage>854</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.biopsych.2011.12.019" xlink:type="simple">10.1016/j.biopsych.2011.12.019</ext-link></comment> <object-id pub-id-type="pmid">22305286</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Howe</surname> <given-names>MW</given-names></name>, <name name-style="western"><surname>Tierney</surname> <given-names>PL</given-names></name>, <name name-style="western"><surname>Sandberg</surname> <given-names>SG</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>PEM</given-names></name>, <name name-style="western"><surname>Graybiel</surname> <given-names>AM</given-names></name>. <article-title>Prolonged dopamine signalling in striatum signals proximity and value of distant rewards</article-title>. <source>Nature</source>. <year>2013</year>;<volume>500</volume>:<fpage>575</fpage>–<lpage>579</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature12475" xlink:type="simple">10.1038/nature12475</ext-link></comment> <object-id pub-id-type="pmid">23913271</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>. <article-title>Neuroscience: Dopamine ramps up</article-title>. <source>Nature</source>. <year>2013</year>;<volume>500</volume>:<fpage>533</fpage>–<lpage>535</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/500533a" xlink:type="simple">10.1038/500533a</ext-link></comment> <object-id pub-id-type="pmid">23985866</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref016">
<label>16</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Houk</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <chapter-title>A model of how the basal ganglia generate and use neural signals that predict reinforcement</chapter-title>. In: <name name-style="western"><surname>Houk</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Beiser</surname> <given-names>DG</given-names></name>, editors. <source>Models of Information Processing in the Basal Ganglia</source>. <publisher-name>MIT Press</publisher-name>; <year>1995</year>. p. <fpage>249</fpage>–<lpage>270</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Samuel</surname> <given-names>AL</given-names></name>. <article-title>Some studies in machine learning using the game of checkers</article-title>. <source>IBM Journal on Research and Development</source>. <year>1959</year>;<volume>3</volume>:<fpage>211</fpage>–<lpage>229</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1147/rd.33.0210" xlink:type="simple">10.1147/rd.33.0210</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref018">
<label>18</label>
<mixed-citation publication-type="other" xlink:type="simple">Watkins, CJCH. Learning from Delayed Rewards. PhD Thesis, University of Cambridge. 1989.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sombers</surname> <given-names>LA</given-names></name>, <name name-style="western"><surname>Beyene</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>. <article-title>Synaptic overflow of dopamine in the nucleus accumbens arises from neuronal activity in the ventral tegmental area</article-title>. <source>The Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>6</issue>):<fpage>1735</fpage>–<lpage>1742</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.5562-08.2009" xlink:type="simple">10.1523/JNEUROSCI.5562-08.2009</ext-link></comment> <object-id pub-id-type="pmid">19211880</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>McClure</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Baldwin</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>PEM</given-names></name>, <name name-style="western"><surname>Budygin</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Stuber</surname> <given-names>GD</given-names></name>, <etal>et al</etal>. <article-title>Dynamic gain control of dopamine delivery in freely moving animals</article-title>. <source>The Journal of Neuroscience</source>. <year>2004</year>;<volume>24</volume>(<issue>7</issue>):<fpage>1754</fpage>–<lpage>1759</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4279-03.2004" xlink:type="simple">10.1523/JNEUROSCI.4279-03.2004</ext-link></comment> <object-id pub-id-type="pmid">14973252</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hart</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Rutledge</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>PE</given-names></name>. <article-title>Phasic dopamine release in the rat nucleus accumbens symmetrically encodes a reward prediction error term</article-title>. <source>The Journal of Neuroscience</source>. <year>2014</year>;<volume>34</volume>(<issue>3</issue>):<fpage>698</fpage>–<lpage>704</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2489-13.2014" xlink:type="simple">10.1523/JNEUROSCI.2489-13.2014</ext-link></comment> <object-id pub-id-type="pmid">24431428</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hart</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Clark</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Phillips</surname> <given-names>PEM</given-names></name>. <article-title>Dynamic shaping of dopamine signals during probabilistic Pavlovian conditioning</article-title>. <source>Neurobiology of Learning and Memory</source>. <year>2015</year>;<volume>117</volume>:<fpage>84</fpage>–<lpage>92</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.nlm.2014.07.010" xlink:type="simple">10.1016/j.nlm.2014.07.010</ext-link></comment> <object-id pub-id-type="pmid">25172480</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bayer</surname> <given-names>HM</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Midbrain dopamine neurons encode a quantitative reward prediction error signal</article-title>. <source>Neuron</source>. <year>2005</year>;<volume>47</volume>(<issue>1</issue>):<fpage>129</fpage>–<lpage>141</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2005.05.020" xlink:type="simple">10.1016/j.neuron.2005.05.020</ext-link></comment> <object-id pub-id-type="pmid">15996553</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bayer</surname> <given-names>HM</given-names></name>, <name name-style="western"><surname>Lau</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>. <article-title>Statistics of midbrain dopamine neuron spike trains in the awake primate</article-title>. <source>Journal of Neurophysiology</source>. <year>2007</year>;<volume>98</volume>:<fpage>1428</fpage>–<lpage>1439</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.01140.2006" xlink:type="simple">10.1152/jn.01140.2006</ext-link></comment> <object-id pub-id-type="pmid">17615124</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Duff</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Dopamine, uncertainty and TD learning</article-title>. <source>Behavioral and Brain Functions</source>. <year>2005</year>;<volume>1</volume>(<issue>1</issue>):<fpage>6</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1186/1744-9081-1-6" xlink:type="simple">10.1186/1744-9081-1-6</ext-link></comment> <object-id pub-id-type="pmid">15953384</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Grace</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Floresco</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>Goto</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Lodge</surname> <given-names>DJ</given-names></name>. <article-title>Regulation of firing of dopaminergic neurons and control of goal-directed behaviors</article-title>. <source>Trends in Neurosciences</source>. <year>2007</year>;<volume>30</volume>(<issue>5</issue>):<fpage>220</fpage>–<lpage>227</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tins.2007.03.003" xlink:type="simple">10.1016/j.tins.2007.03.003</ext-link></comment> <object-id pub-id-type="pmid">17400299</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cachope</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Cheer</surname> <given-names>JF</given-names></name>. <article-title>Local control of striatal dopamine release</article-title>. <source>Frontiers in Behavioral Neuroscience</source>. <year>2014</year>;<volume>8</volume>:<fpage>1</fpage>–<lpage>7</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fnbeh.2014.00188" xlink:type="simple">10.3389/fnbeh.2014.00188</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rice</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Patel</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Cragg</surname> <given-names>SJ</given-names></name>. <article-title>Dopamine release in the basal ganglia</article-title>. <source>Neuroscience</source>. <year>2011</year>;<volume>198</volume>:<fpage>112</fpage>–<lpage>137</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuroscience.2011.08.066" xlink:type="simple">10.1016/j.neuroscience.2011.08.066</ext-link></comment> <object-id pub-id-type="pmid">21939738</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref029">
<label>29</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bellman</surname> <given-names>RE</given-names></name>. <source>Dynamic Programming</source>. <publisher-name>Princeton University Press</publisher-name>; <year>1957</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref030">
<label>30</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Howard</surname> <given-names>R</given-names></name>. <source>Dynamic Programming and Markov Processes</source>. <publisher-name>MIT Press</publisher-name>; <year>1960</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>CW</given-names></name>. <article-title>Neuronlike adaptive elements that can solve difficult learning control problems</article-title>. <source>IEEE Transactions on Systems, Man, and Cybernetics</source>. <year>1983</year>;<volume>13</volume>:<fpage>835</fpage>–<lpage>846</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref032">
<label>32</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Barto</surname> <given-names>AG</given-names></name>. <chapter-title>Adaptive critics in the basal ganglia</chapter-title>. In: <name name-style="western"><surname>Houk</surname> <given-names>JC</given-names></name>, <name name-style="western"><surname>Davis</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Beiser</surname> <given-names>D</given-names></name>, editors. <source>Models of Information Processing in the Basal Ganglia</source>. <publisher-name>MIT Press</publisher-name>; <year>1995</year>. p. <fpage>215</fpage>–<lpage>232</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Joel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Ruppin</surname> <given-names>E</given-names></name>. <article-title>Actor-critic models of the basal ganglia: new anatomical and computational perspectives</article-title>. <source>Neural Networks</source>. <year>2002</year>;<volume>15</volume>:<fpage>535</fpage>–<lpage>547</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0893-6080(02)00047-3" xlink:type="simple">10.1016/S0893-6080(02)00047-3</ext-link></comment> <object-id pub-id-type="pmid">12371510</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Suri</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Temporal difference model reproduces predictive neural activity</article-title>. <source>Neural Computation</source>. <year>2001</year>;<volume>13</volume>:<fpage>841</fpage>–<lpage>862</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976601300014376" xlink:type="simple">10.1162/089976601300014376</ext-link></comment> <object-id pub-id-type="pmid">11255572</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref035">
<label>35</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <chapter-title>Actions, Values, and the Basal Ganglia</chapter-title>. In: <name name-style="western"><surname>Bezard</surname> <given-names>E</given-names></name>, editor. <source>Recent Breakthroughs in Basal Ganglia Research</source>. <publisher-name>Nova Science Publishers</publisher-name>; <year>2006</year>. p. <fpage>91</fpage>–<lpage>106</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>O’Doherty</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Deichmann</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>RJ</given-names></name>. <article-title>Dissociable roles of ventral and dorsal striatum in instrumental conditioning</article-title>. <source>Science</source>. <year>2004</year>;<volume>304</volume>:<fpage>452</fpage>–<lpage>454</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1094285" xlink:type="simple">10.1126/science.1094285</ext-link></comment> <object-id pub-id-type="pmid">15087550</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref037">
<label>37</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cardinal</surname> <given-names>RN</given-names></name>, <name name-style="western"><surname>Parkinson</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Hall</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Everitt</surname> <given-names>BJ</given-names></name>. <article-title>Emotion and motivation: the role of the amygdala, ventral striatum, and prefrontal cortex</article-title>. <source>Neuroscience &amp; Biobehavioral Reviews</source>. <year>2002</year>;<volume>26</volume>(<issue>3</issue>):<fpage>321</fpage>–<lpage>352</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0149-7634(02)00007-6" xlink:type="simple">10.1016/S0149-7634(02)00007-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Packard</surname> <given-names>MG</given-names></name>, <name name-style="western"><surname>Knowlton</surname> <given-names>BJ</given-names></name>. <article-title>Learning and memory functions of the basal ganglia</article-title>. <source>Annual Review of Neuroscience</source>. <year>2002</year>;<volume>25</volume>(<issue>1</issue>):<fpage>563</fpage>–<lpage>593</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.25.112701.142937" xlink:type="simple">10.1146/annurev.neuro.25.112701.142937</ext-link></comment> <object-id pub-id-type="pmid">12052921</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Joel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Tonic dopamine: opportunity costs and the control of response vigor</article-title>. <source>Psychopharmacology</source>. <year>2007</year>;<volume>191</volume>(<issue>3</issue>):<fpage>507</fpage>–<lpage>520</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00213-006-0502-4" xlink:type="simple">10.1007/s00213-006-0502-4</ext-link></comment> <object-id pub-id-type="pmid">17031711</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Niyogi</surname> <given-names>RK</given-names></name>, <name name-style="western"><surname>Breton</surname> <given-names>YA</given-names></name>, <name name-style="western"><surname>Solomon</surname> <given-names>RB</given-names></name>, <name name-style="western"><surname>Conover</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Shizgal</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Optimal indolence: a normative microscopic approach to work and leisure</article-title>. <source>Journal of the Royal Society Interface</source>. <year>2014</year>;<volume>11</volume>:<fpage>20130969</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsif.2013.0969" xlink:type="simple">10.1098/rsif.2013.0969</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Instrumental vigour in punishment and reward</article-title>. <source>European Journal of Neuroscience</source>. <year>2012</year>;<volume>35</volume>(<issue>7</issue>):<fpage>1152</fpage>–<lpage>1168</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1460-9568.2012.08026.x" xlink:type="simple">10.1111/j.1460-9568.2012.08026.x</ext-link></comment> <object-id pub-id-type="pmid">22487044</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref042">
<label>42</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Puterman</surname> <given-names>ML</given-names></name>. <source>Markov decision processes: Discrete stochastic dynamic programming</source>. <publisher-name>Wiley</publisher-name>; <year>1994</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mahadevan</surname> <given-names>S</given-names></name>. <article-title>Average reward reinforcement learning: Foundations, algorithms, and empirical results</article-title>. <source>Machine Learning</source>. <year>1996</year>;<volume>22</volume>:<fpage>159</fpage>–<lpage>196</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00114727" xlink:type="simple">10.1007/BF00114727</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Joel</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>A normative perspective on motivation</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2006</year>;<volume>10</volume>(<issue>8</issue>):<fpage>375</fpage>–<lpage>381</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.tics.2006.06.010" xlink:type="simple">10.1016/j.tics.2006.06.010</ext-link></comment> <object-id pub-id-type="pmid">16843041</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Salamone</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Correa</surname> <given-names>M</given-names></name>. <article-title>The mysterious motivational functions of mesolimbic dopamine</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>76</volume>:<fpage>470</fpage>–<lpage>485</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.10.021" xlink:type="simple">10.1016/j.neuron.2012.10.021</ext-link></comment> <object-id pub-id-type="pmid">23141060</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref046">
<label>46</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Beierholm</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Guitart-Masip</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Economides</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Chowdhury</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Düzel</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>R</given-names></name>, <etal>et al</etal>. <article-title>Dopamine modulates reward-related vigor</article-title>. <source>Neuropsychopharmacology</source>. <year>2013</year>;<volume>38</volume>:<fpage>1495</fpage>–<lpage>1503</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/npp.2013.48" xlink:type="simple">10.1038/npp.2013.48</ext-link></comment> <object-id pub-id-type="pmid">23419875</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Guitart-Masip</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name>, <name name-style="western"><surname>Dolan</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Duzel</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Vigor in the face of fluctuating rates of reward: an experimental examination</article-title>. <source>Journal of Cognitive Neuroscience</source>. <year>2011</year>;<volume>23</volume>(<issue>12</issue>):<fpage>3933</fpage>–<lpage>3938</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/jocn_a_00090" xlink:type="simple">10.1162/jocn_a_00090</ext-link></comment> <object-id pub-id-type="pmid">21736459</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Courville</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Touretzky</surname> <given-names>DS</given-names></name>. <article-title>Representation and timing in theories of the dopamine system</article-title>. <source>Neural Computation</source>. <year>2006</year>;<volume>18</volume>:<fpage>1637</fpage>–<lpage>1677</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2006.18.7.1637" xlink:type="simple">10.1162/neco.2006.18.7.1637</ext-link></comment> <object-id pub-id-type="pmid">16764517</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nakahara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Kaveri</surname> <given-names>S</given-names></name>. <article-title>Internal-time temporal difference model for neural value-based decision making</article-title>. <source>Neural Computation</source>. <year>2010</year>;<volume>22</volume>:<fpage>3062</fpage>–<lpage>3106</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00049" xlink:type="simple">10.1162/NECO_a_00049</ext-link></comment> <object-id pub-id-type="pmid">20858126</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Libet</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gleason</surname> <given-names>CA</given-names></name>, <name name-style="western"><surname>Wright</surname> <given-names>EW</given-names></name>, <name name-style="western"><surname>Pearl</surname> <given-names>DK</given-names></name>. <article-title>Time of conscious intention to act in relation to onset of cerebral activity (readiness-potential)</article-title>. <source>Brain</source>. <year>1983</year>;<volume>106</volume>(<issue>3</issue>):<fpage>623</fpage>–<lpage>642</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/brain/106.3.623" xlink:type="simple">10.1093/brain/106.3.623</ext-link></comment> <object-id pub-id-type="pmid">6640273</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Landry</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Kitai</surname> <given-names>S</given-names></name>. <article-title>Morphological and electrophysiological characteristics of pyramidal tract neurons in the rat</article-title>. <source>Experimental Brain Research</source>. <year>1984</year>;<volume>57</volume>(<issue>1</issue>):<fpage>177</fpage>–<lpage>190</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00231144" xlink:type="simple">10.1007/BF00231144</ext-link></comment> <object-id pub-id-type="pmid">6097471</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lévesque</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Charara</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gagnon</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Parent</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Deschênes</surname> <given-names>M</given-names></name>. <article-title>Corticostriatal projections from layer V cells in rat are collaterals of long-range corticofugal axons</article-title>. <source>Brain Research</source>. <year>1996</year>;<volume>709</volume>(<issue>2</issue>):<fpage>311</fpage>–<lpage>315</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0006-8993(95)01333-4" xlink:type="simple">10.1016/0006-8993(95)01333-4</ext-link></comment> <object-id pub-id-type="pmid">8833768</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lei</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Jiao</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Del Mar</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Reiner</surname> <given-names>A</given-names></name>. <article-title>Evidence for differential cortical input to direct pathway versus indirect pathway striatal projection neurons in rats</article-title>. <source>The Journal of Neuroscience</source>. <year>2004</year>;<volume>24</volume>(<issue>38</issue>):<fpage>8289</fpage>–<lpage>8299</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1990-04.2004" xlink:type="simple">10.1523/JNEUROSCI.1990-04.2004</ext-link></comment> <object-id pub-id-type="pmid">15385612</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Alexander</surname> <given-names>GE</given-names></name>, <name name-style="western"><surname>DeLong</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Strick</surname> <given-names>PL</given-names></name>. <article-title>Parallel organization of functionally segregated circuits linking basal ganglia and cortex</article-title>. <source>Annual Review of Neuroscience</source>. <year>1986</year>;<volume>9</volume>:<fpage>357</fpage>–<lpage>381</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.ne.09.030186.002041" xlink:type="simple">10.1146/annurev.ne.09.030186.002041</ext-link></comment> <object-id pub-id-type="pmid">3085570</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Role of primate basal ganglia and frontal cortex in the internal generation of movements III. Neuronal activity in the supplementary motor area</article-title>. <source>Experimental Brain Research</source>. <year>1992</year>;<volume>91</volume>(<issue>3</issue>):<fpage>396</fpage>–<lpage>407</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00227835" xlink:type="simple">10.1007/BF00227835</ext-link></comment> <object-id pub-id-type="pmid">1483514</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haber</surname> <given-names>SN</given-names></name>. <article-title>The primate basal ganglia: parallel and integrative networks</article-title>. <source>Journal of Chemical Neuroanatomy</source>. <year>2003</year>;<volume>26</volume>:<fpage>317</fpage>–<lpage>330</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jchemneu.2003.10.003" xlink:type="simple">10.1016/j.jchemneu.2003.10.003</ext-link></comment> <object-id pub-id-type="pmid">14729134</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kornhuber</surname> <given-names>HH</given-names></name>, <name name-style="western"><surname>Deecke</surname> <given-names>L</given-names></name>. <article-title>Hirnpotentialänderungen bei Willkürbewegungen und passiven Bewegungen des Menschen: Bereitschaftspotential und reafferente Potentiale</article-title>. <source>Pflüger’s Archiv für die gesamte Physiologie des Menschen und der Tiere</source>. <year>1965</year>;<volume>284</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>17</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00412364" xlink:type="simple">10.1007/BF00412364</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref058">
<label>58</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Libet</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wright</surname> <given-names>EW</given-names></name>, <name name-style="western"><surname>Gleason</surname> <given-names>CA</given-names></name>. <article-title>Readiness potential preceding unrestricted ‘spontaneous’ vs. pre-planned voluntary acts</article-title>. <source>Electroencephalography and Clinical Neurophysiology</source>. <year>1982</year>;<volume>54</volume>:<fpage>322</fpage>–<lpage>335</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0013-4694(82)90181-X" xlink:type="simple">10.1016/0013-4694(82)90181-X</ext-link></comment> <object-id pub-id-type="pmid">6179759</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gibbon</surname> <given-names>J</given-names></name>. <article-title>Scalar expectancy theory and Weber’s law in animal timing</article-title>. <source>Psychological Review</source>. <year>1977</year>;<volume>84</volume>(<issue>3</issue>):<fpage>279</fpage>–<lpage>325</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.84.3.279" xlink:type="simple">10.1037/0033-295X.84.3.279</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Kakade</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Opponent interactions between serotonin and dopamine</article-title>. <source>Neural Networks</source>. <year>2002</year>;<volume>15</volume>:<fpage>603</fpage>–<lpage>616</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0893-6080(02)00052-7" xlink:type="simple">10.1016/S0893-6080(02)00052-7</ext-link></comment> <object-id pub-id-type="pmid">12371515</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bromberg-Martin</surname> <given-names>ES</given-names></name>, <name name-style="western"><surname>Matsumoto</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hikosaka</surname> <given-names>O</given-names></name>. <article-title>Distinct tonic and phasic anticipatory activity in lateral habenula and dopamine neurons</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>67</volume>:<fpage>144</fpage>–<lpage>155</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2010.06.016" xlink:type="simple">10.1016/j.neuron.2010.06.016</ext-link></comment> <object-id pub-id-type="pmid">20624598</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fiorillo</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Newsome</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>The temporal precision of reward prediction in dopamine neurons</article-title>. <source>Nature Neuroscience</source>. <year>2008</year>;<volume>11</volume>:<fpage>966</fpage>–<lpage>973</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.2159" xlink:type="simple">10.1038/nn.2159</ext-link></comment> <object-id pub-id-type="pmid">18660807</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pasquereau</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>RS</given-names></name>. <article-title>Dopamine neurons encode errors in predicting movement trigger occurrence</article-title>. <source>Journal of Neurophysiology</source>. <year>2015</year>;<volume>113</volume>(<issue>4</issue>):<fpage>1110</fpage>–<lpage>1123</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00401.2014" xlink:type="simple">10.1152/jn.00401.2014</ext-link></comment> <object-id pub-id-type="pmid">25411459</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nicola</surname> <given-names>SM</given-names></name>. <article-title>The flexible approach hypothesis: unification of effort and cue-responding hypotheses for the role of nucleus accumbens dopamine in the activation of reward-seeking behavior</article-title>. <source>The Journal of Neuroscience</source>. <year>2010</year>;<volume>30</volume>(<issue>49</issue>):<fpage>16585</fpage>–<lpage>600</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3958-10.2010" xlink:type="simple">10.1523/JNEUROSCI.3958-10.2010</ext-link></comment> <object-id pub-id-type="pmid">21147998</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>McClure</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>. <article-title>A computational substrate for incentive salience</article-title>. <source>Trends in Neurosciences</source>. <year>2003</year>;<volume>26</volume>(<issue>8</issue>):<fpage>423</fpage>–<lpage>428</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0166-2236(03)00177-2" xlink:type="simple">10.1016/S0166-2236(03)00177-2</ext-link></comment> <object-id pub-id-type="pmid">12900173</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Person</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sejnowski</surname> <given-names>TJ</given-names></name>. <article-title>Bee foraging in uncertain environments using predictive Hebbian learning</article-title>. <source>Nature</source>. <year>1995</year>;<volume>377</volume>:<fpage>725</fpage>–<lpage>728</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/377725a0" xlink:type="simple">10.1038/377725a0</ext-link></comment> <object-id pub-id-type="pmid">7477260</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Montague</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Hyman</surname> <given-names>SE</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>Computational roles for dopamine in behavioural control</article-title>. <source>Nature</source>. <year>2004</year>;<volume>431</volume>:<fpage>760</fpage>–<lpage>767</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature03015" xlink:type="simple">10.1038/nature03015</ext-link></comment> <object-id pub-id-type="pmid">15483596</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barnard</surname> <given-names>GA</given-names></name>. <article-title>Sequential tests in industrial statistics</article-title>. <source>Supplement to the Journal of the Royal Statistical Society</source>. <year>1946</year>;<volume>8</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>26</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/2983610" xlink:type="simple">10.2307/2983610</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref069">
<label>69</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Wald</surname> <given-names>A</given-names></name>. <source>Sequential analysis</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Wiley</publisher-name>; <year>1947</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gold</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Shadlen</surname> <given-names>MN</given-names></name>. <article-title>The neural basis of decision making</article-title>. <source>Annual Reviews Neuroscience</source>. <year>2007</year>;<volume>30</volume>:<fpage>535</fpage>–<lpage>574</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.29.051605.113038" xlink:type="simple">10.1146/annurev.neuro.29.051605.113038</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>. <article-title>A theory of memory retrieval</article-title>. <source>Psychological Review</source>. <year>1978</year>;<volume>85</volume>:<fpage>59</fpage>–<lpage>108</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.85.2.59" xlink:type="simple">10.1037/0033-295X.85.2.59</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Krajbich</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Rangel</surname> <given-names>A</given-names></name>. <article-title>Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions</article-title>. <source>Proceedings of the National Academy of Sciences of the USA</source>. <year>2011</year>;<volume>108</volume>(<issue>33</issue>):<fpage>13852</fpage>–<lpage>13857</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1101328108" xlink:type="simple">10.1073/pnas.1101328108</ext-link></comment> <object-id pub-id-type="pmid">21808009</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bogacz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Moehlis</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Holmes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks</article-title>. <source>Psychological Review</source>. <year>2006</year>;<volume>113</volume>(<issue>4</issue>):<fpage>700</fpage>–<lpage>765</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.113.4.700" xlink:type="simple">10.1037/0033-295X.113.4.700</ext-link></comment> <object-id pub-id-type="pmid">17014301</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref074">
<label>74</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Laming</surname> <given-names>DRJ</given-names></name>. <source>Information theory of choice-reaction times</source>. <publisher-name>Wiley</publisher-name>; <year>1968</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stone</surname> <given-names>M</given-names></name>. <article-title>Models for choice reaction time</article-title>. <source>Psychometrika</source>. <year>1960</year>;<volume>25</volume>:<fpage>251</fpage>–<lpage>260</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF02289729" xlink:type="simple">10.1007/BF02289729</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Usher</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>McClelland</surname> <given-names>JL</given-names></name>. <article-title>The time course of perceptual choice: the leaky, competing accumulator model</article-title>. <source>Psychological Review</source>. <year>2001</year>;<volume>108</volume>(<issue>3</issue>):<fpage>550</fpage>–<lpage>592</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/0033-295X.108.3.550" xlink:type="simple">10.1037/0033-295X.108.3.550</ext-link></comment> <object-id pub-id-type="pmid">11488378</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref077">
<label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wang</surname> <given-names>XJ</given-names></name>. <article-title>Probabilistic decision making by slow reverberation in cortical circuits</article-title>. <source>Neuron</source>. <year>2002</year>;<volume>36</volume>(<issue>5</issue>):<fpage>955</fpage>–<lpage>968</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0896-6273(02)01092-9" xlink:type="simple">10.1016/S0896-6273(02)01092-9</ext-link></comment> <object-id pub-id-type="pmid">12467598</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref078">
<label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nicola</surname> <given-names>SM</given-names></name>, <name name-style="western"><surname>Surmeier</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Malenka</surname> <given-names>RC</given-names></name>. <article-title>Dopaminergic modulation of neuronal excitability in the striatum and nucleus accumbens</article-title>. <source>Annual Review of Neuroscience</source>. <year>2000</year>;<volume>23</volume>:<fpage>185</fpage>–<lpage>215</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.23.1.185" xlink:type="simple">10.1146/annurev.neuro.23.1.185</ext-link></comment> <object-id pub-id-type="pmid">10845063</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Servan-Schreiber</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Printz</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>A network model of catecholamine effects: Gain, signal-to-noise ratio, and behavior</article-title>. <source>Science</source>. <year>1990</year>;<volume>249</volume>:<fpage>892</fpage>–<lpage>895</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.2392679" xlink:type="simple">10.1126/science.2392679</ext-link></comment> <object-id pub-id-type="pmid">2392679</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref080">
<label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Gilzenrat</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>Optimization of decision making in multilayer networks: the role of the locus coeruleus</article-title>. <source>Neural Computation</source>. <year>2008</year>;<volume>20</volume>:<fpage>2863</fpage>–<lpage>2894</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.03-07-487" xlink:type="simple">10.1162/neco.2008.03-07-487</ext-link></comment> <object-id pub-id-type="pmid">18624653</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref081">
<label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>Dynamic dopamine modulation in the basal ganglia: A neurocomputational account of cognitive deficits in medicated and nonmedicated Parkinsonism</article-title>. <source>Journal of Cognitive Neuroscience</source>. <year>2005</year>;<volume>17</volume>(<issue>1</issue>):<fpage>51</fpage>–<lpage>72</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/0898929052880093" xlink:type="simple">10.1162/0898929052880093</ext-link></comment> <object-id pub-id-type="pmid">15701239</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref082">
<label>82</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Moehlis</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Bogacz</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Holmes</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>. <article-title>Optimizing reward rate in two alternative choice tasks: mathematical formalism</article-title>. <source>Technical Report</source>, <publisher-name>Princeton University</publisher-name>; <year>2004</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref083">
<label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Satoh</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Nakai</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Sato</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Kimura</surname> <given-names>M</given-names></name>. <article-title>Correlated coding of motivation and outcome of decision by dopamine neurons</article-title>. <source>The Journal of Neuroscience</source>. <year>2003</year>;<volume>23</volume>(<issue>30</issue>):<fpage>9913</fpage>–<lpage>9923</lpage>. <object-id pub-id-type="pmid">14586021</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref084">
<label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daw</surname> <given-names>ND</given-names></name>, <name name-style="western"><surname>Niv</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title>. <source>Nature Neuroscience</source>. <year>2005</year> <month>Dec</month>;<volume>8</volume>(<issue>12</issue>):<fpage>1704</fpage>–<lpage>11</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1560" xlink:type="simple">10.1038/nn1560</ext-link></comment> <object-id pub-id-type="pmid">16286932</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref085">
<label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hamid</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Pettibone</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Mabrouk</surname> <given-names>OS</given-names></name>, <name name-style="western"><surname>Hetrick</surname> <given-names>VL</given-names></name>, <name name-style="western"><surname>Schmidt</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Vander Weele</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Kennedy</surname> <given-names>RT</given-names></name>, <name name-style="western"><surname>Aragona</surname> <given-names>BJ</given-names></name>, and <name name-style="western"><surname>Berke</surname> <given-names>JD</given-names></name>. <article-title>Mesolimbic dopamine signals the value of work</article-title>. <source>Nature Neuroscience</source>. <year>2015</year>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.4173" xlink:type="simple">10.1038/nn.4173</ext-link></comment> <object-id pub-id-type="pmid">26595651</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref086">
<label>86</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bertsekas</surname> <given-names>DP</given-names></name>. <source>Dynamic Programming and Optimal Control</source>, <volume>Vol.II</volume>, <edition>3rd Edition</edition>. <publisher-name>Athena Scientific</publisher-name>; <year>2007</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref087">
<label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Doya</surname> <given-names>K</given-names></name>. <article-title>Reinforcement learning in continuous time and space</article-title>. <source>Neural Computation</source>. <year>2000</year>;<volume>12</volume>:<fpage>219</fpage>–<lpage>245</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976600300015961" xlink:type="simple">10.1162/089976600300015961</ext-link></comment> <object-id pub-id-type="pmid">10636940</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref088">
<label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Heien</surname> <given-names>ML</given-names></name>, <name name-style="western"><surname>Wassum</surname> <given-names>KM</given-names></name>, <name name-style="western"><surname>Sombers</surname> <given-names>LA</given-names></name>, <name name-style="western"><surname>Aragona</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Khan</surname> <given-names>AS</given-names></name>, <etal>et al</etal>. <article-title>Dopamine release is heterogeneous within microenvironments of the rat nucleus accumbens</article-title>. <source>European Journal of Neuroscience</source>. <year>2007</year>;<volume>26</volume>(<issue>7</issue>):<fpage>2046</fpage>–<lpage>2054</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1460-9568.2007.05772.x" xlink:type="simple">10.1111/j.1460-9568.2007.05772.x</ext-link></comment> <object-id pub-id-type="pmid">17868375</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref089">
<label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kobayashi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Influence of reward delays on responses of dopamine neurons</article-title>. <source>The Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>(<issue>31</issue>):<fpage>7837</fpage>–<lpage>7846</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1600-08.2008" xlink:type="simple">10.1523/JNEUROSCI.1600-08.2008</ext-link></comment> <object-id pub-id-type="pmid">18667616</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref090">
<label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ljungberg</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Apicella</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Responses of monkey dopamine neurons during learning of behavioural reactions</article-title>. <source>Journal of Neurophysiology</source>. <year>1992</year>;<volume>67</volume>(<issue>1</issue>):<fpage>145</fpage>–<lpage>163</lpage>. <object-id pub-id-type="pmid">1552316</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref091">
<label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Dopamine neurons of the monkey midbrain: contingencies of response to active touch during self-initiated arm movements</article-title>. <source>Journal of Neurophysiology</source>. <year>1990</year>;<volume>63</volume>(<issue>3</issue>):<fpage>592</fpage>–<lpage>606</lpage>. <object-id pub-id-type="pmid">2329363</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref092">
<label>92</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>. <article-title>Neuronal activity in the monkey striatum during the initiation of movements</article-title>. <source>Experimental Brain Research</source>. <year>1988</year>;<volume>71</volume>:<fpage>431</fpage>–<lpage>436</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00247503" xlink:type="simple">10.1007/BF00247503</ext-link></comment> <object-id pub-id-type="pmid">3169174</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref093">
<label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Romo</surname> <given-names>R</given-names></name>. <article-title>Role of primate basal ganglia and frontal cortex in the internal generation of movements I. Preparatory activity in the anterior striatum</article-title>. <source>Experimental Brain Research</source>. <year>1992</year>;<volume>91</volume>(<issue>3</issue>):<fpage>363</fpage>–<lpage>384</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00227834" xlink:type="simple">10.1007/BF00227834</ext-link></comment> <object-id pub-id-type="pmid">1483512</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref094">
<label>94</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Khamassi</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Mulder</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Tabuchi</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Douchamps</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Wiener</surname> <given-names>SI</given-names></name>. <article-title>Anticipatory reward signals in ventral striatal neurons of behaving rats</article-title>. <source>European Journal of Neuroscience</source>. <year>2008</year>;<volume>28</volume>:<fpage>1849</fpage>–<lpage>1866</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1460-9568.2008.06480.x" xlink:type="simple">10.1111/j.1460-9568.2008.06480.x</ext-link></comment> <object-id pub-id-type="pmid">18973599</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref095">
<label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van der Meer</surname> <given-names>MAA</given-names></name>, <name name-style="western"><surname>Redish</surname> <given-names>AD</given-names></name>. <article-title>Theta phase precession in rat ventral striatum links place and reward information</article-title>. <source>The Journal of Neuroscience</source>. <year>2011</year> <month>Feb</month>;<volume>31</volume>(<issue>8</issue>):<fpage>2843</fpage>–<lpage>2854</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.4869-10.2011" xlink:type="simple">10.1523/JNEUROSCI.4869-10.2011</ext-link></comment> <object-id pub-id-type="pmid">21414906</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref096">
<label>96</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cheer</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Heien</surname> <given-names>MLAV</given-names></name>, <name name-style="western"><surname>Garris</surname> <given-names>PA</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>. <article-title>Simultaneous dopamine and single-unit recordings reveal accumbens GABAergic responses: implications for intracranial self-stimulation</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source>. <year>2005</year>;<volume>102</volume>(<issue>52</issue>):<fpage>19150</fpage>–<lpage>19155</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0509607102" xlink:type="simple">10.1073/pnas.0509607102</ext-link></comment> <object-id pub-id-type="pmid">16380429</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref097">
<label>97</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cheer</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Aragona</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Heien</surname> <given-names>MLAV</given-names></name>, <name name-style="western"><surname>Seipel</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>. <article-title>Coordinated accumbal dopamine release and neural activity drive goal-directed behavior</article-title>. <source>Neuron</source>. <year>2007</year>;<volume>54</volume>:<fpage>237</fpage>–<lpage>244</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2007.03.021" xlink:type="simple">10.1016/j.neuron.2007.03.021</ext-link></comment> <object-id pub-id-type="pmid">17442245</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref098">
<label>98</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cacciapaglia</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Wightman</surname> <given-names>RM</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>. <article-title>Rapid dopamine signaling differentially modulates distinct microcircuits within the nucleus accumbens during sucrose-directed behavior</article-title>. <source>The Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>39</issue>):<fpage>13860</fpage>–<lpage>13869</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1340-11.2011" xlink:type="simple">10.1523/JNEUROSCI.1340-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21957248</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref099">
<label>99</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ludvig</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>Sutton</surname> <given-names>RS</given-names></name>, <name name-style="western"><surname>Kehoe</surname> <given-names>EJ</given-names></name>. <article-title>Stimulus representation and the timing of reward-prediction errors in models of the dopamine system</article-title>. <source>Neural Computation</source>. <year>2008</year>;<volume>20</volume>:<fpage>3034</fpage>–<lpage>3054</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.11-07-654" xlink:type="simple">10.1162/neco.2008.11-07-654</ext-link></comment> <object-id pub-id-type="pmid">18624657</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref100">
<label>100</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rivest</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Kalaska</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Bengio</surname> <given-names>Y</given-names></name>. <article-title>Alternative time representation in dopamine models</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2010</year>;<volume>28</volume>(<issue>1</issue>):<fpage>107</fpage>–<lpage>130</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-009-0191-1" xlink:type="simple">10.1007/s10827-009-0191-1</ext-link></comment> <object-id pub-id-type="pmid">19847635</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref101">
<label>101</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Suri</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>A neural network model with dopamine-like reinforcement signal that learns a spatial delayed response task</article-title>. <source>Neuroscience</source>. <year>1999</year>;<volume>91</volume>(<issue>3</issue>):<fpage>871</fpage>–<lpage>890</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0306-4522(98)00697-6" xlink:type="simple">10.1016/S0306-4522(98)00697-6</ext-link></comment> <object-id pub-id-type="pmid">10391468</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref102">
<label>102</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Moustafa</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Ludvig</surname> <given-names>EA</given-names></name>. <article-title>Time representation in reinforcement learning models of the basal ganglia</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2013</year>;<volume>7</volume>:<fpage>194</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref103">
<label>103</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Buhusi</surname> <given-names>CV</given-names></name>, <name name-style="western"><surname>Meck</surname> <given-names>WH</given-names></name>. <article-title>What makes us tick? Functional and neural mechanisms of interval timing</article-title>. <source>Nature Reviews Neuroscience</source>. <year>2005</year>;<volume>6</volume>:<fpage>755</fpage>–<lpage>765</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn1764" xlink:type="simple">10.1038/nrn1764</ext-link></comment> <object-id pub-id-type="pmid">16163383</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref104">
<label>104</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Clayton</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Rajkowski</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Cohen</surname> <given-names>JD</given-names></name>, <name name-style="western"><surname>Aston-Jones</surname> <given-names>G</given-names></name>. <article-title>Phasic activation of monkey locus ceruleus neurons by simple decisions in a forced-choice task</article-title>. <source>The Journal of Neuroscience</source>. <year>2004</year>;<volume>24</volume>:<fpage>9914</fpage>–<lpage>9920</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2446-04.2004" xlink:type="simple">10.1523/JNEUROSCI.2446-04.2004</ext-link></comment> <object-id pub-id-type="pmid">15525776</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref105">
<label>105</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ratcliff</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>Reinforcement-based decision making in corticostriatal circuits: mutual constraints by neurocomputational and diffusion models</article-title>. <source>Neural Computation</source>. <year>2012</year>;<volume>24</volume>:<fpage>1186</fpage>–<lpage>1229</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00270" xlink:type="simple">10.1162/NECO_a_00270</ext-link></comment> <object-id pub-id-type="pmid">22295983</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref106">
<label>106</label>
<mixed-citation publication-type="other" xlink:type="simple">
Wiecki TV. Computational psychiatry: Combining multiple levels of analysis to understand brain disorders. PhD Thesis, Brown University; 2015.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref107">
<label>107</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Collins</surname> <given-names>AGE</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>MJ</given-names></name>. <article-title>Opponent Actor Learning (OpAL): modeling interactive effects of striatal dopamine on reinforcement learning and choice incentive</article-title>. <source>Psychological Review</source>. <year>2014</year>;<volume>121</volume>(<issue>3</issue>):<fpage>337</fpage>–<lpage>366</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1037/a0037015" xlink:type="simple">10.1037/a0037015</ext-link></comment> <object-id pub-id-type="pmid">25090423</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref108">
<label>108</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ainslie</surname> <given-names>GW</given-names></name>. <article-title>Impulse control in pigeons</article-title>. <source>Journal of the Experimental Analysis of Behavior</source>. <year>1974</year>;<volume>21</volume>(<issue>3</issue>):<fpage>485</fpage>–<lpage>489</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1901/jeab.1974.21-485" xlink:type="simple">10.1901/jeab.1974.21-485</ext-link></comment> <object-id pub-id-type="pmid">16811760</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref109">
<label>109</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Ainslie</surname> <given-names>G</given-names></name>. <source>Breakdown of Will</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>2001</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref110">
<label>110</label>
<mixed-citation publication-type="other" xlink:type="simple">Sorg J, Singh SP, Lewis RL. Internal rewards mitigate agent boundedness. In: Proceedings of the 27th International Conference on Machine Learning; 2010. p. 1007–1014.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref111">
<label>111</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wilson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Daly</surname> <given-names>M</given-names></name>. <article-title>Do pretty women inspire men to discount the future?</article-title> <source>Proceedings of the Royal Society of London B: Biological Sciences</source>. <year>2004</year>;<volume>271</volume>(<issue>Suppl 4</issue>):<fpage>S177</fpage>–<lpage>S179</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsbl.2003.0134" xlink:type="simple">10.1098/rsbl.2003.0134</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref112">
<label>112</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schweighofer</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Shishida</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Han</surname> <given-names>CE</given-names></name>, <name name-style="western"><surname>Okamoto</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Tanaka</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Yamawaki</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Humans can adopt optimal discounting strategy under real-time constraints</article-title>. <source>PLOS Computational Biology</source>. <year>2006</year>;<volume>2</volume>(<issue>11</issue>):<fpage>e152</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.0020152" xlink:type="simple">10.1371/journal.pcbi.0020152</ext-link></comment> <object-id pub-id-type="pmid">17096592</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref113">
<label>113</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tanaka</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Doya</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Okada</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Ueda</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Okamoto</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Yamawaki</surname> <given-names>S</given-names></name>. <article-title>Prediction of immediate and future rewards differentially recruits cortico-basal ganglia loops</article-title>. <source>Nature Neuroscience</source>. <year>2004</year>;<volume>7</volume>(<issue>8</issue>):<fpage>887</fpage>–<lpage>893</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1279" xlink:type="simple">10.1038/nn1279</ext-link></comment> <object-id pub-id-type="pmid">15235607</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref114">
<label>114</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tanaka</surname> <given-names>SC</given-names></name>, <name name-style="western"><surname>Schweighofer</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Asahi</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Shishida</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Okamoto</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Yamawaki</surname> <given-names>S</given-names></name>, <etal>et al</etal>. <article-title>Serotonin differentially regulates short-and long-term prediction of rewards in the ventral and dorsal striatum</article-title>. <source>PLOS One</source>. <year>2007</year>;<volume>2</volume>(<issue>12</issue>):<fpage>e1333</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0001333" xlink:type="simple">10.1371/journal.pone.0001333</ext-link></comment> <object-id pub-id-type="pmid">18091999</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref115">
<label>115</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Floresco</surname> <given-names>SB</given-names></name>, <name name-style="western"><surname>West</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Ash</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Grace</surname> <given-names>AA</given-names></name>. <article-title>Afferent modulation of dopamine neuron firing differentially regulates tonic and phasic dopamine transmission</article-title>. <source>Nature Neuroscience</source>. <year>2003</year>;<volume>6</volume>(<issue>9</issue>):<fpage>968</fpage>–<lpage>973</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1103" xlink:type="simple">10.1038/nn1103</ext-link></comment> <object-id pub-id-type="pmid">12897785</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref116">
<label>116</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Grace</surname> <given-names>AA</given-names></name>. <article-title>Phasic versus tonic dopamine release and the modulation of dopamine system responsivity: a hypothesis for the etiology of schizophrenia</article-title>. <source>Neuroscience</source>. <year>1991</year>;<volume>41</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>24</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0306-4522(91)90196-U" xlink:type="simple">10.1016/0306-4522(91)90196-U</ext-link></comment> <object-id pub-id-type="pmid">1676137</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref117">
<label>117</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fiorillo</surname> <given-names>CD</given-names></name>, <name name-style="western"><surname>Tobler</surname> <given-names>PN</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>W</given-names></name>. <article-title>Discrete coding of reward probability and uncertainty by dopamine neurons</article-title>. <source>Science</source>. <year>2003</year>;<volume>299</volume>:<fpage>1898</fpage>–<lpage>1902</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1077349" xlink:type="simple">10.1126/science.1077349</ext-link></comment> <object-id pub-id-type="pmid">12649484</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref118">
<label>118</label>
<mixed-citation publication-type="other" xlink:type="simple">Fiorillo CD, Tobler PN, Schultz W. Evidence that the delay-period activity of dopamine neurons corresponds to reward uncertainty rather than backpropagating TD errors. Behavioral and Brain Functions. 2005;.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref119">
<label>119</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Threlfell</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lalic</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Platt</surname> <given-names>NJ</given-names></name>, <name name-style="western"><surname>Jennings</surname> <given-names>KA</given-names></name>, <name name-style="western"><surname>Deisseroth</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Cragg</surname> <given-names>SJ</given-names></name>. <article-title>Striatal dopamine release is triggered by synchronized activity in cholinergic interneurons</article-title>. <source>Neuron</source>. <year>2012</year>;<volume>75</volume>:<fpage>58</fpage>–<lpage>64</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2012.04.038" xlink:type="simple">10.1016/j.neuron.2012.04.038</ext-link></comment> <object-id pub-id-type="pmid">22794260</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref120">
<label>120</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zahm</surname> <given-names>DS</given-names></name>, <name name-style="western"><surname>Brog</surname> <given-names>JS</given-names></name>. <article-title>On the significance of subterritories in the “accumbens” part of the rat ventral striatum</article-title>. <source>Neuroscience</source>. <year>1992</year>;<volume>50</volume>(<issue>4</issue>):<fpage>751</fpage>–<lpage>767</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0306-4522(92)90202-D" xlink:type="simple">10.1016/0306-4522(92)90202-D</ext-link></comment> <object-id pub-id-type="pmid">1448200</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref121">
<label>121</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zahm</surname> <given-names>DS</given-names></name>. <article-title>Functional-anatomical implications of the nucleus accumbens core and shell subterritories</article-title>. <source>Annals of the New York Academy of Sciences</source>. <year>1999</year>;<volume>877</volume>(<issue>1</issue>):<fpage>113</fpage>–<lpage>128</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1749-6632.1999.tb09264.x" xlink:type="simple">10.1111/j.1749-6632.1999.tb09264.x</ext-link></comment> <object-id pub-id-type="pmid">10415646</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref122">
<label>122</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Di Chiara</surname> <given-names>G</given-names></name>. <article-title>Nucleus accumbens shell and core dopamine: differential role in behavior and addiction</article-title>. <source>Behavioural Brain Research</source>. <year>2002</year>;<volume>137</volume>(<issue>1</issue>):<fpage>75</fpage>–<lpage>114</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0166-4328(02)00286-3" xlink:type="simple">10.1016/S0166-4328(02)00286-3</ext-link></comment> <object-id pub-id-type="pmid">12445717</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref123">
<label>123</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Corbit</surname> <given-names>LH</given-names></name>, <name name-style="western"><surname>Balleine</surname> <given-names>BW</given-names></name>. <article-title>The general and outcome-specific forms of pavlovian-instrumental transfer are differentially mediated by the nucleus accumbens core and shell</article-title>. <source>The Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>33</issue>):<fpage>11786</fpage>–<lpage>11794</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2711-11.2011" xlink:type="simple">10.1523/JNEUROSCI.2711-11.2011</ext-link></comment> <object-id pub-id-type="pmid">21849539</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref124">
<label>124</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ikemoto</surname> <given-names>S</given-names></name>. <article-title>Dopamine reward circuitry: Two projection systems from the ventral midbrain to the nucleus accumbens-olfactory tubercle complex</article-title>. <source>Brain Research Reviews</source>. <year>2007</year>;<volume>56</volume>:<fpage>27</fpage>–<lpage>78</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.brainresrev.2007.05.004" xlink:type="simple">10.1016/j.brainresrev.2007.05.004</ext-link></comment> <object-id pub-id-type="pmid">17574681</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref125">
<label>125</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Parkinson</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Olmstead</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Burns</surname> <given-names>LH</given-names></name>, <name name-style="western"><surname>Robbins</surname> <given-names>TW</given-names></name>, <name name-style="western"><surname>Everitt</surname> <given-names>BJ</given-names></name>. <article-title>Dissociation in effects of lesions of the nucleus accumbens core and shell on appetitive pavlovian approach behavior and the potentiation of conditioned reinforcement and locomotor activity by d-amphetamine</article-title>. <source>The Journal of Neuroscience</source>. <year>1999</year>;<volume>19</volume>(<issue>6</issue>):<fpage>2401</fpage>–<lpage>2411</lpage>. <object-id pub-id-type="pmid">10066290</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref126">
<label>126</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Humphries</surname> <given-names>MD</given-names></name>, <name name-style="western"><surname>Prescott</surname> <given-names>TJ</given-names></name>. <article-title>The ventral basal ganglia, a selection mechanism at the crossroads of space, strategy, and reward</article-title>. <source>Progress in Neurobiology</source>. <year>2010</year> <month>Apr</month>;<volume>90</volume>(<issue>4</issue>):<fpage>385</fpage>–<lpage>417</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.pneurobio.2009.11.003" xlink:type="simple">10.1016/j.pneurobio.2009.11.003</ext-link></comment> <object-id pub-id-type="pmid">19941931</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref127">
<label>127</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Saddoris</surname> <given-names>MP</given-names></name>, <name name-style="western"><surname>Sugam</surname> <given-names>JA</given-names></name>, <name name-style="western"><surname>Cacciapaglia</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Carelli</surname> <given-names>RM</given-names></name>. <article-title>Rapid dopamine dynamics in the accumbens core and shell: learning and action</article-title>. <source>Frontiers in Bioscience</source>. <year>2013</year>;<volume>5</volume>:<fpage>273</fpage>–<lpage>288</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref128">
<label>128</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gershman</surname> <given-names>SJ</given-names></name>. <article-title>Dopamine ramps are a consequence of reward prediction errors</article-title>. <source>Neural Computation</source>. <year>2014</year>;<volume>26</volume>:<fpage>467</fpage>–<lpage>471</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/NECO_a_00559" xlink:type="simple">10.1162/NECO_a_00559</ext-link></comment> <object-id pub-id-type="pmid">24320851</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref129">
<label>129</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>O’Keefe</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dostrovsky</surname> <given-names>J</given-names></name>. <article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title>. <source>Brain Research</source>. <year>1971</year>;<volume>34</volume>(<issue>1</issue>):<fpage>171</fpage>–<lpage>175</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/0006-8993(71)90358-1" xlink:type="simple">10.1016/0006-8993(71)90358-1</ext-link></comment> <object-id pub-id-type="pmid">5124915</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref130">
<label>130</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>O’Keefe</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Nadel</surname> <given-names>L</given-names></name>. <source>The hippocampus as a cognitive map</source>. <publisher-name>Clarendon Press</publisher-name>; <year>1978</year>.</mixed-citation>
</ref>
<ref id="pcbi.1004622.ref131">
<label>131</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Moser</surname> <given-names>EI</given-names></name>, <name name-style="western"><surname>Kropff</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Moser</surname> <given-names>MB</given-names></name>. <article-title>Place cells, grid cells, and the brain’s spatial representation system</article-title>. <source>Annual Review of Neuroscience</source>. <year>2008</year>;<volume>31</volume>:<fpage>69</fpage>–<lpage>89</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.31.061307.090723" xlink:type="simple">10.1146/annurev.neuro.31.061307.090723</ext-link></comment> <object-id pub-id-type="pmid">18284371</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref132">
<label>132</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Foster</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Morris</surname> <given-names>RGM</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>A model of hippocampally dependent navigation, using the temporal difference learning rule</article-title>. <source>Hippocampus</source>. <year>2000</year>;<volume>10</volume>:<fpage>1</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1002/(SICI)1098-1063(2000)10:1%3C1::AID-HIPO1%3E3.0.CO;2-1" xlink:type="simple">10.1002/(SICI)1098-1063(2000)10:1%3C1::AID-HIPO1%3E3.0.CO;2-1</ext-link></comment> <object-id pub-id-type="pmid">10706212</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref133">
<label>133</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Barbieri</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>. <article-title>An analysis of hippocampal spatio-temporal representations using a Bayesian algorithm for neural spike train decoding</article-title>. <source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source>. <year>2005</year>;<volume>13</volume>(<issue>2</issue>):<fpage>131</fpage>–<lpage>136</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TNSRE.2005.847368" xlink:type="simple">10.1109/TNSRE.2005.847368</ext-link></comment> <object-id pub-id-type="pmid">16003890</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref134">
<label>134</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Morita</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Kato</surname> <given-names>A</given-names></name>. <article-title>Striatal dopamine ramping may indicate flexible reinforcement learning with forgetting in the cortical-basal ganglia circuits</article-title>. <source>Frontiers in Neural Circuits</source>. <year>2014</year>;<volume>8</volume>:<fpage>1</fpage>–<lpage>15</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncir.2014.00048" xlink:type="simple">10.3389/fncir.2014.00048</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref135">
<label>135</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Williams</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Dayan</surname> <given-names>P</given-names></name>. <article-title>Dopamine, learning, and impulsivity: A biological account of attention-deficit/hyperactivity disorder</article-title>. <source>Journal of Child &amp; Adolescent Psychopharmacology</source>. <year>2005</year>;<volume>15</volume>(<issue>2</issue>):<fpage>160</fpage>–<lpage>179</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1089/cap.2005.15.160" xlink:type="simple">10.1089/cap.2005.15.160</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref136">
<label>136</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Araya</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Andino-Pavlovsky</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Yuste</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Etchenique</surname> <given-names>R</given-names></name>. <article-title>Two-photon optical interrogation of individual dendritic spines with caged dopamine</article-title>. <source>ACS Chemical Neuroscience</source>. <year>2013</year>;<volume>4</volume>(<issue>8</issue>):<fpage>1163</fpage>–<lpage>1167</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1021/cn4000692" xlink:type="simple">10.1021/cn4000692</ext-link></comment> <object-id pub-id-type="pmid">23672485</object-id></mixed-citation>
</ref>
<ref id="pcbi.1004622.ref137">
<label>137</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kravitz</surname> <given-names>AV</given-names></name>, <name name-style="western"><surname>Tye</surname> <given-names>LD</given-names></name>, <name name-style="western"><surname>Kreitzer</surname> <given-names>AC</given-names></name>. <article-title>Distinct roles for direct and indirect pathway striatal neurons in reinforcement</article-title>. <source>Nature Neuroscience</source>. <year>2012</year>;<volume>15</volume>(<issue>6</issue>):<fpage>816</fpage>–<lpage>819</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3100" xlink:type="simple">10.1038/nn.3100</ext-link></comment> <object-id pub-id-type="pmid">22544310</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="publisher-id">PCOMPBIOL-D-11-00120</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1002162</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline-v2">
          <subject>Biology</subject>
          <subj-group>
            <subject>Neuroscience</subject>
            <subj-group>
              <subject>Computational neuroscience</subject>
            </subj-group>
          </subj-group>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
      </article-categories><title-group><article-title>Model Cortical Association Fields Account for the Time Course and Dependence on Target Complexity of Human Contour Perception</article-title><alt-title alt-title-type="running-head">Contour Perception via Cortical Association Fields</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Gintautas</surname>
            <given-names>Vadas</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Ham</surname>
            <given-names>Michael I.</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Kunsberg</surname>
            <given-names>Benjamin</given-names>
          </name>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Barr</surname>
            <given-names>Shawn</given-names>
          </name>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Brumby</surname>
            <given-names>Steven P.</given-names>
          </name>
          <xref ref-type="aff" rid="aff5">
            <sup>5</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Rasmussen</surname>
            <given-names>Craig</given-names>
          </name>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>George</surname>
            <given-names>John S.</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Nemenman</surname>
            <given-names>Ilya</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Bettencourt</surname>
            <given-names>Lu√≠s M. A.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Kenyon</surname>
            <given-names>Garret T.</given-names>
          </name>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label><addr-line>Center for Nonlinear Studies and T-5, Theoretical Division, Los Alamos National Laboratory, Los Alamos, New Mexico, United States of America</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Physics Department, Chatham University, Pittsburgh, Pennsylvania, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>P-21 Applied Modern Physics (Biological and Quantum Physics), Los Alamos National Laboratory, Los Alamos, New Mexico, United States of America</addr-line>       </aff><aff id="aff4"><label>4</label><addr-line>New Mexico Consortium, Los Alamos, New Mexico, United States of America</addr-line>       </aff><aff id="aff5"><label>5</label><addr-line>Space and Remote Sensing Sciences, Los Alamos National Laboratory, Los Alamos, New Mexico, United States of America</addr-line>       </aff><aff id="aff6"><label>6</label><addr-line>Departments of Physics and Biology and Computational and Life Sciences Initiative, Emory University, Atlanta, Georgia, United States of America</addr-line>       </aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Sporns</surname>
            <given-names>Olaf</given-names>
          </name>
          <role>Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">Indiana University, United States of America</aff><author-notes>
        <corresp id="cor1">* E-mail: <email xlink:type="simple">vgintautas@chatham.edu</email> (VG); <email xlink:type="simple">gkenyon@lanl.gov</email> (GTK)</corresp>
        <fn fn-type="con">
          <p>Conceived and designed the experiments: VG JSG IN LMAB GTK. Performed the experiments: MIH SB. Analyzed the data: VG MIH BK SB GTK. Contributed reagents/materials/analysis tools: SPB CR GTK. Wrote the paper: VG IN LMAB GTK. Conceived the research program: JSG IN LMAB GTK. Designed and implemented model cortical association fields: VG GTK.</p>
        </fn>
      <fn fn-type="conflict">
        <p>The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="collection">
        <month>10</month>
        <year>2011</year>
      </pub-date><pub-date pub-type="epub">
        <day>6</day>
        <month>10</month>
        <year>2011</year>
      </pub-date><volume>7</volume><issue>10</issue><elocation-id>e1002162</elocation-id><history>
        <date date-type="received">
          <day>27</day>
          <month>1</month>
          <year>2011</year>
        </date>
        <date date-type="accepted">
          <day>29</day>
          <month>6</month>
          <year>2011</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><license><license-p>This is an open-access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the Creative Commons CC0 public domain dedication.</license-p></license></permissions><abstract>
        <p>Can lateral connectivity in the primary visual cortex account for the time dependence and intrinsic task difficulty of human contour detection? To answer this question, we created a synthetic image set that prevents sole reliance on either low-level visual features or high-level context for the detection of target objects. Rendered images consist of smoothly varying, globally aligned contour fragments (amoebas) distributed among groups of randomly rotated fragments (clutter). The time course and accuracy of amoeba detection by humans was measured using a two-alternative forced choice protocol with self-reported confidence and variable image presentation time (20-200 ms), followed by an image mask optimized so as to interrupt visual processing. Measured psychometric functions were well fit by sigmoidal functions with exponential time constants of 30-91 ms, depending on amoeba complexity. Key aspects of the psychophysical experiments were accounted for by a computational network model, in which simulated responses across retinotopic arrays of orientation-selective elements were modulated by cortical association fields, represented as multiplicative kernels computed from the differences in pairwise edge statistics between target and distractor images. Comparing the experimental and the computational results suggests that each iteration of the lateral interactions takes at least <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e001" xlink:type="simple"/></inline-formula> ms of cortical processing time. Our results provide evidence that cortical association fields between orientation selective elements in early visual areas can account for important temporal and task-dependent aspects of the psychometric curves characterizing human contour perception, with the remaining discrepancies postulated to arise from the influence of higher cortical areas.</p>
      </abstract><abstract abstract-type="summary">
        <title>Author Summary</title>
        <p>Current computer vision algorithms reproducing the feed-forward features of the primate visual pathway still fall far behind the capabilities of human subjects in detecting objects in cluttered backgrounds. Here we investigate the possibility that recurrent lateral interactions, long hypothesized to form cortical association fields, can account for the dependence of object detection accuracy on shape complexity and image exposure time. Cortical association fields are thought to aid object detection by reinforcing global image features that cannot easily be detected by single neurons in feed-forward models. Our implementation uses the spatial arrangement, relative orientation, and continuity of putative contour elements to compute the lateral contextual support. We designed synthetic images that allowed us to control object shape and background clutter while eliminating unintentional cues to the presence of an otherwise hidden target. In contrast, real objects can vary uncontrollably in shape, are camouflaged to different degrees by background clutter, and are often associated with non-shape cues, making results using natural image sets difficult to interpret. Our computational model of cortical association fields matches many aspects of the time course and object detection accuracy of human subjects on statistically identical synthetic image sets. This implies that lateral interactions may selectively reinforce smooth object global boundaries.</p>
      </abstract><funding-group><funding-statement>This work was supported by Los Alamos National Laboratory LDRD program under project 20090006DR; the National Science Foundation, grant ID 0749348; and the DARPA NeoVision2 project. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. This publication qualified for unclassified release under DUSA BIOSCI with LA-UR 11-00499.</funding-statement></funding-group><counts>
        <page-count count="16"/>
      </counts></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>The perception of closed contours is fundamental to object recognition, as revealed by the fact that common object categories can be rapidly detected in black and white line drawings in which all shading and luminance cues have been removed <xref ref-type="bibr" rid="pcbi.1002162-Velisavljevi1">[1]</xref>. Cortical association fields, hypothesized to capture spatial correlations between local image features via long-range lateral synaptic interactions, provide a natural substrate for rapid contour perception <xref ref-type="bibr" rid="pcbi.1002162-Field1">[2]</xref>. The link between cortical association fields and contour perception has been investigated through a variety of behavioral, experimental, and theoretical techniques <xref ref-type="bibr" rid="pcbi.1002162-Loffler1">[3]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Seris1">[6]</xref>. Psychophysical measurements reveal that the detection of implicit contours, defined by sequences of Gabor-like elements presented against randomly oriented backgrounds, becomes more difficult as the local curvature increases and as the individual Gabor elements are spaced further apart or their alignment is randomly perturbed. This dependence on proximity and relative orientation implies that, in early visual areas, cortical association fields are primarily local and aligned along smooth trajectories <xref ref-type="bibr" rid="pcbi.1002162-Field1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Kovcs1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Pettet1">[8]</xref>. In related studies, collinear Gabor patches have been shown to both increase and decrease the contrast detection threshold of a central Gabor patch in a manner that depends on the relative timing, orientation and spatial separation of the flanking elements <xref ref-type="bibr" rid="pcbi.1002162-Polat1">[9]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Polat2">[11]</xref>, providing further psychophysical evidence that lateral influences act at early cortical processing stages, although the contribution of collinear facilitation to contour integration remains controversial <xref ref-type="bibr" rid="pcbi.1002162-Huang1">[12]</xref>. In primary visual cortex (V1), electrophysiological recordings indicate that the responses to optimally oriented and positioned stimuli can be facilitated by flanking stimuli placed outside the classical receptive field center <xref ref-type="bibr" rid="pcbi.1002162-Fitzpatrick1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Seris1">[6]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Kapadia1">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Bringuier1">[13]</xref>, although these effects have also been ascribed to elongated central receptive fields <xref ref-type="bibr" rid="pcbi.1002162-Cavanaugh1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Cavanaugh2">[15]</xref> and facilitation has been attributed to increases in baseline activity <xref ref-type="bibr" rid="pcbi.1002162-Pooresmaeili1">[16]</xref>. Nonetheless, collinear facilitation is consistent with anatomical studies indicating that orientation columns are laterally connected to surrounding columns with similar orientation preference <xref ref-type="bibr" rid="pcbi.1002162-Bosking1">[17]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Malach1">[19]</xref>.</p>
      <p>Because extensive association fields are present in the primary visual cortex <xref ref-type="bibr" rid="pcbi.1002162-Bosking1">[17]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Malach1">[19]</xref>, lateral interactions may be key to discriminating smooth object boundaries at very fast time scales (of the order of tens of ms), as observed in numerous speed of sight psychophysical experiments <xref ref-type="bibr" rid="pcbi.1002162-Velisavljevi1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Hess2">[20]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-BaconMac1">[23]</xref>. Correspondingly, theoretical models have proposed that V1 cortical association fields can be described mathematically on the basis of cocircularity, and that relaxation dynamics based on cocircular association fields can extract global contours by suppressing local variation <xref ref-type="bibr" rid="pcbi.1002162-BenShahar1">[24]</xref>. Such models are qualitatively consistent with human judgments as to whether pairs of short line segments belong to the same or separate contours, with human judgments closely following the pairwise statistics of edge segments extracted from natural scenes <xref ref-type="bibr" rid="pcbi.1002162-Geisler1">[25]</xref>. Further, model cortical association fields, when used to detect implicit contours, can predict key aspects of human psychophysics, particularly the measured dependence on the density of foreground elements relative to background elements <xref ref-type="bibr" rid="pcbi.1002162-Pettet1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Mandon1">[26]</xref>.</p>
      <p>In this paper, we extend the above studies by investigating whether model cortical association fields can account not only for dependence of contour perception on intrinsic task difficulty, a relationship that has been previously explored <xref ref-type="bibr" rid="pcbi.1002162-Pettet1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Mandon1">[26]</xref>, but also for the detailed time course of human contour detection, an aspect that has heretofore not been modeled explicitly, although the time-dependent influence of lateral interactions has been determined for several theoretical models <xref ref-type="bibr" rid="pcbi.1002162-Ursino1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Sterkin1">[28]</xref>. In this work, we employ multiplicative relaxational dynamics to estimate the time course of contour detection from a computational model employing optimized kernels. Model results are then compared to speed-of-sight measurements from human subjects performing the same contour detection task. To obtain optimized cortical association fields, we design lateral connectivity patterns using a novel method that exploits the global statistical properties of salient contours relative to background clutter. Our procedure, which can be generalized beyond the present application, can be summarized as follows.</p>
      <p>We begin by generating a large training corpus, divided into target and distractor images, from which we obtain estimates of the pairwise co-occurence probability of oriented edges conditioned on the presence or absence of globally salient contours. From the difference in these two probability distributions, we construct Object-Distractor Difference (ODD) kernels, which are then convolved with every edge feature to obtain the lateral contextual support at each location and orientation across the entire image. Edge features that receive substantial contextual support from the surrounding edges are preserved, indicating they are likely to belong to a globally salient contour, whereas edge features receiving minimal contextual support are suppressed, indicating they are more likely to be part of the background clutter. The lateral contextual support is applied in a multiplicative fashion, so as to prevent the appearance of illusory edges, and the process is iterated several times, mimicking the exchange of information along horizontal connections in the primary visual cortex. Our method is thus intended to capture the essential computational elements of cortical association fields that are hypothesized to mediate the pop-out of salient contours against cluttered backgrounds.</p>
      <p>To obtain a large number of training images and to better isolate the role of cortical association fields linking low-level visual features, we employ abstract computer-generated shapes consisting of short, smooth contour segments that could either be globally aligned to form wiggly, nearly closed objects (<italic>amoebas</italic>), or else randomly rotated to provide a background of locally indistinguishable contour fragments (<italic>clutter</italic>). Amoeba targets lack specific semantic content, presumably reducing the influence of high level cortical areas, such as IT. However, our computer-generated images would not be expected to eliminate the contribution to contour perception from extrastriate areas <xref ref-type="bibr" rid="pcbi.1002162-Bair1">[29]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Angelucci1">[32]</xref>. Thus, our model of lateral interactions between orientation-selective neurons is designed to account for just one of several cortical mechanisms that likely contribute to contour perception.</p>
      <p>Our amoeba/no-amoeba image set differs from stimuli used in previous psychophysical experiments that employed sequences of Gabor-like elements to represent salient contours against randomly oriented backgrounds <xref ref-type="bibr" rid="pcbi.1002162-Field1">[2]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Kovcs1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Pettet1">[8]</xref>. An advantage of contours represented by random Gabor fields is that the target and distractor Gabor elements can be distributed at approximately equal densities, thereby precluding the use of local density operators as surrogates for global contour perception <xref ref-type="bibr" rid="pcbi.1002162-Field1">[2]</xref>. However, our amoeba/no-amoeba image set is more akin to the natural image sets used in previous speed-of-sight object detection tasks <xref ref-type="bibr" rid="pcbi.1002162-Serre1">[33]</xref>, particularly with respect to studies employing line drawings derived from natural scenes <xref ref-type="bibr" rid="pcbi.1002162-Velisavljevi1">[1]</xref>. Humans can detect closed contours, whether defined by aligned Gabor elements or by continuous line fragments, in less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e002" xlink:type="simple"/></inline-formula> ms <xref ref-type="bibr" rid="pcbi.1002162-Velisavljevi1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Hess2">[20]</xref>, which is shorter than the mean interval between saccadic eye movements <xref ref-type="bibr" rid="pcbi.1002162-MartinezConde1">[34]</xref>, thus mitigating the contribution from visual search. Like Gabor defined contours, our amoeba/no-amoeba image set implements a pop-out detection task involving readily perceived target shapes whose complexity can be controlled parametrically.</p>
      <p>To benchmark the accuracy and the time course of the ODD kernel-based procedure applied to the amoeba/no-amoeba task, we compare our model results to the performance of human subjects on a 2AFC speed-of-sight task in which amoeba/no-amoeba images are presented very briefly side by side, followed by a mask designed to limit the time the visual system is able to process the sensory input <xref ref-type="bibr" rid="pcbi.1002162-Velisavljevi1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Hess2">[20]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-BaconMac1">[23]</xref>. Since it takes an estimated <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e003" xlink:type="simple"/></inline-formula> ms for activation to spread through the ventral stream of the visual cortex <xref ref-type="bibr" rid="pcbi.1002162-Keysers1">[21]</xref>, an effective mask presented within this time frame can potentially degrade object detection performance by interfering with the neural processing mechanisms underlying recognition <xref ref-type="bibr" rid="pcbi.1002162-Keysers2">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Rolls1">[35]</xref>. By plotting task performance as a function of the stimulus onset asynchrony (SOA)‚Äìthe interval between image and mask presentation onsets‚Äìthe resulting psychometric curves are hypothesized to estimate the neural processing time required to reach a given level of classification accuracy. Amoeba targets of low to moderate complexity were found to reliably pop-out against the background clutter, allowing subjects to achieve near perfect performance at SOAs less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e004" xlink:type="simple"/></inline-formula> ms, even when followed by an optimized mask consisting of rotated versions of the target and distractor images <xref ref-type="bibr" rid="pcbi.1002162-Hess2">[20]</xref>. Our model cortical association fields were able to account for the dependence of human performance on amoeba complexity as well as for aspects of the time course of contour perception as measured by the improvement in human performance with increasing SOA. Thus, we present the first network-level computational model to simultaneously account for spatial and temporal aspects of contour perception, as measured in human subjects performing the same contour detection task. Aspects of the experimental data for which our model fails to account, particularly data showing that human subjects require longer processing times to detect more complex targets, may indicate the possible involvement of extrastriate areas, which may be essential for the perception of more complex shapes.</p>
    </sec>
    <sec id="s2">
      <title>Results</title>
      <p>To investigate low-level cortical mechanisms for detecting smooth, closed contours presented against cluttered backgrounds with statistically similar low-level features, we designed an amoeba/no-amoeba detection task using a novel set of synthetic images (<xref ref-type="fig" rid="pcbi-1002162-g001">Figure 1</xref>). Amoebas are radial frequency patterns <xref ref-type="bibr" rid="pcbi.1002162-Wilkinson1">[36]</xref> constructed via superposition of periodic functions described by a discrete set of radial frequencies around a circle. In addition, we added clutter objects, or distractors, that were locally indistinguishable from targets. Both targets and distractors were composed of short contour fragments, thus eliminating unambiguous indicators of target presence or absence, such as total line length, the presence of line endpoints, and the existence of short gaps between opposed line segments. To keep the bounding contours smooth, only the lowest <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e005" xlink:type="simple"/></inline-formula> radial frequencies were included in the linear superposition used to construct amoeba targets. To span the maximum range of contour shapes and sizes, the amplitude and phase of each radial frequency component was chosen randomly, under the restriction that the minimum and maximum diameters could not exceed lower and upper limits. When only <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e006" xlink:type="simple"/></inline-formula> radial frequencies were included in the superposition, the resulting amoebas were very smooth. As more radial frequencies were included, the contours became more complex. Thus, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e007" xlink:type="simple"/></inline-formula>, the number of radial frequencies included in the superposition, provided a control parameter for adjusting target complexity. <xref ref-type="fig" rid="pcbi-1002162-g001">Figure 1</xref> shows target and distractor images generated using different values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e008" xlink:type="simple"/></inline-formula>.</p>
      <fig id="pcbi-1002162-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002162.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Examples of targets and distractors from the amoeba/no-amoeba image set for different <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e009" xlink:type="simple"/></inline-formula>.</title>
          <p>From left to right: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e010" xlink:type="simple"/></inline-formula>. Top row: Targets; amoeba complexity increases with increasing numbers of radial frequencies. Clutter was constructed by randomly rotating groups of amoeba contour fragments. Bottom row: Distractors; only clutter fragments are present.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.g001" xlink:type="simple"/>
      </fig>
      <p>Human subjects are able to infer whether a two isolated line segments extracted from a natural scene are from the same or from separate contours using only distance, direction and relative orientation of the two segments as cues <xref ref-type="bibr" rid="pcbi.1002162-Geisler1">[25]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Geisler2">[37]</xref>. The performance of human subjects is well predicted by differences in the empirically calculated co-occurrence statistics of short line segments drawn from either the same or from different contours. To explore the ability of cortical association fields to account for the perception of smooth contours, we developed a network-level computational model of lateral interactions between orientation-selective elements governed by sigmoidal (piecewise linear) input/output synaptic transfer functions. To model lateral interactions, we constructed ‚ÄúObject-Distractor Difference (ODD) kernels‚Äù for the amoeba/no-amoeba task by computing coactivation statistics for the responses of pairs of orientation-selective filter elements, compiled separately for target and distractor images (<xref ref-type="fig" rid="pcbi-1002162-g002">Figure 2</xref>). Because the amoeba/no-amoeba image set was translationally invariant and isotropic, the central filter element may without loss of generality be shifted and rotated to a canonical position and orientation. Thus the canonical ODD kernel was defined relative to filter elements at the origin with orientation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e011" xlink:type="simple"/></inline-formula> (to mitigate aliasing effects). Filter elements located away from the origin can be accounted for by a trivial translation. To account for filter elements with different orientations, separate ODD kernels were computed for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e012" xlink:type="simple"/></inline-formula> orientations then rotated to a common orientation and averaged to produce a canonical ODD kernel. The canonical kernel was then rotated in steps between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e013" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e014" xlink:type="simple"/></inline-formula> (offset by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e015" xlink:type="simple"/></inline-formula>) and then interpolated to Cartesian <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e016" xlink:type="simple"/></inline-formula> axes by rounding to the nearest integer coordinates.</p>
      <fig id="pcbi-1002162-g002" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002162.g002</object-id>
        <label>Figure 2</label>
        <caption>
          <title>ODD kernels.</title>
          <p>Top Row: For a single short line segment oriented approximately horizontally at the center (not drawn), the co-occurrence-based support of other edges at different relative orientations and spatial locations is depicted. Axes were rotated by (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e017" xlink:type="simple"/></inline-formula>) from vertical to mitigate aliasing effects. The color of each edge was set proportional to its co-occurrence-based support. The color scale ranges from blue (negative values) to white (zero) to red (positive values). Left panel: Co-occurrence statistics compiled from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e018" xlink:type="simple"/></inline-formula> target images. Center panel: Co-occurrence statistics compiled from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e019" xlink:type="simple"/></inline-formula> distractor images. Right panel: ODD kernel, given by the difference in co-occurrence statistics between target and distractor kernels. Bottom Row: Subfields extracted from the middle of the upper left quadrant (as indicated by black boxes in the top row figures), shown on an expanded scale to better visualize the difference in co-occurrence statistics between target and distractor images. Alignment of edges in target images is mostly cocircular whereas alignment is mostly random in distractor images, accounting for the fine structure in the corresponding section of the ODD kernel.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.g002" xlink:type="simple"/>
      </fig>
      <p>The resulting ODD kernels were generally consistent with the predictions of cocircular constructions <xref ref-type="bibr" rid="pcbi.1002162-BenShahar1">[24]</xref>, except that support was mostly limited to line elements lying along low curvature contours, which follows naturally from the prevalence of low curvatures in our amoeba training set.</p>
      <p>Curiously, the largest differences in the coactivation statistics occur close to the center of the kernel, where targets and distractors are presumably most similar. However, even at short distances, amoeba segments are still more likely to be aligned than clutter elements. Moreover, nearby pairs occur much more frequently than more distant pairs, amplifying their contribution to the difference map. Since, by design, the individual clutter fragments were locally indistinguishable from the target fragments, co-occurrence statistics of oriented fragments were necessary to solve the amoeba/no-amoeba task. The simplest solution, adopted here, was to focus on pairwise co-occurrences. Notably, in some neural preparations, pairwise interactions have been shown to be sufficient to account for a large fraction of all higher-order correlations <xref ref-type="bibr" rid="pcbi.1002162-Schneidman1">[38]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Shlens1">[39]</xref>.</p>
      <p>At the retinal stage, target and distractor images were represented as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e020" xlink:type="simple"/></inline-formula> pixel monochromatic, binary line drawings. At the next stage, corresponding to an early cortical processing area such as V1, a set of filters was used to represent <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e021" xlink:type="simple"/></inline-formula> orientations, uniformly-spaced and centered at each pixel, with the axes rotated slightly (by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e022" xlink:type="simple"/></inline-formula>) to mitigate aliasing artifacts. The bottom-up responses of each orientation-selective element were computed via linear convolution using filters composed of a central excitatory subunit flanked by two inhibitory subunits. Each subunit was an elliptical Gaussian with an aspect ratio of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e023" xlink:type="simple"/></inline-formula>, consistent with the aspect ratios of V1 simple cell receptive fields measured experimentally <xref ref-type="bibr" rid="pcbi.1002162-Jones1">[40]</xref> and similar to values employed in previously published models of V1 responses <xref ref-type="bibr" rid="pcbi.1002162-Troyer1">[41]</xref>. Likewise, we estimate that each image pixel subtended a visual angle of approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e024" xlink:type="simple"/></inline-formula> (see <xref ref-type="sec" rid="s4">Methods</xref>), so that each orientation-selective element in the model subtended a visual angle of approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e025" xlink:type="simple"/></inline-formula>, consistent with physiological estimates of V1 receptive field sizes at small eccentricities <xref ref-type="bibr" rid="pcbi.1002162-Angelucci2">[42]</xref>. All subunits had the same total integrated strength (to within a sign), whose magnitude was adjusted to yield relatively clean representations of the original image in terms of oriented edges. The synaptic transfer function was piecewise-linear with a minimum value of 0.0 and a maximum value of 1.0 and a fixed threshold of 0.5. A finite threshold and saturation level were essential in order to allow non-supported contour fragments to be suppressed while preventing well-supported fragments from growing without bound. The precise values used for threshold and saturation were not critical, as responsiveness was controlled independently by adjusting the overall integrated strength of the bottom-up and lateral interaction kernels (see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>).</p>
      <p>Orientation-selective responses were modulated by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e026" xlink:type="simple"/></inline-formula> successive applications of the multiplicative ODD kernel. Lateral support was first computed via linear convolution of the ODD kernel with the surrounding orientation-selective elements, out to a radius of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e027" xlink:type="simple"/></inline-formula> pixels. Given that images were approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e028" xlink:type="simple"/></inline-formula> in extent (see <xref ref-type="sec" rid="s4">Methods</xref>), ODD kernels spanned a total visual angle of approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e029" xlink:type="simple"/></inline-formula> degrees, roughly in correspondence with the estimated visuotopic extent of horizontal projections in V1 <xref ref-type="bibr" rid="pcbi.1002162-Angelucci2">[42]</xref>. The previous activity of each cell was multiplied by the current lateral support, passed through the piecewise-linear synaptic transfer function, and the process repeated for up to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e030" xlink:type="simple"/></inline-formula> iterations. Contour segments that received insufficient lateral support were thereby suppressed, whereas strongly supported elements were either enhanced or remained maximally activated. When applied to the amoeba/no-amoeba image set, the ODD kernels typically suppressed clutter relative to target segments (<xref ref-type="fig" rid="pcbi-1002162-g003">Figure 3</xref>, left column).</p>
      <fig id="pcbi-1002162-g003" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002162.g003</object-id>
        <label>Figure 3</label>
        <caption>
          <title>The effect of lateral interactions on example images.</title>
          <p>Left column: black and white amoeba-target image (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e031" xlink:type="simple"/></inline-formula>). Right column: Gray-scale natural image (the standard computer vision test image ‚ÄúLena‚Äù) after applying a hard Difference of Gaussians (DoG) filter to enhance edges. Top row: Raw retinal input. Second row: Responses of orientation-selective elements before any lateral interactions (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e032" xlink:type="simple"/></inline-formula>). To aid visualization, the activity of the maximally responding orientation-selective element at each pixel location is depicted as a gray-scale intensity. Rows 3-6: Activity after <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e033" xlink:type="simple"/></inline-formula> iterations of the multiplicative ODD kernel, as labeled. For each iteration, activity was multiplied by the local support, computed via linear convolution of the previous output activity with the ODD kernel. Lateral interactions tended to support smooth contours, particularly those arising from amoeba segments, while suppressing clutter or background detail.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.g003" xlink:type="simple"/>
      </fig>
      <p>When applied in a similar manner to a natural gray-scale image to which a hard Difference-of-Gaussians (DoG) filter has been applied to maximally enhance local contrast (see <xref ref-type="fig" rid="pcbi-1002162-g003">Figure 3</xref>, right column), ODD-kernels tended to preserve long, smooth lines while suppressing local spatial detail. Although ODD kernels were trained on a narrow set of synthetic images, the results exhibit some generalization to natural images due to the overlap between the cocircularity statistics (see <xref ref-type="fig" rid="pcbi-1002162-g002">Figure 2</xref>) of the synthetic image set and those of natural images.</p>
      <p>To quantify the ability of the model to discriminate between amoeba/no-amoeba target and distractor images, we used the total activation summed over all orientation-selective elements after <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e034" xlink:type="simple"/></inline-formula> iterations of the ODD kernel. A set of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e035" xlink:type="simple"/></inline-formula> target and distractor images was used for testing; test images were generated independently from the training images. Histograms of the total activation show increasing separability between target and distractor images as a function of the number of iterations (<xref ref-type="fig" rid="pcbi-1002162-g004">Figure 4</xref>). To maximize the range of shapes and sizes spanned by our synthetic targets and distractors, we did not require that the number of ON retinal pixels be constant across images. Rather, the retinal representations of both target and distractor images encompassed a broad range of total activity levels, although the two distributions strongly overlapped and there was no evident bias favoring one or the other. At the next processing stage, prior to any lateral interactions, there was likewise little or no bias evident in the bottom-up responses of the orientation-selective elements. Each iteration of the multiplicative ODD kernel then caused the distributions of total activity for target and distractor images to become more separable, implying corresponding improvements in discrimination performance on the amoeba/no-amoeba task.</p>
      <fig id="pcbi-1002162-g004" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002162.g004</object-id>
        <label>Figure 4</label>
        <caption>
          <title>Histograms of total luminance in target and distractor images as a function of the number of iterations.</title>
          <p>Red bins: Total activity histograms for all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e036" xlink:type="simple"/></inline-formula> test target images. Blue bins: Total activity histograms for all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e037" xlink:type="simple"/></inline-formula> test distractor images. The degree that the two distributions overlap is shown as the gray shaded area, which provides a measure of whether total luminance can be used to distinguish targets from distractors. The percentage in each shaded area shows the approximate lower bound amount of overlap of the two histograms, for comparison. Top row: Total summed activity over all retinal pixels. Little, if any bias between target and distractor images was evident in the input black and white images as there is nearly complete overlap between the distributions. Subsequent rows: Total activity histograms summed over all orientation-selective elements. Second row: Bottom-up responses prior to any lateral interactions. Third - sixth rows: Total activity histograms after <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e038" xlink:type="simple"/></inline-formula> - <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e039" xlink:type="simple"/></inline-formula> iterations of the multiplicative ODD kernel, respectively. Total summed activity became progressively more separable with additional iterations, as evinced by a decrease in the overlapping areas.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.g004" xlink:type="simple"/>
      </fig>
      <p>The general principles governing the operation of our model cortical association fields are conceptually straightforward. ODD kernels, which capture differences in the coactivation statistics of edge segments belonging to amoebas relative to edge segments belonging to the background clutter, are used to determine the lateral contextual support for individual edge segments in an image. Edge segments receiving sufficiently strong support are preserved, indicating they are likely to be part of an amoeba, whereas edge segments receiving insufficient support are suppressed, indicating they are likely to belong to the background clutter.</p>
      <p>To assess the ability of the model cortical association fields to account for the time course of human contour perception, we measured the stimulus presentation time required for human subjects to reach a given level of accuracy on an amoeba/no-amoeba task. The psychophysical experiment was implemented using a speed-of-sight protocol employing a two-alternative forced choice (2AFC) design, with subjects using a slider bar to indicate which of two images, presented side-by-side, contained an amoeba (<xref ref-type="fig" rid="pcbi-1002162-g005">Figure 5</xref>). The distance the bar was displaced to the left or to the right was used to indicate confidence, see <italic><xref ref-type="sec" rid="s4">Methods</xref></italic>. To effectively interrupt visual processing at a given SOA, both target and distractor images were replaced by an optimized mask, constructed by combining randomly rotated amoeba and clutter segments <xref ref-type="bibr" rid="pcbi.1002162-Hess2">[20]</xref>. Our optimized masks were designed to render the amoeba targets virtually invisible in the fused target-mask composite.</p>
      <fig id="pcbi-1002162-g005" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002162.g005</object-id>
        <label>Figure 5</label>
        <caption>
          <title>Psychophysical experiment schematic.</title>
          <p>The stimulus consisted of one target image and one distractor image (randomly positioned with equal probability on the left or right), presented simultaneously for an SOA between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e040" xlink:type="simple"/></inline-formula> ms and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e041" xlink:type="simple"/></inline-formula> ms, followed by an optimized <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e042" xlink:type="simple"/></inline-formula> ms mask generated from randomly rotated groups of target and distractor segments. Subjects indicated which side contained the target object (amoeba) using a computer mouse to click along a horizontal slider bar. Clicking far to the left or right indicated strong confidence that the corresponding side contained the target; clicking close to the center indicated weak confidence. A narrow gap in the center forced subjects to choose between left and right.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.g005" xlink:type="simple"/>
      </fig>
      <p>As a measure of human performance on the amoeba/no-amoeba task, we constructed receiver operating characteristic (ROC) curves <xref ref-type="bibr" rid="pcbi.1002162-Azzopardi1">[43]</xref> (<xref ref-type="fig" rid="pcbi-1002162-g006">Figure 6</xref>), using each subject's reported confidence (slider bar location relative to the center position) as a noisy signal for estimating which side, either left or right, contained the target on a given trial. True positives corresponded to trials on which the subject reported the target was on the left (relative to threshold) and the target was actually on the left (relative to threshold). False positives corresponded to trials on which the subject reported the target was on the left whereas the target was actually on the right (relative to threshold). To construct each ROC curve, the confidence scale along the slider bar was divided into 6 discrete threshold values. For each threshold value, a cumulative proportional true positive rate was calculated by considering only those trials as true positives in which the confidence value was above threshold. The cumulative proportional false positive rate for each threshold value was calculated similarly. Each threshold value thus contributed one point on the ROC curve, with true positive rate plotted as the ordinate and the false positive rate as the abscissa. The complete set of points was connected by straight lines to guide the eye (<xref ref-type="fig" rid="pcbi-1002162-g006">Figure 6</xref>), with a separate ROC curve computed for each combination of SOA and target complexity.</p>
      <fig id="pcbi-1002162-g006" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002162.g006</object-id>
        <label>Figure 6</label>
        <caption>
          <title>ROC curves comparing human and model performance on the amoeba/no amoeba task.</title>
          <p>Top two rows: ROC curves averaged over four different human test subjects using reported confidence (points). The dashed diagonal line in each plot indicates the curve corresponding to chance. Red, blue, green, black correspond to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e043" xlink:type="simple"/></inline-formula>, respectively. Bottom two rows: ROC curves for model cortical association fields computed from total activity histograms.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.g006" xlink:type="simple"/>
      </fig>
      <p>ROC curves for quantifying the performance of the model on the amoeba/no-amoeba task were computed similarly, using the difference in total luminance between the left and right images as the raw signal for estimating which side contained the target on a given trial. If the total luminance of the left image was higher than that of the right (relative to threshold), the response of the model would be reported as target on the left. Ideally, after several iterations of the ODD kernel, no segments would remain in the distractor image and only amoeba segments would remain in the target image; in practice, the total luminance served as a measure of confidence. Given the much larger number of trials (1000) available for assessing model performance, 100 equally spaced threshold values were used to calculate the corresponding ROC curves. As with the ROC curves constructed from the confidence values reported by the human subjects, the ROC curves computed from the confidence values reported by the model give the cumulative proportional true positive rate as a function of cumulative proportional false positive rate, with the confidence threshold varied from zero to maximum. Graphically, the area under the ROC curves is given by the amount of overlap between the total luminance histograms (see <xref ref-type="fig" rid="pcbi-1002162-g004">figure 4</xref>) for the target and distractor images <xref ref-type="bibr" rid="pcbi.1002162-Macmillan1">[44]</xref>.</p>
      <p>ROC curves for human subjects show performance increasingly above chance, indicated by a diagonal line of slope <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e044" xlink:type="simple"/></inline-formula>, as a function of both increasing SOA and decreasing target complexity. For amoeba targets of low to moderate complexity, ROC curves obtained from human subjects were well matched to those generated by the model cortical association fields, consistent with the hypothesis that lateral interactions between orientation-selective neurons contribute to human contour perception, at least for simple targets.</p>
      <p>The area under the ROC curve (AUC) gives the probability that a randomly chosen target image will be correctly classified relative to a randomly chosen distractor image, and thus provides a threshold-independent assessment of performance on the 2AFC task. Both the average over human subjects and the model cortical association fields exhibited qualitatively similar performance on the 2AFC amoeba/no-amoeba task (<xref ref-type="fig" rid="pcbi-1002162-g007">Figure 7</xref>). Performance declined as a function of increasing target complexity, both for human subjects, measured at a fixed SOA, and for the model, measured at a fixed number of iterations, implying that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e045" xlink:type="simple"/></inline-formula> was an effective control parameter for adjusting task difficulty. At <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e046" xlink:type="simple"/></inline-formula> ms SOA, the performance of human subjects was indistinguishable from chance, suggesting that our optimized masks effectively prevented the development of bottom-up cortical responses, even for the simplest targets (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e047" xlink:type="simple"/></inline-formula>). Although some studies report that line drawings are processed more rapidly than natural images, with above chance performance being observed at short SOA values <xref ref-type="bibr" rid="pcbi.1002162-Velisavljevi1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Mandon1">[26]</xref>, the fact that performance on the amoeba/no-amoeba task was no better than chance at a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e048" xlink:type="simple"/></inline-formula> ms SOA implies that our optimized masks effectively interrupted visual processing of the amoeba targets. Since the model used here did not include any account for the time course of bottom-up retinocortical dynamics, we assumed that the performance of human subjects at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e049" xlink:type="simple"/></inline-formula> ms SOA should be equated to model performance at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e050" xlink:type="simple"/></inline-formula> iterations (prior to any lateral interactions), a time frame consistent with the distribution of the shortest measured response latencies recorded in primary visual cortex <xref ref-type="bibr" rid="pcbi.1002162-Maunsell1">[45]</xref>.</p>
      <fig id="pcbi-1002162-g007" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002162.g007</object-id>
        <label>Figure 7</label>
        <caption>
          <title>A comparison of human and model performance on the 2AFC amoeba/no amoeba task.</title>
          <p>Left: Average human performance for different SOA in milliseconds. Right: Performance of model cortical association fields for increasing numbers of iterations. Both panels: Accuracy, which is equivalent to area under the ROC curve, (error bars) fitted to single sigmoidal functions (solid lines). The four curves from top to bottom correspond to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e051" xlink:type="simple"/></inline-formula> radial frequencies.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.g007" xlink:type="simple"/>
      </fig>
      <p>Overall, average human performance improved as a function of increasing SOA in a manner analogous to the improvement in model performance as a function of the number of iterations of the ODD kernel. This correspondence was especially evident for amoebas of low to moderate complexity (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e052" xlink:type="simple"/></inline-formula>). For more complex targets, model performance lagged well behind that of human subjects. Studies suggest that low and high radial frequencies are processed by different cortical channels <xref ref-type="bibr" rid="pcbi.1002162-Bell1">[46]</xref>. Model performance might have been improved by training a new set of ODD kernels specifically for targets containing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e053" xlink:type="simple"/></inline-formula> radial frequencies, thereby utilizing a hypothetical sub-population of orientation-selective neurons optimized for detecting high-curvature contours. Here, our model was limited to a single multiplicative kernel for detecting all predominately smooth contours.</p>
      <p>To quantify how average human performance on the 2AFC amoeba/no-amoeba task varied with SOA, and to compare with the dependence of model performance on the number of iterations of the ODD kernel, areas under both sets of ROC curves were fit to a monotonically increasing function of the following sigmoidal form:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e054" xlink:type="simple"/><label>(1)</label></disp-formula></p>
      <p>For human experiments, the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e055" xlink:type="simple"/></inline-formula> corresponds to the SOA in ms. Since we expect humans to perform close to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e056" xlink:type="simple"/></inline-formula> accuracy for very long SOA, we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e057" xlink:type="simple"/></inline-formula>. Since humans perform essentially at chance (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e058" xlink:type="simple"/></inline-formula>) for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e059" xlink:type="simple"/></inline-formula> ms SOA, we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e060" xlink:type="simple"/></inline-formula> ms. Thus <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e061" xlink:type="simple"/></inline-formula> was the only free parameter; fits to the average human data were denoted by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e062" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e063" xlink:type="simple"/></inline-formula> has units of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e064" xlink:type="simple"/></inline-formula>. Likewise, model performance was fit to a curve with the same functional form, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e065" xlink:type="simple"/></inline-formula> measuring the number of iterations; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e066" xlink:type="simple"/></inline-formula> was used to denote curve fits to the model data. However, visual inspection of the model data suggests that its performance saturates at less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e067" xlink:type="simple"/></inline-formula> accuracy even after an infinite number of iterations, thus we forced the sigmoidal curve fit to the model results to asymptote at the final measured value of AUC: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e068" xlink:type="simple"/></inline-formula>. Since the model performs better than chance after only <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e069" xlink:type="simple"/></inline-formula> iteration, we set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e070" xlink:type="simple"/></inline-formula>. For both the human experiments and the model performance, the functional form of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e071" xlink:type="simple"/></inline-formula> ensures that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e072" xlink:type="simple"/></inline-formula>, corresponding to a minimal performance equal to chance.</p>
      <p>We find that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e073" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e074" xlink:type="simple"/></inline-formula> behave quite differently as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e075" xlink:type="simple"/></inline-formula>, the number of radial frequencies used in amoeba generation (<xref ref-type="fig" rid="pcbi-1002162-g007">Figure 7</xref>). As anticipated for a relaxational process governed by a single kernel, the model data was well described by a single value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e076" xlink:type="simple"/></inline-formula> (in units of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e077" xlink:type="simple"/></inline-formula>), equal to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e078" xlink:type="simple"/></inline-formula>. For the human subjects data, values of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e079" xlink:type="simple"/></inline-formula> increased from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e080" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e081" xlink:type="simple"/></inline-formula> as a function of amoeba complexity, corresponding to lateral processing times of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e082" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e083" xlink:type="simple"/></inline-formula> ms, respectively. If human performance depended on only a single set of lateral connections, then, at least in the linear approximation case, we might expect human performance to be well described by a single dominant time constant, representing the dominant eigenmode of the horizontal interactions <xref ref-type="bibr" rid="pcbi.1002162-Li1">[47]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Li2">[48]</xref>. Multiple time scales in the human performance case may emerge from any number of physiological mechanisms not included in the present model, including additional non-linearities in the action of the horizontal connections and/or contributions to contour perception from extrastriate areas. Our data do not allow us to make a firm distinction between these possibilities.</p>
      <p>However, one possible interpretation of the present results is that the perception of simple contours is dominated by relatively fast lateral interactions placed early in the visual processing pathway, thereby accounting for the good fit between the model and experimental results for targets of low to moderate complexity. Building on this interpretation, we postulate that the perception of more complex contours requires more extensive, and therefore slower, processing mechanisms involving higher cortical areas, thus explaining the discrepancy between model and experimental performance as target complexity increases. Under the assumption that human perception of simple amoeba targets (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e084" xlink:type="simple"/></inline-formula>) depends primarily on recurrent lateral interactions between orientation-selective neurons, we can estimate the time required for each iteration of the multiplicative ODD kernel. This rate is estimated using the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e085" xlink:type="simple"/></inline-formula> time constants from the fits: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e086" xlink:type="simple"/></inline-formula> ms per iteration, a value consistent with estimates of lateral conduction delays within the same cortical area <xref ref-type="bibr" rid="pcbi.1002162-Bringuier1">[13]</xref>.</p>
      <p>Having shown that the lateral interactions based on multiplicative ODD kernels can account for both spatial and temporal aspects human contour perception, we seek to identify model details that are essential to the performance reported here. First, we demonstrate that the proposed model is robust and does not require that the magnitude of the ODD kernel be carefully titrated to a precise value. Model performance on the 2AFC amoeba/no-amoeba task, measured by the area under the ROC curve (AUC) for increasing numbers of iterations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e087" xlink:type="simple"/></inline-formula>, was plotted for different values of the strength of the ODD kernel, given by the total integrated strengths of the equal and opposite target and distractor contributions (<xref ref-type="fig" rid="pcbi-1002162-g008">Figure 8</xref>). The number of radial frequencies was fixed at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e088" xlink:type="simple"/></inline-formula>. Qualitatively similar performance was obtained for ODD kernel strengths ranging from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e089" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e090" xlink:type="simple"/></inline-formula>. The ODD kernel used in the present study, whose strength was set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e091" xlink:type="simple"/></inline-formula>, produced near optimal performance and also exhibited monotonic improvement with increasing numbers of iterations. That performance was generally insensitive to the value of the main free parameter in the model provides strong evidence for the robustness of the proposed contour detection mechanism based on multiplicative lateral interactions.</p>
      <fig id="pcbi-1002162-g008" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pcbi.1002162.g008</object-id>
        <label>Figure 8</label>
        <caption>
          <title>A comparison of ODD and simpler ‚ÄúBowtie‚Äù kernel performance on the on the 2AFC, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e092" xlink:type="simple"/></inline-formula> amoeba/no amoeba task plotted as a function of the number of iterations for a range of different kernel strengths.</title>
          <p>Line width and marker size denote values on kernel strength, which was the main free parameter in the model. Kernel strength is a dimensionless constant. Black lines: ODD kernel performance. Blue lines: ‚ÄúBowtie‚Äù kernel performance. Qualitative behavior was similar for both kernels, demonstrating that multiplicative lateral interactions act robustly to reinforce smooth closed contours.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.g008" xlink:type="simple"/>
      </fig>
      <p>A second aspect of the model that merits scrutiny is the detailed structure of the ODD kernels, which were trained using computer-generated images in which the pairwise edge statistics uniquely identifying globally salient contours could be calculated directly. Previous models of contour perception typically employed much simpler patterns of lateral connectivity, in which excitatory interactions were either collinear or cocircular, and inhibitory interactions were approximately independent of relative orientation <xref ref-type="bibr" rid="pcbi.1002162-Pettet1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-BenShahar1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Ursino1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Li1">[47]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Mundhenk1">[49]</xref>. To determine if the detailed structure of the ODD kernel was critical to the observed performance, we repeated the amoeba/no-amoeba experiment using a much simpler kernel whose basic form was consistent with a number of previously published models (see <xref ref-type="fig" rid="pcbi-1002162-g008">Figure 8</xref>). Specifically, we used a ‚ÄúBowtie‚Äù kernel in which excitatory connections fanned out with an opening angle of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e093" xlink:type="simple"/></inline-formula> and the difference in the preferred orientations of the pre- and post-synaptic elements differed by no more than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e094" xlink:type="simple"/></inline-formula>. Both excitatory and inhibitory connection strengths fell off in a Gaussian manner, with inhibition strength being insensitive to orientation. Although the overall accuracy of the Bowtie kernels was lower than that achieved by the ODD kernels, performance on the amoeba/no-amoeba tasks was qualitatively similar, particularly regarding the general monotonic improvement with the number of iterations and the absence of a sensitive dependence on kernel strength. Thus, we conclude that multiplicative lateral interactions are able to preserve smooth closed contours while suppressing clutter in a manner that is robust to broad changes in model details.</p>
    </sec>
    <sec id="s3">
      <title>Discussion</title>
      <p>We have shown that simple models of neural activity in primary visual cortex, enriched with lateral association kernels, reproduce some of the behavioral features regarding the human perception of broken closed contours. Our results agree not only with the measured dependence on contour complexity but also with the temporal dependence of human perception as a function of SOA, suggesting that horizontal connections in V1 may play a non-trivial and global computational role in the perception of closed contours on very fast timescales.</p>
      <p>A number of studies relate to the potential contribution of cortical association fields to human contour perception; these encompass a range of anatomical, physiological, psychophysical, and theoretical techniques <xref ref-type="bibr" rid="pcbi.1002162-Field1">[2]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Fitzpatrick1">[5]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Kovcs1">[7]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Kapadia1">[10]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Polat2">[10]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Bringuier1">[11]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Pooresmaeili1">[13]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Bosking1">[16]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Malach1">[19]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Li3">[50]</xref>. In particular, a number of theoretical models have sought to account for human contour perception at the level of biologically-plausible neural circuits <xref ref-type="bibr" rid="pcbi.1002162-Pettet1">[8]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Ursino1">[27]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Sterkin1">[28]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Mundhenk1">[49]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Grossberg1">[51]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Garrigues1">[54]</xref>, with most studies incorporating some form of cortical association field configured to reinforce smoothness <xref ref-type="bibr" rid="pcbi.1002162-BenShahar1">[24]</xref>. Although biologically plausible models of cortical association fields have been used to account for the dependence of contour visibility on key parameters controlling task difficulty, such as smoothness, closure, and density of background clutter <xref ref-type="bibr" rid="pcbi.1002162-Pettet1">[8]</xref>, model cortical association fields have not been directly compared to the time course of human contour perception as a function of contour complexity. Here, we used cortical association fields based on ODD kernels, which were computed from differences in the pairwise coactivation statistics of orientation-selective elements arising from target as opposed to distractor images. While we designed the kernels specifically for the amoeba-clutter disambiguation, we emphasize that the algorithm for the ODD kernel construction is completely general and can be used to improve detection of salient image features in any situation where generative models of targets and distractors are known, or there exists data sets of sufficient size to characterize the contour co-occurrence statistics empirically for both targets and distractors. In our experiments, ODD kernels were able to account for the experimentally observed variations in the saliency of closed contours as a function of parametric complexity and for the time course with which smooth contours are processed by cortical circuits. Crucial for these results was our use of a synthetic target/distractor data set with controllable complexity and the absence of top-down contextual features or local cues that might give away target presence.</p>
      <p>Here, we used a semi-supervised training scheme to learn lateral connectivity patterns optimized for performing the amoeba/no-amoeba task. Necessarily, we sought to model only a subset of the lateral interactions between orientation-selective neurons, namely, those horizontal connections configured to reinforce smooth, closed contours. We did not attempt to capture the full range of spatial relationships between features extracted at early cortical processing stages <xref ref-type="bibr" rid="pcbi.1002162-BenShahar1">[24]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Ing1">[55]</xref>. Presently, databases containing sufficient numbers of fully <italic>annotated</italic> and <italic>segmented</italic> natural images needed to reproduce the weeks (or months) of visual experience required to train the full complement of horizontal connections in the primary visual cortex do not exist. Moreover, the computational resources to exploit such databases, even if they did exist, are highly non-trivial to assemble. Thus, we focused here on a subset of horizontal connections for which it was possible to construct synthetic surrogate images. At most, the proposed model represents a subset‚Äìand only a subset‚Äìof the lateral connections between orientation-selective cortical neurons. Moreover, even a complete set of such horizontal connections would, at most, represent but a subset of the cortical mechanisms that contribute to the time course and shape-dependence of contour perception.</p>
      <p>The supervised training scheme employed here might be related to perceptual learning phenomena, which take place over time scales much shorter than those typically associated with developmental processes <xref ref-type="bibr" rid="pcbi.1002162-Yao1">[56]</xref>‚Äì<xref ref-type="bibr" rid="pcbi.1002162-Li4">[58]</xref>. It is possible that known physiological mechanisms, such as spike-timing-dependent plasticity (STDP), especially with accounts for realistic conduction delays <xref ref-type="bibr" rid="pcbi.1002162-Knoblauch1">[59]</xref>, could mediate a rapid refinement of lateral connections so as to facilitate the perception of amoeba targets. Moreover, physiological plasticity mechanisms might produce different patterns of connectivity for orientation-selective elements representing points of low as opposed to high local curvature, thereby optimizing lateral interactions for contours of varying complexity. Here, we made no attempt to customize distinct ODD kernels for detecting contours of varying complexity. Instead, a single ODD kernel was trained using a complete set of images in which different numbers of radial frequency components were equally represented. Although we did not investigate whether, or to what extent, the performance of human subjects improved over the course of the amoeba/no-amoeba experiment, such investigations might shed insight into the role of perceptual learning in the detection of closed contours.</p>
      <p>The question of how lateral connectivity based on ODD kernels might be acquired during development was not addressed explicitly. In principle, coactivation statistics between pairs of orientation-selective neurons could be accumulated over time in an unsupervised manner by a Hebbian-like learning rule <xref ref-type="bibr" rid="pcbi.1002162-Hoyer1">[60]</xref>. Under natural viewing conditions, we expect that contour fragments consistent with smooth, closed boundaries would tend to occur simultaneously, whereas contour fragments inconsistent with object boundaries would tend occur at random temporal delays. Thus, a Hebbian-like learning rule sensitive to temporal correlations, such as certain mathematical forms of STDP-like learning rules <xref ref-type="bibr" rid="pcbi.1002162-Song1">[61]</xref>, might under normal developmental conditions lead to connectivity patterns that reinforce smooth contours.</p>
      <p>Of course, human contour perception may have nothing to do with cortical association fields, or lateral interactions may play a subordinate role. Early models showed how spatial filtering could enhance texture-defined contours in the absence of orientation-specific interactions <xref ref-type="bibr" rid="pcbi.1002162-Hess1">[4]</xref> and short-range lateral interactions can accentuate texture-defined boundaries <xref ref-type="bibr" rid="pcbi.1002162-Schwabe1">[31]</xref>,<xref ref-type="bibr" rid="pcbi.1002162-Li5">[62]</xref>. However, psychophysical studies employing implicit contours <xref ref-type="bibr" rid="pcbi.1002162-Field1">[2]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Kovcs1">[7]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Pettet1">[8]</xref>, in which foreground and background elements are present at equal density and which lack explicit texture cues, appear to rule out explanations that omit long-range, orientation-specific interactions. An influential class of biologically-inspired computer vision models achieves a degree of viewpoint-invariant object recognition by constructing feed-forward hierarchies to extract progressively more complex and viewpoint invariant features <xref ref-type="bibr" rid="pcbi.1002162-Serre1">[33]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Fukushima1">[63]</xref>. By analogy with such models, scale- and position-independent representations for detecting long, smooth contours could in principle be constructed hierarchically, starting with simple edge detectors and building up progressively longer, more complex curves using a ‚Äúbag-of-features‚Äù approach. Presently, there appear to be insufficient data to decide whether human contour perception involves primarily lateral, feed-forward, or even top-down connections <xref ref-type="bibr" rid="pcbi.1002162-Zhang1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Angelucci1">[32]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Gilbert2">[64]</xref>. Hypothetically, the cortical association fields used in the present study could have been implemented as a feed-forward architecture, using a hierarchy of orientation-selective neurons to link progressively more widely separated contour fragments. Functionally, there may not exist a clean distinction between lateral, feed-forward and feed-back topologies, with the possibility that all three types of connectivity contribute to human contour perception.</p>
      <p>To quantify the temporal dynamics underlying visual processing, we performed speed-of-sight psychophysical experiments that required subjects to detect closed contours (amoebas) spanning a range of shapes, sizes and positions, whose smoothness could be adjusted parametrically by varying the number of radial frequencies (with randomly chosen amplitudes). To better approximate natural viewing conditions, in which target objects usually appear against noisy backgrounds and both foreground and background objects consist of similar low-level visual features, our amoeba/no-amoeba task required amoeba targets to be distinguished from locally indistinguishable open contour fragments (clutter). For amoeba targets consisting of only a few radial frequencies (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e095" xlink:type="simple"/></inline-formula>), human subjects were able to perform at close to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e096" xlink:type="simple"/></inline-formula> accuracy after seeing target/distractor image pairs for less than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e097" xlink:type="simple"/></inline-formula> ms, consistent with a number of studies showing that the recognition of unambiguous targets typically requires <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e098" xlink:type="simple"/></inline-formula> ms to reach asymptotic performance <xref ref-type="bibr" rid="pcbi.1002162-Keysers2">[22]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-BaconMac1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Rolls1">[35]</xref>, here likely aided by the high intrinsic saliency of closed shapes relative to open shapes <xref ref-type="bibr" rid="pcbi.1002162-Kovcs1">[7]</xref>. Because mean inter-saccade intervals are also in the range of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e099" xlink:type="simple"/></inline-formula> ms <xref ref-type="bibr" rid="pcbi.1002162-MartinezConde1">[34]</xref>, speed-of-sight studies indicate that unambiguous targets in most natural images can be recognized in a single glance. Similarly, we found that closed contours of low to moderate complexity readily ‚Äúpop out‚Äù against background clutter, implying that such radial frequency patterns are processed in parallel, presumably by intrinsic cortical circuitry optimized for automatically extracting smooth, closed contours. As saccadic eye movements were unlikely to play a significant role for such brief presentations, it is unclear to what extent attentional mechanisms are relevant to the speed-of-sight amoeba/no-amoeba task.</p>
      <p>Our results further indicate that subjects perform no better than chance at SOAs shorter than approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e100" xlink:type="simple"/></inline-formula> ms. Other studies, however, report above chance performance on unambiguous target detection tasks at similarly short SOA values <xref ref-type="bibr" rid="pcbi.1002162-Velisavljevi1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-BaconMac1">[23]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Mandon1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1002162-Serre1">[33]</xref>. The discrepancy may be attributed to the different masks employed. Whereas the above cited studies used masks consisting of either spatially filtered (e.g. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e101" xlink:type="simple"/></inline-formula>) noise, distractor images, or scrambled versions of the target image set, we constructed rotation masks that were optimized for each target/distractor image pair <xref ref-type="bibr" rid="pcbi.1002162-Hess2">[20]</xref>. Our working hypothesis was that an optimized mask should completely obscure the target object in the target-mask composite image; also referred to as pattern masking. The requirement that the mask completely hide the target follows from the assumption that at very short SOA, the target and mask images are likely to be effectively fused due to the finite response time of neurons and receptors in the early visual system <xref ref-type="bibr" rid="pcbi.1002162-Schneeweis1">[65]</xref>. For the amoeba/no-amoeba task, we created optimized masks by rotating the amoeba and clutter fragments with the goal of producing the maximum amount of interference in the responses of orientation-selective cells. Presumably, maximum interference occurs when orientation-selective neurons are presented with randomly rotated contour fragments in rapid succession. Although backward masks can have heterogeneous effects, with performance in some cases showing a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e102" xlink:type="simple"/></inline-formula>-shaped dependence on SOA <xref ref-type="bibr" rid="pcbi.1002162-Enns1">[66]</xref>, for the masks used here performance always increased monotonically with SOA. Empirically, the fact that performance was no better than chance at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e103" xlink:type="simple"/></inline-formula> ms SOA suggests that our optimized masks were able to effectively interrupt the processing of smooth, closed contours at early cortical processing stages. Indeed, the ability to drive overall performance down to chance at SOA values shorter than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e104" xlink:type="simple"/></inline-formula> ms could provide an operational criteria for assessing the degree to which a given backward pattern mask is able to effectively interrupt visual processing.</p>
      <p>The amoeba/no-amoeba task required the integration of information over length scales spanning viewing angles of approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e105" xlink:type="simple"/></inline-formula>, larger than the classical excitatory receptive field size of parafoveal V1 neurons. The amoeba/no-amoeba image set (see <xref ref-type="fig" rid="pcbi-1002162-g001">Figure 1</xref>) was configured so that purely local information, such as a few adjoining contour fragments, would not be sufficient to solve the target detection problem. Rather, distinguishing amoebas from clutter required integrating global information across multiple contour fragments. Our results suggest that such global integration can be accomplished via lateral interactions between local, orientation-selective filters. Although the density of target and clutter segments was not precisely equilibrated in our amoeba/no-amoeba image set, the wide range of target sizes and shapes spanned by our image generation algorithm makes it unlikely that the near perfect performance of human subjects at long SOA could have been attained using density cues alone <xref ref-type="bibr" rid="pcbi.1002162-Hess1">[4]</xref>. Here, lateral inputs were used to modulate the bottom-up responses in a multiplicative fashion, so that our cortical association fields acted primarily as gates that suppressed contour fragments that did not receive sufficiently strong contextual support. By preventing lateral inputs from producing activity unless there was already a strong bottom-up input, a multiplicative non-linearity prevented the activation of contour fragments not present in the original image.</p>
      <p>The phenomenon of illusory contours suggests that in some cases contextual effects can produce activity even in the absence of a direct bottom-up response <xref ref-type="bibr" rid="pcbi.1002162-Zhang1">[30]</xref>. The precise form of the multiplicative interaction used here was adopted for algorithmic simplicity rather than for biological realism. We observed that including a small additive contribution from the lateral interactions did not fundamentally affect our conclusions. This suggests that ODD kernels, if implemented more generally, might account for the perception of illusory contours as well. However, a more realistic description of the underlying cellular and synaptic dynamics would likely be necessary to model a relaxation process that includes both additive and multiplicative elements.</p>
      <p>Both the model and the psychophysical experiments employed a 2AFC design (see <xref ref-type="fig" rid="pcbi-1002162-g005">Figure 5</xref>) in which the goal was to correctly identify which of a pair of images contained an amoeba target. Since each trial involved a forced choice between two images, the model used a simple classifier that labeled the image with greater total activity as the target. For both human subjects and the model, the number of radial frequencies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e106" xlink:type="simple"/></inline-formula> proved to be a good control parameter for adjusting task difficulty (see <xref ref-type="fig" rid="pcbi-1002162-g007">Figure 7</xref>). For targets of low to moderate complexity, both model performance (as a function of number of iterations) and human performance (as a function of increasing SOA) monotonically approached nearly perfect asymptotic performance as described by a single sigmoidal function with a characteristic scale, representing either time or number of iterations, that increased with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e107" xlink:type="simple"/></inline-formula> (see <xref ref-type="fig" rid="pcbi-1002162-g007">Figure 7</xref>). Based on comparison with human performance at different SOA values, each iteration of the ODD kernels was estimated to require approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e108" xlink:type="simple"/></inline-formula> ms of cortical processing time, consistent with measured conduction delays between laterally connected cortical neurons <xref ref-type="bibr" rid="pcbi.1002162-Bringuier1">[13]</xref>.</p>
      <p>Prior to any lateral interactions, the stimulus was projected onto a retinotopic array of orientation-selective filter elements, providing a convenient representation for learning cortical association fields by computing differences in pairwise coactivation statistics between target and distractor images. We found that each iteration of the ODD kernel increased the activity of contour fragments that were part of amoebas compared to the activity of clutter fragments, so that after several iterations the mean overall activity, summed across all orientation-selective filter elements, was higher on average for target images than distractor images (see <xref ref-type="fig" rid="pcbi-1002162-g004">Figure 4</xref>). Even in trials that were incorrectly classified, contour fragments belonging to amoebas were typically still favored relative to background clutter. Because the total number of contour fragments varied from trial to trial, with only the average number of fragments being fixed across the entire image set, our relatively crude criterion for discriminating between target and distractor images sometimes led to classification errors even when amoeba fragments had been partially segmented from the background clutter, simply because the distractor image initially contained more fragments. A more sophisticated classifier might have led to a closer correspondence between model and human performance. Although performance of the present multiplicative model appeared to saturate after only a few iterations of the ODD kernel (e.g. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e109" xlink:type="simple"/></inline-formula>), it is possible that a different implementation might have continued to show improvements after additional iterations. However, the longer processing time implied by additional iterations suggests that other physiological mechanisms, particularly visual search, would likely come into play. Granted, there is an apparent mismatch between the fading of clutter elements in the model and the persistence of such elements perceptually in human subjects. To reconcile this apparent mismatch, it has been suggested that the initial perception of brightness might be driven by the initial bottom-up response of the individual orientation-selective feature detectors, whereas persistent responses across these same feature detectors might drive salience <xref ref-type="bibr" rid="pcbi.1002162-Sterkin1">[28]</xref>.</p>
      <p>The amoeba/no-amoeba image set was designed to allow for parameterized complexity (in terms of the amount of clutter, number of radial frequencies, etc.) while avoiding reference to exogenous world knowledge. Since the amoeba/no-amoeba image set was machine generated, it was possible to produce a very large number of training images; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e110" xlink:type="simple"/></inline-formula> target and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e111" xlink:type="simple"/></inline-formula> distractor images at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e112" xlink:type="simple"/></inline-formula> pixel resolution were used to train ODD kernels in the present study. Many computer vision systems employ standard image classification datasets such as the Caltech <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e113" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1002162-FeiFei1">[67]</xref>, which allows for uniform benchmarking and thus facilitates direct comparison between models. Datasets based on natural images, however, suffer from several shortcomings. First, the resolution and number of images are fixed when the set is created. While some man-made datasets, such as MNIST <xref ref-type="bibr" rid="pcbi.1002162-LeCun1">[68]</xref>), consist of tens of thousands of handwritten characters, annotated sets of natural photographs ideal for speed-of-sight experiments are typically limited to a few hundred images. In contrast, humans are exposed to millions of natural scenes during visual development. Biologically motivated models that attempt to replicate human performance might require similar numbers of examples. A second shortcoming of natural image datasets is prevalence of high-level contextual information that utilizes exogenous world knowledge, such as the increased a priori likelihood of finding a car on a road, or an animal in a forest. Exploiting such exogenous world knowledge posses a formidable challenge for existing computational models and, on tasks that employ natural images, may obscure the ability of such models to extract behaviorally meaningful information from low-level visual cues. Third, natural image datasets typically provide limited capability for adjusting intrinsic task difficultly. For example, one widely used dataset <xref ref-type="bibr" rid="pcbi.1002162-Serre1">[33]</xref> includes photographs of animals at different distances, but only a few discrete distances are annotated and the relationship of target distance to task difficultly is not easily quantified. Here, we illustrated how a synthetic set of images could be used to compare model and human performance in a task with parametric difficulty, potentially validating the use of artificial as opposed to natural images.</p>
      <p>The present study addressed the role of cortical association fields in the perception of closed contours, which are presumably important for detecting visual targets based on shape or outline. Although studies show that human subjects can rapidly distinguish between images containing target and non-target object categories using only the line drawings obtained by filtering natural scenes <xref ref-type="bibr" rid="pcbi.1002162-Velisavljevi1">[1]</xref>, normal experience involves a number of complementary visual cues, such as texture, color, motion and stereopsis. Presumably, cortical association fields also act to reinforce features representing these complementary visual cues as well. Human subjects, for example, can distinguish whether pairs of texture patches were drawn from the same natural object or two different natural objects in a manner that exhibits a similar dependence on pairwise co-occurrence statistics as was found for orientated edges <xref ref-type="bibr" rid="pcbi.1002162-Ing1">[55]</xref>. We may speculate that an analysis of coactivation statistics for features selective to a combination of cues such as local orientation, texture, color, motion, and disparity may lead to a more general and more powerful set of kernels capable of fast and effective determination of global object properties, which in turn can play an important role in complex object identification.</p>
    </sec>
    <sec id="s4" sec-type="methods">
      <title>Methods</title>
      <sec id="s4a">
        <title>Synthetic amoeba/no-amoeba image set</title>
        <p>An <italic>amoeba</italic> is a type of radial frequency pattern <xref ref-type="bibr" rid="pcbi.1002162-Wilkinson1">[36]</xref> consisting of a deformed circle in which the radius varies as a function of the polar angle. By choosing the number and relative amplitudes of the different frequency components, the radius can describe an arbitrarily complex shape, exactly analogous to how a Fourier basis can be used to construct an arbitrary waveform on a finite interval. Each radial frequency component was represented by a sinusoidal function defined at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e114" xlink:type="simple"/></inline-formula> discrete polar angles, spaced uniformly on the interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e115" xlink:type="simple"/></inline-formula>. The cutoff radial frequency used in constructing the closed contour provided a control parameter for regulating the complexity of the resulting figure, which ranged from nearly circular, when only the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e116" xlink:type="simple"/></inline-formula> lowest radial frequencies had non-zero amplitudes, to highly sinusoidal and irregular, when the first <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e117" xlink:type="simple"/></inline-formula> radial frequencies had non-zero amplitudes. All amoeba shapes generated here may be considered smooth, in that local curvature was always bounded.</p>
        <p>In detail, the radius of an amoeba at each polar angle was:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e118" xlink:type="simple"/><label>(2)</label></disp-formula></p>
        <p>All amplitudes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e119" xlink:type="simple"/></inline-formula> were initially drawn from normal distributions with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e120" xlink:type="simple"/></inline-formula> mean and unit variance. All phases <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e121" xlink:type="simple"/></inline-formula> were drawn from uniform distributions over the interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e122" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e123" xlink:type="simple"/></inline-formula>. The resulting radial frequency pattern was then linearly rescaled so that the maximum radius, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e124" xlink:type="simple"/></inline-formula>, was equal to a random number drawn from a uniform distribution such that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e125" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e126" xlink:type="simple"/></inline-formula> is the linear size of the square image (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e127" xlink:type="simple"/></inline-formula> pixels), and the minimum radius was given by a second randomly chosen value so that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e128" xlink:type="simple"/></inline-formula>. Uniform pseudo-random numbers were generated by the intrinsic MATLAB <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e129" xlink:type="simple"/></inline-formula> function RAND, or its Octave <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e130" xlink:type="simple"/></inline-formula> equivalent.</p>
        <p>To facilitate the construction of locally indistinguishable clutter and model contour occlusion in natural images, amoeba contours were divided into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e131" xlink:type="simple"/></inline-formula> periodically-spaced fragments by removing short sections whose lengths varied within a specified range. Specifically, the gaps between amoeba fragments varied from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e132" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e133" xlink:type="simple"/></inline-formula> in units of discrete polar angle <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e134" xlink:type="simple"/></inline-formula>. Amoeba contours were then broken into fragments by periodically inserting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e135" xlink:type="simple"/></inline-formula> gaps of variable width ranging from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e136" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e137" xlink:type="simple"/></inline-formula>, spaced <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e138" xlink:type="simple"/></inline-formula> segments apart. Gaps were deleted from the underlying contour, so that the polar angle subtended by each fragment varied in accordance with the changes in preceding gap width. The starting point of the first gap was chosen randomly on the interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e139" xlink:type="simple"/></inline-formula>, so that over the entire image set the inserted gaps were distributed uniformly around the circle.</p>
        <p>To create clutter fragments, an amoeba was first generated using the above procedure. Consecutive amoeba fragments were then grouped, with the number of fragments in each group determined by a Poisson process with a mean value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e140" xlink:type="simple"/></inline-formula> and an upper cutoff of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e141" xlink:type="simple"/></inline-formula>. Each group of amoeba fragments was then rotated about its center of mass through random angles on the interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e142" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e143" xlink:type="simple"/></inline-formula>. The resulting clutter consisted of the same fragments as the original amoeba but rotated so that collectively the rotated fragments no longer supported the perception of a closed object. Clutter fragments constructed in this manner were thus locally indistinguishable from amoeba fragments. To create clutter in both target and distractor images, several amoebas were first superimposed at random positions and then groups of fragments rotated following the procedure described above. All amoebas contained the same total number of contour fragments (and therefore the same number of gaps) but varied in both maximum diameter and total contour length.</p>
        <p>The center of each amoeba was chosen randomly under the restriction that no contour be allowed to cross an image boundary. Specifically, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e144" xlink:type="simple"/></inline-formula>-coordinate of the amoeba center, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e145" xlink:type="simple"/></inline-formula>, was chosen randomly on a restricted interval, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e146" xlink:type="simple"/></inline-formula>, and likewise for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e147" xlink:type="simple"/></inline-formula>-coordinate, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e148" xlink:type="simple"/></inline-formula>. When groups of amoeba fragments were randomly rotated to make clutter, portions of a contour belonging to a clutter fragment would occasionally cross an image boundary. In such cases, any out-of-bounds portions of a contour were reflected back into the image region using mirror boundary conditions.</p>
        <p>Target images always consisted of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e149" xlink:type="simple"/></inline-formula> set of amoeba fragments and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e150" xlink:type="simple"/></inline-formula> sets of clutter fragments. Distractor images consisted of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e151" xlink:type="simple"/></inline-formula> sets of clutter fragments and thus, averaged over the entire image set, had the same mean luminance and the same variance as the target images. Mask images were constructed following a procedure nearly identical to that used for constructing distractor images, except that mask images consisted of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e152" xlink:type="simple"/></inline-formula> sets of clutter fragments, obtained by randomly rotating the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e153" xlink:type="simple"/></inline-formula> original amoeba objects used in constructing the corresponding target and distractor images. All contour fragments were initially represented as a set of points in polar coordinates, corresponding to the radius at each discrete polar angle. Points along the contour were then transformed back to Cartesian coordinates and rounded to the nearest discrete pixel value. MATLAB scripts for generating the image set used in this study are publicly available at: <ext-link ext-link-type="uri" xlink:href="http://petavision.sourceforge.net" xlink:type="simple">http://petavision.sourceforge.net</ext-link>.</p>
      </sec>
      <sec id="s4b">
        <title>Ethics statement</title>
        <p>The Los Alamos National Laboratory (LANL) Human Subjects Research Review Board (HSRRB) has reviewed the following experimental protocol and determined that it provides adequate safeguards for protecting the rights and welfare of human subjects involved in the protocol. The protocol was reviewed and approved in compliance with the U.S. Department of Health and Human Services (DHHS) regulations for the Protection of Human Subjects, 45 CFR 46, and in accordance with the LANL Federal Wide Assurance (FWA#00000362) with the National Institutes of Health/Office for Human Research Protections (NIH/OHRP). The identification number is LANL 08-03 X.</p>
      </sec>
      <sec id="s4c">
        <title>Human psychophysics</title>
        <p>Human performance was evaluated using two-alternative forced choice (2AFC) psychophysical experiments. There were <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e154" xlink:type="simple"/></inline-formula> subjects, all with normal or corrected-to-normal vision. One subject only contributed data for a portion of the tested SOAs. Each subject was seated in a dark room, at an approximate distance of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e155" xlink:type="simple"/></inline-formula> cm from a <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e156" xlink:type="simple"/></inline-formula>-inch nominal (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e157" xlink:type="simple"/></inline-formula> cm actual size) Hitachi <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e158" xlink:type="simple"/></inline-formula> CRT monitor. Images spanned a viewing angle of approximately <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e159" xlink:type="simple"/></inline-formula>. The monitor resolution was <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e160" xlink:type="simple"/></inline-formula> pixels and the refresh rate was <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e161" xlink:type="simple"/></inline-formula> Hz. The display was driven by a dual-core <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e162" xlink:type="simple"/></inline-formula> GHz Mac Pro, with MATLAB <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e163" xlink:type="simple"/></inline-formula> running Psychtoolbox <xref ref-type="bibr" rid="pcbi.1002162-Brainard1">[69]</xref>.</p>
        <p>After a short training period to familiarize the subject with the task, one target image and one distractor image were shown side by side, followed by a mask intended to interrupt cognitive processing of the target and distractor images. Two separate sets of experiments were conducted for each subject. In one set, the SOA was chosen randomly from the values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e164" xlink:type="simple"/></inline-formula> ms. For the second set of experiments, the SOA was chosen randomly from the values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e165" xlink:type="simple"/></inline-formula> ms. The duration of the stimulus was always the same as the SOA, and thus both the target and distractor images remained visible until mask onset. The duration of the mask was always <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e166" xlink:type="simple"/></inline-formula> ms. Each subject was shown <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e167" xlink:type="simple"/></inline-formula> images divided into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e168" xlink:type="simple"/></inline-formula> blocks of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e169" xlink:type="simple"/></inline-formula> images, with rest breaks in between blocks (rest break duration was at the discretion of each subject). The pace of the experiment was under the control of the subject, who initiated each trial using the space bar. A small temporal jitter, chosen uniformly between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e170" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e171" xlink:type="simple"/></inline-formula> ms, was added to the interval preceding each trial, to prevent entrainment. Task conditions, consisting of variations in both the SOA and the number of radial frequencies <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e172" xlink:type="simple"/></inline-formula>, were randomly interleaved such that each condition occurred the same number of times over the course of the entire experiment.</p>
        <p>On each trial, subjects indicated which side contained the target, using a mouse-driven slider bar to report confidence (see <xref ref-type="fig" rid="pcbi-1002162-g005">Figure 5</xref>). The reported confidence values were used to construct receiver operating characteristic (ROC) curves, which plot the percentage of true positives (or hits) against the percentage of false positives (or false alarms), with each true/false positive pair obtained by setting a confidence threshold at a different location along the slider bar. A correct response was not necessarily considered a true positive: to generate one point on the ROC curve, the reported confidence on each trial was measured relative to the current threshold position, which could be to either the left or to the right of center. Thus, a trial might be labeled as incorrect, even though the subject moved the slider bar in the correct direction, as long as the threshold level was not exceeded. Specifically, whenever the reported confidence fell to the left of threshold, the corresponding trial was treated as though the subject reported the target as being to the left, even if the threshold location had been set to the right of center and the confidence bar had actually been slid to the right. Likewise, when the reported confidence fell to the right of the current threshold position, the trial was always treated as if the subject had reported the target to the right, again regardless of how the subject moved the slider bar relative to the center position. By choosing a range of threshold positions, spanning the full range of reported confidence values, a complete ROC curve was obtained. Note that as the threshold was moved closer to the left edge of the slider bar, the percentage of true and false positives both approached minimum values, since only trials with very high reported confidence could contribute to either the true positive or false positive rate (most trials were rejected as either true or false negatives). As the threshold position moved closer to the center of the confidence slider bar, the percentage of true positives increased. Finally, as the threshold was moved closer to the right edge of the slider bar, both the true positive rate and the percentage of false positives approached maximum values. The true positive rate averaged over all false positive rates, or the area under the ROC curve (AUC), was used as an overall measure of subject performance. The AUC is equivalent to the probability that a randomly chosen target image will be correctly classified relative to a randomly chosen distractor image, and thus directly predicts performance on the 2AFC task. Results for each SOA and for each value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e173" xlink:type="simple"/></inline-formula> were averaged over <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e174" xlink:type="simple"/></inline-formula> subjects. Error bars denote the standard deviation over the 5 subjects.</p>
      </sec>
      <sec id="s4d">
        <title>Model</title>
        <p>Model cortical association fields were based on differences in the coactivation statistics of orientation-selective filter elements drawn from target and distractor images. Geisler and Perry measured co-occurrence statistics for oriented edges in human segmented natural images <xref ref-type="bibr" rid="pcbi.1002162-Geisler1">[25]</xref>, and found a close correspondence to human judgments as to whether pairs of short line fragments were drawn from the same or different contours. Thus, we refer to the difference in coactivation statistics between target object and distractor images as Object-Distractor Difference (ODD) kernels. ODD kernels were trained using <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e175" xlink:type="simple"/></inline-formula> target and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e176" xlink:type="simple"/></inline-formula> distractor images, each divided into <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e177" xlink:type="simple"/></inline-formula> sets of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e178" xlink:type="simple"/></inline-formula> images each, with each set associated with a different value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e179" xlink:type="simple"/></inline-formula>. The order in which the images were presented had no bearing on the final form of the ODD kernel; that is, there was no temporal component to the training. Training with more images did not substantively improve performance, although small differences were observed in the ODD kernels trained using a smaller number of images (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e180" xlink:type="simple"/></inline-formula> target and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e181" xlink:type="simple"/></inline-formula> distractor images).</p>
        <p>Each <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e182" xlink:type="simple"/></inline-formula> pixel training image activated a regular array of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e183" xlink:type="simple"/></inline-formula> retinal elements whose outputs were either <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e184" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e185" xlink:type="simple"/></inline-formula>, depending on whether the corresponding image pixel was ON or OFF, respectively. Each retinal unit activated a local neighborhood of orientation-selective filters, which spanned <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e186" xlink:type="simple"/></inline-formula> angles spaced uniformly between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e187" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e188" xlink:type="simple"/></inline-formula>. To mitigate aliasing effects, the orientation-selective filters were rotated by a small, fixed offset, equal to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e189" xlink:type="simple"/></inline-formula>, relative to the axis of the training images. All orientation-selective filters were <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e190" xlink:type="simple"/></inline-formula> pixels in extent and consisted of a central excitatory subunit, represented by an elliptical Gaussian with a standard deviation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e191" xlink:type="simple"/></inline-formula> in the longest direction and an aspect ratio of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e192" xlink:type="simple"/></inline-formula>, flanked by two inhibitory subunits whose shapes were identical to the central excitatory subunit but were offset by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e193" xlink:type="simple"/></inline-formula> pixels in the direction orthogonal to the preferred axis.</p>
        <p>The weight <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e194" xlink:type="simple"/></inline-formula>, from a retinal element at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e195" xlink:type="simple"/></inline-formula> to a filter element at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e196" xlink:type="simple"/></inline-formula> with dominant orientation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e197" xlink:type="simple"/></inline-formula>, was given by a sum over excitatory and inhibitory subunits:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e198" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e199" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e200" xlink:type="simple"/><label>(3)</label></disp-formula>where the position vector is given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e201" xlink:type="simple"/></inline-formula> and the matrix <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e202" xlink:type="simple"/></inline-formula> describes the shape of the elliptical Gaussian subunits for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e203" xlink:type="simple"/></inline-formula>. In Eq. 3, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e204" xlink:type="simple"/></inline-formula> is a unitary rotation matrix,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e205" xlink:type="simple"/><label>(4)</label></disp-formula>and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e206" xlink:type="simple"/></inline-formula> is a translation vector in the direction orthogonal to the dominant orientation when <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e207" xlink:type="simple"/></inline-formula>. The amplitude <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e208" xlink:type="simple"/></inline-formula> was determined empirically so that the total integrated strength of all excitatory connections made by each retinal unit equaled <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e209" xlink:type="simple"/></inline-formula> (and thus the total strength of all inhibitory connections made by each retinal unit equaled <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e210" xlink:type="simple"/></inline-formula>). Mirror boundary conditions were used to mitigate edge effects. The retinal input to each orientation-selective filter element <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e211" xlink:type="simple"/></inline-formula> was then given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e212" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e213" xlink:type="simple"/></inline-formula> is the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e214" xlink:type="simple"/></inline-formula> binary input image patch centered on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e215" xlink:type="simple"/></inline-formula>. The sum is over all pixels <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e216" xlink:type="simple"/></inline-formula> that are part of this image patch. The initial output of each orientation-selective filter element <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e217" xlink:type="simple"/></inline-formula> was obtained by comparing the sum of its excitatory and inhibitory retinal input to a fixed threshold of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e218" xlink:type="simple"/></inline-formula>. Values below threshold were set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e219" xlink:type="simple"/></inline-formula> whereas values above unity were set to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e220" xlink:type="simple"/></inline-formula>. Thus<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e221" xlink:type="simple"/><label>(6)</label></disp-formula>where the function,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e222" xlink:type="simple"/><label>(7)</label></disp-formula>is an element-wise implementation of these thresholds. The responses of all suprathreshold orientation-selective filters contributed to the coactivation statistics, with only the relative distance, direction, and orientation of filter pairs recorded. Because of the threshold condition, only the most active orientation-selective filters contributed to the coactivation statistics.</p>
        <p>For every suprathreshold filter element extracted from the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e223" xlink:type="simple"/></inline-formula>-th target image, coactivation statistics were accumulated relative to all surrounding suprathreshold filter elements extracted from the same image. Thus the ODD kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e224" xlink:type="simple"/></inline-formula> is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e225" xlink:type="simple"/><label>(8)</label></disp-formula>where the radial distance <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e226" xlink:type="simple"/></inline-formula> is a function of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e227" xlink:type="simple"/></inline-formula> coordinates of the two filter elements, the direction <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e228" xlink:type="simple"/></inline-formula> is the angle measured relative to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e229" xlink:type="simple"/></inline-formula>, the sum is over all suprathreshold elements within a cutoff radius of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e230" xlink:type="simple"/></inline-formula>, the superscript <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e231" xlink:type="simple"/></inline-formula> denotes the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e232" xlink:type="simple"/></inline-formula>-th target image, and the difference in the orientations of the two filter elements <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e233" xlink:type="simple"/></inline-formula> is taken modulo <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e234" xlink:type="simple"/></inline-formula>. Because the amoeba/no-amoeba image set was translationally invariant and isotropic, the central filter element may without loss of generality be shifted and rotated to a canonical position and orientation, so that the dependence on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e235" xlink:type="simple"/></inline-formula> may be omitted. The coactivation statistics for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e236" xlink:type="simple"/></inline-formula>-th target image can then be written simply as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e237" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e238" xlink:type="simple"/></inline-formula> gives the distance and direction from the origin to the filter element with orientation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e239" xlink:type="simple"/></inline-formula>, given that the filter element at the origin has orientation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e240" xlink:type="simple"/></inline-formula>. An analogous expression gives the coactivation statistics for the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e241" xlink:type="simple"/></inline-formula>-th distractor image <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e242" xlink:type="simple"/></inline-formula>. The ODD kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e243" xlink:type="simple"/></inline-formula> is given by the difference<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e244" xlink:type="simple"/><label>(9)</label></disp-formula>where the sums are taken over all target and distractor images and the normalization factors <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e245" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e246" xlink:type="simple"/></inline-formula> are determined empirically so as to yield a total ODD strength of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e247" xlink:type="simple"/></inline-formula> (see <xref ref-type="fig" rid="pcbi-1002162-g008">Figure 8</xref> and <italic><xref ref-type="sec" rid="s2">Results</xref></italic>), defined as the sum over all ODD kernel elements arising from either the target or distractor components. By construction, the sum over all ODD kernel elements equals zero, so that the average lateral support for randomly distributed edge fragments would be neutral. Our results did not depend critically on the RMS magnitude of the ODD kernel (see <xref ref-type="fig" rid="pcbi-1002162-g008">Figure 8</xref>). To minimize storage requirements individual connection strengths were stored as unsigned 8-bit integers, so that the results of the present study did not depend on computation of high precision kernels.</p>
        <p>As described above, the canonical ODD kernel is defined relative to filter elements at the origin with orientation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e248" xlink:type="simple"/></inline-formula>. Filter elements located away from the origin can be accounted for by a trivial translation. To account for filter elements with different orientations, separate ODD kernels were computed for all <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e249" xlink:type="simple"/></inline-formula> orientations then rotated to a common orientation and averaged to produce a canonical ODD kernel. The canonical kernel was then rotated in steps between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e250" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e251" xlink:type="simple"/></inline-formula> (offset by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e252" xlink:type="simple"/></inline-formula>) and then interpolated to Cartesian <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e253" xlink:type="simple"/></inline-formula> axes by rounding to the nearest integer coordinates. Although it has been demonstrated that global contour saliency is enhanced for orientations along the cardinal axes <xref ref-type="bibr" rid="pcbi.1002162-Li4">[58]</xref>, this bias is by construction absent from this model.</p>
        <p>ODD kernels were used to compute lateral support for each orientation-selective filter element, via linear convolution. The output of each filter element was then modulated in a multiplicative fashion by the computed lateral support. The procedure was iterated by calculating new values for the lateral support <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e254" xlink:type="simple"/></inline-formula>, which were again used to modulate filter outputs in a multiplicative fashion:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e255" xlink:type="simple"/><label>(10)</label></disp-formula>where the subscript <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e256" xlink:type="simple"/></inline-formula> denotes the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e257" xlink:type="simple"/></inline-formula>-th iteration. The same kernel was used for all iterations. All source code used to train and apply cortical association fields is publicly available at</p>
        <p><ext-link ext-link-type="uri" xlink:href="http://sourceforge.net/projects/petavision/" xlink:type="simple">http://sourceforge.net/projects/petavision/</ext-link>.</p>
        <p>To measure model performance, in each trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e258" xlink:type="simple"/></inline-formula> target image and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e259" xlink:type="simple"/></inline-formula> distractor image were tested as a pair, so as to emulate the 2AFC format of the human experiments. The orientation-selective filter responses to both test images were evaluated after <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e260" xlink:type="simple"/></inline-formula> iterations of the ODD kernel. The total activation across all filter elements, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e261" xlink:type="simple"/></inline-formula>, was used to compare the two test images. Since the model cortical association fields tended to support contour fragments belonging to amoebas while inhibiting clutter fragments, the image with higher total activation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e262" xlink:type="simple"/></inline-formula> was assumed to be the target image. Error bars for the model performance (as shown in <xref ref-type="fig" rid="pcbi-1002162-g007">Figure 7</xref>) were estimated using the standard deviation of a binomial distribution with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e263" xlink:type="simple"/></inline-formula> equal to percent correct and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1002162.e264" xlink:type="simple"/></inline-formula> equal to the number of trials.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>The authors wish to thank Steven Zucker for stimulating discussions that helped initiate this project.</p>
    </ack>
    <ref-list>
      <title>References</title>
      <ref id="pcbi.1002162-Velisavljevi1">
        <label>1</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Velisavljeviƒá</surname><given-names>L</given-names></name><name name-style="western"><surname>Elder</surname><given-names>JH</given-names></name></person-group>             <year>2009</year>             <article-title>Cue dynamics underlying rapid detection of animals in natural scenes.</article-title>             <source>J Vision</source>             <volume>9</volume>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Field1">
        <label>2</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Field</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Hayes</surname><given-names>A</given-names></name><name name-style="western"><surname>Hess</surname><given-names>RF</given-names></name></person-group>             <year>1993</year>             <article-title>Contour integration by the human visual system: Evidence for a local ‚Äúassociation field‚Äù.</article-title>             <source>Vision Res</source>             <volume>33</volume>             <fpage>173</fpage>             <lpage>193</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Loffler1">
        <label>3</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Loffler</surname><given-names>G</given-names></name></person-group>             <year>2008</year>             <article-title>Perception of contours and shapes: Low and intermediate stage mechanisms.</article-title>             <source>Vision Res</source>             <volume>48</volume>             <fpage>2106</fpage>             <lpage>2127</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Hess1">
        <label>4</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hess</surname><given-names>R</given-names></name><name name-style="western"><surname>Field</surname><given-names>D</given-names></name></person-group>             <year>1999</year>             <article-title>Integration of contours: new insights.</article-title>             <source>Trends Cogn Sci</source>             <volume>3</volume>             <fpage>480</fpage>             <lpage>486</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Fitzpatrick1">
        <label>5</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fitzpatrick</surname><given-names>D</given-names></name></person-group>             <year>2000</year>             <article-title>Seeing beyond the receptive field in primary visual cortex.</article-title>             <source>Curr Opin in Neurobiol</source>             <volume>10</volume>             <fpage>438</fpage>             <lpage>443</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Seris1">
        <label>6</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Seri√©s</surname><given-names>P</given-names></name><name name-style="western"><surname>Lorenceau</surname><given-names>J</given-names></name><name name-style="western"><surname>Fr√©gnac</surname><given-names>Y</given-names></name></person-group>             <year>2003</year>             <article-title>The ‚Äúsilent‚Äù surround of v1 receptive fields: theory and experiments.</article-title>             <source>J Physiol Paris</source>             <volume>97</volume>             <fpage>453</fpage>             <lpage>474</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Kovcs1">
        <label>7</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kov√°cs</surname><given-names>I</given-names></name><name name-style="western"><surname>Julesz</surname><given-names>B</given-names></name></person-group>             <year>1993</year>             <article-title>A closed curve is much more than an incomplete one: effect of closure in figure-ground segmentation.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>90</volume>             <fpage>7495</fpage>             <lpage>7497</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Pettet1">
        <label>8</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pettet</surname><given-names>MW</given-names></name><name name-style="western"><surname>McKee</surname><given-names>SP</given-names></name><name name-style="western"><surname>Grzywacz</surname><given-names>NM</given-names></name></person-group>             <year>1998</year>             <article-title>Constraints on long range interactions mediating contour detection.</article-title>             <source>Vision Res</source>             <volume>38</volume>             <fpage>865</fpage>             <lpage>879</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Polat1">
        <label>9</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Polat</surname><given-names>U</given-names></name><name name-style="western"><surname>Sagi</surname><given-names>D</given-names></name></person-group>             <year>1993</year>             <article-title>Lateral interactions between spatial channels: Suppression and facilitation revealed by lateral masking experiments.</article-title>             <source>Vision Res</source>             <volume>33</volume>             <fpage>993</fpage>             <lpage>999</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Kapadia1">
        <label>10</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Kapadia</surname><given-names>MK</given-names></name><name name-style="western"><surname>Ito</surname><given-names>M</given-names></name><name name-style="western"><surname>Gilbert</surname><given-names>CD</given-names></name><name name-style="western"><surname>Westheimer</surname><given-names>G</given-names></name></person-group>             <year>1995</year>             <article-title>Improvement in visual sensitivity by changes in local context: Parallel studies in human observers and in v1 of alert monkeys.</article-title>             <source>Neuron</source>             <volume>15</volume>             <fpage>843</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Polat2">
        <label>11</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Polat</surname><given-names>U</given-names></name><name name-style="western"><surname>Terkin</surname><given-names>A</given-names></name><name name-style="western"><surname>Yehezkel</surname><given-names>O</given-names></name></person-group>             <year>2008</year>             <article-title>Spatio-temporal low-level neural networks account for visual masking.</article-title>             <source>Adv Cogn Psych</source>             <volume>3</volume>             <fpage>153</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Huang1">
        <label>12</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Huang</surname><given-names>PC</given-names></name><name name-style="western"><surname>Hess</surname><given-names>RF</given-names></name></person-group>             <year>2007</year>             <article-title>Collinear facilitation: Effect of additive and multiplicative external noise.</article-title>             <source>Vision Res</source>             <volume>47</volume>             <fpage>3108</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Bringuier1">
        <label>13</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bringuier</surname><given-names>V</given-names></name><name name-style="western"><surname>Chavane</surname><given-names>F</given-names></name><name name-style="western"><surname>Glaeser</surname><given-names>L</given-names></name><name name-style="western"><surname>Fr√©gnac</surname><given-names>Y</given-names></name></person-group>             <year>1999</year>             <article-title>Horizontal Propagation of Visual Activity in the Synaptic Integration Field of Area 17 Neurons.</article-title>             <source>Science</source>             <volume>283</volume>             <fpage>695</fpage>             <lpage>699</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Cavanaugh1">
        <label>14</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cavanaugh</surname><given-names>JR</given-names></name><name name-style="western"><surname>Bair</surname><given-names>W</given-names></name><name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name></person-group>             <year>2002</year>             <article-title>Nature and interaction of signals from the receptive field center and surround in macaque v1 neurons.</article-title>             <source>J Neurophys</source>             <volume>88</volume>             <fpage>2530</fpage>             <lpage>2546</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Cavanaugh2">
        <label>15</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Cavanaugh</surname><given-names>JR</given-names></name><name name-style="western"><surname>Bair</surname><given-names>W</given-names></name><name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name></person-group>             <year>2002</year>             <article-title>Selectivity and spatial distribution of signals from the receptive field surround in macaque v1 neurons.</article-title>             <source>J Neurophys</source>             <volume>88</volume>             <fpage>2547</fpage>             <lpage>2556</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Pooresmaeili1">
        <label>16</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Pooresmaeili</surname><given-names>A</given-names></name><name name-style="western"><surname>Herrero</surname><given-names>JL</given-names></name><name name-style="western"><surname>Self</surname><given-names>MW</given-names></name><name name-style="western"><surname>Roelfsema</surname><given-names>PR</given-names></name><name name-style="western"><surname>Thiele</surname><given-names>A</given-names></name></person-group>             <year>2010</year>             <article-title>Suppressive Lateral Interactions at Parafoveal Representations in Primary Visual Cortex.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>12745</fpage>             <lpage>12758</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Bosking1">
        <label>17</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bosking</surname><given-names>WH</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y</given-names></name><name name-style="western"><surname>Schofield</surname><given-names>B</given-names></name><name name-style="western"><surname>Fitzpatrick</surname><given-names>D</given-names></name></person-group>             <year>1997</year>             <article-title>Orientation Selectivity and the Arrangement of Horizontal Connections in Tree Shrew Striate Cortex.</article-title>             <source>J Neurosci</source>             <volume>17</volume>             <fpage>2112</fpage>             <lpage>2127</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Gilbert1">
        <label>18</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gilbert</surname><given-names>C</given-names></name><name name-style="western"><surname>Wiesel</surname><given-names>T</given-names></name></person-group>             <year>1989</year>             <article-title>Columnar specificity of intrinsic horizontal and corticocortical connections in cat visual cortex.</article-title>             <source>J Neurosci</source>             <volume>9</volume>             <fpage>2432</fpage>             <lpage>2442</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Malach1">
        <label>19</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Malach</surname><given-names>R</given-names></name><name name-style="western"><surname>Amir</surname><given-names>Y</given-names></name><name name-style="western"><surname>Harel</surname><given-names>M</given-names></name><name name-style="western"><surname>Grinvald</surname><given-names>A</given-names></name></person-group>             <year>1993</year>             <article-title>Relationship between intrinsic connections and functional architecture revealed by optical imaging and in vivo targeted biocytin injections in primate striate cortex.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>90</volume>             <fpage>10469</fpage>             <lpage>10473</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Hess2">
        <label>20</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hess</surname><given-names>RF</given-names></name><name name-style="western"><surname>Beaudot</surname><given-names>WHA</given-names></name><name name-style="western"><surname>Mullen</surname><given-names>KT</given-names></name></person-group>             <year>2001</year>             <article-title>Dynamics of contour integration.</article-title>             <source>Vision Res</source>             <volume>41</volume>             <fpage>1023</fpage>             <lpage>1037</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Keysers1">
        <label>21</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Keysers</surname><given-names>C</given-names></name><name name-style="western"><surname>Xiao</surname><given-names>DK</given-names></name><name name-style="western"><surname>F√∂ldi√†k</surname><given-names>P</given-names></name><name name-style="western"><surname>Perrett</surname><given-names>DI</given-names></name></person-group>             <year>2001</year>             <article-title>The speed of sight.</article-title>             <source>J Cognitive Neurosci</source>             <volume>13</volume>             <fpage>90</fpage>             <lpage>101</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Keysers2">
        <label>22</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Keysers</surname><given-names>C</given-names></name><name name-style="western"><surname>Perrett</surname><given-names>DI</given-names></name></person-group>             <year>2002</year>             <article-title>Visual masking and rsvp reveal neural competition.</article-title>             <source>Trends Cogn Sci</source>             <volume>6</volume>             <fpage>120</fpage>             <lpage>125</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-BaconMac1">
        <label>23</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bacon-Mac√©</surname><given-names>N</given-names></name><name name-style="western"><surname>Mac√©</surname><given-names>MJM</given-names></name><name name-style="western"><surname>Fabre-Thorpe</surname><given-names>M</given-names></name><name name-style="western"><surname>Thorpe</surname><given-names>SJ</given-names></name></person-group>             <year>2005</year>             <article-title>The time course of visual processing: Backward masking and natural scene categorisation.</article-title>             <source>Vision Res</source>             <volume>45</volume>             <fpage>1459</fpage>             <lpage>1469</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-BenShahar1">
        <label>24</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ben-Shahar</surname><given-names>O</given-names></name><name name-style="western"><surname>Zucker</surname><given-names>S</given-names></name></person-group>             <year>2004</year>             <article-title>Geometrical computations explain projection patterns of long-range horizontal connections in visual cortex.</article-title>             <source>Neural Comput</source>             <volume>16</volume>             <fpage>445</fpage>             <lpage>476</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Geisler1">
        <label>25</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Geisler</surname><given-names>WS</given-names></name><name name-style="western"><surname>Perry</surname><given-names>JS</given-names></name></person-group>             <year>2009</year>             <article-title>Contour statistics in natural images: Grouping across occlusions.</article-title>             <source>Visual Neurosci</source>             <volume>26</volume>             <fpage>109</fpage>             <lpage>121</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Mandon1">
        <label>26</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mandon</surname><given-names>S</given-names></name><name name-style="western"><surname>Kreiter</surname><given-names>AK</given-names></name></person-group>             <year>2005</year>             <article-title>Rapid contour integration in macaque monkeys.</article-title>             <source>Vision Res</source>             <volume>45</volume>             <fpage>291</fpage>             <lpage>300</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Ursino1">
        <label>27</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ursino</surname><given-names>M</given-names></name><name name-style="western"><surname>Cara</surname><given-names>GEL</given-names></name></person-group>             <year>2004</year>             <article-title>A model of contextual interactions and contour detection in primary visual cortex.</article-title>             <source>Neural Networks</source>             <volume>17</volume>             <fpage>719</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Sterkin1">
        <label>28</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Sterkin</surname><given-names>A</given-names></name><name name-style="western"><surname>Sterkin</surname><given-names>A</given-names></name><name name-style="western"><surname>Polat</surname><given-names>U</given-names></name></person-group>             <year>2008</year>             <article-title>Response similarity as a basis for perceptual binding.</article-title>             <source>J Vis</source>             <volume>8</volume>             <fpage>1</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Bair1">
        <label>29</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bair</surname><given-names>W</given-names></name><name name-style="western"><surname>Cavanaugh</surname><given-names>JR</given-names></name><name name-style="western"><surname>Movshon</surname><given-names>JA</given-names></name></person-group>             <year>2003</year>             <article-title>Time course and time-distance relationships for surround suppression in macaque v1 neurons.</article-title>             <source>J Neurosci</source>             <volume>23</volume>             <fpage>7690</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Zhang1">
        <label>30</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>NR</given-names></name><name name-style="western"><surname>von der Heydt</surname><given-names>R</given-names></name></person-group>             <year>2010</year>             <article-title>Analysis of the Context Integration Mechanisms Underlying Figure-Ground Organization in the Visual Cortex.</article-title>             <source>J Neurosci</source>             <volume>30</volume>             <fpage>6482</fpage>             <lpage>6496</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Schwabe1">
        <label>31</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schwabe</surname><given-names>L</given-names></name><name name-style="western"><surname>Obermayer</surname><given-names>K</given-names></name><name name-style="western"><surname>Angelucci</surname><given-names>A</given-names></name><name name-style="western"><surname>Bressloff</surname><given-names>PC</given-names></name></person-group>             <year>2006</year>             <article-title>The Role of Feedback in Shaping the Extra-Classical Receptive Field of Cortical Neurons: A Recurrent Network Model.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>9117</fpage>             <lpage>9129</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Angelucci1">
        <label>32</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Angelucci</surname><given-names>A</given-names></name><name name-style="western"><surname>Levitt</surname><given-names>JB</given-names></name><name name-style="western"><surname>Walton</surname><given-names>EJS</given-names></name><name name-style="western"><surname>Hupe</surname><given-names>JM</given-names></name><name name-style="western"><surname>Bullier</surname><given-names>J</given-names></name><etal/></person-group>             <year>2002</year>             <article-title>Circuits for Local and Global Signal Integration in Primary Visual Cortex.</article-title>             <source>J Neurosci</source>             <volume>22</volume>             <fpage>8633</fpage>             <lpage>8646</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Serre1">
        <label>33</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Serre</surname><given-names>T</given-names></name><name name-style="western"><surname>Oliva</surname><given-names>A</given-names></name><name name-style="western"><surname>Poggio</surname><given-names>T</given-names></name></person-group>             <year>2007</year>             <article-title>A feedforward architecture accounts for rapid categorization.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>104</volume>             <fpage>6424</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-MartinezConde1">
        <label>34</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Martinez-Conde</surname><given-names>S</given-names></name><name name-style="western"><surname>Macknik</surname><given-names>SL</given-names></name><name name-style="western"><surname>Troncoso</surname><given-names>XG</given-names></name><name name-style="western"><surname>Hubel</surname><given-names>DH</given-names></name></person-group>             <year>2009</year>             <article-title>Microsaccades: a neurophysiological analysis.</article-title>             <source>Trends Neurosci</source>             <volume>32</volume>             <fpage>463</fpage>             <lpage>475</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Rolls1">
        <label>35</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Rolls</surname><given-names>ET</given-names></name><name name-style="western"><surname>Tovee</surname><given-names>MJ</given-names></name></person-group>             <year>1994</year>             <article-title>Processing Speed in the Cerebral Cortex and the Neurophysiology of Visual Masking.</article-title>             <source>P Roy Soc Lond B Bio</source>             <volume>257</volume>             <fpage>9</fpage>             <lpage>15</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Wilkinson1">
        <label>36</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Wilkinson</surname><given-names>F</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>HR</given-names></name><name name-style="western"><surname>Habak</surname><given-names>C</given-names></name></person-group>             <year>1998</year>             <article-title>Detection and recognition of radial frequency patterns.</article-title>             <source>Vision Res</source>             <volume>38</volume>             <fpage>3555</fpage>             <lpage>3568</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Geisler2">
        <label>37</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Geisler</surname><given-names>WS</given-names></name><name name-style="western"><surname>Perry</surname><given-names>JS</given-names></name><name name-style="western"><surname>Super</surname><given-names>BJ</given-names></name><name name-style="western"><surname>Gallogly</surname><given-names>DP</given-names></name></person-group>             <year>2001</year>             <article-title>Edge co-occurrence in natural images predicts contour grouping performance.</article-title>             <source>Vision Res</source>             <volume>41</volume>             <fpage>711</fpage>             <lpage>724</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Schneidman1">
        <label>38</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schneidman</surname><given-names>E</given-names></name><name name-style="western"><surname>Berry</surname><given-names>MJ</given-names><suffix>II</suffix></name><name name-style="western"><surname>Segev</surname><given-names>R</given-names></name><name name-style="western"><surname>Bialek</surname><given-names>W</given-names></name></person-group>             <year>2006</year>             <article-title>Weak pairwise correlations imply strongly correlated network states in neural population.</article-title>             <source>Nature</source>             <volume>440</volume>             <fpage>1007</fpage>             <lpage>1012</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Shlens1">
        <label>39</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Shlens</surname><given-names>J</given-names></name><name name-style="western"><surname>Field</surname><given-names>GD</given-names></name><name name-style="western"><surname>Gauthier</surname><given-names>JL</given-names></name><name name-style="western"><surname>Grivich</surname><given-names>MI</given-names></name><name name-style="western"><surname>Petrusca</surname><given-names>D</given-names></name><etal/></person-group>             <year>2006</year>             <article-title>The Structure of Multi-Neuron Firing Patterns in Primate Retina.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>8254</fpage>             <lpage>8266</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Jones1">
        <label>40</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Jones</surname><given-names>JP</given-names></name><name name-style="western"><surname>Palmer</surname><given-names>LA</given-names></name></person-group>             <year>1987</year>             <article-title>An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex.</article-title>             <source>J Neurophys</source>             <volume>58</volume>             <fpage>1233</fpage>             <lpage>1258</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Troyer1">
        <label>41</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Troyer</surname><given-names>TW</given-names></name><name name-style="western"><surname>Krukowski</surname><given-names>AE</given-names></name><name name-style="western"><surname>Priebe</surname><given-names>NJ</given-names></name><name name-style="western"><surname>Miller</surname><given-names>KD</given-names></name></person-group>             <year>1998</year>             <article-title>Contrast-invariant orientation tuning in visual cortex: feedforward tuning and correlation-based intracortical connectivity.</article-title>             <source>J Neurosci</source>             <volume>18</volume>             <fpage>5908</fpage>             <lpage>5927</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Angelucci2">
        <label>42</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Angelucci</surname><given-names>A</given-names></name><name name-style="western"><surname>Levitt</surname><given-names>JB</given-names></name><name name-style="western"><surname>Walton</surname><given-names>EJS</given-names></name><name name-style="western"><surname>Hup√©</surname><given-names>JM</given-names></name><name name-style="western"><surname>Bullier</surname><given-names>J</given-names></name><etal/></person-group>             <year>2002</year>             <article-title>Circuits for local and global signal integration in primary visual cortex.</article-title>             <source>J Neurosci</source>             <volume>22</volume>             <fpage>8633</fpage>             <lpage>8646</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Azzopardi1">
        <label>43</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Azzopardi</surname><given-names>P</given-names></name><name name-style="western"><surname>Cowey</surname><given-names>A</given-names></name></person-group>             <year>1997</year>             <article-title>Is blindsight like normal, near-threshold vision?</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>94</volume>             <fpage>14190</fpage>             <lpage>14194</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Macmillan1">
        <label>44</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Macmillan</surname><given-names>NA</given-names></name><name name-style="western"><surname>Creelman</surname><given-names>CD</given-names></name></person-group>             <year>1991</year>             <article-title>Detection theory: a user's guide.</article-title>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>CUP Archive</publisher-name>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Maunsell1">
        <label>45</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Maunsell</surname><given-names>JHR</given-names></name><name name-style="western"><surname>Gibson</surname><given-names>JR</given-names></name></person-group>             <year>1992</year>             <article-title>Visual response latencies in striate cortex of the macaque monkey.</article-title>             <source>J Neurophys</source>             <volume>68</volume>             <fpage>1332</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Bell1">
        <label>46</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Bell</surname><given-names>J</given-names></name><name name-style="western"><surname>Badcock</surname><given-names>DR</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>H</given-names></name><name name-style="western"><surname>Wilkinson</surname><given-names>F</given-names></name></person-group>             <year>2007</year>             <article-title>Detection of shape in radial frequency contours: Independence of local and global form information.</article-title>             <source>Vision Res</source>             <volume>47</volume>             <fpage>1518</fpage>             <lpage>1522</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Li1">
        <label>47</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Z</given-names></name></person-group>             <year>2001</year>             <article-title>Computational design and nonlinear dynamics of a recurrent network model of the primary visual cortex.</article-title>             <source>Neural Comput</source>             <volume>13</volume>             <fpage>1749</fpage>             <lpage>1780</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Li2">
        <label>48</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Z</given-names></name></person-group>             <year>1998</year>             <article-title>A neural model of contour integration in the primary visual cortex.</article-title>             <source>Neural Comput</source>             <volume>10</volume>             <fpage>903</fpage>             <lpage>940</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Mundhenk1">
        <label>49</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Mundhenk</surname><given-names>TN</given-names></name><name name-style="western"><surname>Itti</surname><given-names>L</given-names></name></person-group>             <year>2005</year>             <article-title>Computational modeling and exploration of contour integration for visual saliency.</article-title>             <source>Biol Cybern</source>             <volume>93</volume>             <fpage>188</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Li3">
        <label>50</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>W</given-names></name><name name-style="western"><surname>Pi√´ch</surname><given-names>V</given-names></name><name name-style="western"><surname>Gilbert</surname><given-names>CD</given-names></name></person-group>             <year>2006</year>             <article-title>Contour saliency in primary visual cortex.</article-title>             <source>Neuron</source>             <volume>50</volume>             <fpage>951</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Grossberg1">
        <label>51</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Grossberg</surname><given-names>S</given-names></name><name name-style="western"><surname>Mingolla</surname><given-names>E</given-names></name></person-group>             <year>1985</year>             <article-title>Neural dynamics of perceptual grouping: textures, boundaries, and emergent segmentations.</article-title>             <source>Percept Psychophys</source>             <volume>38</volume>             <fpage>141</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Ullman1">
        <label>52</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ullman</surname><given-names>S</given-names></name><name name-style="western"><surname>Gregory</surname><given-names>RL</given-names></name><name name-style="western"><surname>Atkinson</surname><given-names>J</given-names></name></person-group>             <year>1992</year>             <article-title>Low-Level Aspects of Segmentation and Recognition [and Discussion].</article-title>             <source>Philos T R Soc Lon B</source>             <volume>337</volume>             <fpage>371</fpage>             <lpage>379</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Yen1">
        <label>53</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yen</surname><given-names>SC</given-names></name><name name-style="western"><surname>Finkel</surname><given-names>LH</given-names></name></person-group>             <year>1998</year>             <article-title>Extraction of perceptually salient contours by striate cortical networks.</article-title>             <source>Vision Res</source>             <volume>38</volume>             <fpage>719</fpage>             <lpage>741</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Garrigues1">
        <label>54</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Garrigues</surname><given-names>PJ</given-names></name><name name-style="western"><surname>Olshausen</surname><given-names>BA</given-names></name></person-group>             <year>2007</year>             <article-title>Learning horizontal connections in a sparse coding model of natural images.</article-title>             <source>Adv Neur In</source>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Ing1">
        <label>55</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Ing</surname><given-names>AD</given-names></name><name name-style="western"><surname>Wilson</surname><given-names>AJ</given-names></name><name name-style="western"><surname>Geisler</surname><given-names>WS</given-names></name></person-group>             <year>2010</year>             <article-title>Region grouping in natural foliage images: Image statistics and human performance.</article-title>             <source>J Vision</source>             <volume>10</volume>             <fpage>1</fpage>             <lpage>19</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Yao1">
        <label>56</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Yao</surname><given-names>H</given-names></name><name name-style="western"><surname>Shi</surname><given-names>L</given-names></name><name name-style="western"><surname>Han</surname><given-names>F</given-names></name><name name-style="western"><surname>Gao</surname><given-names>H</given-names></name><name name-style="western"><surname>Dan</surname><given-names>Y</given-names></name></person-group>             <year>2007</year>             <article-title>Rapid learning in cortical coding of visual scenes.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <fpage>772</fpage>             <lpage>778</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Hua1">
        <label>57</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hua</surname><given-names>T</given-names></name><name name-style="western"><surname>Bao</surname><given-names>P</given-names></name><name name-style="western"><surname>Huang</surname><given-names>CB</given-names></name><name name-style="western"><surname>Wang</surname><given-names>Z</given-names></name><name name-style="western"><surname>Xu</surname><given-names>J</given-names></name><etal/></person-group>             <year>2010</year>             <article-title>Perceptual learning improves contrast sensitivity of V1 neurons in cats.</article-title>             <source>Curr Biol</source>             <volume>20</volume>             <fpage>887</fpage>             <lpage>894</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Li4">
        <label>58</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>W</given-names></name><name name-style="western"><surname>Gilbert</surname><given-names>CD</given-names></name></person-group>             <year>2002</year>             <article-title>Global contour saliency and local colinear interactions.</article-title>             <source>J Neurophysiol</source>             <volume>88</volume>             <fpage>28462856</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Knoblauch1">
        <label>59</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Knoblauch</surname><given-names>A</given-names></name><name name-style="western"><surname>Sommer</surname><given-names>FT</given-names></name></person-group>             <year>2004</year>             <article-title>Spike-timing-dependent synaptic plasticity can form ‚Äúzero lag links‚Äù for cortical oscillations.</article-title>             <source>Neurocomputing</source>             <volume>58-60</volume>             <fpage>185</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Hoyer1">
        <label>60</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Hoyer</surname><given-names>PO</given-names></name><name name-style="western"><surname>Hyv√§rinen</surname><given-names>A</given-names></name></person-group>             <year>2002</year>             <article-title>A multi-layer sparse coding network learns contour coding from natural images.</article-title>             <source>Vision Res</source>             <volume>42</volume>             <fpage>1593</fpage>             <lpage>1605</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Song1">
        <label>61</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Song</surname><given-names>S</given-names></name><name name-style="western"><surname>Miller</surname><given-names>KE</given-names></name><name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name></person-group>             <year>2000</year>             <article-title>Competitive hebbian learning through spike-timingdependent synaptic plasticity.</article-title>             <source>Nat Neurosci</source>             <volume>3</volume>             <fpage>919</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Li5">
        <label>62</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Li</surname><given-names>Z</given-names></name></person-group>             <year>2002</year>             <article-title>A saliency map in primary visual cortex.</article-title>             <source>Trends Cogn Sci</source>             <volume>6</volume>             <fpage>9</fpage>             <lpage>16</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Fukushima1">
        <label>63</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fukushima</surname><given-names>K</given-names></name></person-group>             <year>1980</year>             <article-title>Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position.</article-title>             <source>Biol Cybern</source>             <volume>36</volume>             <fpage>193</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Gilbert2">
        <label>64</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Gilbert</surname><given-names>CD</given-names></name><name name-style="western"><surname>Sigman</surname><given-names>M</given-names></name></person-group>             <year>2007</year>             <article-title>Brain states: Top-down influences in sensory processing.</article-title>             <source>Neuron</source>             <volume>54</volume>             <fpage>667</fpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Schneeweis1">
        <label>65</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Schneeweis</surname><given-names>D</given-names></name><name name-style="western"><surname>Schnapf</surname><given-names>J</given-names></name></person-group>             <year>1995</year>             <article-title>Photovoltage of rods and cones in the macaque retina.</article-title>             <source>Science</source>             <volume>268</volume>             <fpage>1053</fpage>             <lpage>1056</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-Enns1">
        <label>66</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Enns</surname><given-names>JT</given-names></name><name name-style="western"><surname>Lollo</surname><given-names>VD</given-names></name></person-group>             <year>2000</year>             <article-title>What's new in visual masking?</article-title>             <source>Trends Cogn Sci</source>             <volume>4</volume>             <fpage>345</fpage>             <lpage>352</lpage>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-FeiFei1">
        <label>67</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Fei-Fei</surname><given-names>L</given-names></name><name name-style="western"><surname>Fergus</surname><given-names>R</given-names></name><name name-style="western"><surname>Perona</surname><given-names>P</given-names></name></person-group>             <year>2004</year>             <article-title>Learning generative visual models from few training examples: an incremental bayesian approach tested on 101 object categories.</article-title>             <source>CVPR 2004, Workshop on Generative-Model Based Vision</source>          </element-citation>
      </ref>
      <ref id="pcbi.1002162-LeCun1">
        <label>68</label>
        <element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>LeCun</surname><given-names>Y</given-names></name><name name-style="western"><surname>Bottou</surname><given-names>L</given-names></name><name name-style="western"><surname>Bengio</surname><given-names>Y</given-names></name><name name-style="western"><surname>Haffner</surname><given-names>P</given-names></name></person-group>             <year>1998</year>             <article-title>Gradient-based learning applied to document recognition.</article-title>             <source>P IEEE</source>             <volume>volume 86</volume> <!--===== Restructure page-count as size[@units="page"] =====--><size units="page">2278</size>           </element-citation>
      </ref>
      <ref id="pcbi.1002162-Brainard1">
        <label>69</label>
        <element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author"><name name-style="western"><surname>Brainard</surname><given-names>DH</given-names></name></person-group>             <year>1997</year>             <article-title>The psychophysics toolbox.</article-title>             <source>Spat Vis</source>             <volume>10</volume>             <fpage>433</fpage>          </element-citation>
      </ref>
    </ref-list>
    
  </back>
</article>
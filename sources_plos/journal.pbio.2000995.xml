<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="other" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">plosbiol</journal-id>
<journal-title-group>
<journal-title>PLOS Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1544-9173</issn>
<issn pub-type="epub">1545-7885</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1371/journal.pbio.2000995</article-id>
<article-id pub-id-type="publisher-id">pbio.2000995</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Perspective</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>People and places</subject><subj-group><subject>Population groupings</subject><subj-group><subject>Professions</subject><subj-group><subject>Scientists</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Economics</subject><subj-group><subject>Labor economics</subject><subj-group><subject>Employment</subject><subj-group><subject>Careers</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Ecology</subject><subj-group><subject>Ecosystems</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Ecology and environmental sciences</subject><subj-group><subject>Ecology</subject><subj-group><subject>Ecosystems</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Science policy</subject><subj-group><subject>Science and technology workforce</subject><subj-group><subject>Careers in research</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Public and occupational health</subject><subj-group><subject>Physical activity</subject><subj-group><subject>Physical fitness</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Peer review</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Research errors</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Current Incentives for Scientists Lead to Underpowered Studies with Erroneous Conclusions</article-title>
<alt-title alt-title-type="running-head">Incentive Structures and Reproducibility</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Higginson</surname>
<given-names>Andrew D.</given-names>
</name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<name name-style="western">
<surname>Munafò</surname>
<given-names>Marcus R.</given-names>
</name>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001"><label>1</label> <addr-line>Centre for Research in Animal Behaviour, College of Life and Environmental Sciences, University of Exeter, Exeter, United Kingdom</addr-line></aff>
<aff id="aff002"><label>2</label> <addr-line>MRC Integrative Epidemiology Unit (IEU) at the University of Bristol, Bristol, United Kingdom</addr-line></aff>
<aff id="aff003"><label>3</label> <addr-line>UK Centre for Tobacco and Alcohol Studies, School of Experimental Psychology, University of Bristol, Bristol, United Kingdom</addr-line></aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">a.higginson@exeter.ac.uk</email> (ADH); <email xlink:type="simple">marcus.munafo@bristol.ac.uk</email> (MRM)</corresp>
</author-notes>
<pub-date pub-type="epub">
<day>10</day>
<month>11</month>
<year>2016</year>
</pub-date>
<pub-date pub-type="collection">
<month>11</month>
<year>2016</year>
</pub-date>
<volume>14</volume>
<issue>11</issue>
<elocation-id>e2000995</elocation-id>
<permissions>
<copyright-year>2016</copyright-year>
<copyright-holder>Higginson, Munafò</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pbio.2000995"/>
<abstract>
<p>We can regard the wider incentive structures that operate across science, such as the priority given to novel findings, as an ecosystem within which scientists strive to maximise their fitness (i.e., publication record and career success). Here, we develop an optimality model that predicts the most rational research strategy, in terms of the proportion of research effort spent on seeking novel results rather than on confirmatory studies, and the amount of research effort per exploratory study. We show that, for parameter values derived from the scientific literature, researchers acting to maximise their fitness should spend most of their effort seeking novel results and conduct small studies that have only 10%–40% statistical power. As a result, half of the studies they publish will report erroneous conclusions. Current incentive structures are in conflict with maximising the scientific value of research; we suggest ways that the scientific ecosystem could be improved.</p>
</abstract>
<funding-group>
<funding-statement>Medical Research Council and the University of Bristol (grant number MC_UU_12013/6).Received by MRM. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. Natural Environment Research Council (grant number NE/L011921/1).Received by ADH. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. MRM is a member of the UK Centre for Tobacco and Alcohol Studies, a UKCRC Public Health Research: Centre of Excellence. Funding from British Heart Foundation, Cancer Research UK, Economic and Social Research Council, Medical Research Council, and the National Institute for Health Research, under the auspices of the UK Clinical Research Collaboration, is gratefully acknowledged</funding-statement>
</funding-group>
<counts>
<fig-count count="5"/>
<table-count count="0"/>
<page-count count="14"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<p>The career progression of researchers is strongly influenced by their publication record [<xref ref-type="bibr" rid="pbio.2000995.ref001">1</xref>], but there is growing evidence that many published studies across a number of disciplines may be underpowered and report erroneous conclusions [<xref ref-type="bibr" rid="pbio.2000995.ref002">2</xref>–<xref ref-type="bibr" rid="pbio.2000995.ref004">4</xref>]. In 2005, Ioannidis argued that most published research is false [<xref ref-type="bibr" rid="pbio.2000995.ref005">5</xref>] and that this stems in part from a reliance on null hypothesis significance testing and in particular from a dichotomous interpretation of <italic>p</italic>-values as “significant” or “nonsignificant,” whereas the positive predictive value (PPV) of a study (i.e., the poststudy probability that the finding is correct) is a better measure of the scientific value of a study. In particular, the prestudy odds (<italic>R</italic>) that a hypothesis is correct are rarely considered when interpreting the results of individual studies, yet this can have a dramatic impact on the PPV. Exploratory studies (i.e., those with low <italic>R</italic>) are much less likely to be true than confirmatory studies (i.e., those with high <italic>R</italic>) even if the <italic>p-</italic>value generated is the same, but arguably, current incentive studies reward novel (i.e., exploratory) findings over replication (i.e., confirmatory) studies.</p>
<p>Scientists are trained to be objective and to pursue the discovery of knowledge, through both exploratory work that generates novel lines of enquiry and confirmatory work that assesses the robustness of previous novel findings. However, scientists are also human and work within incentive structures that may shape their behaviours, consciously or unconsciously. For example, publication in a journal with a high (Thomson-Reuters) Impact Factor can accelerate career advancement [<xref ref-type="bibr" rid="pbio.2000995.ref001">1</xref>], enhancing prestige and both personal and grant income. There also appears to be an increasing focus on novel findings: since the 1980s, there has been a disproportionate increase in studies that include “novel” in their title [<xref ref-type="bibr" rid="pbio.2000995.ref006">6</xref>–<xref ref-type="bibr" rid="pbio.2000995.ref009">9</xref>]. At the same time, only a small number of key publications may count towards career advancement: recruitment panels and research assessment exercises, such as the United Kingdom Research Excellence Framework (REF) [<xref ref-type="bibr" rid="pbio.2000995.ref009">9</xref>] and the Australian Excellence in Research exercise [<xref ref-type="bibr" rid="pbio.2000995.ref010">10</xref>], often require researchers to submit for assessment a small number (currently four in the REF) of their “best” outputs. We can regard these incentive structures as an ecosystem within which scientists strive to maximise their fitness (i.e., publication record) and therefore might expect that individual scientists would strategically adapt—consciously or unconsciously—to these pressures, adjusting their research strategy to boost their career success. Understanding research ecosystems is critical if we are to align scientific value and career benefits, in order to maximise the efficiency of scientific research.</p>
<p>Theoretical models of adaptive behaviour are common in evolutionary biology: natural selection should find, or an animal should choose, the behavioural strategy (a set of context-dependent choices) that maximises naturally selected "fitness," or "reproductive value" [<xref ref-type="bibr" rid="pbio.2000995.ref011">11</xref>]. Possible strategies available to natural selection or in decision making can be thought of as lying in multidimensional space with a peak at maximum fitness. We can regard the wider incentive structures that operate across science as the characteristics of an ecosystem, within which scientists strive to maximise their “fitness” by optimising their behaviour and, by extension, their research strategy. We were interested in whether the optimal research strategy for individual scientists aligns with the optimal conditions for the advancement of knowledge.</p>
<p>We used optimality theory [<xref ref-type="bibr" rid="pbio.2000995.ref012">12</xref>] to predict the rational strategy of a scientist possessing finite resources who seeks to maximise the career value of his or her publications. The model is described in brief in <xref ref-type="boxed-text" rid="pbio.2000995.box001">Box 1</xref>. Full details of all methods used are provided in <xref ref-type="supplementary-material" rid="pbio.2000995.s011">S1 Text</xref>, and the Matlab code used to complete the analyses is provided in <xref ref-type="supplementary-material" rid="pbio.2000995.s012">S2 Text</xref>. We considered that researchers must choose how to divide their resources between exploratory studies that seek to identify new phenomena and confirmatory studies that attempt to verify previous findings and that they must decide the amount of resources to invest per study. We characterised the possible strategies as lying in a two-dimensional “fitness” landscape (<xref ref-type="fig" rid="pbio.2000995.g001">Fig 1</xref>) in which the two dimensions are (1) the proportion of research effort spent on exploratory studies that seek novel results (<italic>θ</italic>) and (2) the amount of research effort (e.g., sample size) per exploratory study (<italic>S</italic><sub><italic>E</italic></sub>). For instance, we might assume that collecting one data point has a fixed monetary cost or takes a certain amount of time to collect. For simplicity, we assume that exploratory studies are published only if they obtain a statistically significant result (i.e., <italic>p</italic> &lt; 0.05) and that confirmatory studies are large (i.e., have a large sample size), have high power, and therefore have a high probability of being accepted for publication even if they obtain a nonsignificant result. We also assume that the peer review process means that the likelihood of acceptance for publication increases with sample size, since larger studies are generally considered informative and authoritative, irrespective of whether the result is statistically significant or not.</p>
<fig id="pbio.2000995.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2000995.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Fitness landscape for an individual researcher.</title>
<p>An individual researcher is able to choose the parameters <italic>θ</italic> (<italic>y</italic>-axis) and <italic>S</italic><sub><italic>E</italic></sub>; the <italic>x</italic>-axis shows the resultant power of exploratory studies, <italic>W</italic><sub><italic>E</italic></sub>. White indicates high fitness, black low fitness. For small values of <italic>S</italic><sub><italic>E</italic></sub>, few papers are accepted, while for high values of <italic>S</italic><sub><italic>E</italic></sub>, few studies are carried out. For low values of <italic>θ</italic>, few novel studies are carried out. (A) γ = 0.09, ϕ = 0.9. The optimal strategy that maximises individual fitness is therefore to carry out many small exploratory studies with a power of around 15%. (B) γ = 0.055, ϕ = 0.55. A mixture of exploratory and confirmatory work should be carried out with slightly higher power (20%).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.g001" xlink:type="simple"/>
</fig>
<boxed-text id="pbio.2000995.box001" position="float">
<sec id="sec001">
<title>Box 1. Modelling the Rational Strategy of a Scientist</title>
<p>The researcher optimises the payoff that results from deciding the proportion of total sampling to spend on exploratory studies (<italic>θ</italic>) and the sample size of each exploratory study (<italic>S</italic><sub><italic>E</italic></sub>). <italic>S</italic><sub><italic>E</italic></sub> determines the statistical power of each study, namely the probability of detecting an effect (<italic>W</italic><sub><italic>E</italic></sub>), which in turn controls the probability of Type II errors (1 − <italic>W</italic><sub><italic>E</italic></sub>). The probability of a Type I error (α) is the critical <italic>p-</italic>value within a null hypothesis significance testing framework; we assume α = 0.05. Power depends on the population variance (σ<sup>2</sup>) and the effect size for exploratory or confirmatory studies (<italic>r</italic><sub><italic>E</italic>,</sub> <italic>r</italic><sub><italic>C</italic></sub>). The values we use are in the middle of the range of effect sizes observed in meta-analyses across a number of biomedical research domains (range r ~ 0.15 to 0.50) [<xref ref-type="bibr" rid="pbio.2000995.ref013">13</xref>]. All studies that find significant results are published, and the high statistical power of confirmatory studies means that the results are informative regardless of statistical significance, so nonsignificant confirmatory studies are published with probability ψ, subject to an independent effect of sample size on the likelihood of acceptance by a journal editor (before consideration of the effects themselves) according to the function:
<disp-formula id="pbio.2000995.e001">
<alternatives>
<graphic id="pbio.2000995.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.2000995.e001" xlink:type="simple"/>
<mml:math display="block" id="M1">
<mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mi>m</mml:mi><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(B1)</label>
</disp-formula>
where <italic>m</italic> is a positive constant (see <xref ref-type="supplementary-material" rid="pbio.2000995.s001">S1 Fig</xref>).</p>
<p>The number of publications from exploratory studies (<italic>N</italic><sub><italic>E</italic></sub>) is the product of the total effort put into exploratory studies divided by the sampling effort of each study, the probability of acceptance given the sample size <italic>A</italic>, and the probability of getting a statistically significant result:
<disp-formula id="pbio.2000995.e002">
<alternatives>
<graphic id="pbio.2000995.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.2000995.e002" xlink:type="simple"/>
<mml:math display="block" id="M2">
<mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>θ</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mi>A</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(B2)</label>
</disp-formula>
where <italic>f</italic><sub><italic>E</italic></sub> is the probability that an effect is real, <italic>T</italic> is the total number of samples that can be collected (i.e., total resources), and <italic>k</italic> is the setup cost for any study. The first term in the squared brackets is the probability of a true-positive result, while the second is the probability of a false-positive result. Since confirmatory studies will build on the findings of exploratory studies, the probability that a confirmatory study is looking at a real effect (<italic>f</italic><sub><italic>C</italic></sub>) is equal to the probability that a published exploratory study is correct <italic>(P<sub>F,E</sub>)</italic>. The number of confirmatory studies that are published (<italic>N</italic><sub><italic>C</italic></sub>) is the sampling effort put into all confirmatory studies divided by the sampling effort of each study multiplied by the probability they are accepted:
<disp-formula id="pbio.2000995.e003">
<alternatives>
<graphic id="pbio.2000995.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.2000995.e003" xlink:type="simple"/>
<mml:math display="block" id="M3">
<mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>S</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mi>α</mml:mi><mml:mo>+</mml:mo><mml:mi>ψ</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>F</mml:mi><mml:mo>,</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(B3)</label>
</disp-formula></p>
<p>The terms in the squared brackets are, respectively, the probability of true positive, false positive, true negative, and false negative.</p>
<p>We assume that the number of confirmatory studies per exploratory study is limited to ρ (ρ = 10), by calculating the number of valuable confirmatory studies <inline-formula id="pbio.2000995.e004"><alternatives><graphic id="pbio.2000995.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.2000995.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>C</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> (see <xref ref-type="supplementary-material" rid="pbio.2000995.s011">S1 Text</xref>).</p>
<p>The total fitness (<italic>V</italic><sub><italic>R</italic></sub>) of the researcher is assumed to depend on total number of publications with diminishing returns, with an additional bonus for exploratory studies. One implementation of this is as follows:
<disp-formula id="pbio.2000995.e005">
<alternatives>
<graphic id="pbio.2000995.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.2000995.e005" xlink:type="simple"/>
<mml:math display="block" id="M5">
<mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>γ</mml:mi><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>N</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>C</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow>
</mml:math>
</alternatives>
<label>(B4)</label>
</disp-formula></p>
<p>In Eq (B<xref ref-type="disp-formula" rid="pbio.2000995.e005">4</xref>), ϕ controls how quickly the value of the total number of publications diminishes, and γ controls the extra weighting given to published exploratory studies. The dependence of equation (B<xref ref-type="disp-formula" rid="pbio.2000995.e005">4</xref>) on the number of published exploratory and confirmatory studies is shown in <xref ref-type="supplementary-material" rid="pbio.2000995.s002">S2 Fig</xref> for representative values of γ and ϕ.</p>
<p>Given these assumptions, we identified the optimal research strategy for an individual scientist, which is the combination of <italic>θ</italic> and <italic>N</italic><sub><italic>E</italic></sub> for which the career value of publications (<italic>V</italic><sub><italic>R</italic></sub>) is maximised (i.e., the location of the peak in the fitness landscape, <xref ref-type="fig" rid="pbio.2000995.g001">Fig 1</xref>). See <xref ref-type="supplementary-material" rid="pbio.2000995.s012">S2 Text</xref> for the Matlab code.</p>
<p>A reasonable function describing the scientific value of research (<italic>V</italic><sub><italic>S</italic></sub>) is the product of (1) the number of published exploratory studies, (2) the number of published confirmatory studies, and (3) the proportion of published studies that are correct: <italic>V<sub>S</sub></italic> = <italic>N<sub>C</sub>N<sub>E</sub></italic>(1−<italic>P<sub>F</sub></italic>). This reflects our assumptions that novel findings (from exploratory work) and confirmatory work are equally important for the advancement of knowledge, provided they arrive at correct conclusions, and that an absence of either of them would be very bad for science. That is, we assume that a balance of exploratory and confirmatory work is ideal, so that for any number of publications the scientific value is maximised when half are exploratory and half are confirmatory (see <xref ref-type="supplementary-material" rid="pbio.2000995.s003">S3A Fig</xref>). We also considered other reasonable functions, and these provided the same conclusions (see <xref ref-type="supplementary-material" rid="pbio.2000995.s003">S3 Fig</xref> and <xref ref-type="supplementary-material" rid="pbio.2000995.s005">S5</xref>–<xref ref-type="supplementary-material" rid="pbio.2000995.s009">S9</xref> Figs). Baseline parameter values are given in <xref ref-type="supplementary-material" rid="pbio.2000995.s010">S1 Table</xref>.</p>
</sec>
</boxed-text>
<p>The results (<xref ref-type="fig" rid="pbio.2000995.g002">Fig 2A</xref>) of our model (<xref ref-type="boxed-text" rid="pbio.2000995.box001">Box 1</xref>) indicate that more exploratory work will be carried out if (1) more weight is given to novel findings (γ, shown on the <italic>x</italic>-axis), (2) real effects are more common (<italic>x</italic><sub><italic>E</italic></sub>, compare dotted and solid lines), and (3) the typical effect size is larger (<italic>r</italic><sub><italic>C</italic></sub>, <italic>r</italic><sub><italic>E</italic></sub>, compare dashed and solid lines). There is an optimal sample size (<italic>S</italic><sub><italic>E</italic></sub>*) that maximises the number of published novel findings per unit of resource spent on exploratory studies. <italic>S</italic><sub><italic>E</italic></sub>* decreases as θ increases (<xref ref-type="fig" rid="pbio.2000995.g002">Fig 2B</xref>), because it becomes more important to avoid committing false positives as they will reduce the number of confirmatory studies that find a significant result. The total number of publications declines as the weight given to novel findings (γ) increases (<xref ref-type="fig" rid="pbio.2000995.g002">Fig 2C</xref>). In part, this is because most exploratory studies are not published, as they have low statistical power and therefore often do not obtain statistically significant results. However, the proportion of confirmatory studies also declines (<xref ref-type="fig" rid="pbio.2000995.g002">Fig 2D</xref>) because of the greatly increased exploratory effort. The optimal statistical power is low (<xref ref-type="fig" rid="pbio.2000995.g002">Fig 2E</xref>), especially if the typical effect size is small, since it is better from an individual career perspective to run many exploratory studies (and for a high proportion of statistically significant findings to be Type I errors [<xref ref-type="bibr" rid="pbio.2000995.ref002">2</xref>]) than to run a smaller number of well-powered studies (see <xref ref-type="supplementary-material" rid="pbio.2000995.s004">S4 Fig</xref> for an intuitive illustration). As the weight given to novel findings increases, and so the investment in exploratory studies increases, the proportion of papers that draw erroneous conclusions increases to over 50% (<xref ref-type="fig" rid="pbio.2000995.g002">Fig 2F</xref>). The proportion of false positive studies at optimal behaviour is similar to the proportion incorrect, since false negatives are rare for confirmatory studies because they have high statistical power and false negative exploratory studies tend to remain unpublished.</p>
<fig id="pbio.2000995.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2000995.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Effect of varying the weighting given to published exploratory studies (γ).</title>
<p>Parameter γ reflects the relative importance of published exploratory studies. The lines show predictions for two values of the probability that an effect is real (<italic>f</italic><sub><italic>E</italic></sub>) and two values of the effect sizes <italic>r</italic><sub><italic>C</italic></sub> and <italic>r</italic><sub><italic>E</italic></sub> (solid: <italic>f</italic><sub><italic>E</italic></sub> = 0.2, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.21; dotted: <italic>f</italic><sub><italic>E</italic></sub> = 0.3, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.21; dashed: <italic>f</italic><sub><italic>E</italic></sub> = 0.2, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.32). The panels show (A) the optimal proportion of total sampling to spend on exploratory studies <italic>θ*</italic>, (B) the optimal sample size of exploratory studies <italic>S</italic><sub><italic>E</italic></sub>*, (C) the resultant total number of published studies <italic>N</italic><sub><italic>E</italic></sub> + <italic>N</italic><sub><italic>C</italic></sub>, (D) the proportion of published studies that are confirmatory <italic>N</italic><sub><italic>C</italic></sub> / (<italic>N</italic><sub><italic>E</italic></sub> + <italic>N</italic><sub><italic>C</italic></sub>), (E) the statistical power of exploratory studies <italic>W</italic><sub><italic>E</italic></sub>, and (F) the proportion of published studies that draw incorrect conclusions (<italic>P</italic><sub><italic>F</italic></sub>). Other values: <italic>S</italic><sub><italic>C</italic></sub> = 120, <italic>T</italic> = 2,000, <italic>k</italic> = 20, α = 0.05, σ<sup>2</sup> = 1, <italic>m</italic> = 3, and ϕ = 0.8. The chosen values for <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> reflect data reported by Richard and colleagues [<xref ref-type="bibr" rid="pbio.2000995.ref014">14</xref>], where a correlation coefficient mode of 0.09 and a mean of 0.21 were observed. These values are in the middle of the range of effect sizes observed in meta-analyses across a number of biomedical research domains (range r ~ 0.15 to 0.50) [<xref ref-type="bibr" rid="pbio.2000995.ref013">13</xref>].</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.g002" xlink:type="simple"/>
</fig>
<p>We next used our model to predict how characteristics of the current scientific ecosystem, such as incentives to publish novel, exciting results, influence the total scientific value of research <italic>V</italic><sub><italic>S</italic></sub> (see <xref ref-type="boxed-text" rid="pbio.2000995.box001">Box 1</xref>). Current incentive structures (e.g., recruitment processes and research assessment exercises) place substantial weight on findings published in journals with a high Impact Factor and may consider only the “best” few publications of any individual. These conditions correspond to a situation with a strong weighting given to novel findings (large γ) and quickly diminishing value of additional publications (high ϕ). Our model shows that the scientific value of research (<italic>V</italic><sub><italic>S</italic></sub>) is not maximised at these values (top right of <xref ref-type="fig" rid="pbio.2000995.g003">Fig 3A</xref>) when scientists are behaving rationally to maximise their own success within this ecosystem. If a small number of novel findings counts heavily towards career progression, this encourages scientists to focus almost all of their research effort on underpowered exploratory work. Furthermore, they should carry out lots of underpowered small studies to maximise their number of publications, even though this means around half will be false positives (<xref ref-type="fig" rid="pbio.2000995.g002">Fig 2E</xref> and <xref ref-type="supplementary-material" rid="pbio.2000995.s004">S4 Fig</xref>).</p>
<fig id="pbio.2000995.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2000995.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Effect of γ and ϕ on a hypothetical measure of the total scientific value of research (<italic>V</italic><sub><italic>S</italic></sub>).</title>
<p>The figure shows the product of the number of published confirmatory studies, the number of published exploratory studies, and the proportion of published studies that are correct (red = high, blue = low). This measure is calculated for when all researchers are following the rational strategy given the values of γ and ϕ. The current emphasis on a small number of publications that report novel findings is characterised by high γ and high ϕ (top right). To improve scientific output according to this measure, we could reduce ϕ (i.e., make more published studies count for researchers’ careers) or reduce γ (i.e., reduce weighting of published exploratory studies). Interestingly, the ridge is flat, so any point along it has equal fitness. Therefore, a pragmatic compromise would be to reduce both γ and ϕ by a lesser amount. The panels show the <italic>V</italic><sub><italic>T</italic></sub> for two values of the dependence of acceptance on sample size <italic>m</italic> and the Type I error rate α: (A) α = 0.05, <italic>m</italic> = 3, colour range: 2.0–3.18; (B) α = 0.05, <italic>m</italic> = 6, colour range: 2.0–2.82; (C) α = 0.03, <italic>m</italic> = 6, colour range: 2.0–2.065. Other values: <italic>S</italic><sub><italic>C</italic></sub> = 120, <italic>T</italic> = 2000, <italic>k</italic> = 20, <italic>f</italic><sub><italic>E</italic></sub> = 0.2, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.21, and σ<sup>2</sup> = 1.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.g003" xlink:type="simple"/>
</fig>
<p>Critically, our model suggests ways in which incentive structures could be redesigned so that the optimal strategy for individual scientists aligns with the optimal conditions for the advancement of knowledge. A small reduction in both the weight given to novel findings (γ) and how quickly the value of the total number of publications diminishes (ϕ) would shift individual incentives away from a dominant focus on exploratory work, meaning that more confirmatory work is carried out, thereby increasing the total scientific value of research (<xref ref-type="fig" rid="pbio.2000995.g003">Fig 3A</xref>). Sensitivity analyses (<xref ref-type="supplementary-material" rid="pbio.2000995.s005">S5</xref>–<xref ref-type="supplementary-material" rid="pbio.2000995.s009">S9</xref> Figs) indicate that a reduction in both ϕ and γ increases <italic>V</italic><sub><italic>S</italic></sub> for all reasonable values of the other parameters (i.e., setup cost, <italic>k</italic>; probability effect is real, <italic>f</italic><sub><italic>E</italic></sub>; effect size in exploratory studies, <italic>r</italic><sub><italic>E</italic></sub>; effect size in confirmatory studies, <italic>r</italic><sub><italic>C</italic></sub>; standard deviation of the data, σ; and proportion of nonsignificant confirmatory studies published, ψ). This suggests that the optimal strategy for individual scientists and the optimal conditions for the advancement of knowledge do not currently align even if our estimates of parameter values are incorrect. The equation for <italic>V</italic><sub><italic>S</italic></sub> assumes that there is a place for both exploratory and confirmatory research and that correct findings are more valuable than incorrect findings. How these elements should be weighted is obviously an important question, but our results indicate that our conclusions are unchanged for various possible functions for <italic>V</italic><sub><italic>S</italic></sub> (see <xref ref-type="supplementary-material" rid="pbio.2000995.s005">S5</xref>–<xref ref-type="supplementary-material" rid="pbio.2000995.s009">S9</xref> Figs).</p>
<p>Our metric reflecting the scientific value of research (<italic>V</italic><sub><italic>S</italic></sub>) is related to both the dependence of acceptance on sample size (<italic>m</italic>) and the Type I error rate (α) (<xref ref-type="fig" rid="pbio.2000995.g004">Fig 4</xref>). As the dependence of acceptance on sample size increases (i.e., journal editors are more stringent), so does statistical power, meaning that the proportion of studies that are correct increases, tending to 100% (<xref ref-type="fig" rid="pbio.2000995.g004">Fig 4A</xref>). More confirmatory studies are carried out, so the number of studies that get published increases (<xref ref-type="fig" rid="pbio.2000995.g004">Fig 4C</xref>). However, when the sample size required for publication is very large, the number of exploratory studies approaches zero, so that the total scientific value of research declines (<xref ref-type="fig" rid="pbio.2000995.g004">Fig 4E</xref>). This analysis predicts that the value of <italic>m</italic> that maximises the scientific value of research is quite high, meaning that journals should be more stringent about required statistical power and sample size. Increasing <italic>m</italic> alters the position of the ridge in (γ, ϕ) space, such that total scientific value of research is greatest at larger values of γ and ϕ (<xref ref-type="fig" rid="pbio.2000995.g003">Fig 3B</xref>).</p>
<fig id="pbio.2000995.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2000995.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Effect of editorial stringency on total scientific output for current incentive structures.</title>
<p>The figure shows the proportion of published findings that are correct 1-<italic>P</italic><sub><italic>F</italic></sub> (A, B), the total number of published studies <italic>N</italic><sub><italic>C</italic></sub> + <italic>N</italic><sub><italic>C</italic></sub> (C, D), and the total scientific value of research <italic>V</italic><sub><italic>T</italic></sub> (E, F). We varied the following parameters: the probability of a Type I error α (A, C, E), and the dependence of acceptance on sample size <italic>m</italic> (B, D, F). The lines show predictions for two values of the probability that an effect is real (<italic>f</italic><sub><italic>E</italic></sub>) and two values of the effect size (solid: <italic>f</italic><sub><italic>E</italic></sub> = 0.2, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.21; dotted: <italic>f</italic><sub><italic>E</italic></sub> = 0.3, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.21; and dashed: <italic>f</italic><sub><italic>E</italic></sub> = 0.2, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.32). Other values: <italic>N</italic><sub><italic>C</italic></sub> = 120, <italic>T</italic> = 2,000, <italic>k</italic> = 20, α = 0.05, σ<sup>2</sup> = 1, <italic>m</italic> = 3, ϕ = 0.9, and γ = 0.09. The steps occur where there is discontinuity in the effect of α on <italic>S</italic><sub><italic>E</italic></sub>*.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.g004" xlink:type="simple"/>
</fig>
<p>Our model indicates that, at conventional levels of statistical significance (i.e., α = 0.05, <xref ref-type="fig" rid="pbio.2000995.g004">Fig 4B</xref>), only around 50% of published findings are likely to be correct, close to the ~40% observed by the Open Science Collaboration [<xref ref-type="bibr" rid="pbio.2000995.ref004">4</xref>] and the pharmaceutical industry [<xref ref-type="bibr" rid="pbio.2000995.ref015">15</xref>]. With increasing statistical stringency (i.e., lower α), the proportion of published findings that are correct increases (<xref ref-type="fig" rid="pbio.2000995.g004">Fig 4B</xref>) because more confirmatory studies are carried out and exploratory studies are more powerful because it is optimal to have a larger sample size in order to increase the chance of detecting an effect. This, along with an increase in the number of published studies, means that <italic>V</italic><sub><italic>S</italic></sub> increases (<xref ref-type="fig" rid="pbio.2000995.g004">Fig 4D</xref>). However, at small values of α almost all published papers are confirmatory, and a single novel result would greatly increase <italic>V</italic><sub><italic>R</italic></sub>, so <italic>S</italic><sub><italic>E</italic></sub> increases as α decreases to maintain the chance of a statistically significant result. However, at very high levels of statistical stringency (i.e., very low α) fewer novel findings are published and so the total scientific value of research declines. In a similar way to the result for <italic>m</italic> above, this analysis suggests that the total scientific value of research would be greater given a smaller Type I error rate (α) than is currently conventional (<xref ref-type="fig" rid="pbio.2000995.g004">Fig 4F</xref>). Decreasing α would mean that higher values of γ and ϕ would maximise the total scientific value of research (<xref ref-type="fig" rid="pbio.2000995.g003">Fig 3C</xref>)—in other words, the research strategy encouraged by current incentives (top right of <xref ref-type="fig" rid="pbio.2000995.g003">Fig 3C</xref>) would be closer to that which maximises the scientific value of research. The problem with this solution is that the overall value of the science might be reduced (the maximum <italic>V</italic><sub><italic>S</italic></sub> is smaller in <xref ref-type="fig" rid="pbio.2000995.g003">Fig 3C</xref> than in <xref ref-type="fig" rid="pbio.2000995.g003">Fig 3A</xref>).</p>
<p>Current incentive structures in science, combined with existing conventions such as a significance level of 5%, encourage rational scientists to adopt a research strategy that is to the detriment of the advancement of scientific knowledge. Given finite resources, the importance placed on novel findings, and the emphasis on a relatively small number of publications, scientists wishing to accelerate their career progression should conduct a large number of exploratory studies, each of which will have low statistical power. Since the conclusions of underpowered studies are highly likely to be erroneous [<xref ref-type="bibr" rid="pbio.2000995.ref002">2</xref>], this means that most published findings are likely to be false [<xref ref-type="bibr" rid="pbio.2000995.ref005">5</xref>]. The results of our model support this conclusion. Indeed, given evidence that with sufficient analytical flexibility (known as <italic>p</italic>-hacking) almost any dataset can produce a statistically significant (and therefore publishable) finding [<xref ref-type="bibr" rid="pbio.2000995.ref016">16</xref>], our results are likely to be conservative. There is therefore evidence from both simulations and empirical studies that current research practices may not be optimal for the advancement of knowledge, at least in the biomedical sciences.</p>
<p>Ioannidis [<xref ref-type="bibr" rid="pbio.2000995.ref005">5</xref>] concluded—on the basis of simulations of the impact of varying types of bias—that most published research findings are false. Button and colleagues [<xref ref-type="bibr" rid="pbio.2000995.ref002">2</xref>] showed that the average statistical power of studies in neuroscience is likely to be very low, and there is evidence that this problem exists across different domains of biomedical science [<xref ref-type="bibr" rid="pbio.2000995.ref003">3</xref>]. Recently, the Open Science Collaboration [<xref ref-type="bibr" rid="pbio.2000995.ref004">4</xref>] reported that of 100 psychology studies selected from leading journals, only a minority of findings (approximately 40%) could be replicated. Similar results have been obtained by the pharmaceutical industry attempting to reproduce “landmark” findings from the published academic literature [<xref ref-type="bibr" rid="pbio.2000995.ref015">15</xref>]. A survey of early career researchers indicated that “survival mentoring” (i.e., guidance on how to survive in the profession) is associated with increased odds of questionable behaviour in methods (e.g., withholding details of methodology or results), use of funds (e.g., use of funds from one project on another project), and peer review (e.g., providing an overly positive or negative recommendation) [<xref ref-type="bibr" rid="pbio.2000995.ref017">17</xref>]. Our results align with those of empirical studies indicating that the use of several small underpowered samples represents a more efficient research strategy (in terms of simply publishing papers, irrespective of whether the findings are correct) than does the use of one large powerful sample [<xref ref-type="bibr" rid="pbio.2000995.ref018">18</xref>]. This is presumably why most studies have low statistical power [<xref ref-type="bibr" rid="pbio.2000995.ref002">2</xref>], which is predicted under the rational strategy for individual scientists identified by our analysis. They are also consistent with the results of models of scientific communities, which indicate that selection for high output leads to poorer methods and increasingly high false discovery rates [<xref ref-type="bibr" rid="pbio.2000995.ref019">19</xref>].</p>
<p>Current incentive structures would only be appropriate if editorial and peer review practices were much more stringent regarding the sample size and statistical power, as well as the strength of statistical evidence required of studies (<xref ref-type="fig" rid="pbio.2000995.g004">Fig 4C</xref>). Critically, our model indicates how altering incentive structures, by considering more of a researcher’s output (reducing ϕ) and giving less weight to strikingly novel findings (reducing γ) when making appointment and promotion decisions, would encourage a change in researcher behaviour that improves the scientific value of research. Such a change would mean that parameters reflecting current editorial and peer review practices actually do optimise the scientific value of research (<xref ref-type="fig" rid="pbio.2000995.g005">Fig 5</xref>). Effecting this change would require action by research funders and institutions. Alternatively, journals and journals editors may strive to increase the stringency of the editorial and peer review process, for example, by requiring larger sample sizes (i.e., larger <italic>m</italic>, generating higher statistical power) and greater statistical stringency (i.e., smaller α, increasing the proportion of significant results that are correct). Similar changes have been suggested previously [<xref ref-type="bibr" rid="pbio.2000995.ref018">18</xref>], and some research fields have successfully implemented cultural changes—in genomics, the use of highly stringent α levels and large sample sizes is now standard practice (in part as a result of the multiple testing burden associated with genome-wide association studies) [<xref ref-type="bibr" rid="pbio.2000995.ref020">20</xref>], while particle physics has adopted a “5 sigma” rule for declaring discovery [<xref ref-type="bibr" rid="pbio.2000995.ref021">21</xref>]. However, our analysis is the first to show the likely impact of these strategies on the scientific value of research and how they may be complemented by top-down change to current incentive structures initiated by funders and institutions. Our model predicts that the changes to incentive structures will increase the amount of confirmatory work dramatically, but the increase in the statistical power of exploratory studies would be small (peak in <xref ref-type="fig" rid="pbio.2000995.g001">Fig 1B</xref>). However, we note that the “landscape” would become less steep around the optimum (cf. <xref ref-type="fig" rid="pbio.2000995.g001">Fig 1B</xref> and <xref ref-type="fig" rid="pbio.2000995.g001">Fig 1A</xref>), especially in the direction of higher power (left–right). Therefore, such changes may create conditions in which it is easier to nudge researchers to do higher (&gt; 80%) powered studies, because the (potential) cost to their individual fitness would be small.</p>
<fig id="pbio.2000995.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pbio.2000995.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Effect of editorial stringency on total scientific output for ideal incentive structures.</title>
<p>The figure shows the proportion of published studies that are correct 1 − <italic>P</italic><sub><italic>T</italic></sub> (A, B), the total number of published studies <italic>N</italic><sub><italic>C</italic></sub> + <italic>N</italic><sub><italic>C</italic></sub> (C, D), and the total scientific value of research <italic>V</italic><sub><italic>S</italic></sub> (E, F). We varied the following parameters: the probability of a Type I error α (A, C, E), and the dependence of acceptance on sample size <italic>m</italic> (B, D, F). The lines show predictions for two values of the probability that an effect is real (<italic>f</italic><sub><italic>E</italic></sub>) and two values of the effect size (solid: <italic>f</italic><sub><italic>E</italic></sub> = 0.2, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.21; dotted: <italic>f</italic><sub><italic>E</italic></sub> = 0.3, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.21; dashed: <italic>f</italic><sub><italic>E</italic></sub> = 0.2, <italic>r</italic><sub><italic>C</italic></sub> <italic>= r</italic><sub><italic>E</italic></sub> = 0.32). Other values: <italic>N</italic><sub><italic>C</italic></sub> = 120, <italic>T</italic> = 2,000, <italic>k</italic> = 20, α = 0.05, σ<sup>2</sup> = 1, <italic>m</italic> = 3, ϕ = 0.55, and γ = 0.055.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.g005" xlink:type="simple"/>
</fig>
<p>Perversely, current incentive structures may promote low-quality science, because the research strategy they encourage is more likely to produce striking (but erroneous) findings—publications from institutions that performed well in a recent research evaluation exercise report fewer measures of study quality (e.g., experimenter blinding, randomisation, etc.) than studies selected randomly from the wider literature [<xref ref-type="bibr" rid="pbio.2000995.ref022">22</xref>]. Competition for funding and prestige may contribute to strategic-game playing [<xref ref-type="bibr" rid="pbio.2000995.ref023">23</xref>], and it is plausible that this competition may be most pronounced at the most prestigious institutions. Current incentives that encourage scientists to build momentum around a single research focus may also be problematic, if they discourage scientists from abandoning an existing research focus (for example, because initial findings fail to replicate) and switching to a potentially more fruitful research area [<xref ref-type="bibr" rid="pbio.2000995.ref024">24</xref>]. It is important to note that we will never attain a situation in which 100% of findings are true—indeed, this would be undesirable, as it would require us to only pursue questions with very high prestudy odds and invest considerable resources into each study to achieve near-100% statistical power. This would obviously be at the expense of novelty and discovery. Some balance is necessary. Understanding the ecosystem that gives rise to behaviours that undermine the scientific value of research is the first step towards addressing them and developing a system that strikes the optimal balance between exploratory and confirmatory research.</p>
<sec id="sec002">
<title>Supporting Information</title>
<supplementary-material id="pbio.2000995.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Effect of the value of <italic>m</italic> (shown on lines) on the function <italic>A</italic>.</title>
<p>Larger values of <italic>m</italic> imply that larger sample sizes are required for publication in journals.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s002" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s002" xlink:type="simple">
<label>S2 Fig</label>
<caption>
<title>Assumptions about individual researcher fitness <italic>V</italic><sub><italic>R</italic></sub>.</title>
<p>Individual researcher fitness <italic>V</italic><sub><italic>R</italic></sub> (orange = high, black = low) as a function of the number of exploratory and confirmatory papers published for 3 values of γ (rows) and 3 values of ϕ (columns). The values capture a range that we consider reasonable. When ϕ = 0, for example, there is no diminishing return on additional papers, whereas when ϕ = 1 a single paper is valued equally to 1,000 papers. When γ = 0.0, novel findings are given equal weight to confirmatory findings, whereas when γ = 0.1 only novel findings are worth publishing because they are weighted so much more than confirmatory papers. If both are small (bottom-left) then the effect of number of both papers is linear. If γ is large and ϕ is small (top-left) then fitness is almost completely determined by the number of exploratory. If γ is small and ϕ is large (bottom-right) then fitness asymptotes at a small total number of each. If both are large (top-right) then fitness depends on both but only gets very high at a large number of exploratory.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s003" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s003" xlink:type="simple">
<label>S3 Fig</label>
<caption>
<title>The various possible scientific value <italic>V</italic><sub><italic>S</italic></sub> explored.</title>
<p>To show the value equation we assume that individual researchers publish four studies and a proportion of them are exploratory (shown on x-axis). The value of the science may also depend on the proportion of studies that are wrong <italic>P</italic><sub><italic>F</italic></sub> (shown on lines). In the text we assume that the total value of science follows the equation shown in panel A, but other functions are possible. In the sensitivity analysis (<xref ref-type="supplementary-material" rid="pbio.2000995.s005">S5 Fig</xref>, <xref ref-type="supplementary-material" rid="pbio.2000995.s006">S6 Fig</xref>, <xref ref-type="supplementary-material" rid="pbio.2000995.s007">S7 Fig</xref>, <xref ref-type="supplementary-material" rid="pbio.2000995.s008">S8 Fig</xref>, <xref ref-type="supplementary-material" rid="pbio.2000995.s009">S9 Fig</xref>) we show that our results are not qualitatively altered by a different choice of function.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s004" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s004" xlink:type="simple">
<label>S4 Fig</label>
<caption>
<title>Mechanism of the low power of exploratory studies.</title>
<p>The optimal sample size is low because false positives can be published as exploratory studies. (A) The power of studies (blue dashed line); the number of studies that are carried out (green dotted line); the number of published articles if all studies found significant results (red solid line). (B) The number of true positives (blue dashed line); false positives (green dotted line); total articles (red solid line). The optimal sample size is at the peak total number of articles. (C) The proportion of studies that are false (blue dashed line); published (green solid line). If false positive results did not count towards researcher value, the optimal sample size would quadruple.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s005" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s005" xlink:type="simple">
<label>S5 Fig</label>
<caption>
<title>Sensitivity analysis for parameter values.</title>
<p>All panels show the total value of science <italic>V</italic><sub><italic>S</italic></sub> [<italic>V</italic><sub><italic>S</italic></sub> = (<italic>N</italic><sub><italic>C</italic></sub> + <italic>N</italic><sub><italic>E</italic></sub>)(1 − <italic>P</italic><sub><italic>F</italic></sub>)] given the optimal strategy of researchers, for four values of γ and ϕ shown in the legend. The x-axes show different variables. In almost all the ranges of all parameters, a reduction in either ϕ or γ would improve <italic>V</italic><sub><italic>S</italic></sub>, and reducing both gives the highest <italic>V</italic><sub><italic>S</italic></sub>.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s006" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s006" xlink:type="simple">
<label>S6 Fig</label>
<caption>
<title>Sensitivity analysis for different scientific value function.</title>
<p>As <xref ref-type="supplementary-material" rid="pbio.2000995.s005">S5 Fig</xref> but for <italic>V</italic><sub><italic>S</italic></sub> = <italic>N</italic><sub><italic>C</italic></sub><italic>N</italic><sub><italic>E</italic></sub>; conclusions are unchanged.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s007" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s007" xlink:type="simple">
<label>S7 Fig</label>
<caption>
<title>Sensitivity analysis for different scientific value function.</title>
<p>As <xref ref-type="supplementary-material" rid="pbio.2000995.s005">S5 Fig</xref> but for <inline-formula id="pbio.2000995.e006"><alternatives><graphic id="pbio.2000995.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.2000995.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>; conclusions are unchanged.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s008" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s008" xlink:type="simple">
<label>S8 Fig</label>
<caption>
<title>Sensitivity analysis for different scientific value function.</title>
<p>As <xref ref-type="supplementary-material" rid="pbio.2000995.s005">S5 Fig</xref> but for <inline-formula id="pbio.2000995.e007"><alternatives><graphic id="pbio.2000995.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.2000995.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>; conclusions are unchanged.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s009" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s009" xlink:type="simple">
<label>S9 Fig</label>
<caption>
<title>Sensitivity analysis for different scientific value function.</title>
<p>As <xref ref-type="supplementary-material" rid="pbio.2000995.s005">S5 Fig</xref> but for <inline-formula id="pbio.2000995.e008"><alternatives><graphic id="pbio.2000995.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pbio.2000995.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>S</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>F</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mi>C</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>; conclusions are unchanged.</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s010" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s010" xlink:type="simple">
<label>S1 Table</label>
<caption>
<title>Parameters in the model and their default values.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s011" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s011" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Methods.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
<supplementary-material id="pbio.2000995.s012" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" position="float" xlink:href="info:doi/10.1371/journal.pbio.2000995.s012" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>Matlab Code.</title>
<p>(DOCX)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<fn-group>
<fn fn-type="other" id="fn001">
<p><bold>Provenance:</bold> Not commissioned; externally peer reviewed</p>
</fn>
</fn-group>
<glossary>
<title>Abbreviations</title>
<def-list>
<def-item><term>PPV</term>
<def><p>positive predictive value</p></def>
</def-item>
<def-item><term>REF</term>
<def><p>Research Excellence Framework</p></def>
</def-item>
</def-list>
</glossary>
<ref-list>
<title>References</title>
<ref id="pbio.2000995.ref001"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>van Dijk</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Manor</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Carey</surname> <given-names>LB</given-names></name> (<year>2014</year>) <article-title>Publication metrics and success on the academic job market</article-title>. <source>Curr Biol</source> <volume>24</volume>: <fpage>R516</fpage>–<lpage>517</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.cub.2014.04.039" xlink:type="simple">10.1016/j.cub.2014.04.039</ext-link></comment> <object-id pub-id-type="pmid">24892909</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref002"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Button</surname> <given-names>KS</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Mokrysz</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Nosek</surname> <given-names>BA</given-names></name>, <name name-style="western"><surname>Flint</surname> <given-names>J</given-names></name>, <etal>et al</etal>. (<year>2013</year>) <article-title>Power failure: why small sample size undermines the reliability of neuroscience</article-title>. <source>Nat Rev Neurosci</source> <volume>14</volume>: <fpage>365</fpage>–<lpage>376</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nrn3475" xlink:type="simple">10.1038/nrn3475</ext-link></comment> <object-id pub-id-type="pmid">23571845</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref003"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Szucs D Ioannidis JPA (2016). Empirical assessment of published effect sizes and power in the recent cognitive neuroscience and psychology literature. bioRxiv 071530.</mixed-citation></ref>
<ref id="pbio.2000995.ref004"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><collab>Open Science Collaboration</collab> (<year>2015</year>) <article-title>Estimating the reproducibility of psychological science</article-title>. <source>Science</source> <volume>349</volume>: <fpage>aac4716</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.aac4716" xlink:type="simple">10.1126/science.aac4716</ext-link></comment> <object-id pub-id-type="pmid">26315443</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref005"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name> (<year>2005</year>) <article-title>Why most published research findings are false</article-title>. <source>PLoS Med</source> <volume>2</volume>: <fpage>e124</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pmed.0020124" xlink:type="simple">10.1371/journal.pmed.0020124</ext-link></comment> <object-id pub-id-type="pmid">16060722</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref006"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Friedman</surname> <given-names>SH</given-names></name>, <name name-style="western"><surname>Karlsson</surname> <given-names>JOM</given-names></name> (<year>1997</year>) <article-title>A novel paradigm</article-title>. <source>Nature</source> <volume>385</volume>: <fpage>480</fpage>.</mixed-citation></ref>
<ref id="pbio.2000995.ref007"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Henikoff</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Levis</surname> <given-names>R</given-names></name> (<year>1991</year>) <article-title>So what's new?</article-title> <source>Nature</source> <volume>350</volume>: <fpage>9</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/350009b0" xlink:type="simple">10.1038/350009b0</ext-link></comment> <object-id pub-id-type="pmid">2002851</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref008"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Levis</surname> <given-names>RW</given-names></name>, <name name-style="western"><surname>Henikoff</surname> <given-names>S</given-names></name> (<year>1997</year>) <article-title>You read it here first</article-title>. <source>Nature</source> <volume>387</volume>: <fpage>843</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/43049" xlink:type="simple">10.1038/43049</ext-link></comment> <object-id pub-id-type="pmid">9202111</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref009"><label>9</label><mixed-citation publication-type="other" xlink:type="simple">Research Excellence Framework (2014) Research Excellence Framework. <ext-link ext-link-type="uri" xlink:href="http://www.ref.ac.uk" xlink:type="simple">http://www.ref.ac.uk</ext-link></mixed-citation></ref>
<ref id="pbio.2000995.ref010"><label>10</label><mixed-citation publication-type="other" xlink:type="simple">Excellence Research Australia (2015) Excellence in Research for Australia. <ext-link ext-link-type="uri" xlink:href="http://www.arc.gov.au/excellence-research-australia" xlink:type="simple">http://www.arc.gov.au/excellence-research-australia</ext-link></mixed-citation></ref>
<ref id="pbio.2000995.ref011"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mcnamara</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Houston</surname> <given-names>AI</given-names></name> (<year>1986</year>) <article-title>The common currency for behavioral decisions</article-title>. <source>Am Nat</source> <volume>127</volume>: <fpage>358</fpage>–<lpage>378</lpage>.</mixed-citation></ref>
<ref id="pbio.2000995.ref012"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Parker</surname> <given-names>GA</given-names></name>, <name name-style="western"><surname>Maynard-Smith</surname> <given-names>J</given-names></name> (<year>1990</year>) <article-title>Optimality theory in evolutionary biology</article-title>. <source>Nature</source> <volume>348</volume>: <fpage>27</fpage>–<lpage>33</lpage>.</mixed-citation></ref>
<ref id="pbio.2000995.ref013"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Dumas-Mallet</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Button</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Boraud</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Munafo</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gonon</surname> <given-names>F</given-names></name> (<year>2016</year>) <article-title>Replication Validity of Initial Association Studies: A comparison between psychiatry, neurology and four somatic diseases</article-title>. <source>PLoS ONE</source> <volume>11</volume>: <fpage>e0158064</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0158064" xlink:type="simple">10.1371/journal.pone.0158064</ext-link></comment> <object-id pub-id-type="pmid">27336301</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref014"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Richard</surname> <given-names>FD</given-names></name>, <name name-style="western"><surname>Bond</surname> <given-names>CF</given-names> <suffix>Jr</suffix></name>, <name name-style="western"><surname>Stokes-Zoota</surname> <given-names>JJ</given-names></name> (<year>2003</year>) <article-title>One hundred years of social psychology quantitatively described</article-title>. <source>Rev Gen Psychol</source> <volume>7</volume>: <fpage>331</fpage>–<lpage>363</lpage>.</mixed-citation></ref>
<ref id="pbio.2000995.ref015"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Begley</surname> <given-names>CG</given-names></name>, <name name-style="western"><surname>Ellis</surname> <given-names>LM</given-names></name> (<year>2012</year>) <article-title>Drug development: Raise standards for preclinical cancer research</article-title>. <source>Nature</source> <volume>483</volume>: <fpage>531</fpage>–<lpage>533</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/483531a" xlink:type="simple">10.1038/483531a</ext-link></comment> <object-id pub-id-type="pmid">22460880</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref016"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Simmons</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Nelson</surname> <given-names>LD</given-names></name>, <name name-style="western"><surname>Simonsohn</surname> <given-names>U</given-names></name> (<year>2011</year>) <article-title>False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant</article-title>. <source>Psychol Sci</source> <volume>22</volume>: <fpage>1359</fpage>–<lpage>1366</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/0956797611417632" xlink:type="simple">10.1177/0956797611417632</ext-link></comment> <object-id pub-id-type="pmid">22006061</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref017"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Horn</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Risbey</surname> <given-names>KR</given-names></name>, <name name-style="western"><surname>Ronning</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>De Vries</surname> <given-names>R</given-names></name>, <etal>et al</etal>. (<year>2007</year>) <article-title>What do mentoring and training in the responsible conduct of research have to do with scientists' misbehavior? Findings from a national survey of NIH-funded scientists</article-title>. <source>Acad Med</source> <volume>82</volume>: <fpage>853</fpage>–<lpage>860</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1097/ACM.0b013e31812f764c" xlink:type="simple">10.1097/ACM.0b013e31812f764c</ext-link></comment> <object-id pub-id-type="pmid">17726390</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref018"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bakker</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>van Dijk</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Wicherts</surname> <given-names>JM</given-names></name> (<year>2012</year>) <article-title>The rules of the game called psychological science</article-title>. <source>Perspect Psychol Sci</source> <volume>7</volume>: <fpage>543</fpage>–<lpage>554</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1177/1745691612459060" xlink:type="simple">10.1177/1745691612459060</ext-link></comment> <object-id pub-id-type="pmid">26168111</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref019"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Smaldino</surname> <given-names>PE</given-names></name>, <name name-style="western"><surname>McElreath</surname> <given-names>R</given-names></name> (<year>2016</year>) <article-title>The natural selection of bad science</article-title>. <source>R Soc Open Sci</source> <volume>3</volume>: <fpage>160384</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsos.160384" xlink:type="simple">10.1098/rsos.160384</ext-link></comment> <object-id pub-id-type="pmid">27703703</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref020"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bush</surname> <given-names>WS</given-names></name>, <name name-style="western"><surname>Moore</surname> <given-names>JH</given-names></name> (<year>2012</year>) <article-title>Chapter 11: Genome-wide association studies</article-title>. <source>PLoS Comput Biol</source> <volume>8</volume>: <fpage>e1002822</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002822" xlink:type="simple">10.1371/journal.pcbi.1002822</ext-link></comment> <object-id pub-id-type="pmid">23300413</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref021"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><collab>CMS Collaboration</collab> (<year>2001</year>) <article-title>CMS technical design report, volume II: Physics performance</article-title>. <source>J Phys G: Nuclear and Particle Physics</source> <volume>G34</volume>: <fpage>995</fpage>–<lpage>1579</lpage>.</mixed-citation></ref>
<ref id="pbio.2000995.ref022"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Macleod</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Lawson McLean</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Kyriakopoulou</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Serghiou</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>de Wilde</surname> <given-names>A</given-names></name>, <etal>et al</etal>. (<year>2015</year>) <article-title>Risk of bias in peports of in vivo research: A focus for improvement</article-title>. <source>PLoS Biol</source> <volume>13</volume>: <fpage>e1002273</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pbio.1002273" xlink:type="simple">10.1371/journal.pbio.1002273</ext-link></comment> <object-id pub-id-type="pmid">26460723</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref023"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Anderson</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Ronning</surname> <given-names>EA</given-names></name>, <name name-style="western"><surname>De Vries</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Martinson</surname> <given-names>BC</given-names></name> (<year>2007</year>) <article-title>The perverse effects of competition on scientists' work and relationships</article-title>. <source>Sci Eng Ethics</source> <volume>13</volume>: <fpage>437</fpage>–<lpage>461</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s11948-007-9042-5" xlink:type="simple">10.1007/s11948-007-9042-5</ext-link></comment> <object-id pub-id-type="pmid">18030595</object-id></mixed-citation></ref>
<ref id="pbio.2000995.ref024"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Joyner</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Paneth</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Ioannidis</surname> <given-names>JP</given-names></name> (<year>2016</year>) <article-title>What happens when underperforming big ideas in research become entrenched?</article-title> <source>JAMA</source> <volume>316</volume>: <fpage>1355</fpage>–<lpage>1356</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1001/jama.2016.11076" xlink:type="simple">10.1001/jama.2016.11076</ext-link></comment> <object-id pub-id-type="pmid">27467098</object-id></mixed-citation></ref>
</ref-list>
</back>
</article>
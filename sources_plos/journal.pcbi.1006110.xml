<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-17-01249</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1006110</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Vision</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical mechanics</subject><subj-group><subject>Motion</subject><subj-group><subject>Inertia</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Sensory perception</subject><subj-group><subject>Sensory cues</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive science</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive psychology</subject><subj-group><subject>Perception</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Optimization</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Research assessment</subject><subj-group><subject>Research validity</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Bayesian comparison of explicit and implicit causal inference strategies in multisensory heading perception</article-title>
<alt-title alt-title-type="running-head">Bayesian comparison of causal inference strategies in heading perception</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes" equal-contrib="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7471-7336</contrib-id>
<name name-style="western">
<surname>Acerbi</surname> <given-names>Luigi</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Formal analysis</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Software</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Visualization</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="fn" rid="currentaff001"><sup>¤</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
<contrib contrib-type="author" equal-contrib="yes" xlink:type="simple">
<name name-style="western">
<surname>Dokka</surname> <given-names>Kalpana</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Data curation</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Investigation</role>
<role content-type="http://credit.casrai.org/">Methodology</role>
<role content-type="http://credit.casrai.org/">Validation</role>
<role content-type="http://credit.casrai.org/">Writing – original draft</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Angelaki</surname> <given-names>Dora E.</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9835-9083</contrib-id>
<name name-style="western">
<surname>Ma</surname> <given-names>Wei Ji</given-names></name>
<role content-type="http://credit.casrai.org/">Conceptualization</role>
<role content-type="http://credit.casrai.org/">Funding acquisition</role>
<role content-type="http://credit.casrai.org/">Supervision</role>
<role content-type="http://credit.casrai.org/">Writing – review &amp; editing</role>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Center for Neural Science, New York University, New York, NY, United States of America</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Department of Neuroscience, Baylor College of Medicine, Houston, TX, United States of America</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Department of Psychology, New York University, New York, NY, United States of America</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Gershman</surname> <given-names>Samuel J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>Harvard University, UNITED STATES</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="current-aff" id="currentaff001">
<label>¤</label>
<p>Current address: Département des neurosciences fondamentales, Université de Genève, Genève, Switzerland</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">luigi.acerbi@nyu.edu</email>, <email xlink:type="simple">luigi.acerbi@gmail.com</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>7</month>
<year>2018</year>
</pub-date>
<pub-date pub-type="epub">
<day>27</day>
<month>7</month>
<year>2018</year>
</pub-date>
<volume>14</volume>
<issue>7</issue>
<elocation-id>e1006110</elocation-id>
<history>
<date date-type="received">
<day>26</day>
<month>7</month>
<year>2017</year>
</date>
<date date-type="accepted">
<day>28</day>
<month>3</month>
<year>2018</year>
</date>
</history>
<permissions>
<copyright-year>2018</copyright-year>
<copyright-holder>Acerbi et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1006110"/>
<abstract>
<p>The precision of multisensory perception improves when cues arising from the same cause are integrated, such as visual and vestibular heading cues for an observer moving through a stationary environment. In order to determine how the cues should be processed, the brain must infer the causal relationship underlying the multisensory cues. In heading perception, however, it is unclear whether observers follow the Bayesian strategy, a simpler non-Bayesian heuristic, or even perform causal inference at all. We developed an efficient and robust computational framework to perform Bayesian model comparison of causal inference strategies, which incorporates a number of alternative assumptions about the observers. With this framework, we investigated whether human observers’ performance in an <italic>explicit</italic> cause attribution and an <italic>implicit</italic> heading discrimination task can be modeled as a causal inference process. In the explicit causal inference task, all subjects accounted for cue disparity when reporting judgments of common cause, although not necessarily all in a Bayesian fashion. By contrast, but in agreement with previous findings, data from the heading discrimination task only could not rule out that several of the same observers were adopting a forced-fusion strategy, whereby cues are integrated regardless of disparity. Only when we combined evidence from both tasks we were able to rule out forced-fusion in the heading discrimination task. Crucially, findings were robust across a number of variants of models and analyses. Our results demonstrate that our proposed computational framework allows researchers to ask complex questions within a rigorous Bayesian framework that accounts for parameter and model uncertainty.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author summary</title>
<p>As we interact with objects and people in the environment, we are constantly exposed to numerous sensory stimuli. For safe navigation and meaningful interaction with entities in the environment, our brain must determine if the sensory inputs arose from a common or different causes in order to determine whether they should be integrated into a unified percept. However, how our brain performs such a causal inference process is not well understood, partly due to the lack of computational tools that can address the complex repertoire of assumptions required for modeling human perception. We have developed a set of computational algorithms that characterize the causal inference process within a quantitative model based framework. We have tested the efficacy of our methods in predicting how human observers judge visual-vestibular heading. Specifically, our algorithms perform rigorous comparison of alternative models of causal inference that encompass a wide repertoire of assumptions observers may have about their internal noise or stimulus statistics. Importantly, our tools are widely applicable to modeling other processes that characterize perception.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000053</institution-id>
<institution>National Eye Institute</institution>
</institution-wrap>
</funding-source>
<award-id>R01EY020958</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9835-9083</contrib-id>
<name name-style="western">
<surname>Ma</surname> <given-names>Wei Ji</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award002">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000183</institution-id>
<institution>Army Research Office</institution>
</institution-wrap>
</funding-source>
<award-id>W911NF-12–1-0262</award-id>
<principal-award-recipient>
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9835-9083</contrib-id>
<name name-style="western">
<surname>Ma</surname> <given-names>Wei Ji</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award003">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000055</institution-id>
<institution>National Institute on Deafness and Other Communication Disorders</institution>
</institution-wrap>
</funding-source>
<award-id>R03DC013987</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Dokka</surname> <given-names>Kalpana</given-names></name>
</principal-award-recipient>
</award-group>
<award-group id="award004">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/100000002</institution-id>
<institution>National Institutes of Health</institution>
</institution-wrap>
</funding-source>
<award-id>R01DC007620</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Angelaki</surname> <given-names>Dora E.</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was supported by award number R01EY020958 from the National Eye Institute, and award number W911NF-12–1-0262 from the Army Research Office to WJM. KD was supported by National Institute of Deafness and Communications Disorders Grant R03 DC013987. DEA was supported by National Institute of Health Grant R01 DC007620. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="3"/>
<page-count count="38"/>
</counts>
<custom-meta-group>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>All relevant data and code are available from the following GitHub repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/visvest-causinf" xlink:type="simple">https://github.com/lacerbi/visvest-causinf</ext-link>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>We constantly interact with people and objects around us. As a consequence, our brain receives information from multiple senses as well as multiple inputs from the same sense. Cues from the same sense (e.g., texture and disparity cues to an object shape) are generally congruent as they usually reflect identical properties of a common external entity. Thus, the brain eventually learns to mandatorily integrate inputs from the same modality as a unified percept, which provides more precise information than either cue alone [<xref ref-type="bibr" rid="pcbi.1006110.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref002">2</xref>]. Similarly, integration of cues represented in different modalities but associated with a common stimulus also improves perceptual behavior. There is a wealth of evidence that demonstrates increased precision [<xref ref-type="bibr" rid="pcbi.1006110.ref003">3</xref>–<xref ref-type="bibr" rid="pcbi.1006110.ref012">12</xref>], greater accuracy [<xref ref-type="bibr" rid="pcbi.1006110.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref014">14</xref>] and faster speed [<xref ref-type="bibr" rid="pcbi.1006110.ref015">15</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref016">16</xref>] of perceptual performance due to multimodal integration.</p>
<p>However, multimodal cues present a complex problem. Cues from different modalities are not necessarily congruent as different stimuli can simultaneously impinge on our senses, giving rise to coincident yet conflicting information. For example, in a classic ventriloquist illusion, even though the sound originates from the puppeteer’s mouth, we perceive that it is the puppet which is talking [<xref ref-type="bibr" rid="pcbi.1006110.ref017">17</xref>]. Mandatory integration of multimodal cues arising from different stimuli can induce errors in perceptual estimates [<xref ref-type="bibr" rid="pcbi.1006110.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref014">14</xref>]. Thus, for efficient interaction with the world, the brain must assess whether the multimodal cues originated from the same cause, and should be integrated into a single percept, or instead the cues should be interpreted in isolation as they arose from different causes (segregation). Despite the often overwhelming amount of sensory inputs, we are typically able to integrate relevant cues while ignoring irrelevant sensory input. It is thus plausible that our brain infers the causal relationship between multisensory cues to determine if and how the cues should be integrated.</p>
<p>Bayesian causal inference—inference of the causal relationship between observed cues, based on the inversion of the statistical model of the task—has been proposed as the decision strategy adopted by the brain to address the problem of integration vs. segregation of sensory cues [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref019">19</xref>]. Such a decision strategy has described human performance in spatial localization [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>–<xref ref-type="bibr" rid="pcbi.1006110.ref027">27</xref>], orientation judgment [<xref ref-type="bibr" rid="pcbi.1006110.ref028">28</xref>], oddity detection [<xref ref-type="bibr" rid="pcbi.1006110.ref029">29</xref>], speech perception [<xref ref-type="bibr" rid="pcbi.1006110.ref030">30</xref>], time-interval perception [<xref ref-type="bibr" rid="pcbi.1006110.ref031">31</xref>], simple perceptual organization [<xref ref-type="bibr" rid="pcbi.1006110.ref032">32</xref>], and heading perception [<xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>]. In recent years, interest in the Bayesian approach to causal inference has further increased as neural imaging has identified a hierarchy of brain areas involved in neural processing while observers implemented a Bayesian strategy to perform a causal inference task [<xref ref-type="bibr" rid="pcbi.1006110.ref020">20</xref>]. At the same time, Bayesian models have become more complex as they include more precise descriptions of the sensory noise [<xref ref-type="bibr" rid="pcbi.1006110.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>] and alternative Bayesian decision strategies [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref024">24</xref>]. However, it is still unknown whether observers fully implement Bayesian causal inference, or merely an approximation that does not take into account the full statistical structure of the task. For example, the Bayes-optimal inference strategy ought to incorporate sensory uncertainty into its decision rule. On the other hand, a suboptimal heuristic decision rule may disregard sensory uncertainty [<xref ref-type="bibr" rid="pcbi.1006110.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref036">36</xref>]. Thus, the growing complexity of models and the need to consider alternative hypotheses require an efficient computational framework to address these open questions while avoiding trappings such as overfitting or lack of model identifiability [<xref ref-type="bibr" rid="pcbi.1006110.ref037">37</xref>]. For a more detailed overview of open issues in multisensory perception and causal inference at the intersection of behavior, neurophysiology and computational modeling, we refer the reader to [<xref ref-type="bibr" rid="pcbi.1006110.ref038">38</xref>–<xref ref-type="bibr" rid="pcbi.1006110.ref040">40</xref>].</p>
<sec id="sec002">
<title>Visuo-vestibular integration in heading perception</title>
<p>Visuo-vestibular integration in heading perception presents an ideal case to characterize the details of the causal inference strategy in multisensory perception. While a wealth of published studies have shown that integration of visual and vestibular self-motion cues increases perceptual precision [<xref ref-type="bibr" rid="pcbi.1006110.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1006110.ref012">12</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref041">41</xref>–<xref ref-type="bibr" rid="pcbi.1006110.ref043">43</xref>], and accuracy [<xref ref-type="bibr" rid="pcbi.1006110.ref014">14</xref>], such an integration only makes sense if the two cues arise from the same cause—that is optic flow and inertial motion signal heading in the same direction. Despite the putative relevance of causal inference in heading perception, the inference strategies that characterize visuo-vestibular integration in the presence of sensory conflict remain poorly understood. For example, a recent study has found that observers predominantly integrated visual and vestibular cues even in the presence of large spatial discrepancies [<xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>]—whereas a subsequent work has presented evidence in favor of causal inference [<xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>]. Furthermore, these studies did not vary cue reliability—a manipulation that is critical to test whether a Bayes-optimal inference strategy or a suboptimal approximation was used [<xref ref-type="bibr" rid="pcbi.1006110.ref035">35</xref>].</p>
<p>Another aspect that can influence the choice of inference strategy is the type of inference performed by the observer. In particular, de Winkel and colleagues [<xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>] asked subjects to indicate the perceived direction of inertial heading—an ‘implicit’ causal inference task as subjects implicitly assessed the causal relationship between visual and vestibular cues on their way to indicate the final (integrated or segregated) heading percept. Even in the presence of spatial disparities as high as 90°, one study found that several subjects were best described by a model which fully integrated visual and vestibular cues [<xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>] (possibly influenced by the experimental design; see also [<xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>]). It is plausible that performing an explicit causal inference task, which forces subjects to indicate whether visual and vestibular cues arose from the same or different events, may elicit different inference strategies, as previously reported in category-based induction [<xref ref-type="bibr" rid="pcbi.1006110.ref044">44</xref>], multi-cue judgment [<xref ref-type="bibr" rid="pcbi.1006110.ref045">45</xref>], and sensorimotor decision-making [<xref ref-type="bibr" rid="pcbi.1006110.ref046">46</xref>]. While some studies have tested both explicit and implicit causal inference [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref047">47</xref>], to our knowledge only one previous study contemplated the possibility of different strategies between implicit and explicit causal inference tasks [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>], and a systematic comparison of inference strategies in the two tasks has never been carried out within a larger computational framework.</p>
</sec>
<sec id="sec003">
<title>Bayesian comparison of causal inference strategies</title>
<p>Thus, the goal of this work is two-fold. First, we introduce a set of techniques to perform robust, efficient Bayesian factorial model comparison of a variety of Bayesian and non-Bayesian models of causal inference in multisensory perception. Factorial comparison is a way to simultaneously test different orthogonal hypotheses about the observers [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref048">48</xref>–<xref ref-type="bibr" rid="pcbi.1006110.ref050">50</xref>]. Our approach is fully Bayesian in that we consider both parameter and model uncertainty, improving over previous analyses which used point estimates for the parameters and compared individual models. A full account of uncertainty in both parameter and model space, by marginalizing over parameters and model components, is particularly prudent when dealing with internal processes, such as decision strategies, which may have different latent explanations. An analysis that disregards such uncertainty might produce unwarranted conclusions about the internal processes that generated the observed behavior [<xref ref-type="bibr" rid="pcbi.1006110.ref037">37</xref>]. Second, we demonstrate our methods by quantitatively comparing the decision strategies underlying explicit and implicit causal inference in visuo-vestibular heading perception within the framework of Bayesian model comparison. We found that even though the study of explicit and implicit causal inference in isolation might suggest different inference rules, a joint analysis that combines all available evidence points to no difference between tasks, with subjects performing some form of causal inference in both the explicit and implicit tasks that used identical experimental setups.</p>
<p>In sum, we demonstrate how state-of-the-art techniques for model building, fitting, and comparison, combined with advanced analysis tools, allow us to ask nuanced questions about the observer’s decision strategies in causal inference. Importantly, these methods come with a number of diagnostics, sanity checks and a rigorous quantification of uncertainty that allow the experimenter to be explicit about the weight of evidence.</p>
</sec>
</sec>
<sec id="sec004" sec-type="results">
<title>Results</title>
<sec id="sec005">
<title>Computational framework</title>
<p>We compiled a diverse set of computational techniques to perform robust Bayesian comparison of models of causal inference in multisensory perception, which we dub the ‘Bayesian cookbook for causal inference in multisensory perception’, or herein simply ‘the cookbook’. The main goal of the cookbook is to characterize observers’ decision strategies underlying causal inference, and possibly other details thereof, within a rigorous Bayesian framework that accounts for both parameter uncertainty and model uncertainty. The cookbook is ‘doubly-Bayesian’ in that it affords a fully Bayesian analysis of observers who may or may not be performing Bayesian inference themselves [<xref ref-type="bibr" rid="pcbi.1006110.ref051">51</xref>]. Fully Bayesian model comparison is computationally intensive, hence the cookbook is concerned with efficient algorithmic solutions.</p>
<p>The cookbook comprises of: (a) a fairly general recipe for building observer models for causal inference in multisensory perception (see <xref ref-type="sec" rid="sec019">Methods</xref> and Section 1 of <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>), which lends itself to a factorial model comparison; (b) techniques for fast evaluation of a large number of causal inference observer models; (c) procedures for model fitting via maximum likelihood, and approximating the Bayesian posterior of the parameters via Markov Chain Monte Carlo (MCMC); (d) state-of-the-art methods to compute model comparison metrics and perform factorial model selection. It is noteworthy that, while the current work focuses on the example of visuo-vestibular heading perception, this cookbook is general and can be applied with minor modifications to multisensory perception across sensory domains. Computational details are described in the Methods section and <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>. Here we present an application of our framework to causal inference in multisensory heading perception. For ease of reference, we summarize relevant abbreviations used in the paper and their meaning in <xref ref-type="table" rid="pcbi.1006110.t001">Table 1</xref>.</p>
<table-wrap id="pcbi.1006110.t001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.t001</object-id>
<label>Table 1</label>
<caption>
<title>Abbreviations and symbols.</title>
</caption>
<alternatives>
<graphic id="pcbi.1006110.t001g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.t001" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">Abbreviation</th>
<th align="left" style="border-bottom:thick">Meaning</th>
<th align="left" style="border-bottom:thick">Context</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"/>
<td align="left"><bold>General</bold></td>
<td align="left"/>
</tr>
<tr>
<td align="left">Δ</td>
<td align="left">Directional disparity between stimuli</td>
<td align="left">Generative model</td>
</tr>
<tr>
<td align="left"><italic>s</italic><sub>vis</sub>, <italic>s</italic><sub>vest</sub></td>
<td align="left">Visual / vestibular heading</td>
<td align="left">Generative model</td>
</tr>
<tr>
<td align="left"><italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub></td>
<td align="left">Noisy measurement of visual / vestibular heading</td>
<td align="left">Generative model</td>
</tr>
<tr>
<td align="left"><italic>C</italic></td>
<td align="left">Causal scenario (<italic>C</italic> = 1 for ‘same’, <italic>C</italic> = 2 for ‘different’)</td>
<td align="left">Generative model</td>
</tr>
<tr>
<td align="left"><italic>c</italic><sub>vis</sub></td>
<td align="left">Visual coherence level (low, medium, or high)</td>
<td align="left">Generative model</td>
</tr>
<tr>
<td align="left"><italic>p</italic><sub>c</sub></td>
<td align="left">Probability of common cause (Bayesian model)</td>
<td align="left">Observer model</td>
</tr>
<tr>
<td align="left" style="border-bottom:thick"><italic>κ</italic><sub>c</sub></td>
<td align="left" style="border-bottom:thick">Criterion for common cause (fixed-criterion model)</td>
<td align="left" style="border-bottom:thick">Observer model</td>
</tr>
<tr>
<td align="left"/>
<td align="left"><bold>Model factors</bold></td>
<td align="left"/>
</tr>
<tr>
<td align="left">Bay</td>
<td align="left">Bayesian strategy</td>
<td align="left">Causal inference strategy</td>
</tr>
<tr>
<td align="left">Fix</td>
<td align="left">Fixed-criterion strategy</td>
<td align="left">Causal inference strategy</td>
</tr>
<tr>
<td align="left">Fus</td>
<td align="left">Fusion strategy</td>
<td align="left">Causal inference strategy</td>
</tr>
<tr>
<td align="left">-C</td>
<td align="left">Constant noise</td>
<td align="left">Sensory noise shape</td>
</tr>
<tr>
<td align="left">-X</td>
<td align="left">Eccentricity-dependent noise</td>
<td align="left">Sensory noise shape</td>
</tr>
<tr>
<td align="left">-E</td>
<td align="left">Empirical prior</td>
<td align="left">Prior type</td>
</tr>
<tr>
<td align="left" style="border-bottom:thick">-I</td>
<td align="left" style="border-bottom:thick">Independent priors</td>
<td align="left" style="border-bottom:thick">Prior type</td>
</tr>
<tr>
<td align="left"/>
<td align="left"><bold>Model fitting and comparison</bold></td>
<td align="left"/>
</tr>
<tr>
<td align="left">AIC(c)</td>
<td align="left">(corrected) Akaike’s Information Criterion</td>
<td align="left">Model comparison metric</td>
</tr>
<tr>
<td align="left">BIC</td>
<td align="left">Bayesian Information Criterion</td>
<td align="left">Model comparison metric</td>
</tr>
<tr>
<td align="left">LML</td>
<td align="left">Log marginal likelihood</td>
<td align="left">Model comparison metric</td>
</tr>
<tr>
<td align="left">LOO</td>
<td align="left">Leave-one-out</td>
<td align="left">Model comparison metric</td>
</tr>
<tr>
<td align="left">MCMC</td>
<td align="left">Markov Chain Monte Carlo</td>
<td align="left">Model fitting technique</td>
</tr>
<tr>
<td align="left">
<inline-formula id="pcbi.1006110.e001">
<alternatives>
<graphic id="pcbi.1006110.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e001" xlink:type="simple"/>
<mml:math display="inline" id="M1">
<mml:mover accent="true">
<mml:mi>φ</mml:mi>
<mml:mo>˜</mml:mo>
</mml:mover>
</mml:math>
</alternatives>
</inline-formula>
</td>
<td align="left">Protected exceedance probability</td>
<td align="left">Bayesian model selection statistic</td>
</tr>
<tr>
<td align="left">BOR</td>
<td align="left">Bayesian Omnibus Risk</td>
<td align="left">Bayesian model selection statistic</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t001fn001">
<p>List of abbreviations and symbols used in the paper, with associated description and usage context.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
<sec id="sec006">
<title>Causal inference in heading perception</title>
<p>We demonstrate our framework taking as a case study the comparison of explicit vs. implicit causal inference strategies in heading perception. In this section we briefly summarize our methods. Extended details and description of the cookbook can be found in the Methods and <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>.</p>
<sec id="sec007">
<title>Experiments</title>
<p>Human observers were presented with synchronous visual (<italic>s</italic><sub>vis</sub>) and vestibular (<italic>s</italic><sub>vest</sub>) headings in the same direction (<italic>C</italic> = 1) or in different directions (<italic>C</italic> = 2) separated by a directional disparity Δ (<xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1A</xref>). Mean stimulus direction (−25°, −20°, −15°,…,25°), cue disparity (0°, ±5°, ±10°, ±20°, and ±40°), and visual cue reliability <italic>c</italic><sub>vis</sub> (coherence: high, medium and low) changed randomly on a trial-by-trial basis (<xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1B</xref>). On each trial, non-zero disparity was either positive (vestibular heading to the right of visual heading) or negative. Observers (<italic>n</italic> = 11) first performed several sessions of an <italic>explicit</italic> causal inference task (‘unity judgment’), in which they indicated if the visual and vestibular stimuli signaled heading in the <italic>same</italic> direction (‘common cause’) or in <italic>different</italic> directions (‘different causes’). The same observers then participated in a number of sessions of the <italic>implicit</italic> causal inference task (‘inertial left/right discrimination’) wherein they indicated if their perceived inertial heading (vestibular) was to the left or right of straight forward. Both tasks consisted of a binary classification (same/different or left/right) with identical experimental apparatus and stimuli. No feedback was given to subjects about the correctness of their response. All observers also performed a number of practice trials and an initial session of a ‘unisensory left/right discrimination’ task in which they reported heading direction (left or right of straight forward) of visual or vestibular stimuli presented in isolation. For each subject we obtained 350–750 trials of the unisensory discrimination task (1 session), 700-1200 trials of the unity judgment task (2-3 sessions), and 2100-3000 trials of the inertial discrimination task (7-9 sessions).</p>
<fig id="pcbi.1006110.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Experiment layout.</title>
<p><bold>A</bold>: Subjects were presented with visual (<italic>s</italic><sub>vis</sub>) and vestibular (<italic>s</italic><sub>vis</sub>) headings either in the same direction (<italic>C</italic> = 1) or in different directions (<italic>C</italic> = 2). In different sessions, subjects were asked to judge whether stimuli had the same cause (‘unity judgment’, explicit causal inference) or whether the vestibular heading was to the left or right of straight forward (‘inertial discrimination’, implicit causal inference). <bold>B</bold>: Distribution of stimuli used in the task. Mean stimulus direction was drawn from a discrete uniform distribution (−25°, −20°, −15°,…,25°). In 20% of the trials, <italic>s</italic><sub>vis</sub> ≡ <italic>s</italic><sub>vest</sub> (‘same’ trials, <italic>C</italic> = 1); in the other 80% (‘different’, <italic>C</italic> = 2), disparity was drawn from a discrete uniform distribution (±5°, ±10°, ±20°, ±40°), which led to a correlated pattern of heading directions <italic>s</italic><sub>vis</sub> and <italic>s</italic><sub>vest</sub>. Visual cue reliability <italic>c</italic><sub>vis</sub> was also drawn randomly on each trial (high, medium, and low).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.g001" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec008">
<title>Theory</title>
<p>For each task we built a set of observer models by factorially combining three model components—hence also called model factors—that represent different assumptions about the observers: shape of sensory noise, type of prior over stimuli, and causal inference strategy (<xref ref-type="fig" rid="pcbi.1006110.g002">Fig 2A</xref>).</p>
<fig id="pcbi.1006110.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Observer models.</title>
<p><bold>A</bold>: Observer models consist of three model factors: Causal inference strategy, Shape of sensory noise, and Type of prior over stimuli (see text). <bold>B</bold>: Graphical representation of the observer model. In the left panel (<italic>C</italic> = 1), the visual (<italic>s</italic><sub>vis</sub>) and vestibular (<italic>s</italic><sub>vest</sub>) heading direction have a single, common cause. In the right panel (<italic>C</italic> = 2), <italic>s</italic><sub>vis</sub> and <italic>s</italic><sub>vest</sub> have separate sources, although not necessarily statistically independent. The observer has access to noisy sensory measurements <italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>, and knows the visual reliability level of the trial <italic>c</italic><sub>vis</sub>. The observer is either asked to infer the causal structure (unity judgment, explicit causal inference), or whether the vestibular stimulus is rightward of straight ahead (inertial discrimination, implicit causal inference). Model factors affect different stages of the observer model: the strategy used to combine the two causal scenarios; the type of prior over stimuli <italic>p</italic><sub>prior</sub>(<italic>s</italic><sub>vis</sub>, <italic>s</italic><sub>vest</sub>|<italic>C</italic>); and the shape of sensory noise distributions <italic>p</italic>(<italic>x</italic><sub>vis</sub>|<italic>s</italic><sub>vis</sub>, <italic>c</italic><sub>vis</sub>) and <italic>p</italic>(<italic>x</italic><sub>vest</sub>|<italic>s</italic><sub>vest</sub>) (which affects equally both how noisy measurements are generated and the observer’s beliefs about such noise). <bold>C</bold>: Example decision boundaries for the Bay-X-E model (for the three reliability levels), and for the Fix model, for a representative observer. The observer reports ‘unity’ when the noisy measurements <italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub> fall within the boundaries. Note that the Bayesian decision boundaries expand with larger noise. Nonlinearities are due to the interaction between eccentricity-dependence of the noise and the prior (wiggles are due to the discrete empirical prior).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.g002" xlink:type="simple"/>
</fig>
<p>In each trial of the explicit and implicit causal inference tasks, two stimuli are presented: a visual heading <italic>s</italic><sub>vis</sub> with known reliability <italic>c</italic><sub>vis</sub> ∈ {high, medium, low}, and a vestibular heading <italic>s</italic><sub>vest</sub>. We assume that stimuli <italic>s</italic><sub>vis</sub>, <italic>s</italic><sub>vest</sub> induce noisy measurements <italic>x</italic><sub>vis</sub> (resp., <italic>x</italic><sub>vest</sub>) with conditionally independent distributions <italic>p</italic>(<italic>x</italic><sub>vis</sub>|<italic>s</italic><sub>vis</sub>, <italic>c</italic><sub>vis</sub>) and <italic>p</italic>(<italic>x</italic><sub>vest</sub>|<italic>s</italic><sub>vest</sub>). For any stimulus <italic>s</italic> we assume that the noise distribution is a (wrapped) Gaussian centered on <italic>s</italic> and with variance <italic>σ</italic><sup>2</sup>(<italic>s</italic>). For each observer model we consider a variant in which <italic>σ</italic><sup>2</sup> depends only on the stimulus modality and reliability (<italic>constant</italic>, ‘C’) and a variant in which <italic>σ</italic><sup>2</sup>(<italic>s</italic>) also depends on stimulus location, growing with heading eccentricity, that is with the distance from 0° (<italic>eccentricity-dependent</italic>, ‘X’; see <xref ref-type="sec" rid="sec019">Methods</xref>). With a few notable exceptions [<xref ref-type="bibr" rid="pcbi.1006110.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>], stimulus-dependence in the noise has been generally ignored in previous work [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref027">27</xref>]. The base noise magnitude is governed by model parameters <italic>σ</italic><sub>0vest</sub> and <italic>σ</italic><sub>0vis</sub>(<italic>c</italic><sub>vis</sub>), where the latter is one parameter per visual reliability level. The eccentricity-dependent noise model has additional parameters <italic>w</italic><sub>vest</sub> and <italic>w</italic><sub>vis</sub> which govern the growth of noise with heading eccentricity (see <xref ref-type="sec" rid="sec019">Methods</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref> for details). We assume that the noise distribution equally affects both the generative model and the observer’s decision model, that is, observers have an approximately correct model of their own sensory noise [<xref ref-type="bibr" rid="pcbi.1006110.ref004">4</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref006">6</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref009">9</xref>].</p>
<p>We assume that the observer considers two causal scenarios [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>]: either there is a single common heading direction (<italic>C</italic> = 1) or the two stimuli correspond to distinct headings (<italic>C</italic> = 2) [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>] (<xref ref-type="fig" rid="pcbi.1006110.g002">Fig 2B</xref>). If <italic>C</italic> = 1, the observer believes that the measurements are generated from the same underlying source <italic>s</italic> with prior distribution <italic>p</italic><sub>prior</sub>(<italic>s</italic>). If <italic>C</italic> = 2, stimuli are believed to be distinct, but not necessarily statistically independent, with prior distribution <italic>p</italic><sub>prior</sub>(<italic>s</italic><sub>vis</sub>, <italic>s</italic><sub>vest</sub>). For the type of these priors, we consider an <italic>empirical</italic> (‘E’) observer whose priors correspond to an approximation of the discrete, correlated distribution of stimuli in the task (as per <xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1B</xref>); and an <italic>independent</italic> (‘I’) observer who uses a common and independent uni-dimensional Gaussian prior centered on 0° for the two stimuli.</p>
<p>Parameter <italic>σ</italic><sub>prior</sub> represents the SD of each independent prior (for ‘I’ priors), or of the prior over mean stimulus direction (for ‘E’ priors); whereas Δ<sub>prior</sub> governs the SD of the prior over disparity (‘E’ priors only). See <xref ref-type="sec" rid="sec019">Methods</xref> for details.</p>
<p>We assume that observers are Bayesian in dealing with each causal scenario (<italic>C</italic> = 1 or <italic>C</italic> = 2), but may follow different strategies for weighting and combining information from the two causal hypotheses. Specifically, we consider three families of causal inference strategies. The Bayesian (‘Bay’) strategy computes the posterior probability of each causal scenario Pr(<italic>C</italic>|<italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>, <italic>c</italic><sub>vis</sub>) based on all information available in the trial. The fixed-criterion (‘Fix’) strategy decides based on a fixed threshold of disparity between the noisy visual and vestibular measurements, disregarding reliability and other statistics of the stimuli. Finally, the fusion (‘Fus’) strategy disregards any location information, either always combining cues, or combining them with some probability (depending on whether the task involves implicit or explicit causal inference).</p>
<p>In the explicit causal inference task, the Bayesian (‘Bay’) observer reports a common cause if its posterior probability is greater than 0.5, Pr(<italic>C</italic> = 1|<italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>, <italic>c</italic><sub>vis</sub>) &gt; 0.5. The prior probability of common cause, <italic>p</italic><sub>c</sub> ≡ Pr(<italic>C</italic> = 1), is a free parameter of the model. The fixed-criterion (‘Fix’) observer reports a common cause whenever the two noisy measurements are closer than a fixed distance <italic>κ</italic><sub>c</sub>, that is |<italic>x</italic><sub>vis</sub> − <italic>x</italic><sub>vest</sub>| &lt; <italic>κ</italic><sub>c</sub>, where the criterion <italic>κ</italic><sub>c</sub> is a free parameter that does not depend on stimulus reliability [<xref ref-type="bibr" rid="pcbi.1006110.ref036">36</xref>]. The fixed-criterion decision rule differs fundamentally from the Bayesian one in that it does not take cue reliability and other stimulus statistics into account (although noise will still affect behavior). As an example, <xref ref-type="fig" rid="pcbi.1006110.g002">Fig 2C</xref> shows the decision boundaries for the Bayesian (constant noise, empirical prior) and fixed-criterion rule for a representative observer. Finally, as a variant of the ‘fusion’ strategy we consider an observer that does not perform causal inference at all, but simply reports unity with probability <italic>η</italic>(<italic>c</italic><sub>vis</sub>) regardless of stimulus disparity, where <italic>η</italic><sub>low</sub>, <italic>η</italic><sub>med</sub>, <italic>η</italic><sub>high</sub> are the only parameters of the model (<italic>stochastic fusion</italic>, ‘SFu’). This variant generalizes a trivial ‘forced fusion’ strategy (<italic>η</italic> ≡ 1) that would always report a common cause in the explicit inference.</p>
<p>For the implicit causal inference task, the observer first computes the posterior probability of rightward vestibular motion, Pr(<italic>s</italic><sub>vest</sub> &gt; 0°|<italic>x</italic><sub>vest</sub>, <italic>x</italic><sub>vis</sub>, <italic>c</italic><sub>vis</sub>, <italic>C</italic> = <italic>k</italic>) for the two causal scenarios, <italic>k</italic> = 1, 2. The Bayesian (‘Bay’) observer then reports ‘right’ if the posterior probability of rightward vestibular heading, averaged over the Bayesian posterior over causal structures, is greater than 0.5. The fixed-criterion (‘Fix’) observer reports ‘right’ if Pr(<italic>s</italic><sub>vest</sub> &gt; 0°|<italic>x</italic><sub>vest</sub>, <italic>x</italic><sub>vis</sub>, <italic>c</italic><sub>vis</sub>, <italic>C</italic> = <italic>k</italic><sub>fix</sub>) &gt; 0.5, where <italic>k</italic><sub>fix</sub> = 1 if |<italic>x</italic><sub>vis</sub> − <italic>x</italic><sub>vest</sub>| &lt; <italic>κ</italic><sub>c</sub>, and <italic>k</italic><sub>fix</sub> = 2 otherwise. Finally, for the Fusion strategy we consider here the <italic>forced fusion</italic> (‘FFu’) observer, for which <italic>C</italic> ≡ 1. The forced fusion observer is equivalent to a Bayesian observer with <italic>p</italic><sub>c</sub> ≡ 1, and to a fixed-criterion observer for <italic>κ</italic><sub>c</sub> → ∞.</p>
<p>Observers also performed a unisensory left/right heading discrimination task, in which either a visual or vestibular heading was presented on each trial. In this case observers were modeled as standard Bayesian observers that respond ‘right’ if Pr(<italic>s</italic><sub>vis</sub> &gt; 0°|<italic>x</italic><sub>vis</sub>, <italic>c</italic><sub>vis</sub>) &gt; 0.5 for visual trials, and if Pr(<italic>s</italic><sub>vest</sub> &gt; 0°|<italic>x</italic><sub>vest</sub>) &gt; 0.5 for vestibular trials. These data were used to constrain the joint model fits (see below).</p>
<p>For all observer models and tasks (except stochastic fusion in the explicit task), we considered a lapse probability 0 ≤ λ ≤ 1 of the observer giving a random response. Finally, we note that the Bayesian observer models considered in our main analysis perform Bayesian model averaging (the proper Bayesian strategy). At the end of the Results section we will also consider a ‘probability matching’ suboptimal Bayesian observer [<xref ref-type="bibr" rid="pcbi.1006110.ref024">24</xref>].</p>
</sec>
<sec id="sec009">
<title>Analysis strategy</title>
<p>Our analysis strategy consisted of first examining subjects’ behavior separately in the explicit and implicit tasks via model fitting and comparison. We then compared the model fits across tasks to ensure that model parameters were broadly compatible, allowing us to aggregate data from different tasks without changing the structure of the models. Finally, we re-analyzed observers’ performance by jointly fitting data from all three tasks (explicit causal inference, implicit causal inference, and unisensory heading discrimination), thereby combining all available evidence to characterize subjects’ decision making processes.</p>
<p>Given the large number of models and distinct datasets involved, we coded each model using efficient computational techniques at each step (see <xref ref-type="sec" rid="sec019">Methods</xref> for details).</p>
<p>We fitted our models to the data first via maximum-likelihood estimation, and then via Bayesian estimation of the posterior over parameters using Markov Chain Monte Carlo (MCMC). Posteriors are an improvement over point estimates in that they allow us to incorporate uncertainty over individual subjects’ model parameters in our analysis, and afford computation of more accurate comparison metrics (see below).</p>
<p>We computed for each task, subject, and model the leave-one-out cross-validation score (LOO) directly estimated from the MCMC output [<xref ref-type="bibr" rid="pcbi.1006110.ref052">52</xref>] (reported in <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>). LOO has several advantages over other model selection metrics in that it takes parameter uncertainty into account and provides a more accurate measure of predictive performance [<xref ref-type="bibr" rid="pcbi.1006110.ref053">53</xref>] (see <xref ref-type="sec" rid="sec014">Discussion</xref>). We combined model evidence (LOO scores) from different subjects and models using a hierarchical Bayesian approach for group studies [<xref ref-type="bibr" rid="pcbi.1006110.ref054">54</xref>]. For each model component within the model factors of interest (noise, prior, and causal inference strategy), we reported as the main summary statistic of the analysis the protected exceedence probability <inline-formula id="pcbi.1006110.e002"><alternatives><graphic id="pcbi.1006110.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, that is the (posterior) probability of a model component being the most likely component, above and beyond chance [<xref ref-type="bibr" rid="pcbi.1006110.ref055">55</xref>]. As a test of robustness, we also computed additional model comparison metrics: the corrected Akaike’s information criterion (AICc), the Bayesian information criterion (BIC), and an estimate of the log marginal likelihood (LML). While we prefer LOO as the main metric (see <xref ref-type="sec" rid="sec014">Discussion</xref>), we verified that the results of the model comparison were largely invariant of the choice of comparison metric.</p>
<p>Finally, for each model we estimated the absolute goodness of fit as the fraction of information gain above chance (where 0% is chance and 100% is the estimated intrinsic variability of the data, that is the entropy [<xref ref-type="bibr" rid="pcbi.1006110.ref056">56</xref>]).</p>
</sec>
</sec>
<sec id="sec010">
<title>Explicit causal inference task</title>
<p>We examined how subjects perceived the causal relationship of synchronous visual and vestibular headings as a function of disparity (<italic>s</italic><sub>vest</sub> − <italic>s</italic><sub>vis</sub>, nine levels) and visual reliability level (high, medium, low; <xref ref-type="fig" rid="pcbi.1006110.g003">Fig 3A</xref>). Common cause reports were more frequent near zero disparities than for well-separated stimuli (Repeated-measures ANOVA with Greenhouse-Geisser correction; <italic>F</italic><sub>(1.82,18.17)</sub> = 76.0, <italic>ϵ</italic> = 0.23, <italic>p</italic> &lt; 10<sup>−4</sup>, <inline-formula id="pcbi.1006110.e003"><alternatives><graphic id="pcbi.1006110.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>88</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>). This means that observers neither performed complete integration (always reporting a common cause) nor complete segregation (never reporting a common cause). Common-cause reports were not affected by visual cue reliability alone (<italic>F</italic><sub>(1.23,12.33)</sub> = 1.84, <italic>ϵ</italic> = 0.62, <italic>p</italic> = .2, <inline-formula id="pcbi.1006110.e004"><alternatives><graphic id="pcbi.1006110.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>16</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), but were modulated by an interaction of visual reliability and disparity (<italic>F</italic><sub>(7.44,74.44)</sub> = 7.38, <italic>ϵ</italic> = 0.47, <italic>p</italic> &lt; 10<sup>−4</sup>, <inline-formula id="pcbi.1006110.e005"><alternatives><graphic id="pcbi.1006110.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>42</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>). Thus, observers’ performance was affected by both cue disparity as well as visual cue reliability when explicitly reporting about the causal relationship between visual and vestibular cues. However, this does not necessarily mean that the subjects’ causal inference strategy took visual cue reliability into account. Changes in sensory noise may affect measured behavior even if the observer’s decision rule ignores such changes [<xref ref-type="bibr" rid="pcbi.1006110.ref035">35</xref>]; a quantitative model comparison is needed to probe this question.</p>
<fig id="pcbi.1006110.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Explicit causal inference.</title>
<p>Results of the explicit causal inference (unity judgment) task. <bold>A</bold>: Proportion of ‘unity’ responses, as a function of stimulus disparity (difference between vestibular and visual heading direction), and for different levels of visual cue reliability. Bars are ±1 SEM across subjects. Unity judgments are modulated by stimulus disparity and visual cue reliability. <bold>B</bold>: Protected exceedance probability <inline-formula id="pcbi.1006110.e006"><alternatives><graphic id="pcbi.1006110.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e006" xlink:type="simple"/><mml:math display="inline" id="M6"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and estimated posterior frequency (mean ± SD) of distinct model components for each model factor. Each factor also displays the Bayesian omnibus risk (BOR). <bold>C</bold>: Model fits of several models of interest (see text for details). Shaded areas are ±1 SEM of model predictions across subjects. Numbers on top right of each panel report the absolute goodness of fit.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.g003" xlink:type="simple"/>
</fig>
<p>We compared a subset of models from the full factorial comparison (<xref ref-type="fig" rid="pcbi.1006110.g002">Fig 2A</xref>), since some models are equivalent when restricted to the explicit causal inference task. In particular, here fixed-criterion models are not influenced by the ‘prior’ factor, and the (stochastic) fusion model is not affected by sensory noise or prior, thus reducing the list of models to seven: Bay-C-E, Bay-C-I, Bay-X-E, Bay-X-I, Fix-C, Fix-X, SFu.</p>
<p>To assess the evidence for distinct determinants of subjects’ behavior, we combined LOO scores from individual subjects and models with a hierarchical Bayesian approach [<xref ref-type="bibr" rid="pcbi.1006110.ref054">54</xref>] (<xref ref-type="fig" rid="pcbi.1006110.g003">Fig 3B</xref>). Since we are investigating model factors that comprise of an unequal number of models, we reweighted the prior over models such that distinct components within each model factor had equal prior probability (Fix models had 2× weight, and SFu 4×). In <xref ref-type="fig" rid="pcbi.1006110.g003">Fig 3B</xref> we report the protected exceedance probabilities <inline-formula id="pcbi.1006110.e007"><alternatives><graphic id="pcbi.1006110.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and, for reference, the posterior model frequencies they are based on, and the Bayesian omnibus risk (BOR), which is the estimated probability that the observed differences in factor frequencies may be due to chance [<xref ref-type="bibr" rid="pcbi.1006110.ref055">55</xref>]. We found that the most likely factor of causal inference was the Bayesian model (<inline-formula id="pcbi.1006110.e008"><alternatives><graphic id="pcbi.1006110.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>78</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), followed by fixed-criterion (<inline-formula id="pcbi.1006110.e009"><alternatives><graphic id="pcbi.1006110.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>18</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>) and probabilistic fusion (<inline-formula id="pcbi.1006110.e010"><alternatives><graphic id="pcbi.1006110.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>04</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>). That is, fusion was ∼ 24 times less likely to be the most representative model than any form of causal inference combined, which is strong evidence against fusion, and in agreement with our model-free analysis. The Bayesian strategy was ∼ 3.5 times more likely than the others, which is positive but not strong evidence [<xref ref-type="bibr" rid="pcbi.1006110.ref057">57</xref>]. Conversely, the explicit causal inference data do not allow us to draw conclusions about noise models (constant vs. eccentric) or priors (empirical vs. independent), as we found that all factor components are about equally likely (<inline-formula id="pcbi.1006110.e011"><alternatives><graphic id="pcbi.1006110.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e011" xlink:type="simple"/><mml:math display="inline" id="M11"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>∼</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>).</p>
<p>At the level of specific models—as opposed to aggregate model factors –, we found that the probability of being the most likely model was almost equally divided between fixed-criterion (C-I) and Bayesian (either X-E or C-I). All these models yielded reasonable fits (<xref ref-type="fig" rid="pcbi.1006110.g003">Fig 3C</xref>), which captured a large fraction of the noise in the data (absolute goodness of fit ≈ 76% ± 3%; see <xref ref-type="sec" rid="sec019">Methods</xref>); a large improvement over a constant-probability model, which had a goodness of fit of 14 ± 5%. For comparison, we also show in <xref ref-type="fig" rid="pcbi.1006110.g003">Fig 3C</xref> the stochastic fusion model, which had a goodness of fit of 17 %± 5%. Visually, the Fix model in <xref ref-type="fig" rid="pcbi.1006110.g003">Fig 3C</xref> seems to fit better the group data, but we found that this is an artifact of projecting the data on the disparity axis. Disparity is the only relevant dimension for the Fix model; whereas Bay models fits the data along all dimensions. The visual superiority of the Fix model wanes when the data are visualized in their entirety (see <xref ref-type="supplementary-material" rid="pcbi.1006110.s001">S1 Fig</xref>).</p>
<p>We verified robustness of our findings by performing the same hierarchical analysis with different model comparison metrics. All metrics were in agreement with respect to the Bayesian causal inference strategy as the most likely, and the same three models being most probable (although possibly with different ranking). BIC and marginal likelihood differed from LOO and AICc mainly in that they reported a larger probability for the constant vs. eccentricity-dependent noise (probability ratio ∼4.6, which is positive but not strong evidence).</p>
<p>These results combined provide strong evidence that subjects in the explicit causal inference task took into account some elements of the statistical structure of the trial (disparity, and possibly cue reliability) to report unity judgments, consistent with causal inference, potentially in a Bayesian manner. From these data, it is unclear whether observers took into account the empirical distribution of stimuli, and whether their behavior was affected by eccentricity-dependence in the sensory noise.</p>
</sec>
<sec id="sec011">
<title>Implicit causal inference task</title>
<p>We examined the bias in the reported direction of inertial heading computed as (minus) the point of subjective equality for left/rightward heading choices (L/R PSE), for each visual heading and visual cue reliability (<xref ref-type="fig" rid="pcbi.1006110.g004">Fig 4A</xref>). Specifically, for a given value of visual heading <italic>s</italic><sub>vis</sub> (or small range thereof), we constructed a psychometric function as a function of <italic>s</italic><sub>vest</sub> (see <xref ref-type="sec" rid="sec019">Methods</xref> for details). If subjects were influenced by <italic>s</italic><sub>vis</sub> and took visual heading into account while computing inertial heading, this would manifest as bias in the psychometric function (that is, a shifted point of subjective equality). If subjects were able instead to discount the distracting influence of <italic>s</italic><sub>vis</sub>, there should be negligible bias. As per causal inference, we qualitatively expected that there would be bias for smaller |<italic>s</italic><sub>vis</sub>|, but the bias would either decrease or saturate as |<italic>s</italic><sub>vis</sub>| increases. However, note that a nonlinear pattern of bias may also emerge due to eccentricity-dependence of the noise, even in the absence of causal inference.</p>
<fig id="pcbi.1006110.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Implicit causal inference.</title>
<p>Results of the implicit causal inference (left/right inertial discrimination) task. <bold>A</bold>: Vestibular bias as a function of co-presented visual heading direction <italic>s</italic><sub>vis</sub>, at different levels of visual reliability. Bars are ±1 SEM across subjects. The inset shows a cartoon of how the vestibular bias is computed as minus the point of subjective equality of the psychometric curves of left/right responses (L/R PSE) for vestibular stimuli <italic>s</italic><sub>vest</sub>, for a representative subject and for a fixed value of <italic>s</italic><sub>vis</sub>. The vestibular bias is strongly modulated by <italic>s</italic><sub>vis</sub> and its reliability. <bold>B</bold>: Protected exceedance probability <inline-formula id="pcbi.1006110.e012"><alternatives><graphic id="pcbi.1006110.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e012" xlink:type="simple"/><mml:math display="inline" id="M12"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and estimated posterior frequency (mean ± SD) of distinct model components for each model factor. Each factor also displays the Bayesian omnibus risk (BOR). <bold>C</bold>: Model fits of several models of interests (see text for details). Shaded areas are ±1 SEM of model predictions across subjects. Numbers on top right of each panel report the absolute goodness of fit.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.g004" xlink:type="simple"/>
</fig>
<p>The bias was significantly affected by visual heading (Repeated-measures ANOVA; <italic>F</italic><sub>(0.71,7.08)</sub> = 19.67, <italic>ϵ</italic> = 0.07, <italic>p</italic> = .004, <inline-formula id="pcbi.1006110.e013"><alternatives><graphic id="pcbi.1006110.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>66</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>). We found no main effect of visual cue reliability alone (<italic>F</italic><sub>(0.85,8.54)</sub> = 0.51, <italic>ϵ</italic> = 0.43, <italic>p</italic> = .47, <inline-formula id="pcbi.1006110.e014"><alternatives><graphic id="pcbi.1006110.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), but there was a significant interaction of visual cue reliability and heading (<italic>F</italic><sub>(2.93,29.26)</sub> = 7.36, <italic>ϵ</italic> = 0.15, <italic>p</italic> &lt; 10<sup>−3</sup>, <inline-formula id="pcbi.1006110.e015"><alternatives><graphic id="pcbi.1006110.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e015" xlink:type="simple"/><mml:math display="inline" id="M15"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>42</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>). These data suggest that subjects’ perception of vestibular headings was modulated by visual cue reliability and visual stimulus, in agreement with previous work in visual-auditory localization [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>]. However, quantitative model comparison is required to understand the mechanism in detail since distinct processes, such as different causal inference strategies and noise models, could lead to similar patterns of observed behavior.</p>
<p>We performed a factorial comparison with all models in <xref ref-type="fig" rid="pcbi.1006110.g002">Fig 2A</xref>. In this case, factorial model comparison via LOO was unable to uniquely identify the causal inference strategy adopted by observers (<xref ref-type="fig" rid="pcbi.1006110.g004">Fig 4B</xref>). Forced fusion was slightly favored (<inline-formula id="pcbi.1006110.e016"><alternatives><graphic id="pcbi.1006110.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e016" xlink:type="simple"/><mml:math display="inline" id="M16"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>∼</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>48</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), followed by Bayes (<inline-formula id="pcbi.1006110.e017"><alternatives><graphic id="pcbi.1006110.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>∼</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>27</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>) and fixed-criterion (<inline-formula id="pcbi.1006110.e018"><alternatives><graphic id="pcbi.1006110.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e018" xlink:type="simple"/><mml:math display="inline" id="M18"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>∼</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>25</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), suggesting that all strategies were similar to forced fusion. Conversely, eccentricity-dependent noise was found to be more likely than constant noise (ratio ∼ 5.7), which is positive but not strong evidence, and empirical priors were marginally more likely than independent priors (∼ 2.1). The estimated Bayesian omnibus risk was high (BOR ≥ 0.29), hinting at a large degree of similarity within all model factors such that observed differences could have arisen by chance.</p>
<p>All metrics generally agreed on the lack of evidence in favor of any specific inference strategy (with AICc and BIC tending to marginally favor fixed-criterion instead of fusion), and on empirical priors being more likely. As a notable difference, marginal likelihood and BIC reversed the result about noise models, favoring constant noise models over eccentricity-dependent ones.</p>
<p>In terms of individual models, the most likely models according to LOO were, in order, forced fusion (X-E), Bayesian (X-E), and fixed-criterion (C-E). However, other metrics also favored other models; for example, Bayesian (C-E) was most likely according to the marginal likelihood. All these models obtained similarly good fits to individual data (<xref ref-type="fig" rid="pcbi.1006110.g004">Fig 4C</xref>; absolute goodness of fit ≈ 97%). For reference, a model that responds ‘rightward motion’ with constant probability performed about at chance (goodness of fit ≈ 0.3 ± 0.1%).</p>
<p>In sum, our analysis shows that the implicit causal inference data alone are largely inconclusive, possibly because almost all models behave similarly to forced fusion. To further explore our results, we examined the posterior distribution of the prior probability of common cause parameter <italic>p</italic><sub>c</sub> across Bayesian models, and of the criterion <italic>κ</italic><sub>c</sub> for fixed-criterion models (<xref ref-type="fig" rid="pcbi.1006110.g005">Fig 5</xref>, bottom left panels). In both cases we found a broad distribution of parameters, with only a mild accumulation towards ‘forced fusion’ values (<italic>p</italic><sub>c</sub> = 1 or <inline-formula id="pcbi.1006110.e019"><alternatives><graphic id="pcbi.1006110.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:mrow><mml:msub><mml:mi>κ</mml:mi> <mml:mtext>c</mml:mtext></mml:msub> <mml:mo>≳</mml:mo> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>), suggesting that subjects were not completely performing forced fusion. Thus, it is possible that by constraining the inference with additional data we would be able to draw more defined conclusions.</p>
<fig id="pcbi.1006110.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Posteriors over model parameters.</title>
<p>Each panel shows the marginal posterior distributions over a single parameter for each subject and task. Each line is an individual subject’s posterior (thick line: interquartile range; light line: 95% credible interval); different colors correspond to different tasks. For each subject and task, posteriors are marginalized over models according to their posterior probability (see <xref ref-type="sec" rid="sec019">Methods</xref>). For each parameter we report the across-tasks compatibility probability <italic>C</italic><sub><italic>p</italic></sub>, that is the (posterior) probability that subjects were best described by the assumption that parameter values were the same across separate tasks, above and beyond chance. The first two rows of parameters compute compatibility across all three tasks, whereas in the last row compatibility only includes the bisensory tasks (bisensory inertial discrimination and unity judgment), as these parameters are irrelevant for the unisensory task.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.g005" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec012">
<title>Joint model fits</title>
<p>Data from the explicit and implicit causal inference tasks, when analyzed separately, afforded only weak conclusions about subjects’ behavior. The natural next step is to combine datasets from the two tasks along with the data from the unisensory heading discrimination task in order to better constrain the model fits.</p>
<p>Before performing such joint fit, we verified whether there was evidence that model parameters changed substantially across tasks, in which case we might have had to change the structure of the models (e.g., by introducing a subset of distinct parameters for different tasks [<xref ref-type="bibr" rid="pcbi.1006110.ref049">49</xref>]). For each model parameter, we computed the across-tasks compatibility probability <italic>C</italic><sub><italic>p</italic></sub> (<xref ref-type="fig" rid="pcbi.1006110.g005">Fig 5</xref>), which is the (posterior) probability that subjects were most likely to have the same parameter values across tasks, as opposed to different parameters, above and beyond chance (see <xref ref-type="sec" rid="sec019">Methods</xref> for details). We found at most mild evidence towards difference of parameters across the three tasks, but no strong evidence (all <italic>C</italic><sub><italic>p</italic></sub> &gt; .05). Therefore, we proceeded in jointly fitting the data with the default assumption that parameters were shared across tasks.</p>
<p>For the joint fits there are nine possible models for the causal inference strategy (three explicit causal inference × three implicit causal inference strategies). However, we considered only a subset of plausible combinations, to avoid ‘model overfitting’ (see <xref ref-type="sec" rid="sec014">Discussion</xref>). First, we disregarded the stochastic fusion strategy for the explicit task, since this strategy was strongly rejected by the explicit task data alone. Second, if subjects performed some form of causal inference (Bayesian or fixed-criterion) in both tasks, we forced it to be the same. This reduces the model space for the causal inference strategy to four components: Bay/Bay, Fix/Fix, Bay/FFu, Fix/FFu (explicit/implicit task). Combined with the prior and sensory noise factors as per <xref ref-type="fig" rid="pcbi.1006110.g002">Fig 2A</xref>, this leads to sixteen models.</p>
<p>Factorial model comparison via LOO found that the most likely causal inference strategy was fixed-criterion (<inline-formula id="pcbi.1006110.e020"><alternatives><graphic id="pcbi.1006110.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e020" xlink:type="simple"/><mml:math display="inline" id="M20"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>79</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), followed by Bayesian (<inline-formula id="pcbi.1006110.e021"><alternatives><graphic id="pcbi.1006110.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e021" xlink:type="simple"/><mml:math display="inline" id="M21"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>13</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>), and then by forced fusion in the implicit task (<inline-formula id="pcbi.1006110.e022"><alternatives><graphic id="pcbi.1006110.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e022" xlink:type="simple"/><mml:math display="inline" id="M22"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>05</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> paired with Bayesian explicit causal inference, <inline-formula id="pcbi.1006110.e023"><alternatives><graphic id="pcbi.1006110.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e023" xlink:type="simple"/><mml:math display="inline" id="M23"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>03</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> paired with fixed-criterion explicit causal inference; <xref ref-type="fig" rid="pcbi.1006110.g006">Fig 6A</xref>). This is positive evidence that subjects were performing some form of causal inference also in the implicit task, as opposed to mere forced fusion (ratio ∼ 11.4). Moreover, we found strong evidence for eccentricity-dependent over constant noise (<inline-formula id="pcbi.1006110.e024"><alternatives><graphic id="pcbi.1006110.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>99</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, ratio ∼ 132.7). Instead, the joint data were still inconclusive about the prior adopted by the subjects, with only marginal evidence for the empirical prior over the independent prior (∼ 2.9).</p>
<fig id="pcbi.1006110.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Joint fits.</title>
<p>Results of the joint fits across tasks. <bold>A</bold>: Protected exceedance probability <inline-formula id="pcbi.1006110.e025"><alternatives><graphic id="pcbi.1006110.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e025" xlink:type="simple"/><mml:math display="inline" id="M25"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> and estimated posterior frequency (mean ± SD) of distinct model components for each model factor. Each factor also displays the Bayesian omnibus risk (BOR). <bold>B</bold>: Joint model fits of the explicit causal inference (unity judgment) task, for different models of interest. Each panel shows the proportion of ‘unity’ responses, as a function of stimulus disparity and for different levels of visual reliability. Bars are ±1 SEM of data across subjects. Shaded areas are ±1 SEM of model predictions across subjects. Numbers on top right of each panel report the absolute goodness of fit across all tasks. <bold>C</bold>: Joint model fits of the implicit causal inference task, for the same models of panel B. Panels show vestibular bias as a function of co-presented visual heading direction <italic>s</italic><sub>vis</sub>, and for different levels of visual reliability. Bars are ±1 SEM of data across subjects. Shaded areas are ±1 SEM of model predictions across subjects.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.g006" xlink:type="simple"/>
</fig>
<p>In terms of specific models, the most likely model was fixed-criterion (X-E), followed by Bayesian (X-E), and explicit Bayesian / implicit forced fusion (both X-I and X-E). The best models gave a good description of the individual joint data, with an absolute goodness of fit of ≈ 91% ± 1% (<xref ref-type="fig" rid="pcbi.1006110.g006">Fig 6B</xref>).</p>
<p>Examination of the subjects’ posteriors over parameters for the joint fits (<xref ref-type="table" rid="pcbi.1006110.t002">Table 2</xref> and <xref ref-type="fig" rid="pcbi.1006110.g005">Fig 5</xref>, black lines) showed reasonable results. The base visual noise parameters were generally monotonically increasing with decreasing visual cue reliability; the vestibular base noise was roughly of the same magnitude as the medium visual cue noise (as per experiment design); both visual and vestibular noise increased mildly with the distance from straight ahead; subjects had a small lapse probability. For Bayesian models, <italic>p</italic><sub>c</sub> was substantially larger than the true value, 0.20 (<italic>t</italic>-test <italic>t</italic><sub>(10)</sub> = 10.8, <italic>p</italic> &lt; 10<sup>−4</sup>, <italic>d</italic> = 3.25), suggesting that observers generally thought that heading directions had a higher a priori chance to be the same. Nonetheless, for all but one subject <italic>p</italic><sub>c</sub> was far from 1, suggesting that subjects were not performing forced fusion either. An analogous result holds for the fixed criterion <italic>κ</italic><sub>c</sub>, which was smaller than the largest disparity between heading directions. We found that prior parameters <italic>σ</italic><sub>prior</sub> and Δ<sub>prior</sub> had a lesser impact on the models, and their exact values were less crucial, with generally wide posteriors.</p>
<table-wrap id="pcbi.1006110.t002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.t002</object-id>
<label>Table 2</label>
<caption>
<title>Joint fit parameters.</title>
</caption>
<alternatives>
<graphic id="pcbi.1006110.t002g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.t002" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">Parameter</th>
<th align="left" style="border-bottom:thick">Description</th>
<th align="center" style="border-bottom:thick">Posterior mean</th>
<th align="center" style="border-bottom:thick">Allowed range</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">All tasks</td>
<td align="left"/>
<td align="center"/>
<td align="center"/>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub>0</sub><sub>vest</sub></td>
<td align="left">Vestibular base noise</td>
<td align="center">6.49° ± 0.90°</td>
<td align="center">[0.5°, 80°]<xref ref-type="table-fn" rid="t002fn002">†</xref></td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub>0</sub><sub>vis</sub>(<italic>c</italic><sub>high</sub>)</td>
<td align="left">Visual base noise (high coherence)</td>
<td align="center">4.08° ± 0.54°</td>
<td align="center">[0.5°, 80°]<xref ref-type="table-fn" rid="t002fn002">†</xref></td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub>0</sub><sub>vis</sub>(<italic>c</italic><sub>med</sub>)</td>
<td align="left">Visual base noise (medium coherence)</td>
<td align="center">6.32° ± 1.00°</td>
<td align="center">[0.5°, 80°]<xref ref-type="table-fn" rid="t002fn002">†</xref></td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub>0</sub><sub>vis</sub>(<italic>c</italic><sub>low</sub>)</td>
<td align="left">Visual base noise (low coherence)</td>
<td align="center">11.57° ± 2.67°</td>
<td align="center">[0.5°, 80°]<xref ref-type="table-fn" rid="t002fn002">†</xref></td>
</tr>
<tr>
<td align="left"><italic>w</italic><sub>vest</sub></td>
<td align="left">Vestibular noise eccentricity</td>
<td align="center">0.04 ± 0.01</td>
<td align="center">[0, 1]</td>
</tr>
<tr>
<td align="left"><italic>w</italic><sub>vis</sub></td>
<td align="left">Visual noise eccentricity</td>
<td align="center">0.07 ± 0.02</td>
<td align="center">[0, 1]</td>
</tr>
<tr>
<td align="left">λ</td>
<td align="left">Lapse rate</td>
<td align="center">0.01 ± 0.01</td>
<td align="center">[0, 1]</td>
</tr>
<tr>
<td align="left">Bisensory only</td>
<td align="left"/>
<td align="center"/>
<td align="center"/>
</tr>
<tr>
<td align="left"><italic>p</italic><sub>c</sub></td>
<td align="left">Prior of common cause (Bay models)</td>
<td align="center">0.56 ± 0.05</td>
<td align="center">[0, 1]</td>
</tr>
<tr>
<td align="left"><italic>κ</italic><sub>c</sub></td>
<td align="left">Fixed criterion (Fix models)</td>
<td align="center">26.50° ± 3.52°</td>
<td align="center">[0.25°, 180°]<xref ref-type="table-fn" rid="t002fn002">†</xref></td>
</tr>
<tr>
<td align="left"><italic>σ</italic><sub>prior</sub></td>
<td align="left">Central prior width</td>
<td align="center">49.77° ± 12.08°</td>
<td align="center">[1°, 120°]<xref ref-type="table-fn" rid="t002fn002">†</xref></td>
</tr>
<tr>
<td align="left">Δ<sub>prior</sub></td>
<td align="left">Disparity prior width</td>
<td align="center">23.51° ± 6.39°</td>
<td align="center">[1°, 120°]<xref ref-type="table-fn" rid="t002fn002">†</xref></td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t002fn001"><p>Posterior means of parameters in the joint fit, marginalized over models according to each subject’s posterior model probability, and averaged across subjects (± SEM). For reference, we also report the parameter range used for the optimization and MCMC sampling.</p></fn>
<fn id="t002fn002"><p><sup>†</sup> These parameters were transformed and fitted in log space.</p></fn>
</table-wrap-foot>
</table-wrap>
<p>Finally, we verified that our results did not depend on the chosen comparison metric. Remarkably, the findings regarding causal inference factors were quantitatively the same for all metrics, demonstrating robustness of our main result. Marginal likelihood and BIC differed from LOO and AICc in that they only marginally favored eccentricity-dependent noise models, showing that conclusions over the noise model may depend on the specific choice of metric. All metrics agreed in marginally preferring the empirical prior over the independent prior.</p>
<p>In conclusion, when combining evidence from all available data, our model comparison shows that subjects were most likely performing some form of causal inference instead of forced fusion, for both the explicit and the implicit causal inference tasks. In particular, we find that a fixed-criterion, non-probabilistic decision rule (i.e., one that does not take uncertainty into account) describes the joint data better than the Bayesian strategy, although with some caveats (see <xref ref-type="sec" rid="sec014">Discussion</xref>).</p>
</sec>
<sec id="sec013">
<title>Sensitivity analysis and model validation</title>
<p>Performing a factorial comparison, like any other statistical analysis, requires a number of somewhat arbitrary choices, loosely motivated by previous studies, theoretical considerations, or a preliminary investigation of the data (being aware of the ‘garden of forking paths’ [<xref ref-type="bibr" rid="pcbi.1006110.ref058">58</xref>]). As good practice, we want to check that our main findings are robust to changes in the setup of the analysis, or be able to report discrepancies.</p>
<p>We take as our main result the protected exceedance probabilties <inline-formula id="pcbi.1006110.e026"><alternatives><graphic id="pcbi.1006110.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e026" xlink:type="simple"/><mml:math display="inline" id="M26"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> of the model factors in the joint analysis (<xref ref-type="fig" rid="pcbi.1006110.g006">Fig 6A</xref>, reproduced in <xref ref-type="fig" rid="pcbi.1006110.g007">Fig 7</xref>, top row). In the following, we examine whether this finding holds up to several manipulations of the analysis framework.</p>
<fig id="pcbi.1006110.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Sensitivity analysis of factorial model comparison.</title>
<p>Protected exceedance probability <inline-formula id="pcbi.1006110.e027"><alternatives><graphic id="pcbi.1006110.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e027" xlink:type="simple"/><mml:math display="inline" id="M27"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> of distinct model components for each model factor in the joint fits. Each panel also shows the estimated posterior frequency (mean ± SD) of distinct model components, and the Bayesian omnibus risk (BOR). Each row represents a variant of the factorial comparison. 1st row: Main analysis (as per <xref ref-type="fig" rid="pcbi.1006110.g006">Fig 6A</xref>). 2nd row: Uses marginal likelihood as model comparison metric. 3rd row: Uses hyperprior <italic>α</italic><sub>0</sub> = 1 for the frequencies over models in the population (instead of a flat prior over model factors). 4th row: Uses ‘probability matching’ strategy for the Bayesian causal inference model (replacing model averaging). 5th row: Includes probability matching as a sub-factor of the Bayesian causal inference family (in addition to model averaging).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.g007" xlink:type="simple"/>
</fig>
<p>A first check consists of testing different model comparison metrics. In the previous sections, we have reported results for different metrics, finding in general only minor differences from our results obtained with LOO. As an example, we show here the model comparison using as metric an estimate of the marginal likelihood—the probability of the data under the model (<xref ref-type="fig" rid="pcbi.1006110.g007">Fig 7</xref>, 2nd row). We see that the marginal likelihood results agree with our results with LOO except for the sensory noise factor (see <xref ref-type="sec" rid="sec014">Discussion</xref>). Therefore, our conclusions about the causal inference strategy are not affected.</p>
<p>Second, the hierarchical Bayesian Model Selection method requires to specify a prior over frequencies of models in the population [<xref ref-type="bibr" rid="pcbi.1006110.ref054">54</xref>]. This (hyper)prior is specified via the concentration parameter vector <bold><italic>α</italic></bold><sub>0</sub> of a Dirichlet distribution over model frequencies. For our analysis, since we focused on the factorial aspect, we chose an approximately ‘flat’ prior across model factors (see <xref ref-type="sec" rid="sec019">Methods</xref> for details), instead of the default flat prior over individual models (<italic>α</italic><sub>0</sub> = 1). We found that performing the group analysis with <italic>α</italic><sub>0</sub> = 1 did not change our results (<xref ref-type="fig" rid="pcbi.1006110.g007">Fig 7</xref>, 3rd row).</p>
<p>Another potential source of variation is specific model choices, or inclusion of model factors. For example, a common successful variant of the Bayesian causal inference strategy is ‘probability matching’, according to which the observer chooses the causal scenario (<italic>C</italic> = 1 or <italic>C</italic> = 2) randomly, proportionally to its posterior probability [<xref ref-type="bibr" rid="pcbi.1006110.ref024">24</xref>]. As a first check, we performed the model comparison again using a ‘probability matching’ Bayesian observer <italic>instead</italic> of our main ‘model averaging’ observer (<xref ref-type="fig" rid="pcbi.1006110.g007">Fig 7</xref>, 4th row). Results are similar to the main analysis. If anything, the fixed-criterion causal inference strategy gains additional evidence here, suggesting that probability matching is a worse description of the data than our original Bayesian causal inference model (as confirmed by looking at differences in LOO scores of individual subjects, e.g. for the Bay-X-E model; mean ± SEM: ΔLOO = −17.3 ± 5.7). A recent study in audio-visual causal inference perception has similarly found that probability matching provided a poor explanation of the data [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>].</p>
<p>In the factorial framework we could also have performed the previous analysis in a different way, by considering ‘probability matching’ as a sub-factor of the Bayesian strategy, <italic>together</italic> with ‘model averaging’. As we have done before for the explicit causal inference task, we reassign prior probabilities to the models so that they are constant for each factor (in this case, the two Bayesian strategies get a <inline-formula id="pcbi.1006110.e028"><alternatives><graphic id="pcbi.1006110.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e028" xlink:type="simple"/><mml:math display="inline" id="M28"><mml:mrow><mml:mo>×</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:math></alternatives></inline-formula> multiplier). Results of this alternative approach show an increase of evidence for the Bayesian causal inference family (<xref ref-type="fig" rid="pcbi.1006110.g007">Fig 7</xref>, bottom row). The values of <inline-formula id="pcbi.1006110.e029"><alternatives><graphic id="pcbi.1006110.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e029" xlink:type="simple"/><mml:math display="inline" id="M29"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula> for the fusion models are also slightly higher, which is due to an increase of the Bayesian omnibus risk (the probability that the observed differences in factor frequencies are due to chance, a warning sign that there are too many models for the available data). This result and other lines of reasoning suggest caution when model factors contain an uneven number of models (see <xref ref-type="sec" rid="sec014">Discussion</xref>). Nonetheless, the main conclusion does not qualitatively change, in that observers performed some form of causal inference as opposed to forced fusion.</p>
<p>Finally, we performed several sanity checks, including a model recovery analysis to ensure the integrity of our analysis pipeline and that models of interest were meaningfully distinguishable (see <xref ref-type="sec" rid="sec019">Methods</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref> for details).</p>
<p>In conclusion, we have shown how the computational framework of Bayesian factorial model comparison, which is made possible by a combination of methods described in the cookbook, allows to explore multiple questions about aspects of subjects’ behavior in multisensory perception, and to account for uncertainty at different levels of the analysis in a principled, robust manner.</p>
</sec>
</sec>
<sec id="sec014" sec-type="conclusions">
<title>Discussion</title>
<p>We presented a ‘cookbook’ of algorithmic recipes for robust Bayesian evaluation of observer models of causal inference that have widespread applications to multisensory perception and modeling perceptual behavior in general. We applied these techniques to investigate the decision strategies that characterize explicit and implicit causal inference in multisensory heading perception. Examination of observers’ behavior in the explicit and implicit causal inference tasks provided evidence that observers did not simply fuse visual and vestibular cues. Instead, observers integrated the multisensory cues based on their relative disparity, a signature of causal inference. Importantly, our framework affords investigation of whether humans adopt a statistically optimal Bayesian strategy or instead implement a heuristic decision rule which does not fully consider the uncertainty associated with the stimuli.</p>
<sec id="sec015">
<title>Causal inference in multisensory heading perception</title>
<p>Our findings in the explicit causal inference task demonstrate that subjects used information about the discrepancy between the visual and vestibular cues to infer the causal relationship between them. Results in the implicit causal inference task alone were mixed, in that we could not clearly distinguish between alternative strategies, including forced fusion—in agreement with a previous finding [<xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>]. However, when we combined evidence from all tasks, we found that some form of causal inference was more likely than mere forced fusion, in agreement with a more recent study [<xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>]. Our findings suggest that multiple sources of evidence (e.g., different tasks) can help disambiguate causal inference strategies which might otherwise produce similar patterns of behavioral responses.</p>
<p>Our Bayesian analysis allowed us to examine the distribution of model parameters, in particular the causal inference parameters <italic>p</italic><sub>c</sub> and <italic>κ</italic><sub>c</sub>, which govern the tendency to bind or separate cues for, respectively, a Bayesian and a heuristic fixed-criterion strategy. Evidence from all tasks strongly constrained these parameters for each subject. Interestingly, for the Bayesian models we found an average <italic>p</italic><sub>c</sub> much higher than the true experimental value (inferred <italic>p</italic><sub>c</sub> ∼ 0.5 vs. experimental <italic>p</italic><sub>c</sub> = 0.2). This suggests that subjects had a tendency to integrate sensory cues substantially more than what the statistics of the task would require. Note that, instead, a Bayesian observer would be able to learn the correct value of <italic>p</italic><sub>c</sub> from noisy observations, provided some knowledge of the structure of the task. Our finding is in agreement with previous studies which demonstrated an increased tendency to combine discrepant visual and vestibular cues [<xref ref-type="bibr" rid="pcbi.1006110.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref043">43</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref059">59</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref060">60</xref>] and also a large inter-subject variability in <italic>p</italic><sub>c</sub>, and not obviously related to the statistics of the task [<xref ref-type="bibr" rid="pcbi.1006110.ref023">23</xref>]. We note that, in all studies so far, the ‘binding tendency’ (<italic>p</italic><sub>c</sub> or <italic>κ</italic><sub>c</sub>) is a descriptive parameter of causal inference models that lacks an independent empirical correlate (as opposed to, for example, noise parameters, which can be independently measured). Understanding the origin of the binding tendency, and which experimental manipulations it is sensitive to, is venue for future work [<xref ref-type="bibr" rid="pcbi.1006110.ref023">23</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref061">61</xref>]. For example, de Winkel and colleagues found that the binding tendency depends on the duration of the motion stimuli; decreasing for motions of longer duration [<xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>].</p>
<p>Previous work has performed a factorial comparison of only causal inference strategies [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>]. Our analysis extends that work by including as latent factors the shape of sensory noise (and, thus, likelihoods) and type of priors [<xref ref-type="bibr" rid="pcbi.1006110.ref048">48</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref049">49</xref>]. Models in our set include a full computation of the observers’ posterior beliefs based on eccentricity-dependent likelihoods, which was only approximated in previous studies that considered eccentricity-dependence [<xref ref-type="bibr" rid="pcbi.1006110.ref022">22</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref034">34</xref>]. Indeed, in agreement with a recent finding, we found an important role of eccentricity-dependent noise [<xref ref-type="bibr" rid="pcbi.1006110.ref022">22</xref>]. Conversely, our analysis of priors was inconclusive, as our datasets were unable to tell whether people learnt the empirical (correlated) prior, or made an assumption of independence.</p>
<p>Our main finding, relative to the causal inference strategy, is that subjects performed causal inference both in the explicit and implicit tasks. Interestingly, from our analyses the most likely causal inference strategy is a fixed-criterion strategy, which crucially differs from the Bayesian strategy in that it does not take cue reliability into account—let alone optimally. This finding is seemingly at odds with a long list of results in multisensory perception, in which people are shown to take cue uncertainty into account [<xref ref-type="bibr" rid="pcbi.1006110.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref010">10</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref042">42</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref062">62</xref>]. We note that this is not necessarily in contrast with existing literature, for several reasons. First, this result pertains specifically to the causal inference part of the observer model, and not how cues are combined once a common cause has been inferred [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>]. To our knowledge, no study of multisensory perception has tested Bayesian models of causal inference against heuristic models that take into account disparity but not reliability, as it has been done for example in visual search [<xref ref-type="bibr" rid="pcbi.1006110.ref056">56</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref063">63</xref>] and visual categorization [<xref ref-type="bibr" rid="pcbi.1006110.ref036">36</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref064">64</xref>]. A quantitative modeling approach is needed—qualitatively analyzing the differences in behavior at different levels of reliability is not sufficient to establish that observers take uncertainty into account; patterns of observed differences may be due to a change in sensory noise even if the observer’s decision rule disregards cue reliability. Second, our results are not definitive—the evidence for fixed-criterion vs. Bayesian is positive but not decisive. Our interpretation of this result is that subjects are following some suboptimal decision rule which happens to be closer to fixed-criterion than to the Bayesian strategy for the presented stimuli and range of tested reliability levels. It is possible that with a wider range of stimuli and reliabilities, and possibly with different ways of reporting (e.g., estimation instead of discrimination), we would be able to distinguish the Bayesian strategy from a fixed-criterion heuristic.</p>
<p>Finally, we note that model predictions of our Bayesian models are good but still show systematic discrepancies from the data for the explicit causal inference task (Figs <xref ref-type="fig" rid="pcbi.1006110.g003">3C</xref> and <xref ref-type="fig" rid="pcbi.1006110.g006">6B</xref>). Previous work has found similar discrepancies in model fits of unity judgments data across multiple sensory reliabilities (e.g., see Fig 2A in [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>]). This suggests that there is some element of model mismatch in current Bayesian causal inference models, possibly due to difference in noise models or to other processes that affect causal inference across cue reliabilities, which deserves further investigation.</p>
</sec>
<sec id="sec016">
<title>Bayesian factorial comparison</title>
<p>We performed our analysis within a factorial model comparison framework [<xref ref-type="bibr" rid="pcbi.1006110.ref050">50</xref>]. Even though we were mainly interested in a single factor (causal inference strategy), previous work has shown that the inferred observer’s decision strategy might depend on other aspects of the observer model, such as sensory noise or prior, due to nontrivial interactions of all these model components [<xref ref-type="bibr" rid="pcbi.1006110.ref037">37</xref>]. Our method, therefore, consisted of performing inference across a family of observer models that explicitly instantiated plausible model variants. We then marginalized over details of specific observer models, looking at posterior probabilities of model factors, according to a hierarchical Bayesian Model Selection approach [<xref ref-type="bibr" rid="pcbi.1006110.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref055">55</xref>]. We applied a few tweaks to the Bayesian Model Selection method to account for our focus on factors as opposed to individual models (see <xref ref-type="sec" rid="sec019">Methods</xref>).</p>
<p>Our approach was fully Bayesian in that we took into account parameter uncertainty (by computing a metric, LOO, based on the full posterior distribution) and model uncertainty (by marginalizing over model components). A fully Bayesian approach has the advantages of explicitly representing uncertainty in the results (e.g., credible intervals over parameters), and of reducing the risk of overfitting, although it is not immune to it [<xref ref-type="bibr" rid="pcbi.1006110.ref065">65</xref>].</p>
<p>In our case, we marginalized over models to reduce the risk of model overfitting, which is a complementary problem to parameter overfitting. Model overfitting is likely to happen when model selection is performed within a large number of discrete models. In fact, some authors recommend to skip discrete model selection altogether, preferring instead inference and Bayesian parameter estimation in a single overarching or ‘complete’ model [<xref ref-type="bibr" rid="pcbi.1006110.ref066">66</xref>]. We additionally tried to reduce the risk of model overfitting by balancing prior probabilities across factors, although we noted that this may not be enough to counterbalance the additional flexibility that a model factor gains by having more sub-models than a competitor. Our practical recommendation, until more sophisticated comparison methods are available, is to ensure that all model components within a factor have the same number of models, and to limit the overall number of models.</p>
<p>Our approach was also factorial in the treatment of different tasks, in that first we analyzed each bisensory task in isolation, and then combined trials from all data in a joint fit. The fully Bayesian approach allowed us to compute posterior distributions for the parameters, marginalized over models (see <xref ref-type="fig" rid="pcbi.1006110.g005">Fig 5</xref>), which in turn made it possible to test whether model parameters were compatibile across tasks, via the ‘compatibility probability’ metric. The compatibility probability is an approximation of a full model comparison to test whether a given parameter is the same or should differ across different datasets (in this case, tasks), where we consider ‘sameness’ to be the default (simplyfing) hypothesis. We note that if the identity or not of a parameter across datasets is a main question of the study, its resolution should be addressed via a proper model comparison.</p>
<p>With the joint fits, we found that almost all parameters were well constrained by the data (except possibly for the parameters governing the observers’ priors, <italic>σ</italic><sub>prior</sub> and Δ<sub>prior</sub>). An alternative option to better constrain the inference for scarce data or poorly identified parameters is to use informative priors (as opposed to non-informative priors), or a hierarchical approach that assumes a common (hyper)prior to model parameters across subjects [<xref ref-type="bibr" rid="pcbi.1006110.ref067">67</xref>].</p>
</sec>
<sec id="sec017">
<title>Model comparison metrics</title>
<p>The general goal of a model comparison metric is to score a model for goodness of fit and somehow penalize for model flexibility. In our analysis we have used Pareto-smoothed importance sampling leave-one-out cross-validation (PSIS-LOO [<xref ref-type="bibr" rid="pcbi.1006110.ref053">53</xref>]) as the main metric to compare models (simply called LOO in the other sections for simplicity). In fact, there is a large number of commonly used metrics, such as (corrected) Akaike’s information criterion (AIC(c)) [<xref ref-type="bibr" rid="pcbi.1006110.ref068">68</xref>], Bayesian information criterion (BIC) [<xref ref-type="bibr" rid="pcbi.1006110.ref068">68</xref>], deviance information criterion (DIC) [<xref ref-type="bibr" rid="pcbi.1006110.ref069">69</xref>], widely applicable information criterion (WAIC) [<xref ref-type="bibr" rid="pcbi.1006110.ref070">70</xref>], and marginal likelihood [<xref ref-type="bibr" rid="pcbi.1006110.ref071">71</xref>]. The literature on model comparison is vast and with different schools of thought—by necessity here we only summarize some remarks. The first broad distinction between these metrics is between predictive metrics (AIC(c), DIC, WAIC, and PSIS-LOO) [<xref ref-type="bibr" rid="pcbi.1006110.ref072">72</xref>], that try to approximate out-of-sample predictive error (that is, model performance on unseen data), and BIC and marginal likelihood, which try to establish the true model generating the data [<xref ref-type="bibr" rid="pcbi.1006110.ref071">71</xref>]. Another orthogonal distinction is between metrics based on point estimates (AIC(c) and BIC) vs. metrics that use partial to full information about the model’s uncertainty landscape (DIC, WAIC, PSIS-LOO, based on the posterior, and the marginal likelihood, based on the likelihood integrated over the prior).</p>
<p>First, when computationally feasible we prefer uncertainty-based metrics to point estimates, since the latter are only crude asymptotic approximations that do not take the model and the data into account, besides simple summary statistics (number of free parameters and possibly number of data points). Due to their lack of knowledge of the actual structure of the model, AIC(c) and BIC can grossly misestimate model complexity [<xref ref-type="bibr" rid="pcbi.1006110.ref072">72</xref>].</p>
<p>Second, we have an ordered preference among predictive metrics, that is PSIS-LOO ≻ WAIC ≻ DIC ≻ AIC(c) [<xref ref-type="bibr" rid="pcbi.1006110.ref072">72</xref>]. The reason is that all of these metrics more or less asymptotically approximate full leave-one-out cross validation, with increasing degree of accuracy from right to left [<xref ref-type="bibr" rid="pcbi.1006110.ref053">53</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref072">72</xref>]. As mentioned before, AIC(c) works only in the regime of a large amount of data. DIC, albeit commonly used, has several issues and requires the posterior to be multivariate normal, or at least symmetric and unimodal—gross failures can happen when this is not the case, since DIC bases its estimate of model complexity on the mean (or some other measure of central tendency) of the posterior [<xref ref-type="bibr" rid="pcbi.1006110.ref072">72</xref>]. WAIC is a great improvement over DIC and does not require normality of the posterior, but its approximation is generally superseded by PSIS-LOO [<xref ref-type="bibr" rid="pcbi.1006110.ref053">53</xref>]. Moreover, PSIS-LOO has a natural diagnostic, the exponents of the tails of the fitted Pareto distribution, which allows the user to know when the method may be in trouble [<xref ref-type="bibr" rid="pcbi.1006110.ref053">53</xref>]. Full leave-one-out cross validation is extremely expensive, but PSIS-LOO only requires the user to compute the posterior via MCMC sampling, with no additional cost with respect to DIC or WAIC. Similarly to WAIC, PSIS-LOO requires the user to store for each posterior sample the log likelihood <italic>per trial</italic>, which with modern computers represent a negligible storage cost.</p>
<p>The marginal likelihood, or Bayes factor (of which BIC is a poor approximation), is an alternative approach to quantify model evidence, related to computing the posterior probability of the models [<xref ref-type="bibr" rid="pcbi.1006110.ref071">71</xref>]. While this is a principled approach, it entails several practical and theoretical issues. First, the marginal likelihood is generally hard to compute, since it usually involves a complicated, high-dimensional integral of the likelihood over the prior (although this computation can be simplified for nested models [<xref ref-type="bibr" rid="pcbi.1006110.ref073">73</xref>]). Here, we have applied a novel approximation method for the marginal likelihood following ideas delineated in [<xref ref-type="bibr" rid="pcbi.1006110.ref074">74</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref075">75</xref>], obtaining generally sensible values. However, more work is needed to establish the precision and applicability of such technique. Besides practical computational issues, the marginal likelihood, unlike other metrics, is sensitive to the choice of prior over parameters, in particular its range [<xref ref-type="bibr" rid="pcbi.1006110.ref066">66</xref>]. Crucially, and against common intuition, this sensitivity does not reduce with increasing amounts of data. A badly chosen (e.g., excessively wide) prior for a non-shared parameter might change the marginal likelihood of a model by several points, thus affecting model ranking. The open issue of prior sensitivity has led some authors to largely discard model selection based on the marginal likelihood [<xref ref-type="bibr" rid="pcbi.1006110.ref066">66</xref>].</p>
<p>For these reasons, we chose (PSIS-)LOO as the main model comparison metric. As a test of robustness, we also computed other metrics and verified that our results were largely independent of the chosen metric, or investigated the reasons when it was not the case.</p>
<p>As a specific example, in our analysis we found that LOO and marginal likelihood (or BIC) generally agreed on all comparisons, except for the sensory noise factor. Unlike LOO, the marginal likelihood tended to prefer constant noise models as opposed to eccentricity-dependent models. Our explanation of this discrepancy is that for our tasks eccentricity-dependence provides a consistent but small improvement to the goodness of fit of the models, which can be overrided by a large penalty due to model complexity (BIC), or to the chosen prior over the eccentricity-dependent parameters (<italic>w</italic><sub>vis</sub>, <italic>w</italic><sub>vest</sub>), whose range was possibly wider than needed (see <xref ref-type="fig" rid="pcbi.1006110.g005">Fig 5</xref>). The issue of prior sensitivity (specifically, dependence of results on an arbitrarily chosen range) can be attenuated by adopting a Bayesian hierarchical approach over parameters (or a more computationally feasibile approximation, known as empirical Bayes), which is venue for future work.</p>
</sec>
<sec id="sec018">
<title>Computational framework</title>
<p>Model evaluation, especially from a Bayesian perspective, is a time-consuming business. For this reason, we have compiled several state-of-the-art methods for model building, fitting and comparison, and made our code available.</p>
<p>The main issue of many common observer models in perception is that the expression for the (log) likelihood is not analytical, requiring numerical integration or simulation. To date, this limits the applicability of modern model specification and analysis tools, such as probabilistic programming languages, that exploit auto-differentiation and gradient-based sampling methods (e.g., Stan [<xref ref-type="bibr" rid="pcbi.1006110.ref076">76</xref>] or PyMC3 [<xref ref-type="bibr" rid="pcbi.1006110.ref077">77</xref>]). The goal of such computational frameworks is to remove the burden and technical details of evaluating the models from the shoulders of the modeler, who only needs to provide a model specification.</p>
<p>In our case, we strive towards a more modest goal of providing black-box algorithms for optimization and MCMC sampling that exhibit a larger degree of robustness than standard methods. In particular, for optimization (maximum likelihood estimation) we recommend Bayesian adaptive direct search (BADS [<xref ref-type="bibr" rid="pcbi.1006110.ref078">78</xref>]), a technique based on Bayesian optimization [<xref ref-type="bibr" rid="pcbi.1006110.ref079">79</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref080">80</xref>], which exhibits robustness to noise and jagged likelihood landscapes, unlike common optimization methods such as <monospace>fminsearch</monospace> (Nelder-Mead) and <monospace>fmincon</monospace> in MATLAB. Similarly, for MCMC sampling we propose a sampling method that combines the robustness and self-adaptation of slice sampling [<xref ref-type="bibr" rid="pcbi.1006110.ref081">81</xref>] and ensemble-based methods [<xref ref-type="bibr" rid="pcbi.1006110.ref082">82</xref>]. Crucially, our proposed method almost completely removes the need of expensive trial-and-error tuning on the part of the modeler, possibly one of the main reasons why MCMC methods and full evaluation of the posterior are relatively uncommon in the field (to our knowledge, this is the first study of causal inference in multisensory perception to adopt a fully Bayesian approach).</p>
<p>Our framework is similar to the concept behind the VBA toolbox, a MATLAB toolbox for probabilistic treatment of nonlinear models for neurobiological and behavioral data [<xref ref-type="bibr" rid="pcbi.1006110.ref083">83</xref>]. The VBA toolbox tackles the problem of model fitting via a variational approximation that assumes factorized, Gaussian posteriors over the parameters (mean field/Laplace approximation), and provides the variational free energy as an approximation (lower bound) of the marginal likelihood. Our approach, instead, does not make any strong assumption, using MCMC to recover the full shape of the posterior, and state-of-the-art techniques to assess model performance.</p>
<p>Detailed, rigorous modeling of behavior is a necessary step to constrain the search for neural mechanisms implementing decision strategies [<xref ref-type="bibr" rid="pcbi.1006110.ref084">84</xref>] We have provided a set of computational tools and demonstrated how they can be applied to answer specific questions about internal representation and decision strategies of the observer in multisensory perception, with the goal of increasing the set of models that can be investigated, and the robustness of such analyses. Thus, our tools can be of profound use not only to the field of multisensory perception, but to biological modeling in general.</p>
</sec>
</sec>
<sec id="sec019" sec-type="materials|methods">
<title>Methods</title>
<sec id="sec020">
<title>Ethics statement</title>
<p>The Institutional Review Board at the Baylor College of Medicine approved the experimental procedures (protocol number H-29411, “Psychophysics of spatial orientation and vestibular influences on spatial constancy and movement planning”) and all subjects gave written informed consent.</p>
</sec>
<sec id="sec021">
<title>Human psychophysics</title>
<sec id="sec022">
<title>Subjects</title>
<p>Eleven healthy adults (4 female; age 26.4 ± 4.6 years, mean ± SD) participated in the full study. Subjects had no previous history of neurological disorders and had normal or corrected-to-normal vision. Four other subjects completed only a partial version of the experiment, and their data were not analyzed here.</p>
</sec>
<sec id="sec023">
<title>Apparatus</title>
<p>Details of the experimental apparatus have been previously published and are only described here briefly [<xref ref-type="bibr" rid="pcbi.1006110.ref009">9</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref014">14</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref085">85</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref086">86</xref>]. Subjects were seated comfortably in a cockpit-style chair and were protectively restrained with a 5-point racing safety harness. Each subject wore a custom-made thermoplastic mesh mask that was attached to the back of the chair for head stabilization. The chair, a three-chip DLP projector (Galaxy 6; Barco) and a large projection screen (149 × 127 cm) were all mounted on a motion platform (6DOF2000E; Moog, Inc.). The projection screen was located ∼65 cm in front of the eyes, subtending a visual angle of ∼94° × 84°. Subjects wore LCD-based active 3D stereo shutter glasses (Crystal Eyes 4, RealD, Beverly Hills) to provide stereoscopic depth cues and headphones for providing trial timing-related feedback (a tone to indicate when a trial was about the begin and another when a button press was registered). This apparatus was capable of providing three self-motion conditions: vestibular (inertial motion through the movement of the platform), visual (optic flow simulating movement of the observer in a 3D virtual cloud of stars, platform stationary) and combined visual-vestibular heading (temporally-synchronized optic flow and platform motion) at various spatial discrepancies.</p>
</sec>
<sec id="sec024">
<title>Stimuli</title>
<p>We modified a previous multisensory heading discrimination task [<xref ref-type="bibr" rid="pcbi.1006110.ref009">9</xref>]. Here subjects experienced combined visual and vestibular translation in the horizontal plane (<xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1A</xref>). The visual scene and platform movement followed a Gaussian velocity profile (displacement = 13 cm, peak Gaussian velocity = 26 cm/s and peak acceleration = 0.9m/s<sup>2</sup>, duration = 1 s). Visual and vestibular headings were either in the same direction or their movement trajectories were separated by a directional disparity, Δ, expressed in degrees (<xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1A</xref>). The directional disparity Δ and visual cue reliability were varied on a trial-by-trial basis. Δ took one of five values, selected with equal probability: 0° (no conflict), 5°, 10°, 20° and 40°. Thus, visual and vestibular stimuli were in conflict in 80% of the trials. In each trial, Δ was randomly assigned to be positive (<xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1A</xref> right, vestibular heading to the right of visual heading) or negative. Once a disparity value, Δ, was chosen, the mean heading angle (<inline-formula id="pcbi.1006110.e030"><alternatives><graphic id="pcbi.1006110.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e030" xlink:type="simple"/><mml:math display="inline" id="M30"><mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>¯</mml:mo></mml:mover></mml:math></alternatives></inline-formula>) which represents the average of vestibular and visual headings, was uniformly randomly drawn from the discrete set {−25°, −20°, …, 25°}. Vestibular heading (<italic>s</italic><sub>vest</sub>, red trace in <xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1</xref>) and visual heading (<italic>s</italic><sub>vis</sub>, black trace in <xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1A</xref>) were generated by displacing the platform motion and optic flow on either side of the mean heading by Δ/2. The vestibular and visual headings experienced by subjects were defined as <inline-formula id="pcbi.1006110.e031"><alternatives><graphic id="pcbi.1006110.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e031" xlink:type="simple"/><mml:math display="inline" id="M31"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>+</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006110.e032"><alternatives><graphic id="pcbi.1006110.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e032" xlink:type="simple"/><mml:math display="inline" id="M32"><mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>=</mml:mo> <mml:mover accent="true"><mml:mi>s</mml:mi> <mml:mo>¯</mml:mo></mml:mover> <mml:mo>-</mml:mo> <mml:mo>Δ</mml:mo> <mml:mo>/</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, respectively. This procedure entailed that visual and vestibular heading directions presented in experiment were correlated (<xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1B</xref>). Three levels of visual cue reliability (high, medium, and low) were tested. Visual reliability was manipulated by varying the percentage of stars in the optic flow that coherently moved in the specified heading direction. For all subjects, visual motion coherence at high reliability was set at 100%. Coherence at medium reliability was selected for each subject during a preliminary session via a manual staircasing procedure such that their visual and vestibular thresholds were approximately matched. Coherence at low reliability was also selected for each subject separately and this was a value that was chosen to be lower than the medium reliability. Thus, the optic flow coherences for medium and low reliabilities were different across subjects with ranges of 40-70% and 25-50%, respectively. Overall, there were 297 stimulus conditions (9 directional disparities × 11 mean heading directions × 3 visual cue reliabilities) which were randomly interleaved.</p>
</sec>
<sec id="sec025">
<title>Tasks</title>
<p>First, subjects (<italic>n</italic> = 11) performed in a session of a unisensory heading discrimination task (left/right of straight ahead), in which visual or vestibular stimuli were presented in isolation. Vestibular stimuli had one fixed reliability level, whereas visual stimuli were tested on three different reliability levels, randomly interleaved, resulting in a total of 350–750 trials.</p>
<p>Then, subjects performed two-three sessions of the explicit causal inference task (unity judgment). Here, subjects indicated if the visual and vestibular cues indicated heading in the same direction (“common” cause, <italic>C</italic> = 1) or in different directions (“different” causes, <italic>C</italic> = 2). Each combination of disparity and reliability was presented at least 20 times. Since each disparity was randomly assigned to be positive or negative on each trial, 0° disparity was presented at least 40 times at each visual cue reliability resulting in a total of 700-1200 trials. Subjects did not receive feedback about the correctness of their responses.</p>
<p>Finally, the same subjects also participated in the implicit causal inference task—bisensory (inertial) discrimination. Here, subjects indicated the perceived direction of their inertial self-motion (left or right of straight ahead). Note that although both visual and vestibular stimuli were presented in each trial, subjects were asked to only indicate their perceived direction of inertial heading, similar to the bisensory auditory localization procedure in [<xref ref-type="bibr" rid="pcbi.1006110.ref021">21</xref>]. Each combination of disparity and visual cue reliability was presented at least 70 times. Since each disparity was randomly assigned to be positive or negative on each trial, 0° disparity was presented at least 140 times resulting in a total of 2100-3000 trials divided across 7-9 sessions. No feedback was given about the correctness of subjects’ responses.</p>
<p>For all tasks, sessions were about one hour long and subjects were required to take multiple breaks within each session.</p>
</sec>
<sec id="sec026">
<title>Data analysis</title>
<p>For the explicit causal inference task, we computed the proportion of trials in which subjects perceived a common cause at each disparity and visual cue reliability. For the implicit causal inference task, we calculated the shift in perceived inertial heading as a function of <italic>s</italic><sub>vis</sub>, that is the influence that <italic>s</italic><sub>vis</sub> had on <italic>s</italic><sub>vest</sub>, and we called this model-free summary statistic ‘bias’. In order to build psychometric functions with enough trials, we binned values of <italic>s</italic><sub>vis</sub> in the following intervals: {[−45°, −30°], [−27.5°, −22.5°], [−20°, −15°], [−12.5°, −7.5°], [−5°, −2.5°], 0°, [2.5°, 5°], [7.5°, 12.5°], [15°, 20°], [22.5°, 27.5°], [30°, 45°]}. Bin ranges were chosen to yield a comparable number of trials per bin, according to the nonuniform distribution of <italic>s</italic><sub>vis</sub> in the experiment (see <xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1B</xref>). For each visual bin and level of visual cue reliability, we constructed psychometric functions by fitting the proportion of rightward responses as a function of <italic>s</italic><sub>vest</sub> with cumulative Gaussian functions (inset in <xref ref-type="fig" rid="pcbi.1006110.g003">Fig 3A</xref>). Thus, we defined the bias in the perceived inertial heading as minus the point of subjective equality (L/R PSE). A bias close to zero indicates that subjects accurately perceived their inertial (vestibular) heading. Large shifts of the PSE away from zero, that is substantial biases, suggest that misleading visual cues exerted a significant influence on the accuracy of inertial heading discrimination. Note that we do not expect the psychometric curves to be <italic>exact</italic> cumulative Gaussian functions, because of nonlinearities due to eccentricity-dependence of the noise and effects of causal inference. Nonetheless, the bias as we defined it is useful as a simple model-free statistic. Repeated-measures ANOVA with disparity or visual bin and visual cue reliability as within-subjects factors were performed separately on the proportion of common cause reports and bias in perceived inertial heading. We applied Greenhouse-Geisser correction of the degrees of freedom in order to account for deviations from sphericity [<xref ref-type="bibr" rid="pcbi.1006110.ref087">87</xref>], and report effect sizes as partial eta squared, denoted with <inline-formula id="pcbi.1006110.e033"><alternatives><graphic id="pcbi.1006110.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e033" xlink:type="simple"/><mml:math display="inline" id="M33"><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>p</mml:mi> <mml:mn>2</mml:mn></mml:msubsup></mml:math></alternatives></inline-formula>. For all analyses the criterion for statistical significance was <italic>p</italic> &lt; .05, and we report uncorrected <italic>p</italic>-values. Unless specified otherwise, summary statistics are reported in the text as mean ± SE between subjects. Finally, we remark that the summary statistics described above were used only for visualization and to perform simple descriptive statistics; we fit all models to raw trial data.</p>
</sec>
</sec>
<sec id="sec027">
<title>Causal inference models</title>
<p>We build upon standard causal inference models of multisensory perception [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>]. For concreteness, in the following description of causal inference models we refer to the visuo-vestibular example with binary responses (‘left/right’ for discrimination, and ‘yes/no’ for unity judgements). The basic component of any observer model is the trial response probability, that is the probability of observing a given response for a given trial condition (e.g., stimulus pair, uncertainty level, task). In the following we briefly review how these probabilities are computed.</p>
<p>All analysis code was written in MATLAB (Mathworks, Inc.), with core computations in C for increased performance (via <italic>mex</italic> files in MATLAB). Code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/visvest-causinf" xlink:type="simple">https://github.com/lacerbi/visvest-causinf</ext-link>.</p>
<sec id="sec028">
<title>Unisensory heading discrimination</title>
<p>We used subjects’ binary (‘left or right of straight forward’) heading choices, measured in the presence of visual-only and vestibular-only stimuli, to estimate subjects’ measurement noise in the respective sensory signals. Let us consider a trial with a vestibular-only stimulus (the computation for a visual-only stimulus is analogous). Subjects are asked whether the perceived direction of motion <italic>s</italic><sub>vest</sub> is to the left or to the right of straight forward (0°). We assume that the observer has access to a noisy measurement <italic>x</italic><sub>vest</sub> of stimulus <italic>s</italic><sub>vest</sub> (direction of motion), with probability density
<disp-formula id="pcbi.1006110.e034"><alternatives><graphic id="pcbi.1006110.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e034" xlink:type="simple"/><mml:math display="block" id="M34"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(1)</label></disp-formula>
where <inline-formula id="pcbi.1006110.e035"><alternatives><graphic id="pcbi.1006110.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mrow><mml:mi>x</mml:mi> <mml:mo>|</mml:mo> <mml:mi>μ</mml:mi> <mml:mo>,</mml:mo></mml:mrow> <mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is a normal probability density with mean <italic>μ</italic> and variance <italic>σ</italic><sup>2</sup>. Since stimulus directions are defined over the circle, we also considered a wrapped normal or, similarly, a von Mises distribution instead of <xref ref-type="disp-formula" rid="pcbi.1006110.e034">Eq 1</xref>. Because of the relatively small range of stimuli used in the experiment, we found no difference between the distributions defined over the full circle and the simple normal distribution in <xref ref-type="disp-formula" rid="pcbi.1006110.e034">Eq 1</xref> (see <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>). Incidentally, in an additional investigation we also found no empirical difference between a wrapped normal and a von Mises, so either noise distribution could be used in the presence of fully circular stimuli (see <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>).</p>
<p>Depending on the sensory noise model, the variance in <xref ref-type="disp-formula" rid="pcbi.1006110.e034">Eq 1</xref> is either <italic>constant</italic> (<inline-formula id="pcbi.1006110.e036"><alternatives><graphic id="pcbi.1006110.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:msup><mml:mi>σ</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≡</mml:mo> <mml:msub><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mn>0</mml:mn> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow> <mml:mtext>vest</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>) or <italic>eccentricity-dependent</italic> with base magnitude <inline-formula id="pcbi.1006110.e037"><alternatives><graphic id="pcbi.1006110.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e037" xlink:type="simple"/><mml:math display="inline" id="M37"><mml:msub><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi> <mml:mn>0</mml:mn> <mml:mn>2</mml:mn></mml:msubsup></mml:mrow> <mml:mtext>vest</mml:mtext></mml:msub></mml:math></alternatives></inline-formula> and noise that increases with eccentricity (distance from 0°) approximately quadratically, at least for small headings, according to a parameter <italic>w</italic><sub>vest</sub> ≥ 0 (see <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref> for details). For <italic>w</italic><sub>vest</sub> = 0, the eccentricity-dependent model reduces to the constant model. The observer’s posterior probability density over the vestibular stimulus is <italic>p</italic>(<italic>s</italic><sub>vest</sub>|<italic>x</italic><sub>vest</sub>) ∝ <italic>p</italic>(<italic>x</italic><sub>vest</sub>|<italic>s</italic><sub>vest</sub>)<italic>p</italic><sub>prior</sub>(<italic>s</italic><sub>vest</sub>), and we will see that under some assumptions the prior over heading directions is irrelevant for subsequent computations in the left/right unisensory task (see <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>).</p>
<p>We assume that observers compute the posterior probability that the stimulus is right of straight forward as <inline-formula id="pcbi.1006110.e038"><alternatives><graphic id="pcbi.1006110.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e038" xlink:type="simple"/><mml:math display="inline" id="M38"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mn>0</mml:mn> <mml:mn>90</mml:mn></mml:msubsup> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, and respond ‘right’ if Pr(<italic>s</italic><sub>vest</sub> &gt; 0|<italic>x</italic><sub>vest</sub>) &gt; 0.5; ‘left’ otherwise (see <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref> for details). Observers may also lapse and give a completely random response with probability λ (lapse rate). This yields
<disp-formula id="pcbi.1006110.e039"><alternatives><graphic id="pcbi.1006110.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>choose</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>right</mml:mtext> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo> <mml:mrow><mml:mo>⟦</mml:mo> <mml:mspace width="-0.166667em"/><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn> <mml:mo>⟧</mml:mo></mml:mrow></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(2)</label></disp-formula>
where ⟦·⟧ is Iverson bracket, which is 1 if the argument is true, and 0 otherwise [<xref ref-type="bibr" rid="pcbi.1006110.ref088">88</xref>].</p>
<p>An analogous derivation is applied to each unisensory visual stimulus condition for respectively low, medium, and high visual reliability. We assume a distinct <italic>σ</italic><sub>0</sub><sub>vis</sub> for each visual reliability condition, and, for the eccentricity-dependent models, a common <italic>w</italic><sub>vis</sub> for all visual reliability conditions, so as to reduce model complexity.</p>
</sec>
<sec id="sec029">
<title>Unity judgment (explicit causal inference)</title>
<p>In a unity judgment trial, the observer explicitly evaluates whether there is a single cause (<italic>C</italic> = 1) underlying the noisy measurements <italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>, or two separate causes (<italic>C</italic> = 2; see <xref ref-type="fig" rid="pcbi.1006110.g002">Fig 2B</xref>). All following probability densities are conditioned on <italic>c</italic><sub>vis</sub>, the level of visual cue reliability in the trial, which is assumed to be known to the observer; we omit this dependence to reduce clutter. We consider three families of explicit causal inference strategies.</p>
<p>The <italic>Bayesian</italic> causal inference strategy computes the posterior probability of common cause
<disp-formula id="pcbi.1006110.e040"><alternatives><graphic id="pcbi.1006110.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e040" xlink:type="simple"/><mml:math display="block" id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>p</mml:mi> <mml:mtext>c</mml:mtext></mml:msub></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>p</mml:mi> <mml:mtext>c</mml:mtext></mml:msub> <mml:mo>+</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>p</mml:mi> <mml:mtext>c</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(3)</label></disp-formula>
where 0 ≤ <italic>p</italic><sub>c</sub> ≡ Pr(<italic>C</italic> = 1) ≤ 1, the prior probability of a common cause, is a free parameter of the model. The derivation of <italic>p</italic>(<italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>|<italic>C</italic> = <italic>k</italic>), for <italic>k</italic> = 1, 2, is available in <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>. The observer reports unity if the posterior probability of common cause is greater than 0.5, with the added possibility of random lapse,
<disp-formula id="pcbi.1006110.e041"><alternatives><graphic id="pcbi.1006110.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e041" xlink:type="simple"/><mml:math display="block" id="M41"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mo>(</mml:mo> <mml:mtext>choose</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>unity</mml:mtext> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow> <mml:mrow><mml:mfrac><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>⟦</mml:mo> <mml:mspace width="-0.166667em"/><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn> <mml:mo>⟧</mml:mo></mml:mrow></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(4)</label></disp-formula></p>
<p>For a separate analysis we also considered a ‘probability matching’ variant that reports unity with probability equal to Pr(<italic>C</italic> = 1|<italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>) (plus lapses).</p>
<p>As a non-Bayesian causal inference heuristic model, we consider a <italic>fixed criterion</italic> observer, who reports a common cause whenever the two noisy measurements are within a distance <italic>κ</italic><sub>c</sub> ≥ 0 from each other,
<disp-formula id="pcbi.1006110.e042"><alternatives><graphic id="pcbi.1006110.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e042" xlink:type="simple"/><mml:math display="block" id="M42"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mo>(</mml:mo> <mml:mtext>choose</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>unity</mml:mtext> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow> <mml:mrow><mml:mfrac><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>⟦</mml:mo> <mml:mspace width="-0.166667em"/><mml:mrow><mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:mo>&lt;</mml:mo> <mml:msub><mml:mi>κ</mml:mi> <mml:mtext>c</mml:mtext></mml:msub> <mml:mo>⟧</mml:mo></mml:mrow></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(5)</label></disp-formula></p>
<p>Crucially, the fixed criterion observer does not take into account stimulus reliability or other statistical information when inferring the causal structure.</p>
<p>Finally, we consider a <italic>fusion</italic> observer that eschews causal inference altogether. A classical ‘forced fusion’ observer would <italic>always</italic> report ‘unity’ in the explicit causal inference task, which is easily rejected by the data. Instead, we consider a <italic>stochastic fusion</italic> observer that reports ‘unity’ with probability <italic>η</italic><sub>low</sub>, <italic>η</italic><sub>med</sub>, or <italic>η</italic><sub>high</sub>, depending only on the reliability of the visual cue, and discards any other information.</p>
</sec>
<sec id="sec030">
<title>Bisensory inertial discrimination (implicit causal inference)</title>
<p>In bisensory inertial discrimination trials, the observer reports whether the perceived inertial heading <italic>s</italic><sub>vest</sub> is to the left or right of straight forward (0°). In this experiment, we do not ask subjects to report <italic>s</italic><sub>vis</sub>, but the inference would be analogous. The inertial discrimination task requires an implicit evaluation of whether there is a single cause to the noisy measurements <italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub> (<italic>C</italic> = 1), or two separate causes (<italic>C</italic> = 2), for a known level of visual coherence <italic>c</italic><sub>vis</sub> (omitted from the notation for clarity).</p>
<p>If the observer knew that <italic>C</italic> = <italic>k</italic>, for <italic>k</italic> = 1, 2, the posterior probability density over the vestibular stimulus would be (see <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>)
<disp-formula id="pcbi.1006110.e043"><alternatives><graphic id="pcbi.1006110.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e043" xlink:type="simple"/><mml:math display="block" id="M43"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mo>∝</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:mrow> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:msubsup> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
where the likelihoods are defined as per the uni-sensory task, <xref ref-type="disp-formula" rid="pcbi.1006110.e034">Eq 1</xref>, and for the prior over heading directions, <italic>p</italic>(<italic>s</italic><sub>vis</sub>, <italic>s</italic><sub>vest</sub>|<italic>C</italic>), see ‘Observers’ priors’ below.</p>
<p>The posterior probability of rightward motion is computed for <italic>k</italic> = 1, 2 as
<disp-formula id="pcbi.1006110.e044"><alternatives><graphic id="pcbi.1006110.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e044" xlink:type="simple"/><mml:math display="block" id="M44"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∝</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:msup><mml:mn>0</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:mrow> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:msubsup> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mi>k</mml:mi> <mml:mo>)</mml:mo> <mml:mi>d</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
and an analogous equation holds for the posterior probability of leftward motion.</p>
<p>In general, the causal structure is implicitly inferred by the observer. We assume that observers combine cues according to
<disp-formula id="pcbi.1006110.e045"><alternatives><graphic id="pcbi.1006110.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e045" xlink:type="simple"/><mml:math display="block" id="M45"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>v</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>[</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msub><mml:mi>v</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo> <mml:mo>·</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:mi>C</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
where 0 ≤ <italic>v</italic><sub>1</sub>(<italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>) ≤ 1 is the <italic>implicit causal weight</italic> associated by the observer to the hypothesis of a single cause, <italic>C</italic> = 1. The form of the causal weight depends on the observer’s implicit causal inference strategy.</p>
<p>We consider three families of implicit causal inference. For the <italic>Bayesian</italic> causal inference observer, the causal weight is equal to the posterior probability, <italic>v</italic><sub>1</sub>(<italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>) = Pr(<italic>C</italic> = 1|<italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>), so that <xref ref-type="disp-formula" rid="pcbi.1006110.e045">Eq 6</xref> becomes the expression for Bayesian model averaging [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>] (see <xref ref-type="disp-formula" rid="pcbi.1006110.e040">Eq 3</xref> and <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>). As a variant of the Bayesian observer we consider a <italic>probability matching</italic> Bayesian strategy for which <italic>v</italic><sub>1</sub> = 1 with probability Pr(<italic>C</italic> = 1|<italic>x</italic><sub>vis</sub>, <italic>x</italic><sub>vest</sub>), and <italic>v</italic><sub>1</sub> = 0 otherwise. For the <italic>fixed-criterion</italic> observer, <italic>v</italic><sub>1</sub> = ⟦|<italic>x</italic><sub>vis</sub> − <italic>x</italic><sub>vest</sub>| &lt; <italic>κ</italic><sub>c</sub>⟧, with <italic>κ</italic><sub>c</sub> ≥ 0 as per <xref ref-type="disp-formula" rid="pcbi.1006110.e042">Eq 5</xref>. Finally, for the <italic>forced fusion</italic> observer <italic>v</italic><sub>1</sub> ≡ 1.</p>
<p>The posterior probability of rightward motion is then <inline-formula id="pcbi.1006110.e046"><alternatives><graphic id="pcbi.1006110.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e046" xlink:type="simple"/><mml:math display="inline" id="M46"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mtext>vest</mml:mtext></mml:mrow></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mtext>vest</mml:mtext></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mtext>vis</mml:mtext></mml:mrow></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mstyle><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:msup><mml:mn>0</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:mrow> <mml:mrow><mml:msup><mml:mrow><mml:mn>90</mml:mn></mml:mrow> <mml:mo>°</mml:mo></mml:msup></mml:mrow></mml:msubsup> <mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mtext>vest</mml:mtext></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mtext>vis</mml:mtext></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mrow><mml:mtext>vest</mml:mtext></mml:mrow></mml:msub></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi>s</mml:mi> <mml:mrow><mml:mtext>vest</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></alternatives></inline-formula>, and an analogous equation holds for the posterior probability of leftward motion. We assume the observer reports the direction with highest posterior probability, with occasional lapses (see also <xref ref-type="disp-formula" rid="pcbi.1006110.e039">Eq 2</xref>),
<disp-formula id="pcbi.1006110.e047"><alternatives><graphic id="pcbi.1006110.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e047" xlink:type="simple"/><mml:math display="block" id="M47"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>choose</mml:mtext> <mml:mspace width="4.pt"/><mml:mtext>right</mml:mtext> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mo>λ</mml:mo> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>+</mml:mo> <mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo> <mml:mrow><mml:mo>⟦</mml:mo> <mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>|</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>&gt;</mml:mo> <mml:mn>0</mml:mn> <mml:mo>.</mml:mo> <mml:mn>5</mml:mn> <mml:mo>⟧</mml:mo></mml:mrow></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
where λ ≥ 0 is the lapse rate.</p>
</sec>
<sec id="sec031">
<title>Observers’ prior</title>
<p>We assume subjects develop a symmetric, unimodal prior over heading directions for unisensory trials. Due to the form of the decision rule (<xref ref-type="disp-formula" rid="pcbi.1006110.e039">Eq 2</xref>), a symmetric prior has no effect on the unisensory trials, so we only focus on the bisensory case.</p>
<p>For the bisensory prior over heading directions, <italic>p</italic>(<italic>s</italic><sub>vis</sub>, <italic>s</italic><sub>vest</sub>|<italic>C</italic>) we consider two families of priors. The <italic>empirical</italic> prior approximately follows the correlated structure of the discrete distribution of vestibular and visual headings presented in the experiment (<xref ref-type="fig" rid="pcbi.1006110.g001">Fig 1B</xref>). The <italic>independent</italic> prior assumes that observers learn a generic uncorrelated Gaussian prior over heading directions, as per [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>]. See <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref> for details.</p>
<p>We note that previous work in heading perception has found a ‘repulsive’ bias away from straight ahead [<xref ref-type="bibr" rid="pcbi.1006110.ref089">89</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref090">90</xref>], which is seemingly at odds with the central prior assumed here. However, the repulsion bias previously reported can be explained by the current Bayesian framework by means of a stimulus-dependent likelihood [<xref ref-type="bibr" rid="pcbi.1006110.ref091">91</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref092">92</xref>]. According to the Bayesian theory, such a stimulus-dependent likelihood may induce a bias away from regions of higher sensory precision. Whether the net bias is going to be attractive or repulsive depends on the relative contribution of prior and likelihood [<xref ref-type="bibr" rid="pcbi.1006110.ref093">93</xref>]. Thus, our models that combine a central prior and stimulus-dependent likelihood are not incompatible with previous findings of repulsive biases. See also <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>.</p>
</sec>
<sec id="sec032">
<title>Trial response probabilities</title>
<p>Eqs <xref ref-type="disp-formula" rid="pcbi.1006110.e039">2</xref>, <xref ref-type="disp-formula" rid="pcbi.1006110.e041">4</xref>, <xref ref-type="disp-formula" rid="pcbi.1006110.e042">5</xref> and <xref ref-type="disp-formula" rid="pcbi.1006110.e047">7</xref> represent the probability that an observer chooses a specific response <italic>r</italic> (‘rightward’ or ‘leftward’ for discrimination trials, ‘same’ or ‘different’ for unity judgment trials), for given noisy measurements <italic>x</italic><sub>vis</sub> and <italic>x</italic><sub>vest</sub> (or only one of the two for the unisensory task), and known visual reliability <italic>c</italic><sub>vis</sub>. Since as experimenters we do not have access to subjects’ internal measurements, to compute the trial response probabilities we integrate (‘marginalize’) over the unseen noisy measurements for given heading directions <italic>s</italic><sub>vis</sub> and <italic>s</italic><sub>vest</sub> presented in the trial.</p>
<p>For the unisensory case, considering as example the vestibular case, we get
<disp-formula id="pcbi.1006110.e048"><alternatives><graphic id="pcbi.1006110.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e048" xlink:type="simple"/><mml:math display="block" id="M48"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>observed</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>r</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:mrow> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:msubsup> <mml:mtext>Pr</mml:mtext> <mml:mo>(</mml:mo> <mml:mrow><mml:mtext>choose</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>r</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(8)</label></disp-formula></p>
<p>For the bisensory case, either unity judgment or inertial discrimination, we have
<disp-formula id="pcbi.1006110.e049"><alternatives><graphic id="pcbi.1006110.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e049" xlink:type="simple"/><mml:math display="block" id="M49"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>Pr</mml:mtext> <mml:mo>(</mml:mo> <mml:mtext>observed</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>r</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:mrow> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:msubsup> <mml:msubsup><mml:mo>∫</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:mrow> <mml:msup><mml:mn>90</mml:mn> <mml:mo>°</mml:mo></mml:msup></mml:msubsup> <mml:mtext>Pr</mml:mtext> <mml:mo>(</mml:mo> <mml:mrow><mml:mtext>choose</mml:mtext> <mml:mspace width="4.pt"/><mml:mi>r</mml:mi> <mml:mo>|</mml:mo></mml:mrow> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>×</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>c</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vest</mml:mtext></mml:msub> <mml:mi>d</mml:mi> <mml:msub><mml:mi>x</mml:mi> <mml:mtext>vis</mml:mtext></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(9)</label></disp-formula></p>
<p>It is customary in the causal inference literature to approximate these integrals via Monte Carlo sampling, by drawing a large number of noisy measurements from the noise distributions (e.g., [<xref ref-type="bibr" rid="pcbi.1006110.ref018">18</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref033">33</xref>]). Instead, we computed the integrals via numerical integration, which is more efficient than Monte Carlo techniques for low dimensional problems [<xref ref-type="bibr" rid="pcbi.1006110.ref094">94</xref>]. We used the same numerical approach to evaluate Eqs <xref ref-type="disp-formula" rid="pcbi.1006110.e039">2</xref>, <xref ref-type="disp-formula" rid="pcbi.1006110.e041">4</xref>, <xref ref-type="disp-formula" rid="pcbi.1006110.e042">5</xref> and <xref ref-type="disp-formula" rid="pcbi.1006110.e047">7</xref>, including an adaptive method for choice of integration grid. All numerical integrals were then coded in C (<italic>mex</italic> files in MATLAB) for additional speed. See <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref> for computational details.</p>
</sec>
</sec>
<sec id="sec033">
<title>Model fitting</title>
<p>For a given model, we denote its set of parameters by a vector <bold><italic>θ</italic></bold>. For a given model and dataset, we define the parameter log likelihood function as
<disp-formula id="pcbi.1006110.e050"><alternatives><graphic id="pcbi.1006110.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e050" xlink:type="simple"/><mml:math display="block" id="M50"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>LL</mml:mtext> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo></mml:mrow> <mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mo>=</mml:mo> <mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>trials</mml:mtext></mml:msub></mml:munderover> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msubsup><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>c</mml:mi> <mml:mtext>vis</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mo>=</mml:mo> <mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>trials</mml:mtext></mml:msub></mml:munderover> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi>r</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msubsup><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>c</mml:mi> <mml:mtext>vis</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(10)</label></disp-formula>
where we assumed conditional independence between trials; <italic>r</italic><sup>(<italic>i</italic>)</sup> denotes the subject’s response (‘right’ or ‘left’ for the discrimination trials; ‘common’ or ‘separate’ causes in unity judgment trials); <inline-formula id="pcbi.1006110.e051"><alternatives><graphic id="pcbi.1006110.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:msubsup><mml:mi>s</mml:mi> <mml:mtext>vis</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1006110.e052"><alternatives><graphic id="pcbi.1006110.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:msubsup><mml:mi>s</mml:mi> <mml:mtext>vest</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are, respectively, the direction of motion of the visual (resp. vestibular) stimulus (if present), and <inline-formula id="pcbi.1006110.e053"><alternatives><graphic id="pcbi.1006110.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e053" xlink:type="simple"/><mml:math display="inline" id="M53"><mml:msubsup><mml:mi>c</mml:mi> <mml:mtext>vis</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>i</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> is the visual coherence level (that is, reliability: low, medium, or high), in the <italic>i</italic>-th trial.</p>
<sec id="sec034">
<title>Maximum likelihood estimation</title>
<p>First, we fitted our models to the data via maximum likelihood estimation, by finding the parameter vector <bold><italic>θ</italic></bold>* that maximizes the log likelihood in <xref ref-type="disp-formula" rid="pcbi.1006110.e050">Eq 10</xref>. For optimization of the log likelihood, we used Bayesian Adaptive Direct Search (BADS; <ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/bads" xlink:type="simple">https://github.com/lacerbi/bads</ext-link>). BADS is a black-box optimization algorithm that combines a mesh-adaptive direct search strategy [<xref ref-type="bibr" rid="pcbi.1006110.ref095">95</xref>] with a local Bayesian optimization search step based on Gaussian process surrogates (see [<xref ref-type="bibr" rid="pcbi.1006110.ref080">80</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref096">96</xref>] for an introduction to Bayesian optimization). Bayesian optimization is particularly useful when the target function is costly to evaluate or the likelihood landscape is rough, as it is less likely to get stuck in local optima than other algorithms, and may reduce the number of function evaluations to find the (possibly global) optimum. In our case, evaluation of the log likelihood function for a single parameter vector <bold><italic>θ</italic></bold> could take up to ∼ 2-3 s for bisensory datasets, which makes it a good target for Bayesian optimization. We demonstrated in a separate benchmark that BADS is more effective than a large number of other MATLAB optimizers for our problem (‘causal inference’ problem set in [<xref ref-type="bibr" rid="pcbi.1006110.ref078">78</xref>]). See <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref> for more details about the algorithm and the optimization procedure.</p>
<p>For each subject we first fitted separately the datasets corresponding to three tasks (unisensory and bisensory heading discrimination, unity judgment), and then performed joint fits by combining datasets from all tasks (summing the respective log likelihoods).</p>
</sec>
<sec id="sec035">
<title>Posterior sampling</title>
<p>As a complementary approach to ML parameter estimation, for each dataset and model we calculated the posterior distribution of the parameters,
<disp-formula id="pcbi.1006110.e054"><alternatives><graphic id="pcbi.1006110.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e054" xlink:type="simple"/><mml:math display="block" id="M54"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>|</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>,</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo> <mml:mo>∝</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>|</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
where <italic>p</italic>(data|<bold><italic>θ</italic></bold>, model) is the likelihood (see <xref ref-type="disp-formula" rid="pcbi.1006110.e050">Eq 10</xref>) and <italic>p</italic>(<bold><italic>θ</italic></bold>|model) is the prior over parameters. We assumed a factorized prior <inline-formula id="pcbi.1006110.e055"><alternatives><graphic id="pcbi.1006110.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e055" xlink:type="simple"/><mml:math display="inline" id="M55"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>|</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>k</mml:mi></mml:msubsup> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and a non-informative uniform prior over a bounded interval for each model parameter (uniform in log space for scale parameters such as all noise base magnitudes, fixed criterion <italic>κ</italic><sub>c</sub>, and prior parameters <italic>σ</italic><sub>prior</sub> and Δ<sub>prior</sub>); see <xref ref-type="table" rid="pcbi.1006110.t002">Table 2</xref>.</p>
<p>We approximated <xref ref-type="disp-formula" rid="pcbi.1006110.e054">Eq 11</xref> via Markov Chain Monte Carlo (MCMC) sampling. We used a custom-written sampling algorithm that combines slice sampling [<xref ref-type="bibr" rid="pcbi.1006110.ref081">81</xref>] with adaptive direction sampling [<xref ref-type="bibr" rid="pcbi.1006110.ref082">82</xref>] and a number of other tricks (<ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/eissample" xlink:type="simple">https://github.com/lacerbi/eissample</ext-link>). Slice sampling is a flexible MCMC method that, in contrast with the common Metropolis-Hastings transition operator, requires very little tuning in the choice of length scale. Adaptive direction sampling is an ensemble MCMC method that shares information between several dependent chains (also called ‘walkers’ [<xref ref-type="bibr" rid="pcbi.1006110.ref097">97</xref>]) in order to speed up mixing and exploration of the state space. For details about the MCMC algorithm and the sampling procedure, see <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>.</p>
</sec>
</sec>
<sec id="sec036">
<title>Factorial model comparison</title>
<p>We built different observer models by factorially combining three factors: causal inference strategy (Bayesian, fixed-criterion, or fusion); shape of sensory noise (constant or eccentricity-dependent); and type of prior over heading directions (empirical or independent); see <xref ref-type="fig" rid="pcbi.1006110.g002">Fig 2A</xref> and ‘Causal inference models’ section of the Methods for a description of the different factors.</p>
<p>For each subject, we fitted the different observer models, first separately to different tasks (unity judgment and bisensory inertial discrimination), and then performed a joint fit by combining datasets from all tasks (including the unisensory discrimination task). We evaluated the fits with a number of model comparison metrics and via an objective goodness of fit metric. Finally, we combined evidence for different model factors across subjects with a hierarchical Bayesian approach.</p>
<p>We verified our ability to distinguish different models with a model recovery analysis, described in <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>.</p>
<sec id="sec037">
<title>Model comparison metrics</title>
<p>For each dataset and model we computed a number of different model comparison metrics, all of which take into account quality of fit and penalize model flexibility, but with different underlying assumptions.</p>
<p>Based on the maximum likelihood solution, we computed Akaike information criterion with a correction for sample size (AICc) and Schwarz’s ‘Bayesian’ Information criterion (BIC),
<disp-formula id="pcbi.1006110.e056"><alternatives><graphic id="pcbi.1006110.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e056" xlink:type="simple"/><mml:math display="block" id="M56"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>AICc</mml:mtext> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>L</mml:mi> <mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mn>2</mml:mn> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mfrac><mml:mrow><mml:mn>2</mml:mn> <mml:mi>k</mml:mi> <mml:mo>(</mml:mo> <mml:mi>k</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mi>N</mml:mi> <mml:mtext>trials</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:mi>k</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>BIC</mml:mtext> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:mi>L</mml:mi> <mml:mi>L</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mi>k</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>trials</mml:mtext></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(12)</label></disp-formula>
where <italic>N</italic><sub>trials</sub> is the number of trials in the dataset and <italic>k</italic> is the number of parameters of the model. The factor of −2 that appears in both definitions is due to historical reasons, so that both metrics have the same scale of the deviance.</p>
<p>To assess model performance on unseen data, we performed Bayesian leave-one-out (LOO) cross-validation. Bayesian LOO cross-validation computes the posterior of the parameters given <italic>N</italic><sub>trials</sub> − 1 trials (training), and evaluates the (log) expected likelihood of the left-out trial (test); the procedure is repeated for each trial, yielding the leave-one-out score
<disp-formula id="pcbi.1006110.e057"><alternatives><graphic id="pcbi.1006110.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e057" xlink:type="simple"/><mml:math display="block" id="M57"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>LOO</mml:mtext> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>trials</mml:mtext></mml:msub></mml:munderover> <mml:mo form="prefix">log</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="script">D</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(13)</label></disp-formula>
where <italic>p</italic>(<italic>r</italic><sub><italic>i</italic></sub>|<bold><italic>θ</italic></bold>) is the likelihood associated to the <italic>i</italic>-th trial alone, and <inline-formula id="pcbi.1006110.e058"><alternatives><graphic id="pcbi.1006110.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="script">D</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> is the posterior over <bold><italic>θ</italic></bold> given all trials except the <italic>i</italic>-th one. <xref ref-type="disp-formula" rid="pcbi.1006110.e057">Eq 13</xref> can be estimated at prohibitive computational cost by separately sampling from the leave-one-out posteriors via <italic>N</italic><sub>trials</sub> distinct MCMC runs. A more feasible approach comes from noting that all posteriors differ from the full posterior by only one data point. Therefore, the leave-one-out posteriors can be approximated via <italic>importance sampling</italic>, reweighting the full posterior obtained via MCMC. However, a direct approach of importance sampling can be unstable, since the full posterior is typically narrower than the leave-one-out posteriors. Pareto-smoothed importance sampling (PSIS) is a recent technique to stabilize the importance weights [<xref ref-type="bibr" rid="pcbi.1006110.ref052">52</xref>], implemented in the <monospace>psisloo</monospace> package (<ext-link ext-link-type="uri" xlink:href="https://github.com/avehtari/PSIS" xlink:type="simple">https://github.com/avehtari/PSIS</ext-link>). Thus, <xref ref-type="disp-formula" rid="pcbi.1006110.e057">Eq 13</xref> is approximated as
<disp-formula id="pcbi.1006110.e059"><alternatives><graphic id="pcbi.1006110.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e059" xlink:type="simple"/><mml:math display="block" id="M59"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>LOO</mml:mtext> <mml:mo>≈</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>trials</mml:mtext></mml:msub></mml:munderover> <mml:mo form="prefix">log</mml:mo> <mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>S</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>r</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>S</mml:mi></mml:msubsup> <mml:msubsup><mml:mi>w</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(14)</label></disp-formula>
where <bold><italic>θ</italic></bold><sup>(<italic>s</italic>)</sup> is the <italic>s</italic>-th parameter sample from the posterior, and <inline-formula id="pcbi.1006110.e060"><alternatives><graphic id="pcbi.1006110.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:msubsup><mml:mi>w</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are the Pareto-smoothed importance weights associated to the <italic>i</italic>-th trial and <italic>s</italic>-th sample (out of <italic>S</italic>); see [<xref ref-type="bibr" rid="pcbi.1006110.ref053">53</xref>] for details. PSIS also returns for each trial the exponent <italic>k</italic><sub><italic>i</italic></sub> of the fitted Pareto distribution; if <italic>k</italic><sub><italic>i</italic></sub> is greater than 1 the moments of the importance ratios distribution do not exist and the variance of the PSIS estimate is finite but may be large; this provides a natural diagnostic for the method [<xref ref-type="bibr" rid="pcbi.1006110.ref053">53</xref>] (see <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>). LOO is our comparison metric of choice (see <xref ref-type="sec" rid="sec014">Discussion</xref>). LOO scores for all models and subjects are reported in <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>.</p>
<p>Finally, we approximated the <italic>marginal likelihood</italic> of the model,
<disp-formula id="pcbi.1006110.e061"><alternatives><graphic id="pcbi.1006110.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e061" xlink:type="simple"/><mml:math display="block" id="M61"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>,</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>|</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo> <mml:mi>d</mml:mi> <mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula></p>
<p>The marginal likelihood is a common metric of model evidence that naturally incorporates a penalty for model complexity due to Bayesian Occam razor [<xref ref-type="bibr" rid="pcbi.1006110.ref071">71</xref>]. However, the integral in <xref ref-type="disp-formula" rid="pcbi.1006110.e061">Eq 15</xref> is notoriously hard to evaluate. Here we computed an approximation of the log marginal likelihood (LML) based on MCMC samples from the posterior, by using a <italic>weighted</italic> harmonic mean estimator [<xref ref-type="bibr" rid="pcbi.1006110.ref074">74</xref>]. The formula for the approximation is
<disp-formula id="pcbi.1006110.e062"><alternatives><graphic id="pcbi.1006110.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e062" xlink:type="simple"/><mml:math display="block" id="M62"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mtext>LML</mml:mtext> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mo>(</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>S</mml:mi></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>s</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>S</mml:mi></mml:munderover> <mml:mfrac><mml:mrow><mml:mi>φ</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo> <mml:mi>L</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">θ</mml:mi></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>s</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(16)</label></disp-formula>
where the sum is over <italic>S</italic> samples from the posterior, <bold><italic>θ</italic></bold><sup>(<italic>s</italic>)</sup> is the <italic>s</italic>-th sample, <italic>p</italic>(<bold><italic>θ</italic></bold>) the prior, <italic>L</italic>(<bold><italic>θ</italic></bold>) the likelihood, and <italic>φ</italic>(<bold><italic>θ</italic></bold>) is an arbitrary weight probability density. The behavior of the approximation depends crucially on the choice of <italic>φ</italic>; it is important that <italic>φ</italic> has thinner tails than the posterior, lest the variance of the estimator grows unboundedly. We followed the suggestion of [<xref ref-type="bibr" rid="pcbi.1006110.ref074">74</xref>] and adopted a finite support distribution over a high posterior density region. We fitted a variational Gaussian mixture model to the posterior samples [<xref ref-type="bibr" rid="pcbi.1006110.ref098">98</xref>] (<ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/vbgmm" xlink:type="simple">https://github.com/lacerbi/vbgmm</ext-link>), and then we replaced each Gaussian component with a uniform distribution over an ellipsoid region proportional to the covariance matrix of the component. The proportionality constant, common to all components, was picked by minimizing the empirical variance of the sum in <xref ref-type="disp-formula" rid="pcbi.1006110.e062">Eq 16</xref> [<xref ref-type="bibr" rid="pcbi.1006110.ref075">75</xref>].</p>
</sec>
<sec id="sec038">
<title>Hierarchical Bayesian model selection</title>
<p>We performed Bayesian model selection at the group level via a hierarchical approach that treats subjects and models as random variables [<xref ref-type="bibr" rid="pcbi.1006110.ref054">54</xref>]. Group Bayesian Model Selection infers the posterior over model frequencies in the population, expressed as Dirichlet distributions parametrized by the concentration parameter vector <bold><italic>α</italic></bold>. As a summary statistic we consider the protected exceedance probability <inline-formula id="pcbi.1006110.e063"><alternatives><graphic id="pcbi.1006110.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e063" xlink:type="simple"/><mml:math display="inline" id="M63"><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, that is the probabilty that a given model or model factor is the most likely model or model factor, above and beyond chance [<xref ref-type="bibr" rid="pcbi.1006110.ref055">55</xref>]. For the <italic>i</italic>-th model or model factor,
<disp-formula id="pcbi.1006110.e064"><alternatives><graphic id="pcbi.1006110.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e064" xlink:type="simple"/><mml:math display="block" id="M64"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>φ</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>i</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mtext>BOR</mml:mtext> <mml:mo>)</mml:mo></mml:mrow> <mml:msub><mml:mi>φ</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>K</mml:mi></mml:mfrac> <mml:mtext>BOR</mml:mtext> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives></disp-formula>
where <italic>K</italic> is the number of models (or model factors), <italic>φ</italic><sub><italic>i</italic></sub> is the unprotected exceedance probability for the <italic>i</italic>-th model or model factor [<xref ref-type="bibr" rid="pcbi.1006110.ref054">54</xref>], and BOR is the Bayesian omnibus risk—the posterior probability that the data may be explained by the null hypothesis according to which all models (or model factors) have equal probability [<xref ref-type="bibr" rid="pcbi.1006110.ref055">55</xref>]. For completeness, we report posterior model frequencies and BOR in the figures, but we do not focus on model frequencies per se since our sample size does not afford a more detailed population analysis.</p>
<p>To compute the posterior over model factors in the population we exploit the agglomerative propery of the Dirichlet distribution, and sum the concentration parameters of models that belong to the same factor component [<xref ref-type="bibr" rid="pcbi.1006110.ref054">54</xref>]. While the agglomerative property allows to easily compute the posterior frequencies and the <italic>unprotected</italic> exceedance probabilities for each model factor, calculation of the protected exceedance probabilities required us to compute the BOR for the model factor setup (the probability that the observed differences in factor frequencies may have arisen due to chance).</p>
<p>Additionally, the group Bayesian Model Selection method requires to specify a Dirichlet prior over model frequencies, represented by a concentration parameter vector <italic>α</italic><sub>0</sub> · <bold><italic>w</italic></bold>, with <italic>w</italic><sub><italic>k</italic></sub> = 1 for any model <italic>k</italic> and <italic>α</italic><sub>0</sub> &gt; 0. The common choice is <italic>α</italic><sub>0</sub> = 1 (flat prior over model frequencies), but given the nature of our factorial analysis we prefer a flat prior over model factors (<italic>α</italic><sub>0</sub> = average number factors / number of models), where the average number of factors is ≈ 2.33 for the bisensory tasks and ≈ 2.67 for the joint fits. This choice entails that the concentration parameter of the agglomerate Dirichlet distributions, obtained by grouping models that belong to the same factor component, is of order ∼1 (it cannot be exactly one since different factors have different number of components). When factor components within the same factor had unequal numbers of models, we modified the prior weight vector <bold><italic>w</italic></bold> such that every component had equal prior weight. We verified that our main results did not depend on the specific choice of Dirichlet prior (<xref ref-type="fig" rid="pcbi.1006110.g007">Fig 7</xref>, third row).</p>
</sec>
<sec id="sec039">
<title>Parameter compatibility metric</title>
<p>Before performing the joint fits, we tested whether model parameters differed across the three tasks (unisensory and bisensory discrimination, unity judgment). On one end of the spectrum, the fully Bayesian approach would consist of comparing all combinations of models in which parameters are shared vs. distinct across tasks, and check which combination best explains the data. However, this approach is intractable in practice due to the combinatorial explosion of models, and undesirable in theory due to the risk model overfitting. On the simplest end of the spectrum, we could look at the credible intervals of the parameter posteriors for each subject and visually check whether they are mostly overlapping for different tasks.</p>
<p>As a middle ground, we computed separately for each parameter what we defined as the <italic>compatibility probability</italic> <italic>C</italic><sub><italic>p</italic></sub>, that is the probability that for most subjects the parameter is exactly the same across tasks (<italic>H</italic><sub>0</sub>), as opposed to being different (<italic>H</italic><sub>1</sub>), above and beyond chance.</p>
<p>For a given subject, let <italic>y</italic><sub>1</sub>, <italic>y</italic><sub>2</sub>, and <italic>y</italic><sub>3</sub> be the datasets of the three tasks. For a given parameter <italic>θ</italic> (e.g., lapse rate), we computed the compatibility likelihoods
<disp-formula id="pcbi.1006110.e065"><alternatives><graphic id="pcbi.1006110.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e065" xlink:type="simple"/><mml:math display="block" id="M65"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>H</mml:mi> <mml:mn>0</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>∫</mml:mo> <mml:mo>[</mml:mo> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>3</mml:mn></mml:munderover> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>θ</mml:mi> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>2</mml:mn></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mn>3</mml:mn></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi>H</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>3</mml:mn></mml:munderover> <mml:mo>[</mml:mo> <mml:mo>∫</mml:mo> <mml:msub><mml:mi>g</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi>y</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>θ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:mi>θ</mml:mi> <mml:mo>]</mml:mo> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(17)</label></disp-formula>
where <italic>g</italic><sub><italic>i</italic></sub>(<italic>θ</italic>|<italic>y</italic><sub><italic>i</italic></sub>) is the marginal posterior over <italic>θ</italic> for the dataset <italic>y</italic><sub><italic>i</italic></sub>, and <italic>f</italic>(<italic>θ</italic>) is the prior over <italic>θ</italic>. Having computed the compatibility likelihoods for all subjects, we defined <italic>C</italic><sub><italic>p</italic></sub> as the protected exceedance probability of model <italic>H</italic><sub>0</sub> vs. model <italic>H</italic><sub>1</sub> for the entire group.</p>
<p>For each subject and task, the marginal posteriors <italic>g</italic><sub><italic>i</italic></sub>(<italic>θ</italic>|<italic>y</italic><sub><italic>i</italic></sub>) were obtained as a weighted average over models, with weight equal to each model’s posterior probability for that subject according to the group Bayesian Model Selection method via LOO, and considering only the subset of models that include the parameter of interest (see <xref ref-type="fig" rid="pcbi.1006110.g005">Fig 5</xref>).</p>
<p>For the prior <italic>f</italic>(<italic>θ</italic>) over a given parameter <italic>θ</italic>, for the purposes of this analysis only, we followed an empirical Bayes approach informed by the data and use a truncated Cauchy prior fitted to the average marginal posterior of <italic>θ</italic> across subjects, defined over the range of the MCMC samples for <italic>θ</italic>.</p>
</sec>
<sec id="sec040">
<title>Absolute goodness of fit</title>
<p>Model comparison yields only a <italic>relative</italic> measure of goodness of fit, but does not convey any information of whether a model is a good description of the data in an absolute sense. A standard metric such as the coefficient of variation <italic>R</italic><sup>2</sup> is not appropriate for binary data. Instead, we extended the approach of [<xref ref-type="bibr" rid="pcbi.1006110.ref056">56</xref>] and defined <italic>absolute goodness of fit</italic> as
<disp-formula id="pcbi.1006110.e066"><alternatives><graphic id="pcbi.1006110.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e066" xlink:type="simple"/><mml:math display="block" id="M66"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>g</mml:mi> <mml:mo>(</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo> <mml:mo>≡</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>G</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>LOO</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>model</mml:mtext> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>G</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>N</mml:mi> <mml:mtext>trials</mml:mtext></mml:msub> <mml:mo form="prefix">log</mml:mo> <mml:mn>2</mml:mn></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(18)</label></disp-formula>
where <inline-formula id="pcbi.1006110.e067"><alternatives><graphic id="pcbi.1006110.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1006110.e067" xlink:type="simple"/><mml:math display="inline" id="M67"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>H</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mi>G</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mtext>data</mml:mtext> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is an estimate of the entropy of the data obtained via Grassberger’s estimator [<xref ref-type="bibr" rid="pcbi.1006110.ref099">99</xref>] and LOO(model) is the LOO score of the model of interest.</p>
<p>The numerator in <xref ref-type="disp-formula" rid="pcbi.1006110.e066">Eq 18</xref> represents the Kullback-Leibler (KL) divergence between the distribution of the data and the distribution predicted by the model (that is, how well the model captures the data), which is compared as a reference to the KL divergence between the data and a chance model (at the denominator). See <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref> for a derivation of <xref ref-type="disp-formula" rid="pcbi.1006110.e066">Eq 18</xref>, and code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/gofit" xlink:type="simple">https://github.com/lacerbi/gofit</ext-link>.</p>
</sec>
</sec>
<sec id="sec041">
<title>The cookbook</title>
<p>The Bayesian cookbook for causal inference in multisensory perception, or simply ‘the cookbook’, consists of a recipe to build causal inference observer models for multisensory perception, and a number of algorithms and computational techniques to perform efficient and robust Bayesian comparison of such models. We applied and demonstrated these methods at different points in the main text; further details can be found here in the Methods and <xref ref-type="supplementary-material" rid="pcbi.1006110.s002">S1 Appendix</xref>. For reference, we summarize the main techniques of interest in <xref ref-type="table" rid="pcbi.1006110.t003">Table 3</xref>.</p>
<table-wrap id="pcbi.1006110.t003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1006110.t003</object-id>
<label>Table 3</label>
<caption>
<title>List of algorithms and computational procedures.</title>
</caption>
<alternatives>
<graphic id="pcbi.1006110.t003g" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.t003" xlink:type="simple"/>
<table border="0" frame="box" rules="all">
<colgroup>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
<col align="left" valign="middle"/>
</colgroup>
<thead>
<tr>
<th align="left" style="border-bottom:thick">Description</th>
<th align="left" style="border-bottom:thick">Code</th>
<th align="center" style="border-bottom:thick">References</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left"><italic>Model fitting</italic></td>
<td align="left"/>
<td align="center"/>
</tr>
<tr>
<td align="left">Efficient computation of log likelihood</td>
<td align="left">
<ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/visvest-causinf" xlink:type="simple">https://github.com/lacerbi/visvest-causinf</ext-link>
</td>
<td align="center">This work</td>
</tr>
<tr>
<td align="left">Maximum-likelihood estimation (optimization)</td>
<td align="left">
<ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/bads" xlink:type="simple">https://github.com/lacerbi/bads</ext-link>
</td>
<td align="center">[<xref ref-type="bibr" rid="pcbi.1006110.ref078">78</xref>]</td>
</tr>
<tr>
<td align="left">Posterior estimation (MCMC sampling)</td>
<td align="left">
<ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/eissample" xlink:type="simple">https://github.com/lacerbi/eissample</ext-link>
</td>
<td align="center">In preparation</td>
</tr>
<tr>
<td align="left"><italic>Model evaluation and comparison</italic></td>
<td align="left"/>
<td align="center"/>
</tr>
<tr>
<td align="left">Leave-one-out cross validation (LOO)</td>
<td align="left">
<ext-link ext-link-type="uri" xlink:href="https://github.com/avehtari/PSIS" xlink:type="simple">https://github.com/avehtari/PSIS</ext-link>
</td>
<td align="center">[<xref ref-type="bibr" rid="pcbi.1006110.ref052">52</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref053">53</xref>]</td>
</tr>
<tr>
<td align="left">Estimate of the marginal likelihood</td>
<td align="left">
<ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/marglike" xlink:type="simple">https://github.com/lacerbi/marglike</ext-link>
</td>
<td align="center">[<xref ref-type="bibr" rid="pcbi.1006110.ref074">74</xref>], in preparation</td>
</tr>
<tr>
<td align="left">Parameter compatibility test</td>
<td align="left">
<ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/comprob" xlink:type="simple">https://github.com/lacerbi/comprob</ext-link>
</td>
<td align="center">This work</td>
</tr>
<tr>
<td align="left">Objective goodness of fit</td>
<td align="left">
<ext-link ext-link-type="uri" xlink:href="https://github.com/lacerbi/gofit" xlink:type="simple">https://github.com/lacerbi/gofit</ext-link>
</td>
<td align="center">[<xref ref-type="bibr" rid="pcbi.1006110.ref056">56</xref>], this work</td>
</tr>
<tr>
<td align="left">Group Bayesian Model Selection</td>
<td align="left"><italic>spm_BMS</italic> function in the SPM12 package<break/><ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/" xlink:type="simple">http://www.fil.ion.ucl.ac.uk/spm/</ext-link></td>
<td align="center">[<xref ref-type="bibr" rid="pcbi.1006110.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1006110.ref055">55</xref>]</td>
</tr>
</tbody>
</table>
</alternatives>
<table-wrap-foot>
<fn id="t003fn001">
<p>List of useful algorithms and computational procedures.</p>
</fn>
</table-wrap-foot>
</table-wrap>
</sec>
</sec>
<sec id="sec042">
<title>Supporting information</title>
<supplementary-material id="pcbi.1006110.s001" mimetype="image/tiff" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.s001" xlink:type="simple">
<label>S1 Fig</label>
<caption>
<title>Explicit causal inference; model fits of full data.</title>
<p>Results of the explicit causal inference (unity judgment) task, for two models of interest. Proportion of ‘unity’ responses for a given (<italic>s</italic><sub>vis</sub>, <italic>s</italic><sub>vest</sub>) heading direction pair (indexed from 1 to 99), and for different levels of visual cue reliability. Points are data, lines are model fits (average fit across subjects). Error bars are omitted for clarity. <bold>A</bold>: Best Bayesian model (Bay-X-E). <bold>B</bold>: Best fixed-criterion model (Fix-C). Neither model appears clearly superior across all noise levels (see main text).</p>
<p>(TIF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1006110.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1006110.s002" xlink:type="simple">
<label>S1 Appendix</label>
<caption>
<title>Supplemental methods.</title>
<p>Cookbook for causal inference observers. Observer model factors. Comparison between wrapped normal and von Mises noise. Computational details. Absolute goodness of fit. LOO scores for all subjects and models.</p>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>We thank Bas van Opheusden and Shan Shen for useful discussions about absolute goodness of fit. This work has utilized the NYU IT High Performance Computing resources and services.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1006110.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hillis</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>. <article-title>Combining sensory information: Mandatory fusion within, but not between, senses</article-title>. <source>Science</source>. <year>2002</year>;<volume>298</volume>(<issue>5598</issue>):<fpage>1627</fpage>–<lpage>1630</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.1075396" xlink:type="simple">10.1126/science.1075396</ext-link></comment> <object-id pub-id-type="pmid">12446912</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Nardini</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bedford</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Mareschal</surname> <given-names>D</given-names></name>. <article-title>Fusion of visual cues is not mandatory in children</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2010</year>;<volume>107</volume>(<issue>39</issue>):<fpage>17041</fpage>–<lpage>17046</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1001699107" xlink:type="simple">10.1073/pnas.1001699107</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jacobs</surname> <given-names>RA</given-names></name>. <article-title>Optimal integration of texture and motion cues to depth</article-title>. <source>Vision Research</source>. <year>1999</year>;<volume>39</volume>(<issue>21</issue>):<fpage>3621</fpage>–<lpage>3629</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(99)00088-7" xlink:type="simple">10.1016/S0042-6989(99)00088-7</ext-link></comment> <object-id pub-id-type="pmid">10746132</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>Humans integrate visual and haptic information in a statistically optimal fashion</article-title>. <source>Nature</source>. <year>2002</year>;<volume>415</volume>(<issue>6870</issue>):<fpage>429</fpage>–<lpage>433</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/415429a" xlink:type="simple">10.1038/415429a</ext-link></comment> <object-id pub-id-type="pmid">11807554</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Saunders</surname> <given-names>JA</given-names></name>. <article-title>Do humans optimally integrate stereo and texture information for judgments of surface slant?</article-title> <source>Vision Research</source>. <year>2003</year>;<volume>43</volume>(<issue>24</issue>):<fpage>2539</fpage>–<lpage>2558</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0042-6989(03)00458-9" xlink:type="simple">10.1016/S0042-6989(03)00458-9</ext-link></comment> <object-id pub-id-type="pmid">13129541</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Alais</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Burr</surname> <given-names>D</given-names></name>. <article-title>The ventriloquist effect results from near-optimal bimodal integration</article-title>. <source>Current Biology</source>. <year>2004</year>;<volume>14</volume>(<issue>3</issue>):<fpage>257</fpage>–<lpage>262</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.cub.2004.01.029" xlink:type="simple">10.1016/j.cub.2004.01.029</ext-link></comment> <object-id pub-id-type="pmid">14761661</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hillis</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Watt</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Banks</surname> <given-names>MS</given-names></name>. <article-title>Slant from texture and disparity cues: Optimal cue combination</article-title>. <source>Journal of Vision</source>. <year>2004</year>;<volume>4</volume>(<issue>12</issue>):<fpage>967</fpage>–<lpage>992</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/4.12.1" xlink:type="simple">10.1167/4.12.1</ext-link></comment> <object-id pub-id-type="pmid">15669906</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Helbig</surname> <given-names>HB</given-names></name>, <name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>. <article-title>Optimal integration of shape information from vision and touch</article-title>. <source>Experimental Brain Research</source>. <year>2007</year>;<volume>179</volume>(<issue>4</issue>):<fpage>595</fpage>–<lpage>606</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00221-006-0814-y" xlink:type="simple">10.1007/s00221-006-0814-y</ext-link></comment> <object-id pub-id-type="pmid">17225091</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fetsch</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Turner</surname> <given-names>AH</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>. <article-title>Dynamic reweighting of visual and vestibular cues during self-motion perception</article-title>. <source>The Journal of Neuroscience</source>. <year>2009</year>;<volume>29</volume>(<issue>49</issue>):<fpage>15601</fpage>–<lpage>15612</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2574-09.2009" xlink:type="simple">10.1523/JNEUROSCI.2574-09.2009</ext-link></comment> <object-id pub-id-type="pmid">20007484</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Butler</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>ST</given-names></name>, <name name-style="western"><surname>Campos</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Bülthoff</surname> <given-names>HH</given-names></name>. <article-title>Bayesian integration of visual and vestibular signals for heading</article-title>. <source>Journal of Vision</source>. <year>2010</year>;<volume>10</volume>(<issue>11</issue>):<fpage>1</fpage>–<lpage>23</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/10.11.23" xlink:type="simple">10.1167/10.11.23</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>de Winkel</surname> <given-names>KN</given-names></name>, <name name-style="western"><surname>Weesie</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Werkhoven</surname> <given-names>PJ</given-names></name>, <name name-style="western"><surname>Groen</surname> <given-names>EL</given-names></name>. <article-title>Integration of visual and inertial cues in perceived heading of self-motion</article-title>. <source>Journal of Vision</source>. <year>2010</year>;<volume>10</volume>(<issue>12</issue>):<fpage>1</fpage>–<lpage>10</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/10.12.1" xlink:type="simple">10.1167/10.12.1</ext-link></comment> <object-id pub-id-type="pmid">21047733</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Butler</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Campos</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Bülthoff</surname> <given-names>HH</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>ST</given-names></name>. <article-title>The role of stereo vision in visual–vestibular integration</article-title>. <source>Seeing and perceiving</source>. <year>2011</year>;<volume>24</volume>(<issue>5</issue>):<fpage>453</fpage>–<lpage>470</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1163/187847511X588070" xlink:type="simple">10.1163/187847511X588070</ext-link></comment> <object-id pub-id-type="pmid">21888763</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dokka</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>MacNeilage</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>. <article-title>Multisensory self-motion compensation during object trajectory judgments</article-title>. <source>Cerebral Cortex</source>. <year>2015</year>;<volume>25</volume>(<issue>3</issue>):<fpage>619</fpage>–<lpage>630</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bht247" xlink:type="simple">10.1093/cercor/bht247</ext-link></comment> <object-id pub-id-type="pmid">24062317</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dokka</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>. <article-title>Multisensory Integration of Visual and Vestibular Signals Improves Heading Discrimination in the Presence of a Moving Object</article-title>. <source>The Journal of Neuroscience</source>. <year>2015</year>;<volume>35</volume>(<issue>40</issue>):<fpage>13599</fpage>–<lpage>13607</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.2267-15.2015" xlink:type="simple">10.1523/JNEUROSCI.2267-15.2015</ext-link></comment> <object-id pub-id-type="pmid">26446214</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brandwein</surname> <given-names>AB</given-names></name>, <name name-style="western"><surname>Foxe</surname> <given-names>JJ</given-names></name>, <name name-style="western"><surname>Butler</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Russo</surname> <given-names>NN</given-names></name>, <name name-style="western"><surname>Altschuler</surname> <given-names>TS</given-names></name>, <name name-style="western"><surname>Gomes</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>The development of multisensory integration in high-functioning autism: High-density electrical mapping and psychophysical measures reveal impairments in the processing of audiovisual inputs</article-title>. <source>Cerebral Cortex</source>. <year>2012</year>;<volume>23</volume>(<issue>6</issue>):<fpage>1329</fpage>–<lpage>1341</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/cercor/bhs109" xlink:type="simple">10.1093/cercor/bhs109</ext-link></comment> <object-id pub-id-type="pmid">22628458</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stewart</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Sanchez</surname> <given-names>SS</given-names></name>, <name name-style="western"><surname>Grenesko</surname> <given-names>EL</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>CP</given-names></name>, <name name-style="western"><surname>Keehn</surname> <given-names>B</given-names></name>, <etal>et al</etal>. <article-title>Sensory symptoms and processing of nonverbal auditory and visual stimuli in children with autism spectrum disorder</article-title>. <source>Journal of autism and developmental disorders</source>. <year>2016</year>;<volume>46</volume>(<issue>5</issue>):<fpage>1590</fpage>–<lpage>1601</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10803-015-2367-z" xlink:type="simple">10.1007/s10803-015-2367-z</ext-link></comment> <object-id pub-id-type="pmid">25652601</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Calvert</surname> <given-names>GA</given-names></name>, <name name-style="western"><surname>Brammer</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Iversen</surname> <given-names>SD</given-names></name>. <article-title>Crossmodal identification</article-title>. <source>Trends in cognitive sciences</source>. <year>1998</year>;<volume>2</volume>(<issue>7</issue>):<fpage>247</fpage>–<lpage>253</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1364-6613(98)01189-9" xlink:type="simple">10.1016/S1364-6613(98)01189-9</ext-link></comment> <object-id pub-id-type="pmid">21244923</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Körding</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Quartz</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Tenenbaum</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>. <article-title>Causal inference in multisensory perception</article-title>. <source>PLoS ONE</source>. <year>2007</year>;<volume>2</volume>(<issue>9</issue>):<fpage>e943</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0000943" xlink:type="simple">10.1371/journal.pone.0000943</ext-link></comment> <object-id pub-id-type="pmid">17895984</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sato</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Toyoizumi</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Aihara</surname> <given-names>K</given-names></name>. <article-title>Bayesian inference explains perception of unity and ventriloquism aftereffect: Identification of common sources of audiovisual stimuli</article-title>. <source>Neural Computation</source>. <year>2007</year>;<volume>19</volume>(<issue>12</issue>):<fpage>3335</fpage>–<lpage>3355</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco.2007.19.12.3335" xlink:type="simple">10.1162/neco.2007.19.12.3335</ext-link></comment> <object-id pub-id-type="pmid">17970656</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rohe</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Noppeney</surname> <given-names>U</given-names></name>. <article-title>Cortical hierarchies perform Bayesian causal inference in multisensory perception</article-title>. <source>PLoS Biol</source>. <year>2015</year>;<volume>13</volume>(<issue>2</issue>):<fpage>e1002073</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pbio.1002073" xlink:type="simple">10.1371/journal.pbio.1002073</ext-link></comment> <object-id pub-id-type="pmid">25710328</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rohe</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Noppeney</surname> <given-names>U</given-names></name>. <article-title>Sensory reliability shapes perceptual inference via two mechanisms</article-title>. <source>Journal of Vision</source>. <year>2015</year>;<volume>15</volume>(<issue>5</issue>):<fpage>1</fpage>–<lpage>22</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/15.5.22" xlink:type="simple">10.1167/15.5.22</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Odegaard</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wozny</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>. <article-title>Biases in visual, auditory, and audiovisual perception of space</article-title>. <source>PLoS Comput Biol</source>. <year>2015</year>;<volume>11</volume>(<issue>12</issue>):<fpage>e1004649</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1004649" xlink:type="simple">10.1371/journal.pcbi.1004649</ext-link></comment> <object-id pub-id-type="pmid">26646312</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Odegaard</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>. <article-title>The Brain’s Tendency to Bind Audiovisual Signals Is Stable but Not General</article-title>. <source>Psychological Science</source>. <year>2016</year>;<volume>27</volume>(<issue>4</issue>):<fpage>583</fpage>–<lpage>591</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1177/0956797616628860" xlink:type="simple">10.1177/0956797616628860</ext-link></comment> <object-id pub-id-type="pmid">26944861</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wozny</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>. <article-title>Probability matching as a computational strategy used in perception</article-title>. <source>PLoS Computational Biology</source>. <year>2010</year>;<volume>6</volume>(<issue>8</issue>):<fpage>e1000871</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1000871" xlink:type="simple">10.1371/journal.pcbi.1000871</ext-link></comment> <object-id pub-id-type="pmid">20700493</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wozny</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>. <article-title>Computational characterization of visually induced auditory spatial adaptation</article-title>. <source>Frontiers in Integrative Neuroscience</source>. <year>2011</year>;<volume>5</volume>:<fpage>75</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fnint.2011.00075" xlink:type="simple">10.3389/fnint.2011.00075</ext-link></comment> <object-id pub-id-type="pmid">22069383</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bejjanki</surname> <given-names>VR</given-names></name>, <name name-style="western"><surname>Knill</surname> <given-names>DC</given-names></name>, <name name-style="western"><surname>Aslin</surname> <given-names>RN</given-names></name>. <article-title>Learning and inference using complex generative models in a spatial localization task</article-title>. <source>Journal of Vision</source>. <year>2016</year>;<volume>16</volume>(<issue>5</issue>):<fpage>1</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/16.5.9" xlink:type="simple">10.1167/16.5.9</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name>, <name name-style="western"><surname>Quartz</surname> <given-names>SR</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>. <article-title>Bayesian priors are encoded independently from likelihoods in human multisensory perception</article-title>. <source>Journal of Vision</source>. <year>2009</year>;<volume>9</volume>(<issue>5</issue>):<fpage>1</fpage>–<lpage>9</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/9.5.23" xlink:type="simple">10.1167/9.5.23</ext-link></comment> <object-id pub-id-type="pmid">19757901</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Vogel</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Josić</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Optimal inference of sameness</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2012</year>;<volume>109</volume>(<issue>8</issue>):<fpage>3178</fpage>–<lpage>3183</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1108790109" xlink:type="simple">10.1073/pnas.1108790109</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Hospedales</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Vijayakumar</surname> <given-names>S</given-names></name>. <article-title>Multisensory oddity detection as Bayesian inference</article-title>. <source>PLoS ONE</source>. <year>2009</year>;<volume>4</volume>(<issue>1</issue>):<fpage>e4205</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0004205" xlink:type="simple">10.1371/journal.pone.0004205</ext-link></comment> <object-id pub-id-type="pmid">19145254</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Magnotti</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Beauchamp</surname> <given-names>MS</given-names></name>. <article-title>Causal inference of asynchronous audiovisual speech</article-title>. <source>Frontiers in Psychology</source>. <year>2013</year>;<volume>4</volume>:<fpage>798</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3389/fpsyg.2013.00798" xlink:type="simple">10.3389/fpsyg.2013.00798</ext-link></comment> <object-id pub-id-type="pmid">24294207</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sawai</surname> <given-names>Ki</given-names></name>, <name name-style="western"><surname>Sato</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Aihara</surname> <given-names>K</given-names></name>. <article-title>Auditory time-interval perception as causal inference on sound sources</article-title>. <source>Frontiers in Psychology</source>. <year>2012</year>;<volume>3</volume>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref032">
<label>32</label>
<mixed-citation publication-type="other" xlink:type="simple">Zhou Y, Acerbi L, Ma WJ. The Role of Sensory Uncertainty in Simple Perceptual Organization. bioRxiv. 2018; p. 350082.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>de Winkel</surname> <given-names>KN</given-names></name>, <name name-style="western"><surname>Katliar</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bülthoff</surname> <given-names>HH</given-names></name>. <article-title>Forced fusion in multisensory heading estimation</article-title>. <source>PLoS ONE</source>. <year>2015</year>;<volume>10</volume>(<issue>5</issue>):<fpage>e0127104</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0127104" xlink:type="simple">10.1371/journal.pone.0127104</ext-link></comment> <object-id pub-id-type="pmid">25938235</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>de Winkel</surname> <given-names>KN</given-names></name>, <name name-style="western"><surname>Katliar</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bülthoff</surname> <given-names>HH</given-names></name>. <article-title>Causal Inference in Multisensory Heading Estimation</article-title>. <source>PLoS ONE</source>. <year>2017</year>;<volume>12</volume>(<issue>1</issue>):<fpage>e0169676</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0169676" xlink:type="simple">10.1371/journal.pone.0169676</ext-link></comment> <object-id pub-id-type="pmid">28060957</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Organizing probabilistic models of perception</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2012</year>;<volume>16</volume>(<issue>10</issue>):<fpage>511</fpage>–<lpage>518</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2012.08.010" xlink:type="simple">10.1016/j.tics.2012.08.010</ext-link></comment> <object-id pub-id-type="pmid">22981359</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Qamar</surname> <given-names>AT</given-names></name>, <name name-style="western"><surname>Cotton</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>RG</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Prezhdo</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Laudano</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>Trial-to-trial, uncertainty-based adjustment of decision boundaries in visual categorization</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2013</year>;<volume>110</volume>(<issue>50</issue>):<fpage>20332</fpage>–<lpage>20337</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1073/pnas.1219756110" xlink:type="simple">10.1073/pnas.1219756110</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref037">
<label>37</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Vijayakumar</surname> <given-names>S</given-names></name>. <chapter-title>A Framework for Testing Identifiability of Bayesian Models of Perception</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source> <volume>27</volume>. <publisher-name>Curran Associates, Inc.</publisher-name>; <year>2014</year>. p. <fpage>1026</fpage>–<lpage>1034</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>Gu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>. <article-title>Multisensory integration: Psychophysics, neurophysiology, and computation</article-title>. <source>Current opinion in neurobiology</source>. <year>2009</year>;<volume>19</volume>(<issue>4</issue>):<fpage>452</fpage>–<lpage>458</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2009.06.008" xlink:type="simple">10.1016/j.conb.2009.06.008</ext-link></comment> <object-id pub-id-type="pmid">19616425</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref039">
<label>39</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Beierholm</surname> <given-names>UR</given-names></name>. <article-title>Causal inference in perception</article-title>. <source>Trends in cognitive sciences</source>. <year>2010</year>;<volume>14</volume>(<issue>9</issue>):<fpage>425</fpage>–<lpage>432</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2010.07.001" xlink:type="simple">10.1016/j.tics.2010.07.001</ext-link></comment> <object-id pub-id-type="pmid">20705502</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref040">
<label>40</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Colonius</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Diederich</surname> <given-names>A</given-names></name>. <article-title>Formal models and quantitative measures of multisensory integration: a selective overview</article-title>. <source>European Journal of Neuroscience</source>. <year>2018</year>;. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/ejn.13813" xlink:type="simple">10.1111/ejn.13813</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>de Winkel</surname> <given-names>KN</given-names></name>, <name name-style="western"><surname>Soyka</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Barnett-Cowan</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bülthoff</surname> <given-names>HH</given-names></name>, <name name-style="western"><surname>Groen</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Werkhoven</surname> <given-names>P</given-names></name>. <article-title>Integration of visual and inertial cues in the perception of angular self-motion</article-title>. <source>Experimental Brain Research</source>. <year>2013</year>;<volume>231</volume>(<issue>2</issue>):<fpage>209</fpage>–<lpage>218</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00221-013-3683-1" xlink:type="simple">10.1007/s00221-013-3683-1</ext-link></comment> <object-id pub-id-type="pmid">24013788</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>. <article-title>Neural correlates of multisensory cue integration in macaque MSTd</article-title>. <source>Nature Neuroscience</source>. <year>2008</year>;<volume>11</volume>(<issue>10</issue>):<fpage>1201</fpage>–<lpage>1210</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2191" xlink:type="simple">10.1038/nn.2191</ext-link></comment> <object-id pub-id-type="pmid">18776893</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref043">
<label>43</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Prsa</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gale</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Blanke</surname> <given-names>O</given-names></name>. <article-title>Self-motion leads to mandatory cue fusion across sensory modalities</article-title>. <source>Journal of Neurophysiology</source>. <year>2012</year>;<volume>108</volume>(<issue>8</issue>):<fpage>2282</fpage>–<lpage>2291</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00439.2012" xlink:type="simple">10.1152/jn.00439.2012</ext-link></comment> <object-id pub-id-type="pmid">22832567</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref044">
<label>44</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chen</surname> <given-names>SY</given-names></name>, <name name-style="western"><surname>Ross</surname> <given-names>BH</given-names></name>, <name name-style="western"><surname>Murphy</surname> <given-names>GL</given-names></name>. <article-title>Implicit and explicit processes in category-based induction: Is induction best when we don’t think?</article-title> <source>Journal of Experimental Psychology: General</source>. <year>2014</year>;<volume>143</volume>(<issue>1</issue>):<fpage>227</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0032064" xlink:type="simple">10.1037/a0032064</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref045">
<label>45</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Evans</surname> <given-names>JSB</given-names></name>. <article-title>Dual-processing accounts of reasoning, judgment, and social cognition</article-title>. <source>Annu Rev Psychol</source>. <year>2008</year>;<volume>59</volume>:<fpage>255</fpage>–<lpage>278</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1146/annurev.psych.59.103006.093629" xlink:type="simple">10.1146/annurev.psych.59.103006.093629</ext-link></comment> <object-id pub-id-type="pmid">18154502</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref046">
<label>46</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Trommershäuser</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Maloney</surname> <given-names>LT</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>. <chapter-title>The expected utility of movement</chapter-title>. In: <name name-style="western"><surname>Glimcher</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Fehr</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Camerer</surname> <given-names>CF</given-names></name>, <name name-style="western"><surname>Poldrack</surname> <given-names>RA</given-names></name>, editors. <source>Neuroeconomics: Decision making and the brain</source>. <publisher-name>Academic Press</publisher-name>; <year>2008</year>. p. <fpage>95</fpage>–<lpage>111</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wallace</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Roberson</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Hairston</surname> <given-names>WD</given-names></name>, <name name-style="western"><surname>Stein</surname> <given-names>BE</given-names></name>, <name name-style="western"><surname>Vaughan</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Schirillo</surname> <given-names>JA</given-names></name>. <article-title>Unifying multisensory signals across time and space</article-title>. <source>Experimental Brain Research</source>. <year>2004</year>;<volume>158</volume>(<issue>2</issue>):<fpage>252</fpage>–<lpage>258</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00221-004-1899-9" xlink:type="simple">10.1007/s00221-004-1899-9</ext-link></comment> <object-id pub-id-type="pmid">15112119</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>, <name name-style="western"><surname>Vijayakumar</surname> <given-names>S</given-names></name>. <article-title>Internal representations of temporal statistics and feedback calibrate motor-sensory interval timing</article-title>. <source>PLoS Computational Biology</source>. <year>2012</year>;<volume>8</volume>(<issue>11</issue>):<fpage>e1002771</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1002771" xlink:type="simple">10.1371/journal.pcbi.1002771</ext-link></comment> <object-id pub-id-type="pmid">23209386</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Vijayakumar</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Wolpert</surname> <given-names>DM</given-names></name>. <article-title>On the Origins of Suboptimality in Human Probabilistic Inference</article-title>. <source>PLoS Computational Biology</source>. <year>2014</year>;<volume>10</volume>(<issue>6</issue>):<fpage>e1003661</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003661" xlink:type="simple">10.1371/journal.pcbi.1003661</ext-link></comment> <object-id pub-id-type="pmid">24945142</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Awh</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Factorial comparison of working memory models</article-title>. <source>Psychological Review</source>. <year>2014</year>;<volume>121</volume>(<issue>1</issue>):<fpage>124</fpage>–<lpage>149</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/a0035234" xlink:type="simple">10.1037/a0035234</ext-link></comment> <object-id pub-id-type="pmid">24490791</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref051">
<label>51</label>
<mixed-citation publication-type="other" xlink:type="simple">Huszár F, Noppeney U, Lengyel M. Mind reading by machine learning: A doubly Bayesian method for inferring mental representations. In: Proceedings of the Thirty-Second Annual Conference of the Cognitive Science Society; 2010. p. 2810–2815.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref052">
<label>52</label>
<mixed-citation publication-type="other" xlink:type="simple">Vehtari A, Gelman A, Gabry J. Pareto smoothed importance sampling. arXiv preprint arXiv:150702646. 2015;.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vehtari</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gelman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Gabry</surname> <given-names>J</given-names></name>. <article-title>Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC</article-title>. <source>Statistics and Computing</source>. <year>2016</year>; p. <fpage>1</fpage>–<lpage>20</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref054">
<label>54</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Penny</surname> <given-names>WD</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Moran</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>. <article-title>Bayesian model selection for group studies</article-title>. <source>Neuroimage</source>. <year>2009</year>;<volume>46</volume>(<issue>4</issue>):<fpage>1004</fpage>–<lpage>1017</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2009.03.025" xlink:type="simple">10.1016/j.neuroimage.2009.03.025</ext-link></comment> <object-id pub-id-type="pmid">19306932</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Rigoux</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>. <article-title>Bayesian model selection for group studies—revisited</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>84</volume>:<fpage>971</fpage>–<lpage>985</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2013.08.065" xlink:type="simple">10.1016/j.neuroimage.2013.08.065</ext-link></comment> <object-id pub-id-type="pmid">24018303</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shen</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>A detailed comparison of optimality and simplicity in perceptual decision making</article-title>. <source>Psychological Review</source>. <year>2016</year>;<volume>123</volume>(<issue>4</issue>):<fpage>452</fpage>–<lpage>480</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1037/rev0000028" xlink:type="simple">10.1037/rev0000028</ext-link></comment> <object-id pub-id-type="pmid">27177259</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kass</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Raftery</surname> <given-names>AE</given-names></name>. <article-title>Bayes factors</article-title>. <source>Journal of the American Statistical Association</source>. <year>1995</year>;<volume>90</volume>(<issue>430</issue>):<fpage>773</fpage>–<lpage>795</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/01621459.1995.10476572" xlink:type="simple">10.1080/01621459.1995.10476572</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref058">
<label>58</label>
<mixed-citation publication-type="other" xlink:type="simple">Gelman A, Loken E. The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research hypothesis was posited ahead of time; 2013.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kaliuzhna</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Prsa</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Gale</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>SJ</given-names></name>, <name name-style="western"><surname>Blanke</surname> <given-names>O</given-names></name>. <article-title>Learning to integrate contradictory multisensory self-motion cue pairings</article-title>. <source>Journal of Vision</source>. <year>2015</year>;<volume>15</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>10</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/15.1.10" xlink:type="simple">10.1167/15.1.10</ext-link></comment> <object-id pub-id-type="pmid">25589294</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref060">
<label>60</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Campos</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Siegle</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Mohler</surname> <given-names>BJ</given-names></name>, <name name-style="western"><surname>Bülthoff</surname> <given-names>HH</given-names></name>, <name name-style="western"><surname>Loomis</surname> <given-names>JM</given-names></name>. <article-title>Imagined self-motion differs from perceived self-motion: evidence from a novel continuous pointing method</article-title>. <source>PLoS ONE</source>. <year>2009</year>;<volume>4</volume>(<issue>11</issue>):<fpage>e7793</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0007793" xlink:type="simple">10.1371/journal.pone.0007793</ext-link></comment> <object-id pub-id-type="pmid">19907655</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Odegaard</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Wozny</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Shams</surname> <given-names>L</given-names></name>. <article-title>A simple and efficient method to enhance audiovisual binding tendencies</article-title>. <source>PeerJ</source>. <year>2017</year>;<volume>5</volume>:<fpage>e3143</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7717/peerj.3143" xlink:type="simple">10.7717/peerj.3143</ext-link></comment> <object-id pub-id-type="pmid">28462016</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref062">
<label>62</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ernst</surname> <given-names>MO</given-names></name>, <name name-style="western"><surname>Bülthoff</surname> <given-names>HH</given-names></name>. <article-title>Merging the senses into a robust percept</article-title>. <source>Trends in Cognitive Sciences</source>. <year>2004</year>;<volume>8</volume>(<issue>4</issue>):<fpage>162</fpage>–<lpage>169</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.tics.2004.02.002" xlink:type="simple">10.1016/j.tics.2004.02.002</ext-link></comment> <object-id pub-id-type="pmid">15050512</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>, <name name-style="western"><surname>Navalpakkam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Beck</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Van Den Berg</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Pouget</surname> <given-names>A</given-names></name>. <article-title>Behavior and neural basis of near-optimal visual search</article-title>. <source>Nature Neuroscience</source>. <year>2011</year>;<volume>14</volume>(<issue>6</issue>):<fpage>783</fpage>–<lpage>790</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2814" xlink:type="simple">10.1038/nn.2814</ext-link></comment> <object-id pub-id-type="pmid">21552276</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref064">
<label>64</label>
<mixed-citation publication-type="other" xlink:type="simple">Adler WT, Ma WJ. Comparing Bayesian and non-Bayesian accounts of human confidence reports. bioRxiv. 2016;</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Piironen</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Vehtari</surname> <given-names>A</given-names></name>. <article-title>Comparison of Bayesian predictive methods for model selection</article-title>. <source>Statistics and Computing</source>. <year>2016</year>; p. <fpage>1</fpage>–<lpage>25</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref066">
<label>66</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Gelman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Carlin</surname> <given-names>JB</given-names></name>, <name name-style="western"><surname>Stern</surname> <given-names>HS</given-names></name>, <name name-style="western"><surname>Dunson</surname> <given-names>DB</given-names></name>, <name name-style="western"><surname>Vehtari</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Rubin</surname> <given-names>DB</given-names></name>. <source>Bayesian data analysis</source> (<edition>3rd edition</edition>). <publisher-name>CRC Press</publisher-name>; <year>2013</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Friston</surname> <given-names>KJ</given-names></name>, <name name-style="western"><surname>Litvak</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Oswal</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Razi</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Stephan</surname> <given-names>KE</given-names></name>, <name name-style="western"><surname>van Wijk</surname> <given-names>BC</given-names></name>, <etal>et al</etal>. <article-title>Bayesian model reduction and empirical Bayes for group (DCM) studies</article-title>. <source>Neuroimage</source>. <year>2016</year>;<volume>128</volume>:<fpage>413</fpage>–<lpage>431</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2015.11.015" xlink:type="simple">10.1016/j.neuroimage.2015.11.015</ext-link></comment> <object-id pub-id-type="pmid">26569570</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref068">
<label>68</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Burnham</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>DR</given-names></name>. <source>Model selection and multimodel inference: A practical information-theoretic approach</source>. <publisher-name>Springer Science &amp; Business Media</publisher-name>; <year>2003</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Spiegelhalter</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Best</surname> <given-names>NG</given-names></name>, <name name-style="western"><surname>Carlin</surname> <given-names>BP</given-names></name>, <name name-style="western"><surname>Van Der Linde</surname> <given-names>A</given-names></name>. <article-title>Bayesian measures of model complexity and fit</article-title>. <source>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</source>. <year>2002</year>;<volume>64</volume>(<issue>4</issue>):<fpage>583</fpage>–<lpage>639</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/1467-9868.00353" xlink:type="simple">10.1111/1467-9868.00353</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Watanabe</surname> <given-names>S</given-names></name>. <article-title>Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory</article-title>. <source>Journal of Machine Learning Research</source>. <year>2010</year>;<volume>11</volume>(<issue>Dec</issue>):<fpage>3571</fpage>–<lpage>3594</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref071">
<label>71</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>MacKay</surname> <given-names>DJ</given-names></name>. <source>Information theory, inference and learning algorithms</source>. <publisher-name>Cambridge university press</publisher-name>; <year>2003</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gelman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hwang</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Vehtari</surname> <given-names>A</given-names></name>. <article-title>Understanding predictive information criteria for Bayesian models</article-title>. <source>Statistics and Computing</source>. <year>2014</year>;<volume>24</volume>(<issue>6</issue>):<fpage>997</fpage>–<lpage>1016</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s11222-013-9416-2" xlink:type="simple">10.1007/s11222-013-9416-2</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Verdinelli</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Wasserman</surname> <given-names>L</given-names></name>. <article-title>Computing Bayes factors using a generalization of the Savage-Dickey density ratio</article-title>. <source>Journal of the American Statistical Association</source>. <year>1995</year>;<volume>90</volume>(<issue>430</issue>):<fpage>614</fpage>–<lpage>618</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/01621459.1995.10476554" xlink:type="simple">10.1080/01621459.1995.10476554</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref074">
<label>74</label>
<mixed-citation publication-type="other" xlink:type="simple">Robert CP, Wraith D, Goggans PM, Chan CY. Computational methods for Bayesian model choice. In: AIP Conference Proceedings. vol. 1193. AIP; 2009. p. 251–262.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref075">
<label>75</label>
<mixed-citation publication-type="other" xlink:type="simple">Caldwell A, Liu C. Target density normalization for Markov Chain Monte Carlo algorithms. arXiv preprint arXiv:14107149. 2014;.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Carpenter</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Gelman</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Hoffman</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Lee</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Goodrich</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Betancourt</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Stan: A probabilistic programming language</article-title>. <source>Journal of Statistical Software</source>. <year>2016</year>;<volume>20</volume>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref077">
<label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Salvatier</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Wiecki</surname> <given-names>TV</given-names></name>, <name name-style="western"><surname>Fonnesbeck</surname> <given-names>C</given-names></name>. <article-title>Probabilistic programming in Python using PyMC3</article-title>. <source>PeerJ Computer Science</source>. <year>2016</year>;<volume>2</volume>:<fpage>e55</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7717/peerj-cs.55" xlink:type="simple">10.7717/peerj-cs.55</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref078">
<label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Acerbi</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ma</surname> <given-names>WJ</given-names></name>. <article-title>Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search</article-title>. In: <source>Advances in Neural Information Processing Systems</source> <volume>30</volume>; <year>2017</year>. p. <fpage>1836</fpage>–<lpage>1846</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Jones</surname> <given-names>DR</given-names></name>, <name name-style="western"><surname>Schonlau</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Welch</surname> <given-names>WJ</given-names></name>. <article-title>Efficient global optimization of expensive black-box functions</article-title>. <source>Journal of Global optimization</source>. <year>1998</year>;<volume>13</volume>(<issue>4</issue>):<fpage>455</fpage>–<lpage>492</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1023/A:1008306431147" xlink:type="simple">10.1023/A:1008306431147</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref080">
<label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shahriari</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Swersky</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Wang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Adams</surname> <given-names>RP</given-names></name>, <name name-style="western"><surname>de Freitas</surname> <given-names>N</given-names></name>. <article-title>Taking the human out of the loop: A review of Bayesian optimization</article-title>. <source>Proceedings of the IEEE</source>. <year>2016</year>;<volume>104</volume>(<issue>1</issue>):<fpage>148</fpage>–<lpage>175</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/JPROC.2015.2494218" xlink:type="simple">10.1109/JPROC.2015.2494218</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref081">
<label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Neal</surname> <given-names>RM</given-names></name>. <article-title>Slice sampling</article-title>. <source>Annals of Statistics</source>. <year>2003</year>;<volume>31</volume>(<issue>3</issue>):<fpage>705</fpage>–<lpage>741</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1214/aos/1056562461" xlink:type="simple">10.1214/aos/1056562461</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref082">
<label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gilks</surname> <given-names>WR</given-names></name>, <name name-style="western"><surname>Roberts</surname> <given-names>GO</given-names></name>, <name name-style="western"><surname>George</surname> <given-names>EI</given-names></name>. <article-title>Adaptive direction sampling</article-title>. <source>The Statistician</source>. <year>1994</year>;<volume>43</volume>(<issue>1</issue>):<fpage>179</fpage>–<lpage>189</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2307/2348942" xlink:type="simple">10.2307/2348942</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref083">
<label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Daunizeau</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Adam</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Rigoux</surname> <given-names>L</given-names></name>. <article-title>VBA: A probabilistic treatment of nonlinear models for neurobiological and behavioural data</article-title>. <source>PLoS Comput Biol</source>. <year>2014</year>;<volume>10</volume>(<issue>1</issue>):<fpage>e1003441</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pcbi.1003441" xlink:type="simple">10.1371/journal.pcbi.1003441</ext-link></comment> <object-id pub-id-type="pmid">24465198</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref084">
<label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Krakauer</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Ghazanfar</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Gomez-Marin</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>MacIver</surname> <given-names>MA</given-names></name>, <name name-style="western"><surname>Poeppel</surname> <given-names>D</given-names></name>. <article-title>Neuroscience needs behavior: Correcting a reductionist Bias</article-title>. <source>Neuron</source>. <year>2017</year>;<volume>93</volume>(<issue>3</issue>):<fpage>480</fpage>–<lpage>490</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2016.12.041" xlink:type="simple">10.1016/j.neuron.2016.12.041</ext-link></comment> <object-id pub-id-type="pmid">28182904</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref085">
<label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dokka</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>MacNeilage</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>. <article-title>Estimating distance during self-motion: A role for visual–vestibular interactions</article-title>. <source>Journal of Vision</source>. <year>2011</year>;<volume>11</volume>(<issue>13</issue>):<fpage>1</fpage>–<lpage>16</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1167/11.13.2" xlink:type="simple">10.1167/11.13.2</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref086">
<label>86</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>MacNeilage</surname> <given-names>PR</given-names></name>, <name name-style="western"><surname>Zhang</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>. <article-title>Vestibular facilitation of optic flow parsing</article-title>. <source>PLoS ONE</source>. <year>2012</year>;<volume>7</volume>(<issue>7</issue>):<fpage>e40264</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0040264" xlink:type="simple">10.1371/journal.pone.0040264</ext-link></comment> <object-id pub-id-type="pmid">22768345</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref087">
<label>87</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Greenhouse</surname> <given-names>SW</given-names></name>, <name name-style="western"><surname>Geisser</surname> <given-names>S</given-names></name>. <article-title>On methods in the analysis of profile data</article-title>. <source>Psychometrika</source>. <year>1959</year>;<volume>24</volume>(<issue>2</issue>):<fpage>95</fpage>–<lpage>112</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF02289823" xlink:type="simple">10.1007/BF02289823</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref088">
<label>88</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Knuth</surname> <given-names>DE</given-names></name>. <article-title>Two notes on notation</article-title>. <source>The American Mathematical Monthly</source>. <year>1992</year>;<volume>99</volume>(<issue>5</issue>):<fpage>403</fpage>–<lpage>422</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2307/2325085" xlink:type="simple">10.2307/2325085</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref089">
<label>89</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Gu</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Fetsch</surname> <given-names>CR</given-names></name>, <name name-style="western"><surname>Adeyemo</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>DeAngelis</surname> <given-names>GC</given-names></name>, <name name-style="western"><surname>Angelaki</surname> <given-names>DE</given-names></name>. <article-title>Decoding of MSTd population activity accounts for variations in the precision of heading perception</article-title>. <source>Neuron</source>. <year>2010</year>;<volume>66</volume>(<issue>4</issue>):<fpage>596</fpage>–<lpage>609</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2010.04.026" xlink:type="simple">10.1016/j.neuron.2010.04.026</ext-link></comment> <object-id pub-id-type="pmid">20510863</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref090">
<label>90</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cuturi</surname> <given-names>LF</given-names></name>, <name name-style="western"><surname>MacNeilage</surname> <given-names>PR</given-names></name>. <article-title>Systematic biases in human heading estimation</article-title>. <source>PLoS ONE</source>. <year>2013</year>;<volume>8</volume>(<issue>2</issue>):<fpage>e56862</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1371/journal.pone.0056862" xlink:type="simple">10.1371/journal.pone.0056862</ext-link></comment> <object-id pub-id-type="pmid">23457631</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref091">
<label>91</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stocker</surname> <given-names>AA</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>Noise characteristics and prior expectations in human visual speed perception</article-title>. <source>Nature Neuroscience</source>. <year>2006</year>;<volume>9</volume>(<issue>4</issue>):<fpage>578</fpage>–<lpage>585</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn1669" xlink:type="simple">10.1038/nn1669</ext-link></comment> <object-id pub-id-type="pmid">16547513</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref092">
<label>92</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Girshick</surname> <given-names>AR</given-names></name>, <name name-style="western"><surname>Landy</surname> <given-names>MS</given-names></name>, <name name-style="western"><surname>Simoncelli</surname> <given-names>EP</given-names></name>. <article-title>Cardinal rules: Visual orientation perception reflects knowledge of environmental statistics</article-title>. <source>Nature Neuroscience</source>. <year>2011</year>;<volume>14</volume>(<issue>7</issue>):<fpage>926</fpage>–<lpage>932</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.2831" xlink:type="simple">10.1038/nn.2831</ext-link></comment> <object-id pub-id-type="pmid">21642976</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref093">
<label>93</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Wei</surname> <given-names>XX</given-names></name>, <name name-style="western"><surname>Stocker</surname> <given-names>AA</given-names></name>. <article-title>A Bayesian observer model constrained by efficient coding can explain ‘anti-Bayesian’ percepts</article-title>. <source>Nature neuroscience</source>. <year>2015</year>;<volume>18</volume>(<issue>10</issue>):<fpage>1509</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn.4105" xlink:type="simple">10.1038/nn.4105</ext-link></comment> <object-id pub-id-type="pmid">26343249</object-id></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref094">
<label>94</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Press</surname> <given-names>WH</given-names></name>, <name name-style="western"><surname>Flannery</surname> <given-names>BP</given-names></name>, <name name-style="western"><surname>Teukolsky</surname> <given-names>SA</given-names></name>, <name name-style="western"><surname>Vetterling</surname> <given-names>WT</given-names></name>. <chapter-title>Numerical recipes</chapter-title> <edition>3rd edition</edition>: <source>The art of scientific computing</source>. <publisher-name>Cambridge University Press</publisher-name>; <year>2007</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref095">
<label>95</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Audet</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Dennis</surname> <given-names>JE</given-names> <suffix>Jr</suffix></name>. <article-title>Mesh adaptive direct search algorithms for constrained optimization</article-title>. <source>SIAM Journal on Optimization</source>. <year>2006</year>;<volume>17</volume>(<issue>1</issue>):<fpage>188</fpage>–<lpage>217</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref096">
<label>96</label>
<mixed-citation publication-type="other" xlink:type="simple">Brochu E, Cora VM, De Freitas N. A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. arXiv preprint arXiv:10122599. 2010;.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref097">
<label>97</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Foreman-Mackey</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Hogg</surname> <given-names>DW</given-names></name>, <name name-style="western"><surname>Lang</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Goodman</surname> <given-names>J</given-names></name>. <article-title>emcee: The MCMC hammer</article-title>. <source>Publications of the Astronomical Society of the Pacific</source>. <year>2013</year>;<volume>125</volume>(<issue>925</issue>):<fpage>306</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1086/670067" xlink:type="simple">10.1086/670067</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1006110.ref098">
<label>98</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Bishop</surname> <given-names>CM</given-names></name>. <source>Pattern recognition and machine learning</source>. <publisher-name>Springer</publisher-name>; <year>2006</year>.</mixed-citation>
</ref>
<ref id="pcbi.1006110.ref099">
<label>99</label>
<mixed-citation publication-type="other" xlink:type="simple">Grassberger P. Entropy estimates from insufficient samplings. arXiv preprint physics/0307138. 2003;.</mixed-citation>
</ref>
</ref-list>
</back>
</article>
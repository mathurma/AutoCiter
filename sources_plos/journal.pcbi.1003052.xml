<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="en">
<front>
   <journal-meta>
      <journal-id journal-id-type="publisher-id">plos</journal-id>
      <journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
      <journal-id journal-id-type="pmc">ploscomp</journal-id>
      <journal-title-group>
         <journal-title>PLoS Computational Biology</journal-title>
      </journal-title-group>
      <issn pub-type="ppub">1553-734X</issn>
      <issn pub-type="epub">1553-7358</issn>
      <publisher>
         <publisher-name>Public Library of Science</publisher-name>
         <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher>
   </journal-meta>
   <article-meta>
      <article-id pub-id-type="publisher-id">PCOMPBIOL-D-12-01483</article-id>
      <article-id pub-id-type="doi">10.1371/journal.pcbi.1003052</article-id>
      <article-categories>
         <subj-group subj-group-type="heading">
            <subject>Research Article</subject>
         </subj-group>
<subj-group subj-group-type="Discipline-v2"><subject>Biology</subject>
<subj-group>
<subject>Neuroscience</subject>
<subj-group>
<subject>Animal cognition</subject>
<subject>Behavioral neuroscience</subject>
<subject>Motor systems</subject>
<subject>Neuroethology</subject>
</subj-group>
</subj-group>
</subj-group>
      </article-categories>
      <title-group>
         <article-title>Long-range Order in Canary Song</article-title>
         <alt-title alt-title-type="running-head">Long-range Order in Canary Song</alt-title>
      </title-group>
      <contrib-group>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Markowitz</surname>
<given-names>Jeffrey E.</given-names>
            </name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff2"><sup>2</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Ivie</surname>
<given-names>Elizabeth</given-names>
            </name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Kligler</surname>
<given-names>Laura</given-names>
            </name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref>
         </contrib>
         <contrib contrib-type="author" xlink:type="simple">
            <name name-style="western"><surname>Gardner</surname><given-names>Timothy J.</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff3"><sup>3</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref>
         </contrib>
      </contrib-group>
      <aff id="aff1"><label>1</label><addr-line>Department of Cognitive and Neural Systems, Boston University, Boston, Massachusetts, United States of America</addr-line></aff>
      <aff id="aff2"><label>2</label><addr-line>Center of Excellence for Learning in Education, Science and Technology, Boston, Massachusetts, United States of America</addr-line></aff>
      <aff id="aff3"><label>3</label><addr-line>Department of Biology, Boston University, Boston, Massachusetts, United States of America</addr-line></aff>
      <contrib-group>
         <contrib contrib-type="editor" xlink:type="simple">
            <name name-style="western"><surname>Jin</surname>
<given-names>Dezhe</given-names>
            </name><role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
         </contrib>
      </contrib-group>
      <aff id="edit1"><addr-line>The Pennsylvania State University, United States of America</addr-line></aff>
      <author-notes>
         <corresp id="cor1">* E-mail: <email xlink:type="simple">timothyg@bu.edu</email></corresp>
         <fn fn-type="conflict">
            <p>The authors have declared that no competing interests exist.</p>
         </fn>
         <fn fn-type="con">
            <p>Conceived and designed the experiments: JEM TJG. Performed the experiments: JEM EI LK. Analyzed the data: JEM. Wrote the paper: JEM TJG.</p>
         </fn>
      </author-notes>
      <pub-date pub-type="collection">
         <month>5</month>
         <year>2013</year>
      </pub-date>
      <pub-date pub-type="epub">
         <day>2</day>
         <month>5</month>
         <year>2013</year>
      </pub-date>
      <volume>9</volume>
      <issue>5</issue>
      <elocation-id>e1003052</elocation-id>
      <history>
         <date date-type="received">
            <day>18</day>
            <month>9</month>
            <year>2012</year>
         </date>
         <date date-type="accepted">
            <day>22</day>
            <month>3</month>
            <year>2013</year>
         </date>
      </history>
      <permissions>
         <copyright-year>2013</copyright-year>
         <copyright-holder>Markowitz et al</copyright-holder><license xlink:type="simple"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions>
      <abstract>
         <p>Bird songs range in form from the simple notes of a Chipping Sparrow to the rich performance of the nightingale. Non-adjacent correlations can be found in the syntax of some birdsongs, indicating that the choice of what to sing next is determined not only by the current syllable, but also by previous syllables sung. Here we examine the song of the domesticated canary, a complex singer whose song consists of syllables, grouped into phrases that are arranged in flexible sequences. Phrases are defined by a fundamental time-scale that is independent of the underlying syllable duration. We show that the ordering of phrases is governed by long-range rules: the choice of what phrase to sing next in a given context depends on the history of the song, and for some syllables, highly specific rules produce correlations in song over timescales of up to ten seconds. The neural basis of these long-range correlations may provide insight into how complex behaviors are assembled from more elementary, stereotyped modules.</p>
      </abstract>
      <abstract abstract-type="summary">
         <title>Author Summary</title>
         <p>Bird songs range in form from the simple notes of a Chipping Sparrow to the complex repertoire of the nightingale. Recent studies suggest that bird songs may contain non-adjacent dependencies where the choice of what to sing next depends on the history of what has already been produced. However, the complexity of these rules has not been examined statistically for the most elaborate avian singers. Here we show that one complex singer—the domesticated canary—produces a song that is strongly influenced by long-range rules. The choice of how long to repeat a given note or which note to choose next depends on the history of the song, and these dependencies span intervals of time much longer than previously assumed for birdsong. Like most forms of human music, the songs of canaries contain patterns expressed over long timescales, governed by rules that apply to multiple levels of a temporal hierarchy. This vocal complexity provides a valuable model to examine how ordered behaviors are assembled from more elementary neural components in a relatively simple neural circuit.</p>
      </abstract>
      <funding-group>
         <funding-statement>This work is supported by the NSF Science of Learning Center CELEST (SBE-0354378) and by a Career Award at the Scientific Interface to TJG from the Burroughs Wellcome Fund and a Smith family award to TJG. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
      </funding-group>
<counts>
<page-count count="12"/>
</counts>
</article-meta>
</front>
<body>
   <sec id="s1">
      <title>Introduction</title>
      <p>Brains build complex behaviors from simple modules <xref ref-type="bibr" rid="pcbi.1003052-Fodor1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1003052-Minsky1">[2]</xref>.The ultimate example is speech where sequences of phonemes form words that in turn are rearranged to form sentences. So too, the complex performances of a musician or swordfighter are composed of discrete motor gestures that may be composed of more elementary motor modules or muscle synergies <xref ref-type="bibr" rid="pcbi.1003052-Llins1">[3]</xref>. Songbirds, in their own ways, build complex vocal forms from elementary units known as syllables. Among the 4500+ species of songbirds, simple and complex songs can be found, and a rich history of detailed song descriptions can be found across a wide variety of literature <xref ref-type="bibr" rid="pcbi.1003052-Falls1">[4]</xref>–<xref ref-type="bibr" rid="pcbi.1003052-Lemon1">[12]</xref>. However, quantitative information about the statistical complexity of song is available only for a few species <xref ref-type="bibr" rid="pcbi.1003052-Falls1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003052-Gentner1">[8]</xref>–<xref ref-type="bibr" rid="pcbi.1003052-Lemon1">[12]</xref>. Birdsong has often been described in terms of first-order transition statistics, e.g. between adjacent syllables <xref ref-type="bibr" rid="pcbi.1003052-Scharff1">[13]</xref> in the zebra finch or syllable chunks <xref ref-type="bibr" rid="pcbi.1003052-Todt1">[9]</xref>, <xref ref-type="bibr" rid="pcbi.1003052-Gttinger1">[14]</xref> in the nightingale and Bengalese finch. However, analysis of the Bengalese finch song also reveals non-adjacent dependencies where transition probabilities between syllables depend not only on the current active syllable, but also one or more prior syllables sung <xref ref-type="bibr" rid="pcbi.1003052-Kakishita1">[15]</xref>–<xref ref-type="bibr" rid="pcbi.1003052-Katahira1">[17]</xref>. Formally, this implies that song syntax must be modeled with a second-order or higher order Markov chain. Higher-order Markov chains can also be represented through first-order statistics in a hidden Markov model (HMM). In the latter case, statistically complex sequences will require a large number of hidden states, relative to the number of observed syllables.</p>
      <p>In addition to the detailed quantitative studies of syntax in Bengalese finches in laboratory settings, many field studies have described an array of influences on the delivery of song. For example, some species such as the swamp sparrow engage in antiphonal song type-matching—selecting a song that best matches what the neighbor just sang <xref ref-type="bibr" rid="pcbi.1003052-Prather1">[18]</xref>. In this case, an auditory stimulus is involved in the selection of elements from a vocal repertoire, and the choices are not simply determined by the current motor state <xref ref-type="bibr" rid="pcbi.1003052-Sakata1">[19]</xref>. Other examples of complex vocal behavior can be found for species that sing many song types. In some cases, e.g. with Western Meadowlarks and American Redstarts, the probability of producing a given song type decreases after the first time it is delivered in a bout of singing, and as a result, the full repertoire of songs is expressed more frequently than expected if the selection of songs was random <xref ref-type="bibr" rid="pcbi.1003052-Falls1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1003052-Lemon1">[12]</xref>. In a related example of song performance memory, nightingales can pause for a few seconds, and then resume singing where they left off in a ordered set of songs <xref ref-type="bibr" rid="pcbi.1003052-Hultsch1">[20]</xref>. Taken together, numerous threads suggest that songbirds can maintain a memory trace for songs recently heard or sung for at least a few seconds. If syllables sung or heard can introduce a memory trace that lasts for seconds, and if this memory trace can impact future decisions about what to sing, then a substrate exists that could introduce long-range correlations between decision points in song. How deep is the memory for past choices in song among the most elaborate singers?</p>
      <p>One of the most complex singers that can be easily reared in a laboratory setting is the domesticated canary. Here we investigated the long, complex songs of the Belgian Waterslager strain. We show that their songs are governed by long-range correlations in syntax at multiple hierarchical levels. The time a bird spends repeating a syllable or the choice of what to sing next depends on the history of the song and correlations between the past and present can extend over durations up to 10 seconds, encompassing 4 or more phrases consisting of dozens of syllable repeats. Canary song, like most popular music, contains structure in a range of time-scales through which sequence flexibility is balanced by long-range order <xref ref-type="bibr" rid="pcbi.1003052-Levitin1">[21]</xref>. The neural basis of these long-range correlations may provide insight into how complex behaviors are assembled from more elementary, stereotyped behavioral modules.</p>
   </sec>
   <sec id="s2">
      <title>Results</title>
      <sec id="s2a">
         <title>Phrase time-scales</title>
         <p>The smallest indivisible unit of the domesticated canary's song is the syllable, a stereotyped sound that typically ranges from 20 to 200 ms in duration. The adult repertoire usually contains between 25–35 distinct syllable types whose acoustic forms are learned by an interplay between innate programming and flexible imitation <xref ref-type="bibr" rid="pcbi.1003052-Gardner1">[22]</xref>. Syllables are repeated multiple times to form a phrase, which can range from 500 ms to 3 s, and phrases are flexibly chained together to form songs (<xref ref-type="fig" rid="pcbi-1003052-g001"><bold>Fig. 1</bold></xref>), typically 5–15 s long <xref ref-type="bibr" rid="pcbi.1003052-Belzner1">[23]</xref>. In the present context, the term “phrase type” refers to the syllable type repeated in a given phrase.</p>
         <fig id="pcbi-1003052-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003052.g001</object-id><label>Figure 1</label>
            <caption>
               <title>Sonograms show a relationship between phrase duration, the context of a phrase, and future choices.</title>
               <p>Phrases consist of repetitions of elementary units—the syllables. Distinct phrase types are indicated by colored bars beneath each sonogram. On the right side of each sonogram is a “barcode” summary of all occurrences of the phrases shown in the sonograms. The phrases before (left) and after (right) the gray phrase are color-coded by syllable identity, and the length of the bars in each row indicates duration of the phrase. A square flanks each barcode to indicate the scale, with the width corresponding to 2 seconds and the height to 20 trials. <bold>A</bold>, A case where the duration of a phrase predicts the future path—the barcode is sorted by duration of the black phrase. Short black bars on the bottom of the barcode typically lead to blue, while long black bars at the top typically lead to green. <bold>B</bold>, A case where the identity of the starting phrase (red, yellow, or purple) determines which phrase type comes after the black/gray phrase (green or magenta for example.) The barcode in this panel is sorted by the phrase that comes before the black/gray phrase.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003052.g001" position="float" xlink:type="simple"/></fig>
         <p>These two fundamental units of the canary song—syllables and phrases—form distinct time-scales. Syllable durations range from 28 to 480 milliseconds, while phrase time-scales are on the order of a second (1.3375–1.3589 95% bootstrap confidence interval of the median), and the full song is an order of magnitude longer (<xref ref-type="fig" rid="pcbi-1003052-g001"><bold>Fig. 1</bold></xref> and <xref ref-type="fig" rid="pcbi-1003052-g002"><bold>Fig. 2</bold></xref>). <xref ref-type="fig" rid="pcbi-1003052-g002"><bold>Fig. 2b</bold></xref> shows that there is no general correlation between syllable duration and phrase duration (r = .013, p = .90); canaries persist on a single syllable for a duration that is roughly one second, whether the syllable is short or long <xref ref-type="bibr" rid="pcbi.1003052-Gttinger2">[24]</xref>. To produce a phrase of the characteristic duration, the shortest syllables are repeated 20–30 times, while the longest syllables are repeated only 3–4 times. We discuss later the implications of a phrase time-scale that is not simply related to syllable time-scales.</p>
         <fig id="pcbi-1003052-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003052.g002</object-id><label>Figure 2</label>
            <caption>
               <title>Phrase length is defined by a typical time-scale and depends on context.</title>
               <p><bold>A,</bold> Probability density of phrase durations for all 6 birds (mode = .9416, .8132–1.407 95% bootstrap confidence interval, median = 1.3482, 1.3375–1.3589). <bold>B,</bold> A scatter plot of phrase duration plotted against syllable duration for 6 birds reveals no general correlation between phrase length and syllable length (r = .013,p = .90). <bold>C,</bold> Examples of the effect of phrase context on phrase duration. Each group of points (separated by dotted lines) indicates the duration of a different phrase type, while the colors (arbitrary) indicate different preceding phrase types. (These examples draw from all 6 birds, all phrase durations are given in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s014">Fig. S12</xref></bold>).</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003052.g002" position="float" xlink:type="simple"/></fig>
      </sec>
      <sec id="s2b">
         <title>Correlations between phrase durations and syllable choices</title>
         <p>As a group, there is no general correlation between phrase length and syllable length (<xref ref-type="fig" rid="pcbi-1003052-g002"><bold>Fig. 2b</bold></xref>). However, particular syllable types do have their own characteristic phrase lengths, and the duration of specific phrases can vary depending on the context in which they occur. Specifically, we found highly significant mutual dependence between the length of specific phrases and the phrase type sung <italic>before</italic> or <italic>after</italic> the phrase (<xref ref-type="fig" rid="pcbi-1003052-g001"><bold>Fig. 1a</bold></xref> and <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s003">Fig. S1</xref></bold>) (81 phrase types examined in 6 birds, p&lt;.001 Fisher-Freeman-Halton test, see <xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref>). For a given phrase type, the length of a phrase can depend on the recent history of the song. Moreover, the choice of what to sing at a branch-point can depend not only on the currently active syllable, but also on the amount of time elapsed since the onset of the last phrase.</p>
      </sec>
      <sec id="s2c">
         <title>Syllable stability across the phrase</title>
         <p>Renditions of what appeared to be the same syllable in short and long phrases might show subtle distinctions acoustically. If they are distinct, then the apparent long-range correlations could be more simply described by nearest neighbor rules in the syllable sub-types <xref ref-type="bibr" rid="pcbi.1003052-Jin1">[16]</xref>. Here we sought to provide a methodology for direct visual representation of syllable variability. To proceed, we first isolated all renditions of a chosen syllable based on an automated template matching procedure (see <xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref>). We confirmed by visual inspection of sonograms that all examples of the chosen syllable were extracted, with no errors. We then separated the syllables into three groups depending on whether they came from short, medium or long phrases. (Phrase durations were discretized into three bins of uniform time-span, an arbitrary choice.) We then generated spectral density images (see <xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref>) for each group. The spectral density image provides a quantitative representation of syllable form and its variability across multiple renditions. In the spectral density image, color scale indicates the probability of finding a time-frequency contour <xref ref-type="bibr" rid="pcbi.1003052-Lim1">[25]</xref> at a given point in the time-frequency plane. For a few syllables, visual inspection of the spectral density image revealed no variation for syllables drawn from different phrase duration bins (<xref ref-type="fig" rid="pcbi-1003052-g003"><bold>Fig. 3a</bold></xref>).</p>
         <fig id="pcbi-1003052-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003052.g003</object-id><label>Figure 3</label>
            <caption>
               <title>Renditions of the same syllable in short, medium and long phrases are highly similar.</title>
               <p><bold>A,</bold> Spectral density images were computed for matching syllables in phrases of different relative durations. The images were taken from 2 different birds. <bold>B,</bold> Similarity scores reflect the acoustic similarity between individual sounds and the spectral density image for a group of sounds. Here, we computed the similarity scores of the same syllable extracted from short, medium and long phrases with respect to the spectral density image for syllables extracted from short phrases. These distributions show that phrase duration does not affect the acoustic form. <italic>Top:</italic> similarity scores for the syllable type from the middle row in <xref ref-type="fig" rid="pcbi-1003052-g003"><bold>Fig. 3a</bold></xref>. <italic>Bottom:</italic> similarity scores for the syllable type from the third row in <xref ref-type="fig" rid="pcbi-1003052-g003"><bold>Fig. 3a</bold></xref>. Summary statistics for these distributions are given in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s016">Table S2</xref></bold>.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003052.g003" position="float" xlink:type="simple"/></fig>
         <p>This qualitative observation can be quantified using a similarity score based on the spectral density images (see <xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref>). Specifically, we computed the all-to-all overlap of binary contour images by computing the inner product between all pairs. Then, the all-to-all scores were sorted by their corresponding phrase groups and the distributions were compared using a Kolmogorov-Smirnov (KS) test and a d′ measure (see <xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref>). By the KS test, the distributions were distinct (p&lt;.01), however the scale of the acoustic differences was very small by our measure. In all cases d′&lt;0.2 (see <xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref>), indicating that the average differences between syllable shapes in different groups were smaller than the variations within a given group (<xref ref-type="fig" rid="pcbi-1003052-g003"><bold>Fig. 3b</bold></xref>, and <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s016">Table S2</xref></bold>). Corroborating measurements were found using scores computed from acoustic features defined in the Sound Analysis Pro for MATLAB package <xref ref-type="bibr" rid="pcbi.1003052-Tchernichovski1">[26]</xref>. For these scores, d′&lt;0.1 (see <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s020">Text S1</xref></bold>).</p>
         <p>In this analysis, we chose the most stable syllables. In other syllable types (particularly the fastest syllables), a systematic shift in acoustic form may occur over the course of a phrase. Also, for many phrase types in canaries, the first syllable of a new phrase type shows a structure that matches neither the preceding nor the succeeding phrase. If a switch in syllable forms is made in the central motor control loops, the syringeal or respiratory pattern may require a finite time to reconfigure. Ongoing phonation during this period of reconfiguration may produce syllable forms that differ from the steady state syllable forms <xref ref-type="bibr" rid="pcbi.1003052-Gardner2">[27]</xref>. <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s012">Fig. S10</xref></bold> reveals that these specific context dependent effects can be acoustically significant. Excluding the special case of the first transitional syllables in a new phrase, in the syllables analyzed here, changes in form in different contexts were too small to allow a single instance of a syllable to be reliably assigned to short, medium, or long phrases using scores based on either SAP features or spectral density images.</p>
      </sec>
      <sec id="s2d">
         <title>Second order Markov structure of phrases</title>
         <p>Canary song is organized around a mesoscopic structure, the phrase. Is the larger sequence of song explained by a first-order Markov process in phrases, or is phrase sequencing more complex than a first-order Markov process? To examine this possibility, we first observed that the succession of phrases is quite constrained—each phrase is typically followed by just a few downstream possibilities (<xref ref-type="fig" rid="pcbi-1003052-g004"><bold>Fig. 4a</bold></xref>). The top three or four transitions account for most of the variations that follow a given phrase. We next examined the entropy of phrase sequences of various lengths, and compared this entropy with random sequences that preserve only first-order transition statistics. We found that the entropy of phrase sequences is almost as high as a first-order model would imply (<xref ref-type="fig" rid="pcbi-1003052-g004"><bold>Fig. 4b</bold></xref>). However, the match is not perfect, and for sequences 4–6 phrases long, it is clear that the set of song sequences is smaller than the set of possible sequences in a first-order random model. Song is thus more ordered than a first-order Markov process acting on phrase types.</p>
         <fig id="pcbi-1003052-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003052.g004</object-id><label>Figure 4</label>
            <caption>
               <title>Canary phrase sequences are more ordered than a first-order Markov process.</title>
               <p><bold>A,</bold> For each phrase type the magnitudes of transition probabilities to the next phrase are shown sorted by probability. The rapid decay of the traces indicates that most syllables are followed by just a few high probability transitions. Canaries (magenta) do not simply emit phrases at random, as in the zero-order Markov case (green). <bold>B,</bold> Block entropy is the entropy computed for sequences of <italic>n</italic> phrases, i.e. the block size (see <xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref>). The block entropy was computed for the actual phrase labels (canary), a randomization that only preserved phrase occurrence probabilities (zero-order Markov), and a randomization that only preserved nearest-neighbor transition probabilities (first-order Markov). Block entropy grows slowly with block size (n) for canary song, relative to the random models. This slower entropy growth hints at the existence of structure beyond a first-order Markov chain in phrase types.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003052.g004" position="float" xlink:type="simple"/></fig>
         <p>To examine further the constraints placed on canary phrase sequences, we first tested all phrase types for statistically significant second-order structure. Specifically, for a sequence of three phrases XYZ, we asked whether the phrase type X impacted the phrase type probabilities for Z, for a given phrase type Y. The test reveals that this mutual dependence exists for 70% of all examined phrase types (p&lt;.001, Fisher-Freeman-Halton test, see <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s003">Fig. S1</xref></bold>). Here too, a high-resolution analysis of selected examples using spectral density images confirmed that the acoustic form of the syllable in position Y can remain relatively constant even when flanked by diverse phrase types in position X or Z (<bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s007">Fig. S5a</xref></bold>). As for the earlier analysis of syllable forms in phrases of different lengths, this observation was quantified both with spectral density similarity scores (d′&lt;0.35) and through the use of SAP scores (d′&lt;0.1), indicating that variations of syllable form within each group are larger than the separation between syllable forms in different syntactic contexts. (As before, there are detectable differences between the distributions, p&lt;.01 two-sample Kolmogorov-Smirnov test).</p>
         <p>It is not known whether peripheral motor variables such as air pressure or muscular tone change over the course of a long canary song. Time-dependent changes in the periphery could impact the acoustic details of song <xref ref-type="bibr" rid="pcbi.1003052-Gardner2">[27]</xref>–<xref ref-type="bibr" rid="pcbi.1003052-Elemans1">[29]</xref>. We examined how syllable form changed when syllables occurred early or late in song, for a fixed phrase context defined by the immediate preceding syllable. Pairwise similarity analysis was performed for all syllables examined in the phrase-context analysis described in the preceding paragraph. Grouping syllables into renditions that occur before or after the median song duration for a given bird, detectable differences in acoustic form could be found between groups for all syllable types analyzed (p&lt;.01 two-sample Kolmogorov-Smirnov test, n = 3 syllable types). The d′ value of the group differences is comparable to the changes reported in the previous paragraph for phrase context. For song position effects, spectral density based similarity scores reveal d′&lt;0.2 and for SAP similarity scores d′&lt;0.1. To summarize the analysis of syllable stability: a memory for past phrase choices impacts future phrase choices or phrase durations, and this memory may have a very limited impact on the acoustic form of some syllables (see <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s007">Fig. S5b</xref></bold> and <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s017">Table S3</xref></bold>). It is possible that the minor acoustic changes in syllables can be largely explained by small-scale drift in peripheral control variables.</p>
      </sec>
      <sec id="s2e">
         <title>The long-range order of canary song sequences</title>
         <p>The previous analysis indicated that second-order correlations introduce a statistically detectable shift in phrase transition probabilities for most phrase types, but these second-order effects could be weak. Still, weak higher-order correlations could in principle explain the gap between a first-order random model and canary song. However, the next stage of analysis revealed that while higher-order correlations are weak for many phrase types, for some phrase types, strong long-range rules apply to the delivery of song.</p>
         <p>To examine how long-range correlations varied by phrase type, we constructed a prediction suffix tree (PST) <xref ref-type="bibr" rid="pcbi.1003052-Ron1">[30]</xref> to represent each bird's song. A PST provides a visual representation of how past information in a sequence impacts transition probabilities. Formally, the tree is built from a collection of Markov chains, one for each phrase type. Each chain is initialized as a zero-order Markov chain, and the order is increased only if the information gained by looking further back in time justifies the added complexity (see <xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref>). In <xref ref-type="fig" rid="pcbi-1003052-g005">Fig. 5</xref>, the PST is displayed radially, with each syllable arranged around the inner circle. For a given syllable, the number of nodes between the tree trunk and the outer branches indicates the order of the Markov chain for that syllable. For a syllable impacted by high-order correlations, that syllable on the trunk of the PST tree will be connected to long, multi-branched limbs. Similar methods were recently used in the analysis of Bengalese finch syntax <xref ref-type="bibr" rid="pcbi.1003052-Kakishita1">[15]</xref>.</p>
         <fig id="pcbi-1003052-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003052.g005</object-id><label>Figure 5</label>
            <caption>
               <title>Prediction suffix trees (PSTs) reveal long-range structure in canary song.</title>
               <p>Letters are arbitrary labels for phrase types. PSTs were generated for all 6 birds (the other four are shown in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s010">Fig. S8</xref></bold>). The length of the branch terminating in a given phrase type indicates the extent to which syllable history impacts transition probabilities. A branch 5 nodes long indicates that one must look 5 phrases back in the song to accurately predict the transition probabilities from the terminal node at the center. Each node is shown as a pie chart representing the outgoing transition probabilities from that sequence of phrases (for each bird, syllables are assigned arbitrary colors). The nodes are scaled according to their frequency. Nodes that can be grouped together (chunked) without significantly reducing the power of the model are labeled with blue text.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003052.g005" position="float" xlink:type="simple"/></fig>
         <p>As a control, we used a 10-fold cross-validation procedure. Prediction suffix trees were computed for the training data, and then the average negative log-likelihood of the test data was computed for each tree (<xref ref-type="fig" rid="pcbi-1003052-g006"><bold>Fig. 6</bold></xref>). The PST that leads to the minimum in average negative log-likelihood on the test set is considered the best fit. The depth of the best fit ranged from 4 to 7 phrases in the six birds examined here (<bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s009">Fig. S7</xref></bold>). This corresponds to a propagation of song information over a time-scale of approximately 5 to 10 seconds. Many syllables in this analysis showed no significant structure beyond first-order; just a few syllables are governed by long-range rules. (The prevalence of second-order structure revealed in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s003">Fig. S1</xref></bold> suggests that the PSTs provided a conservative estimate of statistical depth for many syllables.) The structure of example songs with long time-scale correlations is illustrated in <xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref> where the syllable identity of the phrase at the top of a chain impacts transition probabilities many phrases later. (<bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s008">Fig. S6</xref></bold> contains similar song barcodes showing the full song context for the examples in <xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref><bold>.</bold>) In the examples given in <xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref>, the history of previous syllable selections can impact future syllable transitions over 4–5 intervening phrases, spanning a time-scale of up to ten seconds.</p>
         <fig id="pcbi-1003052-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003052.g006</object-id><label>Figure 6</label>
            <caption>
               <title>Cross-validation confirms that prediction suffix trees (PSTs) are not overfitting the data.</title>
               <p>PSTs were fit to 90% of the data and tested on the held-out 10% in a 10-fold cross-validation procedure for different values of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e001" xlink:type="simple"/></inline-formula>, which sets the minimum frequency a sequence has to occur to be considered. If <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e002" xlink:type="simple"/></inline-formula> is too small, overfitting is guaranteed, and suffix trees will appear artificially deep. Shown is the performance of the PSTs for a single bird (PST is given in the bottom of <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref>). Using average negative log-likelihood to measure performance, the test performance peaks at <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e003" xlink:type="simple"/></inline-formula>. Below this value the test performance begins to degrade and sharply diverges from training performance, a clear sign of overfitting.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003052.g006" position="float" xlink:type="simple"/></fig>
         <fig id="pcbi-1003052-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003052.g007</object-id><label>Figure 7</label>
            <caption>
               <title>Decisions at branch points in song can impact syllable transition probabilities 5 phrases later.</title>
               <p>Each panel corresponds to a different bird. For a given panel, the colors in each part of the panel signify the same syllables. <italic>Left:</italic> letters (arbitrarily chosen for each bird) indicate a single phrase type, and arrows indicate phrase transitions. Entry and exit paths are color-coded and the exit paths are sorted and scaled by their transition probability. For instance, on the far left, if the bird sings T→B→D, then K is most likely to follow, whereas a J would most likely follow if he sang U→B→D. The light dotted arrows indicate other possible paths of exiting a block with p&gt;.05. For these other paths, the destination syllable is not shown. Actual transition probabilities with 95% bootstrap confidence intervals, and the number of transitions are given in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s018">Table S4</xref></bold>. <italic>Top right</italic>: song barcodes illustrate this effect for all occurrences of the phrase-block analyzed on the left. A square flanks each barcode to indicate the scale, with the height corresponding to 2 seconds and the width to 20 trials. Barcodes of the full song sequences are given in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s008">Fig. S6</xref>.</bold> <italic>Bottom right:</italic> example sonograms provide examples of how the entry path to a block of phrases changes the exit path.</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003052.g007" position="float" xlink:type="simple"/></fig>
      </sec>
      <sec id="s2f">
         <title>Reducing PST Markov order through phrase chunking</title>
         <p>The apparent statistical depth of the phrase structure could be reduced when sequences of phrases occur as a unit <xref ref-type="bibr" rid="pcbi.1003052-Kakishita1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1003052-Jin1">[16]</xref>. In sequence DABN for example, the choice of syllable D impacts choices after N, implying a fourth-order correlation. However, the PST transition probabilities for nodes A, B and N all have equivalent or near-equivalent values. The state space can be reduced to D (ABN)—a second-order model in phrase sequence “chunks.” In the process of constructing a PST, the nodes that can be collapsed into a single chunk without changing the predictive power of the model are “internal nodes.” These nodes do not impact the transition probability at the end of a chain, but just provide a connection from the leaves of the tree to the trunk. In <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref> and <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s010">Fig. S8</xref></bold> internal nodes are labeled with blue text labels. (Here internal nodes are defined as those nodes that would not have been added to the PST on their own strength, but are simply added to show the connections from the outer branches to the core of the graph. As such, the definition of internal node depends on the parameters used in the PST fit.) After collapsing internal nodes in these figures, the maximum depth of the suffix trees reduce from a range of 4–7 to a range of 2–3 in the 6 birds analyzed here, whereas the log-likelihood of the model changed, on average, by less than 1 percent, indicating that sequence chunks could be regarded as monolithic states without impacting the quality of the model.</p>
      </sec>
      <sec id="s2g">
         <title>First order models</title>
         <p>The PST provides a particularly compact representation of long-range dependencies in song. The compactness of the PST representation is emphasized by comparison of the PST graph with its corresponding probabilistic finite automaton (PFA) <xref ref-type="bibr" rid="pcbi.1003052-Ron1">[30]</xref>–a first-order transition model that can be more easily related to first-order dynamical models of neural activity. <xref ref-type="fig" rid="pcbi-1003052-g008"><bold>Fig. 8</bold></xref> illustrates the graph structure of the PFA for one bird, whose PST is given in the top of <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref>. To render the PFA visually interpretable, 363 edges were deleted from this figure that occur with less than 20 percent probability (more complete PFAs are shown in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s013">Fig. S11</xref></bold>). We emphasize that in spite of the complexity of <xref ref-type="fig" rid="pcbi-1003052-g008"><bold>Fig. 8</bold></xref> and <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s013">Fig. S11</xref></bold>, the PFA is only a statistical model for <italic>phrase transitions</italic>. The model does not account for phrase <italic>durations</italic>, or the fact that phrase durations depend on the recent history of the song–a point documented earlier–these features should be addressed in a more complete statistical model.</p>
         <fig id="pcbi-1003052-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1003052.g008</object-id><label>Figure 8</label>
            <caption>
               <title>Probabilistic finite automata (PFA) computed from prediction suffix trees (PSTs) reveal the complexity of canary song.</title>
               <p>The PFA shown here corresponds to the PST from the top of <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref>. Edges represent transitions between states, and the width indicates the probability of a given transition. Transitions from one state to another always result in the production of a new phrase type. For instance, the edge connecting ZDAB to BN represents the probability of singing N after ZDAB, which leads to the state BN. All edges with transition probabilities below .2 were removed for visualization (see <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s013">Fig. S11</xref></bold> for a more complete PFA).</p>
            </caption><graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1003052.g008" position="float" xlink:type="simple"/></fig>
      </sec>
      <sec id="s2h">
         <title>Tests for simple patterns</title>
         <p>We next examined whether the long-range correlations followed a simple adaptation rule. Long-range correlations could appear if the probability of a given phrase transition decays with the frequency of its use. That is, as each phrase transition occurs, its subsequent probability of occurrence is decreased. In the cases examined in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s011">Fig. S9</xref></bold>, no simple rule was observed—the most frequent syllable transition from a given phrase can increase or decrease in likelihood as a function of the number of times the phrase is produced in a given song. Over the transitions that we could analyze for this property, 33% strictly increased while 50% decreased, and 13% both increased and decreased over the course of a song (17/52, 26/52 and 7/52, respectively).</p>
         <p>We then checked to see if the statistical depth of canary song could be explained by limitations on song duration. The concern here is that some branches in the path of song might lead to unusually long songs that could be prohibited for physiological reasons. We analyzed all examples of context-dependencies and found no evidence for this effect (see <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s020">Text S1</xref></bold>). This search for simple rules explaining the apparent depth of canary song was not exhaustive, and a more extensive analysis involving additional samples from other canaries is needed.</p>
      </sec>
   </sec>
   <sec id="s3">
      <title>Discussion</title>
      <p>Canary song is built from elementary units, the syllables, repeated in groups to form a mesoscopic structure, the phrase. Phrases are flexibly sequenced to form songs. Correlations among phrase choices can extend over time-scales of 7–10 seconds. Over this time-scale, 4–5 phrases may be produced consisting of typically dozens of syllables. This observation significantly extends the time-scales that must be considered in dynamical models for song generation. We first discuss the time-scale of a single phrase. Dynamical theories for the central control of song are, in various forms, attractor models <xref ref-type="bibr" rid="pcbi.1003052-Katahira2">[31]</xref>–<xref ref-type="bibr" rid="pcbi.1003052-Yildiz1">[36]</xref>. If each phrase type is a separate attractor (or closed-neural chain) in canaries, then the phrase transition could be produced by a “kick” that recurs every second or so, inducing a hop from one attractor to another. Statistically, the phrase durations of canary song could also be described by a POMMA model <xref ref-type="bibr" rid="pcbi.1003052-Jin1">[16]</xref> if each syllable has a self-return probability that decreases with each repeat, as long as the adaptation rate scales inversely with syllable duration. More simply, phrase time-scales could be introduced into first order models like POMMA by introducing an adaptation that changes as a function of time rather than syllable repeats. Experiments are needed to determine whether canary phrase time-scales are defined by a fine-tuning of syllabic adaptation rates or a separate phrase transition process with its own intrinsic time-scale. Whatever the mechanism of defining phrase durations, it apparently does not need to be informed by any auditory experience with natural canary song, since birds reared in acoustic isolation also develop canary-typical phrase structure <xref ref-type="bibr" rid="pcbi.1003052-Gardner1">[22]</xref>.</p>
      <p>The observed structure of canary song significantly extends the time-scale of long-range correlations documented in bird song. For example, the sequence CDABNE from the top of <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref> has an average duration of eight seconds and the sequence YFHX from the bottom of <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref> has an average duration of ten seconds. Long-range rules in canary song can be compactly described, by 4<sup>th</sup>–7th order Markov processes acting on phrases, or a 2<sup>nd</sup>–3<sup>rd</sup> order Markov process acting on larger units that include blocks of multiple phrases.</p>
      <p>A suffix tree of depth 7 for 30 phrase types could in principle have 30∧7 nodes, and even a third order process in 30 phrase types could have 30∧3 nodes. In contrast to this large state space, the PSTs included in <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref> are quite sparse. The first-order generative models for the canary songs represented by the PFA diagrams contain only 47–56 states representing syllables or syllable strings. This is not greatly larger than the number of observable syllables (17–26). For canary song, the PST provides a particularly compact representation of syntax dependencies. The compactness of this representation is clear in comparisons between the PST tree and its corresponding first-order models (<bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s013">Fig. S11</xref></bold>). The speed and convergence properties of the PST algorithm make it possible to quickly cross-validate the structure of the PST over large ensembles of trials, defining the point at which over-fitting occurs. Taken together, these properties suggest that the PST analysis will be generally useful for characterizing the structure of birdsong syntax.</p>
      <p>Statistically complex phenomena that are best described by higher-order Markov processes such as the PST can be generated by simple physical processes. For example, if circulating neuromodulators in song nuclei depend on the syllables that are sung, and if syllable transitions themselves depend on the hypothetical neuromodulator, then stochastic variations in the beginning of a song could impact future transition probabilities, generating apparent “long-range rules”. In this scenario, additional information is needed to explain why some syllables show strong long-range rules, and others behave in a simple first-order manner.</p>
      <p>On a fine-grained scale, neural dynamics should be captured by a first-order statistical process. In statistical terms, long-range correlations in syntax imply that multiple “hidden states” can give rise to the observable syllable. This duplication of states statistically does not imply that the motor program for a syllable is duplicated–the smallest change in a syllable program satisfies the duplication of “hidden states.” Recent studies in Bengalese finches have observed that the stereotyped neural program for a syllable depends on its context–in particular, changes were observed in Basal Ganglia projecting neurons in nucleus HVC (used as a proper name) <xref ref-type="bibr" rid="pcbi.1003052-Fujimoto1">[37]</xref>, and subtle acoustic changes in syllable form were observed for syllable in different contexts <xref ref-type="bibr" rid="pcbi.1003052-Jin1">[16]</xref>. Whatever the mechanism of the long-range rules in canaries, the neural variables that carry the memory for past song choices can exert a powerful effect on transition statistics without significantly altering the acoustic form of syllables. This observation is supported through the high-resolution “spectral density” images introduced here to characterize syllable variability.</p>
      <p>Canary phrase structure and canary syllable form appear to be encoded by separable processes. This distinction is supported by the observation that phrase time-scales are not simply predicted by syllable time-scales. Another line of evidence arises in studies of song learning in juvenile canaries. As juveniles, canaries can learn to imitate artificial songs that lack normal phrase structure <xref ref-type="bibr" rid="pcbi.1003052-Gardner1">[22]</xref>. Rising testosterone levels that occur with the onset of the breeding season cause a rearrangement of song–the imitated syllables are reorganized into phrased repetitions. In this artificial tutoring paradigm, what is most dramatically reprogrammed in the transition to adulthood is not syllable acoustic structure, but the sequential organization of the syllables.</p>
      <p>Many questions remain about the neural basis of phrase structure in canary song, but we may also wonder about the relevance of the long-range rules for the natural behavior of the species. Is the statistical depth of song an epiphenomenon of little ethological relevance, or do canaries show preferences for songs with long-range order? Can a canary fine-tune the long-range rules to match a tutor song, or can a bird be trained to alter rule-sets in different behavioral contexts? These questions are addressable since canaries readily imitate artificial songs designed to pose specific questions about their vocal learning processes <xref ref-type="bibr" rid="pcbi.1003052-Gardner1">[22]</xref>.</p>
      <p>Lashley emphasized that the control of serial order in behavior is one of the most important and least understood aspects of neuroscience over 60 years ago <xref ref-type="bibr" rid="pcbi.1003052-Lashley1">[38]</xref>. Songbirds have provided an opportunity for examining sensory-motor learning of stereotyped neural sequences; dynamical models for song sequence generation have generally focused on stringing together bursts of neural activity in a long chain of elementary states <xref ref-type="bibr" rid="pcbi.1003052-Long1">[34]</xref>, <xref ref-type="bibr" rid="pcbi.1003052-Hahnloser1">[39]</xref>. This representation is remarkably similar to observed neural dynamics in zebra finches and Bengalese finches, and can be related to simple first-order statistical models for song production <xref ref-type="bibr" rid="pcbi.1003052-Jin1">[16]</xref>, <xref ref-type="bibr" rid="pcbi.1003052-Katahira1">[17]</xref>. However, the long-range rules that govern canary song extend to time-scales of 10 seconds, and persist while a bird vocalizes five or six intervening phrases, consisting of dozens of syllables each. How is information in the song circuit transferred over these time-scales? Answers to this question may provide general principles of how complex behaviors with long-range correlations are assembled from simple modules.</p>
   </sec>
   <sec id="s4" sec-type="materials|methods">
      <title>Materials and Methods</title>
      <sec id="s4a">
         <title>Ethics statement</title>
         <p>The care of animals in this study was carried out in accordance with Boston University IACUC protocol number 09-007.</p>
      </sec>
      <sec id="s4b">
         <title>Song recording</title>
         <p>Canaries (Belgian Waterslager strain) used in this study were a gift from Fernando Nottebohm. Birds were isolated at least two weeks before recording in soundproof boxes and kept on a light-dark cycle matched to the external annual light cycle in Boston (Boston University IACUC protocol number 09-007). All birds were at least one year old before isolation. Song was recorded between the months of March and April.</p>
      </sec>
      <sec id="s4c">
         <title>Song labeling and software</title>
         <p>Spectrograms of the song were calculated in MATLAB (Mathworks, Natick, MA), and the beginning, end, and syllable identity of each phrase was marked on the image by visual inspection. For all data described here, two independent observers annotated the songs. Observer 1 and observer 2 annotated 33,469 and 36,447 phrases, respectively, between 6 birds (see <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s015">Table S1</xref></bold> for the number of phrases analyzed for individual birds). The annotated sonograms were then scanned and converted into strings, and statistical analysis of the strings was performed using custom MATLAB scripts. Zero to two syllables were excluded per bird because the syllable form consisted of subtypes that could not be labeled consistently.</p>
      </sec>
      <sec id="s4d">
         <title>Mutual dependence analysis</title>
         <p>For each bird (6 total), we first examined the mutual dependence between a given phrase's duration and the path into or out of the phrase. That is, in a given phrase sequence XYZ, we examined the mutual dependence between the length of phrase Y and identity of the syllable type in phrase X or the identity of the syllable type in phrase Z, which we call MD(dur,path<sub>in</sub>) and MD(dur,path<sub>out</sub>), respectively. We discretized phrase durations by terciles and then used a variation of the Fisher test for <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e004" xlink:type="simple"/></inline-formula> contingency tables suitable for arbitrarily large, sparse <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e005" xlink:type="simple"/></inline-formula> contingency tables referred to as the Fisher-Freeman-Halton test <xref ref-type="bibr" rid="pcbi.1003052-Freeman1">[40]</xref>. Significance values for the test were then computed using a standard Monte Carlo procedure where the contingency tables were randomized while preserving the marginal values (i.e. the row and column totals), and to derive a p-value we calculated 1,000,000 randomizations for each test <xref ref-type="bibr" rid="pcbi.1003052-Agresti1">[41]</xref>. Using the same method, we also examined the mutual dependence between the syllable identity of phrase X and the syllable identity of phrase Z, for each Y, which we label MD(path<sub>in</sub>,path<sub>out</sub>).</p>
      </sec>
      <sec id="s4e">
         <title>Automated syllable clustering and alignment</title>
         <p>Custom MATLAB (Mathworks, Natick, MA) scripts were used for automated syllable clustering. After choosing a template, spectral features from the template and the rest of the data were computed using a sparse time-frequency representation <xref ref-type="bibr" rid="pcbi.1003052-Gardner3">[42]</xref> (see <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s020">Text S1</xref></bold>). As a final step, candidate sounds were plotted in two dimensions and a decision boundary was drawn by the user.</p>
      </sec>
      <sec id="s4f">
         <title>Spectral density images and similarity scores</title>
         <p>For a collection of syllables, we first generate a sparse time-frequency representation of each syllable using auditory contours <xref ref-type="bibr" rid="pcbi.1003052-Lim1">[25]</xref>. Auditory contours provide a high-resolution binary image consisting of sparse, continuous lines that follow the features of the sound with high precision. Summing over contours for all renditions of a syllable produces a two-dimensional probability density in time and frequency, which we call a spectral-density image, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e006" xlink:type="simple"/></inline-formula>. Specifically, a single contour image calculated at a given resolution is a sparse, binary time-frequency image or spectrogram <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e007" xlink:type="simple"/></inline-formula>, which we compute for each syllable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e008" xlink:type="simple"/></inline-formula>, denoted <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e009" xlink:type="simple"/></inline-formula>. The spectral density image is then defined as <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e010" xlink:type="simple"/></inline-formula>, where N is the number of binary images. By definition, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e011" xlink:type="simple"/></inline-formula> is the probability of finding a contour in pixel <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e012" xlink:type="simple"/></inline-formula> in a single sample, and in the images shown here, the value <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e013" xlink:type="simple"/></inline-formula> is represented by color scale. These images provide a direct representation of the variability of syllable form for every point in time and frequency.</p>
         <p>Since the starting matrices <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e014" xlink:type="simple"/></inline-formula> are sparse, and high precision, the spread of the acoustic energy revealed in <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e015" xlink:type="simple"/></inline-formula> may be narrower than the resolution of standard sonograms, for sparse stereotyped song elements. When interpreting these images, it must be understood that variations in frequency or timing of auditory contours both lead to a spread in spectral density; separating these sources of variability is not generally possible without additional analysis such as time-warping <xref ref-type="bibr" rid="pcbi.1003052-Gardner1">[22]</xref>.</p>
         <p>We define a simple similarity measure between two syllable contour images <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e016" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e017" xlink:type="simple"/></inline-formula> to be <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e018" xlink:type="simple"/></inline-formula>; With this definition, the average similarity between two groups <bold>A</bold> and <bold>B</bold> is just <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e019" xlink:type="simple"/></inline-formula> , the inner product of their spectral density images. The average similarity between a one specific syllable <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e020" xlink:type="simple"/></inline-formula> and an ensemble of syllables <bold>B</bold> is <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e021" xlink:type="simple"/></inline-formula>. To quantify the separability of two distributions we use the d′ measure, <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e022" xlink:type="simple"/></inline-formula>, or the difference in mean similarity scores in units of pooled standard deviation.</p>
      </sec>
      <sec id="s4g">
         <title>Prediction suffix trees</title>
         <p>To test for the existence of structure beyond second-order (as in the MD(path<sub>in</sub>,path<sub>out</sub>) test), we constructed prediction suffix trees (PSTs) for the sequence of canary phrase types using a previously published algorithm <xref ref-type="bibr" rid="pcbi.1003052-Ron1">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1003052-Bejerano1">[43]</xref>. Further details can be found in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s020">Text S1</xref></bold>.</p>
      </sec>
      <sec id="s4h">
         <title>Block entropy</title>
         <p>To compute block entropy we used standard methods based on Shannon entropy <xref ref-type="bibr" rid="pcbi.1003052-Rao1">[44]</xref>. The maximum entropy line in <xref ref-type="fig" rid="pcbi-1003052-g004"><bold>Fig. 4</bold></xref> assumes symbols are emitted with uniform probability.</p>
      </sec>
   </sec>
   <sec id="s5">
      <title>Supporting Information</title>
<supplementary-material id="pcbi.1003052.s001" mimetype="audio/mpeg" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s001" position="float" xlink:type="simple">
<label>Audio S1</label>
<caption><p><bold>Sample series of song bouts from a single canary.</bold></p>
      <p>(MP3)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s002" mimetype="audio/mpeg" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s002" position="float" xlink:type="simple">
<label>Audio S2</label>
<caption><p><bold>Sample series of song bouts from a single canary, separate from the bird used for Audio S1.</bold></p>
      <p>(MP3)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s003" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s003" position="float" xlink:type="simple">
<label>Figure S1</label>
<caption><p><bold>Pie charts of p-values for association tests.</bold> Charts computed using data from two observers are shown for six birds (each column is a different bird). The graphical conventions of the pie charts follow <xref ref-type="fig" rid="pcbi-1003052-g002"><bold>Fig. 2b</bold></xref> from the main text. Yellow indicates the proportion of syllables with highly significant interactions at the level <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e023" xlink:type="simple"/></inline-formula>, orange <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e024" xlink:type="simple"/></inline-formula> and blue <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e025" xlink:type="simple"/></inline-formula>.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s004" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s004" position="float" xlink:type="simple">
<label>Figure S2</label>
<caption><p><bold>Scatter plots of test statistic values computed for the MD(path<sub>in</sub>,path<sub>out</sub>) test show high inter-observer agreement.</bold> The x and y coordinates of each point are the Fisher-Freeman-Halton test statistic values computed for the same phrase type from each of the two observers for the MD(path<sub>in</sub>,path<sub>out</sub>) test. Linear regression lines are given in red and the unity line in blue, along with the r and p values under the abscissa. Each point in the graph is one phrase type for a specific bird.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s005" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s005" position="float" xlink:type="simple">
<label>Figure S3</label>
<caption><p><bold>Scatter plots of test statistic values computed for the MD(dur,path<sub>out</sub>) test show high inter-observer agreement.</bold> The x and y coordinates of each point are the Fisher-Freeman-Halton test statistic values computed for the same phrase type from each of the two observers for the MD(dur,path<sub>out</sub>) test. Linear regression lines are given in red and the unity line in blue, along with the r and p values under the abscissa. Each point in the graph is one phrase type for a specific bird.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s006" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s006" position="float" xlink:type="simple">
<label>Figure S4</label>
<caption><p><bold>Scatter plots of test statistic values computed for the MD(path<sub>in</sub>,dur) test show high inter-observer agreement.</bold> The x and y coordinates of each point are the Fisher-Freeman-Halton test statistic values computed for the same phrase type from each of the two observers for the MD(path<sub>in</sub>,dur) test. Linear regression lines are given in red and the unity line in blue, along with the r and p values under the abscissa. Each point in the graph is one phrase type for a specific bird.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s007" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s007" position="float" xlink:type="simple">
<label>Figure S5</label>
<caption><p><bold>Spectral density images demonstrate that syllables occurring in different contexts are highly similar.</bold> <bold>A,</bold> Spectral density images of syllables with different surrounding phrases reveal acoustic similarity. As in <xref ref-type="fig" rid="pcbi-1003052-g003"><bold>Fig. 3a</bold></xref>, spectral density images were computed for matching syllables that occur in different contexts; that is, different surrounding phrase types of earlier or later phrases. The particular phrase shown is highlighted in bold just above the image. The images were taken from 2 different birds. As in <xref ref-type="fig" rid="pcbi-1003052-g003"><bold>Fig. 3a</bold></xref>, each row contains the same syllable type in three context groups that are acoustically indistinguishable by our statistical test. <bold>B,</bold> With the spectral density image from the magenta group as a reference, syllables occurring in different sequences have overlapping similarity score distributions. The syllable types match those shown in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s007">Fig. S5a</xref></bold>. Summary statistics for all syllables types in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s007">Fig. S5a</xref></bold> are given in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s017">Table S3</xref></bold>.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s008" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s008" position="float" xlink:type="simple">
<label>Figure S6</label>
<caption><p><bold>Full song barcodes for the examples given in</bold> <xref ref-type="fig" rid="pcbi-1003052-g001"><bold>Fig. 1</bold></xref> <bold>and</bold> <xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref> <bold>allow for direct visualization of long-range rules.</bold> These barcodes represent the full song sequence corresponding to the examples given in <xref ref-type="fig" rid="pcbi-1003052-g001"><bold>Fig. 1</bold></xref> and <xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref><bold>. A,</bold> Barcodes for the example from <xref ref-type="fig" rid="pcbi-1003052-g001"><bold>Fig. 1a</bold></xref> centered on the first occurrence of the black phrase. <bold>B,</bold> Barcodes for the example in <xref ref-type="fig" rid="pcbi-1003052-g001"><bold>Fig. 1b</bold></xref> centered on the black and gray phrases. <bold>C,</bold> Barcodes for the example from the middle of <xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref> centered on the first occurrence of N (shown here in blue). <bold>D,</bold> Barcodes for the example from the bottom of <xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref> centered on the first occurrence of X. All colors match the phrases used in the corresponding parts of <xref ref-type="fig" rid="pcbi-1003052-g001"><bold>Fig. 1</bold></xref> and <xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref>, all other colors are arbitrarily assigned. A square flanks each barcode to indicate the scale, with the width corresponding to 2 seconds and the height to 20 trials.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s009" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s009" position="float" xlink:type="simple">
<label>Figure S7</label>
<caption><p><bold>Using cross-validation to verify PST fits.</bold> To select the parameters used in the PST algorithm, we used a 10-fold cross-validation procedure repeated 3 times (with different data splits). As a measure of model performance we used average negative log-likelihood. Here we show cross-validation results as a function of the PST parameter <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e026" xlink:type="simple"/></inline-formula>. This parameter defines the minimum rate of occurrence for a sequence to be considered for incorporating into the PST. The plot shows the mean of the negative log-likelihood across cross-validation fits for the training and testing data for all 6 birds (error bars indicate the 25<sup>th</sup> and 75<sup>th</sup> percentiles). Also shown is the average maximum order of the PSTs for a given value of <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e027" xlink:type="simple"/></inline-formula>. Overfitting leads to a decline in performance on the test set, or increased negative log-likelihood. In each case, the optimal performance on the test set occurs when <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e028" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e029" xlink:type="simple"/></inline-formula>. Below this point, performance on the test set degrades and sharply diverges from training set performance. We conservatively set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e030" xlink:type="simple"/></inline-formula> to .007 for all birds to avoid overfitting. The same procedure was used to set <inline-formula><inline-graphic xlink:href="info:doi/10.1371/journal.pcbi.1003052.e031" xlink:type="simple"/></inline-formula> and r, which had negligible effects on model performance (data not shown).</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s010" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s010" position="float" xlink:type="simple">
<label>Figure S8</label>
<caption><p><bold>PSTs for the 4 birds not shown in </bold><xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref><bold>.</bold></p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s011" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s011" position="float" xlink:type="simple">
<label>Figure S9</label>
<caption><p><bold>Shown are the transition probabilities from two different phrases sung by the same bird as a function of repetition number.</bold> <italic>Left:</italic> as phrase X is repeated, the most probable phrase transition from X to G decays, while the transition to S increases. <italic>Right:</italic> the opposite effect is seen in the same bird. The most probable transition, from H to X, increases as H is repeated.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s012" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s012" position="float" xlink:type="simple">
<label>Figure S10</label>
<caption><p><bold>Some syllables have context-dependent transitional forms.</bold> <bold>A,</bold> shown on the left are two example sonograms of the same phrase with different preceding phrases. In the two contexts, the first syllable of the phrase has a different transitional form (highlighted by the red and blue boxes). The image on the right is a color channel merge of two spectral density images, which were computing using the first syllable of all phrases in the two different contexts (top sonogram context is the red channel and bottom sonogram context the blue channel). <bold>B,</bold> the same effect is shown for a different phrase from a different bird.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s013" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s013" position="float" xlink:type="simple">
<label>Figure S11</label>
<caption><p><bold>Probabilistic finite automata (PFA) for all 6 birds analyzed.</bold> For visualization, all edges where p&lt;.05 have been removed, and all edges where p&lt;.2 are shown in thin light gray lines. Each PFA is completely determined by its corresponding PST. From top to bottom, the PFAs correspond to the PST shown in: the top left of <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s010">Fig. S8</xref></bold>; top right of <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s010">Fig. S8</xref></bold>; top of <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref>; bottom left of <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s010">Fig. S8</xref></bold>; bottom of <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref>; bottom right of <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s010">Fig. S8</xref></bold>.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s014" mimetype="image/tiff" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s014" position="float" xlink:type="simple">
<label>Figure S12</label>
<caption><p><bold>Phrase durations for all 6 birds analyzed.</bold> Each row corresponds to a different bird (same order as <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s013">Fig. S11</xref></bold>), and each group of points indicates the duration of a different phrase type. The colors (arbitrarily chosen) indicate different preceding phrase types. Abrupt changes in duration distribution that co-occur with color changes reveal a context-dependent shift in phrase length.</p>
      <p>(TIFF)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s015" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s015" position="float" xlink:type="simple">
<label>Table S1</label>
<caption><p><bold>The total number of phrases analyzed by each observer for individual birds.</bold> The bottom row contains the repertoire size for each bird.</p>
      <p>(DOCX)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s016" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s016" position="float" xlink:type="simple">
<label>Table S2</label>
<caption><p><bold>Summary statistics for similarity scores for duration groups (for each syllable type, scores were computed referenced to the spectral density image from the group marked*).</bold> STD, standard deviation.</p>
      <p>(DOCX)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s017" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s017" position="float" xlink:type="simple">
<label>Table S3</label>
<caption><p><bold>Summary statistics for similarity scores for sequence groups (for each syllable type, scores were computed referenced to the spectral density image from the group marked*).</bold> STD, standard deviation.</p>
      <p>(DOCX)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s018" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s018" position="float" xlink:type="simple">
<label>Table S4</label>
<caption><p><bold>Transition probabilities and number of transitions to accompany </bold><xref ref-type="fig" rid="pcbi-1003052-g007"><bold>Fig. 7</bold></xref><bold>.</bold> The 95% confidence intervals are given in brackets below the transition probabilities and were estimated using a bootstrap procedure with a case resampling scheme. That is, the transition probabilities were estimated after randomly resampling the data with replacement. The confidence interval is then defined as the 2.5<sup>th</sup> and 97.5<sup>th</sup> percentiles of the resampled distribution.</p>
      <p>(DOCX)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s019" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s019" position="float" xlink:type="simple">
<label>Table S5</label>
<caption><p><bold>Transition probabilities demonstrating alternative paths for prediction suffix trees (PSTs) shown in </bold><xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref><bold> and <xref ref-type="supplementary-material" rid="pcbi.1003052.s010">Fig. S8</xref>.</bold> The sequence DABN comes from the top PST in <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref>, HX from the bottom PST in <xref ref-type="fig" rid="pcbi-1003052-g005"><bold>Fig. 5</bold></xref>, and ZGKLH from the bottom left PST in <bold><xref ref-type="supplementary-material" rid="pcbi.1003052.s010">Fig. S8</xref></bold>.</p>
      <p>(DOCX)</p>
</caption></supplementary-material>
<supplementary-material id="pcbi.1003052.s020" mimetype="application/vnd.openxmlformats-officedocument.wordprocessingml.document" xlink:href="info:doi/10.1371/journal.pcbi.1003052.s020" position="float" xlink:type="simple">
<label>Text S1</label>
<caption><p><bold>Supplementary </bold><xref ref-type="sec" rid="s4"><bold>Materials and Methods</bold></xref><bold>.</bold></p>
      <p>(DOCX)</p>
</caption></supplementary-material>
   </sec>
</body>
<back>
   <ack>
      <p>The authors would like to thank Christopher Johnson and Lena Sherbakov for useful discussions regarding the statistical analysis, and Ian Davison for advice on visualizing the data. We would also like to thank the three anonymous reviewers for their substantial help in improving the manuscript.</p>
   </ack>
   <ref-list>
      <title>References</title>
      <ref id="pcbi.1003052-Fodor1"><label>1</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fodor</surname><given-names>JA</given-names></name> (<year>1985</year>) <article-title>Précis of The Modularity of Mind</article-title>. <source>Behavioral and Brain Sciences</source> <volume>8</volume>: <fpage>1</fpage>–<lpage>5</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1017/S0140525X0001921X" xlink:type="simple">10.1017/S0140525X0001921X</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Minsky1"><label>2</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Minsky</surname><given-names>M</given-names></name> (<year>1988</year>) <article-title>The Society of Mind</article-title>. <source>Simon and Schuster</source></mixed-citation></ref>
      <ref id="pcbi.1003052-Llins1"><label>3</label><mixed-citation publication-type="other" xlink:type="simple">Llinás RR (2002) I of the Vortex. MIT Press.</mixed-citation></ref>
      <ref id="pcbi.1003052-Falls1"><label>4</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Falls</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Krebs</surname><given-names>JR</given-names></name> (<year>1975</year>) <article-title>Sequence of songs in repertoires of western meadowlarks ( Sturnella neglecta)</article-title>. <source>Can J Zool</source> <volume>53</volume>: <fpage>1165</fpage>–<lpage>1178</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1139/z75-135" xlink:type="simple">10.1139/z75-135</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Catchpole1"><label>5</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Catchpole</surname><given-names>CK</given-names></name> (<year>1976</year>) <article-title>Temporal and sequential organisation of song in the sedge warbler (Acrocephalus schoenobaenus)</article-title>. <source>Behaviour</source> <volume>59</volume>: <fpage>226</fpage>–<lpage>246</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Kroodsma1"><label>6</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kroodsma</surname><given-names>DE</given-names></name> (<year>1977</year>) <article-title>Vocal virtuosity in the brown thrasher</article-title>. <source>The Auk</source> <volume>94</volume>: <fpage>783</fpage>–<lpage>785</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Slater1"><label>7</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Slater</surname><given-names>PJB</given-names></name> (<year>1983</year>) <article-title>Sequences of song in chaffinches</article-title>. <source>Anim Behav</source> <volume>31</volume>: <fpage>272</fpage>–<lpage>281</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/S0003-3472(83)80197-3" xlink:type="simple">10.1016/S0003-3472(83)80197-3</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Gentner1"><label>8</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gentner</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Hulse</surname><given-names>S</given-names></name> (<year>1998</year>) <article-title>Perceptual mechanisms for individual vocal recognition in European starlings, Sturnus vulgaris</article-title>. <source>Anim Behav</source> <volume>56</volume>: <fpage>579</fpage>–<lpage>594</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1006/anbe.1998.0810" xlink:type="simple">10.1006/anbe.1998.0810</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Todt1"><label>9</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Todt</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Hultsch</surname><given-names>H</given-names></name> (<year>1998</year>) <article-title>How songbirds deal with large amounts of serial information: retrieval rules suggest a hierarchical song memory</article-title>. <source>Biological Cybernetics</source> <volume>79</volume>: <fpage>487</fpage>–<lpage>500</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Gil1"><label>10</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gil</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Slater</surname><given-names>P</given-names></name> (<year>2000</year>) <article-title>Song organisation and singing patterns of the willow warbler, Phylloscopus trochilus</article-title>. <source>Behaviour</source> <volume>137</volume>: <fpage>759</fpage>–<lpage>782</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Okanoya1"><label>11</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Okanoya</surname><given-names>K</given-names></name> (<year>2004</year>) <article-title>The Bengalese finch: a window on the behavioral neurobiology of birdsong syntax</article-title>. <source>Annals of the New York Academy of Sciences</source> <volume>1016</volume>: <fpage>724</fpage>–<lpage>735</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Lemon1"><label>12</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lemon</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Dobson</surname><given-names>CW</given-names></name>, <name name-style="western"><surname>Clifton</surname><given-names>PG</given-names></name> (<year>2010</year>) <article-title>Songs of American Redstarts (Setophaga ruticilla): Sequencing Rules and their Relationships to Repertoire Size</article-title>. <source>Ethology</source> <volume>93</volume>: <fpage>198</fpage>–<lpage>210</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1439-0310.1993.tb00989.x" xlink:type="simple">10.1111/j.1439-0310.1993.tb00989.x</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Scharff1"><label>13</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Scharff</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Nottebohm</surname><given-names>F</given-names></name> (<year>1991</year>) <article-title>A comparative study of the behavioral deficits following lesions of various parts of the zebra finch song system: implications for vocal learning</article-title>. <source>Journal of Neuroscience</source> <volume>11</volume>: <fpage>2896</fpage>–<lpage>2913</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Gttinger1"><label>14</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Güttinger</surname><given-names>HR</given-names></name> (<year>1979</year>) <article-title>The Integration of Learnt and Genetically Programmed Behaviour</article-title>. <source>Zeitschrift für Tierpsychologie</source> <volume>49</volume>: <fpage>285</fpage>–<lpage>303</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Kakishita1"><label>15</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Kakishita</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Sasahara</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Nishino</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Takahasi</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Okanoya</surname><given-names>K</given-names></name> (<year>2008</year>) <article-title>Ethological data mining: an automata-based approach to extract behavioral units and rules</article-title>. <source>Data Mining and Knowledge Discovery</source> <volume>18</volume>: <fpage>446</fpage>–<lpage>471</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10618-008-0122-1" xlink:type="simple">10.1007/s10618-008-0122-1</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Jin1"><label>16</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jin</surname><given-names>DZ</given-names></name>, <name name-style="western"><surname>Kozhevnikov</surname><given-names>AA</given-names></name> (<year>2011</year>) <article-title>A compact statistical model of the song syntax in Bengalese finch</article-title>. <source>PLoS Computational Biology</source> <volume>7</volume>: <fpage>e1001108</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1001108" xlink:type="simple">10.1371/journal.pcbi.1001108</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Katahira1"><label>17</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Katahira</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Suzuki</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Okanoya</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Okada</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>Complex sequencing rules of birdsong can be explained by simple hidden Markov processes</article-title>. <source>PloS one</source> <volume>6</volume>: <fpage>e24516</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0024516" xlink:type="simple">10.1371/journal.pone.0024516</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Prather1"><label>18</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Prather</surname><given-names>JF</given-names></name>, <name name-style="western"><surname>Peters</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Nowicki</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Mooney</surname><given-names>R</given-names></name> (<year>2008</year>) <article-title>Precise auditory-vocal mirroring in neurons for learned vocal communication</article-title>. <source>Nature</source> <volume>451</volume>: <fpage>305</fpage>–<lpage>310</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature06492" xlink:type="simple">10.1038/nature06492</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Sakata1"><label>19</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Sakata</surname><given-names>JT</given-names></name>, <name name-style="western"><surname>Brainard</surname><given-names>MS</given-names></name> (<year>2006</year>) <article-title>Real-time contributions of auditory feedback to avian vocal motor control</article-title>. <source>J Neurosci</source> <volume>26</volume>: <fpage>9619</fpage>–<lpage>9628</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2027-06.2006" xlink:type="simple">10.1523/JNEUROSCI.2027-06.2006</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Hultsch1"><label>20</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hultsch</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Todt</surname><given-names>D</given-names></name> (<year>1989</year>) <article-title>Song Acquisition and Acquisition Constraints in the Nightingale, Luscinia-Megarhynchos</article-title>. <source>Naturwissenschaften</source> <volume>76</volume>: <fpage>83</fpage>–<lpage>85</lpage> <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://www.springerlink.com/content/q692437190083178/" xlink:type="simple">http://www.springerlink.com/content/q692437190083178/</ext-link></comment></mixed-citation></ref>
      <ref id="pcbi.1003052-Levitin1"><label>21</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Levitin</surname><given-names>DJ</given-names></name> (<year>2010</year>) <article-title>Why music moves us</article-title>. <source>Nature</source> <volume>464</volume>: <fpage>834</fpage>–<lpage>835</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/464834a" xlink:type="simple">10.1038/464834a</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Gardner1"><label>22</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gardner</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Naef</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Nottebohm</surname><given-names>F</given-names></name> (<year>2005</year>) <article-title>Freedom and rules: the acquisition and reprogramming of a bird's learned song</article-title>. <source>Science</source> <volume>308</volume>: <fpage>1046</fpage>–<lpage>1049</lpage> <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://www.sciencemag.org/content/308/5724/1046.short" xlink:type="simple">http://www.sciencemag.org/content/308/5724/1046.short</ext-link></comment></mixed-citation></ref>
      <ref id="pcbi.1003052-Belzner1"><label>23</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Belzner</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Voigt</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Catchpole</surname><given-names>CK</given-names></name>, <name name-style="western"><surname>Leitner</surname><given-names>S</given-names></name> (<year>2009</year>) <article-title>Song learning in domesticated canaries in a restricted acoustic environment</article-title>. <source>Proceedings of the Royal Society, Biological Sciences</source> <volume>276</volume>: <fpage>2881</fpage>–<lpage>2886</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rspb.2009.0669" xlink:type="simple">10.1098/rspb.2009.0669</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Gttinger2"><label>24</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Güttinger</surname><given-names>HR</given-names></name> (<year>1985</year>) <article-title>Consequences of domestication on the song structures in the canary</article-title>. <source>Behaviour</source> <volume>94</volume>: <fpage>254</fpage>–<lpage>278</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Lim1"><label>25</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Lim</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Shinn-Cunningham</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Gardner</surname><given-names>TJ</given-names></name> (<year>2012</year>) <article-title>Sparse contour representations of sound</article-title>. <source>IEEE Signal Processing Letters</source> <volume>19</volume>: <fpage>684</fpage>–<lpage>687</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Tchernichovski1"><label>26</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Tchernichovski</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Nottebohm</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Ho</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Pesaran</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Mitra</surname><given-names>P</given-names></name> (<year>2000</year>) <article-title>A procedure for an automated measurement of song similarity</article-title>. <source>Anim Behav</source> <volume>59</volume>: <fpage>1167</fpage>–<lpage>1176</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1006/anbe.1999.1416" xlink:type="simple">10.1006/anbe.1999.1416</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Gardner2"><label>27</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gardner</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Cecchi</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Magnasco</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Laje</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Mindlin</surname><given-names>G</given-names></name> (<year>2001</year>) <article-title>Simple Motor Gestures for Birdsongs</article-title>. <source>Physical Review Letters</source> <volume>87</volume>: <fpage>208101</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.87.208101" xlink:type="simple">10.1103/PhysRevLett.87.208101</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Mindlin1"><label>28</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Mindlin</surname><given-names>GB</given-names></name>, <name name-style="western"><surname>Gardner</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Goller</surname><given-names>F</given-names></name>, <name name-style="western"><surname>Suthers</surname><given-names>R</given-names></name> (<year>2003</year>) <article-title>Experimental support for a model of birdsong production</article-title>. <source>Physical review E, Statistical, nonlinear, and soft matter physics</source> <volume>68</volume>: <fpage>041908</fpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Elemans1"><label>29</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Elemans</surname><given-names>CPH</given-names></name>, <name name-style="western"><surname>Mead</surname><given-names>AF</given-names></name>, <name name-style="western"><surname>Rome</surname><given-names>LC</given-names></name>, <name name-style="western"><surname>Goller</surname><given-names>F</given-names></name> (<year>2008</year>) <article-title>Superfast vocal muscles control song production in songbirds</article-title>. <source>PloS one</source> <volume>3</volume>: <fpage>e2581</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pone.0002581" xlink:type="simple">10.1371/journal.pone.0002581</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Ron1"><label>30</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Ron</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Singer</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Tishby</surname><given-names>N</given-names></name> (<year>1996</year>) <article-title>The power of amnesia: Learning probabilistic automata with variable memory length</article-title>. <source>Machine Learning</source> <volume>25</volume>: <fpage>117</fpage>–<lpage>149</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1023/A:1026490906255" xlink:type="simple">10.1023/A:1026490906255</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Katahira2"><label>31</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Katahira</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Okanoya</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Okada</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>A neural network model for generating complex birdsong syntax</article-title>. <source>Biological Cybernetics</source> <volume>97</volume>: <fpage>441</fpage>–<lpage>448</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s00422-007-0184-y" xlink:type="simple">10.1007/s00422-007-0184-y</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Katahira3"><label>32</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Katahira</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Kawamura</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Okanoya</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Okada</surname><given-names>M</given-names></name> (<year>2007</year>) <article-title>Retrieval of Branching Sequences in an Associative Memory Model with Common External Input and Bias Input</article-title>. <source>J Phys Soc Jpn</source> <volume>76</volume>: <fpage>044804</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1143/JPSJ.76.044804" xlink:type="simple">10.1143/JPSJ.76.044804</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Jin2"><label>33</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Jin</surname><given-names>DZ</given-names></name> (<year>2009</year>) <article-title>Generating variable birdsong syllable sequences with branching chain networks in avian premotor nucleus HVC</article-title>. <source>Physical review E, Statistical, nonlinear, and soft matter physics</source> <volume>80</volume>: <fpage>051902</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.80.051902" xlink:type="simple">10.1103/PhysRevE.80.051902</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Long1"><label>34</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Long</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Jin</surname><given-names>DZ</given-names></name>, <name name-style="western"><surname>Fee</surname><given-names>MS</given-names></name> (<year>2010</year>) <article-title>Support for a synaptic chain model of neuronal sequence generation</article-title>. <source>Nature</source> <volume>468</volume>: <fpage>394</fpage>–<lpage>399</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature09514" xlink:type="simple">10.1038/nature09514</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Hanuschkin1"><label>35</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hanuschkin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Morrison</surname><given-names>A</given-names></name> (<year>2011</year>) <article-title>A reafferent and feed-forward model of song syntax generation in the Bengalese finch</article-title>. <source>Journal of Computational Neuroscience</source> <volume>31</volume>: <fpage>509</fpage>–<lpage>532</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-011-0318-z" xlink:type="simple">10.1007/s10827-011-0318-z</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Yildiz1"><label>36</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Yildiz</surname><given-names>IB</given-names></name>, <name name-style="western"><surname>Kiebel</surname><given-names>SJ</given-names></name> (<year>2011</year>) <article-title>A hierarchical neuronal model for generation and online recognition of birdsongs</article-title>. <source>PLoS Computational Biology</source> <volume>7</volume>: <fpage>e1002303</fpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002303" xlink:type="simple">10.1371/journal.pcbi.1002303</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Fujimoto1"><label>37</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Fujimoto</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Hasegawa</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Watanabe</surname><given-names>D</given-names></name> (<year>2011</year>) <article-title>Neural coding of syntactic structure in learned vocalizations in the songbird</article-title>. <source>J Neurosci</source> <volume>31</volume>: <fpage>10023</fpage>–<lpage>10033</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1606-11.2011" xlink:type="simple">10.1523/JNEUROSCI.1606-11.2011</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Lashley1"><label>38</label><mixed-citation publication-type="other" xlink:type="simple">Lashley K (1951) The problem of serial order in behavior. Psycholinguistics: A Book of Readings. New York: Holt.</mixed-citation></ref>
      <ref id="pcbi.1003052-Hahnloser1"><label>39</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Hahnloser</surname><given-names>RHR</given-names></name>, <name name-style="western"><surname>Kozhevnikov</surname><given-names>AA</given-names></name>, <name name-style="western"><surname>Fee</surname><given-names>MS</given-names></name> (<year>2002</year>) <article-title>An ultra-sparse code underlies the generation of neural sequences in a songbird</article-title>. <source>Nature</source> <volume>419</volume>: <fpage>65</fpage>–<lpage>70</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature00974" xlink:type="simple">10.1038/nature00974</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Freeman1"><label>40</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Freeman</surname><given-names>GH</given-names></name>, <name name-style="western"><surname>Halton</surname><given-names>JH</given-names></name> (<year>1951</year>) <article-title>Note on an exact treatment of contingency, goodness of fit and other problems of significance</article-title>. <source>Biometrika</source> <volume>38</volume>: <fpage>141</fpage>–<lpage>149</lpage> <comment>Available: <ext-link ext-link-type="uri" xlink:href="http://biomet.oxfordjournals.org/content/38/1-2/141.extract" xlink:type="simple">http://biomet.oxfordjournals.org/content/38/1-2/141.extract</ext-link></comment></mixed-citation></ref>
      <ref id="pcbi.1003052-Agresti1"><label>41</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Agresti</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Wackerly</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Boyett</surname><given-names>JM</given-names></name> (<year>1979</year>) <article-title>Exact conditional tests for cross-classifications: Approximation of attained significance levels</article-title>. <source>Psychometrika</source> <volume>44</volume>: <fpage>75</fpage>–<lpage>83</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF02293786" xlink:type="simple">10.1007/BF02293786</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Gardner3"><label>42</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Gardner</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Magnasco</surname><given-names>MO</given-names></name> (<year>2006</year>) <article-title>Sparse time-frequency representations</article-title>. <source>Proceedings of the National Academy of Sciences of the United States of America</source> <volume>103</volume>: <fpage>6094</fpage>–<lpage>6099</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0601707103" xlink:type="simple">10.1073/pnas.0601707103</ext-link></comment>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Bejerano1"><label>43</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Bejerano</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Yona</surname><given-names>G</given-names></name> (<year>2001</year>) <article-title>Variations on probabilistic suffix trees: statistical modeling and prediction of protein families</article-title>. <source>Bioinformatics</source> <volume>17</volume>: <fpage>23</fpage>–<lpage>43</lpage>.</mixed-citation></ref>
      <ref id="pcbi.1003052-Rao1"><label>44</label><mixed-citation publication-type="journal" xlink:type="simple"><name name-style="western"><surname>Rao</surname><given-names>RPN</given-names></name> (<year>2010</year>) <article-title>Probabilistic Analysis of an Ancient Undeciphered Script</article-title>. <source>IEEE Computer</source> <volume>43</volume>: <fpage>76</fpage>–<lpage>80</lpage> <comment>doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/MC.2010.112" xlink:type="simple">10.1109/MC.2010.112</ext-link></comment>.</mixed-citation></ref>
   </ref-list>
</back>
</article>
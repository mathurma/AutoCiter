<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-1338R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1001048</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology/Computational Neuroscience</subject><subject>Computer Science/Applications</subject><subject>Mathematics/Statistics</subject><subject>Neuroscience/Behavioral Neuroscience</subject><subject>Neuroscience/Cognitive Neuroscience</subject></subj-group></article-categories><title-group><article-title>Risk, Unexpected Uncertainty, and Estimation Uncertainty: Bayesian Learning in Unstable Settings</article-title><alt-title alt-title-type="running-head">Learning In Restless Bandits</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Payzan-LeNestour</surname><given-names>Elise</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Bossaerts</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>University of New South Wales, Sydney, Australia</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>California Institute of Technology, Pasadena, California, United States of America</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Swiss Finance Institute at EPFL, Lausanne, Switzerland</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Behrens</surname><given-names>Tim</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">John Radcliffe Hospital, United Kingdom</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">elise@unsw.edu.au</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: EP-LN. Performed the experiments: EP-LN. Analyzed the data: EP-LN. Wrote the paper: EP-LN PB. Supervised EP-LN: PB.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>1</month><year>2011</year></pub-date><pub-date pub-type="epub"><day>20</day><month>1</month><year>2011</year></pub-date><volume>7</volume><issue>1</issue><elocation-id>e1001048</elocation-id><history>
<date date-type="received"><day>2</day><month>11</month><year>2009</year></date>
<date date-type="accepted"><day>2</day><month>12</month><year>2010</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2011</copyright-year><copyright-holder>Payzan-LeNestour, Bossaerts</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Recently, evidence has emerged that humans approach learning using Bayesian updating rather than (model-free) reinforcement algorithms in a six-arm restless bandit problem. Here, we investigate what this implies for human appreciation of uncertainty. In our task, a Bayesian learner distinguishes three equally salient levels of uncertainty. First, the Bayesian perceives irreducible uncertainty or risk: even knowing the payoff probabilities of a given arm, the outcome remains uncertain. Second, there is (parameter) estimation uncertainty or ambiguity: payoff probabilities are unknown and need to be estimated. Third, the outcome probabilities of the arms change: the sudden jumps are referred to as unexpected uncertainty. We document how the three levels of uncertainty evolved during the course of our experiment and how it affected the learning rate. We then zoom in on estimation uncertainty, which has been suggested to be a driving force in exploration, in spite of evidence of widespread aversion to ambiguity. Our data corroborate the latter. We discuss neural evidence that foreshadowed the ability of humans to distinguish between the three levels of uncertainty. Finally, we investigate the boundaries of human capacity to implement Bayesian learning. We repeat the experiment with different instructions, reflecting varying levels of structural uncertainty. Under this fourth notion of uncertainty, choices were no better explained by Bayesian updating than by (model-free) reinforcement learning. Exit questionnaires revealed that participants remained unaware of the presence of unexpected uncertainty and failed to acquire the right model with which to implement Bayesian updating.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>The ability of humans to learn changing reward contingencies implies that they perceive, at a minimum, three levels of uncertainty: risk, which reflects imperfect foresight even after everything is learned; (parameter) estimation uncertainty, i.e., uncertainty about outcome probabilities; and unexpected uncertainty, or sudden changes in the probabilities. We describe how these levels of uncertainty evolve in a natural sampling task in which human choices reliably reflect optimal (Bayesian) learning, and how their evolution changes the learning rate. We then zoom in on estimation uncertainty. The ability to sense estimation uncertainty (also known as ambiguity) is a virtue because, besides allowing one to learn optimally, it may guide more effective exploration; but aversion to estimation uncertainty may be maladaptive. Here, we show that participant choices reflected aversion to estimation uncertainty. We discuss how past imaging studies foreshadowed the ability of humans to distinguish the different notions of uncertainty. Also, we document that the ability of participants to do such distinction relies on sufficient revelation of the payoff-generating model. When we induced structural uncertainty, participants did not gain awareness of the jumps in our task, and fell back to model-free reinforcement learning.</p>
</abstract><funding-group><funding-statement>The authors acknowledge financial support from the Swiss Finance Institute and from NCCR FINRISK of the Swiss National Science Foundation. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript application.</funding-statement></funding-group><counts><page-count count="14"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>In an environment where reward targets and loss sources are stochastic, and subject to sudden, discrete changes, the key problem humans face is learning. At a minimum, they need to be able to assess <italic>estimation uncertainty</italic> <xref ref-type="bibr" rid="pcbi.1001048-Daw1">[1]</xref>–<xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref>, i.e., the extent to which learning still has to be completed. High levels of estimation uncertainty call for more learning, while low levels of estimation uncertainty would suggest slower learning.</p>
<p>To correctly gauge estimation uncertainty, two additional statistical properties of the environment ought to be evaluated: <italic>risk</italic>, or how much irreducible uncertainty would be left even after the best of learning; and <italic>unexpected uncertainty</italic>, or how likely it is that the environment suddenly changes <xref ref-type="bibr" rid="pcbi.1001048-Yu1">[5]</xref>. The notion of risk captures the idea that, to a certain extent, forecast errors are expected, and therefore should not affect learning. Under unexpected uncertainty, these same forecast errors are indications that learning may have to be re-started because outcome contingencies have changed discretely.</p>
<p>With Bayesian learning, the three notions of uncertainty are tracked explicitly. This is because Bayesians form a model of the environment that delineates the boundaries of risk, estimation uncertainty and unexpected uncertainty. The delineation is crucial: estimation uncertainty tells Bayesians how much still needs to be learned, while unexpected uncertainty leads them to forget part of what they learned in the past.</p>
<p>This contrasts with model-free reinforcement learning. There, uncertainty is monolithic: it is the expected magnitude of the prediction error <xref ref-type="bibr" rid="pcbi.1001048-Bossaerts1">[6]</xref>. Under reinforcement learning, only the value of a chosen option is updated, on the basis of the reward (or loss) prediction error, i.e., the difference between the received and the anticipated reward (or loss) <xref ref-type="bibr" rid="pcbi.1001048-Wagner1">[7]</xref>. No attempt is made to disentangle the different sources of the prediction error. Usually, the learning rate is kept constant. If not, as in the Pearce-Hall algorithm <xref ref-type="bibr" rid="pcbi.1001048-Pearce1">[8]</xref>, adjustment is based on the <italic>total</italic> size of the prediction error.</p>
<p>Recently, evidence has emerged that, in environments where risk, estimation uncertainty and unexpected uncertainty all vary simultaneously, humans choose as if they were Bayesians <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>. Formally, the experiment that generated this evidence involved a six-arm restless bandit problem. Participants were asked to choose among six options with different risk profiles and differing frequencies of changes in reward (and loss) probabilities. Assuming softmax exploration <xref ref-type="bibr" rid="pcbi.1001048-Daw2">[10]</xref>, the Bayesian updating model was shown to provide a significantly improved fit over standard reinforcement learning as well as the Pearce-Hall extension.</p>
<p>To discover that humans are Bayesians implies that they must have tracked the three levels of uncertainty. Here, we discuss how the levels differentially affected the Bayesian learning rate in our restless bandit task, and how participants could have distinguished between them.</p>
<p>Neural implementation of Bayesian learning would require separate encoding of the three levels of uncertainty. Recent human imaging studies appear to be consistent with this view. The evidence has only been suggestive, however, as no imaging study to date involved independent control of risk, estimation uncertainty and unexpected uncertainty.</p>
<p>Indeed, to our knowledge, ours is the first comprehensive study of risk, estimation uncertainty, and unexpected uncertainty. Many studies have focused on risk <xref ref-type="bibr" rid="pcbi.1001048-Paulus1">[11]</xref>–<xref ref-type="bibr" rid="pcbi.1001048-Preuschoff1">[13]</xref>. Estimation uncertainty has been investigated widely in the economics literature, where it is referred to as ambiguity <xref ref-type="bibr" rid="pcbi.1001048-Ellsberg1">[14]</xref>, and a few imaging studies have explored its neurobiological basis <xref ref-type="bibr" rid="pcbi.1001048-Yoshida1">[3]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Hsu1">[15]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Huettel2">[16]</xref>. Unexpected uncertainty has only rarely been considered <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Yu1">[5]</xref>. <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref> is closest to our study in that it was the first to document that humans correctly adjust their learning rates to changes in the average level of unexpected uncertainty (referred to in <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref> as <italic>volatility</italic>).</p>
<p>The task in <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref> involved a bandit with only two arms, however. For our purposes, this entails a number of disadvantages. First, it is impossible to independently track the three levels of uncertainty with only two arms; at a minimum, six arms are needed, and this is what is implemented in the experiment here. As a matter of fact, in <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref>, risk was decreased along with unexpected uncertainty, introducing a confound that masked the full effect of unexpected uncertainty on the learning rate. Second, the two arms in <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref> have perfectly negatively correlated reward probabilities, and as such, the task is one of reversal learning <xref ref-type="bibr" rid="pcbi.1001048-Hampton1">[17]</xref>. This means that outcomes for one arm are fully informative for the other one. Consequently, exploration is of no consequence.</p>
<p>This is important because, here, we are interested in re-visiting the data in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref> and investigate exploration. One of the notions of uncertainty, namely, estimation uncertainty, is not only an important determinant of the learning rate. It has been conjectured to be a key driving force behind exploration. Specifically, some have proposed that an “exploration bonus” be added to the value of an option, and that this exploration bonus be increased with the need to learn, i.e., with estimation uncertainty <xref ref-type="bibr" rid="pcbi.1001048-Daw1">[1]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Daw2">[10]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Kakade1">[18]</xref>.</p>
<p>In our six-arm restless bandit problem, estimation uncertainty varied substantially over time and across arms, thus providing power to detect the presence of an exploration bonus in valuation, and hence, an effect of estimation uncertainty on exploration. Before our study, behavioral evidence in favor of an exploration bonus had been weak: <xref ref-type="bibr" rid="pcbi.1001048-Daw2">[10]</xref> showed that human exploration can be modeled using softmax, but found no reliable evidence of an exploration bonus. But in their (four-armed) bandit problem, estimation uncertainty varied little across bandits, unlike in ours.</p>
<p>Firing of dopaminergic neurons in response to novel, uncertain stimuli has been interpreted as signaling exploration value <xref ref-type="bibr" rid="pcbi.1001048-Kakade1">[18]</xref>; yet, it can be questioned whether estimation uncertainty ought to enter valuation through a bonus. Findings in economics, starting with <xref ref-type="bibr" rid="pcbi.1001048-Allais1">[19]</xref>, would make one believe otherwise. There, evidence abounds that humans are averse to estimation uncertainty – there called <italic>ambiguity</italic>. Ambiguity aversion often leads to fundamental inconsistencies in choices, as exemplified by the <italic>Ellsberg Paradox</italic> <xref ref-type="bibr" rid="pcbi.1001048-Ellsberg1">[14]</xref>. If anything, this suggests that estimation uncertainty enters valuation through a penalty.</p>
<p>We re-visited the choices generated by the restless six-arm bandit problem of <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref> and investigated whether estimation uncertainty changed valuation positively (exploration bonus) or negatively (ambiguity penalty).</p>
<p>Finally, we studied to what extent the empirical support for Bayesian learning depended on the level of detail participants received regarding the outcome generating process. In <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>, participants were fully informed about the structure of the bandit problem (risks could be different across bandits; probabilities jumped with differing frequency across bandits; and jumps occurred simultaneously for a number of bandits). They were ignorant only about the values of the parameters (outcome probabilities, jump frequencies, occurrence of jumps). As such, there was no “structural uncertainty” (or <italic>Knightian</italic> uncertainty as it is known in economics; <xref ref-type="bibr" rid="pcbi.1001048-Knight1">[20]</xref>–<xref ref-type="bibr" rid="pcbi.1001048-Draper1">[24]</xref>). In contrast, in <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref>, participants were naive about the task structure, so there was substantial structural uncertainty. There, participant choices reflected adjustment of learning rates to <italic>average</italic> unexpected uncertainty, suggesting that they had learned some aspects of the outcome generating process.</p>
<p>Here, we report new results that clarify to what extent <italic>trial-by-trial</italic> choices reflected Bayesian updating under structural uncertainty. We re-ran the six-arm restless bandit experiment, but we varied the amount of structural uncertainty. In one treatment, we told participants nothing about the outcome generating process. In another treatment, we informed the participants about everything except unexpected uncertainty. The third treatment was a replication of <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>, to calibrate the findings.</p>
</sec><sec id="s2">
<title>Results</title>
<sec id="s2a">
<title>Formal Analysis of the Task</title>
<p>Our task was a six-arm restless bandit problem, visually presented as a board game (see <xref ref-type="fig" rid="pcbi-1001048-g001">Fig. 1A</xref>). Arms were color-coded: the outcome probabilities for the red arms jumped more frequently. At each trial, arms paid one of three possible rewards: 1, 0 and −1 Swiss francs (CHF) for the blue arms, and 2, 0, −2 CHF for the red arms. Outcome probabilities were unknown.</p>
<fig id="pcbi-1001048-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001048.g001</object-id><label>Figure 1</label><caption>
<title>Six-arm restless bandit task.</title>
<p><bold>A</bold> The six-arm restless bandit is implemented graphically as a board game. Six locations correspond to the six arms. Locations are color-coded; blue locations have lower average unexpected uncertainty than red locations. Blue locations pay 1, 0 or −1 CHF (Swiss francs). Red locations pay 2, 0 or −2 CHF. Chosen option is highlighted (in this case, location 5). Participants can freely choose a location each trial. Histories of outcomes in locations chosen in the past are shown by means of coin piles. <bold>B</bold> Visual representation of risk and estimation uncertainty. Risk can be tracked using entropy, which depends on the relative magnitudes of the outcome probabilities, i.e., the relative heights of the bars in the left chart. The bars represent the three estimated outcome probabilities (mean of the posterior probability distribution or PPD). Entropy (risk) is maximal when the bars are all equal. Estimation uncertainty is represented by the widths of the posterior distributions of the outcome probabilities, depicted in the right chart.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.g001" xlink:type="simple"/></fig>
<p>Outcome probabilities within a color group jumped simultaneously. Participants did not know the jump frequencies. Nor did they know when jumps occurred. As such, there was unexpected uncertainty. After a jump, the outcome probabilities are given new, unknown values. Specifically, they did not revert to old values as in reversal learning tasks (e.g., <xref ref-type="bibr" rid="pcbi.1001048-Hampton1">[17]</xref>), and hence, there is estimation uncertainty throughout the duration of the task.</p>
<p>In the version of this task in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>, participants were fully informed about the structure of the outcome generating process. They merely had to learn (and, after each perceived jump, re-learn) the values of the outcome probabilities, as well as the probabilities of a jump (or the occurrence of a jump). We replicated this base version – to be referred to as Treatment 3 below. Additionally, we ran two variations of this board game, where we reduced the amount of structural information we gave the participants. We elaborate below. The three variations represent varying levels of model or structural uncertainty.</p>
<p>To analyze the results, we implemented a <italic>forgetting Bayesian algorithm</italic> <xref ref-type="bibr" rid="pcbi.1001048-Quinn1">[25]</xref> based on multinomial sampling under the Dirichlet prior with dynamic adjustment of the learning rate to evidence of the presence of jumps. In <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>, a hierarchical Bayesian scheme was investigated as well. While qualitatively the same (and producing indistinguishable behavioral fits), the forgetting algorithm produces <italic>explicit learning rates</italic>, while in the hierarchical Bayesian approach, learning rates are only implicit. The availability of explicit formulae facilitated our analysis of the impact of the three levels of uncertainty on the learning speed.</p>
<p>In each trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e001" xlink:type="simple"/></inline-formula>, an option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e002" xlink:type="simple"/></inline-formula> generated either the fixed loss outcome, denoted by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e003" xlink:type="simple"/></inline-formula>, with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e004" xlink:type="simple"/></inline-formula>, the null outcome (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e005" xlink:type="simple"/></inline-formula>), with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e006" xlink:type="simple"/></inline-formula>, or the fixed reward outcome (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e007" xlink:type="simple"/></inline-formula>), with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e008" xlink:type="simple"/></inline-formula>. The triplet <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e009" xlink:type="simple"/></inline-formula> is in the three-dimensional simplex <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e010" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e011" xlink:type="simple"/></inline-formula>.</p>
<p>We start from the same prior distribution of outcome probabilities for all options. It is denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e012" xlink:type="simple"/></inline-formula>. We take it to be an uninformative Dirichlet. At each trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e013" xlink:type="simple"/></inline-formula> the Bayesian model updates the distribution of outcome probabilities based on a sufficient statistic that is constructed from the count vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e014" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e015" xlink:type="simple"/></inline-formula>. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e016" xlink:type="simple"/></inline-formula> denotes point mass at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e017" xlink:type="simple"/></inline-formula>. The forgetting algorithm takes the weighted geometric mean between the usual Bayesian update of the Dirichlet prior absent jumps and the original prior (for the case a jump occurred). Weighting is based on the subjective likelihood that no jump has occurred at trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e018" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e019" xlink:type="simple"/></inline-formula> – more on the nature of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e020" xlink:type="simple"/></inline-formula> below. For large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e021" xlink:type="simple"/></inline-formula>, the resulting posterior is Dirichlet, like the prior. Specifically,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e022" xlink:type="simple"/></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e023" xlink:type="simple"/><label>(1)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e024" xlink:type="simple"/><label>(2)</label></disp-formula>where<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e025" xlink:type="simple"/></disp-formula>is the effective number of data used in the estimation of the outcome probabilities. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e026" xlink:type="simple"/></inline-formula> is the set of trials before (and including) trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e027" xlink:type="simple"/></inline-formula> when option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e028" xlink:type="simple"/></inline-formula> was chosen. The sufficient statistic <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e029" xlink:type="simple"/></inline-formula> is defined as:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e030" xlink:type="simple"/></disp-formula>Significantly, this sufficient statistic can be obtained using simple recursive computations. Specifically, if option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e031" xlink:type="simple"/></inline-formula> was chosen in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e032" xlink:type="simple"/></inline-formula>,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e033" xlink:type="simple"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e034" xlink:type="simple"/></inline-formula>, the learning rate, equals:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e035" xlink:type="simple"/><label>(4)</label></disp-formula>The other case (when option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e036" xlink:type="simple"/></inline-formula> was not chosen in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e037" xlink:type="simple"/></inline-formula>) is discussed in the <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<p>In Eqn 3, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e038" xlink:type="simple"/></inline-formula> controls the relative weight of the new observation during learning. As such, it functions as the Bayesian learning rate. This is fortunate. Usually, the learning speed in Bayesian updating is only implicit; e.g., <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref>. Because we have chosen to implement a forgetting algorithm, the speed of learning becomes explicit, in the form of a learning rate to be applied to the new observation.</p>
<p>The posterior mean outcome probabilities are computed as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e039" xlink:type="simple"/></disp-formula>From these posterior means, the Bayesian decision maker computes the expected value (payoff) of option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e040" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e041" xlink:type="simple"/></inline-formula>.</p>
<p>To model adjudication between the six options, we opted for a softmax rule. Specifically, in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e042" xlink:type="simple"/></inline-formula>, option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e043" xlink:type="simple"/></inline-formula> is chosen with probability<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e044" xlink:type="simple"/><label>(5)</label></disp-formula>Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e045" xlink:type="simple"/></inline-formula> (also referred to as inverse temperature) measures the propensity to choose the option of currently greatest value rather than the others. As such, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e046" xlink:type="simple"/></inline-formula> reflects the trade-off between the urge to exploit, i.e., to choose the best option, and the interest in exploring, i.e., to choose options currently deemed sub-optimal with the goal of learning more about their values <xref ref-type="bibr" rid="pcbi.1001048-Ishii1">[26]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-AstonJones1">[27]</xref>.</p>
</sec><sec id="s2b">
<title>Evolution of Uncertainty and Effect on the Learning Rate</title>
<p><xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref> documents that in the current task, learning strategies behind human choices are better explained using Bayesian updating than (model-free) reinforcement learning, even if the learning rates in the latter are allowed to differ across choices with differing jump probability, or allowed to change over time as a function of the size of the reward prediction error. Crucial to correct setting of the Bayesian learning rate in our task is the ability to track three levels of uncertainty: risk, parameter estimation uncertainty, and unexpected uncertainty. The Bayesian model tracks these three levels independently, and they jointly affect the learning rate. We first illustrate their evolution, and then elaborate on how they modulate the learning rate.</p>
<p>Risk can be measured by the entropy of the outcome probabilities. Since outcome probabilities are unknown throughout our experiment, entropy needs to be estimated. We compute entropy based on the posterior mean of the outcome probabilities. See <xref ref-type="fig" rid="pcbi-1001048-g001">Fig. 1B</xref> for a graphical representation (left panel). Estimation uncertainty, on the other hand, reflects the spread of the posterior distribution of outcome probabilities. One could estimate it as the variance of the posterior distribution, or its entropy. See <xref ref-type="sec" rid="s4">Methods</xref> for more information. Estimation uncertainty is depicted graphically in <xref ref-type="fig" rid="pcbi-1001048-g001">Fig. 1B</xref> (right panel). Unexpected uncertainty is the likelihood that outcome probabilities jump. Unexpected uncertainty changes over time, as evidence for jumps fluctuates. Average unexpected uncertainty differs also across options: blue locations on our board game have lower chance of jumping; red locations exhibit higher jump probabilities.</p>
<p><xref ref-type="fig" rid="pcbi-1001048-g002">Fig. 2A</xref> displays the evolution of estimation uncertainty in one instance of the task, based on choices of one participant. Estimation uncertainty is measured here at each trial as entropy of the posterior distribution of outcome probabilities. Estimation uncertainty is shown only for the chosen option. Blue dots indicate that an option was chosen with low average unexpected uncertainty (a blue location); red dots indicate choices of options with high average unexpected uncertainty (red locations). Estimation uncertainty increases each time the participant switches locations. The participant either switches to another location with the same color code (same average unexpected uncertainty) or to a location with a different color code.</p>
<fig id="pcbi-1001048-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001048.g002</object-id><label>Figure 2</label><caption>
<title>Three kinds of uncertainty in the task.</title>
<p><bold>A</bold> Evolution of the estimation uncertainty (entropy of mean posterior outcome probabilities) of chosen options in one instance of the board game. Learning is based on choices of one participant in our experiment. Blue dots on the horizontal axis indicate trials when a blue location was chosen; red dots indicate trials when a red location was visited. <bold>B</bold> Evolution of the unexpected uncertainty of chosen options in one instance of the board game, measured (inversely) as the probability that no jump has occurred. Learning is based on choices of one participant in our experiment. Blue dots on the horizontal axis indicate trials when outcome probabilities for the visited blue location jumped; red dots indicate trials when outcome probabilities for the visited red location jumped. <bold>C</bold> Average estimated risk (entropy of outcome probabilities) in one instance of the board game, by location (numbered 1 to 6). Learning is based on the choices of one participant in our experiment. Locations are arranged by level of unexpected uncertainty (blue: low; red: high). Average estimated risks are compared with true risks. The participant managed to distinguish risk differentials across blue locations, but not across red locations. Average estimated risks regress towards the grand mean because of estimation uncertainty after each jump in outcome probabilities.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.g002" xlink:type="simple"/></fig>
<p><xref ref-type="fig" rid="pcbi-1001048-g002">Fig. 2B</xref> displays the evolution of the probability that no jump occurred in the first 200 trials of another instance. High levels indicate low levels of unexpected uncertainty. Low levels suggest detection of a jump, and hence, high unexpected uncertainty. Blue dots indicate trials when the chosen option was blue (low average unexpected uncertainty) and a jump in blue locations occurred simultaneously. Red dots indicate trials when the chosen option was red and a jump occurred (for the red options). At times, the participant seemed to have falsely detected a jump (e.g., in trial 54); but generally, the participant's belief that a jump has occurred correlates with actual occurrence of jumps.</p>
<p>The presence of unexpected uncertainty and the recurring parameter estimation uncertainty make it more difficult to correctly assess risk. <xref ref-type="fig" rid="pcbi-1001048-g002">Fig. 2C</xref> shows the mean level of risk assessed in one instance of the task. Bayesian updating is assumed. Shown are the average outcome entropies of each of the six options based on posterior mean probabilities. Options are numbered 1 through 6. For comparison, we also display the true outcome entropies. Results are stratified by level of average unexpected uncertainty: blue options had lower probability of jumps in outcome probabilities, while red options had high jump probabilities. The presence of high unexpected uncertainty affects learning of risk levels. On average, correct assignment of risk obtains for blue locations. But it is more difficult to correctly assess the risk of red locations.</p>
<p>The latter illustrates the <italic>antagonistic relationship</italic> <xref ref-type="bibr" rid="pcbi.1001048-Yu1">[5]</xref> between the perceptions of unexpected uncertainty and risk. If the former is high, the latter is harder to estimate. A legitimate concern is, therefore, whether these two sources of uncertainty can be separately identified if participants are not told about their presence. We will elaborate below.</p>
<p>The different levels of uncertainty affect the learning rate in complex ways. Inspection of Eqn. 4 shows that the learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e047" xlink:type="simple"/></inline-formula> changes as a function of the ratio of the probability that no jump has occurred and the past learning rate:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e048" xlink:type="simple"/></disp-formula>If the evidence for unexpected uncertainty is very low, i.e., if a jump is deemed unlikely, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e049" xlink:type="simple"/></inline-formula> is close to 1, and hence, the learning rate decreases as in the absence of jumps, reflecting merely the decrease in estimation uncertainty. If, in contrast, the evidence for jumps is high, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e050" xlink:type="simple"/></inline-formula> is close to zero, then the learning rate increases towards 1 irrespective of the past learning rate. This increase reflects the likely presence of a jump, and hence, the need to learn anew. That is, estimation uncertainty increases and so should the learning rate.</p>
<p>This shows how unexpected uncertainty affects estimation uncertainty, and hence, the learning rate. While not directly, estimation uncertainty itself does affect the learning rate, through its effect on unexpected uncertainty. This can be verified by inspecting the formula for the probability that no jump occurred in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e051" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e052" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e053" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e054" xlink:type="simple"/></inline-formula> denote the estimated probability, initially and in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e055" xlink:type="simple"/></inline-formula> respectively, of observing outcome <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e056" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e057" xlink:type="simple"/></inline-formula>, for loss, zero income, and gain, respectively) and where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e058" xlink:type="simple"/></inline-formula> parameterizes the precision of the posterior distribution of outcome probabilities, which depends on the effective number of data used in estimating those outcome probabilities (see Eqn. 2). (See <xref ref-type="sec" rid="s4">Methods</xref> for the derivation.) Estimation uncertainty, or its inverse, precision of the posterior distribution of outcome probabilities, therefore influences the estimate of the likelihood that no jump has occurred, and hence, unexpected uncertainty. In turn, unexpected uncertainty determines changes in the learning rate.</p>
<p>An analogous result obtains for risk – here defined as the entropy of the outcome probabilities. Intuitively, entropy is the variability in the probabilities across possible outcomes. If all outcome probabilities are the same, entropy is maximal. If one or more outcome probabilities are extreme (high or low), then entropy will be low. Eqn. 6 shows that unexpected uncertainty depends on outcome probabilities. The intuition is simple: if a particular outcome is estimated to occur with low probability, and that outcome does realize, the likelihood that it occurred because there was a jump is higher; conversely, if an outcome had high <italic>a priori</italic> probability, then its occurrence is unlikely to be attributed to unexpected uncertainty. Through its effect on unexpected uncertainty, estimated outcome probabilities have an effect on the learning rate.</p>
<p>Consequently, while the three levels of uncertainty separately influence the learning rate, unexpected uncertainty is pivotal. That is, estimation uncertainty and risk impact the learning rate through their effect on unexpected uncertainty. For instance, if the probability of an outcome is estimated with low precision (estimation uncertainty is high) or if it is estimated to be average (around <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e059" xlink:type="simple"/></inline-formula>), revealing high risk, then the realization of this outcome is unlikely to be attributed to a jump. The parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e060" xlink:type="simple"/></inline-formula> is therefore high, and the Bayesian learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e061" xlink:type="simple"/></inline-formula> reduces as if one were in a jump-free world.</p>
<p><xref ref-type="fig" rid="pcbi-1001048-g003">Fig. 3</xref> displays the evolution of the learning rate for two options in one instance of the task. Shown are the (logarithm of) the learning rates of (i) an option with low risk and low average jump probability (low average unexpected uncertainty) [top], (ii) an option with low risk and high average jump probability [bottom]. The learning history is based on the actual choices of one of the participants in the experiment. Crosses on the horizontal axis indicate trials where the participant chose the option at hand.</p>
<fig id="pcbi-1001048-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001048.g003</object-id><label>Figure 3</label><caption>
<title>Evolution of the (logarithm of the) Bayesian learning rate for two options in one instance of the board game.</title>
<p>Learning is based on the choices of one participant in our experiment. Top option has low average unexpected uncertainty (low chance of jumps) and low risk (one outcome probability was very high); bottom option has high average unexpected uncertainty and low risk. Crosses on the horizontal axis indicate trials when the option was chosen.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.g003" xlink:type="simple"/></fig>
<p>One can easily discern the effect of a reduction in estimation uncertainty on the learning rate. During episodes when the participant chooses an option, she learns about the outcome probabilities, which reduces estimation uncertainty, and hence, the learning rate. This continues until she stops visiting the location at hand, and consequently, the – now imaginary – learning rate increases again. (We call the learning rate “imaginary” because there are no outcomes to be used to update beliefs; belief updating for the unchosen options evolve only because of what one learns about the chosen options.)</p>
</sec><sec id="s2c">
<title>Exploration Bonuses and Ambiguity Penalties</title>
<p>To implement Bayesian learning, the decision maker has, at a minimum, to track estimation uncertainty. As such, the decision maker senses that she does not know the parameters, and hence, she is ambiguity sensitive.</p>
<p>In multi-armed bandit settings, exploration is valuable. Only by trying out options will one be able to learn, thus reducing estimation uncertainty. As such, there should be a bonus to exploration of options with high ambiguity. This was recently proposed <xref ref-type="bibr" rid="pcbi.1001048-Kakade1">[18]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Doya1">[28]</xref>. Decision makers should therefore be ambiguity seeking, which conflicts with claims that humans generally exhibit ambiguity aversion <xref ref-type="bibr" rid="pcbi.1001048-Ellsberg1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Allais1">[19]</xref>.</p>
<p>Here, we re-visit behavior in our six-arm restless bandit task to determine to what extent choices reflect the presence of an exploration bonus or an ambiguity penalty, both equal to the level of estimation uncertainty. To this end, we added to the expected value of each option an exploration bonus, or alternatively, we subtracted an ambiguity penalty – computational details are provided in <xref ref-type="sec" rid="s4">Methods</xref>. For each participant, we compared the maximum log-likelihood of the model with exploration bonus to that of the base version of the Bayesian model; likewise, we compared the log-likelihood of the model with ambiguity penalty to that of the base model. The log-likelihood of a model is defined by Eqn. 8 in <xref ref-type="sec" rid="s4">Methods</xref>.</p>
<p>The model with exploration bonus fitted worse than the one without any correction of valuations for estimation uncertainty. In contrast, the model with ambiguity penalty generated a better likelihood than did the base version of the Bayesian model for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e062" xlink:type="simple"/></inline-formula> of the participants. The individual log-likelihoods are reported graphically in <xref ref-type="supplementary-material" rid="pcbi.1001048.s001">Fig.S1</xref> of the Supporting Information. <xref ref-type="fig" rid="pcbi-1001048-g004">Fig. 4</xref> displays the mean negative log-likelihoods and the corresponding sample standard deviations across the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e063" xlink:type="simple"/></inline-formula> subjects. A <italic>paired t-test</italic> based on the difference between the log-likelihoods of the two models (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e064" xlink:type="simple"/></inline-formula>) leads to reject the hypothesis that this difference is null with a p-value equal to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e065" xlink:type="simple"/></inline-formula>.</p>
<fig id="pcbi-1001048-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001048.g004</object-id><label>Figure 4</label><caption>
<title>Goodness-of-fits of the Bayesian models, with (right) and without (left) penalty for ambiguity.</title>
<p>Based on approximately 500 choices of 62 participants. Data are from <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>. Heights of bars indicate mean of the individual negative log-likelihood; line segments indicate standard deviations. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e066" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e067" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e068" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e069" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e070" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e071" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.g004" xlink:type="simple"/></fig></sec><sec id="s2d">
<title>Structural Uncertainty</title>
<p>To investigate to what extent the evidence in favor of Bayesian updating is related to our providing subjects with ample structural knowledge of the outcome generating process, we ran a new experiment. We considered three treatments. In the first treatment, we provided subjects only with the rules of the game, and no structural information. In the second treatment, subjects were given some structural information (e.g., within a color group, one option was “biased” in the sense that its entropy was lower, while another option was close to random), but were left ignorant about the presence of jumps in the outcome probabilities; which means they were not informed about the potential of unexpected uncertainty. The third treatment was a replication of the original setting in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>.</p>
<p>43 undergraduates from the same institution (Ecole Polytechnique Fédérale Lausanne) participated in the first treatment; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e072" xlink:type="simple"/></inline-formula> (30) of them participated in the second (third) treatment. (We presented the three treatments as three separate experiments, whereby participants in the first treatment were invited but not forced to participate in the two others.)</p>
<p>To calibrate the results, we first compare the fits of the third treatment to those of <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>. Like in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>, we compare the log-likelihood of the base version of the Bayesian model to the one of a Rescorla-Wagner rule in which the learning rates are allowed to differ across choices with differing jump probability (henceforth, the “reinforcement learning model”), and also to the one of the Pearce-Hall extension of reinforcement learning. <xref ref-type="fig" rid="pcbi-1001048-g005">Fig. 5</xref> displays the mean BIC across the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e073" xlink:type="simple"/></inline-formula> participants for each of the three models – the BIC or <italic>Schwarz Criterion</italic> <xref ref-type="bibr" rid="pcbi.1001048-Kass1">[29]</xref> of a model is the negative log-likelihood corrected for differences in number of parameters to be estimated. Corresponding sample standard deviations are also reported. A paired t-test based on the difference between the BICs of the Bayesian and reinforcement learning models (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e074" xlink:type="simple"/></inline-formula>) leads to the conclusion that the Bayesian model fitted better than the reinforcement learning model with a p-value smaller than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e075" xlink:type="simple"/></inline-formula>. Like in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>, the Pearce-Hall model fitted the data worst. The finding that the model with ambiguity penalty provided the best fit is also replicated. The distributions of the individual log-likelihoods for all four models (the base version of the Bayesian model, the version with ambiguity penalty, the reinforcement learning model and the Pearce-Hall extension) are available in the Supporting Information (see <xref ref-type="supplementary-material" rid="pcbi.1001048.s002">Fig.S2</xref>).</p>
<fig id="pcbi-1001048-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001048.g005</object-id><label>Figure 5</label><caption>
<title>Replication of the experiment in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>.</title>
<p>Mean BICs and standard deviations of the Bayesian, reinforcement and Pearce-Hall learning models without structural uncertainty (Treatment 3). Based on the choices of 30 participants in approximately 500 trials of our board game. The Bayesian model is the base version (unadjusted for ambiguity aversion). <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e076" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e077" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e078" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e079" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e080" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e081" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.g005" xlink:type="simple"/></fig>
<p>Having replicated the results with full disclosure of the structure of the outcome generating process, we turn to the first treatment, where subjects were not given any structural information. <xref ref-type="fig" rid="pcbi-1001048-g006">Fig. 6A</xref> compares the mean BIC of the Bayesian model with ambiguity penalty – which appeared to outperform the base Bayesian model in all treatments – to the one of the reinforcement learning model. Corresponding sample standard deviations are displayed as well. The fit of the ambiguity averse Bayesian model now does not improve any more upon simple reinforcement learning, according to a paired <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e082" xlink:type="simple"/></inline-formula>-test based on the difference between the BICs of the two models (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e083" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e084" xlink:type="simple"/></inline-formula>). In the second treatment, the reinforcement learning model marginally outperformed the ambiguity averse Bayesian model: a paired <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e085" xlink:type="simple"/></inline-formula> test (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e086" xlink:type="simple"/></inline-formula>) leads to the conclusion that the reinforcement learning model fitted better with a p-value equal to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e087" xlink:type="simple"/></inline-formula>. See <xref ref-type="fig" rid="pcbi-1001048-g006">Fig. 6B</xref>. In both treatments, the fit of the Pearce-Hall model was worst for the large majority of the subjects, and we do not report it on <xref ref-type="fig" rid="pcbi-1001048-g006">Fig. 6A</xref> or <xref ref-type="fig" rid="pcbi-1001048-g006">Fig. 6B</xref>. The distributions of the individual log-likelihoods of all models are reported in the Supporting Information (see <xref ref-type="supplementary-material" rid="pcbi.1001048.s003">Fig.S3</xref> and <xref ref-type="supplementary-material" rid="pcbi.1001048.s004">Fig.S4</xref>).</p>
<fig id="pcbi-1001048-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1001048.g006</object-id><label>Figure 6</label><caption>
<title>Goodness-of-fits of the Bayesian and reinforcement learning models under varying levels of structural uncertainty.</title>
<p><bold>A</bold> Goodness-of-fits of the Bayesian and reinforcement learning models under full structural uncertainty (Treatment 1). Based on the choices of 43 participants in approximately 500 trials of our board game. The Bayesian model includes a penalty for estimation uncertainty – like in the data from <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>, this model turned out to fit the data better than the base version of the Bayesian model. Heights of bars indicate mean of the individual Bayesian Information Criterion (BIC); line segments indicate standard deviations. The difference in the mean BIC is not significant (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e088" xlink:type="simple"/></inline-formula>). <bold>B</bold> Goodness-of-fits of the Bayesian and reinforcement learning models under partial structural uncertainty (Treatment 2). Mean BICs and standard deviations of the Bayesian and reinforcement learning models in Treatment 2. Based on the choices of 32 participants in approximately 500 trials of our board game. The Bayesian model includes a penalty for estimation uncertainty. Participants knew the structure of the game except for the jumps in outcome probabilities. They were told that the description of the structure was incomplete. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e089" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e090" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e091" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e092" xlink:type="simple"/></inline-formula>; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e093" xlink:type="simple"/></inline-formula>: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e094" xlink:type="simple"/></inline-formula>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.g006" xlink:type="simple"/></fig>
<p>Common to both Treatments 1 and 2 is the absence of information on the presence of unexpected uncertainty. The findings suggest that participants were not able to recognize that outcome probabilities jumped. To verify this conjecture, we examined the answers to the debriefing questionnaire after the experiment – participant answers are available upon request. Pooling the first two treatments (with a total of 75 cases), only <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e095" xlink:type="simple"/></inline-formula> participants detected the presence of instability (they realized that for certain of the six arms, “dark periods” alternated with good ones during the task). When asked whether it would be “equally difficult to learn on the red locations and the blue ones,” many subjects answered affirmatively, despite the fact that the probability of a jump (in outcome probabilities) on the red locations was four times higher. A typical case was that of a participant in the second treatment who reported: “At some point I got several bad outcomes but I tried to be rational and stay since it was the good one.” The participant mis-attributed a sequence of bad outcomes to risk, rather than interpreting it as evidence for a regime shift.</p>
<p>These findings are significant. In no way did the instructions attempt to mislead the participants. On the contrary, we stated explicitly that subjects had to watch out for features of the outcome generating process other than those spelled out in the instructions. In contrast, in the third treatment (as well as in the original experiment of <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>), responses on the debriefing questionnaire indicated that participants managed to detect changes during the task, and could often estimate quite accurately the relative jump probabilities across location colors.</p>
</sec></sec><sec id="s3">
<title>Discussion</title>
<sec id="s3a">
<title>Neural Evidence for Separate Encoding of Uncertainty Levels</title>
<p>On occasion, humans have been shown to choose like Bayesian decision makers. In a context where outcome contingencies change constantly, this implies that humans should be able to distinguish various types of uncertainty, from unexpected uncertainty, over (parameter) estimation uncertainty, to risk. We will argue here that there exists emerging neurobiological evidence for separate encoding of these categories of uncertainty. As such, key components for neural implementation of Bayesian learning have become identified in the human brain.</p>
<p>Numerous studies have localized neural signals correlating with risk. Some sub-cortical regions are also involved in tracking expected reward (striatal regions; <xref ref-type="bibr" rid="pcbi.1001048-Preuschoff2">[30]</xref>) and the relatively crude fMRI evidence is supported by single-unit recordings in the monkey brain <xref ref-type="bibr" rid="pcbi.1001048-Fiorillo1">[31]</xref>; the evidence for neural signals of risk independent of expected reward has been identified mostly in cortical structures (anterior insula, anterior cingulate cortex, inferior frontal gyrus, and interparietal sulcus) <xref ref-type="bibr" rid="pcbi.1001048-Paulus1">[11]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Huettel1">[12]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Preuschoff2">[30]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-VanniMercier1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1001048-Christopoulos1">[35]</xref>.</p>
<p>Estimation uncertainty, or ambiguity as it is referred to in economics, has also recently been investigated in imaging studies. Early evidence pointed to involvement of the amygdala and lateral orbitofrontal cortex <xref ref-type="bibr" rid="pcbi.1001048-Hsu1">[15]</xref>; subsequent parametric work has corroborated <xref ref-type="bibr" rid="pcbi.1001048-Huettel1">[12]</xref> and extended with activation of the frontopolar cortex <xref ref-type="bibr" rid="pcbi.1001048-Yoshida1">[3]</xref>. Experimental paradigms where estimation uncertainty is manipulated as in the six-arm restless bandit problem have yet to be organized.</p>
<p>Involvement of locus coeruleus and the neurotransmitter norepinephrine in tracking unexpected uncertainty has been conjectured a number of times and the evidence in its favor is suggestive <xref ref-type="bibr" rid="pcbi.1001048-Yu1">[5]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Doya1">[28,28]</xref>, but further proof is needed. Unexpected uncertainty will have to be manipulated parametrically, as norepinephrine is known to be generally involved in attention modulation as well as general exploratory behavior <xref ref-type="bibr" rid="pcbi.1001048-Cohen1">[36]</xref>. Without parametric manipulation, activations can as well be interpreted as reflecting attention or exploration.</p>
<p>Activation of the amygdala-hippocampus complex to novel images in a learning context may be conjectured to reflect unexpected uncertainty <xref ref-type="bibr" rid="pcbi.1001048-Strange1">[37]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Rutishauser1">[38]</xref>. Neural correlates with the Bayesian learning rate have been identified in the precuneus and anterior cingulate cortex <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Rushworth1">[39]</xref>. Because of the close relationship between the Bayesian learning rate and unexpected uncertainty (effects of risk and estimation uncertainty on the learning rate operate through unexpected uncertainty, as explained before), these neural signals could as well reflect unexpected uncertainty (changes in the likelihood that outcome probabilities have jumped).</p>
</sec><sec id="s3b">
<title>Bayesian Exploration</title>
<p>Evidence has thus emerged that the distinction of the three forms of uncertainty exists at the neuronal level. The well-documented sensitivity of humans to ambiguity (estimation uncertainty) further proves that the distinction can readily be observed in behavior. Confirming humans' sensitivity to estimation uncertainty, we presented evidence here that participants' tendency to explore in a six-arm restless bandit task decreased with estimation uncertainty. This finding falsifies the hypothesis that estimation uncertainty ought to induce exploration. It is, however, consistent with evidence of ambiguity aversion in the experimental economics literature, starting with <xref ref-type="bibr" rid="pcbi.1001048-Ellsberg1">[14]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Allais1">[19]</xref>. We are the first to show the parametric relationship between estimation uncertainty and exploration: the relationship is negative.</p>
<p>The reader may wonder why we have not augmented the reinforcement learning model with an ambiguity penalty, and examined the behavioral fit of this version of model-free reinforcement learning. The point is that non-Bayesians do not sense ambiguity. Indeed, the concept of a posterior belief is foreign to non-Bayesian updating, and hence, the variance or entropy of the posterior distribution of outcome probabilities, our two measures of estimation uncertainty, are quintessentially Bayesian. Since the representation of ambiguity is absent in the context of model-free reinforcement learning, a fortiori ambiguity cannot weigh in the exploration strategy. In light of this, one should not combine model-free reinforcement learning with an ambiguity penalty/bonus.</p>
</sec><sec id="s3c">
<title>Ambiguity vs. Structural Uncertainty</title>
<p>A third major finding was that full Bayesian updating is reflected in human learning only if enough structural information of the outcome generating process is provided. Specifically, the ability to track unexpected uncertainty, and hence, to detect jumps in the outcome probabilities, appeared to rely on instructions that such jumps would occur. When participants were not informed about the presence of unexpected uncertainty, their choices could equally well be explained in terms of simple reinforcement learning. This evidence emerged despite suggestions to watch for features of the outcome generating process that were not made explicit in the instructions.</p>
<p>Situations where decision makers are ignorant of the specifics of the outcome generating process entail model or structural uncertainty. Our study is the first to discover that humans cannot necessarily resolve model uncertainty. In our experiment, many participants failed to recognize the presence of unexpected uncertainty. Consequently, in the exit questionnaires they often took the arms to be “random” [in our language, risky] which illustrates the antagonistic relationship between risk and unexpected uncertainty – jumps were confounded with realization of risk.</p>
<p>Our participants' failure to detect jumps may suggest that their “mental models” excluded nonstationarity <italic>a priori</italic>. Mental models are expectancies or predispositions which serve to select and organize the information coming from the environment <xref ref-type="bibr" rid="pcbi.1001048-Craik1">[40]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Epstein1">[41]</xref>. <italic>Nudging</italic> <xref ref-type="bibr" rid="pcbi.1001048-Thaler1">[42]</xref> may be needed, whereby the instructions bring the likely presence of jumps to the attention of the participants.</p>
<p>Structural uncertainty was originally suggested in the economics literature, where it is referred to as <italic>Knightian</italic> or <italic>Keynesian</italic> uncertainty <xref ref-type="bibr" rid="pcbi.1001048-Knight1">[20]</xref>, <xref ref-type="bibr" rid="pcbi.1001048-Keynes1">[21]</xref>. Nevertheless, even in economics, structural uncertainty is often treated interchangeably with estimation uncertainty or ambiguity; e.g., <xref ref-type="bibr" rid="pcbi.1001048-Dow1">[43]</xref>. In principle, structural uncertainty can be dealt with by introducing extra parameters that identify the possible models of the outcome generating process. Structural uncertainty thereby collapses to simple (parameter) estimation uncertainty.</p>
<p>Nevertheless, we think it is important to refrain from reducing structural uncertainty to mere parameter estimation uncertainty, because the number of possible models of the outcome generating process in any given situation is large, and hence, the number of parameters to be added to capture structural uncertainty can be prohibitively high <xref ref-type="bibr" rid="pcbi.1001048-Draper1">[24]</xref>. It is well known that Bayesian updating will fail dramatically when the parameter space is high-dimensional <xref ref-type="bibr" rid="pcbi.1001048-Diaconis1">[44]</xref>; in such situations, model-free reinforcement learning produces, in a simple and consistent way, the right statistics to guide choice.</p>
<p>The latter may explain our finding that human choice in our six-arm restless bandit task reveals less evidence of Bayesian updating when we introduce structural uncertainty. Since reinforcement learning provides ready guidance in situations where Bayesian updating may fail, our participants understandably switched learning strategies. Because they became (model-free) reinforcement learners, they no longer detected unexpected uncertainty. Indeed, uncertainty is monolithic in the absence of a model of the outcome generating process; there is no distinction between risk, estimation uncertainty, unexpected uncertainty, or even model uncertainty.</p>
<p>To conclude, our results suggest that learning-wise, structural uncertainty should not be thought of as an extension of ambiguity. We thus advocate a separation of situations entailing structural uncertainty and situations entailing ambiguity in future studies of decision making under uncertainty. We would also advocate a clear separation of situations where the outcome probabilities change suddenly and the related but mathematically distinct situations, where outcome probabilities change continuously. The former entail unexpected uncertainty. The latter are analogous to the contexts where Kalman filtering provides optimal forecasts, but where risk is stochastic. In financial economics, one therefore uses the term <italic>stochastic volatility</italic> <xref ref-type="bibr" rid="pcbi.1001048-Sangjoon1">[45]</xref>. Recently, computational neuroscientists have underscored the need to distinguish between unexpected uncertainty and stochastic volatility <xref ref-type="bibr" rid="pcbi.1001048-Courville1">[46]</xref>.</p>
<p>In our six-arm restless bandit, the three levels of uncertainty change in equally salient ways. Future imaging studies could therefore rely on our task to better localize the encoding of uncertainty and its three components. In addition, our task could allow one to investigate engagement of brain structures in the determination of the learning rate.</p>
</sec></sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<sec id="s4a">
<title>Ethics Statement</title>
<p>All the experiments reported on here had the approval from the ethics commission of the Ecole Polytechnique Fédérale Lausanne.</p>
</sec><sec id="s4b">
<title>The Task</title>
<p>We implemented a six-arm restless bandit task with a board game. See <xref ref-type="fig" rid="pcbi-1001048-g001">Fig. 1A</xref>. Participants played approximately 500 trials of this game. We investigated learning behind participants' choices from two experiments. The data from the first experiment were originally presented in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>. In this experiment, participants were given precise instructions about the structure of the outcome generating process. That is, there was no structural uncertainty. In the second experiment, we invited new participants to play our board game, under one of three treatments. In Treatment 1, participants were not told anything about the structure of the outcome generating process. That is, there was full structural uncertainty. In Treatment 2, participants were told everything about the outcome generating process except the presence of jumps. Participants were warned that the structural description was not complete, and were invited to pay attention to possible structure beyond that revealed in the instructions. Treatment 3 was a replication of the experiment in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref> – as such, there was no structural uncertainty.</p>
</sec><sec id="s4c">
<title>Bayesian Learning in the Task</title>
<p>In our Bayesian learning model, the distribution of outcome probabilities is updated using Bayes' law and a <italic>stabilized forgetting</italic> <xref ref-type="bibr" rid="pcbi.1001048-Quinn1">[25]</xref> operator. At trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e096" xlink:type="simple"/></inline-formula>, Bayes' law transforms the given prior to the posterior using the likelihood of the observed outcome and the prior. The transformation depends on a sufficient statistic which is constructed from the count vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e097" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e098" xlink:type="simple"/></inline-formula>. Here, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e099" xlink:type="simple"/></inline-formula> denotes the point mass at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e100" xlink:type="simple"/></inline-formula> (i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e101" xlink:type="simple"/></inline-formula> if the outcome at location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e102" xlink:type="simple"/></inline-formula> in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e103" xlink:type="simple"/></inline-formula> equals <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e104" xlink:type="simple"/></inline-formula>, and 0 otherwise).</p>
<p>Since our task involves multinomial outcomes, we chose a Dirichlet prior to initiate learning. Without jumps, posterior distributions will be Dirichlet as well. As initial (first-trial) prior, we take the uninformative Dirichlet with center <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e105" xlink:type="simple"/></inline-formula> and precision <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e106" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e107" xlink:type="simple"/></inline-formula>. Formally, the Dirichlet prior equals:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e108" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e109" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e110" xlink:type="simple"/></inline-formula> is the Gamma function (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e111" xlink:type="simple"/></inline-formula>) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e112" xlink:type="simple"/></inline-formula> denotes the three-dimensional simplex, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e113" xlink:type="simple"/></inline-formula>.</p>
<p>Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e114" xlink:type="simple"/></inline-formula> denote the posterior distribution absent jumps. It is obtained from the prior in the usual way, by combining the prior with the (multinomial) likelihood of the count vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e115" xlink:type="simple"/></inline-formula>. The posterior is Dirichlet as well, like the prior.</p>
<p>In a stationary world, this would provide the optimal inference. Because jumps may occur (outcome probabilities may change), we augment the standard Bayesian updating using a forgetting operator, which we denote <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e116" xlink:type="simple"/></inline-formula>.</p>
<p><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e117" xlink:type="simple"/></inline-formula> combines two distributions to generate a new posterior, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e118" xlink:type="simple"/></inline-formula>. These two distributions are the following.</p>
<list list-type="bullet"><list-item>
<p>After a jump in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e119" xlink:type="simple"/></inline-formula>, the posterior should no longer be <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e120" xlink:type="simple"/></inline-formula>, but another reference probability distribution. Here, we use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e121" xlink:type="simple"/></inline-formula>, the initial prior.</p>
</list-item><list-item>
<p>In the absence of a jump, the decision maker should use the standard Bayesian posterior, here denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e122" xlink:type="simple"/></inline-formula>.</p>
</list-item></list>
<p>Therefore, in principle, the new posterior should either be <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e123" xlink:type="simple"/></inline-formula>, when there is no jump, or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e124" xlink:type="simple"/></inline-formula>, when there is one. But the decision maker does not observe jumps directly, and hence, has to weight the two cases based on the evidence for a jump. Our forgetting operator thus mixes the two possibilities:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e125" xlink:type="simple"/></disp-formula></p>
<p>From minimization of a Bayes risk criterion, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e126" xlink:type="simple"/></inline-formula> has to be taken to be a <italic>weighted geometric mean</italic> (see <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>). That is, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e127" xlink:type="simple"/></inline-formula> is the (weighted) geometric mean of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e128" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e129" xlink:type="simple"/></inline-formula>. The weight depends on the estimate of the likelihood that a jump has not occurred, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e130" xlink:type="simple"/></inline-formula>. (Note that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e131" xlink:type="simple"/></inline-formula> depends on the color of the location only, as all options within a same color category jump simultaneously.) The complement of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e132" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e133" xlink:type="simple"/></inline-formula>, is a measure of jump likelihood, and hence, unexpected uncertainty.</p>
<p>Consequently, the forgetting operator equals:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e134" xlink:type="simple"/></disp-formula></p>
<p>The geometric mean is a tractable way to introduce information on unexpected uncertainty in the updating because, for large <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e135" xlink:type="simple"/></inline-formula>, the posterior probability distribution is well approximated by a Dirichlet distribution, so that updates remain in the same family of distributions as the priors, namely, the family of Dirichlet priors. The proof is available upon request.</p>
<p>Another advantage of the forgetting operator, important for our purposes, is that updating can be expressed directly in terms of a learning rate. Usually, with Bayesian updating, learning rates are only implicit (because the Bayes transformation is generally non-linear). We shall use the symbol <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e136" xlink:type="simple"/></inline-formula> for the learning rate for option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e137" xlink:type="simple"/></inline-formula> in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e138" xlink:type="simple"/></inline-formula>.</p>
<p>Specifically, with the forgetting algorithm, the posterior mean probability vector is computed as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e139" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e140" xlink:type="simple"/></inline-formula>, the effective number of observations used to update beliefs for location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e141" xlink:type="simple"/></inline-formula>, equals<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e142" xlink:type="simple"/></disp-formula>if location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e143" xlink:type="simple"/></inline-formula> was chosen in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e144" xlink:type="simple"/></inline-formula>, and otherwise:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e145" xlink:type="simple"/></disp-formula>and where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e146" xlink:type="simple"/></inline-formula> is a sufficient statistic based on past observed outcomes for location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e147" xlink:type="simple"/></inline-formula>, and updated as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e148" xlink:type="simple"/></disp-formula>if option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e149" xlink:type="simple"/></inline-formula> was chosen in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e150" xlink:type="simple"/></inline-formula>, and<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e151" xlink:type="simple"/></disp-formula>if not.</p>
<p>The learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e152" xlink:type="simple"/></inline-formula> determines the weight on the most recent observation in the updating equation for the sufficient statistic <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e153" xlink:type="simple"/></inline-formula>. It is defined, recursively, as follows: if location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e154" xlink:type="simple"/></inline-formula> is chosen in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e155" xlink:type="simple"/></inline-formula>, then<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e156" xlink:type="simple"/></disp-formula>otherwise<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e157" xlink:type="simple"/></disp-formula>One can express the learning rate non-recursively:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e158" xlink:type="simple"/></disp-formula>where the set <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e159" xlink:type="simple"/></inline-formula> contains the trials up to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e160" xlink:type="simple"/></inline-formula> when location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e161" xlink:type="simple"/></inline-formula> was visited.</p>
</sec><sec id="s4d">
<title>Model-Free Reinforcement Learning</title>
<p>For model-free reinforcement learning, we applied a simple Rescorla-Wagner rule. Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e162" xlink:type="simple"/></inline-formula> denote the value of option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e163" xlink:type="simple"/></inline-formula> after the outcome in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e164" xlink:type="simple"/></inline-formula>.</p>
<list list-type="bullet"><list-item>
<p>If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e165" xlink:type="simple"/></inline-formula> is sampled at trial T,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e166" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e167" xlink:type="simple"/></inline-formula> is the prediction error (outcome <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e168" xlink:type="simple"/></inline-formula> minus prediction).</p>
</list-item><list-item>
<p>If <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e169" xlink:type="simple"/></inline-formula> is not sampled at trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e170" xlink:type="simple"/></inline-formula>, then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e171" xlink:type="simple"/></inline-formula>.</p>
</list-item></list>
<p>Here, the learning rate is fixed but color-specific. As such, the reinforcement learning model allows for adjustment of the learning rate to the average level of unexpected uncertainty (red options jump more often than blue ones), in line with evidence that the learning rate increases with average unexpected uncertainty <xref ref-type="bibr" rid="pcbi.1001048-Behrens1">[4]</xref>. We also tested model-free reinforcement learning with a single learning rate across choices. The fit was worse, even after penalizing the model with dual learning rates for the extra degree of freedom.</p>
<p>We also fit a modified reinforcement learning model, where the learning rate adjusts to the size of the prediction error in the last trial. This is the Pearce-Hall model <xref ref-type="bibr" rid="pcbi.1001048-Pearce1">[8]</xref>.</p>
</sec><sec id="s4e">
<title>Computation of Unexpected Uncertainty in the Bayesian Model</title>
<p>The computations, which are provided in <xref ref-type="bibr" rid="pcbi.1001048-PayzanLeNestour1">[9]</xref>, and available in <xref ref-type="supplementary-material" rid="pcbi.1001048.s005">Text S1</xref>. We repeat the key arguments here, for ease of reference. At each trial, the Bayesian decision maker needs to infer whether a jump has occurred. Since jumps are color-dependent only, the Bayesian model extrapolates such inference to all options with the same color as the chosen one. As before, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e172" xlink:type="simple"/></inline-formula> denotes the probability that no jump has occurred. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e173" xlink:type="simple"/></inline-formula> is color-specific and we shall write <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e174" xlink:type="simple"/></inline-formula> for the blue options and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e175" xlink:type="simple"/></inline-formula> for the red ones. Without loss of generality, take <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e176" xlink:type="simple"/></inline-formula>, the visited location at trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e177" xlink:type="simple"/></inline-formula>, to be red. (In the main text, and earlier in the <xref ref-type="sec" rid="s4">Methods</xref> Section, we dropped the color reference, to avoid unnecessary notational burden.) Formally,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e178" xlink:type="simple"/></disp-formula>The computation of this subjective probability leads to<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e179" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e180" xlink:type="simple"/></inline-formula> refers to the realized component of the count vector at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e181" xlink:type="simple"/></inline-formula>. (For example, suppose that location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e182" xlink:type="simple"/></inline-formula> delivered the loss outcome at trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e183" xlink:type="simple"/></inline-formula>; then <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e184" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e185" xlink:type="simple"/></inline-formula> is equal to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e186" xlink:type="simple"/></inline-formula>.) Thus, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e187" xlink:type="simple"/></inline-formula> depends on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e188" xlink:type="simple"/></inline-formula>, the <italic>strength of evidence</italic> for the hypothesis that a jump has occurred at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e189" xlink:type="simple"/></inline-formula>.</p>
<p>Unexpected uncertainty, the chance that a jump has occurred, is complementary to the chance that no jump has occurred. At the red location, it equals <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e190" xlink:type="simple"/></inline-formula>. Therefore, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e191" xlink:type="simple"/></inline-formula> tracks unexpected uncertainty at the red location.</p>
</sec><sec id="s4f">
<title>Computation of Estimation Uncertainty in the Bayesian Model</title>
<p>Estimation uncertainty is the dispersion of the posterior distribution of outcome probabilities. It can be measured either by the variance or the entropy.</p>
<p>The <italic>variance</italic> metric for option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e192" xlink:type="simple"/></inline-formula> at trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e193" xlink:type="simple"/></inline-formula> is computed as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e194" xlink:type="simple"/></disp-formula>From <xref ref-type="bibr" rid="pcbi.1001048-Berger1">[47]</xref>, we define the <italic>entropy</italic> of the posterior probability distribution for option <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e195" xlink:type="simple"/></inline-formula> at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e196" xlink:type="simple"/></inline-formula> as follows:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e197" xlink:type="simple"/></disp-formula>The entropy metric is thus<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e198" xlink:type="simple"/></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e199" xlink:type="simple"/></inline-formula> is the Digamma function.</p>
</sec><sec id="s4g">
<title>Choice Model</title>
<p>We used the softmax function to transform valuations for the options into choice probabilities. It generated a probability distribution <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e200" xlink:type="simple"/></inline-formula> that location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e201" xlink:type="simple"/></inline-formula> would be visited in the subsequent trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e202" xlink:type="simple"/></inline-formula>. In the base version, valuations remained unadjusted, namely, the expected payoff in the next trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e203" xlink:type="simple"/></inline-formula>. The softmax function depended on one parameter, namely, the inverse temperature <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e204" xlink:type="simple"/></inline-formula>. See Eqn. 5.</p>
<p>A couple of alternative versions were considered, by taking the average of the expected payoff and a bonus or (if negative) a penalty. The bonus/penalty was equal to the level of parameter estimation uncertainty (variance or entropy of the posterior distribution as defined above). In the model with bonus, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e205" xlink:type="simple"/></inline-formula> in Eqn. 5 was replaced with either <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e206" xlink:type="simple"/></inline-formula> (when measuring estimation uncertainty with the variance metric) or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e207" xlink:type="simple"/></inline-formula> (when using the entropy metric). In the model with penalty, it was replaced with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e208" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e209" xlink:type="simple"/></inline-formula>. Without loss the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e210" xlink:type="simple"/></inline-formula> can be set equal to 1/2. This particular value is not pivotal in the sense that replacing it with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e211" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e212" xlink:type="simple"/></inline-formula> does not change the main results qualitatively (i.e., whatever the value of the parameter, the version with penalty significantly improved the fit of the base model, and the version with bonus did not).</p>
</sec><sec id="s4h">
<title>Model Fitting</title>
<p>Using participant choices, we fitted the free parameters of each model: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e213" xlink:type="simple"/></inline-formula> for the Bayesian and Pearce-Hall learning models; <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e214" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e215" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e216" xlink:type="simple"/></inline-formula> for the reinforcement learning model. For each participant, best fit was obtained by maximizing the log-likelihood <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e217" xlink:type="simple"/></inline-formula> compounded over trials:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e218" xlink:type="simple"/><label>(8)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e219" xlink:type="simple"/></inline-formula> is the option chosen by subject <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e220" xlink:type="simple"/></inline-formula> in trial <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e221" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e222" xlink:type="simple"/></inline-formula> is the number of trials participant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1001048.e223" xlink:type="simple"/></inline-formula> played.</p>
</sec></sec><sec id="s5">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1001048.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.s001" xlink:type="simple"><label>Figure S1</label><caption>
<p>Graphical display of the individual (negative) log-likelihoods of the Bayesian models, with penalty for ambiguity (Y-axis) and without (X-axis).</p>
<p>(0.01 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1001048.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.s002" xlink:type="simple"><label>Figure S2</label><caption>
<p>Graphical display of the individual (negative) log-likelihoods of the models in Treatment 3.</p>
<p>(0.02 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1001048.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.s003" xlink:type="simple"><label>Figure S3</label><caption>
<p>Graphical display of the individual (negative) log-likelihoods of the models in Treatment 1.</p>
<p>(0.02 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1001048.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.s004" xlink:type="simple"><label>Figure S4</label><caption>
<p>Graphical display of the individual (negative) log-likelihoods of the models in Treatment 2.</p>
<p>(0.02 MB PDF)</p>
</caption></supplementary-material><supplementary-material id="pcbi.1001048.s005" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1001048.s005" xlink:type="simple"><label>Text S1</label><caption>
<p>Supplemental material.</p>
<p>(0.20 MB PDF)</p>
</caption></supplementary-material></sec></body>
<back>
<ack>
<p>We are grateful to Chen Feng for programming the board game application.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1001048-Daw1"><label>1</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>
<name name-style="western"><surname>Niv</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
</person-group>             <year>2005</year>             <article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control.</article-title>             <source>Nat Neurosci</source>             <volume>8</volume>             <fpage>1704</fpage>             <lpage>1711</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Dayan1"><label>2</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Long</surname><given-names>T</given-names></name>
</person-group>             <year>1997</year>             <article-title>Statistical Models of Conditioning.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Kearns</surname><given-names>MJ</given-names></name>
<etal/></person-group>             <source>Conf Proc Adv Neural Inf Process Syst Vol 10.</source>             <publisher-name>MIT Press</publisher-name>             <fpage>117</fpage>             <lpage>123</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Yoshida1"><label>3</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Yoshida</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Ishii</surname><given-names>S</given-names></name>
</person-group>             <year>2006</year>             <article-title>Resolution of uncertainty in prefrontal cortex.</article-title>             <source>Neuron</source>             <volume>50</volume>             <fpage>781</fpage>             <lpage>789</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Behrens1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Behrens</surname><given-names>TEJ</given-names></name>
<name name-style="western"><surname>Woolrich</surname><given-names>MW</given-names></name>
<name name-style="western"><surname>Walton</surname><given-names>ME</given-names></name>
<name name-style="western"><surname>Rushworth</surname><given-names>MFS</given-names></name>
</person-group>             <year>2007</year>             <article-title>Learning the value of information in an uncertain world.</article-title>             <source>Nat Neurosci</source>             <volume>10</volume>             <issue>9</issue>             <fpage>1214</fpage>             <lpage>21</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Yu1"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Yu</surname><given-names>AJ</given-names></name>
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
</person-group>             <year>2005</year>             <article-title>Uncertainty, neuromodulation, and attention.</article-title>             <source>Neuron</source>             <volume>46</volume>             <fpage>681</fpage>             <lpage>692</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Bossaerts1"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Preuschoff</surname><given-names>K</given-names></name>
</person-group>             <year>2007</year>             <article-title>Adding prediction risk to the theory of reward learning.</article-title>             <source>Ann N Y Acad Sci</source>             <volume>1104</volume>             <fpage>135</fpage>             <lpage>146</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Wagner1"><label>7</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wagner</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Rescorla</surname><given-names>R</given-names></name>
</person-group>             <year>1972</year>             <article-title>A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Black</surname><given-names>AH</given-names></name>
<name name-style="western"><surname>Prokasy</surname><given-names>WF</given-names></name>
</person-group>             <source>Classical Conditioning II: Current Research and Theory</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Appleton Century Crofts</publisher-name>             <fpage>64</fpage>             <lpage>99</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Pearce1"><label>8</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pearce</surname><given-names>JM</given-names></name>
<name name-style="western"><surname>Hall</surname><given-names>G</given-names></name>
</person-group>             <year>1980</year>             <article-title>A model for pavlovian learning: variations in the effectiveness of conditioned but not of unconditioned stimuli.</article-title>             <source>Psychol Rev</source>             <volume>87</volume>             <fpage>532</fpage>             <lpage>552</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-PayzanLeNestour1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Payzan-LeNestour</surname><given-names>E</given-names></name>
</person-group>             <year>2010</year>             <article-title>Bayesian learning in unstable settings: Experimental evidence based on the bandit problem.</article-title>             <source>Swiss Finance Institute Research Paper No 10-28</source>             <fpage>1</fpage>             <lpage>41</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Daw2"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>
<name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Seymour</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>
</person-group>             <year>2006</year>             <article-title>Cortical substrates for exploratory decisions in humans.</article-title>             <source>Nature</source>             <volume>441</volume>             <fpage>876</fpage>             <lpage>879</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Paulus1"><label>11</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Paulus</surname><given-names>MP</given-names></name>
<name name-style="western"><surname>Rogalsky</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Simmons</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Feinstein</surname><given-names>JS</given-names></name>
<name name-style="western"><surname>Stein</surname><given-names>MB</given-names></name>
</person-group>             <year>2003</year>             <article-title>Increased activation in the right insula during risk-taking decision making is related to harm avoidance and neuroticism.</article-title>             <source>Neuroimage</source>             <volume>19</volume>             <fpage>1439</fpage>             <lpage>1448</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Huettel1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Huettel</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Song</surname><given-names>A</given-names></name>
<name name-style="western"><surname>McCarthy</surname><given-names>G</given-names></name>
</person-group>             <year>2005</year>             <article-title>Decisions under uncertainty: Probabilistic context influences activation of prefrontal and parietal cortices.</article-title>             <source>J Neurosci</source>             <volume>25</volume>             <fpage>3304</fpage>             <lpage>3311</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Preuschoff1"><label>13</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Preuschoff</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Quartz</surname><given-names>SR</given-names></name>
<name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name>
</person-group>             <year>2008</year>             <article-title>Human insula activation reflects risk prediction errors as well as risk.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>2745</fpage>             <lpage>2752</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Ellsberg1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ellsberg</surname><given-names>D</given-names></name>
</person-group>             <year>1961</year>             <article-title>Risk, ambiguity, and the savage axioms.</article-title>             <source>Q J Econ</source>             <volume>75</volume>             <fpage>643</fpage>             <lpage>669</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Hsu1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hsu</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Bhatt</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Adolphs</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Tranel</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Camerer</surname><given-names>CF</given-names></name>
</person-group>             <year>2005</year>             <article-title>Neural systems responding to degrees of uncertainty in human decision-making.</article-title>             <source>Science</source>             <volume>310</volume>             <fpage>1680</fpage>             <lpage>1683</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Huettel2"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Huettel</surname><given-names>SA</given-names></name>
<name name-style="western"><surname>Stowe</surname><given-names>CJ</given-names></name>
<name name-style="western"><surname>Gordon</surname><given-names>EM</given-names></name>
<name name-style="western"><surname>Warner</surname><given-names>BT</given-names></name>
<name name-style="western"><surname>Platt</surname><given-names>ML</given-names></name>
</person-group>             <year>2006</year>             <article-title>Neural signatures of economic preferences for risk and ambiguity.</article-title>             <source>Neuron</source>             <volume>49</volume>             <fpage>765</fpage>             <lpage>75</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Hampton1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hampton</surname><given-names>AN</given-names></name>
<name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name>
<name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name>
</person-group>             <year>2006</year>             <article-title>The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans.</article-title>             <source>J Neurosci</source>             <volume>26</volume>             <fpage>8360</fpage>             <lpage>8367</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Kakade1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kakade</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
</person-group>             <year>2002</year>             <article-title>Dopamine: generalization and bonuses.</article-title>             <source>Neural Netw</source>             <volume>15</volume>             <fpage>549</fpage>             <lpage>559</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Allais1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Allais</surname><given-names>M</given-names></name>
</person-group>             <year>1953</year>             <article-title>Le comportement de l'homme rationnel devant le risque: critique des postulats et axiomes de l'ecole americaine.</article-title>             <source>Econometrica</source>             <volume>21</volume>             <fpage>503</fpage>             <lpage>546</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Knight1"><label>20</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Knight</surname><given-names>FH</given-names></name>
</person-group>             <year>1921</year>             <source>Risk, Uncertainty and Profit.</source>             <publisher-name>University of Chicago Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1001048-Keynes1"><label>21</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Keynes</surname><given-names>JM</given-names></name>
</person-group>             <year>1921</year>             <source>A Treatise on Probability</source>             <publisher-loc>London</publisher-loc>             <publisher-name>Macmillan</publisher-name>          </element-citation></ref>
<ref id="pcbi.1001048-Basili1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Basili</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Zappia</surname><given-names>C</given-names></name>
</person-group>             <year>2010</year>             <article-title>Ambiguity and uncertainty in Ellsberg and Shackle.</article-title>             <source>Cambridge J Econ</source>             <volume>34</volume>             <fpage>449</fpage>             <lpage>474</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Hansen1"><label>23</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hansen</surname><given-names>LP</given-names></name>
<name name-style="western"><surname>Sargent</surname><given-names>TJ</given-names></name>
</person-group>             <year>2001</year>             <article-title>Acknowledging misspecification in macroeconomic theory.</article-title>             <source>Rev Econ Dyn</source>             <volume>4</volume>             <fpage>519</fpage>             <lpage>535</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Draper1"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Draper</surname><given-names>D</given-names></name>
</person-group>             <year>1995</year>             <article-title>Assessment and propagation of model uncertainty.</article-title>             <source>J R Stat Soc Series B Stat Methodol</source>             <volume>57</volume>             <fpage>45</fpage>             <lpage>97</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Quinn1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Quinn</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Karny</surname><given-names>M</given-names></name>
</person-group>             <year>2007</year>             <article-title>Learning for non-stationary Dirichlet processes.</article-title>             <source>Int J Adapt Control Signal Process</source>             <volume>21</volume>             <fpage>827</fpage>             <lpage>855</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Ishii1"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Ishii</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Yoshida</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Yoshimoto</surname><given-names>J</given-names></name>
</person-group>             <year>2002</year>             <article-title>Control of exploitation-exploration meta-parameter in reinforcement learning.</article-title>             <source>Neural Netw</source>             <volume>15</volume>             <fpage>665</fpage>             <lpage>687</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-AstonJones1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Aston-Jones</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Cohen</surname><given-names>JD</given-names></name>
</person-group>             <year>2005</year>             <article-title>An integrative theory of locus coeruleus-norepinephrine function: adaptive gain and optimal performance.</article-title>             <source>Annu Rev Neurosci</source>             <volume>28</volume>             <fpage>403</fpage>             <lpage>450</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Doya1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Doya</surname><given-names>K</given-names></name>
</person-group>             <year>2008</year>             <article-title>Modulators of decision making.</article-title>             <source>Nat Neurosci</source>             <volume>11</volume>             <fpage>410</fpage>             <lpage>416</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Kass1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kass</surname><given-names>RE</given-names></name>
<name name-style="western"><surname>Raftery</surname><given-names>AE</given-names></name>
</person-group>             <year>1995</year>             <article-title>Bayes factors.</article-title>             <source>J Am Stat Assoc</source>             <volume>90</volume>             <fpage>773</fpage>             <lpage>795</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Preuschoff2"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Preuschoff</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Quartz</surname><given-names>S</given-names></name>
</person-group>             <year>2006</year>             <article-title>Neural differentiation of expected reward and risk in human subcortical structures.</article-title>             <source>Neuron</source>             <volume>51</volume>             <fpage>381</fpage>             <lpage>390</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Fiorillo1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fiorillo</surname><given-names>CD</given-names></name>
<name name-style="western"><surname>Tobler</surname><given-names>PN</given-names></name>
<name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name>
</person-group>             <year>2003</year>             <article-title>Discrete coding of reward probability and uncertainty by dopamine neurons.</article-title>             <source>Science</source>             <volume>299</volume>             <fpage>1898</fpage>             <lpage>1902</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-VanniMercier1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vanni-Mercier</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Mauguière</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Isnard</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Dreher</surname><given-names>JC</given-names></name>
</person-group>             <year>2009</year>             <article-title>The hippocampus codes the uncertainty of cue-outcome associations: an intracranial electrophysiological study in humans.</article-title>             <source>J of Neurosci</source>             <volume>29</volume>             <fpage>5287</fpage>             <lpage>94</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-dAcremont1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>d'Acremont</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Zhong-Lin</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Xiangrui</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Van der Linden</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Bechara</surname><given-names>A</given-names></name>
</person-group>             <year>2009</year>             <article-title>Neural correlates of risk prediction error during reinforcement learning in humans.</article-title>             <source>Neuroimage</source>             <volume>47</volume>             <fpage>1929</fpage>             <lpage>1939</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Tobler1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tobler</surname><given-names>PN</given-names></name>
<name name-style="western"><surname>O'Doherty</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name>
</person-group>             <year>2007</year>             <article-title>Reward value coding distinct from risk attitude-related uncertainty coding in human reward systems.</article-title>             <source>J Neurophysiol</source>             <volume>97</volume>             <fpage>1621</fpage>             <lpage>32</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Christopoulos1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Christopoulos</surname><given-names>GI</given-names></name>
<name name-style="western"><surname>Tobler</surname><given-names>PN</given-names></name>
<name name-style="western"><surname>Bossaerts</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name>
</person-group>             <year>2009</year>             <article-title>Neural correlates of value, risk, and risk aversion contributing to decision making under risk.</article-title>             <source>J Neurosci</source>             <volume>29</volume>             <fpage>12574</fpage>             <lpage>12583</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Cohen1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Cohen</surname><given-names>JD</given-names></name>
<name name-style="western"><surname>McClure</surname><given-names>SM</given-names></name>
<name name-style="western"><surname>Yu</surname><given-names>AJ</given-names></name>
</person-group>             <year>2007</year>             <article-title>Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration.</article-title>             <source>Philos Trans R Soc Lond B Biol Sci</source>             <volume>362</volume>             <fpage>933</fpage>             <lpage>942</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Strange1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Strange</surname><given-names>BA</given-names></name>
<name name-style="western"><surname>Duggins</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Penny</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Dolan</surname><given-names>RJ</given-names></name>
<name name-style="western"><surname>Friston</surname><given-names>KJ</given-names></name>
</person-group>             <year>2005</year>             <article-title>Information theory, novelty and hippocampal responses: unpredicted or unpredictable?</article-title>             <source>Neural Netw</source>             <volume>18</volume>             <fpage>225</fpage>             <lpage>230</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Rutishauser1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rutishauser</surname><given-names>U</given-names></name>
<name name-style="western"><surname>Mamelak</surname><given-names>AN</given-names></name>
<name name-style="western"><surname>Schuman</surname><given-names>EM</given-names></name>
</person-group>             <year>2006</year>             <article-title>Single-trial learning of novel stimuli by individual neurons of the human hippocampus-amygdala complex.</article-title>             <source>Neuron</source>             <volume>49</volume>             <fpage>805</fpage>             <lpage>813</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Rushworth1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rushworth</surname><given-names>MFS</given-names></name>
<name name-style="western"><surname>Behrens</surname><given-names>TEJ</given-names></name>
</person-group>             <year>2008</year>             <article-title>Choice, uncertainty and value in prefrontal and cingulate cortex.</article-title>             <source>Nat Neurosci</source>             <volume>11</volume>             <fpage>389</fpage>             <lpage>397</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Craik1"><label>40</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Craik</surname><given-names>K</given-names></name>
</person-group>             <year>1943</year>             <source>The Nature of Explanation.</source>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1001048-Epstein1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Epstein</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Rock</surname><given-names>I</given-names></name>
</person-group>             <year>1960</year>             <article-title>Perceptual set as an artifact of recency.</article-title>             <source>Am J Psychol</source>             <volume>73</volume>             <fpage>214</fpage>             <lpage>228</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Thaler1"><label>42</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Thaler</surname><given-names>RH</given-names></name>
<name name-style="western"><surname>Sunstein</surname><given-names>CR</given-names></name>
</person-group>             <year>2009</year>             <source>Nudge: Improving Decisions About Health, Wealth, and Happiness</source>             <publisher-name>Penguin</publisher-name>          </element-citation></ref>
<ref id="pcbi.1001048-Dow1"><label>43</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dow</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Werlang</surname><given-names>S</given-names></name>
<name name-style="western"><surname>da Costa</surname><given-names>R</given-names></name>
</person-group>             <year>1992</year>             <article-title>Uncertainty aversion, risk aversion, and the optimal choice of portfolio.</article-title>             <source>Econometrica</source>             <volume>60</volume>             <fpage>197</fpage>             <lpage>204</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Diaconis1"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Diaconis</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Freedman</surname><given-names>D</given-names></name>
</person-group>             <year>1986</year>             <article-title>On the consistency of Bayes estimates.</article-title>             <source>Ann Stat</source>             <volume>14</volume>             <fpage>1</fpage>             <lpage>26</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Sangjoon1"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sangjoon</surname><given-names>K</given-names></name>
<name name-style="western"><surname>Shepherd</surname><given-names>N</given-names></name>
<name name-style="western"><surname>Siddhartha</surname><given-names>C</given-names></name>
</person-group>             <year>1998</year>             <article-title>Stochastic volatility: Likelihood inference and comparison with Arch models.</article-title>             <source>Rev Econ Stud</source>             <volume>65</volume>             <fpage>361</fpage>             <lpage>393</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Courville1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Courville</surname><given-names>AC</given-names></name>
<name name-style="western"><surname>Daw</surname><given-names>ND</given-names></name>
<name name-style="western"><surname>Touretzky</surname><given-names>DS</given-names></name>
</person-group>             <year>2006</year>             <article-title>Bayesian theories of conditioning in a changing world.</article-title>             <source>Trends Cogn Sci</source>             <volume>10</volume>             <fpage>294</fpage>             <lpage>300</lpage>          </element-citation></ref>
<ref id="pcbi.1001048-Berger1"><label>47</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Berger</surname><given-names>JO</given-names></name>
</person-group>             <year>1980</year>             <source>Statistical Decision Theory and Bayesian Analysis. Springer Series in Statistics (Second Edition)</source>             <publisher-name>Springer-Verlag</publisher-name>          </element-citation></ref>
</ref-list>

</back>
</article>
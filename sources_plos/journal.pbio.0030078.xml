<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
  <front>
    <journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pbio</journal-id><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="epub">1545-7885</issn><issn pub-type="ppub">1544-9173</issn><publisher>
        <publisher-name>Public Library of Science</publisher-name>
        <publisher-loc>San Francisco, USA</publisher-loc>
      </publisher></journal-meta>
    <article-meta><article-id pub-id-type="doi">10.1371/journal.pbio.0030078</article-id><article-categories>
        <subj-group subj-group-type="heading">
          <subject>Research Article</subject>
        </subj-group>
        <subj-group subj-group-type="Discipline">
          <subject>Neuroscience</subject>
        </subj-group>
        <subj-group subj-group-type="System Taxonomy">
          <subject>Cat</subject>
        </subj-group>
      </article-categories><title-group><article-title>Location Coding by Opponent Neural Populations in the Auditory Cortex</article-title><alt-title alt-title-type="running-head">Opponent-Channel Code for Auditory Space</alt-title></title-group><contrib-group>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Stecker</surname>
            <given-names>G. Christopher</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="fn" rid="n2">
            <sup>¤</sup>
          </xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>*</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Harrington</surname>
            <given-names>Ian A</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author" xlink:type="simple">
          <name name-style="western">
            <surname>Middlebrooks</surname>
            <given-names>John C</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
        </contrib>
      </contrib-group><aff id="aff1"><label>1</label>
				
				<addr-line>Kresge Hearing Research Institute, University of Michigan, Ann Arbor, Michigan, United States of America</addr-line>
				
			</aff><contrib-group>
        <contrib contrib-type="editor" xlink:type="simple">
          <name name-style="western">
            <surname>Semple</surname>
            <given-names>Malcolm</given-names>
          </name>
          <role>Academic Editor</role>
          <xref ref-type="aff" rid="edit1"/>
        </contrib>
      </contrib-group><aff id="edit1">New York University, 
				
				
			United States of America</aff><author-notes>
        <corresp id="cor1">* To whom correspondence should be addressed. E-mail: <email xlink:type="simple">cstecker@ebire.org</email></corresp>
        <fn fn-type="con" id="n1">
          <p> GCS, IAH, and JCM conceived and designed the experiments. GCS and IAH performed the experiments and analyzed the data. GCS contributed reagents/materials/analysis tools. GCS wrote the paper.</p>
        </fn>
        <fn fn-type="current-aff" id="n2">
          <p>¤Current address: Human Cognitive Neurophysiology Lab, Department of Veterans Affairs Research Service, VA Northern California Health Care System, Martinez, California, United States of America</p>
        </fn>
      <fn fn-type="conflict">
        <p> The authors have declared that no competing interests exist.</p>
      </fn></author-notes><pub-date pub-type="ppub">
        <month>3</month>
        <year>2005</year>
      </pub-date><pub-date pub-type="epub">
        <day>22</day>
        <month>2</month>
        <year>2005</year>
      </pub-date><volume>3</volume><issue>3</issue><elocation-id>e78</elocation-id><history>
        <date date-type="received">
          <day>3</day>
          <month>11</month>
          <year>2004</year>
        </date>
        <date date-type="accepted">
          <day>20</day>
          <month>12</month>
          <year>2004</year>
        </date>
      </history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2005</copyright-year><copyright-holder>Stecker et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><related-article page="e103" related-article-type="companion" vol="3" xlink:href="info:doi/10.1371/journal.pbio.0030103" xlink:title="synopsis" xlink:type="simple">
				<article-title>How the Brain Signals a Sound Source</article-title>
			</related-article><abstract>
        <p>Although the auditory cortex plays a necessary role in sound localization, physiological investigations in the cortex reveal inhomogeneous sampling of auditory space that is difficult to reconcile with localization behavior under the assumption of local spatial coding. Most neurons respond maximally to sounds located far to the left or right side, with few neurons tuned to the frontal midline. Paradoxically, psychophysical studies show optimal spatial acuity across the frontal midline. In this paper, we revisit the problem of inhomogeneous spatial sampling in three fields of cat auditory cortex. In each field, we confirm that neural responses tend to be greatest for lateral positions, but show the greatest modulation for near-midline source locations. Moreover, identification of source locations based on cortical responses shows sharp discrimination of left from right but relatively inaccurate discrimination of locations within each half of space. Motivated by these findings, we explore an opponent-process theory in which sound-source locations are represented by differences in the activity of two broadly tuned channels formed by contra- and ipsilaterally preferring neurons. Finally, we demonstrate a simple model, based on spike-count differences across cortical populations, that provides bias-free, level-invariant localization—and thus also a solution to the “binding problem” of associating spatial information with other nonspatial attributes of sounds.</p>
      </abstract><abstract abstract-type="toc">
        <p>A model relying on properties of auditory cortical neurons recorded in the cat can account for the accurate localization of sounds.</p>
      </abstract></article-meta>
  </front>
  <body>
    <sec id="s1">
      <title>Introduction</title>
      <p>Topographic representation is a hallmark of cortical organization: primary somatosensory cortex contains a somatotopic map of the body surface, primary visual cortex contains a retinotopic map of visual (retinal) space, and primary auditory cortex contains a cochleotopic map of sound frequency. The necessity of auditory cortex for normal sound localization (which is disrupted by cortical lesions [<xref ref-type="bibr" rid="pbio-0030078-b01">1</xref>,<xref ref-type="bibr" rid="pbio-0030078-b02">2</xref>,<xref ref-type="bibr" rid="pbio-0030078-b03">3</xref>]) strongly implies a cortical representation of auditory space. That representation has been reasonably expected to consist of a spatiotopic map, based on the existence of such maps in other sensory systems and on the view, proposed by Jeffress [<xref ref-type="bibr" rid="pbio-0030078-b04">4</xref>], that spatial processing in the auditory brainstem and midbrain might involve a “local code” consisting of topographic maps of interaural spatial cues. A local code, or “place code,” is one in which particular locations in space, or the spatial cues that correspond to those locations, are represented by neural activity at restricted locations in the brain. Evidence for local coding of auditory space has been demonstrated in mammalian superior colliculus [<xref ref-type="bibr" rid="pbio-0030078-b05">5</xref>,<xref ref-type="bibr" rid="pbio-0030078-b06">6</xref>] and in avian inferior colliculus (IC) [<xref ref-type="bibr" rid="pbio-0030078-b07">7</xref>,<xref ref-type="bibr" rid="pbio-0030078-b08">8</xref>] and optic tectum (homologous to mammalian superior colliculus) [<xref ref-type="bibr" rid="pbio-0030078-b09">9</xref>]. Nevertheless, local spatial coding has not thus far been demonstrated in the mammalian ascending auditory pathway.</p>
      <p>If the Jeffress model is correct and a local code for spatial cues exists subcortically, one might anticipate local coding to be maintained in the cortex, where the various cues might finally be integrated into a coherent map of auditory space. Numerous studies, however, have failed to provide evidence for such a map. The spatial tuning of neurons is often characterized using rate–azimuth functions (RAFs), which specify the average response rate (spikes per trial or per second) as a function of stimulus location in the horizontal dimension. Throughout the auditory cortex, such functions typically exhibit broad peaks (up to 180° wide) that cover the contralateral hemifield and broaden further with increasing sound level [<xref ref-type="bibr" rid="pbio-0030078-b10">10</xref>,<xref ref-type="bibr" rid="pbio-0030078-b11">11</xref>,<xref ref-type="bibr" rid="pbio-0030078-b12">12</xref>,<xref ref-type="bibr" rid="pbio-0030078-b13">13</xref>,<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>]. Similar functions have been reported for cortical sensitivity to interaural cues [<xref ref-type="bibr" rid="pbio-0030078-b15">15</xref>,<xref ref-type="bibr" rid="pbio-0030078-b16">16</xref>], and for spatial and interaural sensitivity in the auditory brainstem and midbrain [<xref ref-type="bibr" rid="pbio-0030078-b17">17</xref>,<xref ref-type="bibr" rid="pbio-0030078-b18">18</xref>,<xref ref-type="bibr" rid="pbio-0030078-b19">19</xref>,<xref ref-type="bibr" rid="pbio-0030078-b20">20</xref>,<xref ref-type="bibr" rid="pbio-0030078-b21">21</xref>,<xref ref-type="bibr" rid="pbio-0030078-b22">22</xref>,<xref ref-type="bibr" rid="pbio-0030078-b23">23</xref>,<xref ref-type="bibr" rid="pbio-0030078-b24">24</xref>], thus questioning Jeffress's view of binaural processing in mammals. The emerging alternative view replaces the local code with a “distributed code,” in which sound-source locations are represented by patterns of activity across populations of broadly tuned neurons [<xref ref-type="bibr" rid="pbio-0030078-b12">12</xref>,<xref ref-type="bibr" rid="pbio-0030078-b24">24</xref>,<xref ref-type="bibr" rid="pbio-0030078-b25">25</xref>].</p>
      <p>In the past, we argued for a distributed spatial code in the auditory cortex in part because the broad spatial tuning of cortical neurons would seem to preclude the existence of a local code and also because individual neurons are able to transmit spatial information throughout much, if not all, of auditory space [<xref ref-type="bibr" rid="pbio-0030078-b25">25</xref>,<xref ref-type="bibr" rid="pbio-0030078-b26">26</xref>]. At least implicitly, we have advocated a uniform distributed code, assuming that uniform sampling of space by RAF peaks is required for maximally accurate spatial coding. Spatial centroids of neurons in the posterior auditory field (PAF), for example, sample space more uniformly than neurons in the primary auditory field (A1), and we have suggested that this feature partially underlies the increased ability of ensembles of PAF neurons to accurately signal sound-source locations [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>].</p>
      <p>A number of observations demonstrate, however, that the auditory cortex samples space nonuniformly. RAFs are plotted for a selection of neurons in the dorsal zone (DZ) of auditory cortex in <xref ref-type="fig" rid="pbio-0030078-g001">Figure 1</xref>, to illustrate a common observation of location-sensitive auditory cortical neurons: the majority favor contralateral stimulation, and typically exhibit either “hemifield” or “axial” tuning [<xref ref-type="bibr" rid="pbio-0030078-b11">11</xref>], responding to stimuli located throughout contralateral space or near the acoustic axis of the contralateral pinna, respectively. A smaller number of ipsilaterally tuned units are also observed, the majority of which exhibit hemifield or axial tuning characteristics similar to those of contralateral units. In A1 and DZ, ipsilateral- and/or midline-tuned neurons may be arranged in bands—parallel to the tonotopic axis—that interdigitate with bands of contralaterally tuned cells [<xref ref-type="bibr" rid="pbio-0030078-b25">25</xref>,<xref ref-type="bibr" rid="pbio-0030078-b27">27</xref>,<xref ref-type="bibr" rid="pbio-0030078-b28">28</xref>,<xref ref-type="bibr" rid="pbio-0030078-b29">29</xref>]. The overall preponderance of contralateral tuning among cortical units seems to justify the view that each hemisphere represents the contralateral spatial hemifield, a view that is also supported by the contralateral sound-localization deficits that follow auditory cortical lesions [<xref ref-type="bibr" rid="pbio-0030078-b02">2</xref>,<xref ref-type="bibr" rid="pbio-0030078-b30">30</xref>,<xref ref-type="bibr" rid="pbio-0030078-b31">31</xref>]. Even within a single hemifield, however, no strong evidence for a topographic representation has been reported, and the observation that many units share similar hemifield RAFs demonstrates a profound inhomogeneity in the way cortical populations sample auditory space.</p>
      <fig id="pbio-0030078-g001" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0030078.g001</object-id>
        <label>Figure 1</label>
        <caption>
          <title>Example RAFs</title>
          <p>Plotted are normalized mean spike counts (y-axis) elicited by broadband stimuli (20 dB above unit threshold) varying in azimuth (x-axis). Lines represent units recorded in cortical area DZ. Left: contralaterally responsive units. Right: ipsilaterally responsive units.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030078.g001" xlink:type="simple"/>
      </fig>
      <p>Additional evidence that the cortical representation of auditory space is inhomogeneous comes from studies of the ability of cortical responses to classify stimulus locations. Stecker et al. [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>] found that the responses of most spatially sensitive units in cat cortical areas A1 and PAF could accurately discriminate the lateral hemifield (left versus right) of a stimulus, but often confused locations within the hemifield. This is shown for six PAF neurons represented by confusion matrices in <xref ref-type="fig" rid="pbio-0030078-g002">Figure 2</xref>. Similarly, Middlebrooks et al. [<xref ref-type="bibr" rid="pbio-0030078-b12">12</xref>] measured median localization errors—based on neural-network analyses of responses in the second auditory field (A2) and the field of the anterior ectosylvian sulcus (AES)—between 37.5° ± 8.9° and 43.7°<italic>±</italic> 10.2<italic>°</italic>, just under the theoretical limit of 45<italic>°</italic> attainable through perfect left/right discrimination and within-hemifield confusion. Taken together, these results suggest that auditory space is represented within the cortex by a population of broadly tuned neurons, each of which is able to indicate the lateral hemifield from which a sound originated, but generally little more.</p>
      <fig id="pbio-0030078-g002" position="float">
        <object-id pub-id-type="doi">10.1371/journal.pbio.0030078.g002</object-id>
        <label>Figure 2</label>
        <caption>
          <title>Classification Performance of Accurate PAF Units from [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>]</title>
          <p>Neural spike patterns were classified according to the stimulus location most likely to have elicited them. In each panel, a confusion matrix plots the relative proportion of classifications of each target azimuth (x-axis) to each possible response azimuth (y-axis). Proportions are indicated by the area of a circle located at the intersection of target and response locations. Example units were selected from among those transmitting the most spatial information in their responses. In each case, discrimination of contralateral azimuths (negative values) from ipsilateral azimuths (positive values) is apparent, accompanied by significant within-hemifield confusion. As such, neural responses are sufficient for left/right discrimination only, and the spatial information transmitted by the most accurate units tends not to be much greater than one bit per stimulus.</p>
        </caption>
        <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030078.g002" xlink:type="simple"/>
      </fig>
    </sec>
    <sec id="s2">
      <title>Results/Discussion</title>
      <sec id="s2a">
        <title>Preferred Locations Oversample Lateral Regions of Contralateral Space—Steepest RAF Slopes Straddle the Midline</title>
        <p>The idea that sound locations are signaled by the peaks of RAFs, which tend to be centered deep within the lateral hemifields, is at odds with localization behavior, which shows greatest resolution near the interaural midline [<xref ref-type="bibr" rid="pbio-0030078-b32">32</xref>,<xref ref-type="bibr" rid="pbio-0030078-b33">33</xref>]. An alternative view, however, has emerged for the processing of interaural time and level differences by cortical and subcortical neurons. In that view, locations are coded by the slopes, rather than the peaks, of rate–interaural-time-difference or rate–interaural-level-difference functions [<xref ref-type="bibr" rid="pbio-0030078-b22">22</xref>,<xref ref-type="bibr" rid="pbio-0030078-b24">24</xref>,<xref ref-type="bibr" rid="pbio-0030078-b34">34</xref>]. Moreover, these slopes appear aligned with the interaural midline and provide maximum spatial information in that region [<xref ref-type="bibr" rid="pbio-0030078-b20">20</xref>]. If a similar arrangement can explain the inhomogeneity of spatial sampling in the auditory cortex, then we would expect to find cortical RAF slopes to be steepest near the interaural midline as well.</p>
        <p>In this report, we compare the responses of neurons in primary auditory cortex (A1) and two higher-order auditory cortical fields (PAF and DZ) in the cat. Compared to A1, areas PAF and DZ exhibit spectrotemporally complex responses that are significantly more sensitive to variations in sound-source location [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>,<xref ref-type="bibr" rid="pbio-0030078-b25">25</xref>]. Therefore, these areas are the most likely candidate regions of cat auditory cortex for spatial specialization. PAF, in particular, appears necessary for sound localization by behaving cats [<xref ref-type="bibr" rid="pbio-0030078-b30">30</xref>].</p>
        <p><xref ref-type="fig" rid="pbio-0030078-g003">Figure 3</xref> depicts the distribution of preferred locations (“azimuth centroids”; see [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>]) along with locations of peak RAF slopes in all three fields. As we have reported previously, centroid distributions in <xref ref-type="fig" rid="pbio-0030078-g003">Figure 3</xref> reveal a preponderance of contralateral sensitivity regardless of cortical area or stimulus level [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>,<xref ref-type="bibr" rid="pbio-0030078-b25">25</xref>]. Distributions of peak-slope location, however, are tightly clustered around the frontal midline (median<italic>±</italic> standard error [see <xref ref-type="sec" rid="s3">Materials and Methods</xref>] in A1, +15° ± 2.5°; in DZ, +5° ± 2.1°; in PAF, −5° ± 2.6°). Values in A1 fall significantly farther into the ipsilateral field than do those in DZ (<italic>p</italic> &lt; 0.0004) or PAF (<italic>p</italic> &lt; 0.0002), consistent with both the broader spatial tuning and less extreme azimuth centroids of A1 compared to PAF or DZ units [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>,<xref ref-type="bibr" rid="pbio-0030078-b25">25</xref>]. Overall, the positioning of RAF slopes near the interaural midline suggests that auditory space is sampled inhomogeneously by the cortical population; the midline represents a transition region between locations eliciting responses from populations of contralateral- and ipsilateral-preferring units.</p>
        <fig id="pbio-0030078-g003" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030078.g003</object-id>
          <label>Figure 3</label>
          <caption>
            <title>RAF Slopes Are Steepest near the Interaural Midline</title>
            <p>Plotted are summaries of preferred locations (centroids) and points of maximum RAF slope for 254 units recorded in A1 (left), 411 in PAF (middle), and 298 in DZ (right) for levels 20 and 40 dB above threshold (thr) (bottom and top rows, respectively). In each panel, units are sorted by centroid (blue crosses) on the y-axis. Thin red lines denote the region of azimuth (x-axis) containing the centroid and bounded by the points of steepest slope. For units with centroids lateralized more than 10° from the midline, we marked either the steepest positive slope (for ipsilaterally tuned units) or negative slope (for contralateral units) with a black circle. These points represent the location of most rapid response change that occurs toward the front of the animal (relative to the centroid; for units that respond throughout the frontal hemifield, this point can occur toward the rear). Distributions of centroid (blue line) and peak slope (black line), calculated using kernel density estimation with 20<italic>°</italic> rectangular bins, are plotted below each panel. These indicate that while preferred locations (centroids) are strongly biased toward contralateral azimuths, peak slopes are tightly packed about the interaural midline, consistent with the opponent-channel hypothesis.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030078.g003" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2b">
        <title>Neural Response Patterns Discriminate Best across Midline</title>
        <p>Modulation of spike count is generally the most salient location-sensitive feature of neural responses, especially when data are averaged over many trials. However, temporal features of the neural response—such as first-spike latency, the temporal dispersion of spikes, and specific temporal features such as prototyped bursts of spikes or periods of inhibition—could also play an important role in stimulus coding by cortical neurons, and we have studied this role using pattern-recognition analyses applied to spike patterns [<xref ref-type="bibr" rid="pbio-0030078-b12">12</xref>,<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>,<xref ref-type="bibr" rid="pbio-0030078-b35">35</xref>]. Here, we assess the ability of neural spike patterns to subserve pairwise discrimination of stimulus locations by adapting the pattern-recognition approach of Stecker et al. [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>] to a discrimination paradigm. This approach is similar to the receiver-operating-characteristic analysis used to estimate interaural and/or spatial thresholds from neural spike counts [<xref ref-type="bibr" rid="pbio-0030078-b36">36</xref>,<xref ref-type="bibr" rid="pbio-0030078-b37">37</xref>,<xref ref-type="bibr" rid="pbio-0030078-b38">38</xref>], with the addition of spike-timing information. Given a spike pattern—a smoothed, bootstrap-averaged peristimulus time histogram (2-ms bins) that approximates the instantaneous probability of spike firing over the course of 200 ms following stimulus onset—elicited by stimulation from an unknown location in space, the algorithm estimates the relative likelihood that the pattern was evoked by a sound from each of the 18 tested locations. From these relative likelihoods, we compute the index of discriminability, <italic>d′</italic> [<xref ref-type="bibr" rid="pbio-0030078-b39">39</xref>], for each pair of stimulus locations. In <xref ref-type="fig" rid="pbio-0030078-g004">Figure 4</xref> (right), pairwise <italic>d′</italic> is plotted as a function of the midpoint and separation between paired stimuli for a single PAF unit; the contour <italic>d′</italic> = 1 (dashed line) indicates the spatial discrimination threshold. Note that in this example suprathreshold discrimination is possible at much narrower stimulus separations when the stimuli span the interaural midline (left/right discrimination) than in cases of front/back discrimination spanning +/− 90<italic>°</italic>, about which point many features of the neural response (e.g., spike rate and latency) are symmetrical. As a result, the minimum discriminable angle (MDA, defined as the minimum separation along the <italic>d′</italic> = 1 contour) of 25<italic>°</italic> is found at a best azimuth (BA, the midpoint location of the most discriminable pair) of −5<italic>°</italic>, near the frontal midline.</p>
        <fig id="pbio-0030078-g004" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030078.g004</object-id>
          <label>Figure 4</label>
          <caption>
            <title>Discrimination Analysis Based on Responses of One PAF Unit</title>
            <p>Left: raster plot of spike times (x-axis) recorded in response to broadband noise stimuli varying in azimuth (y-axis). Note the strong modulation of spike count, response latency, and temporal features of the response between contralateral and ipsilateral locations.</p>
            <p>Right: pairwise spatial discrimination. Colors indicate <italic>d′</italic> values for pairs of stimulus locations varying in separation (y-axis) and overall azimuth (x-axis, midpoint of two azimuths). The dashed line indicates threshold discrimination (<italic>d′</italic> = 1), and the red circle marks the unit's MDA (y-axis) and BA (x-axis).</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030078.g004" xlink:type="simple"/>
        </fig>
        <p>In <xref ref-type="fig" rid="pbio-0030078-g005">Figure 5</xref>, MDA is plotted as a function of BA for the entire population of A1, PAF, and DZ units in which discrimination thresholds could be calculated. Overall, two main features of the results should be noted. First, despite the broad azimuth tuning of cortical neurons, the majority can discriminate between stimuli separated by less than 40<italic>°</italic>. A number of neurons successfully discriminate even smaller separations—especially in DZ, in which the median MDA (30.5<italic>° ±</italic> 2.5<italic>°</italic>) is significantly smaller than in A1 (40<italic>° ±</italic> 2.6°; <italic>p</italic> &lt; 0.007) or PAF (43<italic>° ±</italic> 3.8<italic>°</italic>; <italic>p</italic> &lt; 0.0002). Note that MDAs of even the most sensitive units exceed behavioral estimates of 5°–6<italic>°</italic> minimum audible angles in cats [<xref ref-type="bibr" rid="pbio-0030078-b40">40</xref>], but likely underestimate the true neuronal performance because loudspeaker separations were tested in minimum steps of 20<italic>°</italic>, and thus discrimination at smaller separations can only be assessed through extrapolation. Second, the distribution of BAs is tightly clustered around the interaural midline, with 50% of BA values falling within 18.5<italic>°</italic> (PAF), 25<italic>°</italic> (A1), or 26<italic>°</italic> (DZ) of the 0<italic>°</italic> or 180<italic>°</italic> azimuth. Note that this does not mean that units cannot discriminate off-midline locations. It does indicate, however, that the majority of units capable of discriminating between stimulus azimuths do so best for location pairs near the interaural midline. Very few units exhibit BAs located far within either lateral hemifield, although A1 units exhibit significantly more ipsilateral BA values (median, +14.5<italic>° ±</italic> 3.9<italic>°</italic>) than those in PAF (0<italic>° ±</italic> 2.9<italic>°</italic>; <italic>p</italic> &lt; 0.004) or DZ (5<italic>° ±</italic> 4.3<italic>°</italic>; <italic>p</italic> &lt; 0.05). As with the analysis of RAF slopes, the pairwise discrimination data reveal an inhomogeneous arrangement of spatial sampling by neurons in the cortical population. Accurate discrimination is found where RAF slopes are steepest (the midline), rather than where units respond most strongly (the lateral poles).</p>
        <fig id="pbio-0030078-g005" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030078.g005</object-id>
          <label>Figure 5</label>
          <caption>
            <title>MDA by BA</title>
            <p>MDA (y-axis) is plotted against BA (x-axis) for each unit exhibiting suprathreshold spatial discrimination (see <xref ref-type="sec" rid="s3">Materials and Methods</xref>). Symbols indicate the cortical area of each unit. Left and lower panels plot distributions of MDA and BA (in numbers of units per rectangular 20<italic>°</italic> bin), respectively.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030078.g005" xlink:type="simple"/>
        </fig>
      </sec>
      <sec id="s2c">
        <title>An Opponent-Channel Code for Auditory Space?</title>
        <p>We have demonstrated quantitatively that the representation of auditory space in the cortex is inhomogeneous, consisting mainly of broadly tuned neurons whose responses change abruptly across the interaural midline. The population of auditory cortical neurons, then, appears to contain at least two subpopulations broadly responsive to contralateral and ipsilateral space. Neurons within each population exhibit similar spatial tuning and thus appear redundant with respect to spatial coding. The similarity of spatial tuning of units in these populations stands in contrast to their more profound differences in frequency tuning, for example. Each subpopulation, or “spatial channel,” is capable of representing locations on the slopes of their response areas (i.e., across the interaural midline) by graded changes in response—a “rate code” for azimuth, generalized to incorporate spatially informative temporal features of the cortical response [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>,<xref ref-type="bibr" rid="pbio-0030078-b35">35</xref>,<xref ref-type="bibr" rid="pbio-0030078-b41">41</xref>]. In other words, each spatial channel encodes space more or less panoramically, as we have argued previously for individual cortical neurons [<xref ref-type="bibr" rid="pbio-0030078-b12">12</xref>], although it now seems clear that some regions of space are represented with greater precision than others. In the past, we have argued that auditory space is encoded by patterns of activation across populations of such panoramic neurons. Here, we amend that view—which remains tenable—to reflect the observed inhomogeneity of spatial sampling in the cortex and account for differences in coding accuracy of midline and other locations. Following the proposals of von Békésy [<xref ref-type="bibr" rid="pbio-0030078-b42">42</xref>] and van Bergeijk [<xref ref-type="bibr" rid="pbio-0030078-b43">43</xref>] regarding interaural coding in the brainstem, we propose that auditory space is encoded specifically by differences in the activity of two broad spatial channels corresponding to subpopulations of contralateral and ipsilateral units within each hemisphere (i.e., by a left/right opponent process). We will refer to this proposal as the opponent-channel theory of spatial coding in the auditory cortex.</p>
        <p>An important consequence of the opponent-channel theory is that spatial coding may be robust in the face of changes in stimulus level. As is evident from past work, an important constraint on spatial coding in the cortex is the level dependence of many neurons' tuning widths, such that sharp tuning is seen predominantly for low-level stimulation. For example, a number of narrowly tuned units in <xref ref-type="fig" rid="pbio-0030078-g003">Figure 3</xref> exhibit locations of peak slope that closely track their centroids at 20 dB above threshold, and one could argue that such units form the basis of a local (e.g., topographic) spatial code when stimulus levels are low. Such a code, however, would be significantly impaired by increases in stimulus level—predicting that sound localization should be most accurate at low levels. That prediction is not borne out in psychophysical tests [<xref ref-type="bibr" rid="pbio-0030078-b44">44</xref>,<xref ref-type="bibr" rid="pbio-0030078-b45">45</xref>], and we have argued that spatial coding in the auditory cortex must employ relatively level-invariant features of the neural response [<xref ref-type="bibr" rid="pbio-0030078-b12">12</xref>]. Rather than relying on such features as they naturally occur, the opponent-channel mechanism constructs level-invariant features by comparing the activity of neurons that respond similarly to changes in level but differentially to changes in location, similarly to the coding of color by opponent-process cells in the visual system [<xref ref-type="bibr" rid="pbio-0030078-b46">46</xref>].</p>
        <p>To illustrate the level invariance achieved by opponent-process coding, we analyzed the ability of cortical population responses to signal sound-source locations in the frontal hemifield under different stimulus-level conditions. The analysis (see <xref ref-type="sec" rid="s3">Materials and Methods</xref>) is simplified in a number of ways—for example, it utilizes a simple linear decision rule that weights contralateral and ipsilateral input equally, sums across multiple neurons within each subpopulation (ignoring any complexity of neural circuitry), combines data across different cortical areas known to exhibit different spatial sensitivities, and reduces each neural response pattern to a single overall spike count—but serves as a “proof of concept” that differences between the responses of neural subpopulations with quasi-independent spatial tuning can be used to estimate sound-source locations in an unbiased manner when stimulus levels vary, whereas the individual population responses cannot.</p>
        <p>Population responses (means of normalized spike rate across neurons in a population) to stimuli varying in location and level were computed separately for subpopulations composed of contralateral units or ipsilateral units in our sample of recordings in A1, PAF, and DZ. These subpopulations correspond to hypothetical “left” and “right” channels of a spatial coding mechanism. Classification of stimulus locations was based on either one of the subpopulation responses or the difference between the two, and involved linear matching to templates computed from a separate training set [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>]. Population and difference RAFs are plotted in <xref ref-type="fig" rid="pbio-0030078-g006">Figure 6</xref> (left), along with confusion matrices (similar to <xref ref-type="fig" rid="pbio-0030078-g002">Figure 2</xref>) for sound-source classification based on each (right). Relatively accurate classification is exhibited by both subpopulation responses and by their difference when test and training sets reflect the same stimulus level. When training and test sets differ, however, responses are systematically biased. After training with 20-dB stimuli, localization of 40-dB stimuli by the contralateral subpopulation is biased toward the contralateral hemifield, because 40-dB ipsilateral stimuli and 20-dB contralateral stimuli elicit similar responses. Similarly, when trained with 40-dB stimuli, localization of 20-dB stimuli is biased toward the ipsilateral hemifield. This pattern is clear in the responses of both the contralateral-preferring and ipsilateral-preferring subpopulations. Classification based on their difference, however, is relatively unbiased. Significant undershoot (central responses for peripheral stimulus locations) results from compression of population RAFs by intense sound. While we know of no behavioral data relating to the effects of stimulus level on sound localization by cats, undershoot has been reported in numerous studies of their localization behavior [<xref ref-type="bibr" rid="pbio-0030078-b47">47</xref>,<xref ref-type="bibr" rid="pbio-0030078-b48">48</xref>,<xref ref-type="bibr" rid="pbio-0030078-b49">49</xref>]. Such undershoots, however, need not be assumed to reflect a limitation of the underlying neural representation of auditory space.</p>
        <fig id="pbio-0030078-g006" position="float">
          <object-id pub-id-type="doi">10.1371/journal.pbio.0030078.g006</object-id>
          <label>Figure 6</label>
          <caption>
            <title>Difference between Channel Responses Is Less Sensitive to Changes in Level Than Are Channel Responses Themselves</title>
            <p>Left: population responses (y-axis; see <xref ref-type="sec" rid="s3">Materials and Methods</xref>) are plotted as a function of azimuth (x-axis) for stimuli presented 20 dB (red) and 40 dB (blue) above unit thresholds. Population responses were computed separately for subpopulations composed of contralateral units (top) or ipsilateral units (middle) corresponding to hypothetical “left” and “right” channels of an opponent-channel spatial coding mechanism. The difference (bottom) between responses of the two subpopulations is more consistent across stimulus level than is either subpopulation response alone. Error bars indicate the standard deviation of responses across 120 simulated trials.</p>
            <p>Right: stimulus–response matrices (confusion matrices; see <xref ref-type="fig" rid="pbio-0030078-g002">Figure 2</xref>) showing the proportion (area of black circle) of responses to a given (unknown) stimulus azimuth (x-axis) classified at each response azimuth (y-axis). Classification assigned each neural population response in the “test” set to the stimulus azimuth whose mean population response in an independently selected set of “training” trials was most similar. In some conditions, test and training trials were drawn from the same set of (matching level) trials: 20 dB (first column) or 40 dB (far right column). In others, test and training trials reflected different-level stimuli: 40-dB test stimuli classified based on a 20-dB training set (second column), or 20-dB test stimuli classified based on a 40-dB training set (third column). The contralateral and ipsilateral subpopulation responses (top and middle rows) accurately localize fixed-level stimuli, but are strongly biased when tested at non-trained stimulus levels. In contrast, the difference between responses (bottom row) remains relatively unbiased in all conditions, although responses to stimuli at untrained levels do exhibit compressed range and increased variability of classification.</p>
          </caption>
          <graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030078.g006" xlink:type="simple"/>
        </fig>
        <p>Based on its manner of level-invariant spatial coding, it seems clear that an opponent-channel mechanism should behave similarly in the presence of any stimulus change (e.g., in frequency, modulation, or bandwidth) that acts to increase or decrease the response of both channels. This suggests an efficient means for combining spatial information with information about other stimulus dimensions. This general principle of opponent-process coding should hold in any case where both channels exhibit similar sensitivity to the nuisance dimension (level, frequency, etc.) but dissimilar sensitivity to space, and illustrates one strength of the opponent-channel coding strategy: the ability to recover spatial information from the responses of neurons that are strongly modulated by other stimulus dimensions. As long as some of the cortical neurons involved in coding a particular acoustic feature are contralaterally driven and others are ipsilaterally driven, the spatial location of that feature can be computed without imposing additional distortion of its neural representation.</p>
        <p>Note that the opponent-channel theory as presented here involves contralateral and ipsilateral channels within each hemisphere. This feature is based on the observation of both types of neurons in a single hemisphere, and on the results of unilateral cortical lesions, which produce localization deficits mainly in contralesional space [<xref ref-type="bibr" rid="pbio-0030078-b02">2</xref>,<xref ref-type="bibr" rid="pbio-0030078-b30">30</xref>,<xref ref-type="bibr" rid="pbio-0030078-b31">31</xref>,<xref ref-type="bibr" rid="pbio-0030078-b50">50</xref>]. The lesion data prevent us from considering opponent-channel mechanisms that place each channel in a separate hemisphere (e.g., left-hemisphere contralateral units versus right-hemisphere contralateral units) because in that case unilateral lesions should abolish localization throughout the entire acoustic field. As proposed here, however, the opponent-channel mechanism in either hemisphere should be capable of coding locations throughout space, not just in the contralateral hemifield. This would suggest that only bilateral lesions could produce localization deficits, which is also not the case. At this point, we can merely speculate that auditory cortical structures in each hemisphere provide input only to those multimodal spatial or sensorimotor structures that subserve localization behavior in contralateral space and, furthermore, that these inputs cannot be modified in adulthood following cortical lesions.</p>
      </sec>
      <sec id="s2d">
        <title>General Discussion</title>
        <p>In summary, the available data suggest that space is sampled nonuniformly in all fields of auditory cortex, with the majority of neurons responding broadly within one hemifield and modulating their responses abruptly across the interaural midline. Consistent with this view, we found cortical responses to be most sensitive to changes in stimulus azimuth at midline locations. Cortical neurons' RAFs tend to be steepest near the midline even though their preferred locations are found distributed throughout the contralateral hemifield. Spatial discrimination by neural responses is also best at or near the interaural midline. Results of both analyses are compatible with the existence of a limited number of spatial channels in the cortex, and incompatible with either a uniform distributed representation or a local representation (e.g., a topographic map). The relative paucity of units with sharp tuning peaking near the midline strongly suggests that behavioral sound-localization acuity is mediated by the slopes and not the peaks of spatial receptive fields.</p>
        <p>In this report, we consider a model of spatial coding based on differences in the response rates of two broad spatial channels in the auditory cortex. It is similar to the mechanism proposed by Boehnke and Phillips [<xref ref-type="bibr" rid="pbio-0030078-b51">51</xref>] to account for differences in human gap detection when gaps are bounded by auditory stimuli occurring in the same or opposite hemifields. In each proposal, neural response rates are compared across channels, but each is also consistent with information encoded in the relative response timing of cortical neurons [<xref ref-type="bibr" rid="pbio-0030078-b25">25</xref>,<xref ref-type="bibr" rid="pbio-0030078-b52">52</xref>]. Although the psychophysical and physiological data seem to agree on a two-channel mechanism, it is important to note that in this study, we treat units that respond more strongly to forward than rearward locations (“axial” units) as equivalent to units that respond equally to both quadrants (“hemifield” units). Similarly, we do not specifically examine the small number of units that respond best to midline locations. Distributed coding of interaural intensity by neural populations differing in binaural facilitation has been suggested previously [<xref ref-type="bibr" rid="pbio-0030078-b24">24</xref>]; similarly, populations of midline and/or axial units could be treated separately in a three-, four-, or five-channel opponent model of spatial coding. Such a model would follow the general principles of opponent-channel coding described here, but might differ in its ability to accurately code locations over wide regions of azimuth (see [<xref ref-type="bibr" rid="pbio-0030078-b24">24</xref>]).</p>
        <p>That the representation of space appears inhomogeneous in both primary and higher-order auditory cortical fields argues against the existence of a topographic “space map” within sensory cortex, pushing the emergence of any such map further into central structures than previously expected. The processing of interaural cues begins at the level of the superior olivary complex, but the integration of such cues into a complete topographic map of auditory space is presumed to begin with processing at the level of the IC or cortex. The suggestion that interaural cues are represented by a limited number of binaural channels in the IC [<xref ref-type="bibr" rid="pbio-0030078-b22">22</xref>] seems to imply that the space map must emerge at the level of auditory cortex or beyond, and the results of this study, along with others [<xref ref-type="bibr" rid="pbio-0030078-b15">15</xref>,<xref ref-type="bibr" rid="pbio-0030078-b16">16</xref>], suggest that a “limited channel” code is maintained throughout primary and non-primary fields of the auditory cortex as well. PAF, in particular, appears to sit at the top of the auditory cortical processing hierarchy [<xref ref-type="bibr" rid="pbio-0030078-b53">53</xref>] but is similar to primary auditory cortex (A1) in this regard.</p>
        <p>We should note that spatial coding must subserve at least two distinct behavioral tasks, namely, the discrimination of sound-source locations and the localization of individual sources (e.g., orientation, or pointing). Much of the current discussion has focused on aspects of spatial coding relevant to discrimination, and on the observation that the RAF slopes of cortical neurons are better suited to the discrimination of nearby locations than are their broad RAF peaks. Nevertheless, we are interested in general mechanisms of spatial representation, and argue that cortical neurons' broad spatial tuning suggests that neither aspect of sound localization is likely mediated by RAF peaks in cat cortex. This stands in contrast to the neural mechanism for sound localization in the IC of the owl, where sharp circumscribed spatial receptive fields form a place code for localization [<xref ref-type="bibr" rid="pbio-0030078-b07">7</xref>]. Owls' behavioral discrimination of spatial locations, however, is sharper than these neural receptive fields, and appears—as in mammals—to be mediated by receptive-field slopes [<xref ref-type="bibr" rid="pbio-0030078-b38">38</xref>]. Thus, the owl makes use of place and rate codes for different behavioral tasks. The cat's auditory cortex, on the other hand, lacks the sharp spatial tuning necessary for map-based localization, so one coding strategy underlies both types of behaviors.</p>
        <p>It seems clear that these different coding strategies in owls and cats necessitate different mechanisms for generating motor responses and orienting to sound sources. The owl's space map exhibits a straightforward correspondence between restricted neural activity and locations in space, which might be ideal for computing audiovisual correspondence but requires further translation into motor coordinate systems before action can take place. It is possible that the opponent-channel code is transformed into a similar auditory space map within multisensory or sensorimotor areas, that is, not within auditory cortex itself. Alternatively, opponent-channel population codes in the auditory domain might be directly transformed into population codes in the motor domain without an intervening map-like representation. In either case, we could argue that the fundamental mode of spatial coding within the auditory system per se is non-topographic. In fact, it might be that auditory spatial topography is an emergent property of widespread neural populations and is evident only in perception and behavior, not in the physiology of single neurons.</p>
        <p>In considering the relative advantages of opponent-channel spatial coding within the cortex, one might wonder whether the formation of a spatiotopic map would be necessary or desirable. As described above, the opponent-channel mechanism could subserve behavior without an intervening map, and it provides an efficient means of combining information about space with information about other stimulus features. In this regard, at least, the opponent-channel mechanism solves—or simply avoids—the so-called binding problem [<xref ref-type="bibr" rid="pbio-0030078-b54">54</xref>] of how multiple stimulus features can be associated to create a unified neural representation. It does so without recourse to specialized mechanisms for binding [<xref ref-type="bibr" rid="pbio-0030078-b55">55</xref>] and without an explosion in the number of neurons necessary for a complete combinatorial code [<xref ref-type="bibr" rid="pbio-0030078-b56">56</xref>]. So long as feature maps (e.g., of frequency) contain neurons of each class (i.e., contralateral and ipsilateral), the spatial position of any particular feature can be reconstructed without the difficulty of binding activity in one feature map (frequency) with that in another (location).</p>
        <p>Finally, the three cortical fields studied in this report exhibited similar evidence for an opponent-channel mechanism, despite previously reported differences in their spatial sensitivity [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>]. Although such differences appear modest when assessed physiologically, studies indicate that some fields are more critical for localization behavior than others [<xref ref-type="bibr" rid="pbio-0030078-b30">30</xref>]. An intriguing question for future research involves cortical fields—such as the anterior auditory field—that are not necessary for accurate localization. Are spatial channels maintained in such fields, or are they combined to produce space-invariant representations of other stimulus features?</p>
      </sec>
    </sec>
    <sec id="s3">
      <title>Materials and Methods</title>
      <sec id="s3a">
        <title/>
        <p>Data analyzed for this report were collected from extracellular recordings of 254, 411, and 298 units in areas A1, PAF, and DZ (respectively) of the cortex of chloralose-anesthetized cats [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>,<xref ref-type="bibr" rid="pbio-0030078-b25">25</xref>]. Methods of animal preparation, stimulus delivery, unit recording, and basic analysis have been described previously [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>], and were approved by the University of Michigan Committee on Use and Care of Animals. Stimuli were delivered from loudspeakers placed in the free field, and consisted of 80-ms broadband noise bursts presented at levels 20–40 dB above unit threshold. Stimulus locations spanned 360<italic>°</italic> of azimuth in 20<italic>°</italic> steps, and are identified by angular distance from the frontal midline (0<italic>°</italic>). Positive azimuths increase to to the right (ipsilateral to the recording site), whereas negative values correspond to contralateral locations on the cat's left side. Unit activity was recorded extracellularly from the right cerebral hemisphere using 16-channel electrode arrays (“Michigan probes”), and spikes were sorted off-line based on principal-components analysis of their waveshapes.</p>
        <sec id="s3a1">
          <title>Locations of peak slope and centroids</title>
          <p>Each unit's preferred location was characterized by the azimuth centroid of response (dark blue crosses in <xref ref-type="fig" rid="pbio-0030078-g003">Figure 3</xref>; see [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>]); this is the spike-count-weighted average of contiguous stimulus locations eliciting a normalized response at or above 75% of maximum spike count per stimulus presentation. We additionally determined the locations of peak slope for each unit by smoothing its RAF (circular convolution with a 40<italic>°</italic> boxcar) and calculating the first spatial derivative of the result. Maximum and minimum values of the derivative indicate two peak-slope azimuths for each unit (black circles and endpoints of red horizontal lines in <xref ref-type="fig" rid="pbio-0030078-g003">Figure 3</xref>).</p>
        </sec>
        <sec id="s3a2">
          <title>Spatial discrimination by neural response patterns</title>
          <p>Analyses of pairwise spatial discrimination (see <xref ref-type="fig" rid="pbio-0030078-g004">Figures 4</xref> and <xref ref-type="fig" rid="pbio-0030078-g005">5</xref>) employed a statistical pattern-recognition algorithm [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>] to estimate the relative likelihood of each stimulus location, given the temporal pattern of neural response to a single (unknown) stimulus. We computed, for each pair of locations θ<sub>1</sub> and θ<sub>2</sub> in the loudspeaker array, the index of pairwise discriminability <italic>d′</italic> [<xref ref-type="bibr" rid="pbio-0030078-b39">39</xref>] based on the estimated relative likelihoods:</p>
          <p>
						<disp-formula id="pbio-0030078-e001"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030078.e001" xlink:type="simple"/></disp-formula>
					</p>
          <p>where <italic>z</italic>(<italic>P</italic>) represents scaling to the standard normal distribution and the probability <italic>P</italic> of responding “1” is given by the (estimated) relative likelihood <italic>l</italic> of location θ<sub>1</sub> (versus θ<sub>2</sub>), conditional on the actual stimulus location θ<italic><sub>i</sub></italic>.</p>
          <p>
						<disp-formula id="pbio-0030078-e002"><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pbio.0030078.e002" xlink:type="simple"/></disp-formula>
					</p>
          <p>The analysis produces a map of <italic>d′</italic> between each pair of stimulus locations, plotted in coordinates of stimulus separation and overall location in <xref ref-type="fig" rid="pbio-0030078-g004">Figure 4</xref>. The map was interpolated to find a contour of <italic>d′</italic> = 1, which we define as threshold discrimination. The smallest stimulus separation along the threshold contour defines the MDA, and the overall location of that stimulus pair defines the unit's BA. Symbols in <xref ref-type="fig" rid="pbio-0030078-g004">Figures 4</xref> and <xref ref-type="fig" rid="pbio-0030078-g005">5</xref> indicate values of MDA and BA for individual units.</p>
        </sec>
        <sec id="s3a3">
          <title>Evaluation of a simple population code for space</title>
          <p>To assess the level invariance of opponent-channel coding, we analyzed a simplified model of population spatial coding in the cortex. For each neural unit in a channel (e.g., a subpopulation of contralateral-preferring units), we accumulated a list of responses (spike counts normalized to the maximum response across all trials) on each trial with a given combination of stimulus azimuth and level. Azimuths were confined to the frontal hemifield (−80° to +80°) to avoid front–back confusions, which obscure but do not alter the appearance of bias in classification responses, and levels were either 20 or 40 dB above individual unit thresholds. We then computed population responses by randomly selecting one trial (with matching stimulus azimuth and level) from each unit and computing the mean of individual responses. We repeated the selection process 120 times for each combination of azimuth and level to simulate a set of 120 population “trials.” The mean of these population responses for each stimulus is plotted on the left in <xref ref-type="fig" rid="pbio-0030078-g006">Figure 6</xref>. Separate “training” and “test” sets of population responses were computed by this method and used to assess the ability of subpopulations to classify stimulus locations. Individual population responses in the test set were classified to the azimuth with the most-similar mean population response across the training set. Confusion matrices in <xref ref-type="fig" rid="pbio-0030078-g006">Figure 6</xref> plot the proportion of test-set responses assigned to each stimulus azimuth. In some conditions, test and training sets were drawn from the same trials (matching level); in other conditions, training and test sets differed in stimulus level.</p>
          <p>We tested classification based on responses of a contralateral subpopulation, an ipsilateral subpopulation, and on the difference between subpopulation responses. Contralateral and ipsilateral subpopulations were composed of all units with centroids falling farther than 30° into the corresponding hemifield in our sample of A1, PAF, and DZ units. Differences were computed from the two subpopulation responses on a trial-by-trial basis, and classification was tested in the same manner as for the population responses themselves.</p>
        </sec>
        <sec id="s3a4">
          <title>Statistical procedures</title>
          <p>Tests of statistical significance in this study were conducted using a 5,000-permutation bootstrap test (see [<xref ref-type="bibr" rid="pbio-0030078-b14">14</xref>] for details), reported to one significant digit. Standard error of the median, where reported, was obtained using a 2,000-permutation bootstrap, drawing <italic>N</italic> (the total number of data points) samples from the data with replacement on each permutation and recomputing the median. Distributions in <xref ref-type="fig" rid="pbio-0030078-g003">Figures 3</xref> and <xref ref-type="fig" rid="pbio-0030078-g005">5</xref> were computed by kernel density estimation (convolution) with a 20<italic>°</italic> rectangular window to obtain a continuous function of units per 20<italic>°</italic> bin.</p>
        </sec>
      </sec>
    </sec>
  </body>
  <back>
    <ack>
      <p>We thank Ewan Macpherson for assistance with data collection, Zekiye Onsan for technical and administrative support, and three anonymous reviewers for insightful comments. Funding was provided by the National Science Foundation (grant DBI-0107567) and the National Institute on Deafness and Other Communication Disorders (grants R01 DC00420, P30 DC05188, F32 DC006113, and T32 DC00011). Recording probes were provided by the University of Michigan Center for Neural Communication Technology (CNCT, NIBIB P41 EB002030).</p>
    </ack>
    
    <ref-list>
      <title>References</title>
      <ref id="pbio-0030078-b01">
        <label>1</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Heffner</surname>
              <given-names>HE</given-names>
            </name>
            <name name-style="western">
              <surname>Heffner</surname>
              <given-names>RS</given-names>
            </name>
          </person-group>
          <article-title>Effect of bilateral auditory cortex lesions on sound localization in Japanese macaques.</article-title>
          <source>J Neurophysiol</source>
          <year>1990</year>
          <volume>64</volume>
          <fpage>915</fpage>
          <lpage>931</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b02">
        <label>2</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Jenkins</surname>
              <given-names>WM</given-names>
            </name>
            <name name-style="western">
              <surname>Masterton</surname>
              <given-names>RB</given-names>
            </name>
          </person-group>
          <article-title>Sound localization: Effects of unilateral lesions in the central auditory system.</article-title>
          <source>J Neurophysiol</source>
          <year>1982</year>
          <volume>47</volume>
          <fpage>987</fpage>
          <lpage>1016</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b03">
        <label>3</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Kavanagh</surname>
              <given-names>GL</given-names>
            </name>
            <name name-style="western">
              <surname>Kelly</surname>
              <given-names>JB</given-names>
            </name>
          </person-group>
          <article-title>Contributions of auditory cortex to sound localization by the ferret (<named-content content-type="genus-species" xlink:type="simple">Mustela putorius</named-content>).</article-title>
          <source>J Neurophysiol</source>
          <year>1987</year>
          <volume>57</volume>
          <fpage>1746</fpage>
          <lpage>1766</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b04">
        <label>4</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Jeffress</surname>
              <given-names>LA</given-names>
            </name>
          </person-group>
          <article-title>A place theory of sound localization.</article-title>
          <source>J Comp Physiol Psych</source>
          <year>1948</year>
          <volume>41</volume>
          <fpage>35</fpage>
          <lpage>39</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b05">
        <label>5</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Palmer</surname>
              <given-names>AR</given-names>
            </name>
            <name name-style="western">
              <surname>King</surname>
              <given-names>AJ</given-names>
            </name>
          </person-group>
          <article-title>A monaural space map in the guinea-pig superior colliculus.</article-title>
          <source>Hear Res</source>
          <year>1982</year>
          <volume>17</volume>
          <fpage>267</fpage>
          <lpage>280</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b06">
        <label>6</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>JC</given-names>
            </name>
            <name name-style="western">
              <surname>Knudsen</surname>
              <given-names>EI</given-names>
            </name>
          </person-group>
          <article-title>A neural code for auditory space in the cat's superior colliculus.</article-title>
          <source>J Neurosci</source>
          <year>1984</year>
          <volume>4</volume>
          <fpage>2621</fpage>
          <lpage>2634</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b07">
        <label>7</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Knudsen</surname>
              <given-names>E</given-names>
            </name>
            <name name-style="western">
              <surname>Konishi</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>A neural map of auditory space in the owl.</article-title>
          <source>Science</source>
          <year>1978</year>
          <volume>200</volume>
          <fpage>795</fpage>
          <lpage>797</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b08">
        <label>8</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Takahashi</surname>
              <given-names>T</given-names>
            </name>
            <name name-style="western">
              <surname>Moiseff</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Konishi</surname>
              <given-names>M</given-names>
            </name>
          </person-group>
          <article-title>Time and intensity cues are processed independently in the auditory system of the owl.</article-title>
          <source>J Neurosci</source>
          <year>1984</year>
          <volume>4</volume>
          <fpage>1781</fpage>
          <lpage>1786</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b09">
        <label>9</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Knudsen</surname>
              <given-names>EI</given-names>
            </name>
          </person-group>
          <article-title>Auditory and visual maps of space in the optic tectum of the owl.</article-title>
          <source>J Neurosci</source>
          <year>1982</year>
          <volume>2</volume>
          <fpage>1177</fpage>
          <lpage>1194</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b10">
        <label>10</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Brugge</surname>
              <given-names>JF</given-names>
            </name>
            <name name-style="western">
              <surname>Reale</surname>
              <given-names>RA</given-names>
            </name>
            <name name-style="western">
              <surname>Hind</surname>
              <given-names>JE</given-names>
            </name>
          </person-group>
          <article-title>The structure of spatial receptive fields of neurons in primary auditory cortex of the cat.</article-title>
          <source>J Neurosci</source>
          <year>1996</year>
          <volume>16</volume>
          <fpage>4420</fpage>
          <lpage>4437</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b11">
        <label>11</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>JC</given-names>
            </name>
            <name name-style="western">
              <surname>Pettigrew</surname>
              <given-names>JD</given-names>
            </name>
          </person-group>
          <article-title>Functional classes of neurons in primary auditory cortex of the cat distinguished by sensitivity to sound location.</article-title>
          <source>J Neurosci</source>
          <year>1981</year>
          <volume>1</volume>
          <fpage>107</fpage>
          <lpage>120</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b12">
        <label>12</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>JC</given-names>
            </name>
            <name name-style="western">
              <surname>Xu</surname>
              <given-names>L</given-names>
            </name>
            <name name-style="western">
              <surname>Eddins</surname>
              <given-names>AC</given-names>
            </name>
            <name name-style="western">
              <surname>Green</surname>
              <given-names>DM</given-names>
            </name>
          </person-group>
          <article-title>Codes for sound-source location in nontonotopic auditory cortex.</article-title>
          <source>J Neurophysiol</source>
          <year>1998</year>
          <volume>80</volume>
          <fpage>863</fpage>
          <lpage>881</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b13">
        <label>13</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Rajan</surname>
              <given-names>R</given-names>
            </name>
            <name name-style="western">
              <surname>Aitkin</surname>
              <given-names>LM</given-names>
            </name>
            <name name-style="western">
              <surname>Irvine</surname>
              <given-names>DRF</given-names>
            </name>
            <name name-style="western">
              <surname>McKay</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Azimuthal sensitivity of neurons in primary auditory cortex of cats. I. Types of sensitivity and the effects of variations in stimulus parameters.</article-title>
          <source>J Neurophysiol</source>
          <year>1990</year>
          <volume>64</volume>
          <fpage>872</fpage>
          <lpage>887</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b14">
        <label>14</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Stecker</surname>
              <given-names>GC</given-names>
            </name>
            <name name-style="western">
              <surname>Mickey</surname>
              <given-names>BJ</given-names>
            </name>
            <name name-style="western">
              <surname>Macpherson</surname>
              <given-names>EA</given-names>
            </name>
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>JC</given-names>
            </name>
          </person-group>
          <article-title>Spatial sensitivity in field PAF of cat auditory cortex.</article-title>
          <source>J Neurophysiol</source>
          <year>2003</year>
          <volume>89</volume>
          <fpage>2889</fpage>
          <lpage>2903</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b15">
        <label>15</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Kitzes</surname>
              <given-names>L</given-names>
            </name>
            <name name-style="western">
              <surname>Wrege</surname>
              <given-names>K</given-names>
            </name>
            <name name-style="western">
              <surname>Cassady</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Patterns of responses of cortical cells to binaural stimulation.</article-title>
          <source>J Comp Neurol</source>
          <year>1980</year>
          <volume>192</volume>
          <fpage>455</fpage>
          <lpage>472</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b16">
        <label>16</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Phillips</surname>
              <given-names>D</given-names>
            </name>
            <name name-style="western">
              <surname>Irvine</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Responses of single neurons in physiologically defined area AI of cat cerebral cortex: Sensitivity to interaural intensity differences.</article-title>
          <source>Hear Res</source>
          <year>1981</year>
          <volume>4</volume>
          <fpage>299</fpage>
          <lpage>307</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b17">
        <label>17</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Aitkin</surname>
              <given-names>LM</given-names>
            </name>
            <name name-style="western">
              <surname>Martin</surname>
              <given-names>RL</given-names>
            </name>
          </person-group>
          <article-title>The representation of stimulus azimuth by high best-frequency azimuth-selective neurons in the central nucleus of the inferior colliculus of the cat.</article-title>
          <source>J Neurophysiol</source>
          <year>1987</year>
          <volume>57</volume>
          <fpage>1185</fpage>
          <lpage>1200</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b18">
        <label>18</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Brand</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Behrend</surname>
              <given-names>O</given-names>
            </name>
            <name name-style="western">
              <surname>Marquardt</surname>
              <given-names>T</given-names>
            </name>
            <name name-style="western">
              <surname>McAlpine</surname>
              <given-names>D</given-names>
            </name>
            <name name-style="western">
              <surname>Grothe</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>Precise inhibition is essential for microsecond interaural time difference coding.</article-title>
          <source>Nature</source>
          <year>2002</year>
          <volume>417</volume>
          <fpage>543</fpage>
          <lpage>547</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b19">
        <label>19</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Hancock</surname>
              <given-names>KE</given-names>
            </name>
            <name name-style="western">
              <surname>Delgutte</surname>
              <given-names>B</given-names>
            </name>
          </person-group>
          <article-title>A physiologically based model of interaural time difference discrimination.</article-title>
          <source>J Neurosci</source>
          <year>2004</year>
          <volume>24</volume>
          <fpage>7110</fpage>
          <lpage>7117</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b20">
        <label>20</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Harper</surname>
              <given-names>NS</given-names>
            </name>
            <name name-style="western">
              <surname>McAlpine</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Optimal neural population coding of an auditory spatial cue.</article-title>
          <source>Nature</source>
          <year>2004</year>
          <volume>430</volume>
          <fpage>682</fpage>
          <lpage>686</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b21">
        <label>21</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Leiman</surname>
              <given-names>AL</given-names>
            </name>
            <name name-style="western">
              <surname>Hafter</surname>
              <given-names>ER</given-names>
            </name>
          </person-group>
          <article-title>Responses of inferior colliculus neurons to free field auditory stimuli.</article-title>
          <source>Exp Neurol</source>
          <year>1972</year>
          <volume>35</volume>
          <fpage>431</fpage>
          <lpage>449</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b22">
        <label>22</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>McAlpine</surname>
              <given-names>D</given-names>
            </name>
            <name name-style="western">
              <surname>Jiang</surname>
              <given-names>D</given-names>
            </name>
            <name name-style="western">
              <surname>Palmer</surname>
              <given-names>AR</given-names>
            </name>
          </person-group>
          <article-title>A neural code for low-frequency sound localization in mammals.</article-title>
          <source>Nat Neurosci</source>
          <year>2001</year>
          <volume>4</volume>
          <fpage>396</fpage>
          <lpage>401</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b23">
        <label>23</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Semple</surname>
              <given-names>MN</given-names>
            </name>
            <name name-style="western">
              <surname>Aitkin</surname>
              <given-names>LM</given-names>
            </name>
            <name name-style="western">
              <surname>Calford</surname>
              <given-names>MB</given-names>
            </name>
            <name name-style="western">
              <surname>Pettigrew</surname>
              <given-names>JD</given-names>
            </name>
            <name name-style="western">
              <surname>Phillips</surname>
              <given-names>DP</given-names>
            </name>
          </person-group>
          <article-title>Spatial receptive fields in the cat inferior colliculus.</article-title>
          <source>Hear Res</source>
          <year>1983</year>
          <volume>10</volume>
          <fpage>203</fpage>
          <lpage>215</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b24">
        <label>24</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Wise</surname>
              <given-names>L</given-names>
            </name>
            <name name-style="western">
              <surname>Irvine</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Topographic organization of interaural intensity difference sensitivity in deep layers of cat superior colliculus: Implications for auditory spatial representation.</article-title>
          <source>J Neurophysiol</source>
          <year>1985</year>
          <volume>54</volume>
          <fpage>185</fpage>
          <lpage>211</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b25">
        <label>25</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Stecker</surname>
              <given-names>GC</given-names>
            </name>
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>JC</given-names>
            </name>
          </person-group>
          <article-title>Distributed coding of sound locations in the auditory cortex.</article-title>
          <source>Biol Cybern</source>
          <year>2003</year>
          <volume>89</volume>
          <fpage>341</fpage>
          <lpage>349</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b26">
        <label>26</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>J</given-names>
            </name>
            <name name-style="western">
              <surname>Clock</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Xu</surname>
              <given-names>L</given-names>
            </name>
            <name name-style="western">
              <surname>Green</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>A panoramic code for sound location by cortical neurons.</article-title>
          <source>Science</source>
          <year>1994</year>
          <volume>264</volume>
          <fpage>842</fpage>
          <lpage>844</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b27">
        <label>27</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Imig</surname>
              <given-names>T</given-names>
            </name>
            <name name-style="western">
              <surname>Adrin</surname>
              <given-names>H</given-names>
            </name>
          </person-group>
          <article-title>Binaural columns in the primary field (A1) of cat auditory cortex.</article-title>
          <source>Brain Res</source>
          <year>1977</year>
          <volume>138</volume>
          <fpage>241</fpage>
          <lpage>257</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b28">
        <label>28</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>JC</given-names>
            </name>
            <name name-style="western">
              <surname>Dykes</surname>
              <given-names>RW</given-names>
            </name>
            <name name-style="western">
              <surname>Merzenich</surname>
              <given-names>MM</given-names>
            </name>
          </person-group>
          <article-title>Binaural response-specific bands in primary auditory cortex (AI) of the cat: Topographical organization orthogonal to isofrequency contours.</article-title>
          <source>Brain Res</source>
          <year>1980</year>
          <volume>181</volume>
          <fpage>31</fpage>
          <lpage>48</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b29">
        <label>29</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Nakamoto</surname>
              <given-names>KT</given-names>
            </name>
            <name name-style="western">
              <surname>Zhang</surname>
              <given-names>J</given-names>
            </name>
            <name name-style="western">
              <surname>Kitzes</surname>
              <given-names>LM</given-names>
            </name>
          </person-group>
          <article-title>Response patterns along an isofrequency contour in cat primary auditory cortex (AI) to stimuli varying in average and interaural levels.</article-title>
          <source>J Neurophysiol</source>
          <year>2004</year>
          <volume>91</volume>
          <fpage>118</fpage>
          <lpage>135</lpage>
          <comment>doi: <ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1152/jn.00171.2003" xlink:type="simple">10.1152/jn.00171.2003</ext-link></comment>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b30">
        <label>30</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Malhotra</surname>
              <given-names>S</given-names>
            </name>
            <name name-style="western">
              <surname>Hall</surname>
              <given-names>A</given-names>
            </name>
            <name name-style="western">
              <surname>Lomber</surname>
              <given-names>S</given-names>
            </name>
          </person-group>
          <article-title>Cortical control of sound localization in the cat: Unilateral cooling deactivation of 19 cerebral areas.</article-title>
          <source>J Neurophysiol</source>
          <year>2004</year>
          <volume>92</volume>
          <fpage>1625</fpage>
          <lpage>1643</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b31">
        <label>31</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Thompson</surname>
              <given-names>GC</given-names>
            </name>
            <name name-style="western">
              <surname>Cortez</surname>
              <given-names>AM</given-names>
            </name>
          </person-group>
          <article-title>The inability of squirrel monkeys to localize sound after unilateral ablation of auditory cortex.</article-title>
          <source>Behav Brain Res</source>
          <year>1983</year>
          <volume>8</volume>
          <fpage>211</fpage>
          <lpage>216</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b32">
        <label>32</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Hafter</surname>
              <given-names>ER</given-names>
            </name>
            <name name-style="western">
              <surname>De Maio</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Difference thresholds for interaural delay.</article-title>
          <source>J Acoust Soc Am</source>
          <year>1975</year>
          <volume>57</volume>
          <fpage>181</fpage>
          <lpage>187</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b33">
        <label>33</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Mills</surname>
              <given-names>AW</given-names>
            </name>
          </person-group>
          <article-title>On the minimum audible angle.</article-title>
          <source>J Acoust Soc Am</source>
          <year>1958</year>
          <volume>30</volume>
          <fpage>237</fpage>
          <lpage>246</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b34">
        <label>34</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Phillips</surname>
              <given-names>D</given-names>
            </name>
            <name name-style="western">
              <surname>Brugge</surname>
              <given-names>J</given-names>
            </name>
          </person-group>
          <article-title>Progress in neurophysiology of sound localization.</article-title>
          <source>Annu Rev Psychol</source>
          <year>1985</year>
          <volume>36</volume>
          <fpage>245</fpage>
          <lpage>274</lpage>
          <comment>doi: <ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1146/annurev.ps.36.020185.001333" xlink:type="simple">10.1146/annurev.ps.36.020185.001333</ext-link></comment>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b35">
        <label>35</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Furukawa</surname>
              <given-names>S</given-names>
            </name>
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>JC</given-names>
            </name>
          </person-group>
          <article-title>Cortical representation of auditory space: Information-bearing features of spike patterns.</article-title>
          <source>J Neurophysiol</source>
          <year>2002</year>
          <volume>87</volume>
          <fpage>1749</fpage>
          <lpage>1762</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b36">
        <label>36</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Shackleton</surname>
              <given-names>TM</given-names>
            </name>
            <name name-style="western">
              <surname>Skottun</surname>
              <given-names>BC</given-names>
            </name>
            <name name-style="western">
              <surname>Arnott</surname>
              <given-names>RH</given-names>
            </name>
            <name name-style="western">
              <surname>Palmer</surname>
              <given-names>AR</given-names>
            </name>
          </person-group>
          <article-title>Interaural time difference discrimination thresholds for single neurons in the inferior colliculus of guinea pigs.</article-title>
          <source>J Neurosci</source>
          <year>2003</year>
          <volume>23</volume>
          <fpage>716</fpage>
          <lpage>724</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b37">
        <label>37</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Skottun</surname>
              <given-names>B</given-names>
            </name>
            <name name-style="western">
              <surname>Shackleton</surname>
              <given-names>T</given-names>
            </name>
            <name name-style="western">
              <surname>Arnott</surname>
              <given-names>R</given-names>
            </name>
            <name name-style="western">
              <surname>Palmer</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>The ability of inferior colliculus neurons to signal differences in interaural delay.</article-title>
          <source>Proc Natl Acad Sci U S A</source>
          <year>2001</year>
          <volume>98</volume>
          <fpage>14050</fpage>
          <lpage>14054</lpage>
          <comment>doi: <ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1073/pnas.241513998" xlink:type="simple">10.1073/pnas.241513998</ext-link></comment>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b38">
        <label>38</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Takahashi</surname>
              <given-names>TT</given-names>
            </name>
            <name name-style="western">
              <surname>Bala</surname>
              <given-names>ADS</given-names>
            </name>
            <name name-style="western">
              <surname>Spitzer</surname>
              <given-names>MW</given-names>
            </name>
            <name name-style="western">
              <surname>Euston</surname>
              <given-names>DR</given-names>
            </name>
            <name name-style="western">
              <surname>Spezio</surname>
              <given-names>ML</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>The synthesis and use of the owl's auditory space map.</article-title>
          <source>Biol Cybern</source>
          <year>2003</year>
          <volume>89</volume>
          <fpage>378</fpage>
          <lpage>387</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b39">
        <label>39</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Green</surname>
              <given-names>DM</given-names>
            </name>
            <name name-style="western">
              <surname>Swets</surname>
              <given-names>JA</given-names>
            </name>
          </person-group>
          <source>Signal detection theory and psychophysics</source>
          <year>1966</year>
          <publisher-loc>New York</publisher-loc>
          <publisher-name>John Wiley and Sons</publisher-name>
          <page-count count="455"/>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b40">
        <label>40</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Heffner</surname>
              <given-names>R</given-names>
            </name>
            <name name-style="western">
              <surname>Heffner</surname>
              <given-names>H</given-names>
            </name>
          </person-group>
          <article-title>Sound localization acuity in the cat: Effect of azimuth, signal duration, and test procedure.</article-title>
          <source>Hear Res</source>
          <year>1988</year>
          <volume>36</volume>
          <fpage>221</fpage>
          <lpage>232</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b41">
        <label>41</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Jenison</surname>
              <given-names>RL</given-names>
            </name>
          </person-group>
          <article-title>Decoding first-spike latency: A likelihood approach.</article-title>
          <source>Neurocomputing</source>
          <year>2001</year>
          <volume>38–40</volume>
          <fpage>239</fpage>
          <lpage>248</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b42">
        <label>42</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>von Békésy</surname>
              <given-names>G</given-names>
            </name>
          </person-group>
          <article-title>Zur Theorie des Hörens. Über das Richtungshören bei einer Zeitdefferenz oder Lautstärkenungleichheit der beiderseitigen Schalleinwirkungen.</article-title>
          <source>Physik Z</source>
          <year>1930</year>
          <volume>31</volume>
          <fpage>824</fpage>
          <lpage>835</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b43">
        <label>43</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>van Bergeijk</surname>
              <given-names>WA</given-names>
            </name>
          </person-group>
          <article-title>Variation on a theme of Békésy: A model of binaural interaction.</article-title>
          <source>J Acoust Soc Am</source>
          <year>1962</year>
          <volume>34</volume>
          <fpage>1431</fpage>
          <lpage>1437</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b44">
        <label>44</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Sabin</surname>
              <given-names>AT</given-names>
            </name>
            <name name-style="western">
              <surname>Macpherson</surname>
              <given-names>EA</given-names>
            </name>
            <name name-style="western">
              <surname>Middlebrooks</surname>
              <given-names>JC</given-names>
            </name>
          </person-group>
          <article-title>Human sound localization at near-threshold levels.</article-title>
          <source>Hear Res</source>
          <year>2004</year>
          <volume>199</volume>
          <fpage>124</fpage>
          <lpage>134</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b45">
        <label>45</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Vliegen</surname>
              <given-names>J</given-names>
            </name>
            <name name-style="western">
              <surname>Van Opstal</surname>
              <given-names>AJ</given-names>
            </name>
          </person-group>
          <article-title>The influence of duration and level on human sound localization.</article-title>
          <source>J Acoust Soc Am</source>
          <year>2004</year>
          <volume>115</volume>
          <fpage>1705</fpage>
          <lpage>1713</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b46">
        <label>46</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>DeValois</surname>
              <given-names>RL</given-names>
            </name>
            <name name-style="western">
              <surname>DeValois</surname>
              <given-names>KK</given-names>
            </name>
          </person-group>
          <article-title>A multi-stage color model.</article-title>
          <source>Vision Res</source>
          <year>1993</year>
          <volume>33</volume>
          <fpage>1053</fpage>
          <lpage>1065</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b47">
        <label>47</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>May</surname>
              <given-names>B</given-names>
            </name>
            <name name-style="western">
              <surname>Huang</surname>
              <given-names>A</given-names>
            </name>
          </person-group>
          <article-title>Sound orientation behavior in cats. I. Localization of broadband noise.</article-title>
          <source>J Acoust Soc Am</source>
          <year>1996</year>
          <volume>100</volume>
          <fpage>1059</fpage>
          <lpage>1069</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b48">
        <label>48</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Populin</surname>
              <given-names>L</given-names>
            </name>
            <name name-style="western">
              <surname>Yin</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>Behavioral studies of sound localization in the cat.</article-title>
          <source>J Neurosci</source>
          <year>1998</year>
          <volume>18</volume>
          <fpage>2147</fpage>
          <lpage>2160</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b49">
        <label>49</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Tollin</surname>
              <given-names>DJ</given-names>
            </name>
            <name name-style="western">
              <surname>Populin</surname>
              <given-names>LC</given-names>
            </name>
            <name name-style="western">
              <surname>Moore</surname>
              <given-names>JM</given-names>
            </name>
            <name name-style="western">
              <surname>Ruhland</surname>
              <given-names>JL</given-names>
            </name>
            <name name-style="western">
              <surname>Yin</surname>
              <given-names>TC</given-names>
            </name>
          </person-group>
          <article-title>Sound localization performance in the cat: The effect of restraining the head.</article-title>
          <source>J Neurophysiol</source>
          <year>2004</year>
          <comment>doi: <ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1152/jn.00747.2004" xlink:type="simple">10.1152/jn.00747.2004</ext-link></comment>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b50">
        <label>50</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Heffner</surname>
              <given-names>H</given-names>
            </name>
          </person-group>
          <article-title>The role of macaque auditory cortex in sound localization.</article-title>
          <source>Acta Otolaryngol Suppl</source>
          <year>1997</year>
          <volume>532</volume>
          <fpage>22</fpage>
          <lpage>27</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b51">
        <label>51</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Boehnke</surname>
              <given-names>S</given-names>
            </name>
            <name name-style="western">
              <surname>Phillips</surname>
              <given-names>D</given-names>
            </name>
          </person-group>
          <article-title>Azimuthal tuning of human perceptual channels for sound location.</article-title>
          <source>J Acoust Soc Am</source>
          <year>1999</year>
          <volume>106</volume>
          <fpage>1948</fpage>
          <lpage>1955</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b52">
        <label>52</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Phillips</surname>
              <given-names>D</given-names>
            </name>
            <name name-style="western">
              <surname>Hall</surname>
              <given-names>S</given-names>
            </name>
            <name name-style="western">
              <surname>Harrington</surname>
              <given-names>I</given-names>
            </name>
            <name name-style="western">
              <surname>Taylor</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>“Central” auditory gap detection: A spatial case.</article-title>
          <source>J Acoust Soc Am</source>
          <year>1998</year>
          <volume>103</volume>
          <fpage>2064</fpage>
          <lpage>2068</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b53">
        <label>53</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Rouiller</surname>
              <given-names>EM</given-names>
            </name>
            <name name-style="western">
              <surname>Simm</surname>
              <given-names>GM</given-names>
            </name>
            <name name-style="western">
              <surname>Villa</surname>
              <given-names>AEP</given-names>
            </name>
            <name name-style="western">
              <surname>de Ribaupierre</surname>
              <given-names>Y</given-names>
            </name>
            <name name-style="western">
              <surname>de Ribaupierre</surname>
              <given-names>F</given-names>
            </name>
          </person-group>
          <article-title>Auditory corticocortical interconnections in the cat: Evidence for parallel and hierarchical arrangement of the auditory cortical areas.</article-title>
          <source>Exp Brain Res</source>
          <year>1991</year>
          <volume>86</volume>
          <fpage>483</fpage>
          <lpage>505</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b54">
        <label>54</label>
        <nlm-citation publication-type="book" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Rosenblatt</surname>
              <given-names>F</given-names>
            </name>
          </person-group>
          <source>Principles of neurodynamics: Perceptions and the theory of brain mechanisms</source>
          <year>1961</year>
          <publisher-loc>Washington (D.C.)</publisher-loc>
          <publisher-name>Spartan Books</publisher-name>
          <page-count count="616"/>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b55">
        <label>55</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>von der Malsburg</surname>
              <given-names>C</given-names>
            </name>
          </person-group>
          <article-title>The what and why of binding: The modeler's perspective.</article-title>
          <source>Neuron</source>
          <year>1999</year>
          <volume>24</volume>
          <fpage>95</fpage>
          <lpage>104</lpage>
        </nlm-citation>
      </ref>
      <ref id="pbio-0030078-b56">
        <label>56</label>
        <nlm-citation publication-type="journal" xlink:type="simple">
          <person-group person-group-type="author">
            <name name-style="western">
              <surname>Riesenhuber</surname>
              <given-names>M</given-names>
            </name>
            <name name-style="western">
              <surname>Poggio</surname>
              <given-names>T</given-names>
            </name>
          </person-group>
          <article-title>Are cortical models really bound by the “binding problem”?</article-title>
          <source>Neuron</source>
          <year>1999</year>
          <volume>24</volume>
          <fpage>87</fpage>
          <lpage>93</lpage>
        </nlm-citation>
      </ref>
    </ref-list>
    <glossary>
      <title>Abbreviations</title>
      <def-list>
        <def-item>
          <term>A1</term>
          <def>
            <p>primary auditory field</p>
          </def>
        </def-item>
        <def-item>
          <term>BA</term>
          <def>
            <p>best azimuth</p>
          </def>
        </def-item>
        <def-item>
          <term>DZ</term>
          <def>
            <p>dorsal zone</p>
          </def>
        </def-item>
        <def-item>
          <term>IC</term>
          <def>
            <p>inferior colliculus</p>
          </def>
        </def-item>
        <def-item>
          <term>MDA</term>
          <def>
            <p>minimum discriminable angle</p>
          </def>
        </def-item>
        <def-item>
          <term>PAF</term>
          <def>
            <p>posterior auditory field</p>
          </def>
        </def-item>
        <def-item>
          <term>RAF</term>
          <def>
            <p>rate–azimuth function</p>
          </def>
        </def-item>
      </def-list>
    </glossary>
  </back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="3.0" xml:lang="EN">
<front>
<journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta>
<article-meta><article-id pub-id-type="publisher-id">09-PLCB-RA-0949R3</article-id><article-id pub-id-type="doi">10.1371/journal.pcbi.1000586</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Neuroscience/Theoretical Neuroscience</subject></subj-group></article-categories><title-group><article-title>Spike-Based Reinforcement Learning in Continuous State and Action Space: When Policy Gradient Methods Fail</article-title><alt-title alt-title-type="running-head">Navigation: When Policy Gradient Methods Fail</alt-title></title-group><contrib-group>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Vasilaki</surname><given-names>Eleni</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="corresp" rid="cor1"><sup>*</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Frémaux</surname><given-names>Nicolas</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Urbanczik</surname><given-names>Robert</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Senn</surname><given-names>Walter</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib>
<contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Gerstner</surname><given-names>Wulfram</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib>
</contrib-group><aff id="aff1"><label>1</label><addr-line>Laboratory of Computational Neuroscience, EPFL, Lausanne, Switzerland</addr-line>       </aff><aff id="aff2"><label>2</label><addr-line>Department of Computer Science, University of Sheffield, Sheffield, United Kingdom</addr-line>       </aff><aff id="aff3"><label>3</label><addr-line>Department of Physiology, University of Bern, Bern, Switzerland</addr-line>       </aff><contrib-group>
<contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Friston</surname><given-names>Karl J.</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/></contrib>
</contrib-group><aff id="edit1">University College London, United Kingdom</aff><author-notes>
<corresp id="cor1">* E-mail: <email xlink:type="simple">E.Vasilaki@sheffield.ac.uk</email></corresp>
<fn fn-type="con"><p>Conceived and designed the experiments: EV WG. Performed the experiments: EV. Analyzed the data: EV. Wrote the paper: WG. Partially wrote the paper: EV. Participated in discussions: NF RU WS. Partially wrote the <xref ref-type="sec" rid="s4">Methods</xref> section: RU WS.</p></fn>
<fn fn-type="conflict"><p>The authors have declared that no competing interests exist.</p></fn></author-notes><pub-date pub-type="collection"><month>12</month><year>2009</year></pub-date><pub-date pub-type="epub"><day>4</day><month>12</month><year>2009</year></pub-date><volume>5</volume><issue>12</issue><elocation-id>e1000586</elocation-id><history>
<date date-type="received"><day>6</day><month>8</month><year>2009</year></date>
<date date-type="accepted"><day>30</day><month>10</month><year>2009</year></date>
</history><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2009</copyright-year><copyright-holder>Vasilaki et al</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><abstract>
<p>Changes of synaptic connections between neurons are thought to be the physiological basis of learning. These changes can be gated by neuromodulators that encode the presence of reward. We study a family of reward-modulated synaptic learning rules for spiking neurons on a learning task in continuous space inspired by the Morris Water maze. The synaptic update rule modifies the release probability of synaptic transmission and depends on the timing of presynaptic spike arrival, postsynaptic action potentials, as well as the membrane potential of the postsynaptic neuron. The family of learning rules includes an optimal rule derived from policy gradient methods as well as reward modulated Hebbian learning. The synaptic update rule is implemented in a population of spiking neurons using a network architecture that combines feedforward input with lateral connections. Actions are represented by a population of hypothetical action cells with strong mexican-hat connectivity and are read out at theta frequency. We show that in this architecture, a standard policy gradient rule fails to solve the Morris watermaze task, whereas a variant with a Hebbian bias can learn the task within 20 trials, consistent with experiments. This result does not depend on implementation details such as the size of the neuronal populations. Our theoretical approach shows how learning new behaviors can be linked to reward-modulated plasticity at the level of single synapses and makes predictions about the voltage and spike-timing dependence of synaptic plasticity and the influence of neuromodulators such as dopamine. It is an important step towards connecting formal theories of reinforcement learning with neuronal and synaptic properties.</p>
</abstract><abstract abstract-type="summary"><title>Author Summary</title>
<p>Humans and animals learn if they receive reward. Such reward is likely to be communicated throughout the brain by neuromodulatory signals. In this paper we present a network of model neurons, which communicate by short electrical pulses (spikes). Learning is achieved by modifying the input connections depending on the signals they emit and receive, if a sequence of action is followed by reward. With such a learning rule, a simulated animal learns to find (starting from arbitrary initial conditions) a target location where reward has occurred in the past.</p>
</abstract><funding-group><funding-statement>The work was partially supported by FACETS, the Framework Application for Core-Edge Transport Simulations European Project. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><page-count count="17"/></counts></article-meta>
</front>
<body><sec id="s1">
<title>Introduction</title>
<p>Animals can learn new behaviors by exploring available actions in the presence of reward signals. Typical conditioning experiments are structured so that animals learn by trial and error, either by reinforcing a desired behavior with a positive reward (finding food, escaping from a stressful situation), or by penalizing undesired actions by a negative reward signal (electric shock or uncomfortable water temperature). Learning by reward is known in the field of machine learning as reinforcement learning <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref> but has roots in behavioral psychology that can be traced back at least to Thorndike's law of effect <xref ref-type="bibr" rid="pcbi.1000586-Thorndike1">[2]</xref>. These early ideas have influenced the mathematical description of classical conditioning in the theories of Rescorla and Wagner <xref ref-type="bibr" rid="pcbi.1000586-Rescorla1">[3]</xref>, the ‘hedonistic neuron’ of Klopf <xref ref-type="bibr" rid="pcbi.1000586-Klopf1">[4]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Klopf2">[5]</xref>, or the early psychological theories of animal learning and conditioning by Sutton and Barto <xref ref-type="bibr" rid="pcbi.1000586-Sutton2">[6]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Sutton3">[8]</xref>. Before we turn to the specific learning paradigm that we consider in the present paper, we devote some space in this introduction section to an extensive review of three-factor rules in spiking neuron models and their relation to unsupervised Hebbian models and classical reinforcement learning models. The contributions of the present paper are sketched on the background of this earlier work.</p>
<sec id="s1a">
<title/>
<sec id="s1a1">
<title>Didactic Review of three-factor rules</title>
<p>On the cellular level, learning and memory is thought to be implemented by changes in the strength of the synaptic connection between pairs of neurons <xref ref-type="bibr" rid="pcbi.1000586-Bliss1">[9]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Malenka1">[10]</xref>. Many of the classical experiments on Long-Term Potentiation and Depression (LTP and LTD) have been inspired by the ideas of Hebb that the co-activation of two neurons should lead to a strengthening of the connection between them <xref ref-type="bibr" rid="pcbi.1000586-Hebb1">[11]</xref>. Thus, according the Hebb's principle the change of a weight <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e001" xlink:type="simple"/></inline-formula> from a presynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e002" xlink:type="simple"/></inline-formula> to a postsynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e003" xlink:type="simple"/></inline-formula> depends only on the state of the presynaptic and postsynaptic neurons<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e004" xlink:type="simple"/><label>(1)</label></disp-formula>with some learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e005" xlink:type="simple"/></inline-formula>. Even without specifying the functions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e006" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e007" xlink:type="simple"/></inline-formula> and the exact nature of the states <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e008" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e009" xlink:type="simple"/></inline-formula> of the two neurons, the equation (1) captures the essence of a Hebb rule, i.e., the weight change depends only on the state of the two neurons, and possibly on the current value of the weight itself, but not on that of other neurons or other signals. Such a ‘2-factor’ Hebb rule is the basis of classical models of unsupervised <xref ref-type="bibr" rid="pcbi.1000586-Oja1">[12]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Kohonen1">[13]</xref> and developmental learning <xref ref-type="bibr" rid="pcbi.1000586-vonderMalsburg1">[14]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Bienenstock1">[15]</xref>. In these classical models the functions <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e010" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e011" xlink:type="simple"/></inline-formula> are linear or quadratic functions of the firing rates of pre- and postsynaptic neurons, respectively. Modern models of Spike-Timing Dependent Plasticity (STDP) can be considered as an implementation of Hebb's rule on the level of spikes <xref ref-type="bibr" rid="pcbi.1000586-Gerstner1">[16]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Morrison1">[21]</xref>.</p>
<p>However, a Hebbian two-factor rule, be it formulated on the level of spikes or on the level of rates, cannot take into account the presence or absence of a reward signal. Rewarding situations are thought to be represented in the brain by changes in the concentration of neuromodulators that is available to and shared by large populations of neurons. More precisely, in some brain areas, dopamine has been identified as candidate molecule signaling unexpected rewarding situation <xref ref-type="bibr" rid="pcbi.1000586-Schultz1">[22]</xref>. It is therefore tempting to extend the ‘local’ Hebbian rule in Eq. (1) by a third factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e012" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e013" xlink:type="simple"/></inline-formula> represents a ‘global’ neuromodulatory signal characterizing rewarding situations and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e014" xlink:type="simple"/></inline-formula> a baseline<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e015" xlink:type="simple"/><label>(2)</label></disp-formula>Suppose for the moment that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e016" xlink:type="simple"/></inline-formula> if the animal has recently received a reward and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e017" xlink:type="simple"/></inline-formula> otherwise and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e018" xlink:type="simple"/></inline-formula>. The consequence of the 3-factor rule (2) is that a weight change predicted by the Hebbian rule (1) is implemented only in the presence of a reward. In the absence of reward, a weight change cannot occur.</p>
<p>Experimentally, three-factor rules such as (2) have been studied extensively in the cortico-striatal synapse <xref ref-type="bibr" rid="pcbi.1000586-Wickens1">[23]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Reynolds2">[26]</xref> using a classical firing rate-based protocol. A different line of research around synaptic tagging <xref ref-type="bibr" rid="pcbi.1000586-Frey1">[27]</xref> in the hippocampus has shown that synaptic changes induced by tetanic protocols of Long-Term-Potentiation can be stabilized only in the presence of neuromodulators such as dopamine <xref ref-type="bibr" rid="pcbi.1000586-Reymann1">[28]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Sajikumar2">[30]</xref> suggesting that the Hebbian changes need neuromodulators as a third factor for stabilization. More recently the timing-dependence of the three factor rule in cortical-striatal synapses has been studied on the level of spikes, yielding a form of dopamine-dependent STDP <xref ref-type="bibr" rid="pcbi.1000586-Pawlak1">[31]</xref>.</p>
<p>Theories of three-factor rules on the time scale of milliseconds have been addressed by a number of different groups <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Potjans1">[37]</xref>. Three different theoretical approaches can be distinguished. The first one consists in deriving a learning rule from reward optimization by gradient descent <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Baras1">[38]</xref>, an approach that can be linked to policy gradient methods in machine learning <xref ref-type="bibr" rid="pcbi.1000586-Williams1">[39]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Baxter1">[40]</xref>; the second one postulates a form of STDP that is modulated by reward <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Izhikevich1">[35]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Legenstein1">[36]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Farries1">[41]</xref>, an approach that can be considered an extension of classical STDP models <xref ref-type="bibr" rid="pcbi.1000586-Gerstner1">[16]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Abbott1">[17]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Kempter1">[42]</xref>; the third one translates the framework of Temporal-Difference learning (TD) models <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Watkins1">[43]</xref>, in particular actor-critic models <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Barto1">[7]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Suri1">[44]</xref>, to spiking neuronal networks <xref ref-type="bibr" rid="pcbi.1000586-Potjans1">[37]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-DiCastro1">[45]</xref>. As an aside, gradient rules can be also formulated in the context of node and weight perturbation where the postsynaptic activity does not explicitly enter, yielding a modified two-factor rule rather than a three-factor rule <xref ref-type="bibr" rid="pcbi.1000586-Seung1">[46]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Fiete1">[47]</xref>. We would also like to mention the sensitivity of STDP to the derivative of the postsynaptic activity which has been related to TD-learning <xref ref-type="bibr" rid="pcbi.1000586-Wrgtter1">[48]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Rao1">[50]</xref>.</p>
<p>In this paper we study a network of spiking neurons that has to solve a navigation problem to a hidden target. Rewards are delayed, i.e., the animal has to perform a sequence of action before it receives a positive or negative reward signal. Our approach can be related to policy gradient methods for spiking neurons <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>, but goes beyond these earlier studies for two reasons: First, we consider a more general class of learning rules that contain policy gradient rules and a naive reward modulated Hebbian rule as a special case. Second, we consider the case of strong lateral interaction between action neurons, that lead to the spontaneous formation of activity bumps in the layer where the action selection takes place.</p>
<p>The resulting synaptic update rules can be formulated as a differential equation in continuous time that has the form of a three-factor rule<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e019" xlink:type="simple"/><label>(3)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e020" xlink:type="simple"/><label>(4)</label></disp-formula>The term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e021" xlink:type="simple"/></inline-formula>, called eligibility trace, picks up the correlations between pre- and postsynaptic activity just as in a Hebbian learning rule and convolves these with a low-pass filter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e022" xlink:type="simple"/></inline-formula>. However, the final weight change is implemented only in the presence of a reward signal <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e023" xlink:type="simple"/></inline-formula> which is delivered at the time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e024" xlink:type="simple"/></inline-formula> when the animal hits the target. The choices of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e025" xlink:type="simple"/></inline-formula> considered in this paper are: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e026" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e027" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e028" xlink:type="simple"/></inline-formula> is the reward signal averaged over many trials.</p>
<p>In contrast to earlier work of Xie and Seung <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref> but similar to <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Izhikevich1">[35]</xref> our approach takes into account spiking neurons with refractoriness and includes examples such as the standard integrate-and-fire model. Under certain conditions on the refractoriness <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>, our learning rule can be identified with a standard STDP model, but modulated by a third factor <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Legenstein1">[36]</xref>. In contrast to most earlier work <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Legenstein1">[36]</xref>, our learning rule is applied to a network of neurons that combines feed-forward input with lateral interactions.</p>
</sec><sec id="s1a2">
<title>Learning paradigm</title>
<p>In order to show the potential of the family of spike-timing dependent three-factor rules studied in this paper, we apply it to the Morris water maze paradigm <xref ref-type="bibr" rid="pcbi.1000586-Morris1">[51]</xref>. It is a standard paradigm of behavioral learning and navigation, and has also already been used as a challenging paradigm for TD-learning models <xref ref-type="bibr" rid="pcbi.1000586-Foster1">[52]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Sheynikhovich1">[55]</xref>. In this behavioral paradigm, a rat (or mouse) is placed in a pool of milky (non-transparent) water. In order to escape from the water, it has to find an invisible platform hidden just below the water surface. Climbing on the hidden platform can be considered as rewarding, since it ends a disagreeable experience. During the first trial of the experiment, the rat discovers the platform by chance. In subsequent trials the rat is each time placed at a different starting location. Nevertheless, across several trials the rat learns to navigate towards the hidden platform based on distal surrounding cues <xref ref-type="bibr" rid="pcbi.1000586-Foster1">[52]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Poucet1">[56]</xref>. In contrast to a variant of the task with <italic>fixed</italic> initial condition <xref ref-type="bibr" rid="pcbi.1000586-Eichenbaum1">[57]</xref>, the Morris Watermaze task with <italic>variable</italic> starting condition considered in this paper depends on the hippocampus <xref ref-type="bibr" rid="pcbi.1000586-Morris1">[51]</xref>.</p>
<p>In this paper we model the Morris Watermaze paradigm using a minimal hippocampal model of spiking neurons. The model we propose has the following features:</p>
<list list-type="order"><list-item>
<p>The position of the rat is a continuous quantity represented by an ensemble of place cells with overlapping place fields (coarse coding). These place cells have feedforward connections to action cells.</p>
</list-item><list-item>
<p>Actions are represented by a population of action cells representing different direction of movements in a coarse coding paradigm. New actions, defined as the population vector activity across action cells, are chosen periodically at theta frequency.</p>
</list-item><list-item>
<p>The action cells are organized on a ring with lateral connectivity showing local excitation and long-range inhibition. As a result, the population of action cells respond to input from place cells with a bump-like activity profile.</p>
</list-item><list-item>
<p>The feedforward connections of place cells to action cells change according to a three factor learning rule on the level of spikes, that can be considered reward modulated form of Hebbian plasticity derived from reward maximization.</p>
</list-item><list-item>
<p>Synaptic transmission in the feedforward connections is stochastic and learning takes place through the modification of the release probability.</p>
</list-item><list-item>
<p>The problem of learning a sequence of actions when reward is given at only the end of the sequence is solved by an eligibility trace that appears naturally in the derivation of the learning rule. The eligibility trace is implemented as a local memory at the site of the synapse.</p>
</list-item></list>
<p>A large fraction of classical reinforcement models have been developed for artificial systems with a finite number of (discrete) states and a small number of actions. However, real animals move in a continuous space and, in some paradigms, also have a large choice of actions that is best described as a continuum. Classical TD models such as Q-learning <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Watkins1">[43]</xref>, are ill adapted to this situation: if a continuous state is approximated by a discretized state-space of increasing resolution (larger number of states) learning slows down, unless an eligibility trace is introduced into the algorithm and/or function approximation is used <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref>. On the contrary, the architecture we adopt here allows the animal to move in a continuous arena, without a significant reduction in performance.</p>
<p>Moreover, while convergence of TD models is guaranteed in the presence of an eligibility trace <xref ref-type="bibr" rid="pcbi.1000586-Dayan1">[58]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Dayan2">[59]</xref>, the addition of an eligibility trace in these algorithm is somewhat <italic>ad hoc</italic>, whereas eligibility traces appear naturally in the policy gradient framework. Surprisingly, the standard policy gradient method for spiking neurons <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref> does not work for the scenario where action choices are decided by the formation of an activity bump in the layer of action cells. However, we will show that our model network with a modified learning rule with a ‘Hebbian bias’ does learn navigation to an invisible goal within 20 trials, similar to the performance of rats in the Morris Water Maze task <xref ref-type="bibr" rid="pcbi.1000586-Foster1">[52]</xref>. Because of the coarse coding of states and actions by cells with overlapping place fields and ‘action fields’, the model allows to encode position and action in continuous state and action spaces. We will show that with our coarse coding approach the learning performance is independent of the number of cells. Thus performance is stable and does not depend on implementation details. We argue that on one hand, a crucial ingredient of this structural stability are the lateral interactions in the ring of action cells; on the other hand it is exactly the fact that actions are chosen based on the location of a stable activity bump that makes standard policy gradient methods fail.</p>
</sec></sec></sec><sec id="s2">
<title>Results</title>
<p>The results section is organized in three main parts. First, we discuss the main features of our three-factor learning rule for spiking neurons. To test this learning rule in a realistic paradigm, we introduce in the second part the Morris water-maze learning task and the model architecture with place cells and action cells suitable for solving the task. Finally, the performance of the learning rule in this task is presented.</p>
<sec id="s2a">
<title>Three-factor learning rule for spiking neurons</title>
<p>We consider a Spike Response Model neuron with index <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e029" xlink:type="simple"/></inline-formula> that receives input from other neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e030" xlink:type="simple"/></inline-formula>. The <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e031" xlink:type="simple"/></inline-formula> input spike from neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e032" xlink:type="simple"/></inline-formula> arrives at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e033" xlink:type="simple"/></inline-formula> at a synapses onto neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e034" xlink:type="simple"/></inline-formula> and causes there an excitatory (or inhibitory) postsynaptic potential (EPSP or IPSP) of time course <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e035" xlink:type="simple"/></inline-formula> and amplitude <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e036" xlink:type="simple"/></inline-formula>. The EPSPs and IPSPs of all incoming spikes are added to the membrane potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e037" xlink:type="simple"/></inline-formula> of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e038" xlink:type="simple"/></inline-formula>. Spikes are generated stochastically with an instantaneous rate (or stochastic intensity)<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e039" xlink:type="simple"/><label>(5)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e040" xlink:type="simple"/></inline-formula> is a positive function that increases with the membrane potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e041" xlink:type="simple"/></inline-formula>, see also Eq. (24). Immediately after a spike of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e042" xlink:type="simple"/></inline-formula> at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e043" xlink:type="simple"/></inline-formula>, the neuron enters into a state of relative refractoriness, which is implemented by a hyperpolarizing spike afterpotential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e044" xlink:type="simple"/></inline-formula>. Thus the total membrane potential of the Spike Response Model neuron is <xref ref-type="bibr" rid="pcbi.1000586-Gerstner2">[20]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e045" xlink:type="simple"/><label>(6)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e046" xlink:type="simple"/></inline-formula> is the resting potential, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e047" xlink:type="simple"/></inline-formula> is the set of presynaptic spikes, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e048" xlink:type="simple"/></inline-formula> is the set of postsynaptic spikes up to time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e049" xlink:type="simple"/></inline-formula>.</p>
<p>Using this neuron model, we can calculate the probability that neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e050" xlink:type="simple"/></inline-formula> generates a specific spike train with firing times <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e051" xlink:type="simple"/></inline-formula> during a trial of duration <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e052" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>, see <xref ref-type="sec" rid="s4">Methods</xref>, Eq. (25). Some of the spikes of neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e053" xlink:type="simple"/></inline-formula> occur just before a reward is delivered, others not. The aim of learning is to change the synaptic weights <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e054" xlink:type="simple"/></inline-formula> so that the probability of receiving a reward <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e055" xlink:type="simple"/></inline-formula> increases. We consider learning rules of the form<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e056" xlink:type="simple"/><label>(7)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e057" xlink:type="simple"/></inline-formula> is the learning rate (controlling the amplitude of weight updates), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e058" xlink:type="simple"/></inline-formula> the moment when the animal hits the target or the wall, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e059" xlink:type="simple"/></inline-formula> is the positive reward for finding the target, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e060" xlink:type="simple"/></inline-formula> the (negative) reward for bumping into a wall and b a reward baseline, for instance an estimate of the positive reward based on past experience. The eligibility trace <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e061" xlink:type="simple"/></inline-formula> evolves according<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e062" xlink:type="simple"/><label>(8)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e063" xlink:type="simple"/></inline-formula> is the spike train of the postsynaptic neuron, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e064" xlink:type="simple"/></inline-formula> the Dirac function, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e065" xlink:type="simple"/></inline-formula> the eligibility trace time constant, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e066" xlink:type="simple"/></inline-formula> a parameter with units of time, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e067" xlink:type="simple"/></inline-formula> the derivative of the function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e068" xlink:type="simple"/></inline-formula>.</p>
<p>Because of the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e069" xlink:type="simple"/></inline-formula>, the learning equations (9) and (8) define a <italic>family</italic> of learning rules, rather than one single instance of a rule. The parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e070" xlink:type="simple"/></inline-formula> is a specific feature of our model which allows to turn the model from a strict policy gradient method (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e071" xlink:type="simple"/></inline-formula>, <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref> see methods) to a naive Hebbian model (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e072" xlink:type="simple"/></inline-formula>, see below the discussion of the postsynaptic factor). Thus we are able to link and compare these conceptually different rules via the modification of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e073" xlink:type="simple"/></inline-formula>. We note that for small firing rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e074" xlink:type="simple"/></inline-formula>, Eq. (9) approximates the optimal policy gradient rule of <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>, while for larger firing rates, it enhances the Hebbian component of the rule. For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e075" xlink:type="simple"/></inline-formula>, the term in the square brackets goes to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e076" xlink:type="simple"/></inline-formula> so that for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e077" xlink:type="simple"/></inline-formula> learning is driven by the Hebbian correlation term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e078" xlink:type="simple"/></inline-formula>. In the main body of the simulation results, we pick a fixed value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e079" xlink:type="simple"/></inline-formula> which implies that we use a policy gradient method with a Hebbian bias.</p>
<p>The estimate of the positive reward is calculated as a running mean updated <italic>at the end of the trial</italic> according the following equation: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e080" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e081" xlink:type="simple"/></inline-formula> being the number of the trial and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e082" xlink:type="simple"/></inline-formula> being the reward at the end of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e083" xlink:type="simple"/></inline-formula> trial (1 or 0) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e084" xlink:type="simple"/></inline-formula> the width of the averaging window.</p>
<p>We will now show that Eqs. (7) and (8) can be interpreted as a three-factor learning rule for spiking neurons, within the general framework outlined in the introduction.</p>
<sec id="s2a1">
<title>Presynaptic factor</title>
<p>Presynaptic spike arrival causes an EPSP. The time course of the EPSP <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e085" xlink:type="simple"/></inline-formula> represents the effect of presynaptic activity at the location of the synapse. We emphasize that the term presynaptic factor does not imply that this factor is implemented presynaptically - rather it refers to a term causes by the activity of the presynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e086" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s2a2">
<title>Postsynaptic factor</title>
<p>Postsynaptic activity is represented by both the timing <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e087" xlink:type="simple"/></inline-formula> of postsynaptic action potentials and the postsynaptic membrane potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e088" xlink:type="simple"/></inline-formula>. The membrane potential enters in the function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e089" xlink:type="simple"/></inline-formula> that determines the instantaneous firing rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e090" xlink:type="simple"/></inline-formula>. Postsynaptic spikes are treated as events and described by the function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e091" xlink:type="simple"/></inline-formula>. The postsynaptic factor, denoted by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e092" xlink:type="simple"/></inline-formula>, is encapsulated by the square brackets in Eq. (8) and visualized as a function of membrane potential in <xref ref-type="fig" rid="pcbi-1000586-g001">Figure 1</xref>. For the case of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e093" xlink:type="simple"/></inline-formula> the postsynaptic factor depends only on spike timing, but not on the membrane potential of the postsynaptic neuron.</p>
<fig id="pcbi-1000586-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g001</object-id><label>Figure 1</label><caption>
<title>Postsynaptic factors of the learning rule.</title>
<p>A model neuron receives constant strong input making it fire at about 50Hz. A:Time course of the voltage. B: The postsynaptic factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e094" xlink:type="simple"/></inline-formula> of the rule evaluated in time steps of 1 ms (see Eq. 8). The postsynaptic factor decreases with voltage, but has a sharp positive peak during a spike. The case <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e095" xlink:type="simple"/></inline-formula> (blue line) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e096" xlink:type="simple"/></inline-formula> are nearly indistinguishable. C: The accumulated term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e097" xlink:type="simple"/></inline-formula> as a function of time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e098" xlink:type="simple"/></inline-formula> shows a clear difference between the two cases. For the model with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e099" xlink:type="simple"/></inline-formula> (blue line) it fluctuates around 0 while for the model with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e100" xlink:type="simple"/></inline-formula> (red line) it exhibits a positive drift. D: The postsynaptic factor as a function of voltage is extracted from the data in graphs A and B by plotting the momentary value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e101" xlink:type="simple"/></inline-formula> from graph B as a function of the voltage in graph A in the same time step. For voltages above 60 mV the neuron models always spikes for this input scenario, so that the postsynaptic factor is positive.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g001" xlink:type="simple"/></fig>
<p>The presynaptic and postsynaptic factors both enter into the eligibility trace <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e102" xlink:type="simple"/></inline-formula> of Eq. (8) which is a quantity that must be stored locally at the synapses from neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e103" xlink:type="simple"/></inline-formula> to neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e104" xlink:type="simple"/></inline-formula>. The eligibility trace of the synapse from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e105" xlink:type="simple"/></inline-formula> to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e106" xlink:type="simple"/></inline-formula> is updated by a finite positive amount whenever a postsynaptic action potential occurs within the time span of an EPSP at this synapse. Hence the eligibility trace picks up (potentially causal) correlations between presynaptic spike arrival and postsynaptic spike firing. If an EPSP occurs without a postsynaptic spike, the eligibility trace decays smoothly at a rate proportional to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e107" xlink:type="simple"/></inline-formula>. In particular, if the membrane potential is high, but no postsynaptic spike is triggered, the eligibility trace decreases strongly. However, in the limit <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e108" xlink:type="simple"/></inline-formula> such a depression of the synapse does not occur. Thus, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e109" xlink:type="simple"/></inline-formula> the eligibility trace is naive Hebbian in the sense that it is increased if postsynpatic spikes occur shortly after (and potentially triggered by) presynaptic spike arrival. If a synapse is not active (that is, in the absence of an EPSP at the synapse), the eligibility always decays with a slow time constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e110" xlink:type="simple"/></inline-formula> in the range of seconds. Whatever the choice of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e111" xlink:type="simple"/></inline-formula>, the eligibility trace uses only local quantities that are available at the site of the synapse and stores locally the correlations between pre- and postsynaptic activity averaged over several seconds. In the limit of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e112" xlink:type="simple"/></inline-formula> these correlations are zero <italic>on average</italic> because spikes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e113" xlink:type="simple"/></inline-formula> are generated at the rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e114" xlink:type="simple"/></inline-formula> so that the expectation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e115" xlink:type="simple"/></inline-formula> vanishes. However, in a single trial the correlations stored by the eligibility trace are typically nonzero.</p>
</sec><sec id="s2a3">
<title>Global factor</title>
<p>The third factor in our synaptic learning rule is the global reward term described by the expression <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e116" xlink:type="simple"/></inline-formula>. It represents in our theory the time course of the (external) reward delivery. Neuromodulators such as dopamine represent a diffusive reward-related signal across large brain regions <xref ref-type="bibr" rid="pcbi.1000586-Schultz1">[22]</xref>. In our theory, the synapse calculates and stores locally the eligibility trace. However, changes at the weights are implemented only, if the change ‘proposed’ by the eligibility trace is ‘confirmed’ by a global neuromodulatory signal.</p>
</sec><sec id="s2a4">
<title>Stochastic binary synapses</title>
<p>Transmission of information across the synapse is not a deterministic event, but has a stochastic component. Changes in the synaptic ‘weight’ <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e117" xlink:type="simple"/></inline-formula> discussed above, are likely to correspond to changes in the probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e118" xlink:type="simple"/></inline-formula> of releasing a fixed amount of neurotransmitter across the synaptic cleft <xref ref-type="bibr" rid="pcbi.1000586-Tsodyks1">[60]</xref>. Let us suppose that the synapse transmits either a fixed amount <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e119" xlink:type="simple"/></inline-formula> of neurotransmitter or nothing at all. Learning affects the neurotransmitter release so that increasing the weight <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e120" xlink:type="simple"/></inline-formula> of the synapse by the above update rule will increase the release probability such that the mean weight can be expressed as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e121" xlink:type="simple"/></inline-formula>. Thus, for stochastic binary synapses, as used in our simulations, we arrive at the following learning rule<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e122" xlink:type="simple"/><label>(9)</label></disp-formula>where the eligibility trace is the same as in Eq. (8). Since <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e123" xlink:type="simple"/></inline-formula> is a probability it is bounded to a maximum of 1. We also impose a lower bound <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e124" xlink:type="simple"/></inline-formula>. We implement these contraints by a learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e125" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e126" xlink:type="simple"/></inline-formula> and zero otherwise.</p>
</sec><sec id="s2a5">
<title>Learning rule parameters</title>
<p>Free parameters are: the learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e127" xlink:type="simple"/></inline-formula>, the eligibility trace time constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e128" xlink:type="simple"/></inline-formula>, parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e129" xlink:type="simple"/></inline-formula>, which tunes the Hebbian bias of the learning rule, and the noise level of the neuronal response (controlled by parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e130" xlink:type="simple"/></inline-formula>, see Model architecture, Action Cells). Other parameters are fixed a priory <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Clopath1">[61]</xref>.</p>
</sec></sec><sec id="s2b">
<title>Model architecture</title>
<p>The learning rules discussed in the previous subsection (with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e131" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e132" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e133" xlink:type="simple"/></inline-formula>) are tested on a simulated Morris Watermaze task with variable start condition, a task known to involve hippocampus <xref ref-type="bibr" rid="pcbi.1000586-Morris1">[51]</xref>. Hippocampus is represented as a population of place cells, with place cells centers organized on a rectangular grid. These model place cells project onto ‘action’ cells, putatively placed in the nucleus accumbens. The population of action cells represents the next action to be chosen by the model rat and is organized in a ring-like topology with lateral connectivity of the Mexican-hat type; see <xref ref-type="fig" rid="pcbi-1000586-g002">Figure 2</xref>.</p>
<fig id="pcbi-1000586-g002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g002</object-id><label>Figure 2</label><caption>
<title>Hippocampal model.</title>
<p>A: Schematic overview. Place cells are connected via all-to-all feedforward connections (red) to the action cells, which in addition receive lateral input (light blue) via connections with a mexican hat profile (not all connections shown). B: Rasterplot of action cells, showing activity of the cells encoding for the chosen direction. The spiking activity of action cells starts with stochastic firing at low rates until an activity bump is formed after 25ms. C: Spike train of neurons labeled 1 and 2, corresponding to the schema on the left, when the rodent is placed in the receptive field of neuron 1.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g002" xlink:type="simple"/></fig><sec id="s2b1">
<title>Hippocampal place cells (HPC)</title>
<p>Hippocampal place cells are modeled as Poisson neurons with a firing rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e134" xlink:type="simple"/></inline-formula> that is a Gaussian function of the animal position in the environment:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e135" xlink:type="simple"/><label>(10)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e136" xlink:type="simple"/></inline-formula> is the current position of the animal, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e137" xlink:type="simple"/></inline-formula> is the position at which the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e138" xlink:type="simple"/></inline-formula> place cell gives the strongest response, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e139" xlink:type="simple"/></inline-formula> is the maximum firing rate of the place cell. Unless marked otherwise, we consider in our simulations 100 such neurons placed on a grid of 10×10 cells, with a distance of 10cm between two neighboring cells and with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e140" xlink:type="simple"/></inline-formula> being the width of each place field. The environment is a box of 100×100 cm. The ensemble activity of place cells encodes the position <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e141" xlink:type="simple"/></inline-formula> of the animal.</p>
</sec><sec id="s2b2">
<title>Action cells (AC)</title>
<p>Action cells are modeled as Leaky Integrate and Fire units <xref ref-type="bibr" rid="pcbi.1000586-Stein1">[62]</xref>, which are a special case of the Spike Response Model <xref ref-type="bibr" rid="pcbi.1000586-Gerstner2">[20]</xref>. The change of the membrane potential of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e142" xlink:type="simple"/></inline-formula> is given by<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e143" xlink:type="simple"/><label>(11)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e144" xlink:type="simple"/></inline-formula> the membrane time constant, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e145" xlink:type="simple"/></inline-formula> the resting potential, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e146" xlink:type="simple"/></inline-formula> is a stochastic variable that takes the value 1 with probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e147" xlink:type="simple"/></inline-formula> if the presynaptic place cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e148" xlink:type="simple"/></inline-formula> elicited a spike, and otherwise <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e149" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e150" xlink:type="simple"/></inline-formula> the synaptic strength of the lateral connections between neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e151" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e152" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e153" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e154" xlink:type="simple"/></inline-formula> the spikes of the presynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e155" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e156" xlink:type="simple"/></inline-formula> correspondingly, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e157" xlink:type="simple"/></inline-formula> the postsynaptic spikes before time t and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e158" xlink:type="simple"/></inline-formula> a small positive number. We note that the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e159" xlink:type="simple"/></inline-formula> in the second term on the right-hand side refers to place cell firing whereas <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e160" xlink:type="simple"/></inline-formula> in the fourth term refers to action cell firing. We assume that the postsynaptic current is a short pulse:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e161" xlink:type="simple"/><label>(12)</label></disp-formula>with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e162" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e163" xlink:type="simple"/></inline-formula> being the Dirac <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e164" xlink:type="simple"/></inline-formula> function. If neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e165" xlink:type="simple"/></inline-formula> emits a spike, its membrane potential is reset by an amount <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e166" xlink:type="simple"/></inline-formula>. We note that with these definitions, our model is equivalent to a standard leaky integrate-and-fire model with pulse input and also a general case of the spike response model defined in Eq. (6).</p>
<p>In order to account for intrinsic noise or synaptic noise generated by additional presynaptic neurons that are not part of the model, we use a stochastic firing threshold <xref ref-type="bibr" rid="pcbi.1000586-Gerstner2">[20]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Gerstner3">[63]</xref>, also known as escape noise. Action potentials of the postsynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e167" xlink:type="simple"/></inline-formula> are generated by a point process with stochastic intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e168" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e169" xlink:type="simple"/></inline-formula> is an exponential function of the membrane potential <xref ref-type="bibr" rid="pcbi.1000586-Gerstner2">[20]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Jolivet1">[64]</xref><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e170" xlink:type="simple"/><label>(13)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e171" xlink:type="simple"/></inline-formula>/ms is the stochastic intensity at threshold, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e172" xlink:type="simple"/></inline-formula> the formal firing threshold and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e173" xlink:type="simple"/></inline-formula> the width of the threshold region. We note that for the choice (13) the factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e174" xlink:type="simple"/></inline-formula> in the eligibility trace of Eq. (8) is a constant that can be absorbed in the learning rate. Unless stated otherwise, we use <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e175" xlink:type="simple"/></inline-formula> action cells for our simulations.</p>
</sec><sec id="s2b3">
<title>Lateral connections</title>
<p>The action neurons are connected in a ring with “Mexican hat”-type lateral connections. A weakly localized feedforward input to action cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e176" xlink:type="simple"/></inline-formula> is sufficient, to cause within 25–200ms the formation of an activity blob. The location of the activity blob represents the next action of the rat. Because of the broad activity profile, not only the one neuron that is maximally active, but also neighboring active neurons can be reinforced during learning. For the sake of simplicity, we keep in our model the lateral connections fixed (i.e. they do not undergo synaptic plasticity) and use the equation:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e177" xlink:type="simple"/><label>(14)</label></disp-formula>with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e178" xlink:type="simple"/></inline-formula> being the connection between neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e179" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e180" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e181" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e182" xlink:type="simple"/></inline-formula> their corresponding preferred directions (the difference taken modulo <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e183" xlink:type="simple"/></inline-formula>), <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e184" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e185" xlink:type="simple"/></inline-formula> (weak connections) or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e186" xlink:type="simple"/></inline-formula> (strong connections) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e187" xlink:type="simple"/></inline-formula>. Local connections, i.e. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e188" xlink:type="simple"/></inline-formula>, are excitatory with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e189" xlink:type="simple"/></inline-formula> while connections over a longer distance are inhibitory, Eq. (14) with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e190" xlink:type="simple"/></inline-formula>.</p>
<p>We have chosen parameters such that blob formation takes place already at the beginning of the learning procedure. The effect of the lateral connections is similar to a Winner-Take-All mechanism.</p>
</sec><sec id="s2b4">
<title>Decision making</title>
<p>At each location in the maze, the rat has to choose the direction of its next move. The decision is taken after a bump-like activity profile has been formed in the action layer. We suppose that the population of action cells is modulated by inhibitory background input in the theta-frequency range. If inhibition is strong, no activity profile is formed and neurons are inactive. While background inhibition drops to zero an activity profile develops, centered around the action neurons with strongest feedforward input - and these represent the action the rat is going to choose next.</p>
<p>In order to keep the model as simple as possible, we mimic the modulation of inhibition at theta-frequency algorithmically, by resetting every 200 milliseconds the activity of all action cells to zero. Otherwise, the dynamics is evolving freely according to the dynamical equations above. After 200 milliseconds, the rat takes its decision about the next action based on the population vector of the action cell firing rates. More specifically, the firing rate of action cells <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e191" xlink:type="simple"/></inline-formula> is estimated from a low-pass of the spiking activity<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e192" xlink:type="simple"/><label>(15)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e193" xlink:type="simple"/></inline-formula> is a time constant set at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e194" xlink:type="simple"/></inline-formula> (or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e195" xlink:type="simple"/></inline-formula>) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e196" xlink:type="simple"/></inline-formula> the entire postsynaptic train of the action cell defined as <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e197" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e198" xlink:type="simple"/></inline-formula> the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e199" xlink:type="simple"/></inline-formula> firing time of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e200" xlink:type="simple"/></inline-formula> action cell. The direction that the rat will follow is described by the angle <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e201" xlink:type="simple"/></inline-formula> in an allocentric coordinate system, i.e. relative to room coordinates and calculated from the population vector:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e202" xlink:type="simple"/><label>(16)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e203" xlink:type="simple"/></inline-formula> is the total number of action cells (typically 360 unless otherwise stated), and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e204" xlink:type="simple"/></inline-formula> the direction of the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e205" xlink:type="simple"/></inline-formula> action cell. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e206" xlink:type="simple"/></inline-formula> is calculated after a decision time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e207" xlink:type="simple"/></inline-formula>. In <xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3 C–E</xref>, T is the moment when the total activity of all action cells <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e208" xlink:type="simple"/></inline-formula>, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e209" xlink:type="simple"/></inline-formula>, which is achieved if, e.g. 10 cells fire at more than 20Hz, a good indicator of when a decision (an activity bump) is formed. For all other simulations, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e210" xlink:type="simple"/></inline-formula>, but in general any of these conditions are possible for each case.</p>
<fig id="pcbi-1000586-g003" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g003</object-id><label>Figure 3</label><caption>
<title>Learning performance for different variants of the learning rule.</title>
<p>A. Left: Evolution of escape latency as a function of trials, without lateral connections (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e211" xlink:type="simple"/></inline-formula>) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e212" xlink:type="simple"/></inline-formula>. Right: Navigation map after 20 trials visualized in the water maze by a set of direction vectors. At each grid point (defined by the center of a place cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e213" xlink:type="simple"/></inline-formula>) in the graph, we plot the normalized stochastic release probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e214" xlink:type="simple"/></inline-formula> for fixed <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e215" xlink:type="simple"/></inline-formula> in the form of a population vector denoting the direction the animal would most likely take at this location. The red circle marks the position of the hidden platform. The navigation map is less smooth than with the standard choice of parameters of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e216" xlink:type="simple"/></inline-formula>ms or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e217" xlink:type="simple"/></inline-formula>, see D and E, Right. B. As in A with weak lateral connections, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e218" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e219" xlink:type="simple"/></inline-formula>. C. As in A with strong lateral connections, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e220" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e221" xlink:type="simple"/></inline-formula>. D. As in A with strong lateral connections, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e222" xlink:type="simple"/></inline-formula>ms and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e223" xlink:type="simple"/></inline-formula>. E. As in A with strong lateral connections, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e224" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e225" xlink:type="simple"/></inline-formula>. Initial release probabilities are set to 0.2; all other parameters as in Model architecture, <xref ref-type="sec" rid="s4">Methods</xref> and <xref ref-type="table" rid="pcbi-1000586-t001">Tables 1</xref>, <xref ref-type="table" rid="pcbi-1000586-t002">2</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g003" xlink:type="simple"/></fig></sec></sec><sec id="s2c">
<title>Watermaze performance</title>
<p>We perform simulations of a model rat navigating in a square maze of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e226" xlink:type="simple"/></inline-formula>, with a constant speed of 20cm/s. The rat performs a number of trials, with each trial consisting of an attempt to find the goal within a time limit of 90 seconds. At the beginning of each trial, the rat is placed near one of the walls of the maze. Actions are chosen at theta frequency (every 200ms). Between two action choices, the simulated rat moves by about 4cm. The rewarded position (target) is at a random position near the central region of the maze and remains fixed at the same position within a set of trials whereas the initial position of the rat varies, as in the experimental paradigm <xref ref-type="bibr" rid="pcbi.1000586-Morris1">[51]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Morris2">[65]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Morris3">[66]</xref>. Positive reward <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e227" xlink:type="simple"/></inline-formula> is only given if the rat reaches its target and negative reward <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e228" xlink:type="simple"/></inline-formula> if it hits the wall. Thus, synaptic modifications take place either at the time the rat reaches the platform, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e229" xlink:type="simple"/></inline-formula>, or at the time the rat hits a wall, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e230" xlink:type="simple"/></inline-formula>. For an overview of the algorithm see <xref ref-type="fig" rid="pcbi-1000586-g004">Figure 4</xref>.</p>
<fig id="pcbi-1000586-g004" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g004</object-id><label>Figure 4</label><caption>
<title>Learning algorithm.</title>
<p>The decision time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e231" xlink:type="simple"/></inline-formula> can be either 200ms, as in most cases, or can be based on a flexible criterion (<xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3 C–E</xref>), see <xref ref-type="sec" rid="s2">Results</xref>.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g004" xlink:type="simple"/></fig>
<p>When a new <italic>set of trials</italic> starts, the positions of both the rat and the goal are reinitialized as well as the synaptic release of all plastic synapses in the model. Thus each new <italic>set of trials</italic> corresponds to a different animal.</p>
<sec id="s2c1">
<title>Speed of learning</title>
<p>The performance of the rat is measured by the time it takes to reach the target, corresponding to the escape latency in the experimental literature <xref ref-type="bibr" rid="pcbi.1000586-Morris1">[51]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Morris2">[65]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Morris3">[66]</xref>. In the panels of <xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3 A–E</xref> we plot the escape latency versus trials for three values of the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e232" xlink:type="simple"/></inline-formula> and three conditions of the mexican hat connections, zero (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e233" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e234" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e235" xlink:type="simple"/></inline-formula>), weak (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e236" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e237" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e238" xlink:type="simple"/></inline-formula>) and strong (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e239" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e240" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e241" xlink:type="simple"/></inline-formula>). For zero or weak lateral connections learning takes place within 20 trials with any value of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e242" xlink:type="simple"/></inline-formula> (<xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3 A,B</xref>). The performance is similar to that seen in experimental data <xref ref-type="bibr" rid="pcbi.1000586-Morris1">[51]</xref> and previous models <xref ref-type="bibr" rid="pcbi.1000586-Foster1">[52]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Sheynikhovich1">[55]</xref>. The standard deviation of the performance extracted from 10 repetitions of the learning experiment decreases while the task is learned.</p>
<p>Surprisingly, for lateral connections strong enough to form an an activity bump in the action cell layer, only the versions of the rule with a dominant Hebbian component (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e243" xlink:type="simple"/></inline-formula> are able to learn the task (<xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3 D,E</xref>), but not the standard policy gradient rule for spiking neurons (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e244" xlink:type="simple"/></inline-formula>, <xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3 C</xref>). We believe that the critical parameter for a good performance of the policy gradient rule is neither the lateral connectivity nor the total input. Rather, it is a subtle interplay between the rule for the action choice (here: population vector based on firing rates) and the information encoded in the eligibility trace (see <xref ref-type="sec" rid="s3">Discussion</xref> for more details).</p>
<p>In our model, actions depend on the population vector of the Action Cells calculated from the spike count about 200ms from each cell. Action cells, that have emitted most spikes, are most likely to dominate the action choice at a given place. Therefore, a standard Hebbian learning rule, that increases weights when pre- and postsynaptic neurons are jointly active, will set an eligibilty trace that is strongest for the action neurons that have most likely determined the action at this location. If that action led to a reward, those weights would be strengthened. Thus, it is not surprising that the model with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e245" xlink:type="simple"/></inline-formula> does work. What would be the situation for the standard policy gradient rule with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e246" xlink:type="simple"/></inline-formula>? As long as the expected number of spikes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e247" xlink:type="simple"/></inline-formula> within the decision period of duration <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e248" xlink:type="simple"/></inline-formula> is smaller than one, the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e249" xlink:type="simple"/></inline-formula> in the eligibility trace is positive for all neurons that have fired a spike – and these are exactly the neurons that determine the next action via the population vector. However, if the firing rates are higher, such a match between the memory kept in the eligibility trace and the chosen action is not guaranteed for in <italic>single</italic> trials of the standard policy gradient rule (see <xref ref-type="sec" rid="s3">Discussion</xref> for more details). We report that the average instantaneous firing rate for the network without lateral connections, calculated as an average value among all action cells between the 20th and the 30th trial, is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e250" xlink:type="simple"/></inline-formula> Spikes/ms. For the same network but with weak lateral connections is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e251" xlink:type="simple"/></inline-formula> Spikes/ms (three times more) and with strong lateral connections an order of magnitude higher, i.e. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e252" xlink:type="simple"/></inline-formula> Spikes/ms. More importantly, the neurons inside the activity bump fire in <xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3 C–D</xref> at a rate of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e253" xlink:type="simple"/></inline-formula> Hz yielding <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e254" xlink:type="simple"/></inline-formula> spikes, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e255" xlink:type="simple"/></inline-formula>. Thus, the eligibility trace of the most active synapses accumulates about 16 spikes of the postsynaptic neuron.</p>
<p>For the case of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e256" xlink:type="simple"/></inline-formula> we compared the situation without baseline subtraction <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e257" xlink:type="simple"/></inline-formula> and with a baseline subtraction <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e258" xlink:type="simple"/></inline-formula>, and the results are similar (data not shown). However, if we follow learning for more than 100 trials, the factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e259" xlink:type="simple"/></inline-formula> increases long-term stability, as expected.</p>
</sec><sec id="s2c2">
<title>Navigation map</title>
<p>Given the rat's location, the direction of the next move is decided by the population vector of the action cells. Suppose that the rat is in the center of the place field of cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e260" xlink:type="simple"/></inline-formula>. Then the population activity of the action cells is, to a large degree, controlled by the strength of the synapses connecting place cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e261" xlink:type="simple"/></inline-formula> to the different action cells: the stronger the synaptic weight <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e262" xlink:type="simple"/></inline-formula> to an action cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e263" xlink:type="simple"/></inline-formula>, the more likely that the action represented by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e264" xlink:type="simple"/></inline-formula> would be chosen. We therefore use the population vector of the synaptic strength of the feedforward connections from a given place cell to visualize the direction of motion starting at that location. The combination of vectors gives a flow map, corresponding to the navigation map of the rat. In <xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3 A–E</xref> right hand side we show the navigation map after the 20th trial for different <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e265" xlink:type="simple"/></inline-formula> values and lateral connections. It is noteworthy that the quality of the navigation map is increased under the presence of strong connections (and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e266" xlink:type="simple"/></inline-formula>). <xref ref-type="fig" rid="pcbi-1000586-g005">Figure 5</xref> shows the evolution of the navigation map of the rat for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e267" xlink:type="simple"/></inline-formula> after 1, 10 and 50 and 100, with A–C depicting preferred directions as normalized vectors and D–F as non-normalized vectors. A–C show that already within 10 trials the simulated animal has developed a strategy for reaching the goal, and D–F show the relative strength of the population activity, which increases as the animal moves closer to the target. Adequate learning has been achieved, if for any starting condition the flow is towards the target zone. We find that already after 10 trials, a rough strategy for the Morris watermaze task has been developed, which is refined during subsequent trials. <xref ref-type="fig" rid="pcbi-1000586-g006">Figure 6</xref> confirms that trajectories become smoother during learning. A sequence of 3 action choices has a strong random component at the beginning but is nearly continuous after 100 trials.</p>
<fig id="pcbi-1000586-g005" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g005</object-id><label>Figure 5</label><caption>
<title>Navigation map of the rat visualized in the water maze by a set of direction vectors, for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e268" xlink:type="simple"/></inline-formula>.</title>
<p>Panel A depicts the map formation after 1 trial, B after 10 trials and C after 50 trials. The simulated animal has developed a rough strategy to reach its goal already within 10 trials. For details on how the navigation map is calculated, see <xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3</xref>. Learning rate decays as a function of mean reward. Preferred directions are plotted as normalized vectors. In D–F we plot the same navigation maps with non normalized vectors. While F seems to contain no information about preferred directions near the wall (due to scaling of arrows), the normalized version C confirms that the simulated animal has developed a strategy for all positions in the maze.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g005" xlink:type="simple"/></fig><fig id="pcbi-1000586-g006" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g006</object-id><label>Figure 6</label><caption>
<title>Sequential formation of actions.</title>
<p>Spiking activity (dots) of the population of action cells as a function of time during three theta-cycles. A: Before learning, the moves of the simulated animal reflect random exploration of the space leading to a B: discontinuous trajectory. C: After learning, the three consecutive actions exhibit similar direction choices leading to D: a continuous movement.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g006" xlink:type="simple"/></fig></sec><sec id="s2c3">
<title>Performance vs number of place and action cells</title>
<p>How does the performance depend on the number of place and action cells? For place cells, we require that the surface of the water maze will be sufficiently covered by neurons with overlapping receptive fields. This continuous space representation (due to overlapping receptive fields) leads to simultaneous learning of nearby neurons, resulting in no significant change in performance even when doubling the number of neurons in each dimension, see <xref ref-type="fig" rid="pcbi-1000586-g007">Figure 7</xref> left. Similarly, a minimum number of action cells is required such that the activity profile will be created, but increasing the number of cells beyond 300 cells or so does not change the performance. The reason is that the activity profile has always roughly the same width (about 30 degrees) in action space. Adding more cells just increases the number of cells in the activity bump. In <xref ref-type="fig" rid="pcbi-1000586-g007">Figure 7</xref> right we plot the average time it takes the rat to reach the hidden platform at the 5th, 25th and 50th trial versus number of action cells. We note that the performance does not significantly change. This is in contrast to standard reinforcement learning in discrete state and action spaces where increasing the number of states or actions increases the number of free parameters, so that learning becomes slower <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref>.</p>
<fig id="pcbi-1000586-g007" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g007</object-id><label>Figure 7</label><caption>
<title>Scaling properties of the network.</title>
<p>A: Average time it takes the rat to reach the hidden platform at the 5th, 25th and 50th trial versus number of place cells. B: Average time it takes the rat to reach the hidden platform at the 5th, 25th and 50th trial versus number of action cells. Error bars show standard error for the mean. Note the improvement as the number of place cells is increased. This is due to the systematic formation of an activity bump in the presence of stronger input. The same parameters were used in producing all sets of these simulations: <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e269" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e270" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e271" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e272" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e273" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e274" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e275" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e276" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e277" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e278" xlink:type="simple"/></inline-formula>, see also <xref ref-type="sec" rid="s2">Results</xref>. For B, place cells are located every 5cm, with a gaussian receptive field of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e279" xlink:type="simple"/></inline-formula>, and maximum firing rate 120Hz. To reduce CPU time, for this set of simulations we do not implement the stochastic release.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g007" xlink:type="simple"/></fig></sec></sec></sec><sec id="s3">
<title>Discussion</title>
<p>We presented a spike-based reinforcement rule which combines a global reward signal with two local factors available at the site of the synapse. The first local component is a contribution generated by presynaptic spike arrival and enters the update rule in the form of the EPSP. The second local component depends positively on postsynaptic spike firing and negatively on the postsynaptic membrane potential. The relevance of the membrane potential decreases with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e280" xlink:type="simple"/></inline-formula> and vanishes for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e281" xlink:type="simple"/></inline-formula>. The third factor of the learning rule is the global reward signal that can be associated with neuromodulators such as dopamine <xref ref-type="bibr" rid="pcbi.1000586-Schultz1">[22]</xref>. Thus the eligibility trace which combines the two local factors marks the synapse that can undergo LTP or LTD. The actual weight change is implemented only after confirmation by a global reward signal that may arise with a significant delay. Such a picture has interesting relations to the model of synaptic tagging and capture <xref ref-type="bibr" rid="pcbi.1000586-Frey1">[27]</xref> where synaptic connections undergo preliminary changes into early LTP or LTD that decay unless they are stabilized if plasticity related protein is available. Synthesis of these plasticity related protein can occur with a delay and requires neuromodulators such as dopamine <xref ref-type="bibr" rid="pcbi.1000586-Reymann1">[28]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Clopath1">[61]</xref>.</p>
<sec id="s3a">
<title>Global factors, neuromodulators, and TD-learning</title>
<p>In the introduction we mentioned two classes of theoretical reinforcement learning algorithms, that is, temporal difference (TD) learning methods on one side <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Watkins1">[43]</xref> and policy gradient methods on the other side <xref ref-type="bibr" rid="pcbi.1000586-Williams1">[39]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Baxter1">[40]</xref>. Our model task and model architecture would allow to test both types of algorithm in the form of a three-factor rule (see <xref ref-type="bibr" rid="pcbi.1000586-DiCastro1">[45]</xref>, <xref ref-type="bibr" rid="pcbi.1000586-Foster1">[52]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Stroesslin1">[54]</xref> for examples of a TD algorithm for this task). One major difference between the TD algorithms and the algorithm in this paper lies in how the global factor encodes neuromodulatory feedback about the reward. In the case of TD-learning, the global factor expresses the difference between the reward received and the expected reward (where the expected reward is calculated from the temporal difference between reward expectations of subsequent states <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref>), whereas in the case of the gradient learning algorithm of this paper the global factor correspond to reward itself, possibly after subtraction of a baseline. Here we used a variant of the idea of a baseline, since we subtracted the mean reward averaged over order <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e282" xlink:type="simple"/></inline-formula> previous trials, see also <xref ref-type="bibr" rid="pcbi.1000586-Farries1">[41]</xref>. Subtracting the expected reward should help rapid re-learning in case of the change of the learning task (e.g., by moving the escape platform to a different location) <xref ref-type="bibr" rid="pcbi.1000586-Vasilaki1">[67]</xref>. Similar to TD learning the global factor can be interpreted in this case as reward minus expected reward. In contrast to TD learning, the expected reward arises from a running average, rather than a difference in reward expectation across different states as in spike-based TD algorithms <xref ref-type="bibr" rid="pcbi.1000586-Potjans1">[37]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-DiCastro1">[45]</xref>. Experiments on dopaminergic neurons suggest that the phasic dopamine signal indeed encodes a TD-like error signal <xref ref-type="bibr" rid="pcbi.1000586-Schultz1">[22]</xref> although other interpretations of the dopamine signal <xref ref-type="bibr" rid="pcbi.1000586-Redgrave1">[68]</xref> and the involvement of other neuromodulators is also possible <xref ref-type="bibr" rid="pcbi.1000586-Doya1">[69]</xref>.</p>
<p>Our spike-based navigation model features a continuous description of state and action. Unlike traditional TD models with discrete state and action space, increasing the number of neurons while keeping the width of place fields and the width of lateral interactions between action cells constant) does not change the performance of our model. In addition, the model provides insight in studying decision making in the context of navigation. We hypothesized that activity is modulated at theta frequency. Note that we implemented an extreme situation where the action choice is taken at the end of each theta cycle. However, it is easily possible to have the rat take an action as soon as the activity profile is formed. The time necessary to create an activity profile determines then a minimal time for deciding a new action. If this is so, then our model predicts that the time it takes to choose the next action is much faster after learning than before learning, because activity profiles are more rapidly formed with strong feedforward input - as it would occur after learning.</p>
</sec><sec id="s3b">
<title>Morris water maze task</title>
<p>To test the potential of our spike-based reinforcement rule, we have applied it to a biologically relevant navigation problem, i.e., the Morris water maze task with variable start condition <xref ref-type="bibr" rid="pcbi.1000586-Morris1">[51]</xref>. Our model which is based on a simplified model of place cells and action cells reproduces behavioral data of real rats in terms of escape latency versus learning time. The model consists of about 700 spiking neurons, in two layers and includes both feedforward and lateral connections. In the first trial, the model rat moves in a random trajectory and finds the hidden platform by exploration. Across several trials, approach paths towards the platform are reinforced, so that the escape latency is reduced.</p>
<p>A positive reward is delivered when the model rat reaches the target location. In the model, we also use negative reward at the boundaries of the maze so that the simulated rat will learn to avoid the walls. This aspect does not reflect the fact that, normally, during development (or even because of reflexes present at birth) we could assume that the rat already knows how to avoid obstacles prior to the start of the watermaze task. However, since we did not want to include into the model prior knowledge about obstacle avoidance, we let the simulated rat ‘discover’ the effect of the walls. Since our model assumes the existence of place cells, we must assume, however, that the rat has had some pre-exposure to the environment long enough to establish place fields. Experiments have shown that place fields are established during a first exploration of the environment, so that during the learning task, they can be considered as given. Moreover, typical experiments require prior habituation of the animal to the environment, so that place cells may be formed. A model where place cells are learned from visual input and path integration is also possible <xref ref-type="bibr" rid="pcbi.1000586-Arleo1">[53]</xref>.</p>
<p>While in our model place cells can be easily linked to cells in hippocampus, a direct identification of the action cells with the biological substrate is more problematic. In rodents, navigation in water maze task involves two competing pathways <xref ref-type="bibr" rid="pcbi.1000586-Devan1">[70]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-White1">[72]</xref>. The first one is involved in taxon navigation (e.g., approaching a visible target, which could be achieved with stimulus-response habits <xref ref-type="bibr" rid="pcbi.1000586-Hull1">[73]</xref> also called response learning <xref ref-type="bibr" rid="pcbi.1000586-Packard1">[71]</xref>) and associates visual input directly with motor actions. It is independent of hippocampus and the action choice for this navigation strategy can presumably be linked to the the dorsal striatum of the basal ganglia (caudate-putamen in the rat). The second one is concerned with locale navigation (also called place learning <xref ref-type="bibr" rid="pcbi.1000586-Packard1">[71]</xref> or cognitive map <xref ref-type="bibr" rid="pcbi.1000586-Toleman1">[74]</xref>) and this is the relevant pathway in the context of the present model. It relies on hippocampus <xref ref-type="bibr" rid="pcbi.1000586-Morris1">[51]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Devan1">[70]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Packard1">[71]</xref> where the activity of place cells presumably encodes the location of simulated animal. The choice of motor actions is presumably encoded in the nucleus accumbens (NA) of the ventral striatum where our hypothetical action cells could be located. The Mexican hat connectivity between action cells is a simplification of a more complex wiring scheme, where excitatory neurons project to inhibitory neurons, which in turn inhibit other action cells that encode for “different” directions, see for example a biologically plausible winner-take-all <xref ref-type="bibr" rid="pcbi.1000586-Wang1">[75]</xref>. However, to reduce the connectivity in our network, we chose to simulate the equivalent but simpler Mexican hat scheme.</p>
<p>One limitation of the model is that learning only takes place in the presence of a reward signal with the consequence that learning can only occur in a limited radius around a reward. The radius is related to the time scale of the eligibility trace, governed by the time scale <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e283" xlink:type="simple"/></inline-formula>. In a large environment where at a fixed speed <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e284" xlink:type="simple"/></inline-formula> it takes much longer than <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e285" xlink:type="simple"/></inline-formula> to traverse the environment, information about the target falls off exponentially with a spatial scale <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e286" xlink:type="simple"/></inline-formula>. In our case we would encounter this limit only if the environment were scaled by a factor significantly larger than two.</p>
<p>In a TD framework, the situation would be different: even without an eligibility trace, information about the presence of the reward can slowly diffuse across the landscape of estimated reward expectation values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e287" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e288" xlink:type="simple"/></inline-formula> is the position, even beyond the radius <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e289" xlink:type="simple"/></inline-formula> discussed above. This slow diffusion of reward information is possible because the update is not proportional to the reward itself, but to a factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e290" xlink:type="simple"/></inline-formula> where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e291" xlink:type="simple"/></inline-formula> gives the difference between the reward estimation at location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e292" xlink:type="simple"/></inline-formula> and that of the previous location <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e293" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e294" xlink:type="simple"/></inline-formula> is the discount factor. An implementation of a TD learning structure in spiking neurons is possible using the actor-critic scheme <xref ref-type="bibr" rid="pcbi.1000586-Potjans1">[37]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-DiCastro1">[45]</xref>. If a TD algorithm is implemented in discrete time with time steps <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e295" xlink:type="simple"/></inline-formula>, and if the rat runs as before at a constant speed <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e296" xlink:type="simple"/></inline-formula>, the distance travelled between two time steps is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e297" xlink:type="simple"/></inline-formula>. After convergence, the value function decreases exponentially with the distance from the target on a lenght scale <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e298" xlink:type="simple"/></inline-formula>. (In other words, once the exponentially decaying <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e299" xlink:type="simple"/></inline-formula> dependence is reached, the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e300" xlink:type="simple"/></inline-formula> in the update rule vanishes). A comparison with the result in the previous paragraph shows that the time scale <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e301" xlink:type="simple"/></inline-formula> of the eligibility trace in our model plays a role similar to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e302" xlink:type="simple"/></inline-formula> in the TD model. The role of the eligibility trace has been extensively discussed in <xref ref-type="bibr" rid="pcbi.1000586-Izhikevich1">[35]</xref>; in our interpretation the eligibility trace is implemented in the synapse and its time constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e303" xlink:type="simple"/></inline-formula> corresponds to the decay time of some biochemical substance.</p>
<p>The parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e304" xlink:type="simple"/></inline-formula> is an ad-hoc parameter that allows us to vary the behavior of the learning rule from pure Hebbian to optimal in the sense of policy gradient theory. We do not wish to explicitly associate it with a biological substrate, but in our model it would be closely related to the voltage dependence of LTD.</p>
<p>Recently, the influence of neuromodulators on spike-timing dependent synaptic plasticity has been investigated in a small number of studies <xref ref-type="bibr" rid="pcbi.1000586-Pawlak1">[31]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Zhang1">[76]</xref>. These studies show that dopamine acts on the temporal profile of STDP, rather than a simple scaling of STDP. This result is in contrast to some of the assumptions of standard reward-modulated STDP <xref ref-type="bibr" rid="pcbi.1000586-Izhikevich1">[35]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Legenstein1">[36]</xref>, but also in disagreement with policy gradient rules <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Baras1">[38]</xref> and the learning rule discussed in this paper. For plasticity in the cortico-striatal synapse <xref ref-type="bibr" rid="pcbi.1000586-Pawlak1">[31]</xref>, but not for glutamatergic synapses in hippocampal neurons <xref ref-type="bibr" rid="pcbi.1000586-Zhang1">[76]</xref>, dopamine is necessary for synaptic plasticity. In other words, learning is gated by the presence of dopamine. The plasticity rule in the cortico-striatal synapse is in that respect similar to the reward-gated plasticity rules in the present paper. Interestingly, the striatum is potentially involved in action selection.</p>
<p>It should be noted that in standard cortical STDP experiments <xref ref-type="bibr" rid="pcbi.1000586-Markram1">[77]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Sjstrm1">[78]</xref> the level of dopamine and other neuromodulators is not explicitly controlled and a background level of dopamine cannot be excluded. Therefore, it is unclear whether cortical STDP is unsupervised or shows a, possibly weak, dependence upon neuromodulators.</p>
</sec><sec id="s3c">
<title>Limitations of policy gradient methods</title>
<p>An important parameter in our family of learning rules is the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e305" xlink:type="simple"/></inline-formula>, that tunes the learning rate such that for neurons that fire at high learning rates LTD is reduced. To see this, consider an instantaneous firing rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e306" xlink:type="simple"/></inline-formula>. Then the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e307" xlink:type="simple"/></inline-formula> converges to <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e308" xlink:type="simple"/></inline-formula>. Hence, the decrease of the eligibility trace in the absence of spikes is limited. Note that because of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e309" xlink:type="simple"/></inline-formula> high rates correspond to large depolarizations of the membrane potential. For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e310" xlink:type="simple"/></inline-formula>, the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e311" xlink:type="simple"/></inline-formula> vanishes, and the membrane potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e312" xlink:type="simple"/></inline-formula> no longer enters the update of the eligibility trace. In this case the eligibility trace pick up Hebbian correlations <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e313" xlink:type="simple"/></inline-formula> between EPSPs caused by presynaptic spike arrival and postsynpatic firing.</p>
<p>The case <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e314" xlink:type="simple"/></inline-formula> corresponds to the learning rule derived from the reward maximization as shown in the methods section, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e315" xlink:type="simple"/></inline-formula>. For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e316" xlink:type="simple"/></inline-formula> the two postsynaptic terms, i.e., spike firing and voltage dependence cancel each other <italic>on average</italic>, because spikes are generated with the stochastic intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e317" xlink:type="simple"/></inline-formula>, hence <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e318" xlink:type="simple"/></inline-formula> where angular brackets denote expectation values. However, a specific realisation of a spike train (e.g., one with more spikes than expected) may lead to a reward whereas another one (with less spikes than expected) does not. In this case only the rewarded one is learned, making it more likely that the same spike train is reproduced again for the same input <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>. In fact, a large class of learning rules for conditioning can be explained as a reinforcement of the covariance between reward and a noise-induced variation of the output <xref ref-type="bibr" rid="pcbi.1000586-Loewenstein1">[79]</xref>.</p>
<p>There are three reasons why the standard policy gradient rule with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e319" xlink:type="simple"/></inline-formula> derived from reward maximization is not applicable in our scenario.</p>
<p>(i) Large learning rate. The learning rule derived from reward optimization is a batch rule, i.e., it assumes averaging across several realisations and many inputs. For the transition to the online rule we had to assume a very small learning rate so as to make the learning self-averaging. If learning is slow, then thousands of trials are needed before the weights change significantly, so that online and batch have nearly the same effect.</p>
<p>In order to explain biological learning paradigms, we need, however, to achieve learning after as few as ten trials. If we work with a large learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e320" xlink:type="simple"/></inline-formula>, then terms of the form <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e321" xlink:type="simple"/></inline-formula> that average away in the batch rule, can make a big contribution in the eligibility trace of each single trial and can cause weight changes that are not causally linked to the reward. Thus the eligibility trace encodes noise, rather than relevant correlations. With small learning rate, these correlations would average away (and only those systematically linked to the reward would survive), but with a big learning rate these changes act like a diffusion process. Moreover, the effect of the diffusion increases with the number of spikes in the decision window and therefore is highest for neurons having a large firing rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e322" xlink:type="simple"/></inline-formula>. Large firing rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e323" xlink:type="simple"/></inline-formula> appear in particular after learning for neurons inside the activity bump, because strong lateral input is added to strong feedforward input. Hence the eligibility trace is most noisy in the center of the bump, as shown in <xref ref-type="fig" rid="pcbi-1000586-g008">Figure 8 B</xref>.</p>
<fig id="pcbi-1000586-g008" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g008</object-id><label>Figure 8</label><caption>
<title>Action cell activity and eligibility trace.</title>
<p>A: Snapshot of mean firing rate of action cells during one of the trials while the simulated rat is in the center of the place field of cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e324" xlink:type="simple"/></inline-formula>. The chosen action is a movement in direction <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e325" xlink:type="simple"/></inline-formula>. B and C. At this instance, the momentary value of the eligibility <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e326" xlink:type="simple"/></inline-formula> is plotted as a function of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e327" xlink:type="simple"/></inline-formula> for fixed <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e328" xlink:type="simple"/></inline-formula> (fixed presynaptic location). B: For the rule with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e329" xlink:type="simple"/></inline-formula> the profile of eligibility traces is stochastic with zero mean and maximum variance inside the activity bump. C: For <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e330" xlink:type="simple"/></inline-formula> the profile of eligibility traces reflects the activity profile shown in A.</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g008" xlink:type="simple"/></fig>
<p>(ii) Decision by firing rates, not by spikes. The close relation between reward-maximisation by policy gradient rules and supervised learning shows that the spike-based rule with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e331" xlink:type="simple"/></inline-formula> is optimal to learn a specific spatio-temporal spike pattern <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>. However, what counts for the action choice in our simulations is the firing rate accumulated over 200ms. To understand the importance of this distinction let us consider two Poisson neurons coding for actions ‘left’ and ‘right’, respectively. The action ‘right’ is the rewarded one. Suppose the neurons receive inputs that drives the neurons coding for ‘left’ at an intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e332" xlink:type="simple"/></inline-formula> and the other at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e333" xlink:type="simple"/></inline-formula>. Suppose, because of intrinsic noise, the neuron coding for ‘left’ fires 2 spikes in a decision interval of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e334" xlink:type="simple"/></inline-formula>, while the neuron coding for ‘right’ fires 9 spikes in the same time interval. If actions are chosen according to maximal firing rates, the neuron coding for right wins, the system performs the ‘right’ action and receives reward. However, the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e335" xlink:type="simple"/></inline-formula> is negative for the neuron coding for ‘right’ and ‘positive’ for the neuron coding for ‘left’. Hence, after reward is received action ‘right’ is weakened, while action ‘left’ is reinforced, in contradiction to the fact that action ‘right’ is the correct one that should be reinforced. To put it differently, action neurons have to learn that (a) precise spike timing is irrelevant and that (b) even the absolute rates are irrelevant because all that matters is the firing rate relative to those of the other neurons. Since the policy gradient rule is desigend to learn precise spatio-temporal spike patterns, it is not ideally suited for our paradigm. In contrast, reward-modulated Hebbian learning just make the neurons that fired at high rate (and influenced the action) fire at even higher rates. In the specific task we are considering this happens to be a viable strategy.</p>
<p>(iii) Populations of neurons, not single neurons. Furthermore, because of the formation of an activity bump and the readout by a population vector the decision about actions is taken by a <italic>population</italic> of neurons rather than individual neurons. Learning in populations suffers from the problem that firing of individual neurons may differ from the majority vote that led to the actions, so that giving appropriate feedback is nontrivial <xref ref-type="bibr" rid="pcbi.1000586-Urbanczik1">[80]</xref>.</p>
<p><xref ref-type="fig" rid="pcbi-1000586-g008">Figure 8</xref> illustrates the detrimental interaction of points (i)–(iii) for the standard policy gradient rule. We focus on a presynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e336" xlink:type="simple"/></inline-formula> which codes for the current location of the rat so that synapses from <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e337" xlink:type="simple"/></inline-formula> to all action neurons <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e338" xlink:type="simple"/></inline-formula> are active. The instantaneous firing rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e339" xlink:type="simple"/></inline-formula> represents the activity bump (<xref ref-type="fig" rid="pcbi-1000586-g008">Figure 8 A</xref>). Despite the fact that the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e340" xlink:type="simple"/></inline-formula> has an expectation value of zero, the term <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e341" xlink:type="simple"/></inline-formula> gives a non-neglibible contribution in each trial, see also <xref ref-type="fig" rid="pcbi-1000586-g001">Figure 1 C</xref> – as it should be since policy gradient rules need to exploit fluctuations. However, we would like to emphasize two aspects. First, the standard deviation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e342" xlink:type="simple"/></inline-formula> grows with time, similar to a diffusion process. Second the diffusion constant increases with the instantaneous rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e343" xlink:type="simple"/></inline-formula>. Therefore the deviation from the expected value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e344" xlink:type="simple"/></inline-formula> increases with the expected number of spikes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e345" xlink:type="simple"/></inline-formula> the neuron emits during the decision interval of length <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e346" xlink:type="simple"/></inline-formula>. The eligibility trace is sensitive to this deviation. In the case of our action learning model, the consequence of the above argument is that the set of significantly positive eligibility traces <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e347" xlink:type="simple"/></inline-formula> for fixed presynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e348" xlink:type="simple"/></inline-formula> includes not just action neurons within the activity bump, but also those representing other directions; see <xref ref-type="fig" rid="pcbi-1000586-g008">Figure 8 B</xref>. Moreover, the variation of eligibility traces between neighboring neurons inside the activity bump is big, because the expected number of spikes is higher for neurons inside the activity bump. In particular, several synapses from a fixed presynaptic neuron onto neurons in the bump have eligibility traces that are significantly negative (corresponding to the fact that some neurons in the bump fire less spikes than expected from the firing rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e349" xlink:type="simple"/></inline-formula>, see point (ii) above). This leads to the problem that eligibility traces of individual neurons do not reflect the action choice represented by the population of active neurons <xref ref-type="bibr" rid="pcbi.1000586-Urbanczik1">[80]</xref>. Simply speaking, neurons inside the bump are those that determine the action even though their eligibity trace can be negative.</p>
<p>The parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e350" xlink:type="simple"/></inline-formula> in our learning rule gives a systematic positive bias of the postsynaptic term for those postsynaptic neurons that have a large firing rate. Thus the eligibity trace is maximal for neurons within the bump of activity, i.e. for those representing the action that is actually chosen; see <xref ref-type="fig" rid="pcbi-1000586-g008">Figure 8C</xref>. Hence, if the sequence of actions leads to a reward later on, the synpatic weights between those presynaptic place cells and postsynaptic action cells that actually led to the sequence of actions are maximally strengthened. Because of the bounds on the weight dynamics, these weights will eventually converge towards a release probability of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e351" xlink:type="simple"/></inline-formula>. We note that all neurons outside that activity bump have very low activity, so that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e352" xlink:type="simple"/></inline-formula> has a zero average and only small fluctuations. Hence, a learning rule with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e353" xlink:type="simple"/></inline-formula> is expected to work better in the case of large learning rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e354" xlink:type="simple"/></inline-formula>, and high firing rates <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e355" xlink:type="simple"/></inline-formula>, and a decision criterion based on a population vector calculated over a long time period.</p>
<p>In a general spike-based learning problem where the aim is to learn a spatio-temporal spike pattern, the high variability of eligibility traces would allow to explore a large space of firing patterns. However, in our case with lateral interactions and decisions based not on detailed firing patterns, but only on population vector data integated over 200ms, the bias towards high activities identifies neurons in the bump that participate in the action choice.</p>
<p>Indeed, a learning rule with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e356" xlink:type="simple"/></inline-formula> does work in the situation where (a) there are no lateral interactions between the action cells or (b) decisions are based on less than one spike per neuron on average. In the latter case, every spike is unexpected, and basing a decision on the population vector chooses an action that is indeed caused by a fluctuation.</p>
<p>In principle four action neurons would be sufficient to encode the direction of the next action (e.g., <xref ref-type="bibr" rid="pcbi.1000586-DiCastro1">[45]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Arleo1">[53]</xref>). In this case, learning rules based on either policy gradient <xref ref-type="bibr" rid="pcbi.1000586-DiCastro1">[45]</xref> or naive Hebb <xref ref-type="bibr" rid="pcbi.1000586-Arleo1">[53]</xref> work. However, it is likely that in biological brains actions are encoded by large populations of neurons. In order to achieve fast learning despite a large population of action neurons, action neurons must share information during learning – and this can be achieved by the formation of activity bumps. The results of this paper show that in the presence of activity bumps and population vector read-out based on spike counts, the spike based policy gradient rule no longer works, whereas a rule with a bias towards Hebbian correlation does.</p>
<p>From a technical point of view, neither stochastic synapses nor voltage dependent plasticity is critical for the function of the model, however they are both desirable properties for the biophysical plausibility of the rule. In our model, the stochastic release probability of the synapses is hard-bounded in order to maintain reasonable values, for a biophysical implementation of such bounds see <xref ref-type="bibr" rid="pcbi.1000586-Seung1">[46]</xref>.</p>
<p>Also a reset it is not necessary to take place exactly every 200msec; in principle may occur at any point that the activity bump is formed. We require to reset the activity in the action neurons layer only (or equivalently we could clamp the AC activity for say 10ms) so that the activity profile will not become “sticky”, but in no other way the learning would be affected. Without reset, the rat will end up again learning the position of the platform, but its movements will become more curved. A negative input would be desirable after a decision is formed so that at the beginning of the learning the next action will not depend on the previous one. This negative input may arrive at any point after a decision (activity bump) has been formed. We chose 200ms so that this could coincide with the theta rhythms, but it could have been 150ms or 300ms, or a random interval (as we demonstrate in simulations).</p>
</sec></sec><sec id="s4" sec-type="methods">
<title>Methods</title>
<p>Policy gradient methods <xref ref-type="bibr" rid="pcbi.1000586-Williams1">[39]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Baxter1">[40]</xref> have been applied to spiking neurons several times and result in spike-based formulations of reward-based learning <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Baras1">[38]</xref>. In the following subsection we derive again the same rule, but with the aim to show that the derivation holds even in a network of spiking neurons with strong lateral connectivity (see also a comment in <xref ref-type="bibr" rid="pcbi.1000586-Baxter1">[40]</xref>). In the following two subsection we make the transition to an online formulation with eligibility traces and stochastic synaptic transmission. In subsection we leave the policy gradient framework by introducing the parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e357" xlink:type="simple"/></inline-formula> in order to enable a smooth transition between the standard policy gradient rule and a naive Hebbian rule that measures directly correlations between presynaptic spike arrival and postsynaptic firing on the time scale of the EPSP. The rule used in the main body of the paper is a mixture between policy gradient and naive Hebbian rules.</p>
<sec id="s4a">
<title>Derivation of the learning rule</title>
<p>To derive a learning rule for a highly connected network with action cells <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e358" xlink:type="simple"/></inline-formula> with lateral connections receiving from input from place cells <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e359" xlink:type="simple"/></inline-formula>, we shall first consider a restricted scenario where the rat always starts a trial in the same initial location and is left to move around for a fixed duration <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e360" xlink:type="simple"/></inline-formula>. We shall denote by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e361" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e362" xlink:type="simple"/></inline-formula>) the spatio-temporal spike pattern generated during this time by all place (action) cells. The reward, administered at the end of each trial, depends on the trajectory of the rat in the water maze. Given the fixed initial location, this trajectory is determined by the firings of the action cells. So we write reward as a function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e363" xlink:type="simple"/></inline-formula>, where b is the reinforcement baseline <xref ref-type="bibr" rid="pcbi.1000586-Williams1">[39]</xref>, without explictly noting the dependence on the initial position of the rat. Expected reward then is <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e364" xlink:type="simple"/><label>(17)</label></disp-formula>here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e365" xlink:type="simple"/></inline-formula> denote the strengths of the synapses connecting the action to the place cells, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e366" xlink:type="simple"/></inline-formula> is the probability that the network generates the total spike pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e367" xlink:type="simple"/></inline-formula>.</p>
<p>In our model <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e368" xlink:type="simple"/></inline-formula> can be decomposed as (see also Decomposition of probability):<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e369" xlink:type="simple"/><label>(18)</label></disp-formula>Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e370" xlink:type="simple"/></inline-formula> is the function giving for the action cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e371" xlink:type="simple"/></inline-formula> the single neuron probability that it generates its spike train <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e372" xlink:type="simple"/></inline-formula> with an input consisting of all the other spikes produced by the network. Similarly, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e373" xlink:type="simple"/></inline-formula> is the single neuron probability function for the spike train produced by the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e374" xlink:type="simple"/></inline-formula> place cell given its input (determined by the other spikes in the network).</p>
<p>Note that the above product form does not imply that the spike trains are statistically independent. This is obviously not the case: First, due to the lateral connections between the action cells, and, more importantly, due to the simple fact that the action cells decide on the rats trajectory and thus influence the firing of the place cells. The product form simply represents the fact that the internal stochastic processes which modulate the translation of presynaptic input to postsynaptic output are assumed to be independent between different cells. In other words, <italic>given</italic> the input spikes from all other neurons and its own previous spikes up to time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e375" xlink:type="simple"/></inline-formula>, the neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e376" xlink:type="simple"/></inline-formula> decides locally whether it fires between <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e377" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e378" xlink:type="simple"/></inline-formula> or not (i.e., we activate an independent random process for each neuron in each time step of the simulation), see section Decomposition of probability.</p>
<p>An explicit form for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e379" xlink:type="simple"/></inline-formula> would be rather complicated, due to the involved calculations mapping the action cell firings to the trajectory of the rat. Luckily, we just explicitly need <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e380" xlink:type="simple"/></inline-formula>. Note, and this is in fact the crucial feature of the decomposition, that <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e381" xlink:type="simple"/></inline-formula> does not depend on all feed-forward weights, but only on the weight vector <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e382" xlink:type="simple"/></inline-formula> of the synapses actually projecting onto neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e383" xlink:type="simple"/></inline-formula>.</p>
<p>To calculate the gradient of the expected reward (17), we first rewrite the probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e384" xlink:type="simple"/></inline-formula> as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e385" xlink:type="simple"/><label>(19)</label></disp-formula>and note that in view of (18) the term in square brackets in fact does not depend on <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e386" xlink:type="simple"/></inline-formula> (even if this is not apparent from the notation). Now, for the synapse connecting place cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e387" xlink:type="simple"/></inline-formula> to action cell <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e388" xlink:type="simple"/></inline-formula> the gradient calculation is<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e389" xlink:type="simple"/><label>(20)</label></disp-formula>The last line yields a batch rule for synaptic changes. We first average<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e390" xlink:type="simple"/><label>(21)</label></disp-formula>over many trials and then use the result to update the synaptic strength. The biologically reasonable online version of this is to already update after each single trial, i.e.<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e391" xlink:type="simple"/><label>(22)</label></disp-formula>Often we replace the reinforcement baseline <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e392" xlink:type="simple"/></inline-formula> with the estimate of upcoming reinforcement based on past experience <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e393" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000586-Williams1">[39]</xref>. In the context of on-line learning, our initial requirement of a fixed initial position is no longer necessary since we calculate the expected reward by averaging not just over trials with the same but also over trials with different initial positions.</p>
<p>The crucial element of the learning rule is the conditional probability of creating certain outputs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e394" xlink:type="simple"/></inline-formula> (and hence taking certain actions) given an input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e395" xlink:type="simple"/></inline-formula>. In order to calculate the conditional probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e396" xlink:type="simple"/></inline-formula> that neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e397" xlink:type="simple"/></inline-formula> fires a spike given the past, we need to introduce a neuronal model. Following the approach of Pfister et al <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>, we assume that neuronal activity can be described by the Spike Response Model (SRM) <xref ref-type="bibr" rid="pcbi.1000586-Gerstner2">[20]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e398" xlink:type="simple"/><label>(23)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e399" xlink:type="simple"/></inline-formula> is the membrane potential of the neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e400" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e401" xlink:type="simple"/></inline-formula> is the resting potential, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e402" xlink:type="simple"/></inline-formula> is the set of postsynaptic spikes, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e403" xlink:type="simple"/></inline-formula> is the set of postsynaptic spikes up to time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e404" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e405" xlink:type="simple"/></inline-formula> the synaptic strength between the presynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e406" xlink:type="simple"/></inline-formula> and the postsynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e407" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e408" xlink:type="simple"/></inline-formula> is the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e409" xlink:type="simple"/></inline-formula>th firing time of the presynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e410" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e411" xlink:type="simple"/></inline-formula> the <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e412" xlink:type="simple"/></inline-formula>th firing time of the postsynaptic neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e413" xlink:type="simple"/></inline-formula>. The sum is restricted to firing times before time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e414" xlink:type="simple"/></inline-formula>. The kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e415" xlink:type="simple"/></inline-formula> describes the time course on an excitatory postsynaptic potential (EPSP) and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e416" xlink:type="simple"/></inline-formula> the spike-afterpotential. We would like to emphasize that for an exponential kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e417" xlink:type="simple"/></inline-formula> and exponential spike- afterpotential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e418" xlink:type="simple"/></inline-formula>, the SRM becomes identical to a leaky integrate-and-fire model with membrane time constant <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e419" xlink:type="simple"/></inline-formula> <xref ref-type="bibr" rid="pcbi.1000586-Gerstner2">[20]</xref> as used in Eq. (11) in the results section.</p>
<p>Given a membrane potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e420" xlink:type="simple"/></inline-formula>, action potentials are generated by a point process with stochastic intensity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e421" xlink:type="simple"/></inline-formula>, where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e422" xlink:type="simple"/></inline-formula> is some positive nonlinear function. To be specific, we take an exponential function<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e423" xlink:type="simple"/><label>(24)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e424" xlink:type="simple"/></inline-formula> the formal firing threshold, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e425" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e426" xlink:type="simple"/></inline-formula> parameters. Thus the higher the membrane potential, the more likely is the neuron model to fire.</p>
<p>With the above neuron model, the probability of neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e427" xlink:type="simple"/></inline-formula> to emit a particular set of postsynaptic spikes <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e428" xlink:type="simple"/></inline-formula> in the period <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e429" xlink:type="simple"/></inline-formula> given the input <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e430" xlink:type="simple"/></inline-formula> and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e431" xlink:type="simple"/></inline-formula> from all neurons in the network except neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e432" xlink:type="simple"/></inline-formula> is given by:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e433" xlink:type="simple"/><label>(25)</label></disp-formula>with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e434" xlink:type="simple"/></inline-formula> representing the postsynaptic spike train of the neuron <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e435" xlink:type="simple"/></inline-formula> up to time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e436" xlink:type="simple"/></inline-formula> as a sum of the Dirac <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e437" xlink:type="simple"/></inline-formula> functions, i.e <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e438" xlink:type="simple"/></inline-formula>. Taking the partial derivative in respect to the synaptic weight <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e439" xlink:type="simple"/></inline-formula>, we have the following equation <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e440" xlink:type="simple"/><label>(26)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e441" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e442" xlink:type="simple"/></inline-formula> being the set of postsynaptic spikes that occurred before <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e443" xlink:type="simple"/></inline-formula>, and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e444" xlink:type="simple"/></inline-formula> the EPSP kernel. Note that for the exponential function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e445" xlink:type="simple"/></inline-formula>, we have <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e446" xlink:type="simple"/></inline-formula>, so the learning rule becomes:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e447" xlink:type="simple"/><label>(27)</label></disp-formula>Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e448" xlink:type="simple"/></inline-formula> is the total reward received during or after a trial of total duration <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e449" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4b">
<title>Eligibility trace</title>
<p>In order to illustrate the mathematical structure of Eq. (27), we consider the time point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e450" xlink:type="simple"/></inline-formula> at the end of the trial and integrate backwards in time<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e451" xlink:type="simple"/><label>(28)</label></disp-formula>where <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e452" xlink:type="simple"/></inline-formula> is the momentary reward at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e453" xlink:type="simple"/></inline-formula>. Here <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e454" xlink:type="simple"/></inline-formula> is a weighting function that allows us to give different weights to events in the past. If we take <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e455" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e456" xlink:type="simple"/></inline-formula> and zero otherwise, and evaluate at time point <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e457" xlink:type="simple"/></inline-formula>, we retrieve exactly Eq. (27) under the assumption that the reward is given according to one of the following two schedules: (a) all the reward <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e458" xlink:type="simple"/></inline-formula> is delivered at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e459" xlink:type="simple"/></inline-formula>, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e460" xlink:type="simple"/></inline-formula> and a negative <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e461" xlink:type="simple"/></inline-formula> is applied at every time step; this is the scenario we have in mind with our notation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e462" xlink:type="simple"/></inline-formula> that we use throughout the rest of the methods section, since it simplifies the development of the theory. Or, (b) no reward is given in the interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e463" xlink:type="simple"/></inline-formula> and an effective reward <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e464" xlink:type="simple"/></inline-formula> is applied at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e465" xlink:type="simple"/></inline-formula>, i.e., <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e466" xlink:type="simple"/></inline-formula>. This is the scenario we used in the simulations in the main body of the paper. The baseline is either <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e467" xlink:type="simple"/></inline-formula> or <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e468" xlink:type="simple"/></inline-formula>.</p>
<p>Starting from the interpretation (a) we can turn to an online rule in continuous time where rewards can be delivered at arbitrary moments. To arrive at a more elegant representation of the rule, we replace the step function <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e469" xlink:type="simple"/></inline-formula> by an exponential kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e470" xlink:type="simple"/></inline-formula> for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e471" xlink:type="simple"/></inline-formula> and zero otherwise. Then we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e472" xlink:type="simple"/><label>(29)</label></disp-formula><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e473" xlink:type="simple"/></inline-formula> is a learning rate and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e474" xlink:type="simple"/></inline-formula> is called an eligibility trace <xref ref-type="bibr" rid="pcbi.1000586-Sutton1">[1]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref>. For our specific model we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e475" xlink:type="simple"/><label>(30)</label></disp-formula></p>
<p>Because of the exponential in the integral the eligibility trace can be rewritten as a differential equation<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e476" xlink:type="simple"/><label>(31)</label></disp-formula></p>
</sec><sec id="s4c">
<title>Stochastic versus continuous synapses</title>
<p>We consider stochastic binary synapses <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e477" xlink:type="simple"/></inline-formula> with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e478" xlink:type="simple"/></inline-formula>. Synaptic transmission is stochastic with a release probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e479" xlink:type="simple"/></inline-formula>. Learning affects the release property so that increasing the weight <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e480" xlink:type="simple"/></inline-formula> of the synapse by the above update rule will increase the release probability. We choose proportionality factors so that the expectation of the binary synaptic transmission over time is equal to the continuous synaptic weight <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e481" xlink:type="simple"/></inline-formula>, i.e. <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e482" xlink:type="simple"/></inline-formula>. and thus, with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e483" xlink:type="simple"/></inline-formula>, we have for binary synapses instead of Eq. 29 the following learning rule<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e484" xlink:type="simple"/><label>(32)</label></disp-formula>We impose a hard bound <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e485" xlink:type="simple"/></inline-formula> that reflect the interpretation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e486" xlink:type="simple"/></inline-formula> as a probability of transmitter release. In order to guarantee sufficient exploration, we also impose a non-zero lower bound <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e487" xlink:type="simple"/></inline-formula></p>
<p>The factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e488" xlink:type="simple"/></inline-formula> can be absorbed by a learning rate <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e489" xlink:type="simple"/></inline-formula> yielding the final online-rule<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e490" xlink:type="simple"/><label>(33)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e491" xlink:type="simple"/></disp-formula>We note the typical structure of a three-factor learning rule. The eligibility trace picks up correlations between EPSPs <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e492" xlink:type="simple"/></inline-formula> caused by presynaptic spike arrivals <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e493" xlink:type="simple"/></inline-formula> and postsynaptic firing times <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e494" xlink:type="simple"/></inline-formula> as in a STDP learning rule <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref> which is then combined with the reward signal <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>–<xref ref-type="bibr" rid="pcbi.1000586-Izhikevich1">[35]</xref>.</p>
</sec><sec id="s4d">
<title>From a single rule to a family of rules</title>
<p>We extended our rule by introducing <italic>ad hoc</italic> a variant with a parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e495" xlink:type="simple"/></inline-formula>:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e496" xlink:type="simple"/><label>(34)</label></disp-formula><disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e497" xlink:type="simple"/></disp-formula>In the limit of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e498" xlink:type="simple"/></inline-formula> this reduces to the rule derived above.</p>
<p>Eq. (34) in discrete form becomes:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e499" xlink:type="simple"/><label>(35)</label></disp-formula>with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e500" xlink:type="simple"/></inline-formula> being the time step, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e501" xlink:type="simple"/></inline-formula> being 1 if a spike is emitted in the interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e502" xlink:type="simple"/></inline-formula> and 0 otherwise and the hat (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e503" xlink:type="simple"/></inline-formula>) operator denoting discrete firing times. The quantity <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e504" xlink:type="simple"/></inline-formula> is the probability that the postsynaptic neuron emits a spike in the interval <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e505" xlink:type="simple"/></inline-formula> given the input spike trains (denoted <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e506" xlink:type="simple"/></inline-formula> in discrete time) and is computed as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e507" xlink:type="simple"/><label>(36)</label></disp-formula>which computationally advantageous for large timesteps, see also <xref ref-type="bibr" rid="pcbi.1000586-Gerstner2">[20]</xref>.</p>
<p>In <xref ref-type="fig" rid="pcbi-1000586-g001">Figure 1</xref> we plot the factor<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e508" xlink:type="simple"/><label>(37)</label></disp-formula>The voltage trace is obtained by integrating Eq. (11) for constant input, i.e. presynaptic spike arrival is replaced by a positive constant.</p>
</sec><sec id="s4e">
<title>Relationship to other rules</title>
<p>Interestingly the rule developed by <xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref> as well as the variation presented here can be mapped to Associative Reward Inaction (ARI) <xref ref-type="bibr" rid="pcbi.1000586-Williams1">[39]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Barto2">[81]</xref> in discrete time. With Eq. (27), and ignoring the baseline subtraction, we have<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e509" xlink:type="simple"/><label>(38)</label></disp-formula></p>
<p>Let us assume a rectangular EPSP of duration of one time step and unit amplitude. Hence, the EPSP <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e510" xlink:type="simple"/></inline-formula> can be replace by a binary variable <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e511" xlink:type="simple"/></inline-formula> if a spike has arrived at the synapse j at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e512" xlink:type="simple"/></inline-formula>, and with <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e513" xlink:type="simple"/></inline-formula> in the absence of a spike. We then have:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e514" xlink:type="simple"/><label>(39)</label></disp-formula>We note that according to the above derivation <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e515" xlink:type="simple"/></inline-formula> is a sigmoidal function of the membrane potential <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e516" xlink:type="simple"/></inline-formula>. Hence, dropping the hats (that we used to denote discrete time) we have exactly the update rule of the ARI:<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e517" xlink:type="simple"/><label>(40)</label></disp-formula>Similarly the learning rules of <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref> also correspond to ARI or its modern forms of policy gradient. In fact the rule in <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref> is derived from the framework of <xref ref-type="bibr" rid="pcbi.1000586-Baxter1">[40]</xref>. The rule of <xref ref-type="bibr" rid="pcbi.1000586-Xie1">[32]</xref> is a special case of the rules by <xref ref-type="bibr" rid="pcbi.1000586-Florian1">[33]</xref>,<xref ref-type="bibr" rid="pcbi.1000586-Pfister1">[34]</xref>, since it makes use of a memoryless Poisson neural model, wheres our derivation here includes refractoriness via the kernel <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e518" xlink:type="simple"/></inline-formula>.</p>
</sec><sec id="s4f">
<title>Decomposition of probability</title>
<p>Here we show that the probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e519" xlink:type="simple"/></inline-formula> of the place cell spike pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e520" xlink:type="simple"/></inline-formula> and the action cell spike pattern <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e521" xlink:type="simple"/></inline-formula> to occur can be decomposed into the product<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e522" xlink:type="simple"/><label>(41)</label></disp-formula>as mentioned in the <xref ref-type="sec" rid="s4">Methods</xref> of the main text, Eq.(18). The argument is similar to the unfolding in time used by Williams <xref ref-type="bibr" rid="pcbi.1000586-Williams1">[39]</xref>, except that networks of spiking neurons are not Markovian. We claim that the above decomposition holds for an arbitrary network architecture including recurrent connections.</p>
<p>Let <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e523" xlink:type="simple"/></inline-formula> be a collection of discrete random variables, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e524" xlink:type="simple"/></inline-formula> a location index, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e525" xlink:type="simple"/></inline-formula> a time index. Denote by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e526" xlink:type="simple"/></inline-formula> the whole collection up to time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e527" xlink:type="simple"/></inline-formula>. In our example, the index <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e528" xlink:type="simple"/></inline-formula> encompasses both the place and action cells. Moreover, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e529" xlink:type="simple"/></inline-formula> (<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e530" xlink:type="simple"/></inline-formula>) if the corresponding cell did (did not) emit a spike at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e531" xlink:type="simple"/></inline-formula>. We assume that the sequence is generated by choosing at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e532" xlink:type="simple"/></inline-formula> the value <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e533" xlink:type="simple"/></inline-formula> with a probability <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e534" xlink:type="simple"/></inline-formula>. For spiking neurons the sequence <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e535" xlink:type="simple"/></inline-formula> determines the internal states (membrane potentials) at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e536" xlink:type="simple"/></inline-formula> and this modulates the probability of firing at time <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e537" xlink:type="simple"/></inline-formula> given the previous spike history, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e538" xlink:type="simple"/></inline-formula>. We further assume that the internal stochastic processes which trigger the spikes are independent given the membranes potentials. Hence,<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e539" xlink:type="simple"/><label>(42)</label></disp-formula>for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e540" xlink:type="simple"/></inline-formula>.</p>
<p>Because we can always write <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e541" xlink:type="simple"/></inline-formula> with a factor <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e542" xlink:type="simple"/></inline-formula>, we can iteratively apply an analogous multiplicative decomposition for <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e543" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e544" xlink:type="simple"/></inline-formula>, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e545" xlink:type="simple"/></inline-formula>, and receive a product representation of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e546" xlink:type="simple"/></inline-formula>. To anchor the product we assume that (42) also holds at <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e547" xlink:type="simple"/></inline-formula>, and take this to mean that the initial values <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e548" xlink:type="simple"/></inline-formula> are statistically independent with probabilities given by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e549" xlink:type="simple"/></inline-formula>. While consecutively applying (42) at each step of the decomposition we arrive at<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e550" xlink:type="simple"/><label>(43)</label></disp-formula></p>
<p>Setting <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e551" xlink:type="simple"/></inline-formula> and reordering the product terms we can write (43) as<disp-formula><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e552" xlink:type="simple"/></disp-formula>and this is just the decomposition into the product across the place and action cells expressed in (41).</p>
</sec><sec id="s4g">
<title>Implementation</title>
<p>Model and Figures are produced with Matlab R2008b (Linux version), developed by Mathworks. The model is implemented with custom-made code. For implementation details see <xref ref-type="fig" rid="pcbi-1000586-g004">Figures 4</xref> and <xref ref-type="fig" rid="pcbi-1000586-g009">9</xref>. Parameter values are summarized in <xref ref-type="table" rid="pcbi-1000586-t001">Tables 1</xref> and <xref ref-type="table" rid="pcbi-1000586-t002">2</xref>. The Euler method is used for integration. We discretize the learning rule equation according to the method in paragraph ‘From a single rule to a family of rules’, in order to allow for large time steps. The standard time step in our simulation is <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e553" xlink:type="simple"/></inline-formula>. We have checked in additional simulations with smaller time steps of <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e554" xlink:type="simple"/></inline-formula> that the results do not depend on the step size (data not shown).</p>
<fig id="pcbi-1000586-g009" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.g009</object-id><label>Figure 9</label><caption>
<title>Network description and implementation of neuron models according to <xref ref-type="bibr" rid="pcbi.1000586-Nordlie1">[82]</xref>.</title>
<p>Parameters as in Model architecture, <xref ref-type="sec" rid="s4">Methods</xref>, and <xref ref-type="table" rid="pcbi-1000586-t001">Tables 1</xref>, <xref ref-type="table" rid="pcbi-1000586-t002">2</xref> (unless otherwise stated in Figure captions).</p>
</caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.g009" xlink:type="simple"/></fig><table-wrap id="pcbi-1000586-t001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.t001</object-id><label>Table 1</label><caption>
<title>Parameters for producing the comparison graph of <xref ref-type="fig" rid="pcbi-1000586-g003">Figure 3</xref>.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000586-t001-1" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.t001" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Panel</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e555" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e556" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e557" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e558" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e559" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e560" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e561" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e562" xlink:type="simple"/></inline-formula></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">A</td>
<td align="left" colspan="1" rowspan="1">0.02</td>
<td align="left" colspan="1" rowspan="1">0</td>
<td align="left" colspan="1" rowspan="1">200</td>
<td align="left" colspan="1" rowspan="1">5</td>
<td align="left" colspan="1" rowspan="1">0</td>
<td align="left" colspan="1" rowspan="1">-</td>
<td align="left" colspan="1" rowspan="1">1</td>
<td align="left" colspan="1" rowspan="1">3</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">B</td>
<td align="left" colspan="1" rowspan="1">0.02</td>
<td align="left" colspan="1" rowspan="1">0</td>
<td align="left" colspan="1" rowspan="1">200</td>
<td align="left" colspan="1" rowspan="1">5</td>
<td align="left" colspan="1" rowspan="1">0</td>
<td align="left" colspan="1" rowspan="1">-</td>
<td align="left" colspan="1" rowspan="1">1</td>
<td align="left" colspan="1" rowspan="1">5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">C</td>
<td align="left" colspan="1" rowspan="1">0.02/0.0002</td>
<td align="left" colspan="1" rowspan="1">0</td>
<td align="left" colspan="1" rowspan="1">200/10</td>
<td align="left" colspan="1" rowspan="1">5</td>
<td align="left" colspan="1" rowspan="1">0/<inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e563" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">-/150</td>
<td align="left" colspan="1" rowspan="1">1/1.3</td>
<td align="left" colspan="1" rowspan="1">5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">D</td>
<td align="left" colspan="1" rowspan="1">0.0002</td>
<td align="left" colspan="1" rowspan="1">5</td>
<td align="left" colspan="1" rowspan="1">10</td>
<td align="left" colspan="1" rowspan="1">5</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e564" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">150</td>
<td align="left" colspan="1" rowspan="1">1.3</td>
<td align="left" colspan="1" rowspan="1">5</td>
</tr>
<tr>
<td align="left" colspan="1" rowspan="1">E</td>
<td align="left" colspan="1" rowspan="1">0.0002</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e565" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">10</td>
<td align="left" colspan="1" rowspan="1">5</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e566" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1">150</td>
<td align="left" colspan="1" rowspan="1">1.3</td>
<td align="left" colspan="1" rowspan="1">5</td>
</tr>
</tbody>
</table></alternatives><table-wrap-foot><fn id="nt101"><label/><p>Parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e567" xlink:type="simple"/></inline-formula> is the learning rate, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e568" xlink:type="simple"/></inline-formula> turns the model from a strict policy gradient rule to naive Hebbian, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e569" xlink:type="simple"/></inline-formula> is the time constant used to estimate the firing rate of the action cells, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e570" xlink:type="simple"/></inline-formula> is the time constant of the eligibility trace, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e571" xlink:type="simple"/></inline-formula> is the reward baseline, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e572" xlink:type="simple"/></inline-formula> the width of the averaging window of the reward, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e573" xlink:type="simple"/></inline-formula> is the height of the postsynaptic pulse produced by the arrival of a spike and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e574" xlink:type="simple"/></inline-formula> determines the width of the threshold region (escape noise). For C–E integration stops as soon as the total mean firing rate of all action cells <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e575" xlink:type="simple"/></inline-formula>, calculated by <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e576" xlink:type="simple"/></inline-formula>, see equation (15), exceeds 200 spikes/ms, i.e. the activity bump is well formed. For panels where two alternative parameter sets are given, both sets give very similar results, and hence we only depict one of them.</p></fn></table-wrap-foot></table-wrap><table-wrap id="pcbi-1000586-t002" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.1000586.t002</object-id><label>Table 2</label><caption>
<title>Constant parameters for the Leaky Integrate and Fire neurons.</title>
</caption><!--===== Grouping alternate versions of objects =====--><alternatives><graphic id="pcbi-1000586-t002-2" mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1000586.t002" xlink:type="simple"/><table><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup>
<thead>
<tr>
<td align="left" colspan="1" rowspan="1">Model</td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e577" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e578" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e579" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e580" xlink:type="simple"/></inline-formula></td>
<td align="left" colspan="1" rowspan="1"><inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e581" xlink:type="simple"/></inline-formula></td>
</tr>
</thead>
<tbody>
<tr>
<td align="left" colspan="1" rowspan="1">LIF with escape noise (Action Cells)</td>
<td align="left" colspan="1" rowspan="1">10</td>
<td align="left" colspan="1" rowspan="1">−70</td>
<td align="left" colspan="1" rowspan="1">−50</td>
<td align="left" colspan="1" rowspan="1">1</td>
<td align="left" colspan="1" rowspan="1">5</td>
</tr>
</tbody>
</table></alternatives><table-wrap-foot><fn id="nt102"><label/><p>Parameter <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e582" xlink:type="simple"/></inline-formula> is the membrane time constant, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e583" xlink:type="simple"/></inline-formula> is the resting potential, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e584" xlink:type="simple"/></inline-formula> is the formal firing threshold, <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e585" xlink:type="simple"/></inline-formula> is the stochastic intensity at threshold and <inline-formula><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.1000586.e586" xlink:type="simple"/></inline-formula> the amount by which the membrane potential is reset after a spike.</p></fn></table-wrap-foot></table-wrap></sec></sec></body>
<back>
<ack>
<p>We would like to thank the anonymous reviewers for their constructive comments.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1000586-Sutton1"><label>1</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sutton</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Barto</surname><given-names>A</given-names></name>
</person-group>             <year>1998</year>             <source>Reinforcement learning</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000586-Thorndike1"><label>2</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Thorndike</surname><given-names>E</given-names></name>
</person-group>             <year>1911</year>             <source>Animal Intelligence</source>             <publisher-loc>Darien, CT</publisher-loc>             <publisher-name>Hafner</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000586-Rescorla1"><label>3</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rescorla</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Wagner</surname><given-names>A</given-names></name>
</person-group>             <year>1972</year>             <article-title>A theory of pavlovian conditioning: variations in the effectiveness of reinforecement and nonreinforcement.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Black</surname><given-names>AH</given-names></name>
<name name-style="western"><surname>Prokasy</surname><given-names>W</given-names></name>
</person-group>             <source>Classical Conditioning II: current research and theory</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Appleton Century Crofts</publisher-name>             <fpage>64</fpage>             <lpage>99</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Klopf1"><label>4</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Klopf</surname><given-names>A</given-names></name>
</person-group>             <year>1982</year>             <article-title>The hedonistic neuron: a theory of memory, learning, and intelligence.</article-title>             <source>Hemisphere</source>          </element-citation></ref>
<ref id="pcbi.1000586-Klopf2"><label>5</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Klopf</surname><given-names>A</given-names></name>
</person-group>             <year>1988</year>             <article-title>A neuronal model of classical conditioning.</article-title>             <source>Psychobiology</source>             <volume>16</volume>             <fpage>85</fpage>             <lpage>125</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Sutton2"><label>6</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sutton</surname><given-names>RS</given-names></name>
<name name-style="western"><surname>Barto</surname><given-names>AG</given-names></name>
</person-group>             <year>1981</year>             <article-title>Towards a modern theory of adaptive networks: expectation and prediction.</article-title>             <source>Psychol Rev</source>             <volume>88</volume>             <fpage>135</fpage>             <lpage>171</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Barto1"><label>7</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barto</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Sutton</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Anderson</surname><given-names>C</given-names></name>
</person-group>             <year>1983</year>             <article-title>Neuronlike adaptive elements that can solve difficult learning and control problems.</article-title>             <source>IEEE sys man cybern</source>             <volume>13</volume>             <fpage>835</fpage>             <lpage>846</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Sutton3"><label>8</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sutton</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Barto</surname><given-names>A</given-names></name>
</person-group>             <year>1990</year>             <article-title>Time-derivative models of pavlovian reinforcement.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Gabriel</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Moore</surname><given-names>J</given-names></name>
</person-group>             <source>Learning and Computational Neuroscience: Foundations of Adaptive Networks</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT-Press</publisher-name>             <fpage>497</fpage>             <lpage>537</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Bliss1"><label>9</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bliss</surname><given-names>TVP</given-names></name>
<name name-style="western"><surname>Collingridge</surname><given-names>GL</given-names></name>
</person-group>             <year>1993</year>             <article-title>A synaptic model of memory: long-term potentiation in the hippocampus.</article-title>             <source>Nature</source>             <volume>361</volume>             <fpage>31</fpage>             <lpage>39</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Malenka1"><label>10</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Malenka</surname><given-names>RC</given-names></name>
<name name-style="western"><surname>Bear</surname><given-names>MF</given-names></name>
</person-group>             <year>2004</year>             <article-title>LTP and LTD: An embarassment of riches.</article-title>             <source>Neuron</source>             <volume>44</volume>             <fpage>5</fpage>             <lpage>21</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Hebb1"><label>11</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hebb</surname><given-names>DO</given-names></name>
</person-group>             <year>1949</year>             <source>The Organization of Behavior</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Wiley</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000586-Oja1"><label>12</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Oja</surname><given-names>E</given-names></name>
</person-group>             <year>1982</year>             <article-title>A simplified neuron model as a principal component analyzer.</article-title>             <source>J Math Biol</source>             <volume>15</volume>             <fpage>267</fpage>             <lpage>273</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Kohonen1"><label>13</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kohonen</surname><given-names>T</given-names></name>
</person-group>             <year>1989</year>             <source>Self-organization and associative memory, 3rd edition</source>             <publisher-loc>Berlin Heidelberg New York</publisher-loc>             <publisher-name>Springer-Verlag</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000586-vonderMalsburg1"><label>14</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>von der Malsburg</surname><given-names>C</given-names></name>
</person-group>             <year>1973</year>             <article-title>Self-organization of orientation selective cells in the striate cortex.</article-title>             <source>Kybernetik</source>             <volume>14</volume>             <fpage>85</fpage>             <lpage>100</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Bienenstock1"><label>15</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Bienenstock</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Cooper</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Munroe</surname><given-names>P</given-names></name>
</person-group>             <year>1982</year>             <article-title>Theory of the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex.</article-title>             <source>J Neurosci</source>             <volume>2</volume>             <fpage>32</fpage>             <lpage>48</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Gerstner1"><label>16</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Kempter</surname><given-names>R</given-names></name>
<name name-style="western"><surname>van Hemmen</surname><given-names>JL</given-names></name>
<name name-style="western"><surname>Wagner</surname><given-names>H</given-names></name>
</person-group>             <year>1996</year>             <article-title>A neuronal learning rule for sub-millisecond temporal coding.</article-title>             <source>Nature</source>             <volume>383</volume>             <fpage>76</fpage>             <lpage>78</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Abbott1"><label>17</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Abbott</surname><given-names>LF</given-names></name>
<name name-style="western"><surname>Nelson</surname><given-names>SB</given-names></name>
</person-group>             <year>2000</year>             <article-title>Synaptic plastictiy - taming the beast.</article-title>             <source>Nat Neurosci</source>             <volume>3</volume>             <fpage>1178</fpage>             <lpage>1183</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-vanRossum1"><label>18</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>van Rossum</surname><given-names>MCW</given-names></name>
<name name-style="western"><surname>Bi</surname><given-names>GQ</given-names></name>
<name name-style="western"><surname>Turrigiano</surname><given-names>GG</given-names></name>
</person-group>             <year>2000</year>             <article-title>Stable Hebbian learning from spike timing-dependent plasticity.</article-title>             <source>J Neurosci</source>             <volume>20</volume>             <fpage>8812</fpage>             <lpage>8821</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Senn1"><label>19</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Senn</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Markram</surname><given-names>H</given-names></name>
</person-group>             <year>2001</year>             <article-title>An algorithm for modifying neurotransmitter release probability based on pre- and postsynaptic spike timing.</article-title>             <source>Neural Computat</source>             <volume>13</volume>             <fpage>35</fpage>             <lpage>67</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Gerstner2"><label>20</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Kistler</surname><given-names>WK</given-names></name>
</person-group>             <year>2002</year>             <source>Spiking Neuron Models</source>             <publisher-loc>Cambridge UK</publisher-loc>             <publisher-name>Cambridge University Press</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000586-Morrison1"><label>21</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Morrison</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
</person-group>             <year>2008</year>             <article-title>Phenomenological models of synaptic plasticity based on spike timing.</article-title>             <source>Biolog Cybern</source>             <volume>98</volume>             <fpage>459</fpage>             <lpage>478</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Schultz1"><label>22</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Montague</surname><given-names>R</given-names></name>
</person-group>             <year>1997</year>             <article-title>A neural substrate for prediction and reward.</article-title>             <source>Science</source>             <volume>275</volume>             <fpage>1593</fpage>             <lpage>1599</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Wickens1"><label>23</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wickens</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Kotter</surname><given-names>R</given-names></name>
</person-group>             <year>1995</year>             <article-title>Cellular models of reinforcement.</article-title>             <person-group person-group-type="editor">
<name name-style="western"><surname>Houk</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Davis</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Beiser</surname><given-names>DG</given-names></name>
</person-group>             <source>Models of information processing in basal ganglia</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>MIT-Press</publisher-name>             <fpage>187</fpage>             <lpage>214</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Wickens2"><label>24</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wickens</surname><given-names>J</given-names></name>
</person-group>             <year>1997</year>             <article-title>Basal ganglia: structure and computations.</article-title>             <source>Network-Comp Neural</source>             <volume>8</volume>             <fpage>77</fpage>             <lpage>109</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Reynolds1"><label>25</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reynolds</surname><given-names>JNJ</given-names></name>
<name name-style="western"><surname>Hyland</surname><given-names>BI</given-names></name>
<name name-style="western"><surname>Wickens</surname><given-names>JR</given-names></name>
</person-group>             <year>2001</year>             <article-title>A cellular mechanism of reward-related learning.</article-title>             <source>Nature</source>             <volume>413</volume>             <fpage>67</fpage>             <lpage>70</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Reynolds2"><label>26</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reynolds</surname><given-names>JNJ</given-names></name>
<name name-style="western"><surname>Wickens</surname><given-names>JR</given-names></name>
</person-group>             <year>2002</year>             <article-title>Dopamine-dependent plasticity of corticostriatal synapses.</article-title>             <source>Neural Networks</source>             <volume>15</volume>             <fpage>507</fpage>             <lpage>521</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Frey1"><label>27</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Frey</surname><given-names>U</given-names></name>
<name name-style="western"><surname>Morris</surname><given-names>R</given-names></name>
</person-group>             <year>1997</year>             <article-title>Synaptic tagging and long-term potentiation.</article-title>             <source>Nature</source>             <volume>385</volume>             <fpage>533</fpage>             <lpage>536</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Reymann1"><label>28</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Reymann</surname><given-names>KG</given-names></name>
<name name-style="western"><surname>Frey</surname><given-names>JU</given-names></name>
</person-group>             <year>2007</year>             <article-title>The late maintenance of hippocampal LTP: requirements, phases, ‘synaptic tagging’, ‘late-associativity’ and implications.</article-title>             <source>Neuropharmacology</source>             <volume>52</volume>             <fpage>24</fpage>             <lpage>40</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Sajikumar1"><label>29</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sajikumar</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Frey</surname><given-names>JU</given-names></name>
</person-group>             <year>2004</year>             <article-title>Resetting of ‘synaptic tags’ is time- and activity-dependent in rat hippocampal ca1 in vitro.</article-title>             <source>Neuroscience</source>             <volume>129</volume>             <fpage>503</fpage>             <lpage>507</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Sajikumar2"><label>30</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sajikumar</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Navakkode</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Frey</surname><given-names>JU</given-names></name>
</person-group>             <year>2007</year>             <article-title>Identification of compartment- and process-specific molecules required for ‘synaptic tagging’ during long-term potentiation and long-term depression in hippocampal CA1.</article-title>             <source>J Neurosci</source>             <volume>27</volume>             <fpage>5068</fpage>             <lpage>5080</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Pawlak1"><label>31</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pawlak</surname><given-names>V</given-names></name>
<name name-style="western"><surname>Kerr</surname><given-names>JND</given-names></name>
</person-group>             <year>2008</year>             <article-title>Dopamine receptor activation is required for corticostriatal spike-timing-dependent plasticity.</article-title>             <source>J Neurosci</source>             <volume>28</volume>             <fpage>2435</fpage>             <lpage>2446</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Xie1"><label>32</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Xie</surname><given-names>X</given-names></name>
<name name-style="western"><surname>Seung</surname><given-names>S</given-names></name>
</person-group>             <year>2004</year>             <article-title>Learning in neural networks by reinforcement of irregular spiking.</article-title>             <source>Phys Rev E</source>             <volume>69</volume>             <fpage>41909</fpage>          </element-citation></ref>
<ref id="pcbi.1000586-Florian1"><label>33</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Florian</surname><given-names>RV</given-names></name>
</person-group>             <year>2007</year>             <article-title>Reinforcement learning through modulation of spike-timing-dependent synaptic plasticity.</article-title>             <source>Neural Computat</source>             <volume>19</volume>             <fpage>1468</fpage>             <lpage>1502</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Pfister1"><label>34</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Pfister</surname><given-names>JP</given-names></name>
<name name-style="western"><surname>Toyoizumi</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Barber</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
</person-group>             <year>2006</year>             <article-title>Optimal spike-timing dependent plasticity for precise action potential firing in supervised learning.</article-title>             <source>Neural Computat</source>             <volume>18</volume>             <fpage>1309</fpage>             <lpage>1339</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Izhikevich1"><label>35</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Izhikevich</surname><given-names>E</given-names></name>
</person-group>             <year>2007</year>             <article-title>Solving the distal reward problem through linkage of stdp and dopamine signaling.</article-title>             <source>Cereb Cortex</source>             <volume>17</volume>             <fpage>2443</fpage>             <lpage>2452</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Legenstein1"><label>36</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Legenstein</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Pecevski</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Maass</surname><given-names>W</given-names></name>
</person-group>             <year>2008</year>             <article-title>A learning theory for reward-modulated spike-timing-dependent plasticity with application to biofeedback.</article-title>             <source>PLoS Comput Biol</source>             <volume>4(10)</volume>             <fpage>e1000180</fpage>          </element-citation></ref>
<ref id="pcbi.1000586-Potjans1"><label>37</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Potjans</surname><given-names>W</given-names></name>
<name name-style="western"><surname>Morrison</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Diesmann</surname><given-names>M</given-names></name>
</person-group>             <year>2009</year>             <article-title>A spiking neural network model of an actor-critic learning agent.</article-title>             <source>Neural Comput</source>             <volume>21</volume>             <fpage>301</fpage>             <lpage>339</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Baras1"><label>38</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Baras</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Meir</surname><given-names>R</given-names></name>
</person-group>             <year>2007</year>             <article-title>Reinforcement learning, spike-time-dependent plasticity, and the bcm rule.</article-title>             <source>Neural Comput</source>             <volume>19</volume>             <fpage>2245</fpage>             <lpage>2279</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Williams1"><label>39</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Williams</surname><given-names>R</given-names></name>
</person-group>             <year>1992</year>             <article-title>Simple statistical gradient-following methods for connectionist reinforcement learning.</article-title>             <source>Mach Learn</source>             <volume>8</volume>             <fpage>229</fpage>             <lpage>256</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Baxter1"><label>40</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Baxter</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Bartlett</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Weaver</surname><given-names>L</given-names></name>
</person-group>             <year>2001</year>             <article-title>Experiments with infinite-horizon, policy- gradient estimation.</article-title>             <source>J Artif Intell Res</source>             <volume>15</volume>             <fpage>351</fpage>             <lpage>381</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Farries1"><label>41</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Farries</surname><given-names>MA</given-names></name>
<name name-style="western"><surname>Fairhall</surname><given-names>AL</given-names></name>
</person-group>             <year>2007</year>             <article-title>Reinforcement Learning With Modulated Spike Timing Dependent Synaptic Plasticity.</article-title>             <source>J Neurophysiol</source>             <volume>98</volume>             <fpage>3648</fpage>             <lpage>3665</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Kempter1"><label>42</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Kempter</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
<name name-style="western"><surname>van Hemmen</surname><given-names>JL</given-names></name>
</person-group>             <year>1999</year>             <article-title>Hebbian learning and spiking neurons.</article-title>             <source>Phys Rev E</source>             <volume>59</volume>             <fpage>4498</fpage>             <lpage>4514</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Watkins1"><label>43</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Watkins</surname><given-names>C</given-names></name>
</person-group>             <year>1989</year>             <source>Learning from delayed rewards</source>             <publisher-loc>Cambridge</publisher-loc>             <publisher-name>PhD-thesis, Cambridge University</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000586-Suri1"><label>44</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Suri</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Schultz</surname><given-names>W</given-names></name>
</person-group>             <year>2001</year>             <article-title>Temporal difference model reproduces anticipatory neural activity.</article-title>             <source>Neural Comput</source>             <volume>13</volume>             <fpage>841</fpage>             <lpage>862</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-DiCastro1"><label>45</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Di Castro</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Volkinshtein</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Meir</surname><given-names>R</given-names></name>
</person-group>             <year>2009</year>             <article-title>Temporal difference based actor critic learning - convergence and neural implementation.</article-title>             <source>NIPS</source>             <volume>22</volume>             <fpage>385</fpage>             <lpage>392</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Seung1"><label>46</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Seung</surname><given-names>H</given-names></name>
</person-group>             <year>2003</year>             <article-title>Learning in spiking neural networks by reinforcement of stochastic synaptic transmission.</article-title>             <source>Neuron</source>             <volume>40</volume>             <fpage>1063</fpage>             <lpage>1073</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Fiete1"><label>47</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Fiete</surname><given-names>I</given-names></name>
<name name-style="western"><surname>Seung</surname><given-names>H</given-names></name>
</person-group>             <year>2006</year>             <article-title>Gradient learning in spiking neural networks by dynamic perturbation of conductances.</article-title>             <source>Phys Rev Lett</source>             <volume>97</volume>             <fpage>48104</fpage>          </element-citation></ref>
<ref id="pcbi.1000586-Wrgtter1"><label>48</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wörgötter</surname><given-names>F</given-names></name>
<name name-style="western"><surname>Porr</surname><given-names>B</given-names></name>
</person-group>             <year>2005</year>             <article-title>Temporal sequence learning, prediction, and control: a review of different models and their relation to biological mechanisms.</article-title>             <source>Neural Comput</source>             <volume>17</volume>             <fpage>245</fpage>             <lpage>319</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Roberts1"><label>49</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Roberts</surname><given-names>P</given-names></name>
</person-group>             <year>1999</year>             <article-title>Computational consequences of temporally asymmetric learning rules: I. Differential Hebbian learning.</article-title>             <source>J Comput Neurosci</source>             <volume>7</volume>             <fpage>235</fpage>             <lpage>246</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Rao1"><label>50</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Rao</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name>
</person-group>             <year>2000</year>             <article-title>Predictive sequence learning in recurrent neocortical circuits.</article-title>             <fpage>164</fpage>             <lpage>170</lpage>             <comment>In: NIPS vol. 2000</comment>          </element-citation></ref>
<ref id="pcbi.1000586-Morris1"><label>51</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Morris</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Garrard</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Rawlins</surname><given-names>J</given-names></name>
<name name-style="western"><surname>O'Keefe</surname><given-names>J</given-names></name>
</person-group>             <year>1982</year>             <article-title>Place navigation impaired in rats with hippocampal lesions.</article-title>             <source>Nature</source>             <volume>297</volume>             <fpage>681</fpage>             <lpage>683</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Foster1"><label>52</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Foster</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Morris</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
</person-group>             <year>2000</year>             <article-title>Models of hippocampally dependent navigation using the temporal difference learning rule.</article-title>             <source>Hippocampus</source>             <volume>10</volume>             <fpage>1</fpage>             <lpage>16</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Arleo1"><label>53</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Arleo</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
</person-group>             <year>2000</year>             <article-title>Spatial cognition and neuro-mimetic navigation: a model of hippocampal place cell activity.</article-title>             <source>Biol Cybern</source>             <volume>83</volume>             <fpage>287</fpage>             <lpage>299</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Stroesslin1"><label>54</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stroesslin</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Sheynikhovich</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Chavarriaga</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
</person-group>             <year>2005</year>             <article-title>Robust self-localisation and navigation based on hippocampal place cells.</article-title>             <source>Neural Networks</source>             <volume>18</volume>             <fpage>1125</fpage>             <lpage>1140</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Sheynikhovich1"><label>55</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sheynikhovich</surname><given-names>D</given-names></name>
<name name-style="western"><surname>Chavarriaga</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Strösslin</surname><given-names>T</given-names></name>
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
</person-group>             <year>2005</year>             <article-title>Spatial representation and navigation in a bio-inspired robot.</article-title>             <fpage>245</fpage>             <lpage>264</lpage>             <comment>In: Biomimetic Neural Learning for Intelligent Robots: Intelligent Systems, Cognitive Robotics, and Neuroscience</comment>          </element-citation></ref>
<ref id="pcbi.1000586-Poucet1"><label>56</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Poucet</surname><given-names>B</given-names></name>
<name name-style="western"><surname>Lenck-Santini</surname><given-names>PP</given-names></name>
<name name-style="western"><surname>Paz-Villagrán</surname><given-names>VE</given-names></name>
<name name-style="western"><surname>Save</surname><given-names>E</given-names></name>
</person-group>             <year>2003</year>             <article-title>Place cells, neocortex and spatial navigation: a short review.</article-title>             <source>J Physiology-Paris</source>             <volume>97</volume>             <fpage>537</fpage>             <lpage>546</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Eichenbaum1"><label>57</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Eichenbaum</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Stewart</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Morris</surname><given-names>R</given-names></name>
</person-group>             <year>1990</year>             <article-title>Hippocampal representation in place learning.</article-title>             <source>J Neurosci</source>             <volume>10</volume>             <fpage>3531</fpage>             <lpage>3542</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Dayan1"><label>58</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
</person-group>             <year>1992</year>             <article-title>The convergens of TD (<italic>λ</italic>) for general <italic>λ</italic>.</article-title>             <source>Mach learn</source>             <volume>8</volume>             <fpage>341</fpage>             <lpage>362</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Dayan2"><label>59</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Dayan</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Sejnowski</surname><given-names>T</given-names></name>
</person-group>             <year>1994</year>             <article-title>TD(<italic>λ</italic>) converges with probability 1.</article-title>             <source>Mach Learn</source>             <volume>14</volume>             <fpage>295</fpage>             <lpage>301</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Tsodyks1"><label>60</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Tsodyks</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Markram</surname><given-names>H</given-names></name>
</person-group>             <year>1997</year>             <article-title>The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability.</article-title>             <source>P Natl Acad Sci USA</source>             <volume>94</volume>             <fpage>719</fpage>             <lpage>723</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Clopath1"><label>61</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Clopath</surname><given-names>C</given-names></name>
<name name-style="western"><surname>Ziegler</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Vasilaki</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Büsing</surname><given-names>L</given-names></name>
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
</person-group>             <year>2008</year>             <article-title>Tag-trigger-consolidation: a model of early and late long-term-potentiation and depression.</article-title>             <source>PLoS Comput Biol</source>             <volume>4</volume>          </element-citation></ref>
<ref id="pcbi.1000586-Stein1"><label>62</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Stein</surname><given-names>RB</given-names></name>
</person-group>             <year>1965</year>             <article-title>A theoretical analysis of neuronal variability.</article-title>             <source>Biophys J</source>             <volume>5</volume>             <fpage>173</fpage>             <lpage>194</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Gerstner3"><label>63</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
<name name-style="western"><surname>van Hemmen</surname><given-names>JL</given-names></name>
</person-group>             <year>1992</year>             <article-title>Associative memory in a network of ‘spiking’ neurons.</article-title>             <source>Network</source>             <volume>3</volume>             <fpage>139</fpage>             <lpage>164</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Jolivet1"><label>64</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Jolivet</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Rauch</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Lüscher</surname><given-names>HR</given-names></name>
<name name-style="western"><surname>Gerstner</surname><given-names>W</given-names></name>
</person-group>             <year>2006</year>             <article-title>Predicting spike timing of neocortical pyramidal neurons by simple threshold models.</article-title>             <source>J Comput Neurosci</source>             <volume>21</volume>             <fpage>35</fpage>             <lpage>49</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Morris2"><label>65</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Morris</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Moser</surname><given-names>EI</given-names></name>
<name name-style="western"><surname>Riedel</surname><given-names>G</given-names></name>
<name name-style="western"><surname>Martin</surname><given-names>SJ</given-names></name>
<name name-style="western"><surname>Sandin</surname><given-names>J</given-names></name>
<etal/></person-group>             <year>2003</year>             <article-title>Elements of a neurobiological theory of the hippocampus: the role of activity-dependent synaptic plasticity in memory.</article-title>             <source>Phil Trans R Soc Lond B</source>             <volume>358</volume>             <fpage>773</fpage>             <lpage>786</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Morris3"><label>66</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Morris</surname><given-names>R</given-names></name>
</person-group>             <year>2007</year>             <article-title>Theories of hippocampal function.</article-title>             <source>The hippocampus book</source>             <publisher-name>Oxford university press</publisher-name>             <fpage>581</fpage>             <lpage>713</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Vasilaki1"><label>67</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Vasilaki</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Fusi</surname><given-names>S</given-names></name>
<name name-style="western"><surname>Wang</surname><given-names>XJ</given-names></name>
<name name-style="western"><surname>Senn</surname><given-names>W</given-names></name>
</person-group>             <year>2009</year>             <article-title>Learning flexible sensori-motor mappings in a complex network.</article-title>             <source>Biol Cybern</source>             <volume>100</volume>             <fpage>147</fpage>             <lpage>158</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Redgrave1"><label>68</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Redgrave</surname><given-names>P</given-names></name>
<name name-style="western"><surname>Gurney</surname><given-names>K</given-names></name>
</person-group>             <year>2006</year>             <article-title>The short-latency dopamine signal: a role in discovering novel actions?</article-title>             <source>Nat Rev Neurosci</source>             <volume>7</volume>             <fpage>967</fpage>             <lpage>975</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Doya1"><label>69</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Doya</surname><given-names>K</given-names></name>
</person-group>             <year>2002</year>             <article-title>Metalearning and neuromodulation.</article-title>             <source>Neural Networks</source>             <volume>15</volume>             <fpage>495</fpage>             <lpage>506</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Devan1"><label>70</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Devan</surname><given-names>B</given-names></name>
<name name-style="western"><surname>White</surname><given-names>N</given-names></name>
</person-group>             <year>1999</year>             <article-title>Parallel information processing in the dorsal striatum: Relation to hippocampal function.</article-title>             <source>J Neurosci</source>             <volume>19</volume>             <fpage>2789</fpage>             <lpage>2798</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Packard1"><label>71</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Packard</surname><given-names>M</given-names></name>
<name name-style="western"><surname>McGaugh</surname><given-names>J</given-names></name>
</person-group>             <year>1996</year>             <article-title>Inactivation of hippocampus or caudate nucleus with lidocaine differentially affects expression of place and response learning.</article-title>             <source>Neurobiol Learn Mem</source>             <volume>65</volume>             <fpage>65</fpage>             <lpage>72</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-White1"><label>72</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>White</surname><given-names>N</given-names></name>
<name name-style="western"><surname>McDonald</surname><given-names>R</given-names></name>
</person-group>             <year>2002</year>             <article-title>Multiple parallel memory systems in the brain of the rat.</article-title>             <source>Neurobiol Learn and Mem</source>             <volume>77</volume>             <fpage>125</fpage>             <lpage>184</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Hull1"><label>73</label><element-citation publication-type="other" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Hull</surname><given-names>C</given-names></name>
</person-group>             <year>1943</year>             <source>Principles of behavior</source>             <publisher-loc>New York</publisher-loc>             <publisher-name>Appleton-Century-Crofts</publisher-name>          </element-citation></ref>
<ref id="pcbi.1000586-Toleman1"><label>74</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Toleman</surname><given-names>E</given-names></name>
</person-group>             <year>1948</year>             <article-title>Cogitiva maps in rats and men.</article-title>             <source>Psychol Rev</source>             <volume>55</volume>             <fpage>189</fpage>             <lpage>208</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Wang1"><label>75</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Wang</surname><given-names>XJ</given-names></name>
</person-group>             <year>2002</year>             <article-title>Probabilistic decision making by slow reverrberation in cortical circuits.</article-title>             <source>Neuron</source>             <volume>36</volume>             <fpage>955</fpage>             <lpage>968</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Zhang1"><label>76</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Zhang</surname><given-names>JC</given-names></name>
<name name-style="western"><surname>Lau</surname><given-names>PM</given-names></name>
<name name-style="western"><surname>Bi</surname><given-names>GQ</given-names></name>
</person-group>             <year>2009</year>             <article-title>Gain in sensitivity and loss in temporal contrast of stdp by dopaminergic modulation at hippocampal synapses.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>106</volume>             <fpage>13028</fpage>             <lpage>13033</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Markram1"><label>77</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Markram</surname><given-names>H</given-names></name>
<name name-style="western"><surname>Lübke</surname><given-names>J</given-names></name>
<name name-style="western"><surname>Frotscher</surname><given-names>M</given-names></name>
<name name-style="western"><surname>Sakmann</surname><given-names>B</given-names></name>
</person-group>             <year>1997</year>             <article-title>Regulation of synaptic efficacy by coincidence of postysnaptic AP and EPSP.</article-title>             <source>Science</source>             <volume>275</volume>             <fpage>213</fpage>             <lpage>215</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Sjstrm1"><label>78</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Sjöström</surname><given-names>PJ</given-names></name>
<name name-style="western"><surname>Rancz</surname><given-names>EA</given-names></name>
<name name-style="western"><surname>Roth</surname><given-names>A</given-names></name>
<name name-style="western"><surname>Häusser</surname><given-names>M</given-names></name>
</person-group>             <year>2008</year>             <article-title>Dendritic excitability and synaptic plasticity.</article-title>             <source>Physiol Rev</source>             <volume>88</volume>             <fpage>769</fpage>             <lpage>840</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Loewenstein1"><label>79</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Loewenstein</surname><given-names>Y</given-names></name>
<name name-style="western"><surname>Seung</surname><given-names>HS</given-names></name>
</person-group>             <year>2006</year>             <article-title>Operant matching is a generic outcome of synaptic plasticity based on the covariance between reward and neural activity.</article-title>             <source>Proc Natl Acad Sci USA</source>             <volume>103</volume>             <fpage>15224</fpage>             <lpage>15229</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Urbanczik1"><label>80</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Urbanczik</surname><given-names>R</given-names></name>
<name name-style="western"><surname>Senn</surname><given-names>W</given-names></name>
</person-group>             <year>2009</year>             <article-title>Reinforcement learning in populations of spiking neurons.</article-title>             <source>Nat Neurosci</source>             <volume>12</volume>             <fpage>250</fpage>             <lpage>252</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Barto2"><label>81</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Barto</surname><given-names>A</given-names></name>
</person-group>             <year>1985</year>             <article-title>Learning by statistical cooperation of self-interested neuron-like neuron elements.</article-title>             <source>Hum Neurobiol</source>             <volume>4</volume>             <fpage>229</fpage>             <lpage>256</lpage>          </element-citation></ref>
<ref id="pcbi.1000586-Nordlie1"><label>82</label><element-citation publication-type="journal" xlink:type="simple">             <person-group person-group-type="author">
<name name-style="western"><surname>Nordlie</surname><given-names>E</given-names></name>
<name name-style="western"><surname>Gewaltig</surname><given-names>MO</given-names></name>
<name name-style="western"><surname>Plesser</surname><given-names>HE</given-names></name>
</person-group>             <year>2009</year>             <article-title>Towards reproducible descriptions of neuronal network models.</article-title>             <source>PLoS Comput Biol</source>             <volume>5</volume>             <fpage>e1000456</fpage>          </element-citation></ref>
</ref-list>

</back>
</article>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN" "http://jats.nlm.nih.gov/publishing/1.1d3/JATS-journalpublishing1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id>
<journal-id journal-id-type="publisher-id">plos</journal-id>
<journal-id journal-id-type="pmc">ploscomp</journal-id>
<journal-title-group>
<journal-title>PLOS Computational Biology</journal-title>
</journal-title-group>
<issn pub-type="ppub">1553-734X</issn>
<issn pub-type="epub">1553-7358</issn>
<publisher>
<publisher-name>Public Library of Science</publisher-name>
<publisher-loc>San Francisco, CA USA</publisher-loc>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="publisher-id">PCOMPBIOL-D-16-01234</article-id>
<article-id pub-id-type="doi">10.1371/journal.pcbi.1005309</article-id>
<article-categories>
<subj-group subj-group-type="heading">
<subject>Research Article</subject>
</subj-group>
<subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Cell biology</subject><subj-group><subject>Cellular types</subject><subj-group><subject>Animal cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Approximation methods</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and information sciences</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neural networks</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Thermodynamics</subject><subj-group><subject>Entropy</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane potential</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and health sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action potentials</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability theory</subject><subj-group><subject>Random variables</subject><subj-group><subject>Covariance</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and analysis methods</subject><subj-group><subject>Simulation and modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and life sciences</subject><subj-group><subject>Population biology</subject><subj-group><subject>Population dynamics</subject></subj-group></subj-group></subj-group></article-categories>
<title-group>
<article-title>Approximate Inference for Time-Varying Interactions and Macroscopic Dynamics of Neural Populations</article-title>
<alt-title alt-title-type="running-head">Macroscopic Dynamics of Neural Populations</alt-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-4499-2895</contrib-id>
<name name-style="western">
<surname>Donner</surname> <given-names>Christian</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
<xref ref-type="aff" rid="aff003"><sup>3</sup></xref>
</contrib>
<contrib contrib-type="author" xlink:type="simple">
<name name-style="western">
<surname>Obermayer</surname> <given-names>Klaus</given-names></name>
<xref ref-type="aff" rid="aff001"><sup>1</sup></xref>
<xref ref-type="aff" rid="aff002"><sup>2</sup></xref>
</contrib>
<contrib contrib-type="author" corresp="yes" xlink:type="simple">
<contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7794-3064</contrib-id>
<name name-style="western">
<surname>Shimazaki</surname> <given-names>Hideaki</given-names></name>
<xref ref-type="aff" rid="aff004"><sup>4</sup></xref>
<xref ref-type="corresp" rid="cor001">*</xref>
</contrib>
</contrib-group>
<aff id="aff001">
<label>1</label>
<addr-line>Bernstein Center for Computational Neuroscience, Berlin, Germany</addr-line>
</aff>
<aff id="aff002">
<label>2</label>
<addr-line>Neural Information Processing Group, Department of Electrical Engineering and Computer Science, Technische Universität Berlin, Berlin, Germany</addr-line>
</aff>
<aff id="aff003">
<label>3</label>
<addr-line>Group for Methods of Artificial Intelligence, Department of Electrical Engineering and Computer Science, Technische Universität Berlin, Berlin, Germany</addr-line>
</aff>
<aff id="aff004">
<label>4</label>
<addr-line>RIKEN Brain Science Institute, Wako-shi, Saitama, Japan</addr-line>
</aff>
<contrib-group>
<contrib contrib-type="editor" xlink:type="simple">
<name name-style="western">
<surname>Bethge</surname> <given-names>Matthias</given-names></name>
<role>Editor</role>
<xref ref-type="aff" rid="edit1"/>
</contrib>
</contrib-group>
<aff id="edit1">
<addr-line>University of Tübingen and Max Planck Institute for Biologial Cybernetics, GERMANY</addr-line>
</aff>
<author-notes>
<fn fn-type="conflict" id="coi001">
<p>The authors have declared that no competing interests exist.</p>
</fn>
<fn fn-type="con">
<p>
<list list-type="simple">
<list-item>
<p><bold>Conceptualization:</bold> CD KO HS.</p>
</list-item>
<list-item>
<p><bold>Formal analysis:</bold> CD HS.</p>
</list-item>
<list-item>
<p><bold>Investigation:</bold> CD HS.</p>
</list-item>
<list-item>
<p><bold>Methodology:</bold> CD HS.</p>
</list-item>
<list-item>
<p><bold>Project administration:</bold> CD KO HS.</p>
</list-item>
<list-item>
<p><bold>Resources:</bold> CD HS.</p>
</list-item>
<list-item>
<p><bold>Software:</bold> CD HS.</p>
</list-item>
<list-item>
<p><bold>Supervision:</bold> KO HS.</p>
</list-item>
<list-item>
<p><bold>Validation:</bold> CD HS.</p>
</list-item>
<list-item>
<p><bold>Visualization:</bold> CD HS.</p>
</list-item>
<list-item>
<p><bold>Writing – original draft:</bold> CD HS.</p>
</list-item>
<list-item>
<p><bold>Writing – review &amp; editing:</bold> CD KO HS.</p>
</list-item>
</list>
</p>
</fn>
<corresp id="cor001">* E-mail: <email xlink:type="simple">shimazaki@brain.riken.jp</email></corresp>
</author-notes>
<pub-date pub-type="collection">
<month>1</month>
<year>2017</year>
</pub-date>
<pub-date pub-type="epub">
<day>17</day>
<month>1</month>
<year>2017</year>
</pub-date>
<volume>13</volume>
<issue>1</issue>
<elocation-id>e1005309</elocation-id>
<history>
<date date-type="received">
<day>29</day>
<month>7</month>
<year>2016</year>
</date>
<date date-type="accepted">
<day>12</day>
<month>12</month>
<year>2016</year>
</date>
</history>
<permissions>
<copyright-year>2017</copyright-year>
<copyright-holder>Donner et al</copyright-holder>
<license xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">
<license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" xlink:type="simple">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p>
</license>
</permissions>
<self-uri content-type="pdf" xlink:href="info:doi/10.1371/journal.pcbi.1005309"/>
<abstract>
<p>The models in statistical physics such as an Ising model offer a convenient way to characterize stationary activity of neural populations. Such stationary activity of neurons may be expected for recordings from <italic>in vitro</italic> slices or anesthetized animals. However, modeling activity of cortical circuitries of awake animals has been more challenging because both spike-rates and interactions can change according to sensory stimulation, behavior, or an internal state of the brain. Previous approaches modeling the dynamics of neural interactions suffer from computational cost; therefore, its application was limited to only a dozen neurons. Here by introducing multiple analytic approximation methods to a state-space model of neural population activity, we make it possible to estimate dynamic pairwise interactions of up to 60 neurons. More specifically, we applied the pseudolikelihood approximation to the state-space model, and combined it with the Bethe or TAP mean-field approximation to make the sequential Bayesian estimation of the model parameters possible. The large-scale analysis allows us to investigate dynamics of macroscopic properties of neural circuitries underlying stimulus processing and behavior. We show that the model accurately estimates dynamics of network properties such as sparseness, entropy, and heat capacity by simulated data, and demonstrate utilities of these measures by analyzing activity of monkey V4 neurons as well as a simulated balanced network of spiking neurons.</p>
</abstract>
<abstract abstract-type="summary">
<title>Author Summary</title>
<p>Simultaneous analysis of large-scale neural populations is necessary to understand coding principles of neurons because they concertedly process information. Methods of thermodynamics and statistical mechanics are useful to understand collective phenomena of the interacting elements, and they have been successfully used to understand diverse activity of neurons. However, most analysis methods assume stationary data, in which activity rates of neurons and their correlations are constant over time. This assumption is easily violated in the data recorded from awake animals. Neural correlations likely organize dynamically during behavior and cognition, and this may be independent from the modulated activity rates of individual neurons. Recently several methods were proposed to simultaneously estimate dynamics of neural interactions. However, these methods are applicable to up to about 10 neurons. Here by combining multiple analytic approximation methods, we made it possible to estimate time-varying interactions of much larger neural populations. The method allows us to trace dynamic macroscopic properties of neural circuitries such as sparseness, entropy, and sensitivity. Using these statistics, researchers can now quantify to what extent neurons are correlated or de-correlated, and test if neural systems are susceptible within a specific behavioral period.</p>
</abstract>
<funding-group>
<award-group id="award001">
<funding-source>
<institution-wrap>
<institution-id institution-id-type="funder-id">http://dx.doi.org/10.13039/501100001659</institution-id>
<institution>Deutsche Forschungsgemeinschaft</institution>
</institution-wrap>
</funding-source>
<award-id>GRK1589/2</award-id>
<principal-award-recipient>
<name name-style="western">
<surname>Obermayer</surname> <given-names>Klaus</given-names></name>
</principal-award-recipient>
</award-group>
<funding-statement>This work was in part supported by the Deutsche Forschungsgemeinschaft GRK1589/2 (CD and KO) <ext-link ext-link-type="uri" xlink:href="http://www.dfg.de/en/" xlink:type="simple">http://www.dfg.de/en/</ext-link>. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement>
</funding-group>
<counts>
<fig-count count="7"/>
<table-count count="0"/>
<page-count count="27"/>
</counts>
<custom-meta-group>
<custom-meta>
<meta-name>PLOS Publication Stage</meta-name>
<meta-value>vor-update-to-uncorrected-proof</meta-value>
</custom-meta>
<custom-meta>
<meta-name>Publication Update</meta-name>
<meta-value>2017-01-31</meta-value>
</custom-meta>
<custom-meta id="data-availability">
<meta-name>Data Availability</meta-name>
<meta-value>Data are taken from Synder et. al, Nature Neurosci., Vol 18, pp 736-743 (doi:<ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3979" xlink:type="simple">10.1038/nn.3979</ext-link>) with permissions of the authors, who may be contacted at <email xlink:type="simple">smithma@pitt.edu</email>.</meta-value>
</custom-meta>
</custom-meta-group>
</article-meta>
</front>
<body>
<sec id="sec001" sec-type="intro">
<title>Introduction</title>
<p>Activity patterns of neuronal populations are constrained by biological mechanisms such as biophysical properties of each neuron (e.g., synaptic integration and spike generation [<xref ref-type="bibr" rid="pcbi.1005309.ref001">1</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref002">2</xref>]) and their anatomical connections [<xref ref-type="bibr" rid="pcbi.1005309.ref003">3</xref>]. The characteristic correlations among neurons imposed by the biological mechanisms interplay with statistics of sensory inputs, and influence how the sensory information is represented in the population activity [<xref ref-type="bibr" rid="pcbi.1005309.ref004">4</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref006">6</xref>]. Thus accurate assessment of the neural correlations in ongoing and evoked activities is a key to understand the underlying biological mechanisms and their coding principles.</p>
<p>The number of possible activity patterns increases combinatorially with the number of neurons analyzed. The maximum entropy (ME) principle and derived ME models—known as the pairwise ME model or the Ising model—have been used to explain neural population activities using fewer activity features such as event rates or correlations between pairs of neurons [<xref ref-type="bibr" rid="pcbi.1005309.ref007">7</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref008">8</xref>]. This approach has been employed to explain not only the activity of neuronal networks but also other types of biological networks [<xref ref-type="bibr" rid="pcbi.1005309.ref009">9</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref011">11</xref>]. For large networks, however, exact inference of these models becomes computationally infeasible. Thus researchers have employed approximation methods [<xref ref-type="bibr" rid="pcbi.1005309.ref012">12</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref018">18</xref>]. While they successfully extended the number of neurons that could be analyzed, it was pointed out that the pairwise ME model might fail to explain large neural populations because the effect of higher-order interactions may become prominent [<xref ref-type="bibr" rid="pcbi.1005309.ref019">19</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref021">21</xref>]. Another fundamental problem of the conventional ME models is that these models assume temporarily constant spike rates for individual neurons. The assumption of stationary spike-rates is invalid, e.g., when <italic>in vivo</italic> activity is recorded while an animal performs a behavioral task. Ignoring such dynamics might result in erroneous model estimates and misleading interpretations on their correlations [<xref ref-type="bibr" rid="pcbi.1005309.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref026">26</xref>]. Moreover neural correlations themselves likely organize dynamically during behavior and cognition, which can be independent from changes in the spike rates of individual neurons [<xref ref-type="bibr" rid="pcbi.1005309.ref027">27</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref029">29</xref>]. The time-dependence of neural activity may be explained by including stimulus signals in the model, e.g., for analyses of early sensory cells [<xref ref-type="bibr" rid="pcbi.1005309.ref030">30</xref>]. However, the approach may become impractical when analyzing neurons in higher brain areas in which receptive fields of neurons are not easily characterized. Thus it remains to be examined how much the pairwise ME model can explain the data if the inappropriate stationary assumption is removed.</p>
<p>The state-space analysis [<xref ref-type="bibr" rid="pcbi.1005309.ref031">31</xref>] offers a general framework to model time-series data as observations driven by an unobserved latent state process. The underlying state changes are uncovered by a sequential estimation method from the noisy measurements. While observations of neuronal activity are often characterized by point events (spikes), a series of studies have established the nonlinear recursive Bayesian estimation of the underlying state that drives the event activity [<xref ref-type="bibr" rid="pcbi.1005309.ref032">32</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref034">34</xref>]. The method successfully estimated an animal’s position from population activity of hippocampal place cells [<xref ref-type="bibr" rid="pcbi.1005309.ref032">32</xref>], or estimate arm trajectories from neurons in the monkey motor cortex [<xref ref-type="bibr" rid="pcbi.1005309.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref036">36</xref>]. Recently, this framework has been extended to the analysis of population activity [<xref ref-type="bibr" rid="pcbi.1005309.ref037">37</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref039">39</xref>]. In addition to the point estimates of interaction parameters suggested by earlier studies [<xref ref-type="bibr" rid="pcbi.1005309.ref040">40</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref042">42</xref>], the state-space analysis provides credible intervals of those estimates through the recursive Bayesian fitting algorithm.</p>
<p>Nevertheless, as previously mentioned, the state-space model of a neural population was restricted by its computational cost. Therefore, it could be utilized to analyze only small populations (<italic>N</italic> ≤ 15). Recent advances in electrophysiological and optical recording techniques from a large number of neurons <italic>in vivo</italic> under free moving or virtual reality settings challenge these analysis methods. Thus the challenge is to make it possible to fit the exponentially complex state-space model to such large-scale data. For this goal, we need to incorporate approximation methods into the sequential Bayesian algorithm. More specifically, we need good approximations of mean and variance of the model parameters required in the approximate Bayesian scheme. These approximation methods must be analytical to avoid impractical computation time. By doing so we will be able to directly estimate all time-varying interactions of a large neural population. Such a model will serve as benchmark for alternative unsupervised methods that aim to capture low-dimensional, time-dependent latent structure of the pairwise interactions [<xref ref-type="bibr" rid="pcbi.1005309.ref043">43</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref045">45</xref>] (see also [<xref ref-type="bibr" rid="pcbi.1005309.ref046">46</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref048">48</xref>] for other dimension reduction methods for neuroscience data).</p>
<p>Here by combining the state-space model proposed in [<xref ref-type="bibr" rid="pcbi.1005309.ref037">37</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref039">39</xref>] with analytic approximation methods, we provide a framework for estimating interactions of neuronal populations consisting of up to 60 neurons. To find the mean we used the pseudolikelihood approximation method. To approximate the variance, we provide two alternative methods: the Bethe or the mean-field approximation. The Bayesian analysis methods for larger networks of neurons allow us to better understand macroscopic states of a neural population, such as entropy, free energy and sensitivity, all in a time-resolved manner and with credible intervals. Thus the model provides a new way to investigate effects of stimuli and behavior on activity of neuronal populations. It is expected to provide observations that give us insights into the underlying circuitry and its computation.</p>
</sec>
<sec id="sec002" sec-type="materials|methods">
<title>Materials and Methods</title>
<p>To clarify the problem of large-scale analysis on dynamic population activity, we first formulate the state-space model and its estimation method originally investigated in [<xref ref-type="bibr" rid="pcbi.1005309.ref037">37</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref038">38</xref>] in the next subsection. Then we describe how to introduce approximation methods to the state-space model in order to overcome the limitation of the model and make the large-scale analysis possible. The custom-made Python programs are provided on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/christiando/ssll_lib" xlink:type="simple">https://github.com/christiando/ssll_lib</ext-link>).</p>
<sec id="sec003">
<title>The state-space analysis of neural population activity</title>
<sec id="sec004">
<title>Spike data</title>
<p>To investigate how neuronal activities realize perception, cognition, and behavior, neurophysiologists record timing of neuronal spiking activity over the course of a behavioral paradigm designed to test specific hypotheses. Typically, these experiments are repeated multiple times under the same experimental conditions to uncover common neuronal dynamics related to the behavioral paradigm from stochastic spiking activities. We assume that neural data is composed of repeated measurements (<italic>R</italic> times) of spike timing recorded from <italic>N</italic> neurons simultaneously. Hereafter repetition is termed trial. To analyze activity patterns of neurons, we discretize the parallel spike sequences into <italic>T</italic> time bins with bin size Δ, and represent the population activity by a set of binary variables. For neurons <italic>n</italic> = 1, …, <italic>N</italic>, time bins <italic>t</italic> = 1, …, <italic>T</italic>, and trials <italic>r</italic> = 1, …, <italic>R</italic>, the neural activity is represented by a binary variable <inline-formula id="pcbi.1005309.e001"><alternatives><graphic id="pcbi.1005309.e001g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e001" xlink:type="simple"/><mml:math display="inline" id="M1"><mml:msubsup><mml:mi>X</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>, where <inline-formula id="pcbi.1005309.e002"><alternatives><graphic id="pcbi.1005309.e002g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e002" xlink:type="simple"/><mml:math display="inline" id="M2"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> when neuron <italic>n</italic> spiked in time bin <italic>t</italic> and trial <italic>r</italic>; and <inline-formula id="pcbi.1005309.e003"><alternatives><graphic id="pcbi.1005309.e003g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e003" xlink:type="simple"/><mml:math display="inline" id="M3"><mml:mrow><mml:msubsup><mml:mi>X</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> otherwise. Hence, we describe the whole data as a <italic>N</italic> × <italic>R</italic> × <italic>T</italic> dimensional binary matrix. The activity pattern of <italic>N</italic> neurons at time bin <italic>t</italic> and trial <italic>r</italic> is a vector, <inline-formula id="pcbi.1005309.e004"><alternatives><graphic id="pcbi.1005309.e004g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e004" xlink:type="simple"/><mml:math display="inline" id="M4"><mml:mrow><mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>X</mml:mi> <mml:mn>1</mml:mn> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>X</mml:mi> <mml:mi>N</mml:mi> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>,</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>. Similarly, <bold>X</bold><sup><italic>t</italic></sup> = (<bold>X</bold><sup>1,<italic>t</italic></sup>, …, <bold>X</bold><sup><italic>R</italic>,<italic>t</italic></sup>) summarizes observations for all neurons 1, …, <italic>N</italic> and all trials 1, …, <italic>R</italic> at time bin <italic>t</italic>. Finally, <inline-formula id="pcbi.1005309.e005"><alternatives><graphic id="pcbi.1005309.e005g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e005" xlink:type="simple"/><mml:math display="inline" id="M5"><mml:mrow><mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>:</mml:mo> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msup> <mml:mo>=</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:msub><mml:mi>t</mml:mi> <mml:mn>1</mml:mn></mml:msub></mml:msup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:msub><mml:mi>t</mml:mi> <mml:mn>2</mml:mn></mml:msub></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> denotes the observations from time bin <italic>t</italic><sub>1</sub> to <italic>t</italic><sub>2</sub>.</p>
</sec>
<sec id="sec005">
<title>State-space model of neural population activity</title>
<p>We assume a state-space model of dynamic population activity composed of two submodels; an observation model and a state model. First, the observation model specifies the probability distribution of population activity patterns using state variables, whereas the latter dictates how those state variables change. Here we construct the observation model using the exponential family distribution considering up to pairwise interactions of neurons’ activities,
<disp-formula id="pcbi.1005309.e006"><alternatives><graphic id="pcbi.1005309.e006g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e006" xlink:type="simple"/><mml:math display="block" id="M6"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mfenced close="]" open="[" separators=""><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(1)</label></disp-formula>
where <italic>ψ</italic><sub><italic>t</italic></sub>(<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>) is a log normalization term (a.k.a. log partition function). The model contains <italic>d</italic> = <italic>N</italic> + <italic>N</italic>(<italic>N</italic> − 1)/2 parameters <inline-formula id="pcbi.1005309.e007"><alternatives><graphic id="pcbi.1005309.e007g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e007" xlink:type="simple"/><mml:math display="inline" id="M7"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> known as natural or canonical parameters of an exponential family distribution. In statistical mechanics, this model is named “Ising model”, where the vector <bold>x</bold> represents a spin configuration (up or down). There, the natural parameters <inline-formula id="pcbi.1005309.e008"><alternatives><graphic id="pcbi.1005309.e008g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e008" xlink:type="simple"/><mml:math display="inline" id="M8"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> represent external magnetic field and interactions among the spins, and may be denoted as {<italic>h</italic><sub><italic>i</italic></sub>}, {<italic>J</italic><sub><italic>ij</italic></sub>} conventionally. Here we consider these parameters to be time-dependent, and refer to them as state variables of the state-space model. By introducing the <italic>d</italic>-dimensional state vector <inline-formula id="pcbi.1005309.e009"><alternatives><graphic id="pcbi.1005309.e009g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e009" xlink:type="simple"/><mml:math display="inline" id="M9"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mn>1</mml:mn> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>N</mml:mi> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:mi>N</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>′</mml:mo></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>, and the feature vector <bold>F</bold>(<bold>x</bold>) = (<italic>x</italic><sub>1</sub>, …, <italic>x</italic><sub><italic>N</italic></sub>, <italic>x</italic><sub>1</sub><italic>x</italic><sub>2</sub>, …, <italic>x</italic><sub><italic>N</italic>−1</sub><italic>x</italic><sub><italic>N</italic></sub>)′, the model of <xref ref-type="disp-formula" rid="pcbi.1005309.e006">Eq 1</xref> is written concisely as <inline-formula id="pcbi.1005309.e010"><alternatives><graphic id="pcbi.1005309.e010g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e010" xlink:type="simple"/><mml:math display="inline" id="M10"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. The resulting log partition function is then given by
<disp-formula id="pcbi.1005309.e011"><alternatives><graphic id="pcbi.1005309.e011g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e011" xlink:type="simple"/><mml:math display="block" id="M11"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi mathvariant="bold">x</mml:mi></mml:munder> <mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mspace width="0.166667em"/><mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(2)</label></disp-formula>
In statistical mechanics, <italic>ψ</italic><sub><italic>t</italic></sub> is known as the free energy. Note that it specifies the probability that all neurons are simultaneously silent because <italic>p</italic>(<bold>0</bold>|<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>) = exp[−<italic>ψ</italic><sub><italic>t</italic></sub>(<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>)]. This model considers individual and pairwise activity of neurons. Hence, we will refer to it as the <italic>pairwise observation model</italic> in the following.</p>
<p>Next, the state model considers that dynamics of the latent state <bold><italic>θ</italic></bold><sub><italic>t</italic></sub> is described by a random walk
<disp-formula id="pcbi.1005309.e012"><alternatives><graphic id="pcbi.1005309.e012g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e012" xlink:type="simple"/><mml:math display="block" id="M12"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">ξ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(3)</label></disp-formula>
where <bold><italic>ξ</italic></bold><sub><italic>t</italic></sub> is a random vector drawn from a multivariate normal distribution <inline-formula id="pcbi.1005309.e013"><alternatives><graphic id="pcbi.1005309.e013g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e013" xlink:type="simple"/><mml:math display="inline" id="M13"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mn>0</mml:mn> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">Q</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, and <bold>Q</bold> is a diagonal covariance matrix. Here we assume that entries of the diagonal of the inverse matrix <bold>Q</bold><sup>−1</sup> are given by a scalar λ that determines precision of the noise for all elements. For the initial time bin we set the density to <inline-formula id="pcbi.1005309.e014"><alternatives><graphic id="pcbi.1005309.e014g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e014" xlink:type="simple"/><mml:math display="inline" id="M14"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>It should be noted that here we model the neural dynamics as a <italic>quasistatic</italic> process, similarly to the classical analysis on dynamics of a thermodynamic system, e.g., a heat engine (see also [<xref ref-type="bibr" rid="pcbi.1005309.ref049">49</xref>]): At each time <italic>t</italic>, we presume that neural activity is sampled from the <italic>equilibrium</italic> distribution (<xref ref-type="disp-formula" rid="pcbi.1005309.e006">Eq 1</xref>), which is the same across the trials (across-trial stationarity). The free energy (<xref ref-type="disp-formula" rid="pcbi.1005309.e011">Eq 2</xref>) is also defined in the same manner as in the classical thermodynamics. We emphasize that the quasistatic process is a simplified view of the neural dynamics. See <xref ref-type="sec" rid="sec018">Discussion</xref> for possible extensions of the model.</p>
</sec>
<sec id="sec006">
<title>Estimating the state-space model</title>
<p>Given the data <bold>X</bold><sup>1:<italic>T</italic></sup>, our goal is to jointly estimate the posterior density of the latent states and the optimal noise precision λ. By denoting hyperparameters of the model as <bold>w</bold> = (λ, <bold><italic>μ</italic></bold>, <bold>Σ</bold>), the posterior density of the state process writes as
<disp-formula id="pcbi.1005309.e015"><alternatives><graphic id="pcbi.1005309.e015g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e015" xlink:type="simple"/><mml:math display="block" id="M15"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>;</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>;</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(4)</label></disp-formula>
where the first component in the numerator is constructed from the observation model, and the second component from the state model. In the next section, we provide the iterative method to construct this posterior density by approximating it by a Gaussian distribution (the Laplace approximation). The posterior density depends on the choice of the parameters <bold>w</bold>. The optimal <bold>w</bold> maximizes the marginal likelihood, a.k.a. evidence, that appears in the denominator in <xref ref-type="disp-formula" rid="pcbi.1005309.e015">Eq 4</xref>, given by
<disp-formula id="pcbi.1005309.e016"><alternatives><graphic id="pcbi.1005309.e016g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e016" xlink:type="simple"/><mml:math display="block" id="M16"><mml:mrow><mml:mi>l</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mn>1</mml:mn></mml:msup> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold-italic">μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>t</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mo>λ</mml:mo> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(5)</label></disp-formula>
This approach is called the empirical Bayes method. In this study, we optimize noise precision λ and mean <bold><italic>μ</italic></bold> of the initial distribution as described below while values for the covariance <bold>Σ</bold> are fixed. For fitting in the subsequent analyses, we set initial values as λ = 100 and <bold>Σ</bold> = 10<bold>I</bold>. For initial value of <bold><italic>μ</italic></bold> we computed the vector <bold><italic>θ</italic></bold> from time and trial averaged data, assuming <inline-formula id="pcbi.1005309.e017"><alternatives><graphic id="pcbi.1005309.e017g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e017" xlink:type="simple"/><mml:math display="inline" id="M17"><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>}</mml:mo> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>.</p>
<p>The optimization is achieved by an EM-algorithm combined with recursive Bayesian filtering/smoothing algorithms [<xref ref-type="bibr" rid="pcbi.1005309.ref033">33</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref050">50</xref>]. In this approach, we alternately perform construction of the posterior density (<xref ref-type="disp-formula" rid="pcbi.1005309.e015">Eq 4</xref>, E-step) and optimization of the hyperparameters (M-step) until the marginal likelihood (<xref ref-type="disp-formula" rid="pcbi.1005309.e016">Eq 5</xref>) saturates. In order to update the hyperparameters to new values <bold>w</bold>* from old values <bold>w</bold> in the M-step, a lower bound of the marginal likelihood is maximized. This lower bound is obtained by applying the Jensen’s inequality to the marginal likelihood:
<disp-formula id="pcbi.1005309.e018"><alternatives><graphic id="pcbi.1005309.e018g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e018" xlink:type="simple"/><mml:math display="block" id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>l</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">w</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">w</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:msub><mml:mfenced close="〉" open="〈" separators=""><mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">w</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mfenced> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>≥</mml:mo> <mml:msub><mml:mfenced close="〉" open="〈" separators=""><mml:mo form="prefix">log</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">w</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mfenced> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo> <mml:msub><mml:mfenced close="〉" open="〈" separators=""><mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">w</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>)</mml:mo></mml:mfenced> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mfenced close="〉" open="〈" separators=""><mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mfenced> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(6)</label></disp-formula>
Here <inline-formula id="pcbi.1005309.e019"><alternatives><graphic id="pcbi.1005309.e019g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e019" xlink:type="simple"/><mml:math display="inline" id="M19"><mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mo>⋅</mml:mo> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub></mml:math></alternatives></inline-formula> is expectation by the posterior density of the state variables (<xref ref-type="disp-formula" rid="pcbi.1005309.e015">Eq 4</xref>). In order to maximize the lower bound w.r.t. the new hyperparameters <bold>w</bold>*, we only need to maximize the first term, <italic>q</italic>(<bold>w</bold>*|<bold>w</bold>) ≡ 〈log <italic>p</italic> (<bold>X</bold><sup>1:<italic>T</italic></sup>, <bold><italic>θ</italic></bold><sub>1:<italic>T</italic></sub>|<bold>w</bold>*)〉<sub><bold><italic>θ</italic></bold><sub>1:<italic>T</italic></sub>|<bold>X</bold><sup>1:<italic>T</italic></sup>,<bold>w</bold></sub>. This term is called expected complete data log-likelihood, where the expectation is taken by the posterior density with the old <bold>w</bold>. It is computed as
<disp-formula id="pcbi.1005309.e020"><alternatives><graphic id="pcbi.1005309.e020g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e020" xlink:type="simple"/><mml:math display="block" id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>q</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">w</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>ψ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow> <mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:msub><mml:mfenced close="〉" open="〈" separators=""><mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow> <mml:mo>*</mml:mo></mml:msup></mml:mfenced> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mrow><mml:mi mathvariant="bold">Σ</mml:mi></mml:mrow> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">μ</mml:mi></mml:mrow> <mml:mo>*</mml:mo></mml:msup></mml:mfenced></mml:mfenced> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mrow><mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mn>2</mml:mn> <mml:mi>π</mml:mi></mml:mrow> <mml:msup><mml:mi mathvariant="bold">Q</mml:mi> <mml:mo>*</mml:mo></mml:msup> <mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msub><mml:mfenced close="〉" open="〈" separators=""><mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfenced> <mml:mo>′</mml:mo></mml:msup> <mml:msup><mml:mi mathvariant="bold">Q</mml:mi> <mml:mrow><mml:mo>*</mml:mo> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfenced></mml:mfenced> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(7)</label></disp-formula>
By considering derivatives of this equation w.r.t. the hypermarameters, we obtain their update rules. The precision λ<sup>⋆</sup><bold>I</bold>(= <bold>Q</bold><sup>* − <bold>1</bold></sup>) is updated as
<disp-formula id="pcbi.1005309.e021"><alternatives><graphic id="pcbi.1005309.e021g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e021" xlink:type="simple"/><mml:math display="block" id="M21"><mml:mrow><mml:msup><mml:mo>λ</mml:mo> <mml:mo>*</mml:mo></mml:msup> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>T</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo> <mml:mi>d</mml:mi></mml:mrow></mml:mfrac> <mml:mtext>tr</mml:mtext> <mml:mspace width="1pt"/> <mml:mfenced close="]" open="[" separators=""><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>2</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msub><mml:mfenced close="〉" open="〈" separators=""><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>′</mml:mo></mml:msup></mml:mfenced> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi></mml:mrow></mml:msub></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(8)</label></disp-formula>
where <italic>d</italic> is the dimension of vector <bold><italic>θ</italic></bold><sub><italic>t</italic></sub>. The initial mean is optimized by <bold><italic>μ</italic></bold>* = 〈<bold><italic>θ</italic></bold><sub>1</sub>〉<sub><bold><italic>θ</italic></bold><sub>1:<italic>T</italic></sub>|<bold>X</bold><sup>1:<italic>T</italic></sup>,<bold>w</bold></sub>. Here the key step is to develop an algorithm that constructs the posterior density of <xref ref-type="disp-formula" rid="pcbi.1005309.e015">Eq 4</xref>. This is done by the forward and backward recursive Bayesian algorithms. Below we review this method followed by introduction of the approximations that make the method applicable to larger number of neurons.</p>
</sec>
<sec id="sec007">
<title>Recursive estimation of dynamic neural interactions</title>
<p>The estimation of the latent process is achieved by forward filtering and then backward smoothing algorithms. In the filtering algorithm, we sequentially estimate the state of population activity at time bin <italic>t</italic> given the data up to time <italic>t</italic>. This estimate is given by the recursive Bayesian formula
<disp-formula id="pcbi.1005309.e022"><alternatives><graphic id="pcbi.1005309.e022g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e022" xlink:type="simple"/><mml:math display="block" id="M22"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>t</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>t</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(9)</label></disp-formula>
where <italic>p</italic>(<bold>X</bold><sup><italic>t</italic></sup>|<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>) is obtained from the observation model. The second term in the numerator <italic>p</italic>(<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>|<italic>X</italic><sup>1:<italic>t</italic>−1</sup>, <bold>w</bold>) is called the one-step prediction density. It is computed using the state model and the filter density at the previous time bin via the Chapman-Kolmogorov equation,
<disp-formula id="pcbi.1005309.e023"><alternatives><graphic id="pcbi.1005309.e023g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e023" xlink:type="simple"/><mml:math display="block" id="M23"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mrow><mml:mi>X</mml:mi></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(10)</label></disp-formula>
Thus the filter density (<xref ref-type="disp-formula" rid="pcbi.1005309.e022">Eq 9</xref>) can be recursively computed for <italic>t</italic> = 2, …, <italic>T</italic> using <xref ref-type="disp-formula" rid="pcbi.1005309.e023">Eq 10</xref>, given observation and state models as well as an initial distribution of the one-step prediction density at time <italic>t</italic> = 1. Note that the initial one-step prediction density was specified as <inline-formula id="pcbi.1005309.e024"><alternatives><graphic id="pcbi.1005309.e024g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e024" xlink:type="simple"/><mml:math display="inline" id="M24"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mn>1</mml:mn></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi mathvariant="script">N</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. This distribution dictates the density of the state at the initial time step without observing neural activity.</p>
<p>The approximate nonlinear recursive formulae were developed by approximating the posterior density (<xref ref-type="disp-formula" rid="pcbi.1005309.e022">Eq 9</xref>) with a Gaussian distribution [<xref ref-type="bibr" rid="pcbi.1005309.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref051">51</xref>]. Let us assume that the filter density at time <italic>t</italic> − 1 is given by a Gaussian distribution with mean <bold><italic>θ</italic></bold><sub><italic>t</italic>−1|<italic>t</italic>−1</sub> and the covariance matrix <bold>W</bold><sub><italic>t</italic>−1|<italic>t</italic>−1</sub>. The subscript <italic>t</italic> − 1|<italic>t</italic> − 1 means the estimate at time <italic>t</italic> − 1 (left) given the data up to time bin <italic>t</italic> − 1 (right). Because the state model (<xref ref-type="disp-formula" rid="pcbi.1005309.e012">Eq 3</xref>) is also Gaussian, the Chapman-Kolmogorov equation yields the one-step prediction density that is a Gaussian distribution with mean <bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>t</italic>−1</sub> = <bold><italic>θ</italic></bold><sub><italic>t</italic>−1|<italic>t</italic>−1</sub> and covariance <bold>W</bold><sub><italic>t</italic>|<italic>t</italic>−1</sub> = <bold>W</bold><sub><italic>t</italic>−1|<italic>t</italic>−1</sub> + <bold>Q</bold>. We then obtain the following log posterior density (<xref ref-type="disp-formula" rid="pcbi.1005309.e022">Eq 9</xref>),
<disp-formula id="pcbi.1005309.e025"><alternatives><graphic id="pcbi.1005309.e025g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e025" xlink:type="simple"/><mml:math display="block" id="M25"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo> <mml:mo>=</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:mfenced close="]" open="[" separators=""><mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mi>ψ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>′</mml:mo></mml:msup> <mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>const</mml:mtext> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(11)</label></disp-formula>
Here we approximate the posterior density by a Gaussian distribution (the Laplace approximation). We identify the mean of this distribution with the MAP estimate:
<disp-formula id="pcbi.1005309.e026"><alternatives><graphic id="pcbi.1005309.e026g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e026" xlink:type="simple"/><mml:math display="block" id="M26"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mtext>argmax</mml:mtext> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:msub> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(12)</label></disp-formula>
This solution is called a filter mean. It may be obtained by gradient ascent algorithms such as the conjugate gradient algorithm and the Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm. These algorithms use the gradient
<disp-formula id="pcbi.1005309.e027"><alternatives><graphic id="pcbi.1005309.e027g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e027" xlink:type="simple"/><mml:math display="block" id="M27"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:mfenced close="]" open="[" separators=""><mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mfenced> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(13)</label></disp-formula>
Here we define the expectation parameters <bold><italic>η</italic></bold><sub><italic>t</italic></sub> as
<disp-formula id="pcbi.1005309.e028"><alternatives><graphic id="pcbi.1005309.e028g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e028" xlink:type="simple"/><mml:math display="block" id="M28"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>≡</mml:mo> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mi>ψ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:msub> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(14)</label></disp-formula>
where 〈<bold>x</bold>〉<sub><bold><italic>θ</italic></bold><sub><italic>t</italic></sub></sub> is the expectation of <bold>x</bold> with respect to <italic>p</italic>(<bold>x</bold>|<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>). This expectation needs to be computed repeatedly in the gradient algorithms. The covariance matrix of the approximated Gaussian distribution is computed from the Hessian of the log posterior evaluated at the MAP estimate:
<disp-formula id="pcbi.1005309.e029"><alternatives><graphic id="pcbi.1005309.e029g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e029" xlink:type="simple"/><mml:math display="block" id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mo>=</mml:mo> <mml:mrow><mml:mo>-</mml:mo> <mml:msub><mml:mfenced close="|" open="" separators=""><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mi>∂</mml:mi> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mfrac></mml:mfenced> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"/> <mml:mtd columnalign="left"><mml:mo>=</mml:mo> <mml:mrow><mml:mi>R</mml:mi> <mml:msub><mml:mi mathvariant="bold">G</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(15)</label></disp-formula> <bold>G</bold><sub><italic>t</italic></sub> is the Fisher-information matrix:
<disp-formula id="pcbi.1005309.e030"><alternatives><graphic id="pcbi.1005309.e030g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e030" xlink:type="simple"/><mml:math display="block" id="M30"><mml:mrow><mml:msub><mml:mi mathvariant="bold">G</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>≡</mml:mo> <mml:msub><mml:mfenced close="|" open="" separators=""><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mi>ψ</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mi>∂</mml:mi> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mfrac></mml:mfenced> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi mathvariant="bold">F</mml:mi> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>′</mml:mo></mml:msup> <mml:mo>〉</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub> <mml:msubsup><mml:mrow><mml:mo>〈</mml:mo> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>〉</mml:mo></mml:mrow> <mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(16)</label></disp-formula>
The expectations are taken by <italic>p</italic>(<bold>x</bold>|<bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>t</italic></sub>). Note that we initially assumed that the filter density at previous time step is a Gaussian distribution when computing the Chapman-Kolmogorov equation. By the Laplace approximation, this assumption is fulfilled in the next time step. Additionally we assumed that the initial distribution of the state variables is Gaussian. Thus we obtain an approximate nonlinear recursive filter that is consistent across the iterations.</p>
<p>Once the approximate filter density is constructed for <italic>t</italic> = 1, …, <italic>T</italic>, the backward smoothing algorithm is applied to obtain the smoothed posterior density of the state variable at time <italic>t</italic> [<xref ref-type="bibr" rid="pcbi.1005309.ref032">32</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref052">52</xref>],
<disp-formula id="pcbi.1005309.e031"><alternatives><graphic id="pcbi.1005309.e031g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e031" xlink:type="simple"/><mml:math display="block" id="M31"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>∫</mml:mo> <mml:mfrac><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mrow><mml:mi mathvariant="bold-italic">X</mml:mi></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mfrac> <mml:mi>d</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(17)</label></disp-formula>
for <italic>t</italic> = <italic>T</italic>, …, 1. In practice, the following fixed interval smoothing algorithm [<xref ref-type="bibr" rid="pcbi.1005309.ref032">32</xref>] provides the smoothed MAP estimate <bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>T</italic></sub> and smoothed covariance <bold>W</bold><sub><italic>t</italic>|<italic>T</italic></sub> of the posterior distribution
<disp-formula id="pcbi.1005309.e032"><alternatives><graphic id="pcbi.1005309.e032g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e032" xlink:type="simple"/><mml:math display="block" id="M32"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(18)</label></disp-formula> <disp-formula id="pcbi.1005309.e033"><alternatives><graphic id="pcbi.1005309.e033g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e033" xlink:type="simple"/><mml:math display="block" id="M33"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:msubsup><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(19)</label></disp-formula>
where <inline-formula id="pcbi.1005309.e034"><alternatives><graphic id="pcbi.1005309.e034g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e034" xlink:type="simple"/><mml:math display="inline" id="M34"><mml:mrow><mml:msub><mml:mi mathvariant="bold">A</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:msub><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>+</mml:mo> <mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. In addition, the posterior covariance matrix between state variables at time <italic>t</italic> and <italic>t</italic> − 1 is obtained as <bold>W</bold><sub><italic>t</italic>−1, <italic>t</italic>|<italic>T</italic></sub> = <bold>A</bold><sub><italic>t</italic>−1</sub> <bold>W</bold><sub><italic>t</italic>|<italic>T</italic></sub> [<xref ref-type="bibr" rid="pcbi.1005309.ref053">53</xref>]. This procedure constructs the smoother posterior density of the latent process (<xref ref-type="disp-formula" rid="pcbi.1005309.e015">Eq 4</xref>) by approximating it as a Gaussian process of length <italic>N</italic>(<italic>N</italic> + 1)/2 × <italic>T</italic> with mean <inline-formula id="pcbi.1005309.e035"><alternatives><graphic id="pcbi.1005309.e035g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e035" xlink:type="simple"/><mml:math display="inline" id="M35"><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mn>2</mml:mn> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>,</mml:mo> <mml:mo>…</mml:mo> <mml:mo>,</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>T</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and a block tridiagonal covariance matrix whose block diagonal is given by <bold>W</bold><sub><italic>t</italic>|<italic>T</italic></sub> (for <italic>t</italic> = 1, …, <italic>T</italic>), and block off-diagonals are given by <bold>W</bold><sub><italic>t</italic>−1,<italic>t</italic>|<italic>T</italic></sub> (for <italic>t</italic> = 2, …, <italic>T</italic>).</p>
</sec>
</sec>
<sec id="sec008">
<title>Approximation methods for large-scale analysis</title>
<sec id="sec009">
<title>Approximate estimate of filter mean by pseudolikelihood method</title>
<p>To obtain the filter estimate using iterative gradient ascent methods, the gradient (<xref ref-type="disp-formula" rid="pcbi.1005309.e027">Eq 13</xref>) needs to be evaluated at each iteration. This requires computation of the expectations (<xref ref-type="disp-formula" rid="pcbi.1005309.e028">Eq 14</xref>) by summing over all 2<sup><italic>N</italic></sup> states the network can realize. This is infeasible for a large network size <italic>N</italic>. Thus the method introduced in the previous subsection was limited to <italic>N</italic> ≤ 15. However, the <italic>pseudolikelihood</italic> method [<xref ref-type="bibr" rid="pcbi.1005309.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref054">54</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref055">55</xref>] has been shown to estimate with reasonable accuracy the interactions without requiring evaluation of the expectations. Here we incorporate it into the sequential Bayesian estimation framework.</p>
<p>The pseudolikelihood approximates the likelihood of the joint activity of neurons by a product of conditional likelihoods of each neuron given the activity of the others. Let the activity of neurons except neuron <italic>n</italic> be <bold>x</bold><sub>∖<italic>n</italic></sub> = (<italic>x</italic><sub>1</sub>, …, <italic>x</italic><sub><italic>n</italic>−1</sub>, <italic>x</italic><sub><italic>n</italic>+1</sub>, …, <italic>x</italic><sub><italic>N</italic></sub>)′; and <inline-formula id="pcbi.1005309.e036"><alternatives><graphic id="pcbi.1005309.e036g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e036" xlink:type="simple"/><mml:math display="inline" id="M36"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi> <mml:mi>t</mml:mi> <mml:mi>n</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>\</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>n</mml:mi></mml:msub> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold">x</mml:mi> <mml:mrow><mml:mo>\</mml:mo> <mml:mi>n</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Then the pseudolikelihood is given by
<disp-formula id="pcbi.1005309.e037"><alternatives><graphic id="pcbi.1005309.e037g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e037" xlink:type="simple"/><mml:math display="block" id="M37"><mml:mrow><mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:mover accent="true"><mml:mi>p</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:mi>p</mml:mi> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>X</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msubsup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>\</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup> <mml:mo>,</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mfenced> <mml:mo>=</mml:mo> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:munderover><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:mfrac><mml:mrow><mml:mo form="prefix">exp</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>X</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>f</mml:mi> <mml:mi>t</mml:mi> <mml:mi>n</mml:mi></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>\</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mfenced></mml:mfenced></mml:mrow> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>f</mml:mi> <mml:mi>t</mml:mi> <mml:mi>n</mml:mi></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>\</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mfenced></mml:mfenced></mml:mrow></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(20)</label></disp-formula>
Note that the log partition function does not appear in <xref ref-type="disp-formula" rid="pcbi.1005309.e037">Eq 20</xref>. Replacing the likelihood in <xref ref-type="disp-formula" rid="pcbi.1005309.e022">Eq 9</xref> with <xref ref-type="disp-formula" rid="pcbi.1005309.e037">Eq 20</xref> yields
<disp-formula id="pcbi.1005309.e038"><alternatives><graphic id="pcbi.1005309.e038g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e038" xlink:type="simple"/><mml:math display="block" id="M38"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo> <mml:mo>≈</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:mfenced close="]" open="[" separators=""><mml:msubsup><mml:mi>X</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>f</mml:mi> <mml:mi>t</mml:mi> <mml:mi>n</mml:mi></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>\</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:mo>-</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>f</mml:mi> <mml:mi>t</mml:mi> <mml:mi>n</mml:mi></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>\</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mfenced></mml:mfenced></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>′</mml:mo></mml:msup> <mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:mtext>const.</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(21)</label></disp-formula>
The derivative of this approximated filter density results in
<disp-formula id="pcbi.1005309.e039"><alternatives><graphic id="pcbi.1005309.e039g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e039" xlink:type="simple"/><mml:math display="block" id="M39"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:mo form="prefix">log</mml:mo> <mml:mi>p</mml:mi> <mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac> <mml:mo>≈</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>n</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:mfenced close="]" open="[" separators=""><mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>X</mml:mi> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:msubsup><mml:mover accent="true"><mml:mi>η</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msubsup><mml:mi>f</mml:mi> <mml:mi>t</mml:mi> <mml:mi>n</mml:mi></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mfenced> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(22)</label></disp-formula>
where <inline-formula id="pcbi.1005309.e040"><alternatives><graphic id="pcbi.1005309.e040g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e040" xlink:type="simple"/><mml:math display="inline" id="M40"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>η</mml:mi> <mml:mo>˜</mml:mo></mml:mover> <mml:mi>n</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:msubsup><mml:mi>x</mml:mi> <mml:mi>n</mml:mi> <mml:mi>t</mml:mi></mml:msubsup> <mml:mrow><mml:mo>|</mml:mo></mml:mrow> <mml:msubsup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mo>\</mml:mo> <mml:mi>n</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msubsup> <mml:mo>〉</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, i.e., the expectation of <inline-formula id="pcbi.1005309.e041"><alternatives><graphic id="pcbi.1005309.e041g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e041" xlink:type="simple"/><mml:math display="inline" id="M41"><mml:msubsup><mml:mi>x</mml:mi> <mml:mi>n</mml:mi> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> being 1 given the activity of the other neurons. Using this gradient in the same gradient ascent algorithms as before we obtain the approximate mean <bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>t</italic></sub> of the filter density.</p>
</sec>
<sec id="sec010">
<title>Approximation of the filter covariance</title>
<p>The pseudolikelihood can provide the approximate mode of the filter density (<xref ref-type="disp-formula" rid="pcbi.1005309.e026">Eq 12</xref>). However, to perform the sequential estimation, we need in addition the filter covariance matrix (<xref ref-type="disp-formula" rid="pcbi.1005309.e029">Eq 15</xref>). This requires to compute the Fisher information matrix (<xref ref-type="disp-formula" rid="pcbi.1005309.e030">Eq 16</xref>, i.e., the Hessian of the observation model at the filter mean <bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>t</italic></sub>). To compute the Fisher information matrix, not only the first and second order but also the third and fourth order expectation parameters need to be evaluated at the filter mean parameters. In order to avoid computing the higher-order expectation parameters and to reduce the computational cost of the matrix inversion, we approximate it by a diagonal matrix. The diagonal is composed of the first and second order expectation parameters <inline-formula id="pcbi.1005309.e042"><alternatives><graphic id="pcbi.1005309.e042g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e042" xlink:type="simple"/><mml:math display="inline" id="M42"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>, where the expectations parameters are defined as <inline-formula id="pcbi.1005309.e043"><alternatives><graphic id="pcbi.1005309.e043g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e043" xlink:type="simple"/><mml:math display="inline" id="M43"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>≡</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>〉</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005309.e044"><alternatives><graphic id="pcbi.1005309.e044g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e044" xlink:type="simple"/><mml:math display="inline" id="M44"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>≡</mml:mo> <mml:msub><mml:mrow><mml:mo>〈</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>〉</mml:mo></mml:mrow> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Here we test two different approximation methods to obtain these marginals. One is the <italic>Bethe approximation</italic> [<xref ref-type="bibr" rid="pcbi.1005309.ref056">56</xref>] and the other the mean-field <italic>Thouless-Anderson-Palmer</italic> (<italic>TAP</italic>) approach [<xref ref-type="bibr" rid="pcbi.1005309.ref057">57</xref>].</p>
<p><italic>Bethe approximation.</italic> The Bethe approach approximates a probability distribution by assuming that it factorizes into its pairwise marginals. Hence, the approximated joint distribution writes as
<disp-formula id="pcbi.1005309.e045"><alternatives><graphic id="pcbi.1005309.e045g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e045" xlink:type="simple"/><mml:math display="block" id="M45"><mml:mrow><mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>≈</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mo>∏</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>,</mml:mo> <mml:mi>j</mml:mi> <mml:mo>&gt;</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:msub> <mml:msub><mml:mi>q</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>,</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mrow><mml:msub><mml:mo>∏</mml:mo> <mml:mi>i</mml:mi></mml:msub> <mml:msub><mml:mi>q</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi>x</mml:mi> <mml:mi>i</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>N</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac> <mml:mo>:</mml:mo> <mml:mo>=</mml:mo> <mml:msub><mml:mi>q</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(23)</label></disp-formula>
where <italic>q</italic> are so-called <italic>beliefs</italic> [<xref ref-type="bibr" rid="pcbi.1005309.ref058">58</xref>] that approximate the marginals of the underlying distribution <italic>p</italic>. Note that for any acyclic graph this yields the true joint distribution. However, here the observation model (<xref ref-type="disp-formula" rid="pcbi.1005309.e006">Eq 1</xref>) is a fully connected graph and hence the Bethe approximation ignores all cycles. Realizing that the beliefs have to fulfill constraints (∑<sub><italic>x</italic><sub><italic>j</italic></sub></sub> <italic>q</italic><sub><italic>t</italic></sub>(<italic>x</italic><sub><italic>i</italic></sub>, <italic>x</italic><sub><italic>j</italic></sub>) = <italic>q</italic><sub><italic>t</italic></sub>(<italic>x</italic><sub><italic>i</italic></sub>) and ∑<sub><italic>x</italic><sub><italic>i</italic></sub></sub> <italic>q</italic><sub><italic>t</italic></sub>(<italic>x</italic><sub><italic>i</italic></sub>) = 1) one can write the problem as a Lagrangian that has to be minimized. This allows to derive a dual representation of the marginals (in terms of the Lagrangian multipliers), which in turn allows to derive messages that are sent from one belief to another. Propagating this beliefs through the Markov field yields the belief propagation algorithm (BP) [<xref ref-type="bibr" rid="pcbi.1005309.ref056">56</xref>]. While BP is relatively fast in obtaining the expectation values, it is not guaranteed to converge to an unique solution. This guarantee is provided by the alternative concave-convex procedure (CCCP) [<xref ref-type="bibr" rid="pcbi.1005309.ref059">59</xref>]. CCCP also starts from the same Lagrangian, but updates the beliefs and Lagrangian multipliers in an alternating manner. This more strict procedure comes with the disadvantage that it is much slower than BP. Therefore, here the two algorithms are combined to a <italic>hybrid method</italic>, where BP is utilized primarily and the algorithm falls back to CCCP, when BP does not converge. For more details on the Bethe approximation, see <xref ref-type="supplementary-material" rid="pcbi.1005309.s001">S1 Text</xref>.</p>
<p>The estimation of the log partition function for the Bethe approximation is simply computed by the negative logarithm of the approximated probability (<xref ref-type="disp-formula" rid="pcbi.1005309.e045">Eq 23</xref>) that all neurons are silent, i.e.,
<disp-formula id="pcbi.1005309.e046"><alternatives><graphic id="pcbi.1005309.e046g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e046" xlink:type="simple"/><mml:math display="block" id="M46"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>≈</mml:mo> <mml:mo>-</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:msub><mml:mi>q</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn mathvariant="bold">0</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(24)</label></disp-formula> <italic>TAP approximation.</italic> The TAP approximation of the expectation parameters <italic>η</italic><sub><italic>t</italic>|<italic>t</italic></sub> given the natural parameters <bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>t</italic></sub> (<italic>forward-problem</italic>) can be derived in multiple ways [<xref ref-type="bibr" rid="pcbi.1005309.ref013">13</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref060">60</xref>], but here we follow [<xref ref-type="bibr" rid="pcbi.1005309.ref061">61</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref062">62</xref>] that use the so-called “Plefka expansion”. The following formulae and their derivation are revised for binary variables <italic>x</italic><sub><italic>i</italic></sub> ∈ {0, 1} instead of {−1, 1}. See <xref ref-type="supplementary-material" rid="pcbi.1005309.s002">S2 Text</xref> for more details. The method constructs a new free energy as a function of the mixture coordinates <inline-formula id="pcbi.1005309.e047"><alternatives><graphic id="pcbi.1005309.e047g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e047" xlink:type="simple"/><mml:math display="inline" id="M47"><mml:mrow><mml:mo>(</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>,</mml:mo> <mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> by the Legendre transformation of the log partition function <italic>ψ</italic><sub><italic>t</italic></sub> as <inline-formula id="pcbi.1005309.e048"><alternatives><graphic id="pcbi.1005309.e048g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e048" xlink:type="simple"/><mml:math display="inline" id="M48"><mml:mrow><mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:msubsup> <mml:mrow><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>. Then this function is approximated by a second-order expansion around the independent model assuming weak pairwise interactions. This results in the approximate log partition function,
<disp-formula id="pcbi.1005309.e049"><alternatives><graphic id="pcbi.1005309.e049g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e049" xlink:type="simple"/><mml:math display="block" id="M49"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>≈</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo form="prefix">log</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>+</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mfenced> <mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>8</mml:mn></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mfenced> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(25)</label></disp-formula>
Here we extended the definition of interaction parameters as <inline-formula id="pcbi.1005309.e050"><alternatives><graphic id="pcbi.1005309.e050g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e050" xlink:type="simple"/><mml:math display="inline" id="M50"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005309.e051"><alternatives><graphic id="pcbi.1005309.e051g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e051" xlink:type="simple"/><mml:math display="inline" id="M51"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>j</mml:mi> <mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>. At the independent model, the values for the expectations can be computed and the expansion yields correction terms for the non-zero <inline-formula id="pcbi.1005309.e052"><alternatives><graphic id="pcbi.1005309.e052g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e052" xlink:type="simple"/><mml:math display="inline" id="M52"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. Since derivatives of the new free energy based on the mixture coordinates w.r.t. <inline-formula id="pcbi.1005309.e053"><alternatives><graphic id="pcbi.1005309.e053g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e053" xlink:type="simple"/><mml:math display="inline" id="M53"><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> yield the first order parameters <inline-formula id="pcbi.1005309.e054"><alternatives><graphic id="pcbi.1005309.e054g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e054" xlink:type="simple"/><mml:math display="inline" id="M54"><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>, we obtain the following self-consistent equations:
<disp-formula id="pcbi.1005309.e055"><alternatives><graphic id="pcbi.1005309.e055g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e055" xlink:type="simple"/><mml:math display="block" id="M55"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mfenced> <mml:mo>-</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:munder> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:msub><mml:mi>η</mml:mi> <mml:mi>j</mml:mi></mml:msub> <mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munder><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>j</mml:mi> <mml:mo>≠</mml:mo> <mml:mi>i</mml:mi></mml:mrow></mml:munder> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:msup><mml:mrow><mml:mo>(</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow> <mml:mn>2</mml:mn></mml:msup></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(26)</label></disp-formula>
for <italic>i</italic>, <italic>j</italic> = 1, …, <italic>N</italic>. Solving this equations yields the first order expectations which can be used to estimate the log partition function (<xref ref-type="disp-formula" rid="pcbi.1005309.e049">Eq 25</xref>).</p>
<p>Furthermore, from the relation <inline-formula id="pcbi.1005309.e056"><alternatives><graphic id="pcbi.1005309.e056g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e056" xlink:type="simple"/><mml:math display="inline" id="M56"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>∂</mml:mi> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mi mathvariant="bold">G</mml:mi> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></alternatives></inline-formula> we obtain
<disp-formula id="pcbi.1005309.e057"><alternatives><graphic id="pcbi.1005309.e057g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e057" xlink:type="simple"/><mml:math display="block" id="M57"><mml:mrow><mml:msub><mml:mrow><mml:mo>[</mml:mo> <mml:msubsup><mml:mi mathvariant="bold">G</mml:mi> <mml:mi>t</mml:mi> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mo>]</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:msub><mml:mi>δ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>-</mml:mo> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:mn>2</mml:mn></mml:msup> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:mfenced close=")" open="(" separators=""><mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mfenced> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(27)</label></disp-formula>
Here <italic>δ</italic><sub><italic>ij</italic></sub> is the Kronecker delta function, which is 1 for <italic>i</italic> = <italic>j</italic> and 0 otherwise. To obtain the second order expectation parameters, we calculate and then invert the <italic>N</italic> × <italic>N</italic> matrix obtained by <xref ref-type="disp-formula" rid="pcbi.1005309.e057">Eq 27</xref>, and approximate it as the Fisher information matrix for {<italic>θ</italic><sub><italic>i</italic></sub>} given in <xref ref-type="disp-formula" rid="pcbi.1005309.e030">Eq 16</xref> to obtain the second order expectation parameters by <inline-formula id="pcbi.1005309.e058"><alternatives><graphic id="pcbi.1005309.e058g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e058" xlink:type="simple"/><mml:math display="inline" id="M58"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:mo>=</mml:mo> <mml:msub><mml:mrow><mml:mo>[</mml:mo> <mml:msub><mml:mi mathvariant="bold">G</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>]</mml:mo></mml:mrow> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow></mml:msub> <mml:mo>+</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup> <mml:msubsup><mml:mi>η</mml:mi> <mml:mi>j</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula> [<xref ref-type="bibr" rid="pcbi.1005309.ref061">61</xref>].</p>
<p><italic>Approximate marginal likelihood.</italic> Because the TAP and Bethe approximations provide estimates of the log partition function <italic>ψ</italic><sub><italic>t</italic></sub>, we are able to evaluate the approximation of the marginal likelihood (<xref ref-type="disp-formula" rid="pcbi.1005309.e020">Eq 7</xref>), and the EM-algorithm for the state-space model can be run until it converges. The approximate marginal likelihood is obtained as (see also [<xref ref-type="bibr" rid="pcbi.1005309.ref038">38</xref>])
<disp-formula id="pcbi.1005309.e059"><alternatives><graphic id="pcbi.1005309.e059g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e059" xlink:type="simple"/><mml:math display="block" id="M59"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>l</mml:mi> <mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msup> <mml:mo>|</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mtd> <mml:mtd columnalign="left"><mml:mo>=</mml:mo> <mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:mo form="prefix">log</mml:mo> <mml:mo>∫</mml:mo> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mi>t</mml:mi></mml:msup> <mml:mo>|</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>p</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>|</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mn>1</mml:mn> <mml:mo>:</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msup> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">w</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mi>d</mml:mi> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd columnalign="right"/> <mml:mtd columnalign="left"><mml:mo>≈</mml:mo> <mml:mrow><mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>r</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>R</mml:mi></mml:munderover> <mml:mfenced close="]" open="[" separators=""><mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow> <mml:mo>′</mml:mo></mml:msubsup> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msup><mml:mi mathvariant="bold">X</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>,</mml:mo> <mml:mi>r</mml:mi></mml:mrow></mml:msup> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mfenced></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mspace width="1em"/><mml:mrow><mml:mo>-</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msup><mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfenced> <mml:mo>′</mml:mo></mml:msup> <mml:msubsup><mml:mi mathvariant="bold">W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mrow><mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msubsup> <mml:mfenced close=")" open="(" separators=""><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mfenced></mml:mrow></mml:mtd></mml:mtr> <mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mspace width="1em"/><mml:mrow><mml:mo>+</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mn>2</mml:mn></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:mfenced close=")" open="(" separators=""><mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>-</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:mrow><mml:mo form="prefix" movablelimits="true">det</mml:mo> <mml:msub><mml:mi>W</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>t</mml:mi> <mml:mo>-</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced> <mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives> <label>(28)</label></disp-formula>
where <italic>p</italic>(<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>|<bold>X</bold><sup>1:0</sup>, <bold>w</bold>) indicates a prior of the initial distribution <inline-formula id="pcbi.1005309.e060"><alternatives><graphic id="pcbi.1005309.e060g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e060" xlink:type="simple"/><mml:math display="inline" id="M60"><mml:mrow><mml:mi mathvariant="script">N</mml:mi> <mml:mo>(</mml:mo> <mml:mi mathvariant="bold-italic">μ</mml:mi> <mml:mo>,</mml:mo> <mml:mi mathvariant="bold">Σ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula>. Similarly, we use <bold><italic>θ</italic></bold><sub>1|0</sub> = <bold><italic>μ</italic></bold> and <bold>W</bold><sub>1|0</sub> = <bold>Σ</bold>. Here the integral with respect to <bold><italic>θ</italic></bold><sub><italic>t</italic></sub> at the first equality is approximated as an integral of a Gaussian function, using up to the quadratic information around its mode (the Laplace approximation). From Eqs <xref ref-type="disp-formula" rid="pcbi.1005309.e025">11</xref> and <xref ref-type="disp-formula" rid="pcbi.1005309.e026">12</xref>, it turns out that the mean and covariance of the filter density provide this information.</p>
</sec>
</sec>
</sec>
<sec id="sec011" sec-type="results">
<title>Results</title>
<sec id="sec012">
<title>Model fit to simulated data</title>
<p>In the following subsections, we demonstrate the fit of the state-space model of neural population activity to artificially generated data of 40 neurons with dynamic couplings for <italic>T</italic> = 500 time bins. To be able to compare it to the ground truth we construct 4 populations each consisting of 10 neurons. Individual parameters <bold><italic>θ</italic></bold><sub>1:<italic>T</italic></sub> of the underlying submodels are generated as smooth independent Gaussian processes, where the mean for the first order parameters <inline-formula id="pcbi.1005309.e061"><alternatives><graphic id="pcbi.1005309.e061g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e061" xlink:type="simple"/><mml:math display="inline" id="M61"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> increases at <italic>t</italic> = 100 and then decreases more slowly shortly after that. The interaction parameters <inline-formula id="pcbi.1005309.e062"><alternatives><graphic id="pcbi.1005309.e062g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e062" xlink:type="simple"/><mml:math display="inline" id="M62"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> are generated as Gaussian processes whose mean is fixed at 0. In total, 500 trials of spike data are sampled from this generative model. Note that the sampled individual parameters differ and vary over time although we use homogeneous means. The increase of the mean for <inline-formula id="pcbi.1005309.e063"><alternatives><graphic id="pcbi.1005309.e063g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e063" xlink:type="simple"/><mml:math display="inline" id="M63"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> increases spiking probability followed by a decrease back to baseline (<xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>A</bold></xref>). In the resulting data neurons spike with time averaged probabilities ranging from 0.10 up to 0.21. Supposing bin width Δ = 10 ms these are in a physiologically reasonable range. This exemplary scenario may mimic a population that independently receives an external input elicited by e.g., a sensory stimulus. For details of the generation of the data see <xref ref-type="supplementary-material" rid="pcbi.1005309.s003">S3 Text</xref>.</p>
<fig id="pcbi.1005309.g001" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005309.g001</object-id>
<label>Fig 1</label>
<caption>
<title>Approximate inference of dynamic neural interactions and macroscopic network properties.</title>
<p>Analysis on simulated spike data of 40 neurons. <bold>A</bold> Top: Simultaneous spiking activity of 40 neurons that are repeatedly simulated 500 times (here only 3 trials are visualized). The data is sampled from a time-dependent model of a neural population (<xref ref-type="disp-formula" rid="pcbi.1005309.e006">Eq 1</xref>). The time-varying parameters are chosen such that neurons’ spike probability resembles evoked activity in response to stimulus presentation to an animal. The neural interactions are assumed to smoothly change irrespective of the firing rates. See the main text for details. Bottom: Empirical spike probability over time, averaged over trials and neurons. <bold>B</bold> Top: Estimated network states at <italic>t</italic> = 50, 150, 300 by the pseudolikelihood-Bethe approximation method. Neurons are represented by nodes whose colors respectively indicate a value of the smoothed estimate of <inline-formula id="pcbi.1005309.e064"><alternatives><graphic id="pcbi.1005309.e064g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e064" xlink:type="simple"/><mml:math display="inline" id="M64"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (for <italic>i</italic> = 1, …, 40). Links are color-coded according to estimated strength of the interaction <inline-formula id="pcbi.1005309.e065"><alternatives><graphic id="pcbi.1005309.e065g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e065" xlink:type="simple"/><mml:math display="inline" id="M65"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> between connected nodes (positive or negative interactions are marked in red or blue, respectively). Only significant edges are displayed, where the corresponding <inline-formula id="pcbi.1005309.e066"><alternatives><graphic id="pcbi.1005309.e066g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e066" xlink:type="simple"/><mml:math display="inline" id="M66"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> has a 98% credible interval that does not include 0. Bottom: Dynamics of 3 exemplary interaction parameters, <inline-formula id="pcbi.1005309.e067"><alternatives><graphic id="pcbi.1005309.e067g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e067" xlink:type="simple"/><mml:math display="inline" id="M67"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula>. The lines denote the ground truth from which the binary data are sampled. The shaded areas are 98% credible intervals. <bold>C</bold> Estimated population rate (top left). Probability that all neurons are silent (bottom left). Entropy (top right) and heat capacity (bottom right) of the neural population. In all panels, shaded areas indicate 1% and 99% quantiles obtained by resampling the natural parameters from the fitted smoothed distribution. Solid lines represent ground truth computed from the underlying network model.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.g001" xlink:type="simple"/>
</fig>
<p>Next we fit the state-space model of neural population activity to the generated data with the combination of pseudolikelihood and Bethe approximation. This combination is chosen for the demonstration because it provides the best estimates of the underlying model as we will assess later in this section. Top panel of <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>B</bold></xref> shows snapshots of the smoothed estimates of the inferred network at different time points (<italic>t</italic> = 50, 150, 300). The color of the nodes indicate the smoothed estimates of the first order parameters <inline-formula id="pcbi.1005309.e068"><alternatives><graphic id="pcbi.1005309.e068g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e068" xlink:type="simple"/><mml:math display="inline" id="M68"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and the one of the edges interactions <inline-formula id="pcbi.1005309.e069"><alternatives><graphic id="pcbi.1005309.e069g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e069" xlink:type="simple"/><mml:math display="inline" id="M69"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. Visual inspection of the fitted network suffices to identify that there are 4 independent subpopulations of correlated neurons (one in each quadrant). To check whether the inferred changes over time match those of the underlying generative model, credible intervals of three fitted couplings are compared with their underlying values (<xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>B</bold></xref> Bottom). The fit follows the dynamics, and correctly identifies the parameter that is constantly 0 (the lowest panel).</p>
</sec>
<sec id="sec013">
<title>Estimating macroscopic properties of the network</title>
<p>One of the main motives to model joint activities of a large population of neurons is to assess macroscopic properties of the network in a time-dependent manner with credible intervals. The macroscopic measures obtained for this example are shown in <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>C</bold></xref>, and in the following we introduce them one by one.</p>
<p>The first and simplest macroscopic property shown in the top left panel of <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>C</bold></xref> is the probability of spiking in a network (population spike rate). We define it as
<disp-formula id="pcbi.1005309.e070"><alternatives><graphic id="pcbi.1005309.e070g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e070" xlink:type="simple"/><mml:math display="block" id="M70"><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mtext>spike</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mn>1</mml:mn> <mml:mi>N</mml:mi></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>i</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>N</mml:mi></mml:munderover> <mml:msubsup><mml:mi>η</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(29)</label></disp-formula>
where <inline-formula id="pcbi.1005309.e071"><alternatives><graphic id="pcbi.1005309.e071g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e071" xlink:type="simple"/><mml:math display="inline" id="M71"><mml:msubsup><mml:mi>η</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> is the spike rate of <italic>i</italic>th neuron at time <italic>t</italic>. Considering the smoothed estimate <inline-formula id="pcbi.1005309.e072"><alternatives><graphic id="pcbi.1005309.e072g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e072" xlink:type="simple"/><mml:math display="inline" id="M72"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:msubsup><mml:mi>η</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:math></alternatives></inline-formula>, the method recovers correctly the empirical rate obtained from the data (<xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>A</bold></xref> Bottom). The shaded area in the panel indicates the 98% credible interval of the population spike rate obtained by resampling the natural parameters from the smoothed posterior density 100 times at each bin. The underlying spike probability for <italic>N</italic> = 40 neurons is obtained by calculating the marginals <inline-formula id="pcbi.1005309.e073"><alternatives><graphic id="pcbi.1005309.e073g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e073" xlink:type="simple"/><mml:math display="inline" id="M73"><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> independently for each subpopulation and averaging over all neurons.</p>
<p>Next from the state-space model of neural population activity one can estimate the probability of simultaneous silence (i.e., the probability that no neuron elicits a spike, <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>C</bold></xref> bottom left)
<disp-formula id="pcbi.1005309.e074"><alternatives><graphic id="pcbi.1005309.e074g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e074" xlink:type="simple"/><mml:math display="block" id="M74"><mml:mrow><mml:msub><mml:mi>p</mml:mi> <mml:mtext>silence</mml:mtext></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mo>-</mml:mo> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(30)</label></disp-formula>
The approximation methods allow us to evaluate the log partition function <italic>ψ</italic><sub><italic>t</italic></sub> (Eqs <xref ref-type="disp-formula" rid="pcbi.1005309.e046">24</xref> and <xref ref-type="disp-formula" rid="pcbi.1005309.e049">25</xref>). Here we use smoothed estimates to compute the log partition function. Thus we immediately obtain the probability of simultaneous silence. The expected simultaneous silence for <italic>N</italic> = 40 neurons is obtained as multiplication of the silence probabilities of the 4 subpopulations.</p>
<p>The entropy of the network (i.e., expectation of the information content, 〈−log <italic>p</italic>(<bold>x</bold>|<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>)〉<sub><bold><italic>θ</italic></bold><sub><italic>t</italic></sub></sub>) can be also calculated from the model as
<disp-formula id="pcbi.1005309.e075"><alternatives><graphic id="pcbi.1005309.e075g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e075" xlink:type="simple"/><mml:math display="block" id="M75"><mml:mrow><mml:mi>S</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo>-</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(31)</label></disp-formula>
Estimation of this information theoretic measure allows us to quantify the amount of interactions in the network by comparing the pairwise model to the independent one (see following analyses and <xref ref-type="disp-formula" rid="pcbi.1005309.e090">Eq 36</xref>). Since it is an extensive quantity, the entropy of <italic>N</italic> = 40 neurons is obtained by addition of the entropies from the 4 independent subpopulations. The entropy increases while the individual activity rates of neurons also increases (<xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>C</bold></xref> top right).</p>
<p>The last measure shown in the bottom right panel of <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>C</bold></xref> is the heat capacity, or sensitivity, of the system. It is the variance of information content: <italic>C</italic>(<italic>t</italic>) = 〈{−log <italic>p</italic>(<bold>x</bold>|<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>)}<sup>2</sup>〉<sub><bold><italic>θ</italic></bold><sub><italic>t</italic></sub></sub> − {〈−log <italic>p</italic>(<bold>x</bold>|<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>)〉<sub><bold><italic>θ</italic></bold><sub><italic>t</italic></sub></sub>}<sup>2</sup>, where the brackets indicate expectation by <italic>p</italic>(<bold>x</bold>|<bold><italic>θ</italic></bold><sub><italic>t</italic></sub>). It is also the variance of the Hamiltonian <inline-formula id="pcbi.1005309.e076"><alternatives><graphic id="pcbi.1005309.e076g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e076" xlink:type="simple"/><mml:math display="inline" id="M76"><mml:mrow><mml:mo>-</mml:mo> <mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. Thus we can obtain it by introducing a nominal dual parameter <italic>β</italic> to the Hamiltonian in the model, assuming that it is 1 for real data. The log partition function of the augmented model is
<disp-formula id="pcbi.1005309.e077"><alternatives><graphic id="pcbi.1005309.e077g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e077" xlink:type="simple"/><mml:math display="block" id="M77"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>β</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mo form="prefix">log</mml:mo> <mml:munder><mml:mo>∑</mml:mo> <mml:mi mathvariant="bold">x</mml:mi></mml:munder> <mml:mo form="prefix">exp</mml:mo> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>β</mml:mi> <mml:mspace width="0.166667em"/><mml:msubsup><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi> <mml:mo>′</mml:mo></mml:msubsup> <mml:mi mathvariant="bold">F</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi mathvariant="bold">x</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(32)</label></disp-formula>
The variance of Hamiltonian is given as the Fisher information w.r.t. <italic>β</italic>, i.e., the second derivative of the log partition function. This allows us to use the approximate <italic>ψ</italic><sub><italic>t</italic></sub> to assess the heat capacity. Then we further approximate the second derivative by its discrete version
<disp-formula id="pcbi.1005309.e078"><alternatives><graphic id="pcbi.1005309.e078g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e078" xlink:type="simple"/><mml:math display="block" id="M78"><mml:mrow><mml:mi>C</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:mi>t</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msub><mml:mfenced close="|" open="" separators=""><mml:mfrac><mml:mrow><mml:msup><mml:mi>∂</mml:mi> <mml:mn>2</mml:mn></mml:msup> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mrow> <mml:mrow><mml:mi>∂</mml:mi> <mml:msup><mml:mi>β</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mfenced> <mml:mrow><mml:mi>β</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow></mml:msub> <mml:mo>≈</mml:mo> <mml:mfrac><mml:mrow><mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>+</mml:mo> <mml:mi>ϵ</mml:mi> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>-</mml:mo> <mml:mn>2</mml:mn> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>+</mml:mo> <mml:msub><mml:mi>ψ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mrow><mml:mo>(</mml:mo> <mml:mn>1</mml:mn> <mml:mo>-</mml:mo> <mml:mi>ϵ</mml:mi> <mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:msup><mml:mi>ϵ</mml:mi> <mml:mn>2</mml:mn></mml:msup></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(33)</label></disp-formula>
and <italic>ϵ</italic> is chosen to be 10<sup>−3</sup>. The heat capacity measures sensitivity of the network, namely how much the network activity changes due to subtle changes in its network configuration (i.e., to changes of the <bold><italic>θ</italic></bold><sub><italic>t</italic></sub> parameters). Networks with higher sensitivity are more responsive to changes than those with lower sensitivity. Similarly to the entropy, the heat capacity is an extensive quantity. For the simulated data, the heat capacity decreases while activity rates of neurons are increased (<xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1<bold>C</bold></xref> bottom right).</p>
</sec>
<sec id="sec014">
<title>Assessment of fitting error with different network sizes and amount of data</title>
<p>Next we examine the goodness-of-fit of the model fitted by the pseudolikelihood and Bethe approximation methods. In particular, we ask how the fitting performance changes with increasing network size. For this reason we generated 6 dynamic models for populations of 10 neurons as described previously (500 time bins, 500 trials). Then we construct smaller or larger populations by concatenating the independent groups. The model is fitted by the pseudolikelihood and Bethe approximation methods to the first subnetwork, then two subnetworks, and so on, until we fit the model to a network containing 60 neurons composed of 6 independent groups. We obtain estimates of the macroscopic measures from the smoothed estimates of the model parameters at each time bin. <xref ref-type="fig" rid="pcbi.1005309.g002">Fig 2<bold>A</bold></xref> shows values of these measures averaged over time. The results show extensive properties of macroscopic measures (except for the population spike rate), and that the estimates may slightly deviate for larger number of neurons.</p>
<fig id="pcbi.1005309.g002" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005309.g002</object-id>
<label>Fig 2</label>
<caption>
<title>Approximation error and network size.</title>
<p>Error analysis on networks consisting of subpopulations with 10 neurons, constructed by the same procedure as in <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1</xref>. <bold>A</bold>: The average value of the macroscopic properties over time as a function of network size. Black line is the true value, while colored lines show the estimated ones (solid line fit with 500 trials and dashed with 1000 trials) <bold>B</bold>: The corresponding errors (only for <bold><italic>θ</italic></bold><sub><italic>t</italic></sub> the RMSE is shown) for 500 trials (solid) and 1000 trials (dashed).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.g002" xlink:type="simple"/>
</fig>
<p>To assess quality of the fit, first the root mean squared error (RMSE) for the natural parameters averaged across time bins is calculated
<disp-formula id="pcbi.1005309.e079"><alternatives><graphic id="pcbi.1005309.e079g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e079" xlink:type="simple"/><mml:math display="block" id="M79"><mml:mrow><mml:mtext>RMSE</mml:mtext> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>T</mml:mi></mml:mfrac> <mml:munderover><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:munderover> <mml:msup><mml:mfenced close="∥" open="∥" separators=""><mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub></mml:mfenced> <mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(34)</label></disp-formula>
where <bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>T</italic></sub> is the smoothed estimate of the underlying model <bold><italic>θ</italic></bold><sub><italic>t</italic></sub>. ‖<italic>v</italic>‖ denotes the <italic>L</italic>2-norm of vector <italic>v</italic>. For the data sets with 500 trials, the RMSE increases linearly with network size (<xref ref-type="fig" rid="pcbi.1005309.g002">Fig 2<bold>B</bold></xref> Left). Furthermore, the error for the macroscopic measures is assessed by
<disp-formula id="pcbi.1005309.e080"><alternatives><graphic id="pcbi.1005309.e080g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e080" xlink:type="simple"/><mml:math display="block" id="M80"><mml:mrow><mml:mtext>Error</mml:mtext> <mml:mrow><mml:mo>[</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow> <mml:mo>=</mml:mo> <mml:mfrac><mml:mrow><mml:mtext>RMSE</mml:mtext> <mml:mo>(</mml:mo> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>)</mml:mo></mml:mrow> <mml:mrow><mml:mfrac><mml:mn>1</mml:mn> <mml:mi>T</mml:mi></mml:mfrac> <mml:msubsup><mml:mo>∑</mml:mo> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>=</mml:mo> <mml:mn>1</mml:mn></mml:mrow> <mml:mi>T</mml:mi></mml:msubsup> <mml:mi>f</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mi>t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac> <mml:mo>,</mml:mo></mml:mrow></mml:math></alternatives> <label>(35)</label></disp-formula>
where <italic>f</italic>(<bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>T</italic></sub>) is any function of the macroscopic measures. The RMSE is defined similarly to <xref ref-type="disp-formula" rid="pcbi.1005309.e079">Eq 34</xref> while substituting the parameters <bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>T</italic></sub> by the function <italic>f</italic>(<bold><italic>θ</italic></bold><sub><italic>t</italic>|<italic>T</italic></sub>). Besides the population rate these errors also increase as the network size increases (<xref ref-type="fig" rid="pcbi.1005309.g002">Fig 2<bold>B</bold></xref>). We observe non-monotonic behavior in some of the macroscopic properties (e.g., average spike rate and the entropy’s error), which can be explained by fluctuations from the data generation process.</p>
<p>To understand whether these errors increase primarily due to the approximation methods used for the fit or because of the finite amount of data, the fit is repeated but now to spiking data with 1000 trials. The error of the fit is reduced particularly for larger network size (<xref ref-type="fig" rid="pcbi.1005309.g002">Fig 2<bold>B</bold></xref> dashed lines), suggesting that the limited amount of data is mainly responsible for the estimation error.</p>
<p>In general, the estimation error is largest at time points where the parameters <bold><italic>θ</italic></bold><sub><italic>t</italic></sub> change rapidly. This is a general problem of smoothing algorithms, including spike rate estimation, which depend on fixed smoothness parameter(s) (i.e., here λ) optimized for an entire observation period (see e.g., [<xref ref-type="bibr" rid="pcbi.1005309.ref063">63</xref>] for optimizing a variable smoothness parameter to cope with such abrupt changes).</p>
</sec>
<sec id="sec015">
<title>Comparison between Bethe and TAP approximation</title>
<p>To this end, only the Bethe approximation was used in combination with the pseudolikelihood to fit the model approximately. However, as discussed previously, the TAP approximation constitutes a potential alternative. To assess the quality of both approximations, we investigated a small network (15 neurons, 500 time bins, 1000 trials). The data was generated as described for <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1</xref>. The smaller network is considered because it allows to fit the model by an exact method without the Bethe or TAP approximations. Here the exact method refers to the method in which the expectation parameters are calculated exactly at the gradient search for the MAP estimates of model parameters (<xref ref-type="disp-formula" rid="pcbi.1005309.e027">Eq 13</xref>). It should be noted that we approximate the posterior density by the Gaussian distribution even for the “exact method” in the recursive Bayesian algorithm. Comparison of the approximation methods with the exact method determines the error that is caused by the approximation methods and not by the finite amount of data.</p>
<p>First, investigation of three exemplary time points (<xref ref-type="fig" rid="pcbi.1005309.g003">Fig 3<bold>A</bold></xref>) reveals that both the pseudolikelihood-Bethe and the pseudolikelihood-TAP approximation recover the underlying parameters. We examine the error across time bins by the RMSE. Comparing RMSE of the approximation results with the exact fit (<xref ref-type="fig" rid="pcbi.1005309.g003">Fig 3<bold>B</bold></xref>) demonstrates that the both approximations perform worse in the same range. To examine the approximations also for large networks (<italic>N</italic> = 60) we sampled 1000 trials (as for <xref ref-type="fig" rid="pcbi.1005309.g002">Fig 2</xref>). In <xref ref-type="fig" rid="pcbi.1005309.g003">Fig 3<bold>C</bold></xref> we observe that errors of the approximations are comparable. Furthermore, we compare running times required for fitting the network of the two methods (<xref ref-type="fig" rid="pcbi.1005309.g003">Fig 3<bold>D</bold></xref>). The pseudolikelihood-TAP approximation turns out to be faster than Bethe. We observed that the EM algorithm required more iterations for the Bethe approximation. Furthermore, the occasional use of the CCCP contributed to the long fitting time of the pseudolikelihood-Bethe procedure.</p>
<fig id="pcbi.1005309.g003" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005309.g003</object-id>
<label>Fig 3</label>
<caption>
<title>Comparison of the Bethe and TAP approximation.</title>
<p>Simulated neural activity composed of 500 time bins, and 1000 trials are used to compare the two approximation methods. The underlying model parameters follow <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1</xref>. <bold>A</bold> Top: Ground truth <bold><italic>θ</italic></bold><sub><italic>t</italic></sub> of a network of 15 neurons vs. its smoothed estimate by pseudolikelihood-Bethe approximation at three different time points (<italic>t</italic> = 50, 150, 300). Bottom: The same as above obtained with pseudolikelihood-TAP approximation. <bold>B</bold> The RMSE between the true model parameter <bold><italic>θ</italic></bold><sub><italic>t</italic></sub> and its smoothed estimate by the exact inference, pseudolikelihood-Bethe, or pseudolikelihood-TAP approximation. The bar height and error bars indicate the mean and standard deviation from 10 realizations of data, each sampled from the same underlying parameters (generated as in <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1</xref>). <bold>C</bold> As in B the RMSE of the estimated model parameters for a network of 60 neurons, composed of 6 equally sized subnetworks. <bold>D</bold> Running time as function of network size for the two different approximation methods.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.g003" xlink:type="simple"/>
</fig>
<p>Since both, Bethe and TAP, provide an approximation for the log partition function <italic>ψ</italic><sub><italic>t</italic></sub> (Eqs <xref ref-type="disp-formula" rid="pcbi.1005309.e049">25</xref> and <xref ref-type="disp-formula" rid="pcbi.1005309.e046">24</xref>), we assess their performance for the same data as in <xref ref-type="fig" rid="pcbi.1005309.g003">Fig 3</xref>. The time evolution of simultaneous silence (directly linked to <italic>ψ</italic> by <xref ref-type="disp-formula" rid="pcbi.1005309.e074">Eq 30</xref>) is recovered by exact, Bethe, and TAP (<xref ref-type="fig" rid="pcbi.1005309.g004">Fig 4<bold>A</bold></xref>). The results show that the TAP approximation slightly overestimated the probability in this example. This is also reflected in the <inline-formula id="pcbi.1005309.e081"><alternatives><graphic id="pcbi.1005309.e081g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e081" xlink:type="simple"/><mml:math display="inline" id="M81"><mml:mrow><mml:mtext>Error</mml:mtext> <mml:mo>[</mml:mo> <mml:mi>ψ</mml:mi> <mml:mrow><mml:mo>(</mml:mo> <mml:msub><mml:mrow><mml:mo>{</mml:mo> <mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold-italic">θ</mml:mi> <mml:mo>^</mml:mo></mml:mover> <mml:mrow><mml:mi mathvariant="normal">t</mml:mi> <mml:mo>|</mml:mo> <mml:mi mathvariant="normal">T</mml:mi></mml:mrow></mml:msub> <mml:mo>}</mml:mo></mml:mrow> <mml:mi mathvariant="normal">t</mml:mi></mml:msub> <mml:mo>)</mml:mo></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> (<xref ref-type="fig" rid="pcbi.1005309.g004">Fig 4<bold>B</bold></xref>), where the Bethe approximation performs better than the TAP method. However, the error for the Bethe approximation increases compared to the exact method. The relation between the two approximation methods persists also for large networks (<xref ref-type="fig" rid="pcbi.1005309.g004">Fig 4<bold>C</bold></xref>). Another disadvantage of the TAP approximation is that the system of non-linear equations occasionally could not be solved. This happens more frequently when fitting larger networks and/or networks with stronger interactions. Therefore, it seems that the pseudolikelihood-Bethe approximation exhibits more accurate estimates; hence we will use it again for the following analysis. However the faster fitting of pesudolikelihood-TAP can be advantageous elsewhere.</p>
<fig id="pcbi.1005309.g004" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005309.g004</object-id>
<label>Fig 4</label>
<caption>
<title>Time-varying probability of simultaneous silence.</title>
<p>Results of different approximation methods. The underlying model parameters are the same as in <xref ref-type="fig" rid="pcbi.1005309.g003">Fig 3</xref>. <bold>A</bold> The probability of simultaneous silence (<italic>p</italic><sub>silence</sub>(<italic>t</italic>) = exp(−<italic>ψ</italic><sub><italic>t</italic></sub>)) for a network of 15 neurons as a function of time. The pseudolikelihood-Bethe (orange) and pseudolikelihood-TAP (lavender) method estimate the underlying value with sufficient accuracy (dashed black). For comparison, an estimate by the exact method (green) is shown. <bold>B</bold> The error between the approximate and true free energy <italic>ψ</italic><sub><italic>t</italic></sub>. <bold>C</bold> The error of free energy <italic>ψ</italic><sub><italic>t</italic></sub> for large networks (<italic>N</italic> = 60, data same as in <xref ref-type="fig" rid="pcbi.1005309.g003">Fig 3<bold>C</bold></xref>).</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.g004" xlink:type="simple"/>
</fig>
</sec>
<sec id="sec016">
<title>Dynamic network inference from V4 spiking data of behaving monkey</title>
<p>We now apply the approximate inference method to analyze activity of monkey V4 neurons recorded while the animal performed repeatedly (1004 trials) the following behavioral task. Each trial began when the monkey fixated its gaze within 1 degree of a centrally-positioned dot on a computer screen. After 150 ms, a drifting sinusoidal grating was presented for 2 s in the receptive field area of the neuronal population that was recorded, at which time the grating stimulus disappeared and the fixation point moved to a new, randomly chosen location on the screen, and the animal made an eye movement to fixate on the new location. Data epochs from 500 ms prior to grating stimulus onset until 500 ms after stimulus offset were extracted from the continuous recording for analysis. The spiking data obtained by micro-electrode recordings includes 112 single and multi units identified by their distinct wave forms. The experiment was performed at the University of Pittsburgh. All experimental procedures were approved by the University of Pittsburgh Institutional Animal Care and Use Committee, and were performed in accordance with the United States’ National Institutes of Health (NIH) <italic>Guide for the Care and Use of Laboratory Animals</italic>. For details on experimental setup, recording and unit identification see [<xref ref-type="bibr" rid="pcbi.1005309.ref064">64</xref>]. The recorded units are tested for across-trial stationarity (which is the assumption of the model): The mean firing rates for each trial are standardized and if more than 5% of the trials were outside the 95% confidence interval the unit is excluded. After this preprocessing 45 units remained. To obtain the binary data, the spike trains are discritized into time bins with Δ = 10 ms resulting into 300 time bins over the course of the trial. Exemplary data are displayed in <xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5<bold>A</bold></xref> Top. We note that the following conclusions of this analysis do not change even if we use smaller and larger bin size (Δ = 5 and 20 ms).</p>
<fig id="pcbi.1005309.g005" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005309.g005</object-id>
<label>Fig 5</label>
<caption>
<title>Dynamic network inference from monkey V4 data.</title>
<p>In this experiment, a 90° grating on a screen was presented to the monkey for 2s (light gray shaded areas). 1004 trials were recorded, and binary spike trains were constructed with bin width of 10 ms. <bold>A</bold> Top: Exemplary spiking data (<italic>N</italic> = 45). Bottom: Empirical probability (black) of observing a spike over time and spike probability of the fitted model (green). <bold>B</bold> Top: The fitted network at three different time points, before, during, and after stimulation. Edges with significantly non-zero <inline-formula id="pcbi.1005309.e083"><alternatives><graphic id="pcbi.1005309.e083g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e083" xlink:type="simple"/><mml:math display="inline" id="M83"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> are displayed (as in <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1</xref>). Bottom: The mean of smoothed MAP estimates for <inline-formula id="pcbi.1005309.e084"><alternatives><graphic id="pcbi.1005309.e084g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e084" xlink:type="simple"/><mml:math display="inline" id="M84"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005309.e085"><alternatives><graphic id="pcbi.1005309.e085g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e085" xlink:type="simple"/><mml:math display="inline" id="M85"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> (dark gray line). The shaded area is the mean ± standard deviation. <bold>C</bold> Credible intervals of macroscopic measures of the network over time obtained from the smoothed estimates of the model (light color). Dark shaded area corresponds to the credible intervals of the estimates for trial shuffled data.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.g005" xlink:type="simple"/>
</fig>
<p>After the data are preprocessed, we analyze the network dynamics of the 45 units during the task period by the state-space model for the neural population activity. Inference is done by using the pseudolikelihood-Bethe approximation. The results of fitting the state-space model are displayed in <xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5<bold>B</bold></xref>. Before presenting detailed results, we note that considering dynamics in activity rates and neural correlations better explains the population activity while avoiding overfitting, compared to assuming that they are stationary. To assess this, we compared the predictive ability of the state-space model with that of the stationary model, using the Aikake (Bayesian) Information Criterion (AIC) [<xref ref-type="bibr" rid="pcbi.1005309.ref065">65</xref>] defined as −2<italic>l</italic>(<bold>X</bold><sup>1:<italic>T</italic></sup>|<bold>w</bold>) + 2<italic>k</italic>, where <italic>k</italic> is the number of free parameters in <bold>w</bold>. To obtain the latter, we fitted the state-space model once more but now fixing λ<sup>−1</sup> = 0, which results in a stationary model since the state model in <xref ref-type="disp-formula" rid="pcbi.1005309.e012">Eq 3</xref> no longer contains variability. The result confirms that the dynamic model better predicts the data (AIC<sub>dyn</sub> = 4467026 for the dynamic model and AIC<sub>stat</sub> = 4576544 for the stationary model).</p>
<p>We observe stimulus locked oscillations in the population firing rate that are also captured by the model (<xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5<bold>A</bold></xref> Bottom). The average of the estimated natural parameters (<xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5<bold>B</bold></xref> Bottom) show that these oscillations are explained by the first order parameters <inline-formula id="pcbi.1005309.e086"><alternatives><graphic id="pcbi.1005309.e086g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e086" xlink:type="simple"/><mml:math display="inline" id="M86"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula>. We note that these oscillations are mainly caused by two units with high firing rates and they should not be considered as a homogeneous property of the network. Investigation of the network states before, during, and after the stimulus (<xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5<bold>B</bold></xref> Top) reveals that the interactions <inline-formula id="pcbi.1005309.e087"><alternatives><graphic id="pcbi.1005309.e087g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e087" xlink:type="simple"/><mml:math display="inline" id="M87"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> are altered over time. This is also reflected in an average over the all pairwise interactions (<xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5<bold>B</bold></xref> Center), where the mean decreases during the stimulus presentation as well as the standard deviation. Thus neurons are likely to decorrelate during the stimulus presentation whereas the population rate increases and oscillates at the same time.</p>
<p>Similarly to the analysis of artificial data (<xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1</xref>), we measure the macroscopic properties of the fitted model over the task period (see <xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5<bold>C</bold></xref> for credible intervals). To test the contribution of interactions in the recorded data, the model is once again fitted to trial shuffled data [<xref ref-type="bibr" rid="pcbi.1005309.ref023">23</xref>], which should destroy all correlations among units that do not occur due to chance. Comparison of the macroscopic measures between the models fitted to the original data and to the trial shuffled data shows how interactions among units alter the results. In the following, we will refer to the two models as “actual” and “trial shuffled” model.</p>
<p>The probability of simultaneous silence shows again the stimulus locked oscillations, and decreases during the stimulus period. The difference between the actual and trial shuffled model before the stimulus is larger than during and after the stimulus, suggesting that the observed positive interactions contributed to increasing the silence probability in particular before and after the stimulus period. The entropy reflects the oscillations and shows a strong increase (∼1/3) during the stimulus period. This is reasonable because we observe an increase in activity rates and a decrease in correlations—both effects should result in an increase in entropy. Next, we examine how much of the entropy is explained by the interactions among the neurons. To do so, at each time point we calculate the corresponding independent model by projecting the fitted interaction model to the independent model (i.e., the model with the same individual firing rates <inline-formula id="pcbi.1005309.e088"><alternatives><graphic id="pcbi.1005309.e088g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e088" xlink:type="simple"/><mml:math display="inline" id="M88"><mml:msubsup><mml:mi>η</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> but with all <inline-formula id="pcbi.1005309.e089"><alternatives><graphic id="pcbi.1005309.e089g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e089" xlink:type="simple"/><mml:math display="inline" id="M89"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>=</mml:mo> <mml:mn>0</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>). The entropy of the independent model <italic>S</italic><sub>ind</sub> should always be larger than <italic>S</italic><sub>pair</sub>, the entropy of the model with interactions. Hence, a fraction of entropy explained by the interactions can be calculated as
<disp-formula id="pcbi.1005309.e090"><alternatives><graphic id="pcbi.1005309.e090g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e090" xlink:type="simple"/><mml:math display="block" id="M90"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi> <mml:mtext>ind</mml:mtext></mml:msub> <mml:mo>-</mml:mo> <mml:msub><mml:mi>S</mml:mi> <mml:mtext>pair</mml:mtext></mml:msub></mml:mrow> <mml:msub><mml:mi>S</mml:mi> <mml:mtext>ind</mml:mtext></mml:msub></mml:mfrac> <mml:mo>.</mml:mo></mml:mrow></mml:math></alternatives> <label>(36)</label></disp-formula>
In general, contribution of interactions to the entropy is small for these data (≤ 2%). However, the contribution is less during stimulus presentation, compared to the period before the stimulus. Only in the beginning of the stimulus presentation, two peaks of correlated activity can be observed. The observed reduction of the fractional entropy for interactions could be caused by the increase of the first order parameters <inline-formula id="pcbi.1005309.e091"><alternatives><graphic id="pcbi.1005309.e091g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e091" xlink:type="simple"/><mml:math display="inline" id="M91"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and/or by the decrease of the interactions <inline-formula id="pcbi.1005309.e092"><alternatives><graphic id="pcbi.1005309.e092g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e092" xlink:type="simple"/><mml:math display="inline" id="M92"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> during the stimulus period. The decorrelation observed during the stimulus period is successfully dissociated from the oscillatory activity: Previously observed oscillations are absent in this measure of interactions. This result is important because ignoring such firing rate dynamics often leads to erroneous detection of positive correlations among neurons. A clear exception is the first peak appeared during the stimulus presentation, which was also observed in the trial-shuffled model. Indeed, the first sharp increase of the spike rates was not faithfully captured by the models, which caused spurious interactions in the trial-shuffled model. Last, the sensitivity (heat capacity) of the network over time is obtained. While for the artificial data in <xref ref-type="fig" rid="pcbi.1005309.g001">Fig 1</xref> the sensitivity showed a drastic decrease, such reduction is not observed in the V4 data. The sensitivity of the network is maintained at approximately the same value before and during the stimulus period. This is interesting since we already observed that before and during the stimulus the network seems to be in two qualitatively different states (low vs. high firing rate and strong vs. weak interactions). After stimulus presentation the sensitivity drops. Overall, neural interactions contribute to have higher sensitivity (see light vs. dark credible intervals).</p>
</sec>
<sec id="sec017">
<title>Dynamic network inference from simulated balanced network data</title>
<p>Networks with balanced excitation and inhibition have been used to describe cortical activity [<xref ref-type="bibr" rid="pcbi.1005309.ref066">66</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref067">67</xref>]. To see whether the balanced network model can reproduce the findings from the recorded V4, we simulate spiking data using the balanced spiking network following [<xref ref-type="bibr" rid="pcbi.1005309.ref024">24</xref>], and analyze these data with the state-space model. The network consists of 1000 leaky integrate-and-fire neurons (800 excitatory, 200 inhibitory) (For details see <xref ref-type="supplementary-material" rid="pcbi.1005309.s004">S4 Text</xref>). Connection probability is 20%, between all neurons. The network receives input from 800 Poisson neurons. Each input neuron has a Gaussian tuning curve, where the preferred direction is randomly assigned. We choose an experimental paradigm which resembles one of the V4 data. 1000 trials of 3 s duration are simulated. Before each trial, the simulation runs for 500 ms under random Poisson inputs such that the network state at the beginning of each trial is independent. Then the trial starts at −500 ms. At 0 ms a 90° is shown for 2 s followed again by a 500 ms period of stimulus absence. The activity of 140 neurons are recorded for investigation. From the recorded subpopulation, we further selected 40 excitatory and 20 inhibitory neurons with the highest firing rates for the following analysis. Binary spike trains were obtained by binning with Δ = 10 ms. Exemplary data are shown in <xref ref-type="fig" rid="pcbi.1005309.g006">Fig 6<bold>A</bold></xref> (top spike trains are from excitatory, and bottom spike trains from inhibitory neurons). We then fitted the state-space model to these data.</p>
<fig id="pcbi.1005309.g006" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005309.g006</object-id>
<label>Fig 6</label>
<caption>
<title>Dynamic network inference from simulated balanced network data.</title>
<p>60 neurons (40 excitatory, 20 inhibitory) are recorded from a simulated balanced network of 1000 leaky integrate-and-fire neurons that receive inputs from 800 excitatory orientation selective Poisson neurons (mean firing rate 7.5 Hz when no stimulus present). See main text for the details. Stimulus was presented for 2 s, and 1000 trials are generated. Bin width is 10 ms. The structure of this figure is the same as in <xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5</xref>.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.g006" xlink:type="simple"/>
</fig>
<p>As for the V4 data, we show in <xref ref-type="fig" rid="pcbi.1005309.g006">Fig 6<bold>B</bold></xref> 3 snapshots of the network (<italic>N</italic> = 60) (Top), as well as mean and standard deviation of <inline-formula id="pcbi.1005309.e093"><alternatives><graphic id="pcbi.1005309.e093g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e093" xlink:type="simple"/><mml:math display="inline" id="M93"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> and <inline-formula id="pcbi.1005309.e094"><alternatives><graphic id="pcbi.1005309.e094g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e094" xlink:type="simple"/><mml:math display="inline" id="M94"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> (Bottom). In contrast to the V4 network there are numerous significant non-zero couplings. However, similarly to the monkey data, we observe an increase for <inline-formula id="pcbi.1005309.e095"><alternatives><graphic id="pcbi.1005309.e095g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e095" xlink:type="simple"/><mml:math display="inline" id="M95"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> and a decrease of <inline-formula id="pcbi.1005309.e096"><alternatives><graphic id="pcbi.1005309.e096g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e096" xlink:type="simple"/><mml:math display="inline" id="M96"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mi>t</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> during the stimulus period. We also assess the macroscopic states for the balanced network (<xref ref-type="fig" rid="pcbi.1005309.g006">Fig 6<bold>C</bold></xref>). As in the V4 data the probability of silence decreases during the stimulus period. Furthermore, compared to the trial shuffled result, the difference is larger before and after the stimulus than during the stimulus, suggesting a larger contribution of the couplings to silence when no stimulus is present. The entropy increases during the stimulus period. The credible interval for the trial shuffled data is narrower than for actual model and the entropy tends to be larger. Up to this point we did not find, in the macroscopic properties, significant qualitative differences between the V4 data and the simulated data from the balanced network. However, the entropy that is explained by the couplings increases during the stimulus, while in the V4 data a decrease is observed (<xref ref-type="fig" rid="pcbi.1005309.g006">Fig 6<bold>C</bold></xref>, third panel). Hence, the interactions in the balanced network become stronger during the stimulus, even though the mean of the couplings <inline-formula id="pcbi.1005309.e097"><alternatives><graphic id="pcbi.1005309.e097g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e097" xlink:type="simple"/><mml:math display="inline" id="M97"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> decreases for this period. This can be explained by more negative values in estimated couplings during the stimulus period. The sensitivity slightly decreases when the stimulus is shown and, as for the V4 data, couplings contribute to higher sensitivity.</p>
<p>Observing the dynamics in the model parameters poses the question how the actual synaptic connectivity structure of the network is reflected in the inferred interactions. Do positive values correspond to excitatory synapses, and negative to inhibitory ones? While for the V4 data this is impossible to assess, we compare the values of <inline-formula id="pcbi.1005309.e098"><alternatives><graphic id="pcbi.1005309.e098g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e098" xlink:type="simple"/><mml:math display="inline" id="M98"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> of pairs, that are at least connected by one excitatory synapse and those that are connected by at least one inhibitory synapse (<xref ref-type="fig" rid="pcbi.1005309.g007">Fig 7<bold>A</bold></xref>, red and blue histograms respectively). In general, excitatory connected pairs show more positive values, while inhibiting ones tend to be negative. The most negative values are almost exclusively explained by inhibiting pairs. However, compared to all <inline-formula id="pcbi.1005309.e099"><alternatives><graphic id="pcbi.1005309.e099g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e099" xlink:type="simple"/><mml:math display="inline" id="M99"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> (gray histogram) many positive couplings <inline-formula id="pcbi.1005309.e100"><alternatives><graphic id="pcbi.1005309.e100g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e100" xlink:type="simple"/><mml:math display="inline" id="M100"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> do not represent excitatory connected pairs. Thus it is difficult to identify excitatory synapses from the inferred couplings. The result that inhibitory pairs showed stronger negative couplings, while excitatory pairs were mostly represented by weak positive couplings, can be explained by on average much stronger conductance of inhibitory synapses.</p>
<fig id="pcbi.1005309.g007" position="float">
<object-id pub-id-type="doi">10.1371/journal.pcbi.1005309.g007</object-id>
<label>Fig 7</label>
<caption>
<title>Comparison of model interactions with synapses in the balanced network.</title>
<p>The synaptic structure is reflected in the inferred interactions. <bold>A</bold> Histograms of the interactions <inline-formula id="pcbi.1005309.e101"><alternatives><graphic id="pcbi.1005309.e101g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e101" xlink:type="simple"/><mml:math display="inline" id="M101"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> for all pairs (gray), pairs that are connected by <italic>at least</italic> one excitatory synapse (red), and those that are connected by <italic>at least</italic> one inhibitory synapse (blue) at three different time points. <bold>B</bold> Averages of the couplings <inline-formula id="pcbi.1005309.e102"><alternatives><graphic id="pcbi.1005309.e102g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e102" xlink:type="simple"/><mml:math display="inline" id="M102"><mml:msubsup><mml:mi>θ</mml:mi> <mml:mrow><mml:mi>i</mml:mi> <mml:mi>j</mml:mi></mml:mrow> <mml:mrow><mml:mi>t</mml:mi> <mml:mo>|</mml:mo> <mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math></alternatives></inline-formula> across time and pairs as a function of a network size (always consisting of two thirds of excitatory and one third of inhibitory neurons). Colors as in A, and error bars denote standard deviations.</p>
</caption>
<graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.g007" xlink:type="simple"/>
</fig>
<p>Finally we compare the mean values of couplings between different network sizes (<xref ref-type="fig" rid="pcbi.1005309.g007">Fig 7<bold>B</bold></xref>). To do so networks of size <italic>N</italic> = 15, 30, 60 are fitted, where the network always consisted of one third inhibitory and two thirds excitatory neurons. However, neither for excitatory, inhibitory or all couplings we could identify dependency on the network sizes that can be analyzed by our model.</p>
</sec>
</sec>
<sec id="sec018" sec-type="conclusions">
<title>Discussion</title>
<p>This study provides approximate inference methods for simultaneously estimating neural interactions of a large number of neurons, and quantifying macroscopic properties of the network in a time-resolved manner. We assessed performance of these methods by using simulated parallel spike sequences, and demonstrated the utility of the proposed approach by revealing dynamic decorrelation of V4 neurons and maintained susceptibility during stimulus presentations. Furthermore we compared those findings with data from a simple balanced network of LIF neurons, which suggested that further refinements were necessary to reproduce the observed network activity.</p>
<p>Accurate assessment of correlated population activity in ongoing and evoked activity is a key to understand the underlying biological mechanisms and their coding principles. It is critical to model time-dependent firing rates to correctly assess neural interactions. If we apply a stationary model of neural interactions to independent neurons with varying firing rates, we may erroneously observe excess of correlations [<xref ref-type="bibr" rid="pcbi.1005309.ref022">22</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref024">24</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref068">68</xref>]. Such an apparent issue of a stationary model can introduce considerable confusion in search of fundamental coding principles of neurons. Several related studies accounted for the nonstationary activity by modeling time-dependent external fields (c.f., <inline-formula id="pcbi.1005309.e082"><alternatives><graphic id="pcbi.1005309.e082g" mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.1005309.e082" xlink:type="simple"/><mml:math display="inline" id="M82"><mml:mrow><mml:mo>{</mml:mo> <mml:msubsup><mml:mi>θ</mml:mi> <mml:mi>i</mml:mi> <mml:mi>t</mml:mi></mml:msubsup> <mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> in <xref ref-type="disp-formula" rid="pcbi.1005309.e006">Eq 1</xref>) while fixing pairwise interactions [<xref ref-type="bibr" rid="pcbi.1005309.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref030">30</xref>]. In addition to the external fields, however, we consider that modeling dynamics of correlations are important particularly for analyses of neurons recorded from awake animals because neural correlations are known to appear dynamically in relation to behavioral demand to the animals [<xref ref-type="bibr" rid="pcbi.1005309.ref027">27</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref029">29</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref069">69</xref>]. Indeed, we found dynamic decorrelation of V4 neurons during stimulus presentation (<xref ref-type="fig" rid="pcbi.1005309.g005">Fig 5C</xref> 3rd panel), which may reflect asynchronous neural activities under stimulus processing of an alert animal [<xref ref-type="bibr" rid="pcbi.1005309.ref070">70</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref071">71</xref>]. In general, it is important to compare the result with that of surrogate data in which one destroys correlations to examine potentially short-lasting time-varying interactions in relation to behavioral paradigms.</p>
<p>The current state-space model presumes that the neural dynamic follows a <italic>quasistatic</italic> process. At each time <italic>t</italic>, we assumed that population activity is sampled from the <italic>equilibrium</italic> joint distribution given by <xref ref-type="disp-formula" rid="pcbi.1005309.e006">Eq 1</xref> across trials while the state of population activity smoothly changes within a trial. This is of course a simplified view of neuronal dynamics. Most notably, dependency of the neurons’ activity on their past activity makes the system a nonequilibrium one. Such activity is captured by models via the history effect, e.g., using the kinetic Ising model [<xref ref-type="bibr" rid="pcbi.1005309.ref025">25</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref026">26</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref072">72</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref073">73</xref>] or generalized linear models (GLM) of point and Bernoulli processes [<xref ref-type="bibr" rid="pcbi.1005309.ref035">35</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref074">74</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref076">76</xref>]. Given the past activities, these models construct the joint activity assuming their conditional independence. The equilibrium and non-equilibrium models thus assume different generative processes, even though the pseudo-likelihood approximation for our equilibrium Ising model used similar conditional independence given the activity of other neurons at the same time. It is an important topic to include both modeling frameworks in the sequential Bayes estimation to better account for dynamic and nonequilibrium properties of neural activity [<xref ref-type="bibr" rid="pcbi.1005309.ref039">39</xref>]. The model goodness-of-fit may be additionally improved by including sparseness constraints on the couplings as was done in the stationary models [<xref ref-type="bibr" rid="pcbi.1005309.ref040">40</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref077">77</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref078">78</xref>].</p>
<p>In this study, we employed the classical pseudolikelihood method to perform MAP estimation of interactions (i.e., natural parameters) without computing the partition function. For the inverse problem without the prior, we may use alternative approximation methods such as Bethe and TAP approximations, and further state-of-the-art methods such as the Sessak-Monasson [<xref ref-type="bibr" rid="pcbi.1005309.ref012">12</xref>], minimum-probability-flow [<xref ref-type="bibr" rid="pcbi.1005309.ref015">15</xref>], and adaptive-cluster expansion [<xref ref-type="bibr" rid="pcbi.1005309.ref017">17</xref>] method. However, here we chose the pseudolikelihood method because it was not trivial to apply the other methods to the Bayesian estimation. Alternatively, the Bethe and TAP approximation methods may be used to approximate the expectation parameters during the iterative procedure of the exact MAP estimation (<xref ref-type="disp-formula" rid="pcbi.1005309.e027">Eq 13</xref>) because these methods allow us to estimate the expectation parameter from the natural parameters (the forward problem). However, as we found in the estimation of the Fisher information, TAP may occasionally fail and Bethe approximation by BP may not converge. Thus we rather used these methods after the MAP estimation was found by the pseudolikelihood method. The framework, however, is not limited to these approximation methods, and new methods may be incorporated into the state-space model to further increase the number of neurons that can be analyzed.</p>
<p>It should be noted that the current model does not include higher-order interactions to explain the population dynamics. While neural higher-order interactions are ubiquitously observed <italic>in vivo</italic> [<xref ref-type="bibr" rid="pcbi.1005309.ref038">38</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref079">79</xref>–<xref ref-type="bibr" rid="pcbi.1005309.ref081">81</xref>] as well as <italic>in vitro</italic> [<xref ref-type="bibr" rid="pcbi.1005309.ref020">20</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref021">21</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref082">82</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref083">83</xref>] conditions, it remains to be elucidated how they contribute to characterizing evoked activities. It is an important step to include higher-order interactions in the large-scale time-dependent model. However, the proposed method that includes up to pairwise interactions can be used as a null model for testing activity features involving higher-order interactions. For example, both experimental and modeling studies showed that simultaneous silence of neurons constitutes a major feature of higher-order interactions of stationary neural activities [<xref ref-type="bibr" rid="pcbi.1005309.ref083">83</xref>, <xref ref-type="bibr" rid="pcbi.1005309.ref084">84</xref>]. It remains to be tested, though, if silence probability of all neurons recorded from behaving animals exceed prediction by the pairwise model. Such sparse population activity may be expected when animals process natural scenes, compared to artificial stimuli [<xref ref-type="bibr" rid="pcbi.1005309.ref085">85</xref>].</p>
<p>The limiting factor for the current model on the network size is rather the lack of data than the performance of the approximation methods (<xref ref-type="fig" rid="pcbi.1005309.g002">Fig 2</xref>). Hence, the state-space or other time-resolved methods that include dimension reduction techniques will be important approaches to explain activity of much larger populations than analyzed here. While there is still room for improvement, the currently proposed method already allows researchers to start testing hypotheses of network responses under distinct task conditions or brain states. These observations will serve to construct biophysical models of neural networks by constraining them, therefore revealing their coding principles.</p>
</sec>
<sec id="sec019">
<title>Supporting Information</title>
<supplementary-material id="pcbi.1005309.s001" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.s001" xlink:type="simple">
<label>S1 Text</label>
<caption>
<title>Bethe approximation.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005309.s002" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.s002" xlink:type="simple">
<label>S2 Text</label>
<caption>
<title>TAP approximation.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005309.s003" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.s003" xlink:type="simple">
<label>S3 Text</label>
<caption>
<title>Generation of simulated data.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
<supplementary-material id="pcbi.1005309.s004" mimetype="application/pdf" position="float" xlink:href="info:doi/10.1371/journal.pcbi.1005309.s004" xlink:type="simple">
<label>S4 Text</label>
<caption>
<title>Simulated experiment with a balanced network.</title>
<p>(PDF)</p>
</caption>
</supplementary-material>
</sec>
</body>
<back>
<ack>
<p>The authors thank Thomas Sharp for originally translating Matlab code written by HS to Python code, and Adam Snyder and Matthew A. Smith for kindly providing the V4 spiking data. CD and HS acknowledge Taro Toyoizumi for hosting CD’s stay in RIKEN Brain Science Institute, and Timm Lochmann for valuable ideas and discussions.</p>
</ack>
<ref-list>
<title>References</title>
<ref id="pcbi.1005309.ref001">
<label>1</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>London</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Häusser</surname> <given-names>M</given-names></name>. <article-title>Dendritic computation</article-title>. <source>Annual Review on Neuroscience</source>. <year>2005</year>;<volume>28</volume>:<fpage>503</fpage>–<lpage>532</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1146/annurev.neuro.28.061604.135703" xlink:type="simple">10.1146/annurev.neuro.28.061604.135703</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref002">
<label>2</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>De La Rocha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Doiron</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Shea-Brown</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Josić</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Reyes</surname> <given-names>A</given-names></name>. <article-title>Correlation between neural spike trains increases with firing rate</article-title>. <source>Nature</source>. <year>2007</year>;<volume>448</volume>(<issue>7155</issue>):<fpage>802</fpage>–<lpage>806</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature06028" xlink:type="simple">10.1038/nature06028</ext-link></comment> <object-id pub-id-type="pmid">17700699</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref003">
<label>3</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Reyes</surname> <given-names>AD</given-names></name>. <article-title>Synchrony-dependent propagation of firing rate in iteratively constructed networks in vitro</article-title>. <source>Nature Neuroscience</source>. <year>2003</year>;<volume>6</volume>(<issue>6</issue>):<fpage>593</fpage>–<lpage>599</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn1056" xlink:type="simple">10.1038/nn1056</ext-link></comment> <object-id pub-id-type="pmid">12730700</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref004">
<label>4</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pitkow</surname> <given-names>X</given-names></name>, <name name-style="western"><surname>Meister</surname> <given-names>M</given-names></name>. <article-title>Decorrelation and efficient coding by retinal ganglion cells</article-title>. <source>Nature Neuroscience</source>. <year>2012</year>;<volume>15</volume>(<issue>4</issue>):<fpage>628</fpage>–<lpage>635</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3064" xlink:type="simple">10.1038/nn.3064</ext-link></comment> <object-id pub-id-type="pmid">22406548</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref005">
<label>5</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kenet</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Bibitchkov</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Tsodyks</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Grinvald</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Arieli</surname> <given-names>A</given-names></name>. <article-title>Spontaneously emerging cortical representations of visual attributes</article-title>. <source>Nature</source>. <year>2003</year>;<volume>425</volume>(<issue>6961</issue>):<fpage>954</fpage>–<lpage>956</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature02078" xlink:type="simple">10.1038/nature02078</ext-link></comment> <object-id pub-id-type="pmid">14586468</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref006">
<label>6</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Luczak</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Barthó</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>KD</given-names></name>. <article-title>Spontaneous events outline the realm of possible sensory responses in neocortical populations</article-title>. <source>Neuron</source>. <year>2009</year>;<volume>62</volume>(<issue>3</issue>):<fpage>413</fpage>–<lpage>425</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2009.03.014" xlink:type="simple">10.1016/j.neuron.2009.03.014</ext-link></comment> <object-id pub-id-type="pmid">19447096</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref007">
<label>7</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Field</surname> <given-names>GD</given-names></name>, <name name-style="western"><surname>Gauthier</surname> <given-names>JL</given-names></name>, <name name-style="western"><surname>Grivich</surname> <given-names>MI</given-names></name>, <name name-style="western"><surname>Petrusca</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>The structure of multi-neuron firing patterns in primate retina</article-title>. <source>The Journal of Neuroscience</source>. <year>2006</year>;<volume>26</volume>(<issue>32</issue>):<fpage>8254</fpage>–<lpage>8266</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.1282-06.2006" xlink:type="simple">10.1523/JNEUROSCI.1282-06.2006</ext-link></comment> <object-id pub-id-type="pmid">16899720</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref008">
<label>8</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>Weak pairwise correlations imply strongly correlated network states in a neural population</article-title>. <source>Nature</source>. <year>2006</year>;<volume>440</volume>(<issue>7087</issue>):<fpage>1007</fpage>–<lpage>1012</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature04701" xlink:type="simple">10.1038/nature04701</ext-link></comment> <object-id pub-id-type="pmid">16625187</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref009">
<label>9</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Lezon</surname> <given-names>TR</given-names></name>, <name name-style="western"><surname>Banavar</surname> <given-names>JR</given-names></name>, <name name-style="western"><surname>Cieplak</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Maritan</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Fedoroff</surname> <given-names>NV</given-names></name>. <article-title>Using the principle of entropy maximization to infer genetic interaction networks from gene expression patterns</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2006</year>;<volume>103</volume>(<issue>50</issue>):<fpage>19033</fpage>–<lpage>19038</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.0609152103" xlink:type="simple">10.1073/pnas.0609152103</ext-link></comment> <object-id pub-id-type="pmid">17138668</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref010">
<label>10</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Walczak</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Callan</surname> <given-names>CG</given-names></name>. <article-title>Maximum entropy models for antibody diversity</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2010</year>;<volume>107</volume>(<issue>12</issue>):<fpage>5405</fpage>–<lpage>5410</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1001705107" xlink:type="simple">10.1073/pnas.1001705107</ext-link></comment> <object-id pub-id-type="pmid">20212159</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref011">
<label>11</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Cavagna</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Giardina</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Silvestri</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Viale</surname> <given-names>M</given-names></name>, <etal>et al</etal>. <article-title>Statistical mechanics for natural flocks of birds</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2012</year>;<volume>109</volume>(<issue>13</issue>):<fpage>4786</fpage>–<lpage>4791</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1118633109" xlink:type="simple">10.1073/pnas.1118633109</ext-link></comment> <object-id pub-id-type="pmid">22427355</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref012">
<label>12</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sessak</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Monasson</surname> <given-names>R</given-names></name>. <article-title>Small-correlation expansions for the inverse Ising problem</article-title>. <source>Journal of Physics A: Mathematical and Theoretical</source>. <year>2009</year>;<volume>42</volume>(<issue>5</issue>):<fpage>055001</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1751-8113/42/5/055001" xlink:type="simple">10.1088/1751-8113/42/5/055001</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref013">
<label>13</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Aurell</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>. <article-title>Statistical physics of pairwise probability models</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2009</year>;<volume>3</volume>(<issue>22</issue>). <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/neuro.10.022.2009" xlink:type="simple">10.3389/neuro.10.022.2009</ext-link></comment> <object-id pub-id-type="pmid">19949460</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref014">
<label>14</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Tyrcha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>. <article-title>Ising model for neural data: model quality and approximate methods for extracting functional connectivity</article-title>. <source>Physical Review E</source>. <year>2009</year>;<volume>79</volume>(<issue>5</issue>):<fpage>051915</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.79.051915" xlink:type="simple">10.1103/PhysRevE.79.051915</ext-link></comment> <object-id pub-id-type="pmid">19518488</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref015">
<label>15</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sohl-Dickstein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Battaglino</surname> <given-names>PB</given-names></name>, <name name-style="western"><surname>DeWeese</surname> <given-names>MR</given-names></name>. <article-title>New method for parameter estimation in probabilistic models: minimum probability flow</article-title>. <source>Physical Review Letters</source>. <year>2011</year>;<volume>107</volume>(<issue>22</issue>):<fpage>220601</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.107.220601" xlink:type="simple">10.1103/PhysRevLett.107.220601</ext-link></comment> <object-id pub-id-type="pmid">22182019</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref016">
<label>16</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Schaub</surname> <given-names>MT</given-names></name>, <name name-style="western"><surname>Schultz</surname> <given-names>SR</given-names></name>. <article-title>The Ising decoder: reading out the activity of large neural ensembles</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2012</year>;<volume>32</volume>(<issue>1</issue>):<fpage>101</fpage>–<lpage>118</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-011-0342-z" xlink:type="simple">10.1007/s10827-011-0342-z</ext-link></comment> <object-id pub-id-type="pmid">21667155</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref017">
<label>17</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cocco</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Monasson</surname> <given-names>R</given-names></name>. <article-title>Adaptive cluster expansion for the inverse Ising problem: convergence, algorithm and tests</article-title>. <source>Journal of Statistical Physics</source>. <year>2012</year>;<volume>147</volume>(<issue>2</issue>):<fpage>252</fpage>–<lpage>314</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10955-012-0463-4" xlink:type="simple">10.1007/s10955-012-0463-4</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref018">
<label>18</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Haslinger</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Ba</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Galuske</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Williams</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Pipa</surname> <given-names>G</given-names></name>. <article-title>Missing mass approximations for the partition function of stimulus driven Ising models</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2013</year>;<volume>7</volume>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2013.00096" xlink:type="simple">10.3389/fncom.2013.00096</ext-link></comment> <object-id pub-id-type="pmid">23898262</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref019">
<label>19</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Nirenberg</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Latham</surname> <given-names>PE</given-names></name>. <article-title>Pairwise maximum entropy models for studying large biological systems: when they can work and when they can’t</article-title>. <source>PLoS Computational Biology</source>. <year>2009</year>;<volume>5</volume>(<issue>5</issue>):<fpage>e1000380</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1000380" xlink:type="simple">10.1371/journal.pcbi.1000380</ext-link></comment> <object-id pub-id-type="pmid">19424487</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref020">
<label>20</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ganmor</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>. <article-title>Sparse low-order interaction network underlies a highly correlated and learnable neural population code</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2011</year>;<volume>108</volume>(<issue>23</issue>):<fpage>9679</fpage>–<lpage>9684</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1019641108" xlink:type="simple">10.1073/pnas.1019641108</ext-link></comment> <object-id pub-id-type="pmid">21602497</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref021">
<label>21</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tkačik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Amodei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names> <suffix>II</suffix></name>. <article-title>Searching for collective behavior in a large network of sensory neurons</article-title>. <source>PLoS Computational Biology</source>. <year>2014</year>;<volume>10</volume>(<issue>1</issue>):<fpage>e1003408</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003408" xlink:type="simple">10.1371/journal.pcbi.1003408</ext-link></comment> <object-id pub-id-type="pmid">24391485</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref022">
<label>22</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brody</surname> <given-names>CD</given-names></name>. <article-title>Correlations without synchrony</article-title>. <source>Neural computation</source>. <year>1999</year>;<volume>11</volume>(<issue>7</issue>):<fpage>1537</fpage>–<lpage>1551</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976699300016133" xlink:type="simple">10.1162/089976699300016133</ext-link></comment> <object-id pub-id-type="pmid">10490937</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref023">
<label>23</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>. <article-title>Data-driven significance estimation for precise spike correlation</article-title>. <source>Journal of Neurophysiology</source>. <year>2009</year>;<volume>101</volume>(<issue>3</issue>):<fpage>1126</fpage>–<lpage>1140</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00093.2008" xlink:type="simple">10.1152/jn.00093.2008</ext-link></comment> <object-id pub-id-type="pmid">19129298</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref024">
<label>24</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Renart</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>de la Rocha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Bartho</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Hollender</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Parga</surname> <given-names>N</given-names></name>, <name name-style="western"><surname>Reyes</surname> <given-names>A</given-names></name>, <etal>et al</etal>. <article-title>The asynchronous state in cortical circuits</article-title>. <source>Science</source>. <year>2010</year>;<volume>327</volume>(<issue>5965</issue>):<fpage>587</fpage>–<lpage>590</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.1179850" xlink:type="simple">10.1126/science.1179850</ext-link></comment> <object-id pub-id-type="pmid">20110507</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref025">
<label>25</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>. <article-title>Mean field theory for nonequilibrium network reconstruction</article-title>. <source>Physical Review Letters</source>. <year>2011</year>;<volume>106</volume>(<issue>4</issue>):<fpage>048702</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.106.048702" xlink:type="simple">10.1103/PhysRevLett.106.048702</ext-link></comment> <object-id pub-id-type="pmid">21405370</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref026">
<label>26</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tyrcha</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Marsili</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>. <article-title>The effect of nonstationarity on models inferred from neural data</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>. <year>2013</year>;<volume>2013</volume>(<issue>03</issue>):<fpage>P03005</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-5468/2013/03/P03005" xlink:type="simple">10.1088/1742-5468/2013/03/P03005</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref027">
<label>27</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Vaadia</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Haalman</surname> <given-names>I</given-names></name>, <name name-style="western"><surname>Abeles</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Bergman</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Prut</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Slovin</surname> <given-names>H</given-names></name>, <etal>et al</etal>. <article-title>Dynamics of neuronal interactions in monkey cortex in relation to behavioural events</article-title>. <source>Nature</source>. <year>1995</year>;<volume>373</volume>(<issue>6514</issue>):<fpage>515</fpage>–<lpage>518</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/373515a0" xlink:type="simple">10.1038/373515a0</ext-link></comment> <object-id pub-id-type="pmid">7845462</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref028">
<label>28</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Riehle</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Diesmann</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Aertsen</surname> <given-names>A</given-names></name>. <article-title>Spike synchronization and rate modulation differentially involved in motor cortical function</article-title>. <source>Science</source>. <year>1997</year>;<volume>278</volume>(<issue>5345</issue>):<fpage>1950</fpage>–<lpage>1953</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.278.5345.1950" xlink:type="simple">10.1126/science.278.5345.1950</ext-link></comment> <object-id pub-id-type="pmid">9395398</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref029">
<label>29</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Sakurai</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Takahashi</surname> <given-names>S</given-names></name>. <article-title>Dynamic synchrony of firing in the monkey prefrontal cortex during working-memory tasks</article-title>. <source>The Journal of Neuroscience</source>. <year>2006</year>;<volume>26</volume>(<issue>40</issue>):<fpage>10141</fpage>–<lpage>10153</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.2423-06.2006" xlink:type="simple">10.1523/JNEUROSCI.2423-06.2006</ext-link></comment> <object-id pub-id-type="pmid">17021170</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref030">
<label>30</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Granot-Atedgi</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Tkacik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Segev</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Schneidman</surname> <given-names>E</given-names></name>. <article-title>Stimulus-dependent maximum entropy models of neural population codes</article-title>. <source>PLoS Computational Biology</source>. <year>2013</year>;<volume>9</volume>(<issue>3</issue>):<fpage>e1002922</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002922" xlink:type="simple">10.1371/journal.pcbi.1002922</ext-link></comment> <object-id pub-id-type="pmid">23516339</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref031">
<label>31</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chen</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>. <article-title>State space model</article-title>. <source>Scholarpedia</source>. <year>2013</year>;<volume>8</volume>(<issue>3</issue>):<fpage>30868</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.4249/scholarpedia.30868" xlink:type="simple">10.4249/scholarpedia.30868</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref032">
<label>32</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Tang</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Quirk</surname> <given-names>MC</given-names></name>, <name name-style="western"><surname>Wilson</surname> <given-names>MA</given-names></name>. <article-title>A statistical paradigm for neural spike train decoding applied to position prediction from ensemble firing patterns of rat hippocampal place cells</article-title>. <source>The Journal of Neuroscience</source>. <year>1998</year>;<volume>18</volume>(<issue>18</issue>):<fpage>7411</fpage>–<lpage>7425</lpage>. <object-id pub-id-type="pmid">9736661</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref033">
<label>33</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Smith</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>. <article-title>Estimating a state-space model from point process observations</article-title>. <source>Neural Computation</source>. <year>2003</year>;<volume>15</volume>(<issue>5</issue>):<fpage>965</fpage>–<lpage>991</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976603765202622" xlink:type="simple">10.1162/089976603765202622</ext-link></comment> <object-id pub-id-type="pmid">12803953</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref034">
<label>34</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Eden</surname> <given-names>UT</given-names></name>, <name name-style="western"><surname>Frank</surname> <given-names>LM</given-names></name>, <name name-style="western"><surname>Barbieri</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Solo</surname> <given-names>V</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>. <article-title>Dynamic analysis of neural encoding by point process adaptive filtering</article-title>. <source>Neural Computation</source>. <year>2004</year>;<volume>16</volume>(<issue>5</issue>):<fpage>971</fpage>–<lpage>998</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/089976604773135069" xlink:type="simple">10.1162/089976604773135069</ext-link></comment> <object-id pub-id-type="pmid">15070506</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref035">
<label>35</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Truccolo</surname> <given-names>W</given-names></name>, <name name-style="western"><surname>Eden</surname> <given-names>UT</given-names></name>, <name name-style="western"><surname>Fellows</surname> <given-names>MR</given-names></name>, <name name-style="western"><surname>Donoghue</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>. <article-title>A point process framework for relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects</article-title>. <source>Journal of Neurophysiology</source>. <year>2005</year>;<volume>93</volume>(<issue>2</issue>):<fpage>1074</fpage>–<lpage>1089</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.00697.2004" xlink:type="simple">10.1152/jn.00697.2004</ext-link></comment> <object-id pub-id-type="pmid">15356183</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref036">
<label>36</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Srinivasan</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Eden</surname> <given-names>UT</given-names></name>, <name name-style="western"><surname>Willsky</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>. <article-title>A state-space analysis for reconstruction of goal-directed movements using neural signals</article-title>. <source>Neural Computation</source>. <year>2006</year>;<volume>18</volume>(<issue>10</issue>):<fpage>2465</fpage>–<lpage>2494</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2006.18.10.2465" xlink:type="simple">10.1162/neco.2006.18.10.2465</ext-link></comment> <object-id pub-id-type="pmid">16907633</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref037">
<label>37</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Shimazaki</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Amari</surname> <given-names>Si</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>. <chapter-title>State-space analysis on time-varying correlations in parallel spike sequences</chapter-title>. In: <source>Acoustics, Speech and Signal Processing (ICASSP), IEEE International Conference on</source>. <publisher-name>IEEE</publisher-name>; <year>2009</year>. p. <fpage>3501</fpage>–<lpage>3504</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/ICASSP.2009.4960380" xlink:type="simple">10.1109/ICASSP.2009.4960380</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref038">
<label>38</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shimazaki</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Amari</surname> <given-names>Si</given-names></name>, <name name-style="western"><surname>Brown</surname> <given-names>EN</given-names></name>, <name name-style="western"><surname>Grün</surname> <given-names>S</given-names></name>. <article-title>State-space analysis of time-varying higher-order spike correlation for multiple neural spike train data</article-title>. <source>PLoS Computational Biology</source>. <year>2012</year>;<volume>8</volume>(<issue>3</issue>):<fpage>e1002385</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1002385" xlink:type="simple">10.1371/journal.pcbi.1002385</ext-link></comment> <object-id pub-id-type="pmid">22412358</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref039">
<label>39</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Shimazaki</surname> <given-names>H</given-names></name>. <chapter-title>Single-trial estimation of stimulus and spike-history effects on time-varying ensemble spiking activity of multiple neurons: a simulation study</chapter-title>. In: <source>Journal of Physics: Conference Series</source>. <volume>vol. 473</volume>. <publisher-name>IOP Publishing</publisher-name>; <year>2013</year>. <fpage>012009</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1088/1742-6596/473/1/012009" xlink:type="simple">10.1088/1742-6596/473/1/012009</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref040">
<label>40</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Kolar</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Song</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Ahmed</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Xing</surname> <given-names>EP</given-names></name>. <chapter-title>Estimating time-varying networks</chapter-title>. <source>The Annals of Applied Statistics</source>. <year>2010</year>; p. <fpage>94</fpage>–<lpage>123</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/09-AOAS308" xlink:type="simple">10.1214/09-AOAS308</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref041">
<label>41</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Long</surname> <given-names>JDI</given-names></name>, <name name-style="western"><surname>Carmena</surname> <given-names>JM</given-names></name>. <article-title>A statistical description of neural ensemble dynamics</article-title>. <source>Frontiers in Computational Neuroscience</source>. <year>2011</year>;<volume>5</volume>:<fpage>52</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.3389/fncom.2011.00052" xlink:type="simple">10.3389/fncom.2011.00052</ext-link></comment> <object-id pub-id-type="pmid">22319486</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref042">
<label>42</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kass</surname> <given-names>RE</given-names></name>, <name name-style="western"><surname>Kelly</surname> <given-names>RC</given-names></name>, <name name-style="western"><surname>Loh</surname> <given-names>WL</given-names></name>. <article-title>Assessment of synchrony in multiple neural spike trains using loglinear point process models</article-title>. <source>The Annals of Applied Statistics</source>. <year>2011</year>;<volume>5</volume>(<issue>2B</issue>):<fpage>1262</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1214/10-AOAS429" xlink:type="simple">10.1214/10-AOAS429</ext-link></comment> <object-id pub-id-type="pmid">21837263</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref043">
<label>43</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hayashi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Hirayama</surname> <given-names>JI</given-names></name>, <name name-style="western"><surname>Ishii</surname> <given-names>S</given-names></name>. <chapter-title>Dynamic exponential family matrix factorization</chapter-title>. In: <source>Pacific-Asia Conference on Knowledge Discovery and Data Mining</source>. <publisher-name>Springer</publisher-name>; <year>2009</year>. p. <fpage>452</fpage>–<lpage>462</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/978-3-642-01307-2_41" xlink:type="simple">10.1007/978-3-642-01307-2_41</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref044">
<label>44</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Effenberger</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Hillar</surname> <given-names>C</given-names></name>. <chapter-title>Discovery of Salient Low-Dimensional Dynamical Structure in Neuronal Population Activity Using Hopfield Networks</chapter-title>. In: <source>International Workshop on Similarity-Based Pattern Recognition</source>. <publisher-name>Springer</publisher-name>; <year>2015</year>. p. <fpage>199</fpage>–<lpage>208</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/978-3-319-24261-3_16" xlink:type="simple">10.1007/978-3-319-24261-3_16</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref045">
<label>45</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Hirayama</surname> <given-names>Ji</given-names></name>, <name name-style="western"><surname>Hyvärinen</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Ishii</surname> <given-names>S</given-names></name>. <chapter-title>Sparse and low-rank matrix regularization for learning time-varying Markov networks</chapter-title>. <source>Machine Learning</source>. <year>2016</year>; p. <fpage>1</fpage>–<lpage>32</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10994-016-5568-6" xlink:type="simple">10.1007/s10994-016-5568-6</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref046">
<label>46</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Byron</surname> <given-names>MY</given-names></name>, <name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Santhanam</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Ryu</surname> <given-names>SI</given-names></name>, <name name-style="western"><surname>Shenoy</surname> <given-names>KV</given-names></name>, <name name-style="western"><surname>Sahani</surname> <given-names>M</given-names></name>. <chapter-title>Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</chapter-title>. In: <source>Advances in Neural Information Processing Systems</source>; <year>2009</year>. p. <fpage>1881</fpage>–<lpage>1888</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1152/jn.90941.2008" xlink:type="simple">10.1152/jn.90941.2008</ext-link></comment> <object-id pub-id-type="pmid">19357332</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref047">
<label>47</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Cunningham</surname> <given-names>JP</given-names></name>, <name name-style="western"><surname>Byron</surname> <given-names>MY</given-names></name>. <article-title>Dimensionality reduction for large-scale neural recordings</article-title>. <source>Nature Neuroscience</source>. <year>2014</year>;<volume>17</volume>(<issue>11</issue>):<fpage>1500</fpage>–<lpage>1509</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3776" xlink:type="simple">10.1038/nn.3776</ext-link></comment> <object-id pub-id-type="pmid">25151264</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref048">
<label>48</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Okun</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Steinmetz</surname> <given-names>NA</given-names></name>, <name name-style="western"><surname>Cossell</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Iacaruso</surname> <given-names>MF</given-names></name>, <name name-style="western"><surname>Ko</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Barthó</surname> <given-names>P</given-names></name>, <etal>et al</etal>. <article-title>Diverse coupling of neurons to populations in sensory cortex</article-title>. <source>Nature</source>. <year>2015</year>;<volume>521</volume>(<issue>7553</issue>):<fpage>511</fpage>–<lpage>515</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature14273" xlink:type="simple">10.1038/nature14273</ext-link></comment> <object-id pub-id-type="pmid">25849776</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref049">
<label>49</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shimazaki</surname> <given-names>H</given-names></name>. <source>Neurons as an Information-theoretic Engine</source>. <year>2015</year>;arXiv:1512.07855.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref050">
<label>50</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shumway</surname> <given-names>RH</given-names></name>, <name name-style="western"><surname>Stoffer</surname> <given-names>DS</given-names></name>. <article-title>An approach to time series smoothing and forecasting using the EM algorithm</article-title>. <source>Journal of Time Series Analysis</source>. <year>1982</year>;<volume>3</volume>(<issue>4</issue>):<fpage>253</fpage>–<lpage>264</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1111/j.1467-9892.1982.tb00349.x" xlink:type="simple">10.1111/j.1467-9892.1982.tb00349.x</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref051">
<label>51</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Fahrmeir</surname> <given-names>L</given-names></name>. <article-title>Posterior mode estimation by extended Kalman filtering for multivariate dynamic generalized linear models</article-title>. <source>Journal of the American Statistical Association</source>. <year>1992</year>;<volume>87</volume>(<issue>418</issue>):<fpage>501</fpage>–<lpage>509</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1080/01621459.1992.10475232" xlink:type="simple">10.1080/01621459.1992.10475232</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref052">
<label>52</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Kitagawa</surname> <given-names>G</given-names></name>. <article-title>Non-Gaussian state-space modeling of nonstationary time series</article-title>. <source>Journal of the American Statistical Association</source>. <year>1987</year>;<volume>82</volume>(<issue>400</issue>):<fpage>1032</fpage>–<lpage>1041</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/2289381" xlink:type="simple">10.2307/2289381</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref053">
<label>53</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>De Jong</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Mackinnon</surname> <given-names>MJ</given-names></name>. <article-title>Covariances for smoothed estimates in state space models</article-title>. <source>Biometrika</source>. <year>1988</year>;<volume>75</volume>(<issue>3</issue>):<fpage>601</fpage>–<lpage>602</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/biomet/75.3.601" xlink:type="simple">10.1093/biomet/75.3.601</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref054">
<label>54</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Besag</surname> <given-names>J</given-names></name>. <chapter-title>Statistical analysis of non-lattice data</chapter-title>. <source>The Statistician</source>. <year>1975</year>; p. <fpage>179</fpage>–<lpage>195</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.2307/2987782" xlink:type="simple">10.2307/2987782</ext-link></comment></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref055">
<label>55</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Höfling</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Tibshirani</surname> <given-names>R</given-names></name>. <article-title>Estimation of sparse binary pairwise markov networks using pseudo-likelihoods</article-title>. <source>The Journal of Machine Learning Research</source>. <year>2009</year>;<volume>10</volume>:<fpage>883</fpage>–<lpage>906</lpage>. <object-id pub-id-type="pmid">21857799</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref056">
<label>56</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yedidia</surname> <given-names>JS</given-names></name>, <name name-style="western"><surname>Freeman</surname> <given-names>WT</given-names></name>, <name name-style="western"><surname>Weiss</surname> <given-names>Y</given-names></name>. <article-title>Understanding belief propagation and its generalizations</article-title>. <source>Exploring Artificial Intelligence in the New Millennium</source>. <year>2003</year>;<volume>8</volume>:<fpage>236</fpage>–<lpage>239</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref057">
<label>57</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Thouless</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Anderson</surname> <given-names>PW</given-names></name>, <name name-style="western"><surname>Palmer</surname> <given-names>RG</given-names></name>. <article-title>Solution of’solvable model of a spin glass’</article-title>. <source>Philosophical Magazine</source>. <year>1977</year>;<volume>35</volume>(<issue>3</issue>):<fpage>593</fpage>–<lpage>601</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref058">
<label>58</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Yedidia</surname> <given-names>J</given-names></name>. <chapter-title>An idiosyncratic journey beyond mean field theory</chapter-title>. <source>Advanced mean field methods: Theory and practice</source>. <year>2001</year>; p. <fpage>21</fpage>–<lpage>36</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref059">
<label>59</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yuille</surname> <given-names>AL</given-names></name>. <article-title>CCCP algorithms to minimize the Bethe and Kikuchi free energies: Convergent alternatives to belief propagation</article-title>. <source>Neural Computation</source>. <year>2002</year>;<volume>14</volume>(<issue>7</issue>):<fpage>1691</fpage>–<lpage>1722</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/08997660260028674" xlink:type="simple">10.1162/08997660260028674</ext-link></comment> <object-id pub-id-type="pmid">12079552</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref060">
<label>60</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Opper</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Saad</surname> <given-names>D</given-names></name>. <source>Advanced mean field methods: Theory and practice</source>. <publisher-name>MIT Press</publisher-name>; <year>2001</year>.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref061">
<label>61</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tanaka</surname> <given-names>T</given-names></name>. <article-title>Mean-field theory of Boltzmann machine learning</article-title>. <source>Physical Review E</source>. <year>1998</year>;<volume>58</volume>(<issue>2</issue>):<fpage>2302</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref062">
<label>62</label>
<mixed-citation publication-type="book" xlink:type="simple">
<name name-style="western"><surname>Tanaka</surname> <given-names>T</given-names></name>. <chapter-title>A theory of mean field approximation</chapter-title>. <source>Advances in Neural Information Processing Systems</source>. <year>1999</year>; p. <fpage>351</fpage>–<lpage>360</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref063">
<label>63</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shimazaki</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Shinomoto</surname> <given-names>S</given-names></name>. <article-title>Kernel bandwidth optimization in spike rate estimation</article-title>. <source>Journal of Computational Neuroscience</source>. <year>2010</year>;<volume>29</volume>(<issue>1–2</issue>):<fpage>171</fpage>–<lpage>182</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/s10827-009-0180-4" xlink:type="simple">10.1007/s10827-009-0180-4</ext-link></comment> <object-id pub-id-type="pmid">19655238</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref064">
<label>64</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Snyder</surname> <given-names>AC</given-names></name>, <name name-style="western"><surname>Morais</surname> <given-names>MJ</given-names></name>, <name name-style="western"><surname>Willis</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Smith</surname> <given-names>MA</given-names></name>. <article-title>Global network influences on local functional connectivity</article-title>. <source>Nature Neuroscience</source>. <year>2015</year>;<volume>18</volume>(<issue>5</issue>):<fpage>736</fpage>–<lpage>743</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3979" xlink:type="simple">10.1038/nn.3979</ext-link></comment> <object-id pub-id-type="pmid">25799040</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref065">
<label>65</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Akaike</surname> <given-names>H</given-names></name>. <article-title>A new look at the statistical model identification</article-title>. <source>IEEE Transactions on Automatic Control</source>. <year>1974</year>;<volume>19</volume>(<issue>6</issue>):<fpage>716</fpage>–<lpage>723</lpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref066">
<label>66</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Amit</surname> <given-names>DJ</given-names></name>, <name name-style="western"><surname>Brunel</surname> <given-names>N</given-names></name>. <article-title>Model of global spontaneous activity and local structured activity during delay periods in the cerebral cortex</article-title>. <source>Cerebral Cortex</source>. <year>1997</year>;<volume>7</volume>(<issue>3</issue>):<fpage>237</fpage>–<lpage>252</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1093/cercor/7.3.237" xlink:type="simple">10.1093/cercor/7.3.237</ext-link></comment> <object-id pub-id-type="pmid">9143444</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref067">
<label>67</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>van Vreeswijk</surname> <given-names>C</given-names></name>, <name name-style="western"><surname>Sompolinsky</surname> <given-names>H</given-names></name>. <article-title>Chaos in neuronal networks with balanced excitatory and inhibitory activity</article-title>. <source>Science</source>. <year>1996</year>;<volume>274</volume>(<issue>5293</issue>):<fpage>1724</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1126/science.274.5293.1724" xlink:type="simple">10.1126/science.274.5293.1724</ext-link></comment> <object-id pub-id-type="pmid">8939866</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref068">
<label>68</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Mochol</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Hermoso-Mendizabal</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Sakata</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Harris</surname> <given-names>KD</given-names></name>, <name name-style="western"><surname>de la Rocha</surname> <given-names>J</given-names></name>. <article-title>Stochastic transitions into silence cause noise correlations in cortical circuits</article-title>. <source>Proceedings of the National Academy of Sciences</source>. <year>2015</year>;<volume>112</volume>(<issue>11</issue>):<fpage>3529</fpage>–<lpage>3534</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1073/pnas.1410509112" xlink:type="simple">10.1073/pnas.1410509112</ext-link></comment> <object-id pub-id-type="pmid">25739962</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref069">
<label>69</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Steinmetz</surname> <given-names>PN</given-names></name>, <name name-style="western"><surname>Roy</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Fitzgerald</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Hsiao</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Johnson</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Niebur</surname> <given-names>E</given-names></name>. <article-title>Attention modulates synchronized neuronal firing in primate somatosensory cortex</article-title>. <source>Nature</source>. <year>2000</year>;<volume>404</volume>(<issue>6774</issue>):<fpage>187</fpage>–<lpage>190</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/35004588" xlink:type="simple">10.1038/35004588</ext-link></comment> <object-id pub-id-type="pmid">10724171</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref070">
<label>70</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Poulet</surname> <given-names>JF</given-names></name>, <name name-style="western"><surname>Petersen</surname> <given-names>CC</given-names></name>. <article-title>Internal brain state regulates membrane potential synchrony in barrel cortex of behaving mice</article-title>. <source>Nature</source>. <year>2008</year>;<volume>454</volume>(<issue>7206</issue>):<fpage>881</fpage>–<lpage>885</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07150" xlink:type="simple">10.1038/nature07150</ext-link></comment> <object-id pub-id-type="pmid">18633351</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref071">
<label>71</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tan</surname> <given-names>AY</given-names></name>, <name name-style="western"><surname>Chen</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Scholl</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Seidemann</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Priebe</surname> <given-names>NJ</given-names></name>. <article-title>Sensory stimulation shifts visual cortex from synchronous to asynchronous states</article-title>. <source>Nature</source>. <year>2014</year>;<volume>509</volume>(<issue>7499</issue>):<fpage>226</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature13159" xlink:type="simple">10.1038/nature13159</ext-link></comment> <object-id pub-id-type="pmid">24695217</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref072">
<label>72</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Zeng</surname> <given-names>HL</given-names></name>, <name name-style="western"><surname>Alava</surname> <given-names>M</given-names></name>, <name name-style="western"><surname>Aurell</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Hertz</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>. <article-title>Maximum likelihood reconstruction for Ising models with asynchronous updates</article-title>. <source>Physical Review Letters</source>. <year>2013</year>;<volume>110</volume>(<issue>21</issue>):<fpage>210601</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevLett.110.210601" xlink:type="simple">10.1103/PhysRevLett.110.210601</ext-link></comment> <object-id pub-id-type="pmid">23745850</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref073">
<label>73</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Dunn</surname> <given-names>B</given-names></name>, <name name-style="western"><surname>Roudi</surname> <given-names>Y</given-names></name>. <article-title>Learning and inference in a nonequilibrium Ising model with hidden nodes</article-title>. <source>Physical Review E</source>. <year>2013</year>;<volume>87</volume>(<issue>2</issue>):<fpage>022127</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1103/PhysRevE.87.022127" xlink:type="simple">10.1103/PhysRevE.87.022127</ext-link></comment> <object-id pub-id-type="pmid">23496479</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref074">
<label>74</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Brillinger</surname> <given-names>DR</given-names></name>. <article-title>Maximum likelihood analysis of spike trains of interacting nerve cells</article-title>. <source>Biological Cybernetics</source>. <year>1988</year>;<volume>59</volume>(<issue>3</issue>):<fpage>189</fpage>–<lpage>200</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00318010" xlink:type="simple">10.1007/BF00318010</ext-link></comment> <object-id pub-id-type="pmid">3179344</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref075">
<label>75</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Chornoboy</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Schramm</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Karr</surname> <given-names>A</given-names></name>. <article-title>Maximum likelihood identification of neural point process systems</article-title>. <source>Biological Cybernetics</source>. <year>1988</year>;<volume>59</volume>(<issue>4–5</issue>):<fpage>265</fpage>–<lpage>275</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1007/BF00332915" xlink:type="simple">10.1007/BF00332915</ext-link></comment> <object-id pub-id-type="pmid">3196770</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref076">
<label>76</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Pillow</surname> <given-names>JW</given-names></name>, <name name-style="western"><surname>Shlens</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Paninski</surname> <given-names>L</given-names></name>, <name name-style="western"><surname>Sher</surname> <given-names>A</given-names></name>, <name name-style="western"><surname>Litke</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Chichilnisky</surname> <given-names>E</given-names></name>, <etal>et al</etal>. <article-title>Spatio-temporal correlations and visual signalling in a complete neuronal population</article-title>. <source>Nature</source>. <year>2008</year>;<volume>454</volume>(<issue>7207</issue>):<fpage>995</fpage>–<lpage>999</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature07140" xlink:type="simple">10.1038/nature07140</ext-link></comment> <object-id pub-id-type="pmid">18650810</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref077">
<label>77</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Stevenson</surname> <given-names>IH</given-names></name>, <name name-style="western"><surname>Rebesco</surname> <given-names>JM</given-names></name>, <name name-style="western"><surname>Hatsopoulos</surname> <given-names>NG</given-names></name>, <name name-style="western"><surname>Haga</surname> <given-names>Z</given-names></name>, <name name-style="western"><surname>Miller</surname> <given-names>LE</given-names></name>, <name name-style="western"><surname>Kording</surname> <given-names>KP</given-names></name>. <article-title>Bayesian inference of functional connectivity and network structure from spikes</article-title>. <source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source>. <year>2009</year>;<volume>17</volume>(<issue>3</issue>):<fpage>203</fpage>–<lpage>213</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TNSRE.2008.2010471" xlink:type="simple">10.1109/TNSRE.2008.2010471</ext-link></comment> <object-id pub-id-type="pmid">19273038</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref078">
<label>78</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Köster</surname> <given-names>U</given-names></name>, <name name-style="western"><surname>Sohl-Dickstein</surname> <given-names>J</given-names></name>, <name name-style="western"><surname>Gray</surname> <given-names>CM</given-names></name>, <name name-style="western"><surname>Olshausen</surname> <given-names>BA</given-names></name>. <article-title>Modeling higher-order correlations within cortical microcolumns</article-title>. <source>PLoS Computational Biology</source>. <year>2014</year>;<volume>10</volume>(<issue>7</issue>):<fpage>e1003684</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.1003684" xlink:type="simple">10.1371/journal.pcbi.1003684</ext-link></comment> <object-id pub-id-type="pmid">24991969</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref079">
<label>79</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Montani</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Ince</surname> <given-names>RA</given-names></name>, <name name-style="western"><surname>Senatore</surname> <given-names>R</given-names></name>, <name name-style="western"><surname>Arabzadeh</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Diamond</surname> <given-names>ME</given-names></name>, <name name-style="western"><surname>Panzeri</surname> <given-names>S</given-names></name>. <article-title>The impact of high-order interactions on the rate of synchronous discharge and information transmission in somatosensory cortex</article-title>. <source>Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</source>. <year>2009</year>;<volume>367</volume>(<issue>1901</issue>):<fpage>3297</fpage>–<lpage>3310</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1098/rsta.2009.0082" xlink:type="simple">10.1098/rsta.2009.0082</ext-link></comment> <object-id pub-id-type="pmid">19620125</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref080">
<label>80</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Ohiorhenuan</surname> <given-names>IE</given-names></name>, <name name-style="western"><surname>Mechler</surname> <given-names>F</given-names></name>, <name name-style="western"><surname>Purpura</surname> <given-names>KP</given-names></name>, <name name-style="western"><surname>Schmid</surname> <given-names>AM</given-names></name>, <name name-style="western"><surname>Hu</surname> <given-names>Q</given-names></name>, <name name-style="western"><surname>Victor</surname> <given-names>JD</given-names></name>. <article-title>Sparse coding and high-order correlations in fine-scale cortical networks</article-title>. <source>Nature</source>. <year>2010</year>;<volume>466</volume>(<issue>7306</issue>):<fpage>617</fpage>–<lpage>621</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nature09178" xlink:type="simple">10.1038/nature09178</ext-link></comment> <object-id pub-id-type="pmid">20601940</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref081">
<label>81</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Yu</surname> <given-names>S</given-names></name>, <name name-style="western"><surname>Yang</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Nakahara</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Santos</surname> <given-names>GS</given-names></name>, <name name-style="western"><surname>Nikolić</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Plenz</surname> <given-names>D</given-names></name>. <article-title>Higher-order interactions characterized in cortical activity</article-title>. <source>The Journal of Neuroscience</source>. <year>2011</year>;<volume>31</volume>(<issue>48</issue>):<fpage>17514</fpage>–<lpage>17526</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1523/JNEUROSCI.3127-11.2011" xlink:type="simple">10.1523/JNEUROSCI.3127-11.2011</ext-link></comment> <object-id pub-id-type="pmid">22131413</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref082">
<label>82</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Tkačik</surname> <given-names>G</given-names></name>, <name name-style="western"><surname>Marre</surname> <given-names>O</given-names></name>, <name name-style="western"><surname>Mora</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Amodei</surname> <given-names>D</given-names></name>, <name name-style="western"><surname>Berry</surname> <given-names>MJ</given-names> <suffix>II</suffix></name>, <name name-style="western"><surname>Bialek</surname> <given-names>W</given-names></name>. <article-title>The simplest maximum entropy model for collective behavior in a neural network</article-title>. <source>Journal of Statistical Mechanics: Theory and Experiment</source>. <year>2013</year>;<volume>2013</volume>(<issue>03</issue>):<fpage>P03011</fpage>.</mixed-citation>
</ref>
<ref id="pcbi.1005309.ref083">
<label>83</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Shimazaki</surname> <given-names>H</given-names></name>, <name name-style="western"><surname>Sadeghi</surname> <given-names>K</given-names></name>, <name name-style="western"><surname>Ishikawa</surname> <given-names>T</given-names></name>, <name name-style="western"><surname>Ikegaya</surname> <given-names>Y</given-names></name>, <name name-style="western"><surname>Toyoizumi</surname> <given-names>T</given-names></name>. <article-title>Simultaneous silence organizes structured higher-order interactions in neural populations</article-title>. <source>Scientific Reports</source>. <year>2015</year>;<volume>5</volume>:<fpage>9821</fpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/srep09821" xlink:type="simple">10.1038/srep09821</ext-link></comment> <object-id pub-id-type="pmid">25919985</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref084">
<label>84</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Macke</surname> <given-names>JH</given-names></name>, <name name-style="western"><surname>Berens</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ecker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Tolias</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Bethge</surname> <given-names>M</given-names></name>. <article-title>Generating spike trains with specified correlation coefficients</article-title>. <source>Neural Computation</source>. <year>2009</year>;<volume>21</volume>(<issue>2</issue>):<fpage>397</fpage>–<lpage>423</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1162/neco.2008.02-08-713" xlink:type="simple">10.1162/neco.2008.02-08-713</ext-link></comment> <object-id pub-id-type="pmid">19196233</object-id></mixed-citation>
</ref>
<ref id="pcbi.1005309.ref085">
<label>85</label>
<mixed-citation publication-type="journal" xlink:type="simple">
<name name-style="western"><surname>Froudarakis</surname> <given-names>E</given-names></name>, <name name-style="western"><surname>Berens</surname> <given-names>P</given-names></name>, <name name-style="western"><surname>Ecker</surname> <given-names>AS</given-names></name>, <name name-style="western"><surname>Cotton</surname> <given-names>RJ</given-names></name>, <name name-style="western"><surname>Sinz</surname> <given-names>FH</given-names></name>, <name name-style="western"><surname>Yatsenko</surname> <given-names>D</given-names></name>, <etal>et al</etal>. <article-title>Population code in mouse V1 facilitates readout of natural scenes through increased sparseness</article-title>. <source>Nature Neuroscience</source>. <year>2014</year>;<volume>17</volume>(<issue>6</issue>):<fpage>851</fpage>–<lpage>857</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1038/nn.3707" xlink:type="simple">10.1038/nn.3707</ext-link></comment> <object-id pub-id-type="pmid">24747577</object-id></mixed-citation>
</ref>
</ref-list>
</back>
</article>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  PUBLIC "-//NLM//DTD Journal Publishing DTD v3.0 20080202//EN" "http://dtd.nlm.nih.gov/publishing/3.0/journalpublishing3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="discussion" dtd-version="3.0" xml:lang="EN"><front><journal-meta><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="publisher">pcbi</journal-id><journal-id journal-id-type="allenpress-id">plcb</journal-id><journal-id journal-id-type="nlm-ta">PLoS Comput Biol</journal-id><journal-id journal-id-type="pmc">ploscomp</journal-id><!--===== Grouping journal title elements =====--><journal-title-group><journal-title>PLoS Computational Biology</journal-title></journal-title-group><issn pub-type="ppub">1553-734X</issn><issn pub-type="epub">1553-7358</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1371/journal.pcbi.0030252</article-id><article-id pub-id-type="publisher-id">07-PLCB-MI-0342R2</article-id><article-id pub-id-type="sici">plcb-03-12-02</article-id><article-categories><subj-group subj-group-type="heading"><subject>Message from ISCB</subject></subj-group><subj-group subj-group-type="Discipline"><subject>Computational Biology</subject><subject>Computer Science</subject><subject>Mathematics</subject></subj-group><subj-group subj-group-type="System Taxonomy"><subject>Probabilistic graphical models</subject><subject>Statistics</subject><subject>Pattern discovery</subject></subj-group></article-categories><title-group><article-title>Getting Started in Probabilistic Graphical Models</article-title><alt-title alt-title-type="running-head">N/A</alt-title></title-group><contrib-group><contrib contrib-type="author" xlink:type="simple"><name name-style="western"><surname>Airoldi</surname><given-names>Edoardo M</given-names></name><xref ref-type="corresp" rid="cor1"/></contrib></contrib-group><contrib-group><contrib contrib-type="editor" xlink:type="simple"><name name-style="western"><surname>Noble</surname><given-names>William</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">University of Washington, United States of America</aff><author-notes><corresp id="cor1">Edoardo M. Airoldi is with the Lewis-Sigler Institute for Integrative Genomics and the Computer Science Department, Princeton University, Princeton, New Jersey, United States of America. E-mail: <email xlink:type="simple">eairoldi@princeton.edu</email></corresp><fn fn-type="con" id="ack1"><p> EMA wrote the paper.</p></fn><fn fn-type="conflict" id="ack3"><p> The author has declared that there are no competing interests.</p></fn></author-notes><pub-date pub-type="ppub"><month>12</month><year>2007</year></pub-date><pub-date pub-type="epub"><day>7</day><month>12</month><year>2007</year></pub-date><volume>3</volume><issue>12</issue><elocation-id>e252</elocation-id><!--===== Grouping copyright info into permissions =====--><permissions><copyright-year>2007</copyright-year><copyright-holder> Edoardo M. Airoldi</copyright-holder><license><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><funding-group><funding-statement> This research was partly supported by United States National Institute of General Medical Sciences Center of Excellence grant P50 GM071508, by National Science Foundation grants DBI-0546275 and IIS-0513552, and by National Institutes of Health grant R01 GM071966.</funding-statement></funding-group><counts><page-count count="5"/></counts><!--===== Restructure custom-meta-wrap to custom-meta-group =====--><custom-meta-group><custom-meta><meta-name>citation</meta-name><meta-value>Airoldi EM (2007) Getting started in probabilistic graphical models. PLoS Comput Biol 3(12): e252. doi:<ext-link ext-link-type="doi" xlink:href="http://dx.doi.org/10.1371/journal.pcbi.0030252" xlink:type="simple">10.1371/journal.pcbi.0030252</ext-link></meta-value></custom-meta></custom-meta-group></article-meta></front><body><p><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030252.ICSB_logo" xlink:type="simple"/></p><sec id="s0"><title/><p>Probabilistic graphical models (PGMs) have become a popular tool for computational analysis of biological data in a variety of domains. But, what exactly are they and how do they work? How can we use PGMs to discover patterns that are biologically relevant? And to what extent can PGMs help us formulate new hypotheses that are testable at the bench? This Message sketches out some answers and illustrates the main ideas behind the statistical approach to biological pattern discovery.</p></sec><sec id="s1"><title>Introduction</title><p>Probabilistic graphical models offer a common conceptual architecture where biological and mathematical objects can be expressed with a common, intuitive formalism. This enables effective communication between scientists across the mathematical divide by fostering substantive debate in the context of a scientific problem, and ultimately facilitates the joint development of statistical and computational tools for quantitative data analysis. A number of success stories have appeared over the years [<xref ref-type="bibr" rid="pcbi-0030252-b001">1</xref>–<xref ref-type="bibr" rid="pcbi-0030252-b004">4</xref>]. Today, probabilistic graphical models promise to play a major role in the resolution of many intriguing conundrums in the biological sciences. The goal of this short article is to be a dense, informative introduction to <italic>the language</italic> of probabilistic graphical models, for beginners, with <italic>pointers</italic> to successful applications in selected areas of biology. The exposition introduces the essential concepts involved in PGMs in the context of the various stages of a typical collaboration between natural and computational scientists, and discusses the aspects to which each scientist should contribute to carry out the data analysis successfully using PGMs.</p><p>Let us start by considering a specific problem in transcriptional regulation. Given measurements about the abundance of gene transcripts in retinal cells across stages of development, we would like to discover which functional processes are relevant for development, and reveal which ones are most important at which stage. To develop a PGM to address this problem, we begin by identifying the biological objects that would appear in a cartoon model of how cellular development impacts transcription. In this illustrative example, we have genes and functional processes/contexts. It is reasonable to assume that each gene will participate in multiple functional processes, although typically in a small number of them, and that not all functional processes will be important at all stages of development. We then assess what aspects of the problem we can probe directly, with experimental techniques, and what aspects we cannot. In the example, while an abundance of gene transcripts can be obtained, for instance, via SAGE (serial analysis of gene expression), it is harder to measure functional processes. However, the latter could be operationally defined as sets of genes that share a similar temporal regulation pattern; this definition has the advantage of creating a connection between membership of genes to functional processes (i.e., an unobservable mapping) and similarity of the temporal expression profiles (i.e., observable quantities). The establishment of connections between those biological objects that we can probe and those that we cannot ends a first conceptual effort.</p><p>A cartoon model of how cellular development impacts transcription is now specified in terms of genes and their abundance, functional processes, and membership of genes to functional processes. Next we translate the biological players and the connections we established among them into mathematical quantities (i.e., random variables) and connections among them (i.e., statistical dependencies). This translation specifies the model structure. At this stage, we rely on biological intuitions to fine-tune the model, for instance, by deciding which sources of variability in the measurements carry information about the latent variables and which do not—if the temporal expression profiles of genes A and B are similar on a relative scale, but their absolute abundance is quite different, should we believe that they both participate in the same functional processes? Last, we assign numerical values to those quantities that are unknown in the final model specifications (i.e., we fit the model to the data) and we use them to develop biological intuitions in the context of the original problem. (Functional aspects of retinal development, in mouse, are fully addressed in [<xref ref-type="bibr" rid="pcbi-0030252-b005">5</xref>].)</p><p>In the following, we briefly introduce the basic mathematical quantities that enable the translation of a cartoon model of biology into a PGM, and we review strategies to assign numerical values to the unknown quantities underlying any PGM that are most likely given the observations. We conclude with an overview of selected applications, complete with pointers to published work.</p></sec><sec id="s2"><title>The Basics</title><p>A probabilistic graphical model defines a family of probability distributions that can be represented in terms of a graph. Nodes in the graph correspond to random variables; its structure translates into statistical dependencies (among such variables) that drive the computation of joint, conditional, and marginal probabilities of interest [<xref ref-type="bibr" rid="pcbi-0030252-b006">6</xref>]. In applications, most of the (node-specific) random variables are chosen to express the variability of an observed quantity, such as the expression of a specific gene measured under a certain condition. Some random variables, however, may specify unobserved quantities that are believed to influence the observable outcomes of a given experiment, such as which cellular processes were active at the time measurements were taken. The (directed or undirected) arcs of the graph specify the biological hypotheses about how observable and latent quantities influence one another. A set of constants underlying the distributions of the random variables completes the picture. These constants are referred to as <italic>parameters</italic> in the frequentist paradigm and as <italic>hyper-parameters</italic> in the Bayesian paradigm. (See [<xref ref-type="bibr" rid="pcbi-0030252-b007">7</xref>], pp. 185–189, for a discussion of when the distinction matters in practice, with examples.)</p><p><xref ref-type="fig" rid="pcbi-0030252-g001">Figure 1</xref> shows an example of a probabilistic graphical model for gene expression. (We note that there is a considerable overlap between the class of probabilistic graphical models and the class of Bayesian networks. A number of scholars choose to refer to PGMs that <italic>can be represented as directed acyclic graphs, with nodes corresponding to discrete-valued random variables, encoding observed measurements, and no latent variables</italic> as Bayesian networks.) The observed expression of a gene, <italic>Y</italic>(<italic>g</italic>)<italic>,</italic> depends on the latent functional process it is involved in, <italic>X</italic>(<italic>g</italic>)<italic>.</italic> The underlying constants, (<italic>α,β</italic>)<italic>,</italic> control the probability that any given functional process is active and the probability of observing expression of a certain magnitude, respectively. The left panel shows the full model, and the right panel shows the same model expressed in compact form.</p><fig id="pcbi-0030252-g001" position="float"><object-id pub-id-type="doi">10.1371/journal.pcbi.0030252.g001</object-id><label>Figure 1</label><caption><title>Two Equivalent Representations of the Same Probabilistic Graphical Model</title><p>The left panel shows the full model, and the right panel shows the same model expressed in compact form. Nodes denote random variables; observed random variables are shaded while latent random variables are not; edges denote possible dependences. The box in the right panel is called a <italic>plate</italic>; it denotes independent and identically distributed replicates.</p></caption><graphic mimetype="image" position="float" xlink:href="info:doi/10.1371/journal.pcbi.0030252.g001" xlink:type="simple"/></fig><p>The <italic>likelihood function,</italic> or the probability of the measurements given the underlying constants, is the main quantity of interest in PGMs. It summarizes how well the observations are explained by the specific PGM that is identified by a given value of the underlying constants. The likelihood can be computed using the structural hypotheses encoded by the graph, and the probability distributions specified for the nodes. Continuing the example, the likelihood corresponding to the model in <xref ref-type="fig" rid="pcbi-0030252-g001">Figure 1</xref> is computed as follows:
				<disp-formula id="pcbi-0030252-e001"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030252.e001" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mo>Pr</mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mi>Y</mml:mi><mml:mtext>| </mml:mtext><mml:mi>&alpha;</mml:mi><mml:mo>,</mml:mo><mml:mi>&beta;</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:msub><mml:mo>&int;</mml:mo><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mi>Pr</mml:mi></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy='false'>(</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>X</mml:mi><mml:mtext>| </mml:mtext><mml:mi>&alpha;</mml:mi><mml:mo>,</mml:mo><mml:mi>&beta;</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mi>d</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:math> --></disp-formula>
				<disp-formula id="pcbi-0030252-e002"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030252.e002" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mo>&equals;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:msub><mml:mo>&int;</mml:mo><mml:mi>X</mml:mi></mml:msub><mml:mrow><mml:mstyle displaystyle='true'><mml:munderover><mml:mo>&prod;</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>G</mml:mi></mml:munderover></mml:mstyle><mml:mo stretchy='false'>&lsqb;</mml:mo><mml:mo>Pr</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy='false'>(</mml:mo><mml:mi>Y</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mo>g</mml:mo><mml:mo stretchy='false'>)</mml:mo><mml:mo>|</mml:mo><mml:mo>X</mml:mo><mml:mo stretchy='false'>(</mml:mo><mml:mo>g</mml:mo><mml:mo stretchy='false'>)</mml:mo><mml:mo>,</mml:mo><mml:mi>&beta;</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>&sdot;</mml:mo><mml:mtext>Pr</mml:mtext><mml:mo stretchy='false'>(</mml:mo><mml:mi>X</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mtext>|</mml:mtext><mml:mi>&alpha;</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo stretchy='false'>&rsqb;</mml:mo><mml:mi>d</mml:mi><mml:mi>X</mml:mi></mml:mrow></mml:math> --></disp-formula>
				<disp-formula id="pcbi-0030252-e003"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030252.e003" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mo>&equiv;</mml:mo><mml:mi>&ell;</mml:mi><mml:mo stretchy='false'>(</mml:mo><mml:mi>Y</mml:mi><mml:mtext>|</mml:mtext><mml:mi>&Thetas;</mml:mi><mml:mo stretchy='false'>)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>for Θ ≡ (<italic>α</italic>,<italic>β</italic>). The joint probability of measurements and latent variables given the underlying constants, that is, the integrand on the right-end side of <xref ref-type="disp-formula" rid="pcbi-0030252-e001">Equation 1</xref>, is often referred to as the <italic>complete likelihood function</italic> in the literature—an important quantity in the statistical treatment of PGMs with latent variables.
			</p></sec><sec id="s3"><title>Estimation and Inference</title><p>A family of PGMs is <italic>fit to the data</italic> to find likely values for its underlying constants and likely distributions for its latent variables. This process boils down to an optimization problem where the objective function is based on the likelihood. Considered jointly, the estimation and inference tasks identify a specific model in the family of PGMs that is defined by the assumptions on the graph and the random variables, which successfully summarizes the variability of the observations.</p><p>In the language of the statistical literature, we distinguish the task of <italic>estimating</italic> the underlying constants (i.e., the parameters in a frequentist statistical setting, or the hyper-parameters in a Bayesian statistical setting) of a probabilistic graphical model, from the task of <italic>inferring</italic> the distributions of the latent variables given the observations. Let us consider strategies to address the latter task first. The choice among the many strategies available is often informed by the complexity of the model, and in particular by whether the integral on the right-end side of <xref ref-type="disp-formula" rid="pcbi-0030252-e001">Equation 1</xref> can be computed in closed form. Exact inference is available for models that belong to special families [<xref ref-type="bibr" rid="pcbi-0030252-b006">6</xref>]. Focusing on the biology of the problem, however, often leads to a model structure and probabilistic specifications that cannot be subsumed under any special family. The likelihood is intractable in many such cases—that is, the integral in <xref ref-type="disp-formula" rid="pcbi-0030252-e001">Equation 1</xref> cannot be solved in closed form—and we resort to approximations. Below, we briefly survey the intuitions behind three popular strategies to perform approximate inference in PGMs: Monte Carlo Markov chains (sampling-based), and expectation–maximization (EM) and variational methods (optimization-based).</p><p>Monte Carlo Markov chain (MCMC) techniques such as the Gibbs or Metropolis-Hastings samplers can be used to explore the joint posterior distribution of the latent variables [<xref ref-type="bibr" rid="pcbi-0030252-b008">8</xref>,<xref ref-type="bibr" rid="pcbi-0030252-b009">9</xref>]. Although the likelihood is intractable, the complete likelihood <italic>Pr</italic> (<italic>Y,X | α,β</italic>) can be easily computed for the large majority of PGMs. The main concept behind MCMC schemes is to work with the complete likelihood, and to reduce the full joint posterior to lower-dimensional conditional distributions—on individual, or blocks of latent variables—that we can sample from. Samples from the joint posterior are then obtained by composing conditional samples. The Gibbs sampler, for instance, requires that one can sample from all univariate, full-conditional distributions:
				<disp-formula id="pcbi-0030252-e004"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030252.e004" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mo>Pr</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&minus;</mml:mo><mml:mi>g</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>&alpha;</mml:mi><mml:mo>,</mml:mo><mml:mi>&beta;</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext>for</mml:mtext><mml:mspace width="2pt"/><mml:mi>g</mml:mi><mml:mo>&equals;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:mi>G</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>where <italic>X</italic>(<italic>−g</italic>) is the collection of random variables <italic>X</italic> without <italic>X</italic>(<italic>g</italic>)<italic>.</italic> The Metropolis-Hastings sampler requires that one can at least compute a quantity proportional to the desired posterior—samples are drawn from an arbitrary <italic>proposal distribution</italic> and are accepted or rejected using a formula that depends on the proposal. Other sampling-based algorithms such as particle filters can be used to perform inference in PGMs of sequential observations [<xref ref-type="bibr" rid="pcbi-0030252-b010">10</xref>].
			</p><p>The two alternatives to sampling we survey here aim at approximating the integral on the right-end side of <xref ref-type="disp-formula" rid="pcbi-0030252-e001">Equation 1</xref>. The main idea shared by both approaches is to find a lower bound for the likelihood, ℓ (<italic>Y |</italic>Θ)<italic>,</italic> making use of Jensen's inequality and of an arbitrary distribution on the latent variables <italic>q</italic>(<italic>X</italic>):
				<disp-formula id="pcbi-0030252-e005"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030252.e005" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:mtext>log</mml:mtext><mml:mspace width="2pt"/><mml:mi>&ell;</mml:mi><mml:mspace width="2pt"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Y</mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mi>&Thetas;</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&equals;</mml:mo><mml:mtext>log</mml:mtext><mml:mstyle displaystyle='true'><mml:mrow><mml:msub><mml:mo>&int;</mml:mo><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Y</mml:mtext><mml:mo>,</mml:mo><mml:mtext>X</mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mo>,</mml:mo><mml:mi>&beta;</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>dX</mml:mtext></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math> --><!-- <mml:math display='block'><mml:mrow><mml:mo>&equals;</mml:mo><mml:mtext>log</mml:mtext><mml:mstyle displaystyle='true'><mml:mrow><mml:msub><mml:mo>&int;</mml:mo><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mtext>q</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>X</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>&sdot;</mml:mo><mml:mspace width="2pt"/><mml:mtext>Pr</mml:mtext><mml:mspace width="2pt"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Y</mml:mtext><mml:mo>,</mml:mo><mml:mtext>X</mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mo>,</mml:mo><mml:mi>&beta;</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mtext>q</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>X</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mtext>dX&!emsp;</mml:mtext><mml:mtext>(for any q)</mml:mtext></mml:mrow></mml:mrow></mml:mstyle><mml:mtext> </mml:mtext></mml:mrow></mml:math> --><!-- <mml:math display='block'><mml:mrow><mml:mo>&ge;</mml:mo><mml:mstyle displaystyle='true'><mml:mrow><mml:msub><mml:mo>&int;</mml:mo><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mtext>q</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>X</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mstyle><mml:mo>&sdot;</mml:mo><mml:mspace width="2pt"/><mml:mi>log</mml:mi><mml:mspace width="2pt"/><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Y</mml:mtext><mml:mo>,</mml:mo><mml:mtext>X</mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>&alpha;</mml:mi><mml:mo>,</mml:mo><mml:mi>&beta;</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mtext>q</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>X</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mtext>dX &!emsp;</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mspace width="2pt"/><mml:mrow><mml:mtext>Jensen's inequality</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> --><!-- <mml:math display='block'><mml:mrow><mml:mo>&equals;</mml:mo><mml:msub><mml:mn>E</mml:mn><mml:mtext>q</mml:mtext></mml:msub><mml:mrow><mml:mo>&lsqb;</mml:mo><mml:mrow><mml:mi>log</mml:mi><mml:mspace width="2pt"/><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>Y</mml:mtext><mml:mo>,</mml:mo><mml:mtext>X</mml:mtext><mml:mrow><mml:mo>|</mml:mo><mml:mi>&Thetas;</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>&rsqb;</mml:mo></mml:mrow><mml:mo>&minus;</mml:mo><mml:mi>log</mml:mi><mml:mspace width="2pt"/><mml:mtext>q</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>X</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>&equiv;</mml:mo><mml:mtext>L</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>q</mml:mtext><mml:mo>,</mml:mo><mml:mi>&Thetas;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math> --></disp-formula>In EM, the lower bound <italic><monospace>L</monospace></italic> (<italic>q,</italic> Θ) is iteratively maximized with respect to Θ, in the M step, and <italic>q</italic> in the E step [<xref ref-type="bibr" rid="pcbi-0030252-b011">11</xref>]. In particular, at the t-th iteration of the E step the <italic>q</italic> distribution must satisfy the following equation:
				<disp-formula id="pcbi-0030252-e006"><graphic mimetype="image" position="anchor" xlink:href="info:doi/10.1371/journal.pcbi.0030252.e006" xlink:type="simple"/><!-- <mml:math display='block'><mml:mrow><mml:msup><mml:mi>q</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mtext>t</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>&equals;</mml:mo><mml:mo>Pr</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>X</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>&Thetas;</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&minus;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math> --></disp-formula>That is, we set the arbitrary distribution <italic>q</italic> equal to the posterior distribution of the latent variables given the data and the estimates of the parameters at the previous iteration. Unfortunately, it is not always possible to express the distribution <italic>q</italic><sup>(<italic>t</italic>)</sup> in <xref ref-type="disp-formula" rid="pcbi-0030252-e006">Equation 6</xref> in analytic form. In such cases, a variational approximation to the EM [<xref ref-type="bibr" rid="pcbi-0030252-b012">12</xref>] can be obtained by defining a parametric approximation to the posterior in <xref ref-type="disp-formula" rid="pcbi-0030252-e006">Equation 6</xref>, denoted by
					q̃ ≡ <italic>q</italic><sub>Δ</sub> (<italic>X</italic>), which involves an extra set of <italic>variational parameters,</italic> Δ, and leads to an approximate lower bound for the likelihood <italic>L</italic><sub>Δ</sub> (<italic>q,</italic> Θ)<italic>.</italic> At the t-th iteration of the E step, we then minimize the Kullback-Leibler divergence between <italic>q</italic><sup>(<italic>t</italic>)</sup> and <inline-formula id="pcbi-0030252-ex001"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0030252.ex001" xlink:type="simple"/></inline-formula>
					<italic>,</italic> with respect to Δ<italic>,</italic> using the data—this is equivalent to maximizing the approximate lower bound for the likelihood, <italic>L</italic><sub>Δ</sub> (<italic>q,</italic> Θ) with respect to Δ<italic>.</italic> The optimal parametric approximation can be thought of as an approximate posterior distribution for the latent variables in the sense that it depends on the data <italic>Y,</italic> although indirectly, <italic>q</italic><sup>(<italic>t</italic>)</sup> ≈ <inline-formula id="pcbi-0030252-ex002"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0030252.ex002" xlink:type="simple"/></inline-formula>
					 <italic>= Pr</italic> (<italic>X | Y</italic>)<italic>.</italic>
				</p><p>Let us now return to the task of estimating the constants underlying a PGM; few established strategies exist. The estimates for the underlying constants may be chosen, for instance, to maximize the likelihood, or to match empirical and theoretical moments of the random variables that correspond to measurements ([<xref ref-type="bibr" rid="pcbi-0030252-b007">7</xref>], pp. 120–124). Alternatively, when the likelihood is too difficult or expensive to compute, an approximation, <italic>L</italic><sub>Δ</sub> ≈ ℓ<italic>,</italic> or a lower bound, <italic>L ≤</italic> ℓ<italic>,</italic> for the likelihood can be used as a surrogate. These alternatives and others are sometimes referred to as empirical Bayes estimates in the context of nontrivial probabilistic graphical models ([<xref ref-type="bibr" rid="pcbi-0030252-b013">13</xref>], Chapter 3).</p><p>Popular software packages that implement a language to specify and fit PGMs are available. For MCMC, see BUGS [<xref ref-type="bibr" rid="pcbi-0030252-b014">14</xref>]; for variational inference, see VIBES [<xref ref-type="bibr" rid="pcbi-0030252-b015">15</xref>].</p></sec><sec id="s4"><title>Applications</title><p>With the technical machinery we just introduced, we are now ready to bring the biological intuition back into the picture. Let us continue with the transcriptional regulation example. In the PGM of <xref ref-type="fig" rid="pcbi-0030252-g001">Figure 1</xref>, the expression of gene <italic>g</italic> may be encoded by a real-valued random variable <italic>Y</italic>(<italic>g</italic>)<italic>.</italic> The mixed membership of gene <italic>g</italic> to nonobservable biological contexts may be encoded by the nonzero components of a latent random vector, <italic>X</italic>(<italic>g</italic>)<italic>.</italic> The number of latent biological contexts we ask the PGM to infer, denoted by <italic>K,</italic> is an important quantity in this model, which we discuss later—briefly, the value of <italic>K</italic> specifies the <italic>dimensionality</italic> of this PGM, that is, the number of components of the vector-valued latent variables, <italic>X</italic>(<italic>g</italic>)<italic>.</italic> The two constants (<italic>α,β</italic>) may be used to encode biological constraints. For instance, <italic>α</italic> may be used to introduce a notion of biological parsimony in the form of a probabilistic (soft) constraint on the number of biological contexts each gene may participate in, and <italic>β</italic> may be used to specify gene expression patterns in the form of differential expression levels across those experimental conditions for which microarray measurements were taken—alternative pattern specifications and parameterizations exist [<xref ref-type="bibr" rid="pcbi-0030252-b005">5</xref>]. For any given number of latent biological contexts, <italic>K,</italic> the PGM is fit to the data. Estimation and inference will assign numerical values to the unknown quantities (<inline-formula id="pcbi-0030252-ex003"><inline-graphic mimetype="image" xlink:href="info:doi/10.1371/journal.pcbi.0030252.ex003" xlink:type="simple"/></inline-formula>
					<italic>,α,β).</italic> These quantities provide us with <italic>model-based</italic> and <italic>observation-induced</italic> summaries of the data. In the example, for instance, while <italic>β</italic> summarizes gene expression patterns that summarize the main trends of transcription in a collection of microarrays, the values assigned to the latent variables, <italic>X</italic>(<italic>g</italic>), provide gene-specific information that can be used for making fine-grained predictions.
				</p><p>In the last stage of the analysis, we assess the biological relevance of the patterns we inferred from the data (such as the biological contexts, or gene coexpression patterns, in the example) to make sure the model is capturing the signal we set out to capture, and we use the inferred patterns to gain insights into the problem. Assessment of biological relevance can be qualitative or quantitative. Qualitative methods such as visual inspection are typically useful for focused scientific endeavors; for instance, whenever a biological problem targets a small set of genes or a specific cellular process or component, or a signaling pathway. Quantitative methods are necessary for genome-wide scientific endeavors, and typically rely on knowledge-based repositories and ontologies (such as gene ontology [<xref ref-type="bibr" rid="pcbi-0030252-b016">16</xref>]) and bioinformatics tools to carry out the evaluation [<xref ref-type="bibr" rid="pcbi-0030252-b017">17</xref>,<xref ref-type="bibr" rid="pcbi-0030252-b018">18</xref>]. Arguably, in any given application, the more interpretable the patterns are, in terms of functional processes and other biological concepts of interest, the better the family of PGMs captures some aspects of biology that may be relevant for the understanding of the phenomenon under investigation, and that <italic>are not directly measurable</italic> with experimental techniques.</p><p>Moving a step forward, the goodness of model fit is often taken as a measure of <italic>how well</italic> the data support structural biological hypotheses encoded by the cartoon model of biology that was used to posit a given family of PGMs. Measures of goodness of model fit include the Bayesian information criterion, the held-out likelihood obtained using bootstrap or cross-validation techniques, measures of predictive power such as the predictive <italic>R<sup>2</sup></italic> in linear regression, or other quantities, depending on the goals of the analysis. (These measures can also be used to select the dimensionality, <italic>K</italic>, of the PGM in the example.) The goodness of fit, along with the substantive value of the inferred patterns, should inform a critical review of the biological assumptions underlying the initial cartoon model, and possibly suggest new hypotheses—testable either with new statistical analyses, or with new experimental probes at the bench. In this sense, probabilistic graphical models contribute to an iterative process of scientific discovery, where statistical and biological thinking are intertwined as both cause and effect.</p><p>There is a rich history of applied research that leverages the probabilistic graphical models approach outlined above to problems in the biological sciences. It includes a model for inferring the ancestral population structure of individuals starting from a collection of multilocus genotype measurements [<xref ref-type="bibr" rid="pcbi-0030252-b002">2</xref>] and a model for inferring HIV mutation patterns from longitudinal clonal sequence data [<xref ref-type="bibr" rid="pcbi-0030252-b019">19</xref>]; the former model is closely related to the classic probabilistic graphical models to infer phylogenetic trees [<xref ref-type="bibr" rid="pcbi-0030252-b001">1</xref>,<xref ref-type="bibr" rid="pcbi-0030252-b020">20</xref>] and to recent extensions, in particular, that take into account the dependence among the bases at neighboring sites [<xref ref-type="bibr" rid="pcbi-0030252-b021">21</xref>,<xref ref-type="bibr" rid="pcbi-0030252-b022">22</xref>]. Models for sequence analysis are well-established in the community [<xref ref-type="bibr" rid="pcbi-0030252-b004">4</xref>,<xref ref-type="bibr" rid="pcbi-0030252-b023">23</xref>]; more recently, the connection between sequence information and gene expression has been investigated using probabilistic graphical models as well [<xref ref-type="bibr" rid="pcbi-0030252-b024">24</xref>,<xref ref-type="bibr" rid="pcbi-0030252-b025">25</xref>]. Other applications of this research include: a model for predicting the clinical status of breast cancer using gene expression profiles [<xref ref-type="bibr" rid="pcbi-0030252-b026">26</xref>]; a model for facilitating content browsing of biomedical literature about the nematode <named-content content-type="genus-species" xlink:type="simple">Caenorhabditis elegans</named-content> [<xref ref-type="bibr" rid="pcbi-0030252-b027">27</xref>]; a model for inferring the location of chromosome aberrations from array-based comparative genomic hybridization measurements [<xref ref-type="bibr" rid="pcbi-0030252-b028">28</xref>], and an extension that leverages array-based comparative genomic hybridization profiles from multiple individuals to recover shared aberration patterns [<xref ref-type="bibr" rid="pcbi-0030252-b029">29</xref>]; a model for reconstructing features of the internal organization of the cell from the nested structure of observed perturbation effects, such as those measured via high-dimensional phenotype screens [<xref ref-type="bibr" rid="pcbi-0030252-b030">30</xref>]; a model for inferring proteins' multiple functional roles from a large collection of manually curated protein interactions, as well as cross-talk patterns among proteins that participate in distinct functional processes [<xref ref-type="bibr" rid="pcbi-0030252-b031">31</xref>]; and a model for inferring temporal patterns of coexpressed genes from time-course expression data measured via SAGE and microarray technologies [<xref ref-type="bibr" rid="pcbi-0030252-b005">5</xref>].</p><p>Note that the graphical representation of a family of PGMs goes only so far in specifying the model; it's informative, but not exhaustive. Probabilistic assumptions and some features of the sampling scheme cannot be specified by the graph. Such subtle variants typically make a significant difference in applications.</p></sec><sec id="s5"><title>Conclusions</title><p>Probabilistic graphical models offer a common conceptual architecture where biological and mathematical objects can be expressed with a common, intuitive formalism. This enables effective communication between scientists across the mathematical divide by fostering substantive debate in the context of a scientific problem, and ultimately facilitates the joint development of statistical and computational tools for quantitative data analysis. In other words, probabilistic graphical models provide a bridge between biology and statistical computations. These models recently earned a spot at the center stage of modern (computational) biology by furthering our ability to probe data for biological hypotheses, and will undoubtedly play an important role in resolving many intriguing conundrums in the biological sciences, in the future. </p></sec></body><back><ack><p>The author thanks Florian Markowetz, Chad Myers, David Hess, and Olga Troyanskaya at Princeton University, and Eric Xing at Carnegie Mellon University, for comments on an early draft of this manuscript.</p></ack><glossary><title>Abbreviations</title><def-list><def-item><term>EM</term><def><p>expectation–maximization</p></def></def-item><def-item><term>MCMC</term><def><p>Monte Carlo Markov chain</p></def></def-item><def-item><term>PGM</term><def><p>probabilistic graphical model</p></def></def-item></def-list></glossary><ref-list><title>References</title><ref id="pcbi-0030252-b001"><label>1</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Felsenstein</surname><given-names>J</given-names></name></person-group>
						<year>1981</year>
						<article-title>Evolutionary trees from DNA sequences: A maximum likelihood approach.</article-title>
						<source>J Mol Evol</source>
						<volume>17</volume>
						<fpage>368</fpage>
						<lpage>376</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b002"><label>2</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Pritchard</surname><given-names>J</given-names></name><name name-style="western"><surname>Stephens</surname><given-names>M</given-names></name><name name-style="western"><surname>Donnelly</surname><given-names>P</given-names></name></person-group>
						<year>2000</year>
						<article-title>Inference of population structure using multilocus genotype data.</article-title>
						<source>Genetics</source>
						<volume>155</volume>
						<fpage>945</fpage>
						<lpage>959</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b003"><label>3</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Friedman</surname><given-names>N</given-names></name></person-group>
						<year>2004</year>
						<article-title>Inferring cellular networks using probabilistic graphical models.</article-title>
						<source>Science</source>
						<volume>303</volume>
						<fpage>799</fpage>
						<lpage>805</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b004"><label>4</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Xing</surname><given-names>EP</given-names></name><name name-style="western"><surname>Karp</surname><given-names>RM</given-names></name></person-group>
						<year>2004</year>
						<article-title>MotifPrototyper: A profile Bayesian model for motif family.</article-title>
						<source>Proc Natl Acad Sci U S A</source>
						<volume>101</volume>
						<fpage>10523</fpage>
						<lpage>10528</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b005"><label>5</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Airoldi</surname><given-names>EM</given-names></name><name name-style="western"><surname>Fienberg</surname><given-names>SE</given-names></name><name name-style="western"><surname>Xing</surname><given-names>EP</given-names></name></person-group>
						<year>2006</year>
						<source>Mixed membership analysis of expression studies: Attribute data</source>
						<comment>Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/0711.2520/" xlink:type="simple">http://arxiv.org/abs/0711.2520/</ext-link>. Accessed 20 November 2007.</comment>
					</element-citation></ref><ref id="pcbi-0030252-b006"><label>6</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name></person-group>
						<year>2004</year>
						<article-title>Graphical models.</article-title>
						<source>Statistical Science</source>
						<volume>19</volume>
						<fpage>140</fpage>
						<lpage>155</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b007"><label>7</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Wasserman</surname><given-names>L</given-names></name></person-group>
						<year>2004</year>
						<source>All of statistics</source>
						<publisher-loc>New York</publisher-loc>
						<publisher-name>Springer-Verlag</publisher-name>
					</element-citation></ref><ref id="pcbi-0030252-b008"><label>8</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Gelman</surname><given-names>A</given-names></name><name name-style="western"><surname>Carlin</surname><given-names>J</given-names></name><name name-style="western"><surname>Stern</surname><given-names>H</given-names></name><name name-style="western"><surname>Rubin</surname><given-names>D</given-names></name></person-group>
						<year>1995</year>
						<source>Bayesian data analysis</source>
						<publisher-loc>London</publisher-loc>
						<publisher-name>Chapman &amp; Hall</publisher-name>
					</element-citation></ref><ref id="pcbi-0030252-b009"><label>9</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Robert</surname><given-names>C</given-names></name><name name-style="western"><surname>Casella</surname><given-names>G</given-names></name></person-group>
						<year>2005</year>
						<article-title>Monte Carlo statistical methods.</article-title>
						<source>Springer texts in statistics. Corrected second edition</source>
						<publisher-loc>New York</publisher-loc>
						<publisher-name>Springer-Verlag</publisher-name>
					</element-citation></ref><ref id="pcbi-0030252-b010"><label>10</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Liu</surname><given-names>JS</given-names></name></person-group>
						<year>2001</year>
						<source>Monte Carlo strategies in scientific computing</source>
						<publisher-loc>New York</publisher-loc>
						<publisher-name>Springer-Verlag</publisher-name>
					</element-citation></ref><ref id="pcbi-0030252-b011"><label>11</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Dempster</surname><given-names>A</given-names></name><name name-style="western"><surname>Laird</surname><given-names>N</given-names></name><name name-style="western"><surname>Rubin</surname><given-names>D</given-names></name></person-group>
						<year>1977</year>
						<article-title>Maximum likelihood from incomplete data via the EM algorithm.</article-title>
						<source>J R Stat Soc [Series B]</source>
						<volume>39</volume>
						<fpage>1</fpage>
						<lpage>38</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b012"><label>12</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Jordan</surname><given-names>M</given-names></name><name name-style="western"><surname>Ghahramani</surname><given-names>Z</given-names></name><name name-style="western"><surname>Jaakkola</surname><given-names>T</given-names></name><name name-style="western"><surname>Saul</surname><given-names>L</given-names></name></person-group>
						<year>1999</year>
						<article-title>Introduction to variational methods for graphical models.</article-title>
						<source>Machine Learning</source>
						<volume>37</volume>
						<fpage>183</fpage>
						<lpage>233</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b013"><label>13</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Carlin</surname><given-names>BP</given-names></name><name name-style="western"><surname>Louis</surname><given-names>TA</given-names></name></person-group>
						<year>2005</year>
						<source>Bayes and empirical Bayes methods for data analysis. Second edition</source>
						<publisher-loc>London</publisher-loc>
						<publisher-name>Chapman &amp; Hall</publisher-name>
					</element-citation></ref><ref id="pcbi-0030252-b014"><label>14</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Lunn</surname><given-names>DJ</given-names></name><name name-style="western"><surname>Thomas</surname><given-names>A</given-names></name><name name-style="western"><surname>Best</surname><given-names>NG</given-names></name><name name-style="western"><surname>Spiegelhalter</surname><given-names>DJ</given-names></name></person-group>
						<year>2000</year>
						<article-title>WinBUGS: A Bayesian modeling framework: Concepts, structure and extensibility.</article-title>
						<source>Statistics and Computing 10</source>
						<fpage>321</fpage>
						<lpage>333</lpage>
						<comment>Available: <ext-link ext-link-type="uri" xlink:href="http://www.mrc-bsu.cam.ac.uk/bugs/" xlink:type="simple">http://www.mrc-bsu.cam.ac.uk/bugs/</ext-link>. Accessed 8 November 2007.</comment>
					</element-citation></ref><ref id="pcbi-0030252-b015"><label>15</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Bishop</surname><given-names>C</given-names></name><name name-style="western"><surname>Spiegelhalter</surname><given-names>D</given-names></name><name name-style="western"><surname>Winn</surname><given-names>J</given-names></name></person-group>
						<year>2003</year>
						<article-title>VIBES: A variational inference engine for Bayesian networks.</article-title>
						<comment>In:</comment>
						<person-group person-group-type="editor"><name name-style="western"><surname>Becker</surname><given-names>S</given-names></name><name name-style="western"><surname>Thrun</surname><given-names>S</given-names></name><name name-style="western"><surname>Obermayer</surname><given-names>K</given-names></name></person-group>
						<source>Advances in neural information processing systems 15</source>
						<publisher-loc>Cambridge (Massachusetts)</publisher-loc>
						<publisher-name>MIT Press</publisher-name>
						<fpage>777</fpage>
						<lpage>784</lpage>
						<comment>Available: <ext-link ext-link-type="uri" xlink:href="http://vibes.sourceforge.net/" xlink:type="simple">http://vibes.sourceforge.net/</ext-link>. Accessed 8 November 2007.</comment>
					</element-citation></ref><ref id="pcbi-0030252-b016"><label>16</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Ashburner</surname><given-names>M</given-names></name><name name-style="western"><surname>Ball</surname><given-names>CA</given-names></name><name name-style="western"><surname>Blake</surname><given-names>JA</given-names></name><name name-style="western"><surname>Botstein</surname><given-names>D</given-names></name><name name-style="western"><surname>Butler</surname><given-names>H</given-names></name><etal/></person-group>
						<year>2000</year>
						<article-title>Gene ontology: Tool for the unification of biology. The gene ontology consortium.</article-title>
						<source>Nat Genet</source>
						<volume>25</volume>
						<fpage>25</fpage>
						<lpage>29</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b017"><label>17</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Boyle</surname><given-names>EI</given-names></name><name name-style="western"><surname>Weng</surname><given-names>S</given-names></name><name name-style="western"><surname>Gollub</surname><given-names>J</given-names></name><name name-style="western"><surname>Jin</surname><given-names>H</given-names></name><name name-style="western"><surname>Botstein</surname><given-names>D</given-names></name><etal/></person-group>
						<year>2004</year>
						<article-title>GO::TermFinder—Open source software for accessing Gene Ontology terms associated with a list of genes.</article-title>
						<source>Bioinformatics</source>
						<volume>20</volume>
						<fpage>3710</fpage>
						<lpage>3715</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b018"><label>18</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Myers</surname><given-names>CL</given-names></name><name name-style="western"><surname>Barret</surname><given-names>DA</given-names></name><name name-style="western"><surname>Hibbs</surname><given-names>MA</given-names></name><name name-style="western"><surname>Huttenhower</surname><given-names>C</given-names></name><name name-style="western"><surname>Troyanskaya</surname><given-names>OG</given-names></name></person-group>
						<year>2006</year>
						<article-title>Finding function: An evaluation framework for functional genomics.</article-title>
						<source>BMC Genomics</source>
						<volume>7</volume>
						<fpage>187</fpage>
					</element-citation></ref><ref id="pcbi-0030252-b019"><label>19</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Beerenwinkel</surname><given-names>N</given-names></name><name name-style="western"><surname>Drton</surname><given-names>M</given-names></name></person-group>
						<year>2007</year>
						<article-title>A mutagenetic tree hidden Markov model for longitudinal clonal HIV sequence data.</article-title>
						<source>Biostatistics</source>
						<volume>8</volume>
						<fpage>53</fpage>
						<lpage>71</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b020"><label>20</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Felsenstein</surname><given-names>J</given-names></name><name name-style="western"><surname>Churchill</surname><given-names>GA</given-names></name></person-group>
						<year>1996</year>
						<article-title>A hidden Markov model approach to variation among sites in rate of evolution.</article-title>
						<source>Mol Biol Evol</source>
						<volume>13</volume>
						<fpage>93</fpage>
						<lpage>104</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b021"><label>21</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>McAuliffe</surname><given-names>JD</given-names></name><name name-style="western"><surname>Pachter</surname><given-names>L</given-names></name><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name></person-group>
						<year>2004</year>
						<article-title>Multiple-sequence functional annotation and the generalized hidden Markov phylogeny.</article-title>
						<source>Bioinformatics</source>
						<volume>20</volume>
						<fpage>1850</fpage>
						<lpage>1860</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b022"><label>22</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Siepel</surname><given-names>A</given-names></name><name name-style="western"><surname>Haussler</surname><given-names>D</given-names></name></person-group>
						<year>2004</year>
						<article-title>Combining phylogenetic and hidden Markov models in biosequence analysis.</article-title>
						<source>J Comput Biol</source>
						<volume>11</volume>
						<fpage>413</fpage>
						<lpage>428</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b023"><label>23</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Durbin</surname><given-names>R</given-names></name><name name-style="western"><surname>Eddy</surname><given-names>S</given-names></name><name name-style="western"><surname>Krogh</surname><given-names>A</given-names></name><name name-style="western"><surname>Mitchison</surname><given-names>G</given-names></name></person-group>
						<year>1998</year>
						<source>Biological sequence analysis: Probabilistic models of proteins and nucleic acids</source>
						<publisher-loc>Cambridge</publisher-loc>
						<publisher-name>Cambridge University Press</publisher-name>
					</element-citation></ref><ref id="pcbi-0030252-b024"><label>24</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Segal</surname><given-names>E</given-names></name><name name-style="western"><surname>Yelensky</surname><given-names>R</given-names></name><name name-style="western"><surname>Koller</surname><given-names>D</given-names></name></person-group>
						<year>2003</year>
						<article-title>Genome-wide discovery of transcriptional modules from dna sequence and gene expression.</article-title>
						<source>Bioinformatics</source>
						<volume>19</volume>
						<issue>Supplement 1</issue>
						<fpage>i273</fpage>
						<lpage>282</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b025"><label>25</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Beer</surname><given-names>MA</given-names></name><name name-style="western"><surname>Tavazoie</surname><given-names>S</given-names></name></person-group>
						<year>2004</year>
						<article-title>Predicting gene expression from sequence.</article-title>
						<source>Cell</source>
						<volume>117</volume>
						<fpage>185</fpage>
						<lpage>198</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b026"><label>26</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>West</surname><given-names>M</given-names></name><name name-style="western"><surname>Blanchette</surname><given-names>C</given-names></name><name name-style="western"><surname>Dressman</surname><given-names>H</given-names></name><name name-style="western"><surname>Huang</surname><given-names>E</given-names></name><name name-style="western"><surname>Ishida</surname><given-names>S</given-names></name><etal/></person-group>
						<year>2001</year>
						<article-title>Predicting the clinical status of human breast cancer by using gene expression profiles.</article-title>
						<source>Proc Natl Acad Sci U S A</source>
						<volume>98</volume>
						<fpage>11462</fpage>
						<lpage>11467</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b027"><label>27</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Blei</surname><given-names>DM</given-names></name><name name-style="western"><surname>Franks</surname><given-names>K</given-names></name><name name-style="western"><surname>Jordan</surname><given-names>MI</given-names></name><name name-style="western"><surname>Mian</surname><given-names>IS</given-names></name></person-group>
						<year>2006</year>
						<article-title>Statistical modeling of biomedical corpora: Mining the Caenorhabditis genetic center bibliography for genes related to life span.</article-title>
						<source>BMC Bioinformatics</source>
						<volume>7</volume>
						<fpage>250</fpage>
					</element-citation></ref><ref id="pcbi-0030252-b028"><label>28</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Myers</surname><given-names>CL</given-names></name><name name-style="western"><surname>Dunham</surname><given-names>MJ</given-names></name><name name-style="western"><surname>Kung</surname><given-names>SY</given-names></name><name name-style="western"><surname>Troyanskaya</surname><given-names>OG</given-names></name></person-group>
						<year>2004</year>
						<article-title>Accurate detection of aneuploidies in array CGH and gene expression microarray data.</article-title>
						<source>Bioinformatics</source>
						<volume>20</volume>
						<fpage>3533</fpage>
						<lpage>3543</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b029"><label>29</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Shah</surname><given-names>SP</given-names></name><name name-style="western"><surname>Lam</surname><given-names>WL</given-names></name><name name-style="western"><surname>Ng</surname><given-names>RT</given-names></name><name name-style="western"><surname>Murphy</surname><given-names>KP</given-names></name></person-group>
						<year>2007</year>
						<article-title>Modeling recurrent DNA copy number alterations in array CGH data.</article-title>
						<source>Bioinformatics</source>
						<volume>23</volume>
						<fpage>i450</fpage>
						<lpage>i458</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b030"><label>30</label><element-citation publication-type="journal" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Markowetz</surname><given-names>F</given-names></name><name name-style="western"><surname>Kostka</surname><given-names>D</given-names></name><name name-style="western"><surname>Troyanskaya</surname><given-names>OG</given-names></name><name name-style="western"><surname>Spang</surname><given-names>R</given-names></name></person-group>
						<year>2007</year>
						<article-title>Nested effects models for high-dimensional phenotyping screens.</article-title>
						<source>Bioinformatics</source>
						<volume>23</volume>
						<fpage>i305</fpage>
						<lpage>i312</lpage>
					</element-citation></ref><ref id="pcbi-0030252-b031"><label>31</label><element-citation publication-type="other" xlink:type="simple">
						<person-group person-group-type="author"><name name-style="western"><surname>Airoldi</surname><given-names>EM</given-names></name><name name-style="western"><surname>Blei</surname><given-names>DM</given-names></name><name name-style="western"><surname>Fienberg</surname><given-names>SE</given-names></name><name name-style="western"><surname>Xing</surname><given-names>EP</given-names></name></person-group>
						<year>2006</year>
						<source>Mixed membership analysis of high-throughput interaction studies: Relational data</source>
						<comment>Available: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/0706.0294/" xlink:type="simple">http://arxiv.org/abs/0706.0294/</ext-link>. Accessed 20 November 2007.</comment>
					</element-citation></ref></ref-list></back></article>